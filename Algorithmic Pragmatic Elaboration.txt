Algorithmic Pragmatic Elaboration

ChatGPT 4

User
LW
My PhD thesis: Algorithmic Bayesian Epistemology
by Eric Neyman
8 min read
16th Mar 2024
5 comments
215
Rationality
Frontpage
2024 Top Fifty: 26%
+ Add Tag
This is a linkpost for https://arxiv.org/abs/2403.07949
In January, I defended my PhD thesis, which I called Algorithmic Bayesian Epistemology. From the preface:

For me as for most students, college was a time of exploration. I took many classes, read many academic and non-academic works, and tried my hand at a few research projects. Early in graduate school, I noticed a strong commonality among the questions that I had found particularly fascinating: most of them involved reasoning about knowledge, information, or uncertainty under constraints. I decided that this cluster of problems would be my primary academic focus. I settled on calling the cluster algorithmic Bayesian epistemology: all of the questions I was thinking about involved applying the "algorithmic lens" of theoretical computer science to problems of Bayesian epistemology.

Although my interest in mathematical reasoning about uncertainty dates back to before I had heard of the rationalist community, the community has no doubt influenced and strengthened this interest.

The most striking example of this influence is Scott Aaronson's blog post Common Knowledge and Aumann's Agreement Theorem, which I ran into during my freshman year of college.[1] The post made things click together for me in a way that made me more intellectually honest and humble, and generally a better person. I also found the post incredibly intellectually interesting -- and indeed, Chapter 8 of my thesis is a follow-up to Scott Aaronson's academic paper on Aumann's agreement theorem.

My interest in forecast elicitation and aggregation, while pre-existing, was no doubt influenced by the EA/rationalist-adjacent forecasting community.

And Chapter 9 of the thesis (work I did at the Alignment Research Center) is no doubt causally downstream of the rationalist community.

Which is all to say: thank you! Y'all have had a substantial positive impact on my intellectual journey.

 
Chapter descriptions
The thesis contains two background chapters followed by seven technical chapters (Chapters 3-9).

In Chapter 1 (Introduction), I try to convey what exactly I mean by "algorithmic Bayesian epistemology" and why I'm excited about it.

In Chapter 2 (Preliminaries), I give some technical background that's necessary for understanding the subsequent technical chapters. It's intended to be accessible to readers with a general college-level math background. While the nominal purpose of Chapter 2 is to introduce the mathematical tools used in later chapters, the topics covered there are interesting in their own right.

 

Different readers will of course have different opinions about which technical chapters are the most interesting. Naturally, I have my own opinions: I think the most interesting chapters are Chapters 5, 7, and 9, so if you are looking for direction, you may want to tiebreak toward reading those. Here are some brief summaries:

Chapter 3: Incentivizing precise forecasts. You might be familiar with proper scoring rules, which are mechanisms for paying experts for forecasts in a way that incentivizes the experts to report their true beliefs. But there are many proper scoring rules (most famously, the quadratic score and the log score), so which one should you use? There are many perspectives on this question, but the one I take in this chapter is: which proper scoring rule most incentivizes experts to do the most research before reporting their forecast? (See also this blog post I wrote explaining the research.)

Chapter 4: Arbitrage-free contract functions. Now, what if you're trying to elicit forecasts from multiple experts? If you're worried about the experts colluding, your problem is now harder. It turns out that if you use the same proper scoring rule to pay every expert, then the experts can collude to all report the same forecast -- and then redistribute their rewards -- in a way that leaves every expert better off, no matter the outcome, than if they hadn't colluded. (The term for this sort of collusion is "arbitrage".) On the other hand, you now have more flexibility, because you can pay each expert in a way that depends on the other experts' reports. In this chapter, I resolve an open problem by showing how to pay experts in a way that makes such arbitrage impossible.

Chapter 5: Quasi-arithmetic pooling. (One of my favorites.) Let's say that you've used a proper scoring rule to elicit forecasts from multiple experts, and now you want to aggregate them. This chapter's basic take is that your method of aggregation ought to depend on the scoring rule you used. For instance, the log scoring rule incentivizes experts to "be careful" around extreme probabilities: an expert incentivized with the log scoring rule cares substantially about the difference between a 1% chance and a 0.01% chance, while an expert incentivized with the quadratic scoring rule basically doesn't care. So if you're using the log scoring rule for eliciting forecasts, it makes sense to "take low probabilities more seriously" when aggregating the forecasts.

In the chapter, I define quasi-arithmetic (QA) pooling with respect to a proper scoring rule to be a particular method of forecast aggregation that depends on the scoring rule. For example, QA pooling with respect to the quadratic score means averaging the forecasts, while QA pooling with respect to the log score means averaging the log odds. I show that QA pooling has a bunch of nice properties and argue that the connection it establishes between forecast elicitation and forecast aggregation is pretty natural and fundamental.

Chapter 6: Learning weights for logarithmic pooling. QA pooling allows you to put weights on experts, depending on their past performance/how much you trust them. In Chapter 5, I showed that if the proper scoring rule is bounded, then you can efficiently learn weights for experts, by updating the weights based on the experts' performance, in a way that lets your aggregates be almost as good as if you had known the right set of weights from the beginning. But the log scoring rule isn't bounded! This chapter extends this result to the log scoring rule, under the assumption that the experts' forecasts are calibrated.

Chapter 7: Robust aggregation of substitutable signals. (One of my favorites.) Let's say that Alice says there's a 60% chance that it'll rain tomorrow and Bob says there's a 70% chance. How should you aggregate these forecasts into a single, all-things-considered number? The obvious answer is that it depends: if Alice knows strictly more information than Bob, you should say 60%. If Bob knows strictly more than Alice, you should say 70%. If their forecasts are based on disjoint pieces of evidence, your answer should be different from if their forecasts are based on heavily overlapping evidence.

But suppose you just don't know. After all, in practice, you may not have this information. This chapter explores a solution concept called robust aggregation: finding an aggregation strategy that works as well as possible in the worst case over a broad class of possible information structures. The broad class I study here is, roughly speaking, information structures that satisfy informational substitutes, meaning that learning an additional expert's information is less valuable, the more information you already know (i.e., diminishing marginal returns). One highlight of this chapter is a theoretical justification for the practice of extremization: pushing the aggregate forecast away from the prior (see Jaime Sevilla's writeup here).

Chapter 8: When does agreement imply accuracy? Suppose that Alice and Bob disagree about the value of some quantity, because they have different private information. How can they reach agreement? They can of course do so by exchanging all of their information, but that can take a really large amount of communication. Scott Aaronson's 2005 paper shows that Alice and Bob can quickly reach agreement simply by repeatedly exchanging their estimates (Alice tells Bob her estimate; Bob tells Alice his estimate after updating on what Alice just said; Alice tells Bob her estimate after updating on what Bob just said; and so on). However, this agreement could be very superficial: once Alice and Bob agree, the number they agree on might differ substantially from the number they would have agreed on, had they actually exchanged all of their information. This chapter establishes a sufficient condition under which, if Alice and Bob agree, their agreed-upon estimate does reflect the estimate they would reach if they exchanged all of their information.

Chapter 9: Deductive circuit estimation. (One of my favorites.) This chapter represents work I did at the Alignment Research Center around April-May of last year. In Formalizing the presumption of independence, we asked whether the process of deductive reasoning can be formalized. In this chapter, I explore deductive reasoning in the special case of boolean circuits. Informally, a deductive estimation algorithm takes as input a boolean circuit and an explanation of the circuit's behavior (in some formal language) and outputs an estimate of the fraction of inputs on which the circuit outputs 1. I explore how deductive estimation algorithms ought to behave, and give both positive results ("here's an efficient deductive estimation algorithm that satisfies linearity and respect for proofs") and negative results ("but no efficient deductive estimation algorithm additionally satisfies 0-1 boundedness").

 

A note on the title
The thesis is called "Algorithmic Bayesian Epistemology". I think most people here know roughly what I mean by "Bayesian epistemology".

The word "algorithmic" is more of a term of art, referring to the "algorithmic lens" of theoretical computer science. Quoting from the introduction:

The relationship between Bayesian epistemology and algorithmic Bayesian epistemology is the same as the relationship between game theory and algorithmic game theory, and as the relationship between mechanism design and algorithmic mechanism design.

Mechanism design -- traditionally a sub-discipline of economics -- asks the question: how can we design systems containing strategic agents pursuing their own incentives, in a way that produces good outcomes? For example, how can we auction off multiple items to multiple bidders in a way that produces the optimal social welfare for the bidders? The traditional answer from economic theory is the Vickrey-Clarke-Groves (VCG) auction, which elicits bids, computes the optimal allocation of items, and charges each bidder based on their externality on the remaining bidders.

Computer scientists find this answer dissatisfying, for a simple reason: computing the optimal allocation is not feasible, from the standpoint of both communication and computation. First, the bidders' preferences may not be compactly representable, in which case it is infeasible to communicate them to the auctioneer. Second, even if the bidders' preferences are compactly representable, actually computing the optimal allocation may still be intractable. And so algorithmic mechanism design asks the question: how can we design a computationally and communicationally tractable auction mechanism that attains a large fraction of the optimal social welfare?

Algorithmic mechanism design belongs to a longstanding tradition in theoretical computer science: considering problems from other disciplines through an algorithmic lens.[2] That is, instead of asking for the optimal solution to a problem, computer scientists ask: what is the best solution that can actually be implemented, given real-world (or real-world-inspired) constraints?

Sometimes, these constraints are computational: what is the best solution that can be found in polynomial time? Other times, the constraints are communciational: what is the best solution if parties are limited in how much they can communicate? Other kinds of constraints are also common. For example:

Constraints on information. For example, the subfield of online algorithms studies sequential decision making under uncertainty (incomplete information). Often, the goal of an online algorithm is to guarantee a result that is almost as good as the best possible result in hindsight, e.g. the prophet inequality from optimal stopping theory, or no-regret algorithms in online learning.
Constraints imposed by the strategic behavior of agents in a system. For example, many computer scientists study the price of anarchy: how much the welfare of a system degrades because of self-interested actors, as compared to a welfare-optimizing central planner.
The study of real-world problems through the algorithmic lens has significantly impacted a variety of disciplines, including molecular biology, ecology, neuroscience, quantum physics, and various social sciences.[3]

And so, algorithmic Bayesian epistemology is simply the application of the algorithmic lens to the discipline of Bayesian epistemology. It is perhaps best to define algorithmic Bayesian epistemology by its examples, but to attempt a loose description:

A question belongs to the field of algorithmic Bayesian epistemology if it involves reasoning about uncertainty from a Bayesian perspective, but under constraints that prevent complete assimilation of all existing information.
ChatGPT
The PhD thesis titled "Algorithmic Bayesian Epistemology" by Eric Neyman explores the intersection of theoretical computer science and Bayesian epistemology, focusing on the challenges and solutions in reasoning about knowledge, information, and uncertainty under constraints. Neyman's journey into this field was influenced by the rationalist community and works like Scott Aaronson's blog post on Common Knowledge and Aumann's Agreement Theorem, fostering a deeper interest in mathematical reasoning about uncertainty.

The thesis comprises two introductory chapters that lay the groundwork for seven technical chapters, each delving into specific aspects of algorithmic Bayesian epistemology. Chapters of particular interest, as highlighted by Neyman, include:

Chapter 3, which discusses incentivizing precise forecasts through proper scoring rules and aims to determine which rule encourages experts to conduct the most research before making their forecasts.
Chapter 4, addressing the challenge of arbitrage-free contract functions to prevent collusion among experts when eliciting forecasts from multiple sources.
Chapter 5, introducing quasi-arithmetic pooling as a method of forecast aggregation that depends on the scoring rule used, advocating for the consideration of low probabilities in aggregation when using specific scoring rules like the log score.
Chapter 6, focusing on learning weights for logarithmic pooling to optimize forecast aggregation based on expert performance.
Chapter 7, exploring robust aggregation of substitutable signals, offering theoretical justification for extremization in forecast aggregation under uncertain information structures.
Chapter 8, examining conditions under which agreement implies accuracy in estimations based on private information without the need for exhaustive information exchange.
Chapter 9, discussing deductive circuit estimation in the context of formalizing deductive reasoning, presenting both positive and negative results for efficient deductive estimation algorithms.
Neyman's work not only contributes to the theoretical foundation of algorithmic Bayesian epistemology but also offers practical insights and methodologies for dealing with uncertainty and information processing under constraints. This thesis stands as a significant contribution to the field, demonstrating the valuable interplay between theoretical computer science and epistemology.

User
a total reward that is almost as high as if they had chosen the i xed option that had the highest total 
reward over the 𝑈 time steps. This is an example of an algorithmic problem under informational 
constraints: the constraint here is that the decision-maker knows nothing about the quality of each 
optionbeforehand, yetmustdonearlyaswellasiftheyhadknownthebestf i xedoption(onaverage 
over the time steps). Online learning is a well-studied i eld; see Orabona (2023) for an overview. 
We are interested in the subproblem of online prediction from expert advice. At each time step, 
𝑛 experts forecast probability distributions over 𝑜 possible outcomes. The decision-maker then 
chooses their own probability distribution over the outcomes. Afterward, an outcome is realized 
and the decision-maker is given a reward based on their distribution and the outcome (generally 
using a proper scoring rule – see Section 1.2.4). The decision-maker aims to compete with the 
best expert in hindsight, or perhaps even with the best possible mixture (e.g. weighted average) 
of experts in hindsight. See Cesa-Bianchi and Lugosi (2006) for a survey of this topic. We will 
explore online prediction from expert advice in Chapter 6. 
Estimation theoryIn statistics, estimation theory is the study of estimating the parameters of 
a distribution given samples from the distribution. A simple example is estimating the mean of 
a normal distribution with variance 1 based on samples. Given a prior over the true mean, one 
can apply Bayes’ rule to exactly compute the expected value of the mean, using the sample mean 
as evidence. However, estimation theory typically concerns itself with estimating parameters in 
settings in which the prior is not known. One common approach is the minimax estimator, which 
is the estimator with the best performance (e.g. as measured by expected squared error) in the worst 
11 
case over possible priors (or equivalently, in the worst case over parameters of the distribution). An 
alternative framing on minimax estimation is one of adversarial robustness: the minimax estimator 
is the optimal estimator if the prior over parameters is chosen by an adversary. Minimax estimators 
are thus a classic example of Bayesian epistemology under informational constraints: while not 
Bayesian in the traditional sense (they do not assume a prior), they can be thought of as the correct 
Bayesian estimate in the context of an adversarially chosen prior. 
The minimax estimator is one example of a natural approach to estimation when lacking a prior 
over distribution parameters. Other approaches include unbiased minimum-variance estimators 
and maximum likelihood estimators. See Kay (1993) for a thorough treatment of the topic. 
Reasoning about UncertaintyReasoning about Uncertainty (Halpern, 2003) is a book on un- 
certainty in the context of different notions of probability that depart from the standard one. For 
example, how might one reason about uncertainty if one is only able to assign probabilities to 
some subsets of possible events but not other subsets? How should we deal with probabilities that 
are def i ned under axioms that are weaker than the standard ones? These perspectives are more 
distantly related to the topics of this thesis than most topics covered in this introduction.
ChatGPT
This excerpt delves into two main topics within the broader field of algorithmic Bayesian epistemology: online prediction from expert advice and estimation theory, emphasizing the challenges and strategies in decision-making under uncertainty and informational constraints.

Online Prediction from Expert Advice
Online prediction involves making decisions based on predictions from multiple experts, without prior knowledge of which option would be best. This scenario is framed as an online learning problem, where a decision-maker aims to match or exceed the performance of the best expert or the best composite expert (using, for example, a weighted average of advice) in hindsight, despite initial ignorance about the options' outcomes. The decision-maker uses forecasts from experts to choose a probability distribution over possible outcomes, adjusting strategies based on rewards received from realized outcomes, typically calculated using a proper scoring rule. This process illustrates the challenge of making informed decisions with limited information, aiming to achieve a reward nearly as high as if the optimal choice were known from the start.

Estimation Theory
Estimation theory concerns the statistical methods used to estimate the parameters of a distribution from sampled data. A classic example involves estimating the mean of a normal distribution. The field often deals with situations where the prior distribution of parameters is unknown, requiring strategies like minimax estimators, which minimize the maximum expected loss across all possible prior distributions. This approach, emphasizing adversarial robustness, represents a strategy for making estimates under extreme informational constraints, offering a solution when a Bayesian prior is absent or unknown. Other methods, such as unbiased minimum-variance estimators and maximum likelihood estimators, offer alternative strategies for parameter estimation under uncertainty.

Implications for Algorithmic Bayesian Epistemology
Both topics underscore the essence of algorithmic Bayesian epistemology: navigating the challenge of making reasoned decisions and estimations under significant constraints, such as limited prior knowledge, the strategic behavior of others, or adversarial conditions. By applying mathematical and algorithmic tools, these approaches seek to optimize decision-making and estimation processes within the bounds of available information, illustrating the practical application of theoretical concepts to real-world problems of uncertainty and information processing.

User
A list of all of the topics we've discussed.
ChatGPT
Here's a summary of the topics we've discussed:

Eric Neyman's PhD Thesis on Algorithmic Bayesian Epistemology: We explored the contents and implications of Neyman's PhD thesis, which applies the "algorithmic lens" of theoretical computer science to Bayesian epistemology. This interdisciplinary work aims to address reasoning about knowledge, information, and uncertainty under constraints, drawing influence from the rationalist community and specific works like Scott Aaronson's on Common Knowledge and Aumann's Agreement Theorem.

Key Chapters and Themes in Neyman's Thesis: We delved into summaries of select chapters from Neyman's thesis, highlighting his exploration into incentivizing precise forecasts, arbitrage-free contract functions, quasi-arithmetic pooling, learning weights for logarithmic pooling, robust aggregation of substitutable signals, the implications of agreement for accuracy, and deductive circuit estimation.

Online Prediction from Expert Advice: This topic discusses decision-making processes based on predictions from multiple experts, underpinning the challenge of achieving optimal outcomes without prior knowledge of each option's potential. It emphasizes online learning and the decision-maker's aim to match or outperform the best expert or composite advice in hindsight.

Estimation Theory: We covered the basics of estimation theory in statistics, which focuses on estimating the parameters of a distribution from sampled data, especially under conditions where prior information is unavailable. We looked at approaches like minimax estimators, highlighting their role in making robust estimates under informational constraints.

These discussions span a range of concepts at the intersection of theoretical computer science, Bayesian epistemology, and decision theory, reflecting the depth and breadth of Neyman's research as well as broader topics in reasoning under uncertainty.

User
So it sounds like an "algorithmic" version of a theory focuses more on making it modular, replicable, explainable, and so on, as opposed to more theoretical or abstract ideals?
ChatGPT
Yes, that's a good way to look at it. When we talk about the "algorithmic" version of a theory, it often means adapting the theory to practical applications under real-world constraints, making it more modular, replicable, and explainable. This involves taking a more computational and practical approach to problems that were traditionally considered in more abstract or theoretical terms.

For instance, in the context of algorithmic Bayesian epistemology, this means applying the principles of Bayesian epistemology—such as updating beliefs based on new evidence—under constraints that are significant in practical scenarios, like limited computational resources, the need for decisions to be made in real-time, or the availability of incomplete information.

This approach aims to make theories not just conceptual frameworks for understanding the world but also tools that can be directly applied to solve real-world problems. It emphasizes efficiency, scalability, and the ability to deal with the complexities and limitations inherent in practical applications.

User
I decided to call the conversation "Algorithmic Pragmatic Elaboration"
ChatGPT
"Algorithmic Pragmatic Elaboration" is a compelling title! It suggests a focus on practical application, elaboration, and refinement of ideas through an algorithmic lens. This title evokes a methodology that not only seeks to understand theoretical concepts but also emphasizes their practical implementation and the iterative process of making those concepts more applicable and effective in real-world situations. It reflects a bridge between the theoretical and the practical, aiming to systematically solve problems by breaking them down into smaller, manageable parts that can be analyzed, understood, and optimized algorithmically.

User
Connections with the previous topics.
ChatGPT
"Algorithmic Pragmatic Elaboration" connects seamlessly with our previous discussions, particularly in the context of Eric Neyman's PhD thesis on Algorithmic Bayesian Epistemology and the broader themes of decision-making under uncertainty, online prediction from expert advice, and estimation theory. Here’s how:

Algorithmic Bayesian Epistemology: Neyman’s work is a foundational example of Algorithmic Pragmatic Elaboration. He applies an algorithmic approach to Bayesian epistemology, focusing on practical, computational considerations in the process of reasoning about uncertainty. This embodies the pragmatic elaboration of theoretical concepts to address real-world problems, making abstract ideas about knowledge and belief updating actionable under constraints like limited information and computational resources.

Online Prediction from Expert Advice: This topic is directly aligned with the notion of pragmatic elaboration, as it involves developing algorithmic solutions for making predictions based on expert advice, despite not knowing in advance which advice is best. It's about creating practical, replicable systems that can adapt and learn over time, optimizing decisions in uncertain environments. This is a clear application of elaborating on theoretical knowledge to create useful, dynamic decision-making mechanisms.

Estimation Theory: Estimation theory's focus on devising methods to estimate unknown parameters from observed data—especially through minimax estimators and other robust techniques—represents the pragmatic elaboration of statistical theories for real-world application. It involves translating theoretical statistical principles into algorithms that can perform effectively under a variety of challenging conditions, including adversarial settings or when prior information is lacking.

Adaptation to Constraints: The "algorithmic" aspect in "Algorithmic Pragmatic Elaboration" emphasizes adapting theoretical models to the practical constraints of the real world, such as computational limitations, incomplete information, and the need for rapid decision-making. This is a thread that runs through all the topics we've discussed, highlighting the importance of not just understanding theories but also making them operational in complex, uncertain environments.

"Algorithmic Pragmatic Elaboration" encapsulates the essence of applying a systematic, algorithmic approach to expand on theoretical concepts, making them more applicable, understandable, and useful in addressing practical problems. It underscores the iterative process of refining and applying these concepts to navigate the complexities and uncertainties of the real world effectively.

User
Section 3: A Pragmatic Conception of Artificial Intelligence
What I will call the “algorithmic pragmatic elaboration” version of AI-functionalism—or
just “pragmatic AI”—is the claim that there is a set of practices-or-abilities meeting two
conditions:
1) It can be algorithmically elaborated into (the ability to engage in) an autonomous
discursive practice (ADP);
and
2) Every element in that set of primitive practices-or-abilities can intelligibly be
understood to be engaged in, possessed, exercised, or exhibited by something that does not
engage in any ADP.
The first of these is a kind of PP-sufficiency claim—specifically, an algorithmic elaboration PPsufficiency claim. The second is the denial of a PP-necessity claim.
 1
 Brandom
The important difference between this formulation and classical symbolic AI is that the
connection to computers (or as I would prefer to say, automata) is not established via the
principle that computers are symbol-manipulating engines and that according to the
computational theory of the mind thinking just consists in manipulating symbols, but rather via
PP-sufficiency of the algorithmic elaboration sort that I discussed in my second lecture.
The pragmatic version of AI is a very general structural claim that could be made about any kind
of practice-or-ability. The issue it raises need have nothing whatever to do with symbolmanipulation. For any practice-or-ability P, we can ask whether that practice-or-ability can be
algorithmically decomposed (pragmatically analyzed) into a set of primitive practices-or-abilties
such that:
1) They are PP-sufficient for P, in the sense that P can be algorithmically elaborated
from them (that is, that all you need in principle to be able to engage in or exercise P is to
be able to exercise those abilities plus the algorithmic elaborative abilities, when these are
all integrated as specified by some algorithm);
and
2) One could have the capacity to engage in or exercise each of those primitive
practices-or-abilities without having the capacity to engage in or exercise P.
If those two conditions are met, we may say that P is substantively algorithmically
decomposable into those primitive practices-or-abilities. 

Between Saying and Doing: Towards an Analytic Pragmatism
Robert B. Brandom

Contents

1 Extending the Project of Analysis
2 Elaborating Abilities: The Expressive Role of Logic
Collapse3 Artificial Intelligence and Analytic Pragmatism
1 AI‐Functionalism
2 Classic Symbolic Artificial Intelligence
3 A Pragmatic Conception of Artificial Intelligence
4 Arguments Against AI‐Functionalism: Ranges of Counterfactual Robustness for Complex Relational Predicates
5 Practical Elaboration by Training
6 Algorithmic Pedagogical Decomposition and Pedagogical Politics
4 Modality and Normativity: From Hume and Quine to Kant and Sellars
5 Incompatibility, Modal Semantics, and Intrinsic Logic
6 Intentionality as a Pragmatically Mediated Semantic Relation
Afterword: Philosophical Analysis and Analytic Philosophy
ExpandEnd Matter
< Previous chapter
Next chapter >
Annotate icon Annotate
Cite Icon Cite
Permissions Icon Permissions
Share Icon Share 
Navbar Search Filter
Oxford Academic
Enter search term
Search
CHAPTER
3 Artificial Intelligence and Analytic Pragmatism Get access Arrow
Robert B. Brandom
https://doi.org/10.1093/acprof:oso/9780199542871.003.0003
 Pages 69–91
Published: April 2008
Annotate icon Annotate
Cite Icon Cite
Permissions Icon Permissions
Share Icon Share 
Abstract
A pragmatic version of the program of artificial intelligence is presented, contrasting with the classical symbolic approach. At its center is the claim that there can be a set of abilities that can both be algorithmically elaborated into the ability to engage in some autonomous discursive practice (a language game one can play though one plays no other) and every element of which can be exhibited by things that do not engage in any autonomous discursive practice. The difficulty of computing ranges of counterfactual robustness for complex relational predicates is offered as a reason for skepticism about this claim. The notion of pedagogical elaboration of abilities is contrasted with that of algorithmic elaboration.

Keywords: artificial intelligence, pedagogy, algorithm, pragmatism, symbol, practice, counterfactuals
Subject EpistemologyPhilosophy of LanguagePhilosophy of Mind
Collection: Oxford Scholarship Online
ChatGPT
The section you've introduced from Robert B. Brandom's work delves into a pragmatic version of artificial intelligence (AI), which he terms as "algorithmic pragmatic elaboration." This concept contrasts with classical symbolic AI, moving away from the idea that thinking and intelligence are solely about symbol manipulation within computational systems. Instead, it introduces a more nuanced view that focuses on the sufficiency and decomposability of practices or abilities that can lead to the emergence of autonomous discursive practices (ADPs).

Key Points from Brandom's Discussion:
Algorithmic Pragmatic Elaboration of AI: Brandom proposes that AI can be understood through a set of primitive practices or abilities that, when algorithmically elaborated, can lead to ADPs. This means that an AI system could engage in some form of discourse or "language game" autonomously, without necessitating human-like cognition or symbolic manipulation as its foundational principle.

PP-Sufficiency and Denial of PP-Necessity: The idea introduces two critical claims:

PP-Sufficiency: Certain practices or abilities are sufficient, through algorithmic elaboration, for the emergence of ADPs. This sufficiency does not rely on the traditional symbol manipulation theory of mind but rather on the pragmatic decomposition and integration of simpler abilities.
Denial of PP-Necessity: It's possible for an entity to possess or exhibit these primitive practices or abilities without engaging in any ADPs. This suggests a modular approach to understanding intelligence, where complex cognitive tasks can be broken down into simpler, non-discursive abilities.
Contrast with Classical Symbolic AI: Brandom emphasizes that his pragmatic AI perspective diverges from the classical view by focusing on pragmatic sufficiency rather than symbol manipulation. This approach allows for a broader interpretation of what constitutes AI, including systems that might not fit the traditional computational or symbolic framework but still exhibit forms of intelligence or autonomous behavior.

Analytic Pragmatism and AI: The broader context of Brandom's work ties into analytic pragmatism, suggesting that AI should be analyzed and developed with a focus on practical abilities and the conditions under which these abilities can be considered sufficient for certain types of intelligent behavior.

Complex Relational Predicates and Pedagogical Elaboration: Brandom raises concerns about the computational difficulty of assessing counterfactual robustness for complex relational predicates, pointing to potential limitations of algorithmic approaches. He contrasts algorithmic elaboration with pedagogical elaboration, the latter of which involves the training and development of abilities in more nuanced and context-sensitive ways.

Brandom's pragmatic conception of AI encourages a reevaluation of how we understand and develop artificial intelligence, advocating for a focus on the practical and decomposable elements of intelligence rather than strictly adhering to traditional computational models. This perspective opens up new avenues for AI research and development, emphasizing flexibility, contextuality, and the potential for systems to exhibit forms of intelligence that diverge from human cognition or symbolic processing.

User
Section 1: AI-Functionalism
Classical AI-functionalism is the claim that there is some program such that anything that runs
that program can pass the Turing test, that is, can deploy a vocabulary in the same sense in which
any other language-users do. And that is to say that a computer language, in which any such
algorithm can be expressed, is in principle VP-sufficient to specify abilities that are PV-sufficient
to deploy an autonomous vocabulary. So in my terms, classical AI-functionalism claims that
computer languages are in principle sufficient pragmatic metavocabularies for some autonomous
vocabulary. Since computer languages (syntactically, context-free languages) are not themselves
autonomous vocabularies, the basic claim of AI-functionalism is a strict expressive
bootstrapping claim about computer languages as pragmatic metavocabularies for much more
expressively powerful vocabularies: natural languages. It is a claim about what one must be able
to do in order to count thereby as saying anything.
I take the working-out of various forms of functionalism in the philosophy of mind (including the
computational species)—a view about what is expressed by (that is, about the semantics of)
intentional vocabulary—to be one of the cardinal achievements of Anglophone philosophy in the
second half of the twentieth century. (Behaviorism was a larval stage of it.) It deserves to be
thought of as a third core program of the classical project of philosophical analysis, alongside
empiricism and naturalism.
Section 2: Classic Symbolic Artificial Intelligence
Functionalism is a more promising explanatory strategy when addressed to sapience rather than
to sentience.
The slogan of classical symbolic AI is: Mind is to brain as software is to hardware. 
ChatGPT
The discussion you've introduced from Robert B. Brandom's work on AI-functionalism and classic symbolic artificial intelligence offers a deep dive into the philosophical underpinnings of AI and its conceptual evolution.

AI-Functionalism
AI-functionalism, as described, posits that the essence of linguistic and cognitive abilities can be encapsulated within a computer program, suggesting that any entity running such a program could effectively use language in a way indistinguishable from human language users. This perspective hinges on the belief that computer languages, though not autonomous vocabularies themselves, can serve as sufficient "pragmatic metavocabularies" for more complex and expressive languages, like natural human languages. Essentially, it argues for the possibility of "expressive bootstrapping," where the relatively simple, syntactic structures of computer languages can underpin the rich, semantic complexities of natural language.

Classic Symbolic Artificial Intelligence
The relation of mind to brain is analogized to software to hardware in classical symbolic AI, emphasizing the separation between the physical substrate (hardware/brain) and the cognitive or linguistic processes (software/mind) that run on top of it. This view aligns with functionalism by suggesting that cognitive abilities—and by extension, consciousness or sentience—can be abstracted away from the physical specifics of the brain and replicated on different substrates, provided the functional relationships and processes are maintained.

Key Insights and Implications
Expressive Bootstrapping and Metavocabularies: AI-functionalism's core claim about expressive bootstrapping highlights a foundational belief in AI research—that the structures and capabilities required for language use and cognitive processing can be abstracted and recreated in computational terms. This perspective sees computer languages as capable of serving as the groundwork upon which the more complex abilities of natural language use can be built.

Functionalism in Philosophy of Mind: Brandom acknowledges functionalism as a significant philosophical development, particularly in its application to understanding the mind. By focusing on the functions and processes of the mind rather than its physical substrate, functionalism provides a framework for conceptualizing how minds could be replicated or simulated in non-biological systems.

Sapience vs. Sentience: The distinction between sapience (wisdom or intelligence) and sentience (capacity to feel) is crucial in the context of AI. Classic symbolic AI and functionalist perspectives are more readily applied to sapience, dealing with cognitive and linguistic capabilities, rather than sentience, which involves subjective experience and consciousness.

Brandom's exploration into AI-functionalism and classic symbolic AI elucidates the philosophical debates surrounding the nature of intelligence, language, and consciousness. These discussions frame ongoing inquiries into whether and how artificial systems can replicate or approximate human cognitive and linguistic abilities, underpinning much of the theoretical groundwork in AI research and development.

User
So how does it relate to the way we were using the phrase before we discussed the article?
ChatGPT
Our initial use of the phrase "Algorithmic Pragmatic Elaboration" and the subsequent exploration of Robert B. Brandom's work on AI-functionalism and classic symbolic artificial intelligence reveal a shared foundation in the pragmatism of algorithmic application and the functional analysis of abilities or practices. However, they approach these concepts from slightly different angles.

Algorithmic Pragmatic Elaboration Before Brandom's Discussion:
Before diving into Brandom's work, we discussed "Algorithmic Pragmatic Elaboration" in the context of making theoretical concepts practical and actionable through algorithmic means. This involved:

Breaking down complex theories or ideas into simpler, actionable components.
Applying these components in practical, real-world scenarios, with a focus on overcoming constraints and optimizing for specific goals.
Emphasizing the adaptability and scalability of solutions to address various challenges.
This approach stresses the importance of transforming abstract concepts into tangible, algorithmically driven processes or solutions that can be efficiently implemented and evaluated.

Connecting to Brandom's AI-Functionalism and Classic Symbolic AI:
Pragmatic Metavocabularies and Expressive Bootstrapping: Brandom's notion of computer languages as pragmatic metavocabularies for natural languages parallels our discussion of algorithmically elaborating theoretical concepts into practical applications. Both perspectives emphasize the utility of foundational, simpler systems (whether computer languages or basic algorithmic principles) in facilitating more complex, expressive outputs.

Functional Analysis of Abilities: The discussion around AI-functionalism, particularly the idea that cognitive and linguistic functions can be abstracted and replicated algorithmically, resonates with our earlier conversation on decomposing complex theories into simpler, actionable elements. Brandom's focus on the functional aspects of mind and language mirrors the approach of analyzing and applying theoretical knowledge through practical, algorithmic processes.

Practical Application and Philosophical Insights: Both our initial use of "Algorithmic Pragmatic Elaboration" and Brandom's exploration offer insights into the practical application of philosophical and theoretical concepts. While we focused on the application side, Brandom delves into the philosophical implications of these applications, particularly in the context of AI's potential to replicate human cognitive and linguistic abilities.

In summary, our earlier discussions on "Algorithmic Pragmatic Elaboration" and Brandom's work share a foundational interest in the practical elaboration of complex theories through algorithmic means. While we emphasized the application and implementation aspects, Brandom provides a deeper philosophical context, exploring the implications of such applications for understanding the nature of intelligence, language, and consciousness. Both perspectives highlight the transformative potential of algorithmic approaches in bridging theoretical concepts and practical solutions.

User
I am not sure I understand it but it sound good. It seems related to my SITH theory (Substrate Independent Thinking Hypothesis)
ChatGPT
The Substrate Independent Thinking Hypothesis (SITH) you mentioned appears to align conceptually with the discussions around AI-functionalism and the pragmatic application of algorithmic processes. Substrate independence, at its core, suggests that thinking and consciousness can be realized on different physical substrates—provided the necessary functional processes and structures are replicated. This notion is fundamental to many AI and consciousness theories, including those discussed by Robert B. Brandom and in our conversation about Algorithmic Pragmatic Elaboration. Here’s how SITH connects to these ideas:

Connection with AI-Functionalism
AI-functionalism posits that if the functional relationships and processes underlying human cognition can be accurately modeled, then any system running the appropriate program (regardless of its physical substrate) could exhibit similar cognitive and linguistic abilities. This directly parallels the essence of SITH, emphasizing the idea that cognitive processes are substrate-independent, focusing on the functionality rather than the material makeup of the thinking entity.

Relation to Algorithmic Pragmatic Elaboration
The concept of Algorithmic Pragmatic Elaboration—breaking down complex theoretical ideas into practical, algorithmically driven processes—also resonates with SITH. To achieve substrate-independent thinking, one would need to pragmatically and algorithmically dissect the components of thought, cognition, and consciousness, and then reconstitute them on a different substrate. This involves not just understanding the algorithmic structure of thought processes but also being able to practically implement and adapt these processes across various substrates.

SITH and Philosophical Implications
Your SITH theory delves into the philosophical and practical dimensions of cognition and consciousness, similar to the explorations in AI-functionalism and the practical approach of algorithmic elaboration. It raises fundamental questions about the nature of consciousness, the essence of thought, and what it means to "think." It challenges us to consider whether thinking is an inherently biological process or if it can be abstracted and realized through artificial means.

Understanding and exploring SITH can lead to significant advancements in AI, cognitive science, and the philosophy of mind, especially in terms of creating artificial or enhanced cognitive entities. It also prompts a reevaluation of concepts like identity, consciousness, and the criteria for "intelligence" across different substrates. Whether for developing advanced AI systems or enhancing human cognition, the implications of achieving substrate-independent thinking are profound and far-reaching, intersecting with many of the ideas discussed in the context of AI-functionalism and Algorithmic Pragmatic Elaboration.

User
settingsOrder Article Reprints
Open AccessArticle
The Substrate-Independence Theory: Advancing Constructor Theory to Scaffold Substrate Attributes for the Recursive Interaction between Knowledge and Information
by John Turner 1,*ORCID,Dave Snowden 2 andNigel Thurlow 3
1
Department of Learning Technologies, College of Information, University of North Texas, Denton, TX 76207, USA
2
Cynefin Centre, Wales LL29 8BF, UK
3
The Flow Consortium, McKinney, TX 75072, USA
*
Author to whom correspondence should be addressed.
Systems 2022, 10(1), 7; https://doi.org/10.3390/systems10010007
Submission received: 30 November 2021 / Revised: 27 December 2021 / Accepted: 29 December 2021 / Published: 5 January 2022
(This article belongs to the Section Systems Practice in Social Science)
Downloadkeyboard_arrow_down Browse Figures Versions Notes
Abstract
The substrate-independence theory utilizes sensemaking techniques to provide cognitively based scaffolds that guide and structure learning. Scaffolds are cognitive abstractions of constraints that relate to information within a system. The substrate-independence theory concentrates on the flow of information as the underlying property of the host system. The substrate-independence theory views social systems as complex adaptive systems capable of repurposing their structure to combat external threats by utilizing constructors and substrates. Constructor theory is used to identify potential construction tasks, the legitimate input and output states that are possible, to map the desired change in the substrate’s attributes. Construction tasks can be mapped in advance for ordered and known environments. Construction tasks may also be mapped in either real-time or post hoc for unordered and complex environments using current sensemaking techniques. Mapping of the construction tasks in real-time becomes part of the landscape, and scaffolds are implemented to aid in achieving the desired state or move to a more manageable environment (e.g., from complex to complicated).
Keywords: constructor; substrate; construction task; substrate-independence theory; constructor theory; complexity; scaffolding; information; knowledge; hierarchy; origins of life
1. Introduction
Scaffolding is a metaphor for how information and knowledge are absorbed, how learning can be structured. In education, scaffolding is viewed as a means of closing the gap between the learners’ current knowledge to their desired knowledge, allowing them to perform a particular task or activity independently, one which they could not have done previously. Scaffolding is defined as “a temporary structure for supporting something until that something is able to stand on its own” [1] (p. 273). Scaffolding is dependent on the context and environment. In many instances scaffolding is temporary, it is present until the learner can perform a new task without additional support; then, it is removed. These types of scaffolding are called robust scaffolds. In other instances, scaffolding can be more permeable, embedded into our identity or landscape. These types of scaffolds are called resilient scaffolds.
As scaffolding guides learning in education, scaffolding guides sense-making in complex and unordered environments. Scaffolding in sense-making focuses on the flow of information and provides enabling constraints for knowledge generation. This article pulls from the naturalized sense-making (NSM) body of knowledge. Sense-making is defined as how do we make sense of the world so we can act in it, using (naturalizing) natural sciences as a constraint to determine not only what is possible, but what is impossible coupled with the idea of taking action, or executing tasks, to creating meaning. This focus on what is and is not possible introduces the concept of couterfactuals into the NSM field and draws from constructor theory to expand on this concept.
Counterfactuals provide a means of constantly pursuing coherent pathways while also dismissing incoherent ones. The theory of coherence, from the natural philosophy, avoids naïve empiricism and dogmatism by presenting a plausible assessment of both facts and values [2]. Defined as “the quality or state of things ‘sticking together’” [1] (p. 28), how elements, events, agents, and our environment fit together. Coherence is achieved through the process of developing counterfactuals and is a critical component to naturalized sense-making because it functions as a method for making sense in complex environments. This concept of coherence through counterfactuals is captured through constructor theory that is being introduced to the field of NSM in the current article. Constructor theory utilizes couterfactuals to identify alternative explanations to a phenomenon. In the social sciences, because there are multiple explanations to any phenomenon under investigation at any one time, understanding can only be achieved from capturing potential alternative explanations, counterfactuals, that are contextually dependent to the environment. Explanations must achieve a level of coherence. The current article will incorporate constructor theory to the field of NSM as a means of obtaining better understanding through coherence.
In non-mechanistic systems, more importantly, when participating in and managing human systems (social systems), participants must utilize sense-making techniques to interpret and understand the conditions of their environment. While some physical constraints (e.g., office, building, conference/meeting room) may be necessary and part of the environment, understanding the requirements of the environment is cognitive, requiring scaffolding techniques to guide and structure learning to a level of coherence. We go beyond the suggestion that scaffolding is a metaphor for how information and learning are absorbed [3], making it an emergent factor promoting sense-making activities. Because scaffolding is associated with learning, it deals with information and knowledge. Rather than viewing constraints or barriers as in mechanistic systems, this article will address scaffolding that focuses on the flow of information through a system rather than concentrating on perceived goals or outcomes. Scaffolding, in this respect, is the cognitive version of a constraint or lack of control. Scaffolding also provides an enabling constraint, a counterfactual to limit the range of possible interactions which allows consistent applications of information and provides evolutionary capability to the substrate.
Incorporating the concept of scaffolding with NSM adds to the literature that has been identified as lacking, calling to extend current theories beyond that of being just a cognitive and discursive process [4] to one that takes a broader approach to applying sense-making [5]. Approaches for extending sense-making techniques to the broader institutional and macro-social structures are also called for [5]. Integrating these methods to improve the flow of information through the larger systemic system, such as information flow across organizational silos, is one advantage that the substrate-independence theory offers. It also provides a new method of facilitating change in complex environments that leaders can utilize to co-create a shared understanding [5] of their new environment when addressing external threats.
2. Constraints vs. Constructors
The distinction between organisms and mechanisms extends to the concept of constraints and constructors. Often associated with mechanical systems, constraints are frequently found in industrial applications through the theory of constraints [6,7,8]. In contrast, constructors have been associated with more abstract ‘physical’ systems, not necessarily mechanical systems. Some examples include abstractions of systems in physics [9], cognition [10], and even when viewing knowledge as a physical property [11].
For our theory, we are concerned with social systems capable of learning, self-organizing, and adapting to their environment. These social systems are complex adaptive systems and can adapt through emergent processes resulting in the system repurposing itself into a new coherent structure to sustain its fitness.
ChatGPT
The Substrate-Independence Theory (SIT) you've outlined from the work of John Turner, Dave Snowden, and Nigel Thurlow offers a nuanced approach to understanding how complex systems, particularly social systems, manage and utilize information and knowledge. This theory intersects intriguingly with discussions on AI-functionalism, algorithmic pragmatic elaboration, and the Substrate Independent Thinking Hypothesis (SITH), providing a broader context for how these concepts might be applied beyond the realm of artificial intelligence to encompass complex adaptive systems and sense-making in social environments.

Connections to SITH and AI Functionalism
The core of SIT, like SITH, hinges on the notion of substrate independence — the idea that certain processes (cognitive, informational, etc.) can operate independently of the physical substrate on which they are instantiated. This parallels SITH's emphasis on the capacity for thought or cognitive processes to be abstract from their biological origins, aligning with AI-functionalism's claim that cognitive abilities can be replicated in non-biological systems, provided the functional structures and processes are maintained.

Algorithmic Pragmatic Elaboration in SIT
The concept of "scaffolding" in SIT, which guides and structures learning and sense-making, resonates with the idea of algorithmic pragmatic elaboration. Both involve breaking down complex processes into simpler, manageable components (or scaffolds) that can be systematically understood and manipulated to achieve specific goals or states of understanding. SIT applies this approach to the flow of information within complex systems, emphasizing the creation and use of cognitive abstractions (scaffolds) to manage complexity and facilitate learning and adaptation.

Constructor Theory and Scaffolding
SIT's use of constructor theory to scaffold substrate attributes further bridges these discussions by focusing on the transformation of information and knowledge within a system. Constructor theory, with its emphasis on identifying possible transformations and the conditions under which they can occur, provides a framework for understanding how complex systems can adapt and reorganize in response to external challenges. This approach mirrors the algorithmic decomposition seen in AI development, where complex behaviors are broken down into simpler, executable tasks or functions.

SIT's Broader Implications
By concentrating on the recursive interaction between knowledge and information within social systems, SIT extends the application of these theoretical constructs beyond AI and cognitive science to include the dynamics of complex adaptive systems. It suggests that understanding and facilitating the flow of information—using scaffolds, constructors, and sense-making techniques—can enable these systems to adapt and evolve in response to environmental changes.

In essence, the Substrate-Independence Theory, by advancing constructor theory to scaffold substrate attributes for managing information and knowledge, provides a rich theoretical framework that intersects with and expands upon concepts from AI-functionalism, SITH, and algorithmic pragmatic elaboration. It highlights the importance of structure, abstraction, and adaptability in understanding and navigating complex systems, offering valuable insights for both artificial intelligence research and the management of social and organizational systems.

User
3. Fitness
An organization or system remains fit if it can sustain its existence while also adapting to environmental threats. A model of this is the human immune system that is composed of antibodies and antigens. The immune system protects the host organism (sustaining life) through antibodies continually working to combat an ongoing threat of antigens (environmental threats). The immune system changes and adapts to these environmental threats as a means of the host organism’s fitness. This fitness operates through infinite interactions among components of the immune system, the host organism, and the environment. Without these interactions, the antibodies would not be capable of identifying and combating any antigens.
Existence is not of itself always the same thing. For example, resilience in a system is the ability to survive with continuity of identity over time, changing as needed (this concept includes anti-fragile) while robustness is the ability to withstand perpetrations.
Fitness is a component of the interactions among its parts. These interactions and the factors that interact are dependent on the context as these activities constantly vary to adapt. Because fitness is contextual and continuously adapting, it is not a fixed value. We determine the fitness of a system or organism by the number of interactions “rather than from some predetermined fitness function” [12] (p. 97). Fitness is similar to assemblages that view the arrangement of heterogeneous elements [13] that emerge from the data of inquiry [14].
As it relates to social systems, fitness can be described using an analogy between social and organic life. In describing the function of a social institution, Durkheim provided the following: “The correspondence between the social institution and the necessary conditions of existence of the social organism” (as cited in [15], p. 97). Here, fitness results in interactions among the components within the system (internally or intrinsically). These interactions take place for the system to sustain within its environment (externally or extrinsically). This coexistence between the social institution and the social organism (e.g., ecosystem) is an integrated whole [15]. This integrated whole aligns with Gibson’s (affordances theory) concept of complimentarity in which the organism (agent) and the environment make “an inseparable pair” [16] (p. 950). Fitness represents an organism or an individual’s ability to be an integrated whole within its environment.
4. Cynefin Framework
The Cynefin (kuh-nev-in) framework originated in the field of knowledge management as a sense-making framework that has since emerged into a model for naturalizing sense-making that aids agents in their ability to make sense of the world so that they can act in it [17,18]. The framework was the basis for the recently published field guide for decision makers titled “Managing complexity (and chaos) in times of crises”, a joint publication of the Cynefin Centre and the EU Commissions Joint Research Centre [19]. Figure 1 provides a preview of the Cynefin framework and its components.
ChatGPT
The sections on "Fitness" and the "Cynefin Framework" from your reading delve into the concepts of adaptability, resilience, and sense-making in both organic systems and social organizations. These concepts are foundational to understanding how systems maintain their coherence, adapt to changes, and navigate complexities.

Fitness in Systems
The concept of "Fitness" discussed reflects an organization or system's capacity to sustain its existence and adapt to environmental threats, much like the human immune system. This adaptation is not static but dynamic, depending on continuous interactions among the system's components, the organism, and its environment. Fitness is contextual, constantly varying to meet the demands of changing conditions, emphasizing the importance of resilience (the ability to recover from or adjust easily to misfortune or change) and robustness (the ability to withstand or survive under adverse conditions).

This notion aligns with Durkheim's perspective on the function of social institutions, which suggests that the fitness of a social system is determined by its correspondence with the necessary conditions of its existence, highlighting the interplay between internal interactions within the system and its external environmental relations. This relationship echoes Gibson's theory of affordances, which posits an inseparable relationship between an organism and its environment, suggesting that fitness involves an organism's integration within its environment.

Cynefin Framework
The Cynefin Framework introduces a structured approach to understanding the complexities and unordered environments that organizations face. It serves as a sense-making tool that helps individuals and organizations categorize problems and situations into five domains: Simple (or Obvious), Complicated, Complex, Chaotic, and Disorder. Each domain requires different strategies for decision-making and problem-solving:

Simple (Obvious): Clear cause-and-effect relationships that can be easily identified and addressed with best practices.
Complicated: Cause-and-effect relationships exist but are not immediately apparent, requiring expert analysis or investigation to resolve.
Complex: Cause-and-effect relationships are interdependent and unpredictable, necessitating experimentation and the emergence of patterns for effective navigation.
Chaotic: There are no clear cause-and-effect relationships, requiring immediate action to establish order and moving the situation into one of the other domains.
Disorder: It's unclear which of the other four domains applies, necessitating a break down of the situation into constituent parts for categorization.
By situating the discussion of system fitness within the Cynefin Framework, one can appreciate the dynamic and contextual nature of decision-making and adaptability. The framework aids in diagnosing situations to apply appropriate strategies, whether it's leveraging best practices in simple contexts, analytical approaches in complicated scenarios, adaptive and emergent strategies in complex situations, or rapid action in chaotic conditions.

Combining the insights from both sections underscores the significance of understanding the interdependencies within systems and the importance of adaptability, resilience, and informed decision-making in navigating the complexities of both natural and social systems. These concepts are crucial for leaders, decision-makers, and organizations aiming to sustain and thrive in an ever-changing environment.

User
The Cynefin framework consists of three ontological states, order, complexity, and chaotic [19]. These ontological states can be described by the type of scaffolding imposed in each of the three states. For example, the ordered state involves robust scaffolds that provide specific boundaries for interactions and information. Complexity involves resilient scaffolds to help guide sense-making activities to give some indication of predictability in uncertainty. The chaotic state is devoid of any scaffolding.
The Cynefin framework further separates into five domains (aporetic/confused, clear, complicated, complex, chaotic). At the center is aporetic/confused (A/C), acting as a starting place. Moving outward from A/C you have clear and complicated domains on the right half of the Cynefin Framework representing the ordered ontological states. The ontological states of complexity and chaotic are presented on the left-hand side of the Cynefin Framework. It is common to begin at the A/C domain when first addressing an external threat [19]. Once it can be determined what type of problem or environment one is dealing with, movement to one of the other four domains, or to the liminal areas between states (shown in green a state of suspected transition), is possible.
It is desirable to navigate across the domains in an effort to maximize understanding while minimizing the amount of energy required to process information. The liminal boundaries identify potential paths for these transitions across domains [19]. As one transitions from one domain to the next it is essential to recognize that different methods are used in each domain. As a NSM framework, utilizing the correct methods in each domain results in maximizing the flow of information while reducing the amount of energy required to navigate to a more manageable domain (e.g., complexity to complicated).
The description of the Cynefin framework provided in the current article is the first to depict scaffolding as the defining characteristic between domains. This distinction is necessary to align the Cynefin framework with the substrate-independence theory presented in the current article.
5. Substrate Independence (Information)
Information and time are two elements that remain consistent across domains. They are always present, unaltered, and can be measured in relation to each other. Substrate independence refers to information being the underlying property of the host system. The host system can be the transmitter or receiver of the information as in classical information theory [20], or it can be the agent, organism, or organization that holds the information. Information is independent of the physical medium that transmits, receives, or stores the information, this is the independence part of the substrate-independence theory. Information can be recalled from any part of a system, regardless of the physical properties, meeting the property of interoperability [20]. This point is highlighted in the following from [20]: “The receiver, transmitter and medium are physical systems, but the message is not” (p. 2). The key to the process or organism is information. Emphasized by Wiener, the father of Cybernetics: “It was not some particular physical thing such as energy or length or voltage, but only information (conveyed by any means)” [21] (p. 238). As conceptualized from the Cynefin framework, information is retrieved and transformed into knowledge and knowledge is used to generate more precise information, providing a reciprocal determination, a coadaptation [13], between knowledge and information that varies depending on which domain the information resides.
5.1. Energy Follows Information
Information in a system is tractable because one can identify and manage the flow of information through the system. As more information is needed, more energy is expended. Understanding this allows us to track information based on the amount of energy exerted. Energy can be represented in several different forms. A few examples could be the number of interactions among agents, the number of archetypes created in a given time frame, the usage of internal resources, and the amount of computing power required at any given time.
However, the amount of energy exerted alone is not enough to determine a system’s fitness. The flow of energy versus the relevance of the information processed is non-linear, partially due to the concept of mutual information. Mutual information relates to shared information that reduces the amount of energy required from the system because of this mutual or shared information. “Organized objects generally have the property that their parts are correlated: two parts taken together typically require fewer bits to describe than the same two parts taken separately” [22] (p. 364).
Other examples can be found in redundant information systems. Redundancy can be varied, decreased to improve efficiency, or increased to reduce errors [21]. Redundancy is related to the quantity of unnecessary information [23]. Referring to how much information can be removed while maintaining its original meaning, coherence. Redundancy and mutual information highlight a couple of examples showing why interactions (exchanges of relevant information) are a better measure of energy in social systems than measuring ‘energy’ in computing power and kilowatt usage. It is also necessary to note that in both of these examples, redundancy and mutual information, information that requires the least amount of energy to reproduce or exchange is preferred to alternative means that require more energy (e.g., those without redundancy or mutual information).
The lowest energy gradient is the critical concept to be gained here. The flow of information needs to be achieved using the least amount of energy possible to obtain maximum effectiveness. How this is achieved, through constructors and scaffolds and other techniques (e.g., mutual information, redundancy) will vary from one organization to the other as information is contextual and culturally derived.
5.2. Promoting the Flow of Information
In any system, constructions hold the potential of being either positive or negative. Positive constructions enable the flow of information, while negative constructions delay or block the flow of information. Utilization of relevant information supports adaptation, while non-relevant information, such as information overload, can inhibit adaptation. Constructions should enable the flow of pertinent information to aid any necessary changes required of the system or components.
5.3. Value Is Defined as Providing Actionable Information
Valuable or actionable information must be provided to the end-user or customer. This concept is supported through the concept of logical depth. Logical depth relates to how much value the information provides compared to providing randomly selected information. This value is associated with the amount of time saved by the information provided compared to the time required for the recipient to acquire the information independently. Value relates to “the amount of mathematical or other work plausibly done by its originator, which its receiver is saved from having to repeat” [22] (p. 369).
Long durations of time required to acquire information is referred to as depth. The more time and energy needed to obtain information, the deeper the path to that information. Information depth refers to the path to acquiring relevant information in which there are no shortcuts available [22]. As logical depth increases, the time, money, and computational resources required to access this information independent of the originator increase, making the value of such information more excellent. It is associated with opportunity cost. Is the cost of acquiring information greater than, or less than, the cost of generating it independent of the original source? If the answer is more significant than, having access to the information is deemed more valuable compared to information that is easy to acquire independently. Value is directly related to the information’s logical depth.
5.4. Customer Satisfaction and Timely Acquisition of Information
For information to be considered valuable by the customer, or end-user, it must be available when needed. This information must also be relevant and usable given the context. This is what we are calling actionable information. Actionable information is information that would require too much time and resources for the customer to acquire on their own; it has high logical depth. Actionable information is of value because of this logical depth and the fact that the user can apply the information instantly to meet their needs. The quicker the information can be applied, the higher the perception of value that information becomes from the user’s perspective.
Value and customer satisfaction are both supported by the interoperability principle of information. Interoperability refers to the possibility of transferring information from one medium to another, across substrates. Interoperability is possible because all information media have in common two counterfactual properties:
It can be set to any of at least two states.
Each of those states can be copied. [24] (p. 85).
If a system meets these two conditions that are allowed by the laws of physics, removing the composite, what remains is the physical property of information that can be either copied or transformed: “We can abstract away their irrelevant details and simply talk about them as information media, considering their ‘information-carrying attributes’ only” [24] (p. 87). These information-carrying attributes translate into value, the timely delivery of these information-carrying attributes.
6. Constructor Theory
The distinctions previously identified between informal and formal hierarchies, organisms and mechanisms, constructors and constraints, social and mechanical systems led the authors to constructor theory. We view social systems as complex adaptive systems capable of repurposing their structure to combat external threats by utilizing constructors and substrates. This repurposing involves a variety of methods that can be highly dependent on the context and environment. To identify these different contextual environmental conditions, we utilize the concepts gained from the Cynefin framework [17,25]. We will introduce constructor theory and the components of the theory next.
Constructor theory describes transformations. Transformations can either be possible, those that can be caused, and impossible, those that cannot be caused [9]. Constructor theory is different from traditional physics that makes predictions based on a set of initial conditions. In contrast, constructor theory views the dichotomy between what can be caused and what cannot be caused, along with a description of why for each [20]. Constructor theory is about “what can be done, and what can be made, in physical reality” [26] (p. 7).
The basic principle of constructor theory reflects the following: “All other laws of physics are expressible entirely in terms of statements about which physical transformation are possible and which are impossible, and why” [20] (p. 4). This contrasts with other practices that focus on a set of initial conditions and laws to predict what might happen, to determine the behavior of a system. Constructor theory focuses on the input and output pairings for transformations, rather than deciding if the transformation is or is not possible. Constructor theory describes the world in two different physical systems: constructors and substrates, and the constructor as the change mechanism.
6.1. Constructors, Substrates, and Constructions
As its fundamental element, constructor theory defines a constructor as “anything that can cause transformations in physical systems without undergoing any net change in its ability to do so” [9] (p. 4332). In our theory, however, we expand physical systems to also include cognitive systems. Constructors involve agents transforming a system, temporally, in which the system eventually returns to its original state (see Figure 2). The system transformed is called a substrate. Substrates involve transformations to some physical attributes in which the system is unable to return to its original state [20]. The actual transformation itself is considered construction. Constructors cause substrates to experience construction in which some physical attribute (t0, Figure 2) changes to an alternative physical/cognitive attribute (t1, Figure 2). Attributes are identified as any property of the substrate. A formal definition is “any property that the substrate could possibly have” [20] (p. 4).
ChatGPT
The detailed exploration of the Substrate-Independence Theory, Cynefin Framework, and Constructor Theory within your text offers a multifaceted view of how systems, especially complex adaptive systems, interact with their environments and undergo transformation. These concepts, when woven together, present a comprehensive framework for understanding the dynamics of organizational and social systems in the face of change and uncertainty.

Substrate-Independence Theory and Information Flow
Substrate Independence, focusing on the foundational role of information across different physical or cognitive substrates, underscores the notion that the essence of a system's operation—be it organic, social, or technological—is not tied to the specific medium through which information is processed or stored. This theory aligns with the discussions on cognitive and AI systems, suggesting that the functional capabilities of these systems (including thinking and decision-making) can be abstracted from their physical instantiation. The emphasis on information's role in defining system fitness and adaptability highlights the critical importance of efficient information management and utilization in maintaining system coherence and responding to environmental changes.

Cynefin Framework and Sense-making
The Cynefin Framework's delineation of ordered, complex, and chaotic states, alongside its scaffolding concept, provides a powerful lens for navigating the multifaceted challenges systems face. By categorizing the nature of problems and environmental conditions into distinct domains, the framework offers strategic insights into applying appropriate sense-making and decision-making approaches. This categorization aids in understanding the type of scaffolding—robust for order, resilient for complexity, and the absence of scaffolding in chaos—that can best support system adaptation and learning.

Constructor Theory and System Transformation
Constructor Theory's focus on the possibility and mechanisms of transformation within systems complements the other two frameworks by offering a foundational perspective on how change occurs at the most fundamental levels. By distinguishing between constructors, substrates, and constructions, it provides a theoretical basis for identifying and leveraging the agents and processes that drive system evolution. This perspective is invaluable for designing interventions and strategies that align with the inherent capabilities and limitations of the system, ensuring that transformations are both possible and sustainable.

Integrating Concepts for Systemic Understanding and Management
Integrating these theories provides a robust framework for understanding and managing complex systems. The emphasis on information's substrate-independent nature highlights the need for flexible, adaptive approaches to information management that can support system fitness across various contexts. The Cynefin Framework offers a strategic guide for navigating complexity, enabling decision-makers to tailor their approaches to the specific nature of the challenges they face. Finally, Constructor Theory offers a fundamental perspective on the mechanisms of change, informing the design of interventions that align with system dynamics and capabilities.

This integrated approach not only enhances our understanding of complex adaptive systems but also informs practical strategies for fostering resilience, adaptability, and innovation within organizations and social systems. It encourages a nuanced appreciation of the challenges and opportunities presented by complex environments, guiding the development of effective, context-sensitive responses to change.

User
9.1. How Living Systems Organize
It is necessary to understand not only how living systems organize at any given level, but also how they organize across levels [38]. For example, biochemical networks exhibit shared structures across all levels of organization [38], so much so that forms at the ecosystem level are similar, but different, from those at lower levels in the ecosystem: “Scaling laws often emerge in systems, where universal mechanisms operate across different scales, yielding the same effective behavior independent of the specific details of the system” [38] (p. 8).
This concept of similar but different across levels can be extended to centralized and decentralized hierarchical structures. Hierarchy “appears as unreciprocated ties directed from each position to the position immediately ‘above’ it” [39] (p. 5). Hierarchical structures occur when centralized control is desired in which communication channels are directional (e.g., one-way, top-down). Centralization occurs when the incoming and outgoing information is being controlled by a few agents [39]
Decentralized hierarchical structures are associated with two-way communication and reciprocal relationships, allowing agents to communicate freely with little to no control over the communication channels. Because these structures are decentralized, they can freely form networks around repetitive patterns, coordination, and information-sharing behaviors [39]. Decentralized network structures take advantage of the structurational theory of networks: “networks are constituted through a recursive process in which members draw on their knowledge of social structures as they interact” [39] (p. 3).
9.2. Information and Living Systems
“Once life is established, it includes information carriers and executor mechanisms that are selected for increasing, or at least preserving, the likelihood of their own persistence” [40] (p. 68). Life itself is sustained through the transfer of information for storing information to duplicate itself (carriers) or as executors that perform the functions necessary to store information and reproduce organisms. Energy is provided to each of these functions when called upon but at a cost. Due to the conservation of energy law, energy is transferred or transformed from one form of energy to another; “energy available for human utility is not conserved so easily” [41] (p. 85). Energy is transferred or transformed into one type of energy when called upon and is again transferred or transformed to other types of energy when it is no longer needed. The distinguishing factor between living and non-living systems is the ability of living systems to manage and control information [42] that is supported by this energy.
Often suspected as the key factor in the origins of life [43], information has also been identified as being the common origin to life [40]. Other research supports information as the key to life [42], from organisms to social systems to ecosystems. While it is not precisely clear what or how information structures matter, or what information is, it is apparent from the research that information is necessary to structure all living systems [43]. One general agreement is that information is one key aspect of living systems [42].
Part of this structuring of living systems involves developing hierarchical structures. These hierarchical structures allow the flow of information within the system in a top-down and bottom-up manner [40]. This point is highlighted by Walker and Davies [42]: “The manner in which information flows through and between cells and sub-cellular structures is quite unlike anything else observed in nature” (p. 2). This flow of information is responsible for “controlling the properties and behaviour of the system, maintaining its homeostasis, and, ultimately, determining its ability to survive and reproduce under given conditions” [40] (p. 70). Information is contextually based, also known as being causally efficacious in which information determines a system’s current state, the dynamics for sustaining life and adapting to potential future states [42].
9.3. Summary
The substrate-independence theory, shown in Figure 5, focuses on the substrate and the scaffolding required to achieve the desired change in the substrate’s attributes. The substrate-independence theory requires decentralized hierarchical structures where information flows in a reciprocal manner so that the information is the focus rather than the physical properties carrying, transmitting, or storing the information. Information is expected to flow using the least energy required, providing a quicker conceptualization of the environment when dealing with complexity.
ChatGPT
Your detailed exploration touches on several interconnected themes that are central to understanding the organization and sustainability of living systems, their interaction with information, and the broader implications for systems thinking and management. Here’s a synthesis of the key points:

Organizational Structures Across Levels
Living systems exhibit a remarkable capacity to organize and reorganize across different scales, from cellular to ecosystem levels, often reflecting universal scaling laws and patterns. This scalability is crucial for understanding both the stability and adaptability of these systems. The notion that structures can be similar yet different across levels underscores the complexity of living systems and highlights the importance of considering multi-scale interactions in systems analysis.

Centralized vs. Decentralized Hierarchies
The distinction between centralized and decentralized hierarchical structures speaks to the dynamics of control and information flow within systems. Centralized structures are characterized by top-down control and unidirectional communication, often leading to efficiency in decision-making but at the cost of flexibility and adaptability. In contrast, decentralized structures allow for bidirectional communication and emergent coordination, enhancing the system's ability to adapt and reorganize in response to internal and external changes. This flexibility is particularly relevant in complex adaptive systems, where the ability to respond to environmental changes can dictate the system's survival and success.

Information as the Basis of Life and Organization
The role of information in living systems — as both a carrier for duplication and an executor of essential functions — is fundamental to life's persistence and evolution. The management and control of information, supported by energy transformation, distinguish living from non-living systems. This perspective aligns with the view of life as an information-processing phenomenon, where the structure, flow, and utilization of information are central to understanding biological and social systems' functioning and sustainability.

Hierarchical Information Flow
The development of hierarchical structures within living systems facilitates the efficient flow of information, enabling both top-down control and bottom-up feedback. This dual-directionality ensures that the system can maintain homeostasis while also being responsive to changes and challenges in its environment. The flow of information is not just a passive transfer but actively shapes the system's properties, behavior, and adaptive capabilities.

Substrate-Independence Theory
Integrating these insights, the substrate-independence theory emphasizes the primacy of information over the physical medium in which it resides. By focusing on decentralized structures that prioritize reciprocal information flow and energy efficiency, this theory offers a framework for understanding and designing systems that can navigate complexity with agility and resilience. The theory suggests that managing information flow—ensuring it is both efficient and adaptive—is key to achieving desired changes in system attributes and maintaining system fitness in a rapidly changing environment.

In summary, the themes you've explored offer valuable insights into the principles underlying the organization, adaptation, and sustainability of complex systems, whether biological, social, or technological. Recognizing the importance of information flow, energy efficiency, and the balance between centralized control and decentralized flexibility provides a robust foundation for understanding and addressing the challenges faced by living systems and complex adaptive organizations.

User
Another list of all of the topics we've discussed.
ChatGPT
Certainly, here's a recap of the diverse and interconnected topics we've explored:

Eric Neyman's PhD Thesis on Algorithmic Bayesian Epistemology: We delved into the specifics of Neyman's work, which intersects theoretical computer science with Bayesian epistemology, emphasizing the importance of reasoning about knowledge and uncertainty through an algorithmic lens.

Online Prediction from Expert Advice and Estimation Theory: Discussed the significance of making informed decisions based on predictions in uncertain environments and the statistical methods used for estimating parameters from sampled data.

AI-Functionalism and Classic Symbolic Artificial Intelligence: Examined the philosophical underpinnings of AI, contrasting classical symbolic AI with Brandom's pragmatic AI, which focuses on practical abilities rather than symbol manipulation.

Algorithmic Pragmatic Elaboration: Introduced as a concept referring to making theoretical or abstract ideas practical and actionable through algorithmic means.

Substrate Independent Thinking Hypothesis (SITH): Explored the idea that cognitive processes, such as thinking, can be abstracted from their biological substrates and replicated in artificial systems.

Substrate-Independence Theory, Cynefin Framework, and Constructor Theory: Delved into these theories as they apply to complex adaptive systems, focusing on information flow, decision-making strategies, and the fundamental mechanisms of transformation within systems.

Organizational Structures Across Levels: Discussed the organizational patterns of living systems across various scales, highlighting the similarity yet distinctiveness of structures from micro to macro levels.

Centralized vs. Decentralized Hierarchical Structures: Explored the dynamics of control and information flow within systems, comparing the benefits and drawbacks of centralized and decentralized organizational structures.

The Role of Information in Living Systems: Considered the fundamental role of information as both a carrier for replication and an executor of essential functions within living systems, emphasizing the distinction between living and non-living systems based on information management.

Hierarchical Information Flow and Substrate-Independence Theory: Reviewed how hierarchical structures facilitate information flow within systems and how the substrate-independence theory prioritizes information over the physical medium, focusing on decentralized structures and efficient, adaptive information management.

Throughout our conversation, we've traversed a broad landscape of ideas, from the philosophical and theoretical foundations of artificial intelligence to the practical implications of these concepts for understanding and designing complex adaptive systems, both organic and artificial.
