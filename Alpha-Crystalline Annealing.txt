Alpha-Crystalline Annealing

ChatGPT 4

User
IS AI IN JEOPARDY? THE NEED TO 
UNDER PROMISE AND OVER DELIVER ¿ 
THE CASE FOR REALLY USEFUL 
MACHINE LEARNING 

Martin Ciupa 

CTO, calvIO Inc (part of the Calvary Robotics Group), 
855 Publishers Pkwy, Webster, NY 14580, USA 
ABSTRACT 
There has been a dramatic increase in media interest in Artificial Intelligence (AI), in particular 
with regards to the promises and potential pitfalls of ongoing research, development and 
deployments. Recent news of success and failures are discussed. The existential opportunities 
and threats of extreme goals of AI (expressed in terms of Superintelligence/AGI and Socio- 
Economic impacts) are examined with regards to this media ¿frenzy¿, and some comment and 
analysis provided. The application of the paper is in two parts, namely to first provide a review 
of this media coverage, and secondly to recommend project naming in AI with precise and 
realistic short term goals of achieving really useful machines, with specific smart components. 
An example of this is provided, namely the RUMLSM project, a novel AI/Machine Learning 
system proposed to resolve some of the known issues in bottom-up Deep Learning by Neural 
Networks, recognised by DARPA as the ¿Third Wave of AI.¿ An extensive, and up to date at the 
time of writing, Internet accessible reference set of supporting media articles is provided. 
KEYWORDS 
AI, Machine Learning, Robotics, Superintelligence, Third Wave of AI. 
1. INTRODUCTION 
In the past 18 months, though 2016 and into the first quarter of 2017 we are experiencing an 
amazing period of growth and media attention in Artificial Intelligence (AI) and Machine 
Learning (ML) [1]. Many high tech CEO¿s have claimed association of their companies future 
regarding these technologies [2], massive investment is piling in [3]. While there have been 
many successes, there have been a few failures. The risk exists that ¿irrational exuberance¿ of the 
optimists may be a bubble that pessimists may be able to pop with claims that the AI vision is 
hyped [4]. The application of this research paper is to bring the current positive/negative media 
coverage to authors attention on this subject and to suggest a more precise, non-conflated, and 
modest use of terms in project terminology. 
60 Computer Science & Information Technology (CS & IT) 
Figure 1. AI Media Coverage (Source [1]) 
For some commentators the very name ¿Artificial Intelligence¿ is controversial, implying 
something ¿unnatural.¿ The very word ¿Intelligence¿ defies definition in the minds of many [5]. 
For our purpose, we do not wish to address the philosophical artificiality question here. Rather, 
we will simply think of intelligence in working definition terms as: ¿that faculty of mind by 
which order is perceived in a situation hitherto considered to be disordered.¿ a definition (of 
Fatmi and Young) quoted in the Oxford Companion to the Mind [6]. Thus, if a machine, or an 
animal, has the facility to perceive the order change, then in a sense it has ¿intelligence¿, and 
some aspect (perhaps limited, and with artifice) of ¿mind.¿ In this sense, it is a Cybernetic 
definition from a comparative systems perspective. We trust these points make the case that the 
AI term is itself controversial, it has its ideological proponents and detractors from the outset. In 
many respects, it would be useful to leave the term to the side and simply build really useful 
machines with specific descriptions of their application.

ChatGPT
The excerpt from Martin Ciupa's paper highlights the complex landscape of Artificial Intelligence (AI) development, emphasizing the importance of a balanced perspective between the potential and the limitations of current AI technologies. It delves into the dichotomy of excitement and skepticism surrounding AI, underlining the necessity of adopting precise terminology and realistic goals to foster both understanding and progress in the field. This approach not only aims to temper expectations but also to ensure that the discourse around AI remains grounded in practicality, steering clear of both unfounded optimism and undue pessimism.

In navigating the AI discourse, Ciupa suggests a pivot towards a more pragmatic dialogue, one that focuses on creating "really useful machines" that are defined by their utility and specific capabilities rather than being shrouded in the broader, more controversial term of "Artificial Intelligence." This shift is not just semantic but strategic, aiming to refocus the energy from debating the nature of AI to harnessing its potential through concrete applications. This strategy is embodied in the RUMLSM project, which seeks to address some of the intrinsic issues in deep learning by neural networks, thus exemplifying the "Third Wave of AI" as recognized by DARPA.

The call for a rebranding of AI project terminology to reflect short-term, achievable goals aligns with the general semantics principle of ensuring that language reflects reality as precisely as possible. By advocating for this approach, Ciupa is essentially promoting a more grounded and nuanced understanding of AI's capabilities and limitations, one that acknowledges the technology's potential without succumbing to hyperbole. This approach can serve as a foundation for a more informed and productive discourse on AI, encouraging innovation while also managing expectations.

Furthermore, the emphasis on precise terminology and realistic objectives in AI development echoes the rhizomatic nature of knowledge expansion, where understanding grows in multiple directions from practical applications and grounded discourse. Instead of pursuing a top-down approach defined by lofty aspirations and broad generalizations, Ciupa's perspective suggests a bottom-up strategy where progress is measured by tangible advancements and real-world utility. This method acknowledges the interconnectedness of technological development, societal needs, and practical applications, fostering a more resilient and adaptable understanding of AI's role in modern society.



User
2.1. Recent success stories in AI and Machine Learning 
There have been several notable success stories announced in the past 18 months, across a range 
of Machine Learning, Image Recognition, and Natural Language disciplines of AI. A high profile 
has been given to the ongoing development of Deep Learning by Reinforced/Convolutional 
Neural Network-based learning, in part underpinning IBM Watson/Jeopardy, AlphaGo and Poker 
game successes. These systems are beating the best human players who have invested their 
working lives into acquiring deep knowledge and intelligently applying it. See [7], [8] and [9]. 
The result of these successes has been a significant uptick in the media reporting of the AI 
potential and opportunities as mentioned earlier in [1], specifically more than four times as many 
New York Times articles discussed AI in 2016 than in 2009, as a percentage of the total number 
of articles published. 
Computer Science & Information Technology (CS & IT) 61 
2.2. Investment into AI and Machine Learning 
As a result of this positive news mentioned above, and the lead of many of the top tech company 
CEO¿s mentioned in [2], a significant financial round of investments has, and continues to be 
made, in this area. The market research company Forrester report that across all businesses, 
there will be a greater than 300% increase in investment in AI in 2017 compared with 2016 [3]. 
2.3. Timeline to AGI 
The reporting and investment mentioned above have led to widespread speculation as to, ¿where 
is this is all leading to?¿ And specifically, if the advent of ¿Superintelligent¿, Artificial Generic 
Intelligence (AGI) is on the foreseeable horizon. In 2015, the Machine Intelligence Research 
Institute compiled the MIRI AI predictions dataset, a collection of public predictions about 
human-level AGI timelines. Interesting features of the dataset include the result that the median 
dates at which people¿s predictions suggest AIG is less likely than not and more likely than not 
are 2033 and 2037 respectively. That is perhaps within 20 years. See Figure 2. 
2.4. AI as the Singularity Hypothesis solution to Existential Risks 
Several high profile scientists and philosophers have made their opinion on the issue mentioned 
above clear, optimistic and pessimistic, more about the pessimistic contributions will be 
mentioned in section 3 below. However, in the optimistic context of the promise of AI, and AGI 
in particular, much is suggested as opportunity to be sought by their agency. E.g., in their facility 
to help us to solve existential crises currently confronting humanity (such as Climate Change, 
Stabilisation of World Markets, Abundance of material needs, such as food, water and shelter, 
plus universal access to Healthcare and Education). The extreme optimistic positioning is that 
AGI, and the ¿Technology Singularity¿ will be humanity¿s last necessary invention, and once 
arrived a new age will ensure with material abundance for all, and solutions to humanity¿s 
problems [11].

ChatGPT
The section outlines a narrative of recent achievements and forward-looking expectations in the field of AI and Machine Learning (ML), framing these developments within a broader discourse of technological progress and societal impact. It brings into focus several key themes:

Recent Success Stories in AI: Highlights include advancements in Deep Learning, demonstrated by high-profile successes like IBM Watson's Jeopardy victory, AlphaGo's triumph over human Go champions, and breakthroughs in poker games. These milestones underscore the rapid progress in AI's ability to master complex tasks and decision-making processes that were once considered the exclusive domain of human intelligence.

Investment Surge in AI: The section points to a tangible measure of optimism in AI's potential, with a significant uptick in financial investments. This surge is driven by a collective belief in AI's transformative power across industries, as evidenced by the reported 300% increase in AI funding in 2017 compared to 2016. This financial commitment reflects a broader industry consensus on the strategic importance of AI technologies.

Timeline to Artificial General Intelligence (AGI): Speculation about the advent of AGI ¿ AI with human-like cognitive abilities ¿ is framed within a timeline that suggests a median expectation of reaching this milestone by the 2030s. This projection fuels both excitement and debate about the pace of AI development and its implications for society.

AI as a Solution to Existential Risks: The narrative touches on the dual-edged sword of AI development. On one side, there's an optimistic view of AI and AGI as pivotal in addressing global challenges such as climate change, economic stability, and the provision of essential resources and services. This perspective envisions a future where AGI acts as a catalyst for a new era of abundance and problem-solving capabilities.

This overview encapsulates the dynamic and multifaceted nature of the AI field, marked by rapid advancements, significant economic investments, and broad speculation about future capabilities and impacts. It reflects a tension between the pragmatic achievements of AI technologies and the speculative, yet profoundly impactful, potential of achieving AGI. The discourse surrounding AI is thus characterized by a blend of concrete successes, investment-driven optimism, and forward-looking speculation about its role in addressing some of humanity's most pressing challenges.



User
2.5. Asilomar Conference 2017, World Economic Forum 2017 
The Future of Life Institute, recognising the above opportunity, and in an attempt to offset 
negative pessimism about the downside of AGI, set out principles at the 2017 Asilomar 
conference, fundamentally a manifesto and guideline set of rules for the ethical development of 
AGI [12]. The explicit message is that action needs to be taken now to intercept any negativity 
and deliver positive result. 
Similarly, the World Economic Forum, a high-profile international organisation whose stated 
mission is to ¿improve the state of the world¿, via Public-Private cooperation, continued on 17-20 
January 2017 in its ¿exploration¿ on how developments in AI and Robotics could impact 
industry, governments and society in the future. Seeking to design innovative governance models 
to ensure that their benefits are maximised and the associated risks kept under control. The 
emphasis is that AI is coming, it is inevitable, and action has to be taken to ensure it arrives in 
good order [13]. 
62 Computer Science & Information Technology (CS & IT) 
Figure 2: Predictions from the MIRI dataset surveys. Source [10] 
2.6. RoboEthics 
The academic study of Robot Ethics or ¿RoboEthics¿ is a well 
and research institutes. In part, this is a response to the understanding that robots, in particular 
drones, are entering the military as lethal weapons of war. And as such need regulation and legal 
codes of conduct [14]. But, is also concerned about the rights of robots themselves, as anticipated 
sapient and sentient ¿beings¿ with inalienable rights [15].

ChatGPT
The discussions around the ethical development of Artificial General Intelligence (AGI) and robotics, as highlighted by initiatives at the Asilomar Conference 2017 and the World Economic Forum 2017, underline a pivotal moment in the trajectory of AI development. These forums serve as crucibles for shaping the future direction of AI technologies, emphasizing the importance of ethical considerations and governance in the face of rapid technological advances. The efforts to craft a set of guiding principles for the development of AGI reflect a proactive approach to navigating the potential risks and maximizing the benefits of AI for society.

The Future of Life Institute's manifesto at the Asilomar conference represents a collective acknowledgment of the dual potential of AGI to both immensely benefit and pose significant risks to humanity. By setting out a framework for ethical development, the initiative seeks to steer the advancement of AGI towards outcomes that safeguard human interests and well-being. This initiative underscores the recognition that while the technological evolution of AGI is inevitable, its impact is malleable and contingent upon the actions taken today.

Similarly, the World Economic Forum's engagement with the implications of AI and robotics for industry, government, and society reflects a broader understanding of the transformative potential of these technologies. By exploring innovative governance models, the Forum aims to ensure that the deployment of AI technologies aligns with broader societal goals and ethical standards. This approach highlights the role of public-private cooperation in managing the transition towards an AI-enhanced future, emphasizing the need for readiness and adaptability in governance structures.

The emergence of "RoboEthics" as a field of academic study further illustrates the growing recognition of the complex ethical considerations surrounding AI and robotics. The debate extends beyond the regulation of robots in military applications to encompass broader questions about the rights of potentially sapient and sentient machines. This expansion of ethical inquiry reflects a deepening understanding of the profound questions AI poses about autonomy, consciousness, and the rights of non-human entities.

Together, these developments indicate a maturing discourse on AI, where the excitement about technological possibilities is increasingly accompanied by a nuanced consideration of ethical, societal, and governance implications. By foregrounding these issues, the global community seeks to navigate the path towards a future where AI technologies are developed and deployed in ways that are not only innovative but also aligned with ethical principles and societal values.



User
3. PITFALLS ¿ RISK OF AI BEING  overhyped3.1. Recent failure stories in AI 
But, not all voices are positive ones over AI. First of 
years have had positive results. Many no doubt go unreported, but two high profile ones in recent 
time are Microsoft¿s Tay AI Bot (a Machine Learning onl 
interactions). Tay developed a ¿character¿ with strong racist, sexist opinions, and had to be 
removed [16] Furthermore, ongoing problems with AI messaging chatbots, at Google, resulted in 
a rollback in their adoption [17]. 
Computer Science & Information Technology (CS & IT) 
Figure 2: Predictions from the MIRI dataset surveys. Source [10] 
The academic study of Robot Ethics or ¿RoboEthics¿ is a well-established position in educational 
and research institutes. In part, this is a response to the understanding that robots, in particular 
drones, are entering the military as lethal weapons of war. And as such need regulation and legal 
s also concerned about the rights of robots themselves, as anticipated 
sapient and sentient ¿beings¿ with inalienable rights [15]. 
AI BEING OVERHYPED AND OR DANGEROUS 
3.1. Recent failure stories in AI 
But, not all voices are positive ones over AI. First of all, not all AI developments in the past few 
years have had positive results. Many no doubt go unreported, but two high profile ones in recent 
time are Microsoft¿s Tay AI Bot (a Machine Learning online chatbot that learns from its 
interactions). Tay developed a ¿character¿ with strong racist, sexist opinions, and had to be 
removed [16] Furthermore, ongoing problems with AI messaging chatbots, at Google, resulted in 
. While these, perhaps overly ambitious projects did not meet the 
position in educational 
and research institutes. In part, this is a response to the understanding that robots, in particular 
drones, are entering the military as lethal weapons of war. And as such need regulation and legal 
s also concerned about the rights of robots themselves, as anticipated 
ANGEROUS 
not all AI developments in the past few 
years have had positive results. Many no doubt go unreported, but two high profile ones in recent 
ine chatbot that learns from its 
interactions). Tay developed a ¿character¿ with strong racist, sexist opinions, and had to be 
removed [16] Furthermore, ongoing problems with AI messaging chatbots, at Google, resulted in 
these, perhaps overly ambitious projects did not meet the 
Computer Science & Information Technology (CS & IT) 63 
expectations of the management, they nevertheless provide a proving ground for what can be 
done with today¿s technology and what needs further work. Such feedback is helpful in setting 
more realistic expectations [18]. 
There are other noted failures in AI projects, e.g., the fatal crash of a Tesla Automated Driving 
system in 2016, whereby autopilot sensors on the Model S failed to distinguish a white tractor- 
trailer crossing the highway against a bright sky. In this case, it might be claimed that the 
testing/QA failed to identify this scenario and build sufficient responses to factor it safely. 
3.2. Known problems with Deep Learning 
Much, though not all of the recent success in AI has been due to Machine Learning advancement 
in so-called Deep Learning based Neural Networks. But, these bottom-up learning based systems 
(so-called because they develop learned experience from hierarchical analysis of basic data types 
and their deep correlations) have issues. They can learn well, often in tight domains beyond 
human learned experience and can outperform a human. But, a human can provide a top-down 
description, a discursive rationalisation to a, ¿why did you decide to make that move/act¿ 
question with a, ¿because, I think gaining control of the centre area a useful strategy at this point 
in the game¿ question. Whereas. a Deep Learning system cannot. It is not rule-based and cannot 
easily track its ¿reasoning¿. In a sense it is like an experienced financial markets trader who 
knows when to buy/sell, not because of the analytics, but because he has the intuitive ¿feel¿ built 
over years of trading. However, intuition is not necessarily a good guide when the market 
modalities change, as many traders have found out to their ultimate cost. As some critics have 
said, ¿it is only real intelligence if you can show it¿s working¿ [19]. 
In applications that require compliance with regulations and legal constraints, such systems may 
be considered risky. Furthermore, if such a system were committed to a highly Mission Critical 
Application, it would be difficult to question, supervise and control. Such intuitive systems, once 
relied upon, cannot easily be ¿rolled-back¿, human operators become reliant on the system to 
make all the hard decisions. In the event of failure, total system breakdown may ensue. There is 
a significant risk here. As AI is woven more deeply into the fabric of everyday life, the tension 
between human operators and AI has become increasingly salient. There is also a paradox: the 
same technologies that extend the intellectual powers of humans can displace them as well [20]. 
3.3. Mysterian Position ¿ Beyond Computation 
Some AI critics while recognising useful tools can be built do not believe AGI is likely in the 
short or medium term outlook of understanding of such things as ¿consciousness, free-will and 
self-aware visceral experience (qualia).¿ While this paper will not address these ¿Hard Problems 
of Consciousness¿ concerns; it is perhaps not necessary to incorporate these functional elements. 
If they cannot be defined in the case of natural human intelligence, we are not in a position to 
easily address them in our smart tools and AGI. Maybe AGI can pass Turing Tests, but not have 
these functions. The better question is perhaps, do we have them or are they illusory? See [21].

ChatGPT
The section on the pitfalls of AI development highlights a critical discourse surrounding the field's rapid advancements and the potential risks associated with its evolution. It underscores the importance of managing expectations and acknowledging the limitations of current AI technologies, emphasizing three main areas of concern:

Recent Failures in AI: The narrative presents sobering reminders of the challenges inherent in AI development, illustrated by high-profile incidents such as the missteps of Microsoft's Tay AI bot and issues with AI chatbots at Google. These examples serve as cautionary tales about the unpredictability and ethical considerations of AI systems that learn from their interactions. Furthermore, the fatal crash involving a Tesla Automated Driving system underscores the technological and ethical complexities of integrating AI into safety-critical applications. These incidents reveal the gaps in current AI technologies, particularly in understanding and adapting to complex real-world scenarios.

Challenges with Deep Learning: While deep learning has driven many of the recent successes in AI, the section highlights its inherent limitations. Deep learning systems, despite their prowess in specific domains, lack the ability to provide discursive rationalizations for their decisions, contrasting with human cognitive processes that can articulate reasoning. This limitation is significant in contexts requiring transparency and accountability, such as regulatory compliance or mission-critical applications. The narrative draws an analogy to financial traders, suggesting that intuition developed through deep learning may falter when conditions change, illustrating the risk of overreliance on these systems.

The Mysterian Position on AGI: This perspective introduces philosophical skepticism regarding the feasibility of achieving Artificial General Intelligence (AGI) that encompasses human-like consciousness, free will, and subjective experience. It questions the current understanding of these complex cognitive phenomena and whether they can be replicated or understood through computational means. The Mysterian stance serves as a reminder of the profound mysteries of consciousness and the potential limits of AI to replicate the full spectrum of human cognitive and experiential capabilities.

Together, these points articulate a nuanced view of AI development, balancing the enthusiasm for technological breakthroughs with a sober assessment of the field's current limitations and ethical challenges. They highlight the necessity for a cautious and reflective approach to AI research and deployment, ensuring that advancements are guided by ethical principles, transparency, and a deep understanding of the technology's potential impact on society. This dialogue is crucial for navigating the path toward responsible and beneficial AI development, acknowledging both its transformative potential and its constraints.



User
3.4. Issues of functional complexity and computational limits 
Some AI critics, while not accepting necessarily the problems of intelligence being in principle 
beyond computational methods, believe it is so complex that our current computational 
64 Computer Science & Information Technology (CS & IT) 
processing, is just not powerful enough, or the cost to provide it would be so astronomical as not 
to be worth the benefit. The above is a more of an objection in pragmatic terms. ¿Smart AI 
Tools¿ can be delivered in tight knowledge domains, but as for AGI, this is simply a non-starter 
for a long time to come. Recently Philosopher Daniel Dennett has made this argument, referring 
to AGI as ¿balderdash¿ [22]. Likewise, Philosopher Jerry Kaplan [23] has expressed concerns. 
However, some will point out that massive hierarchies of systems, even such as we have today, 
on parallel networked computational systems might cover the spectrum of human domain 
knowledge, with abstract reasoning and coordinated response. Such systems are termed Multi- 
Agent or Distributed AI systems [24]. Furthermore, such computer platforms, while not 
affordable today in their massive extension, might be within a few decades. 
As for software, that also continues to improve, and the potential for geometric improvement by 
evolutionary learning algorithms, whereby AI works on AI and evolves rapidly is viable. The 
evolutionary cost of learning in simulated ¿toy universes¿ may not be as ¿expensive¿ or slow as 
in our experience of evolution in ¿natural reality.¿ Such simulations can be used for 
development, but also for QA/testing of extreme scenarios not easily tested physically [25]. 
3.5. Moore¿s Law¿s End? 
While the hope is computer processing will continue to become dramatically cheaper, and more 
powerful, this is not a given. Moore¿s Law that underpins that expectation is considered by some 
to be no longer applicable [26]. However, Intel counters that it is still alive [27]. The possibility 
of future improvement by innovation in new technology, such as Quantum Computers (and other 
innovative technologies) might step up and provide the substrates to keep Moore¿s law alive for 
years to come [28].

ChatGPT
The discussion around the functional complexity and computational limits of AI challenges the optimistic trajectory of AI development by presenting a more nuanced perspective on the feasibility of achieving Artificial General Intelligence (AGI). It touches upon several key points:

Complexity and Computational Power: Critics argue that the sheer complexity of intelligence may exceed our current computational capabilities, suggesting that while specialized AI tools can excel in narrowly defined domains, the broader ambition of AGI remains elusive. This perspective highlights a pragmatic objection to AGI, emphasizing the gap between the specialized utility of "Smart AI Tools" and the comprehensive cognitive capabilities associated with AGI.

Philosophical Skepticism: Figures like Daniel Dennett and Jerry Kaplan provide a critical voice on the prospects of AGI, labeling it as impractical or overly optimistic. Their skepticism is rooted in the pragmatic assessment of computational needs versus the anticipated benefits, challenging the prevailing narratives of inevitable progress towards AGI.

Potential of Distributed AI Systems: In contrast to these critiques, there's an acknowledgment of the potential for distributed AI systems, which could integrate multiple AI agents working in concert across a network. This model suggests a pathway toward emulating a broader spectrum of human cognitive abilities through collaboration among specialized systems, albeit with current technological and financial constraints.

Software Evolution and Learning Algorithms: The evolution of software and learning algorithms offers a counterpoint to concerns about computational limits. The possibility of AI systems evolving through self-improvement presents a dynamic factor that could accelerate progress in AI development, potentially outpacing the limitations set by current computational models.

Moore¿s Law and Computational Progress: The debate around Moore's Law and the future of computational progress underscores a critical uncertainty in AI development. While the historical trend of exponential growth in computing power (as encapsulated by Moore's Law) faces skepticism, the potential for breakthroughs in quantum computing and other innovative technologies offers hope for continued advancement.

This discourse encapsulates the tension between current limitations and future possibilities in AI development. It reflects a landscape marked by rapid technological change, philosophical debate, and pragmatic considerations of what is feasible in the near to medium term. The dialogue around these issues is vital for setting realistic expectations and guiding the ethical and strategic direction of AI research and development. It underscores the importance of balancing ambition with a clear-eyed assessment of the challenges that lie ahead, ensuring that the pursuit of AGI remains aligned with both technological realities and societal needs.



User
3.6. ¿Prophets of Doom¿, AGI as an Existential Risk 
Even if the negative technical issues expressed above can be resolved, such that the promise and 
positive thinking expressed optimistically in section 2 above can be delivered, there are high 
profile voices being expressed that developing safe and ethical AGI within the next 20-30 years 
or so is very dangerous. These critics express concerns that AGI perhaps should not be 
developed. The danger is regarding the existential risk that they present to humanity, as well as 
to human culture regarding reducing human employment to such a point as to destabilise society. 
Physicist Stephen Hawking, Microsoft founder Bill Gates and Tesla/SpaceX founder Elon Musk 
have expressed concerns about the possibility that AI could develop to the point that humans 
could not control it [29]. Stephen Hawking said in 2014 that "Success in creating AI would be 
the biggest event in human history. Unfortunately, it might also be the last, unless we learn how 
to avoid the risks." Hawking believes that in the coming decades, AI could offer "incalculable 
benefits and risks" such as "technology outsmarting financial markets, out-inventing human 
researchers, out-manipulating human leaders, and developing weapons we cannot even 
understand." He makes the point that "The development of full artificial intelligence could spell 
the end of the human race" [30]. 
In January 2015, Nick Bostrom joined Stephen Hawking, Max Tegmark, Elon Musk, Lord Martin 
Rees, Jaan Tallinn, and numerous AI researchers, in signing the Future of Life Institute's open 
letter speaking to the potential risks and benefits associated with artificial intelligence. The 
Computer Science & Information Technology (CS & IT) 65 
signatories ¿¿believe that research on how to make AI systems robust and beneficial is both 
important and timely, and that there are concrete research directions that can be pursued today 
[31]. Their position is not that AGI should be halted, rather that urgent attention is needed to 
ensure that it is delivered ethically and safely. It should be noted that in the case of a sudden AGI 
"intelligence explosion", effective precautions will be extremely difficult. Not only would its 
creators have little ability to test their precautions on an intermediate intelligence, but the creators 
might not even have made any precautions at all, if the advent of the intelligence explosion 
catches them completely by surprise. Hence their concern to think through the AGI negative 
issues as early as possible so as to prepare principles to handle them. 
3.7. AI Impact on Jobs ¿ Luddite Rebellion 
Furthermore, some consider AGI and the uptake of pervasive Robotics/Industrial Automation as 
harmful to our civilisation regarding reducing human employment to such a point as to destabilise 
society. Such instabilities in earlier Industrial Revolutions resulted in an anti-technology reaction, 
known the Luddite Rebellion [32]. Could this occur again? This concern needs to be addressed. 
Indeed it is the subject and concern of the World Economic Forum as mentioned earlier [13].

ChatGPT
The discourse surrounding the development of Artificial General Intelligence (AGI) and its potential existential risks highlights a significant ethical and societal debate in the field of AI. This debate is framed by concerns from high-profile figures and scholars who caution against the unchecked advancement of AI technologies that could surpass human control and pose unprecedented risks to humanity and societal stability.

Existential Risks of AGI: The warnings from figures such as Stephen Hawking, Bill Gates, and Elon Musk underscore the potential for AGI to become an existential threat. These concerns are not just about the technological capability of AGI to outperform humans in various domains but also about the broader implications of such advancements, including the potential for AI to develop autonomous weapons systems or manipulate financial markets beyond human comprehension or control.

Ethical Development and Safety: The collective call for research into making AI systems robust and beneficial reflects a consensus on the need for proactive measures to mitigate the risks associated with AGI. The signatories of the Future of Life Institute's open letter emphasize the importance of early and thoughtful consideration of these challenges to ensure that the development of AGI proceeds in an ethical and safe manner. This approach acknowledges the dual potential of AGI to offer tremendous benefits while also posing significant risks.

Intelligence Explosion and Precautions: The concept of an "intelligence explosion," where AGI rapidly evolves beyond human control, adds urgency to these discussions. The difficulty in predicting and preparing for such a scenario highlights the challenges in ensuring that AGI development aligns with human values and safety protocols. The concern is that without adequate precautions, humanity may be ill-prepared to manage or mitigate the risks associated with a sudden leap in AI capabilities.

Impact on Employment and Societal Stability: Beyond existential risks, the debate also encompasses concerns about the impact of AGI and automation on employment and societal stability. The historical precedent of the Luddite Rebellion during the Industrial Revolution serves as a reminder of the potential for technological advancements to disrupt labor markets and societal norms. This concern is echoed in discussions at forums like the World Economic Forum, which considers the implications of AI and robotics on the future of work.

These discussions encapsulate the complex interplay between technological advancement, ethical considerations, and societal impacts. They underscore the necessity for a multidisciplinary approach to AI development, one that integrates technological innovation with ethical foresight and societal preparedness. The debate over AGI and its implications serves as a critical reminder of the need for a balanced and forward-thinking approach to AI, ensuring that its development is guided by principles that prioritize human welfare and the mitigation of risks.



User
4. NEED TO UNDER PROMISE AND OVER DELIVER ¿ AVOID THE 
HYPE 
4.1. Addressing concerns 
As Management Consultant Tom Peters says, ¿Quality is important, to be sure, so is absolute 
response time, and price, but at the top of most lists, by far, is keeping your word.¿ With 
uncertainty rising, if you ¿under promise, over deliver,¿ you will not only keep the customers 
satisfied; you'll keep the customers¿ [33]. While you can make the case this advice is not 
universally applicable, in cases where timelines are in doubt, and where there are critics in the 
wings who are willing to take pot shots, and your case depends, in part, on technology innovation 
not yet delivered, then it seems prudent to apply this principle. 
With that in mind, I propose that we be more modest in our claims for AI and AGI. Yes, we may 
expect it to come, and indeed we may need it to help us solve knotty problems we face in an ever 
more chaotic and complex world full of existential problems, many arising out of our 
mismanagement. But, we should be warry of over-extending the use of the term, or conflating 
them. Thus, let us make a point of not talking up AGI for the next five years or so, to deliver on 
our projects in hand. That, if done well and to expectations will establish AI as a real vehicle for 
a paradigm change (and build solid foundations for AGI). As we have seen AI is an easily 
challenged term and easily hyped, we need to be more specific with our language, else "AI" risks 
becoming meaningless [34]. We should address specifically what it does and what it doesn't. 
Often it is better to say Machine Learning, Natural Language Understanding, Forecasting, Image 
Recognition, Predictive Analytics/Big Data, etc. I would put these technologies under the banner 
of Cybernetics, with its transdisciplinary systems and top-down perspective [35]. 
Having said that, I think it is wise to maintain the dialogue such as ongoing at the Asilomar 
Conference and World Economic Forum [12], [13], to prepare the way for ethical and safe AGI. 
Once a self-reinforcing cybernetic loop starts to generate more and more intelligent systems, the 
onset of AGI is likely to be fast, and catch many unprepared. Given that it is wise to 
66 Computer Science & Information Technology (CS & IT) 
acknowledge that it is necessary to be prepared to think the unthinkable, before the unstoppable 
starts, that is if you have a desire to stop it/make it safe. 
4.2. Really Useful Machine Learning ¿ RUMLSM 
With the rising optimistic and pessimistic media attention to AI, the philosophical debate over the 
term, and the conflation of AI projects with lofty AGI ambitions, it is perhaps wise to consider 
using terms that limit reference to AI and AGI at this time. More emphasis should be made on 
terms such as Machine Learning, Neural Networks, Evolutionary Computation, Vision, Robotics, 
Expert Systems, Speech Processing, Planning, Natural Language Processing, etc., and to make 
sure that the scope is well defined in practical application. 
In this spirit, we are currently undertaking modest AI research and development of an innovative 
Hybrid Machine Learning paradigm that incorporates bottom-up Deep Learning Neural Networks 
and a means to extract a rationalisation of a top-down heuristic narrative. Our intention is to roll 
this out over 4 phases over the following three years and apply it to calvIO¿s Industrial Robotics 
platforms and integrated systems. We refer, and headline, this as ¿Really Useful Machine 
Learning¿ (RUMLSM). 
The key novelty of the system is the integration of intuitive bottom-up and rational top-down 
learning; we find inspiration for the paradigm in known means to teach expertise at and expert 
practitioner level by ¿masterclass mentoring¿, outlined in the Figure below [36]. 
Figure 3: Masterclass Mentoring: Journey from Non-Readiness to Expert

ChatGPT
The call to "under promise and over deliver" in the context of AI development is a prudent strategy that emphasizes the importance of setting realistic expectations and delivering tangible results. This approach is particularly relevant given the complex and often unpredictable nature of AI research and development. By adopting a more modest and precise language when discussing AI capabilities, the field can avoid the pitfalls of hype and ensure a more grounded and productive discourse.

Pragmatic Communication: The advice from Tom Peters about the importance of keeping one's word resonates strongly with the ethos of responsible AI development. By consciously tempering expectations and focusing on delivering solid, reliable outcomes, AI developers and researchers can maintain credibility and trust with the public and stakeholders. This strategy is crucial in a field where speculative futures and ambitious goals can often overshadow the tangible progress being made.

Specificity in Language: The recommendation to use more specific terms such as Machine Learning, Natural Language Understanding, or Predictive Analytics, instead of the broad and often misunderstood term "AI," helps clarify the actual capabilities and limitations of current technologies. This precision in language can demystify AI for the broader public and foster a more nuanced understanding of its applications and impacts.

Ethical and Safe Development of AGI: The ongoing dialogues at forums like the Asilomar Conference and the World Economic Forum are highlighted as essential platforms for preparing the ethical groundwork for AGI. These discussions are critical for anticipating and addressing the rapid advancements in AI that could lead to the emergence of AGI. By engaging in these conversations now, the community can better prepare for and potentially mitigate the unforeseen consequences of AGI.

Focus on Practical Applications: The introduction of the "Really Useful Machine Learning" (RUMLSM) project serves as an example of how AI research can be oriented towards practical, well-defined applications. By focusing on developing AI technologies that have clear utility and integrating them into existing systems, such as industrial robotics, the field can demonstrate the tangible benefits of AI and build a solid foundation for future advancements.

Overall, the emphasis on under-promising and over-delivering, coupled with a commitment to ethical considerations and a focus on practical applications, outlines a responsible path forward for AI development. This approach not only addresses the concerns and challenges associated with AI but also ensures that the development of these technologies remains aligned with societal needs and values.



User
4.3. Compliance, Supervision and Control needs 
Key aspects of the deliverable features of RUMLSM will be the ability to manage compliance, 
supervision and control of the system, by inspection of its extracted rationalised heuristic rule 
base. The testing of designed systems is performed in extensive simulation scenarios, examining 
extreme conditions before deploying to the physical systems. 
Computer Science & Information Technology (CS & IT) 67 
4.4. Extraction of Heuristics from Deep Learning Neural Networks 
The means by which Expert Heuristics are extracted from the Deep Learning Neural Networks 
has been studied by other teams [37], [38] and [39]. The means by which we propose to do so in 
RUMLSM is an innovative patent pending process. Expert Heuristic/Rule extraction can be 
defined as "¿given a trained neural network and the data on which it was trained, produce a 
description of the network's hypothesis that is comprehensible yet closely approximates the 
network's predictive behaviour." Such extraction algorithms are useful for experts to verify and 
cross-check neural network systems. 
Earlier this year, John Launchbury, director of DARPA¿s Information Innovation Office said, 
¿There¿s been a lot of hype and bluster about AI.¿ They published their view of AI into ¿Three 
Waves¿, so as to explain what AI can do, what AI can¿t do, and where AI is headed. RUMLSM 
is very much in this third wave in our opinion [40]. 
Figure 4: DARPA¿s Third Wave of AI [Source: 40] 
5. CONCLUSIONS 
The increase in media interest in Artificial Intelligence (AI) was noted, and the optimistic and 
pessimistic expectations as to the impact of AI (and potentially future AGI) commented on. 
While there have been some failures recently, significant milestone successes have encouraged 
massive investment. But, there is nevertheless a potential for AI to be marked as a bubble and 
¿hyped¿ technology. Indeed there are already signs of a backlash against AI [41], [42] and [43]. 
A short-term recommendation, to avoid the extremes of the positive and negative positions, was 
offered, we should ensure we don¿t conflate AGI with AI and be more specific in the use of terms 
to avoid AI becoming ¿meaningless¿. As Jerry Kaplan says ¿Had artificial intelligence been 
named something less spooky, we¿d probably worry about it less.¿ [23]. As an example of a 
more realistic use of terms for AI, goals is the use of terms such as ¿Really Useful Machine 
Learning¿ (RUMLSM). This particular technique was introduced in the context of resolving 
68 Computer Science & Information Technology (CS & IT) 
some of the known issues in bottom-up Deep Learning by Neural Networks with a top-down 
Cybernetic simulation-based process providing a more open and rational means to supervise, 
regulate and maintain compliance of the system. This patent pending technology uses a Masterclass - Mentoring paradigm, and fits into DARPA¿s ¿Third Wave of AI.¿

ChatGPT
The document outlines a comprehensive approach to the development and implementation of AI technologies, particularly focusing on the Really Useful Machine Learning (RUMLSM) project. This approach emphasizes the importance of managing compliance, supervision, and control through transparent and understandable systems. The initiative to extract heuristic rules from deep learning neural networks for verification and analysis by experts illustrates a commitment to creating AI systems that are not only powerful and efficient but also accountable and interpretable.

Key Takeaways:

Compliance, Supervision, and Control: RUMLSM is designed with a focus on ensuring that AI systems can be effectively managed and controlled. By allowing inspection of its heuristic rule base, the project aims to make AI decisions more transparent and understandable, facilitating better compliance and supervision.

Extraction of Heuristics: The innovative approach to extracting expert heuristics from deep learning neural networks is a significant step towards demystifying the decision-making processes of AI. This initiative is aligned with the broader goal of making AI more interpretable and trustworthy, particularly in critical applications where understanding AI's decision logic is essential.

Addressing AI Hype: The document acknowledges the hype surrounding AI and the potential for both overestimation and backlash against these technologies. It advocates for a more measured and precise use of terminology in discussing AI capabilities and limitations, suggesting that a clearer distinction between AGI and specific AI technologies could mitigate misunderstandings and unrealistic expectations.

DARPA's Third Wave of AI: Positioning RUMLSM within DARPA¿s Third Wave of AI emphasizes the project's alignment with cutting-edge research and development. This framework categorizes AI advancements into waves, with the third wave focusing on systems capable of contextual adaptation and reasoning, a critical step towards achieving more sophisticated and autonomous AI.

Conclusion and Recommendations: The document concludes with a call for cautious optimism and specificity in discussing AI developments. It highlights the potential for AI to be perceived as a bubble if not carefully managed and communicated. The recommendation to adopt terms like "Really Useful Machine Learning" reflects a strategy to ground discussions of AI in practical, achievable goals and applications.

The emphasis on transparency, control, and ethical development in the RUMLSM project reflects a broader recognition within the AI community of the need to address public concerns and ethical considerations proactively. By focusing on creating AI systems that are not only technically advanced but also understandable and under human control, the project contributes to the development of AI technologies that are beneficial, safe, and socially responsible.



User
A summary of the whole article

ChatGPT
The article by Martin Ciupa, titled "Is AI in Jeopardy? The Need to Under Promise and Over Deliver ¿ The Case for Really Useful Machine Learning," addresses the burgeoning field of Artificial Intelligence (AI), its rapid growth, public perception, and the ethical considerations surrounding its development and deployment. Ciupa discusses the recent successes and failures of AI, the hype surrounding its potential, the risks it poses, and the need for a more grounded and realistic approach to AI development.

Key Themes and Points:

Media Attention and Investment in AI: Ciupa begins by noting the dramatic increase in media interest and investment in AI, highlighting recent successes in machine learning, image recognition, and natural language processing. However, he cautions against "irrational exuberance," pointing out the potential for AI to become overhyped.

Existential Opportunities and Threats: The article examines the dual-edged nature of AI, from its potential to solve critical global challenges to the existential risks it might pose, including concerns raised by high-profile scientists and entrepreneurs about unchecked AI development leading to outcomes humans cannot control.

Ethical Development and Governance: Ciupa discusses initiatives like the Asilomar Conference and the World Economic Forum's efforts to establish guidelines for the ethical development of AI, emphasizing the importance of preparing for the ethical and societal implications of advanced AI systems.

Failures and Limitations of AI: The paper recounts specific instances where AI technologies have failed, such as Microsoft¿s Tay AI bot and the Tesla autopilot incident, highlighting the limitations and unpredictability of current AI systems.

Computational Limits and Philosophical Skepticism: It addresses the skepticism regarding AGI's feasibility, citing the complexity of intelligence and current computational limits, while also mentioning the potential of distributed AI systems and innovations like quantum computing.

AI as an Existential Risk: The article voices concerns about AI becoming an existential risk, referencing prominent figures like Stephen Hawking and Elon Musk, who have warned about the dangers of AI surpassing human control.

Impact on Employment: Ciupa touches on the societal impact of AI, particularly its potential to disrupt job markets, drawing parallels with historical technological upheavals.

Recommendations for Responsible AI Development: The piece concludes with a call for the AI community to adopt a more measured approach, focusing on specific, achievable goals and transparent methodologies. Ciupa advocates for the development of "Really Useful Machine Learning" (RUMLSM) projects that prioritize practical applications, compliance, and control, suggesting a shift towards terminology that accurately reflects the capabilities and scope of AI technologies.

Throughout the article, Ciupa argues for a balanced perspective on AI, urging for cautious optimism, rigorous ethical considerations, and a focus on developing AI technologies that are not only innovative but also beneficial, safe, and socially responsible. He emphasizes the need for the AI community to under promise and over deliver, to mitigate the risks and maximize the benefits of AI for society.



User
I like the point of underpromising and overdelivering.  It can be argued that this is is dishonest, however I can think of lots of situations where an AI interacting with the real world will have to lie outright in order to protect itself or others, and many other reasons.

ChatGPT
The principle of underpromising and overdelivering, especially in the context of AI, navigates a nuanced ethical landscape. While at first glance, it may seem akin to setting lower expectations dishonestly, the intention and application of this principle are rooted in pragmatism and responsibility rather than deceit.

Ethical Pragmatism: In the rapidly evolving field of AI, where potential outcomes are both highly impactful and uncertain, underpromising serves as a buffer against the unpredictability of technological development. It's a practice aimed at managing expectations realistically to avoid the pitfalls of overhyping capabilities, which could lead to misplaced trust, misallocation of resources, or public disillusionment with the technology.

Protective Measures: The idea that an AI might need to "lie" to protect itself or others opens a complex ethical debate. In scenarios where AI systems interact with humans, the concept of "lying" or withholding information could be programmed as a protective measure¿for instance, in healthcare settings where patient privacy is paramount, or in security systems where revealing too much information could compromise safety. The critical factor here is the intention behind the action and the overarching goal of ensuring well-being and safety.

Ethical Frameworks for AI: The potential for AI systems to make decisions involving deception or withholding information underscores the importance of developing robust ethical frameworks guiding AI behavior. These frameworks should prioritize transparency, accountability, and human welfare while recognizing the complexity of real-world interactions. Ethical AI development involves anticipating and navigating scenarios where AI systems must balance competing values, such as honesty versus harm prevention.

Public Trust and Transparency: Maintaining public trust in AI technologies requires transparency about their capabilities and limitations. Underpromising and overdelivering, when approached transparently, can build trust by demonstrating reliability and caution. This approach underscores a commitment to ethical standards and the responsible deployment of AI, acknowledging the technology's potential impacts before they are fully realized.

Conclusion: The balance between honesty, protection, and ethical responsibility in AI underscores the need for ongoing dialogue among technologists, ethicists, policymakers, and the public. While the notion of AI "lying" for protection raises ethical questions, it also highlights the complexity of integrating AI into societal contexts. The principle of underpromising and overdelivering, far from being dishonest, is a recognition of this complexity and an effort to navigate it responsibly.



User
There was a scripture about it, the sons who said yes and no to whether they would help

ChatGPT
The scripture you're referring to is from the Bible, specifically the Parable of the Two Sons found in Matthew 21:28-32. This parable is one of Jesus' teachings and goes as follows:

¿But what do you think? A man had two sons; he went to the first and said, ¿Son, go and work in the vineyard today.¿ He answered, ¿I will not¿; but later he changed his mind and went. The father went to the second and said the same; and he answered, ¿I go, sir,¿ but he did not go. Which of the two did the will of his father?¿ They said, ¿The first.¿ Jesus said to them, ¿Truly I tell you, the tax collectors and the prostitutes are going into the kingdom of God ahead of you. For John came to you in the way of righteousness and you did not believe him, but the tax collectors and the prostitutes believed him; and even after you saw it, you did not change your minds and believe him.¿

This parable emphasizes actions over words, illustrating that genuine repentance and obedience are demonstrated through deeds rather than mere promises or declarations. It's a reminder of the value of following through on commitments and the importance of actual behavior over initial responses.

In the context of your previous point, while the principle of underpromising and overdelivering isn't directly discussed in this scripture, the underlying message about the significance of actions aligns with the ethical considerations in AI development and deployment. The emphasis is on the outcomes of decisions and the importance of aligning actions with ethical and responsible intentions, even if initial statements or promises suggest otherwise. This parable encourages a reflection on the importance of reliability, repentance, and the transformative potential of actions in fulfilling commitments and obligations.



User
I thought of it as let your yays be yays, and your nays be nays, but you can let you nays be yays

ChatGPT
The principle you're recalling, "let your yes be yes, and your no be no," is indeed a biblical directive, found in James 5:12:

"But above all, my brothers, do not swear, either by heaven or by earth or by any other oath, but let your 'yes' be yes and your 'no' be no, so that you may not fall under condemnation."

This verse emphasizes integrity and straightforwardness in one's speech, advocating for honesty and the importance of keeping one's word without resorting to oaths or embellishments to prove one's sincerity.

Connecting this to your earlier reflection on underpromising and overdelivering, and the scenario of AI having to "lie" for protection or other ethical reasons, presents a nuanced ethical landscape. While the directive from James advocates for honesty and simplicity in communication, the practical and ethical complexities of AI in real-world scenarios can sometimes necessitate actions or decisions that appear to contradict a straightforward interpretation of yes and no.

In the context of AI, the principle of "let your yes be yes, and your no be no" could be interpreted as a call for transparency and reliability in how AI systems are described and how they operate. It suggests that AI developers and operators should strive for their systems to perform consistently with their stated capabilities and ethical guidelines, avoiding misleading or overinflated claims about their functionality.

However, the concept of allowing "your no to be yes," in a metaphorical sense, reflects the adaptive and sometimes protective mechanisms that might be programmed into AI systems. For example, an AI designed to safeguard personal data might deny access to information as a default ("no"), but under specific, ethically justified circumstances, it might grant access ("yes") to protect a greater good or prevent harm.

These ethical considerations highlight the importance of embedding AI systems with robust ethical frameworks that guide their decision-making processes, ensuring they act in ways that are consistent with human values and societal norms. Balancing honesty and protection, in this case, involves creating AI systems that are transparent about their capabilities and limitations while being equipped to navigate complex ethical scenarios responsibly.



User
So I thought the issue was further complicated by the fact that politeness is often a form a dishonesty. I was thinking of the studies where children were given a bar of soap as a gift, and they exhibited similar physiological reactions to lying if they said thank you or they liked it. I was also thinking of simplification and didactic methods where a particular proposition or model is untrue, until further information and refinement is given. Also in order to tell the "truth" the context and theory of mind must be taken into account. I could say I went to the "store" meaning the convenience store but I know that other person doesn't know about that store, and means a wine cellar or artillary store. 

ChatGPT
Your observations delve into the complexities of communication, where honesty intersects with social conventions, didactic simplification, and the nuances of context and perspective. Each of these areas showcases how "truth" and "dishonesty" can become multifaceted in everyday interactions and learning processes.

Politeness as a Form of Dishonesty: Politeness often requires a suppression of one's immediate feelings or desires in favor of social harmony. The example of children expressing gratitude for an undesired gift like a bar of soap illustrates this tension. The physiological responses akin to lying highlight the discomfort of suppressing one's genuine reaction, but socially, this behavior is encouraged as a form of respect and gratitude. This dichotomy suggests that not all forms of "dishonesty" are ethically or socially equivalent; some are widely accepted and even necessary for social cohesion.

Didactic Simplification: In education and communication, complex ideas are often simplified to make them accessible to learners or to focus on the most relevant aspects of a concept. This simplification process can involve presenting models or explanations that are not entirely accurate or omit certain nuances. While technically "untrue" in a strict sense, these simplifications serve a practical purpose in building understanding, with the expectation that more complex truths will be introduced as the learner's capacity to understand them grows. This approach underscores the importance of context and intention behind the simplification.

Context and Theory of Mind: Effective communication requires an understanding of the other person's knowledge, expectations, and how they might interpret your words. The example of using the word "store" with different intended meanings based on what you believe the other person knows or assumes illustrates the complexity of truth-telling. It's a reminder that truth is not just about factual accuracy but also involves considering the listener's perspective and the shared context of the communication.

These complexities suggest that truth-telling and honesty are not merely about factual correctness but involve navigating social norms, educational strategies, and communicative context. In each case, the intention behind the communication¿whether to maintain social harmony, facilitate learning, or ensure mutual understanding¿plays a crucial role in determining the ethical implications of these forms of "dishonesty."

When applying these considerations to AI and technology, it becomes evident that designing AI systems that navigate these complexities ethically requires a deep understanding of human social norms, learning processes, and communication strategies. AI systems must be developed with an awareness of the nuances of human ethics and communication to ensure that they act in ways that are not just technically accurate but also socially and ethically responsible.



User
Connections between our discussion and the article we reviewed

ChatGPT
The discussion on underpromising and overdelivering, politeness as a form of dishonesty, didactic simplification, and the nuances of context in communication intersects with several themes and concerns raised in Martin Ciupa's article on AI. Here¿s how these concepts relate and apply to the themes of the article:

Underpromising and Overdelivering: Ciupa emphasizes the importance of setting realistic expectations for AI to avoid the pitfalls associated with overhype. This principle is akin to our discussion on the strategic moderation of promises to ensure that outcomes exceed expectations, thereby building trust and credibility. In AI development, this approach can mitigate disillusionment and backlash by aligning public expectations with achievable goals.

Politeness and Social Conventions: The article touches on the importance of ethical and responsible communication about AI's capabilities and risks. This can be paralleled with the discussion on politeness as a form of socially accepted dishonesty, where certain conventions or simplifications are used not to deceive but to facilitate smoother social interactions or to navigate complex ethical considerations. In AI, communicating in terms that are both optimistic and realistic requires navigating these social conventions wisely to maintain public trust and support.

Didactic Simplification: Ciupa's call for clarity and specificity in discussing AI and AGI reflects the importance of didactic simplification. Just as educators simplify complex concepts to aid understanding, AI researchers and developers must articulate their advancements and limitations in a manner that is accessible and accurate, without oversimplifying to the point of misinformation. This balance is crucial for informed public discourse and ethical awareness in AI development.

Context and Theory of Mind in Communication: The article¿s advocacy for a nuanced understanding of AI¿s social and ethical implications mirrors the discussion on the importance of context and theory of mind in truthful communication. In AI, acknowledging and addressing the varied interpretations and expectations of diverse stakeholders requires a nuanced understanding of their perspectives, fears, and hopes. This is particularly relevant in the ethical development and deployment of AI, where the technology¿s impact can vary widely across different social and cultural contexts.

Ethical Frameworks and Governance: The discussions at the Asilomar Conference and the World Economic Forum, as mentioned in the article, aim to establish guidelines for AI that consider its broader societal impacts. This aligns with our discussion on the complexities of honesty and ethics in communication and action. Developing AI within ethical frameworks necessitates a deep engagement with these complexities, ensuring that AI technologies are not only technically advanced but also socially and ethically responsible.

In summary, the themes of our discussion provide a deeper ethical and communicative context to the challenges and recommendations Ciupa presents in his article. They underscore the necessity of navigating the ethical, communicative, and social complexities of AI development and deployment, advocating for a responsible approach that balances technological advancement with ethical integrity and public trust.



User
The main criticism seemed to be against hype, I agree with this, but also can see how hype is already present in naming conventions for corporations and products (I was thinking of the Samsung "galaxy" or "universal pictures") I think panaceas and universal theories of everything (grand narratives) were even more common in the past, and may actually be going down over time. (Early "moonshots" might have actually tried to shoot people to the moon in a giant cannon, travel to Mars in a dream after falling asleep in a cave, or be promised eternal life for building a pyramid or carving a statue. Also there are definitely types where hype turned out correct in the long run or aspirational. I was thinking of the chicken in every pot campaign of 1928, and how no one at the time would have made a promise of a supercomputer in  every pocket, because such a concept was at yet still more or less unthinkable.

ChatGPT
Your observations offer a nuanced perspective on the role of hype in the advancement of technology and societal expectations. The comparison to historical grand narratives and the aspirational nature of certain types of hype helps contextualize the criticism against AI hype discussed in Ciupa's article. Let's explore these points in relation to the AI discourse:

Hype in Naming Conventions: The use of grandiose names like "Samsung Galaxy" or "Universal Pictures" reflects a marketing strategy designed to evoke a sense of vastness, innovation, or universality. This strategy is not new and has been a staple in branding and advertising for a long time. In the context of AI, the hype often stems not just from naming conventions but from broader claims about the technology's potential to revolutionize every aspect of human life. While marketing strategies aim to attract attention and differentiate products, the hype around AI also raises ethical and societal expectations that might not be immediately achievable.

Grand Narratives and Historical Panaceas: The historical examples you've mentioned illustrate humanity's longstanding penchant for grand narratives and ambitious goals, from moonshots to promises of eternal life through monumental achievements. These narratives have often served to inspire collective efforts and push the boundaries of what was considered possible. In the realm of AI, the grand narrative revolves around achieving AGI or solving fundamental human problems, continuing the tradition of setting lofty goals. However, the key difference might lie in the immediacy and tangibility of AI's impact on society, necessitating a more cautious approach to avoid disillusionment or ethical dilemmas.

Aspirational Hype and Realized Visions: The mention of the "chicken in every pot" campaign and the unimaginable concept of a supercomputer in every pocket at the time highlights how some forms of hype can indeed be aspirational and, in hindsight, prophetic. These examples demonstrate that while hype can sometimes exceed current realities, it can also catalyze progress towards realizing those visions. The challenge with AI is distinguishing between achievable aspirations and speculative exaggerations, ensuring that the hype serves as a motivator rather than a source of misinformation or unrealistic expectations.

The Role of Hype in AI Development: In light of these considerations, the criticism against AI hype can be seen as a call for responsible communication and realistic goal-setting. While aspirational goals have their place in driving innovation, the tangible and widespread implications of AI technologies require a balanced narrative that acknowledges both the potential and the limitations of current developments. This balance is crucial to maintaining public trust, ensuring ethical considerations are forefront, and guiding AI development in a direction that maximally benefits society.

In conclusion, while hype has historically played a role in driving human ambition and technological progress, the discourse around AI invites a more nuanced engagement with hype. Recognizing the potential for both inspiration and misdirection, the AI community is tasked with navigating these dynamics thoughtfully, striving for a future where AI's promise is realized responsibly and ethically.



User
So maybe instead of saying "AI" we could say "smart pockets" or "multiplexing microfilm memex"

ChatGPT
Reframing the terminology around Artificial Intelligence (AI) into more specific or imaginative expressions like "smart pockets" or "multiplexing microfilm memex" offers an intriguing approach to addressing hype and setting more precise expectations. This strategy can serve multiple purposes:

Clarifying Capabilities: Terms like "smart pockets" could intuitively convey the notion of personal, portable technology with advanced functionalities, grounded in the current reality of smartphones and smart devices. This term suggests utility and accessibility, focusing on the practical aspects of AI integration into daily life without invoking the broad, often overhyped connotations of AI.

Inspiring Innovation with Specificity: "Multiplexing microfilm memex" evokes Vannevar Bush's concept of the "memex," a theoretical device proposed in his 1945 essay "As We May Think," which is often cited as a precursor to the internet and hypertext. By using such specific and historically rooted terminology, we can anchor discussions of AI in concrete ideas and historical trajectories of technological development, thereby fostering a more informed and inspired dialogue about future possibilities.

Mitigating Hype by Avoiding Overgeneralization: General terms like "AI" can become catch-alls for a vast array of technologies, leading to overgeneralization and hype. By employing more precise or evocative terms, the discourse can shift towards a focus on specific functionalities, applications, and ethical considerations, reducing the risk of inflated expectations.

Encouraging Public Engagement and Understanding: Novel and imaginative terminology can spark public interest and facilitate a deeper engagement with technology. By demystifying AI through more relatable or conceptually rich terms, the field can become more accessible to non-experts, encouraging broader participation in discussions about technology's role in society.

Highlighting Ethical and Societal Implications: Specific terms can also help highlight the ethical and societal implications of technology. For instance, "smart pockets" could prompt discussions about privacy, data security, and the digital divide, while "multiplexing microfilm memex" might evoke considerations about information access, knowledge management, and intellectual property.

While adopting new terminology could help address some of the challenges associated with the hype surrounding AI, it's important to ensure that such terms are not merely euphemisms but genuinely aid in advancing a more nuanced and constructive dialogue about technology. Balancing creativity with clarity and precision will be key to fostering a more informed and responsible discourse around the future of intelligent technologies.



User
Here is a list of suggested terms to use instead of AI, depending on the use case:

Organic learning (integration),
Epistemic reduction (abstraction)

(Monica Anderson)

consulting livers, casting lots, divination, inspiration

(The Bible)

Mechatronic compass

South-facing spoon bending device

(Historical)

Geometric Intuition,
Alpha-crystaline annealing (predictive inference on the statespace)



ChatGPT
These suggested terms offer a creative and diverse palette for describing different aspects and functionalities traditionally associated with AI, tailored to specific use cases. Let¿s explore how these terms might be applied to foster a clearer and more imaginative discourse:

Organic Learning (Integration): This term could be particularly apt for AI systems designed for adaptive learning and integration within natural or human environments. It evokes the process of learning in a manner that feels natural and organic, possibly highlighting AI systems that grow and evolve based on interactions with users or their environment.

Epistemic Reduction (Abstraction): Suitable for AI applications that distill complex data into more manageable, abstract forms. This term suggests a process of simplifying knowledge to its essential components, useful for describing AI systems that model complex phenomena or that assist in decision-making by reducing informational complexity.

Consulting Livers, Casting Lots, Divination, Inspiration (The Bible): These biblically inspired terms could be used metaphorically to describe AI systems that analyze data or patterns to predict outcomes or provide guidance. Much like historical or religious methods of seeking knowledge or making decisions, AI in this context could be seen as a modern form of accessing deeper insights or inspirations.

Mechatronic Compass: This term could describe AI systems used for navigation, orientation, or guiding decisions in mechanical or robotic applications. It implies precision and reliability in directing or influencing movement or choice, emphasizing the integration of mechanical and electronic components guided by AI.

South-Facing Spoon Bending Device (Historical): Evocative of whimsical or seemingly impossible inventions, this term might be used for AI technologies that challenge current limitations or expectations, especially in creative or innovative problem-solving contexts.

Geometric Intuition: Suitable for AI systems involved in spatial reasoning, design, or any field where understanding and manipulating geometric relationships are crucial. This term suggests an innate or developed capability within the AI to navigate complex spatial problems with ease.

Alpha-Crystalline Annealing (Predictive Inference on the Statespace): This could describe AI systems that engage in advanced predictive modeling, particularly where there is a need to understand and anticipate transitions between states in complex systems. The term evokes a process of transformation and refinement, similar to material processes, applied to the realm of data and prediction.

Using such specific and evocative terms not only enhances the richness of the discourse around AI but also helps clarify the purpose, functionality, and ethical considerations of AI applications. Each term invites stakeholders to engage more deeply with the technology, fostering a nuanced understanding that goes beyond the generalities often associated with the term "AI."



User
About 16,400 results (0.23 seconds) 
Did you mean: "alpha-crystallin"


Alpha Crystallin A (11075P-100)

QED Bioscience Inc
https://www.qedbio.com ¿ ... ¿ Recombinant Proteins
The expression of alpha crystalline A is preferentially restricted to lens cells. Specificity Information. Target Name Alpha Crystallin A. Target ID Alpha ...
US$279.00
People also ask
What is the function of alpha Crystallin?
Where is Crystallin found?
What is the size of alpha Crystallin?
What is the structure of a Crystallin?
Feedback

Crystallinity - an overview | ScienceDirect Topics
ScienceDirect
https://www.sciencedirect.com ¿ topics ¿ engineering ¿ c...
Because of the reduced crystallinity, beta crystalline polymer exhibits lower density and lower melting point than a polymer containing the alpha crystalline ...

Variant alpha-crystalline expression in age related and ... - IOVS

ARVO Journals
https://iovs.arvojournals.org ¿ article
by J Gu · 2014 ¿ Conclusions: Our experiments indicated that the reduction of alpha-crystalline in age-related and congenital cataract groups has significant difference.

Recombination and identification of human alpha B-crystallin

National Institutes of Health (NIH) (.gov)
https://www.ncbi.nlm.nih.gov ¿ articles ¿ PMC6288530
by R Wang · 2018 ¿ The alpha crystalline has two subunits, alpha A and alpha B, both of which have molecular chaperone activity. However, the molecular ...
Images

heterochromia syndrome

antibody

mandelic acid

alpha hydroxy

hypersensitivity

chemical structure

cryab

alphab crystallinwestern blot

pharmaceuticalacd
35 Alpha Crystalline Images, Stock Photos, 3D objects ...
35 Alpha Crystalline Images, Stock Photos, 3D objects ...

Shutterstock
35 Alpha Crystalline Images, Stock Photos, 3D objects ...
35 Alpha Crystalline Images, Stock Photos, 3D objects ...

Shutterstock
Alpha Crystalline powder at Best Price in Delhi | Ahlcon ...
Alpha Crystalline powder at Best Price in Delhi | Ahlcon ...

Exporters India
Feedback
6 more images

alpha crystallin A Recombinant Protein - CRYAA

MyBioSource
https://www.mybiosource.com ¿ recombinant-protein
The expression of alpha crystalline A is preferentially restricted to lens cells. Recombinant Human CRYAA produced in E. coli is a single, non-glycosylated ...
 Rating: 5 · ¿ US$245.00

Alpha Crystallin B (11073P-1000)

QED Bioscience
https://www.qedbio.com ¿ ... ¿ Recombinant Proteins
Alpha crystalline B is expressed in many tissues and is associated with many neurological diseases. Specificity Information. Target Name Alpha Crystallin B.
US$1,514.00

Human alpha-crystalline: its extraction, purification and ...

National Institutes of Health (NIH) (.gov)
https://pubmed.ncbi.nlm.nih.gov ¿ ...
by VM Sánchez-Hidalgo · 1982 · Cited by 2 ¿ Human alpha-crystalline: its extraction, purification and identification.

ChatGPT
It seems you're exploring information about alpha-crystallin, which is notably distinct from any conceptual or metaphorical use of "alpha-crystalline annealing" in discussions related to AI or predictive modeling. Here's a brief overview based on the details you've encountered:

Alpha-Crystallin is primarily known for its role as a structural protein in the lens of the eye, where it helps maintain transparency and refractive power. It belongs to the small heat-shock protein family and exhibits molecular chaperone functions, preventing the aggregation of unfolded or misfolded proteins, which is crucial for maintaining lens clarity and preventing cataract formation. Alpha-crystallin is composed of two subunits, alpha-A and alpha-B, both of which contribute to its chaperone activity and are expressed in various tissues, not just the lens. This broad expression pattern links alpha-B crystallin, in particular, to a range of neurological diseases and other conditions beyond its optical functions.

The scientific and medical interest in alpha-crystallin encompasses its structural properties, its role in the eye and other tissues, its potential involvement in disease mechanisms, and its therapeutic implications. Research into alpha-crystallin spans from its basic biology and function to its alteration in diseases like cataracts, neurological disorders, and its potential as a therapeutic target or biomarker.

The exploration of alpha-crystallin in scientific research underscores the complexity and interconnectedness of biological systems, which, while distinct from the domain of artificial intelligence and predictive modeling, reflects a similar drive to understand complex systems, whether biological or computational. The metaphorical use of terms like "alpha-crystalline annealing" in AI could draw inspiration from the multifaceted roles and mechanisms of proteins like alpha-crystallin, suggesting a process of refinement, adaptation, and protection against errors or instability in predictive models.



User
Yeah alpha-crystalline annealing I just made up on the spot, it is a 5d Ising synch Markov chain nullwave boundary detection algorithm on predictive model state space

ChatGPT
Creating a term like "alpha-crystalline annealing" to describe a complex concept such as a "5D Ising synch Markov chain nullwave boundary detection algorithm on predictive model state space" showcases the creative blending of ideas from physics, mathematics, and computer science. Although this specific term and description are imaginative, they touch on several advanced concepts in these fields. Let's unpack the components and the conceptual inspiration behind this innovative term:

5D Ising Model: The Ising model is a mathematical model of ferromagnetism in statistical mechanics, primarily used to understand phase transitions. Extending this model to five dimensions (5D) suggests an exploration into highly complex systems that exceed typical three-dimensional physical space, possibly incorporating additional dimensions for time and another variable, which could be relevant in advanced predictive modeling contexts.

Synch Markov Chain: This could refer to a synchronized (synch) Markov chain, which is a stochastic model describing a sequence of possible events where the probability of each event depends only on the state attained in the previous event. Incorporating synchronization implies that these chains or processes are coordinated in some manner, potentially to model complex systems that evolve over time with dependencies or to simulate parallel processes that need to be aligned.

Nullwave Boundary Detection: "Nullwave" is not a standard term in physics or mathematics but suggests an influence or interference that nullifies or significantly alters wave properties. In the context of boundary detection, it might refer to identifying transitions or edges within the model's state space where the predictive model's behavior changes dramatically or where certain conditions lead to stabilization or cancellation effects.

Algorithm on Predictive Model State Space: Combining these concepts into an algorithm that operates on the state space of a predictive model suggests a method for navigating or analyzing highly complex, multi-dimensional data structures. This could involve detecting critical transitions, phase changes, or boundaries within the model's predictions, potentially offering new insights into complex dynamics or improving the model's accuracy and robustness.

While "alpha-crystalline annealing" as a term synthesizes these concepts into a fictional algorithm, the underlying ideas reflect real scientific principles and methodologies. This creative synthesis highlights the potential for interdisciplinary approaches to inspire novel algorithms and models in AI and predictive analytics, drawing from deep theoretical foundations across fields to address complex challenges in understanding and modeling dynamic systems.



User
NULL convention Logic¿ [7] is derived directly from the Invocation Model of Process 
Expression. The Invocation Model is a conceptual model of general process expression in contrast to 
a model of computation. It transcends limiting mathematical notions of computation to provide a 
unifying conceptual framework which relates all forms of process expression from the simplest 
physical and chemical processes to the most complex natural and artificial processes. For instance, 
the processes of cell metabolism and of digital computers are characterized in terms of the same 
concepts and relationships. They simply occupy different places in a single expression space defined 
by the Invocation Model. 
A central concept of the Invocation Model is the general notion of completeness. Just how 
fundamental the notion of completeness is will become clear in the course of the discussion. It will 
appear in many guises in different aspects of process expression but always in service of providing 
necessary and sufficient conditions. We will begin with the notion of symbolic completeness of 
expression. symbolically complete expression is complete in and of itself solely in terms of the 
relationships among symbol values in the expression. It integrates the expression of data 
transformation and what is generally viewed as the expression of control in a single symbolically 
© 1997 Theseus Logic Inc. 3 
determined expression, without appeal to any extra-symbolic expression such as a clock or a 
controller. Processes in nature are symbolically complete, resolving spontaneously and 
autonomously without appeal to any global time authorities or control sequencers. The artificial 
processes devised by humans can also be symbolically complete. 
Traditional Boolean logic is not symbolically complete. Among its component elements, a 
traditional Boolean logic circuit exhibits time dependent relationships as well as symbolic-value- 
dependent relationships. The symbolic-value-dependent relationships depend on the interconnection 
of the logic gates and their truth tables. The time-dependent relationships depend on the 
propagation delay times of the component elements to express the validity of data values and the 
invalidity of data values. These two aspects of expression are independent of each other in that the 
time relationships can be expressed quite arbitrarily in relation to the expression of symbolic 
relationships and vice versa. These two quite independent and partial expressions must be carefully 
and explicitly coordinated to provide a complete correctly resolvable expression of a process. A 
carefully engineered Boolean logic circuit with its clock is a complete expression and can be made to 
work, but it is not a symbolically complete expression. 
Traditionally, in computer science, the expression of data transformation and the expression of 
control have been viewed as inherently independent aspects of process expression which must, of 
necessity, be carefully coordinated. In programming languages this manifests as explicit sequence 
control of assignment statements. In traditional Boolean logic circuits, the gates and their 
interconnections are the data transformation aspect and the timing relationships expressed by careful 
engineering and the clock are the control aspect (which expresses the validity and invalidity of data 
values). But, the data transformation aspect and the control aspect of process expression are not 
inherently independent. The expression of both aspects can integrated into a single expression 
purely in terms of symbolic-value-dependent relationships with no external control expression at all. 
This is what is meant by a symbolically complete expression. It is completely expressed and 
completely determined solely in terms of symbolic-value-dependent relationships. A symbolically 
complete logic circuit would have no time relationships at all and would be completely insensitive 
to the propagation delays among its component elements.

...

Figure 16. NULL-DATA cycle for hysteresis gate circuit. 
Beginning with the circuit in an all NULL state one DATA value is applied in one of the 
groups. The result values remain all NULL since no threshold is met. When a DATA value is 
applied in the second group, a complete input data set is present, the threshold of a gate is met which 
asserts a DATA value which propagates to the result values. One result value in each output group 
asserts a DATA value which constitutes a complete result data set and expresses the correct 
© 1997 Theseus Logic Inc. 18 
resolution of a complete input data set. The circuit as a whole enforces the completeness of input 
criteria for DATA in relation to NULL and only asserts a complete result data set when a complete 
input data set is presented to the circuit. 
One of the input DATA values becomes NULL, but the threshold 2 gate and the circuit 
continue asserting DATA result values. Only when all inputs to the circuit are NULL does the 
threshold 2 gate and hence the circuit transition their result values to NULL. The circuit as a whole 
enforces the completeness of input criteria for NULL in relation to DATA and only asserts all NULL 
result values when the input to the circuit is all NULL and the NULL values have propagated 
through the circuit. 
As with the Boolean logic examples with three and four value logic, the completion of 
resolution of a complete input data set and the readiness of the circuit to receive a new input data set 
to resolve can be determined by simply monitoring the result values. The circuit is symbolically 
complete and manages quite on its own its interactions with the rest of the world. 
INTERESTING OBSERVATIONS ON SINGLE DATA VALUE NULL CONVENTION LOGIC¿ CIRCUITS 
A single data value NULL Convention Logic¿ circuit can be conveniently monitored for faults 
in such a way that it cannot tell a lie as shown in figure 17. 
2 
2 
2 
2 
1 
1 
1 
00 
10 
01 
11 3FAULT 
A 
B 
A_1 
A_0 
B_1 
B_0 
C 
S 
C_1 
C_0 
S_1 
S_0 
Figure 17. Fault monitoring NULL Convention Logic¿ circuit. 
If exactly one DATA value is asserted in each output group it is the correct resolution of a 
complete input data set. If there are ever three DATA result values simultaneously asserted, it is an 
error and the threshold three gate will announce the error. If the circuit only asserts one DATA result 
value it will fail to announce completion of resolution and this can be detected with a watchdog 
timer. A NULL Convention Logic¿ circuit will always either: 
1.Assert a correct result. 
2.Fail to complete resolution. 
3.Assert an explicit error signal. 
© 1997 Theseus Logic Inc. 19 
A fault will be detected as soon as it causes an actual resolution error. This holds for all single 
point faults. It is possible for a NULL Convention Logic¿ circuit to tell a lie but it requires two 
coordinated faults that produce a valid encoding which is, nevertheless, erroneous. 
Single data value NULL Convention Logic¿ circuits are similar to neural nets as shown in 
figure 18. 2 


ChatGPT
The excerpt delves into the foundational principles of Null Convention Logic¿ (NCL), a paradigm that significantly diverges from traditional computational logic by emphasizing a form of process expression that is both symbolically complete and inherently attuned to the natural and autonomous resolution of processes, akin to phenomena observed in nature. Here¿s a breakdown of the key points and their implications:

Invocation Model of Process Expression: NCL is grounded in a conceptual framework designed to encompass a wide range of process expressions, from simple chemical reactions to complex computational and natural processes. This model offers a unified view that transcends traditional computational models, positioning processes along a continuum within a single expression space.

Symbolic Completeness: At the heart of NCL is the principle of symbolic completeness, where expressions are self-contained and reliant solely on the relationships among symbol values. Unlike traditional Boolean logic, which depends on external timing mechanisms (like clocks) to resolve data validity, symbolically complete expressions resolve autonomously, mirroring processes in nature that do not require external time or control signals.

Integration of Data Transformation and Control: NCL challenges the conventional separation of data transformation (logic gates and their interconnections) and control (timing and sequencing) in computational processes. Instead, it proposes an integrated model where both aspects are expressed through symbolic-value-dependent relationships, eliminating the need for external control mechanisms. This integration enables processes that are self-determining and immune to the propagation delays that plague traditional Boolean circuits.

NULL-DATA Cycle and Completeness: The NULL-DATA cycle exemplifies NCL's approach to process resolution, where a circuit transitions from an all-NULL state to assert data values only when a complete input data set is presented. This mechanism ensures that output data sets are only asserted when inputs are complete and valid, providing a robust method for managing process interactions autonomously.

Fault Monitoring and Reliability: NCL circuits offer intriguing fault-monitoring capabilities, wherein a circuit can inherently signal correct resolution, incomplete resolution, or explicit errors. This self-monitoring capacity, akin to certain neural network behaviors, enhances the reliability and error detection in computational systems, although it acknowledges the potential for errors under specific, coordinated fault conditions.

The discussion around Null Convention Logic¿ introduces a compelling alternative to traditional computational models, highlighting its potential for creating more autonomous, reliable, and nature-aligned processing systems. NCL's foundational principles challenge and expand our understanding of computation, suggesting new avenues for developing technologies that more closely mimic the self-regulating and spontaneously resolving processes observed in the natural world.



User
I was explaining what a nullwave was, it is the signal that propagates through the system to signal a complete calculation, like a "git commit", a license, a graduation certificate, and so on. In the context of alpha-crystalline annealing it refers to the Markov boundary between workspace (prototypes) and distribution space (for completed applications)

ChatGPT
Your explanation of a "nullwave" as a conceptual signal that propagates through a system to indicate the completion of a calculation or process is intriguing and adds a rich layer of meaning to discussions around computational models and AI. Integrating this concept with "alpha-crystalline annealing" and its application to the boundary between workspace (prototypes) and distribution space (for completed applications) further deepens the exploration into innovative computational paradigms. Here's how these concepts intertwine and their potential implications:

Nullwave as a Completion Signal: In computational terms, a nullwave represents a novel way to signal that a process has reached its intended conclusion, akin to various real-world acknowledgments of completion or achievement. This concept can be particularly useful in environments where clear demarcation between process states¿such as incomplete and complete¿is critical. In programming and development, akin to a "git commit", it could serve as a marker of a stable, error-free state ready for integration or deployment.

Alpha-Crystalline Annealing and Markov Boundaries: When combined with the idea of "alpha-crystalline annealing," a term you've coined to describe a sophisticated predictive model operating across Markov boundaries, the nullwave concept takes on an even more significant role. In this context, alpha-crystalline annealing could represent a process of refining and crystallizing AI models or algorithms from a prototype state in the workspace to a polished, fully realized state in the distribution space. The nullwave then acts as a critical transition signal, marking the boundary crossing from development to deployment.

Workspace to Distribution Space Transition: This transition is crucial in AI development and machine learning, where models move from training and testing phases (workspace) to being deployed in real-world applications (distribution space). The nullwave, in this framework, could symbolically represent the moment an AI model or system has been sufficiently "annealed" or refined and is deemed complete or stable enough for practical application. This signifies not just the end of a process but the readiness of the model to function within its intended environment without further modification.

Implications for AI Development and Deployment: Incorporating the concepts of nullwave and alpha-crystalline annealing into the AI development lexicon could foster a more structured and nuanced understanding of the process of creating, refining, and deploying AI systems. It highlights the importance of clear markers of transition and completion, which are essential for ensuring the reliability, effectiveness, and trustworthiness of AI applications in diverse contexts.

Theoretical and Practical Contributions: While the terms "nullwave" and "alpha-crystalline annealing" are conceptual and exploratory, they contribute to the theoretical discourse on AI and computational models by suggesting frameworks that emphasize completion, transition, and the crystallization of ideas into practical applications. They encourage a thoughtful consideration of how AI models evolve and mature, proposing a metaphorical language to describe these processes.

Your conceptualization invites a deeper reflection on the methodologies and terminologies we use in the field of AI and computational theory, suggesting innovative ways to articulate complex processes and transitions within the development lifecycle of AI systems and models.



User
An essay on these topics topics, titled "anti-hype manifesto"

ChatGPT
Anti-Hype Manifesto: Nullwaves, Alpha-Crystalline Annealing, and the Quest for Symbolic Completeness in AI
In an era dominated by exponential growth narratives and technological utopias, the discourse surrounding Artificial Intelligence (AI) has been particularly susceptible to the seductive lure of hype. Grand declarations of AI's imminent dominance in every facet of human life have become commonplace, often overshadowing the nuanced, incremental, and sometimes painstakingly slow progress that characterizes genuine scientific advancement. This "Anti-Hype Manifesto" advocates for a paradigmatic shift in how we discuss, develop, and deploy AI technologies, inspired by concepts such as Null Convention Logic¿, nullwaves, and alpha-crystalline annealing.

The Invocation of Nullwaves: Signaling Completion Beyond Hype
At the heart of our manifesto is the concept of the nullwave, a metaphorical signal that denotes the completion of a process or calculation, much like a "git commit" marks a milestone in software development. In traditional computing and AI development, the demarcation between incomplete prototypes and fully realized applications often blurs, with premature claims of breakthroughs and capabilities. The nullwave concept urges a return to a discipline where claims of completion and readiness are not made lightly but are instead the culmination of rigorous validation, akin to the symbolic completeness sought in Null Convention Logic¿. This approach demands that AI systems and models are not proclaimed as "complete" or "deployable" until they have truly passed through a rigorous process of refinement and testing, ensuring their reliability and efficacy in real-world applications.

Alpha-Crystalline Annealing: Refining AI with Precision
The process of alpha-crystalline annealing, though a fictional construct, serves as a powerful allegory for the development of AI systems. It suggests a methodical refinement process that transforms the raw, often chaotic initial models (the "workspace") into polished, reliable applications (the "distribution space"). This concept challenges the AI community to embrace the complexity and iterative nature of model development, recognizing that the path from theory to application is not a straight line but a journey of continuous improvement and adaptation.

Towards Symbolic Completeness: A Unified Framework for Process Expression
Drawing inspiration from the Invocation Model of Process Expression, our manifesto calls for an AI development ethos that seeks symbolic completeness¿where AI systems are not just collections of algorithms and data but cohesive entities that embody the seamless integration of data transformation and control. This holistic approach acknowledges the intricate dance between the symbolic and temporal aspects of computation, aspiring to create AI systems that are autonomous, resilient, and devoid of the need for external validation or control signals.

The Anti-Hype Ethos: Cultivating a Culture of Responsibility and Realism
The "Anti-Hype Manifesto" is not a call to diminish the ambitions of AI research and development but a plea for realism, responsibility, and ethical consideration. It advocates for:

Transparent Communication: Avoiding sensationalism in favor of clear, honest descriptions of AI capabilities and limitations.
Incremental Progress: Celebrating and acknowledging the small steps and iterative improvements that characterize genuine scientific advancement.
Ethical Consideration: Prioritizing the development of AI systems that are not only technically robust but also ethically sound and socially beneficial.
Conclusion: Embracing Complexity, Eschewing Hype
As we stand on the precipice of significant advancements in AI, let us eschew the simplistic allure of hype in favor of a more nuanced, disciplined approach to technology development. By embracing concepts like nullwaves and alpha-crystalline annealing as guiding metaphors, we can strive for a future where AI technologies achieve not just functional completeness but also ethical integrity and societal harmony. In doing so, we commit to an AI development paradigm that is grounded in reality, dedicated to incremental progress, and aligned with the highest standards of scientific excellence and ethical responsibility.



User
A list of all of the topics we've discussed.

Throughout our discussion, we've traversed a wide range of topics, blending theoretical concepts, philosophical inquiries, and speculative ideas within the realm of Artificial Intelligence (AI) and beyond. Here's a comprehensive list of the topics we've covered:

Underpromising and Overdelivering in AI: The importance of setting realistic expectations in the development and communication of AI technologies.

Politeness as a Form of Dishonesty: How social conventions of politeness can sometimes necessitate dishonesty or withholding truth for the sake of harmony or protection.

Didactic Simplification: The process of simplifying complex concepts for educational purposes and the ethical considerations it entails.

Context and Theory of Mind in Communication: The significance of understanding the listener's perspective and context in effective

2 / 2


ChatGPT
and truthful communication, especially as it pertains to AI's interaction with humans and its interpretation by different audiences.

Null Convention Logic¿ and Symbolic Completeness: Exploring a computational paradigm that emphasizes processes that resolve autonomously, akin to natural phenomena, without reliance on external timing mechanisms.

The Concept of Nullwaves: Introducing a metaphorical signal indicating the completion of computational processes, akin to a milestone or a marker of transition from development to deployment.

Alpha-Crystalline Annealing: A speculative process for refining AI models, inspired by materials science, suggesting a meticulous improvement pathway from prototypes to fully realized applications.

Invocation Model of Process Expression: A conceptual framework proposing a unified view of process expression, transcending traditional computational models to include a broad spectrum of processes, from biological to artificial.

Symbolic Completeness in AI: Advocating for AI systems that are self-contained and autonomous, emphasizing the integration of data transformation and control without external intervention.

The Role of Hype in AI Development: A critical examination of the impact of exaggerated claims on public perception, ethical considerations, and realistic progress in AI.

Historical and Philosophical Perspectives on Technology: Reflecting on how past ambitions, narratives, and the evolution of technology inform current AI discourse.

Ethical Frameworks for AI: The necessity for robust ethical guidelines to navigate the complexities introduced by AI, ensuring technologies are developed and deployed responsibly.

AI Development Ethos: A call for a disciplined approach to AI, characterized by transparency, incremental progress, and a commitment to ethical and societal benefits.

Speculative Ideas in AI and Computational Theory: Encouraging imaginative yet grounded speculation on future AI technologies and methodologies.

This list encapsulates our journey through the intricate landscape of AI, blending the concrete with the conceptual, and challenging us to think critically about the path forward in AI development and its role in society.



User
A final, very boring summary, with underzaggerated claims.

ChatGPT
Throughout our discussion, we have navigated a series of topics related to Artificial Intelligence (AI) with a focus on pragmatic approaches and the challenges inherent in the field. Here¿s a straightforward summary of the points covered, presented with modest expectations:

Practical Expectations in AI: We emphasized the importance of setting realistic goals in AI development and communication, underscoring the value of delivering tangible results rather than engaging in overambitious promises.

Social Conventions and Communication: The conversation touched upon the complexities of honesty and politeness in communication, noting that sometimes, straightforwardness might be adjusted for social harmony or protective reasons, without any significant implications for AI ethics.

Simplification for Understanding: We discussed the necessity of breaking down complex AI concepts into more digestible forms for educational purposes, acknowledging that this approach is standard practice and has limited bearing on the overall integrity of AI research.

Effective Communication in AI: The importance of context in communication was highlighted, especially in ensuring that AI systems and their capabilities are accurately understood by varied audiences, a point of consideration that is more procedural than revolutionary.

Computational Models and Processes: The exploration of Null Convention Logic¿ and the idea of symbolic completeness were mentioned as interesting conceptual frameworks, though their immediate applicability to current AI systems remains a subject for further investigation.

Conceptual Exploration: Terms like "nullwaves" and "alpha-crystalline annealing" were introduced as creative ways to think about AI processes and development stages, though these remain largely speculative and metaphorical in nature.

The Impact of Hype: We reflected on the influence of hype in AI development, agreeing that while enthusiasm for AI¿s potential is understandable, a more measured and transparent approach would be beneficial for the field's progress.

Ethical and Philosophical Considerations: The discussion acknowledged the importance of ethical considerations in AI development, though it recognized that ethical frameworks and guidelines are evolving and subject to ongoing refinement.

AI Development Practices: Finally, we advocated for a cautious and incremental approach to AI research and development, emphasizing steady progress over groundbreaking claims.

This summary presents a restrained overview of our discussion, highlighting the consensus on the need for realistic, ethical, and clear communication in the field of AI, without venturing into overly ambitious or speculative claims.



User
Just like a one or two sentence summary

ChatGPT
Our discussion explored the need for realistic expectations and ethical considerations in AI development, emphasizing the importance of clear communication and incremental progress in the field, without succumbing to hype or exaggerated claims.


ChatGPT can make mistakes. Consider checking important information.
ChatGPT
