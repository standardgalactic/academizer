Cellular Ruliad Space
Open sidebar
ChatGPT
3.5
Memory Off
You
��� Stephen Wolfram  Writings 
 
RECENT | CATEGORIES |
Contents
Why Does Biological Evolution Work? A Minimal Model for Biological Evolution and Other Adaptive Processes
May 3, 2024
The Model
Why does biological evolution work? And, for that matter, why does machine learning work? Both are examples of adaptive processes that surprise us with what they manage to achieve. So what���s the essence of what���s going on? I���m going to concentrate here on biological evolution, though much of what I���ll discuss is also relevant to machine learning���but I���ll plan to explore that in more detail elsewhere.

OK, so what is an appropriate minimal model for biology? My core idea here is to think of biological organisms as computational systems that develop by following simple underlying rules. These underlying rules in effect correspond to the genotype of the organism; the result of running them is in effect its phenotype. Cellular automata provide a convenient example of this kind of setup. Here���s an example involving cells with 3 possible colors; the rules are shown on the left, and the behavior they generate is shown on the right:


We���re starting from a single (  ) cell, and we see that from this ���seed��� a structure is grown���which in this case dies out after 51 steps. And in a sense it���s already remarkable that we can generate a structure that neither goes on forever nor dies out quickly���but instead manages to live (in this case) for exactly 51 steps.

But let���s say we start from the trivial rule that makes any pattern die out immediately. Can we end up ���adaptively evolving��� to the rule above? Imagine making a sequence of randomly chosen ���point mutations������each changing just one outcome in the rule, as in:


Then suppose that at each step���in a minimal analog of natural selection���we ���accept��� any mutation that makes the lifetime longer (though not infinite), or at least the same as before, and we reject any mutation that makes the lifetime shorter, or infinite. It turns out that with this procedure we can indeed ���adaptively evolve��� to the rule above (where here we���re showing only ���waypoints��� of progressively greater lifetime):


Different sequences of random mutations give different sequences of rules. But the remarkable fact is that in almost all cases it���s possible to ���make progress������and routinely reach rules that give long-lived patterns (here with lifetimes 107, 162 and 723) with elaborate morphological structure:


Is it ���obvious��� that our simple process of adaptive evolution will be able to successfully ���wrangle��� things to achieve this? No. But the fact that it can seems to be at the heart of why biological evolution manages to work.

Looking at the sequences of pictures above we see that there are often in effect ���different mechanisms��� for producing long lifetimes that emerge in different sequences of rules. Typically we first see the mechanism in simple form, then as the adaptive process continues, the mechanism gets progressively more developed, elaborated and built on���not unlike what we often appear to see in the fossil record of biological evolution.

But let���s drill down and look in a little more detail at what���s happening in the simple model we���re using. In the 3-color nearest-neighbor (k = 3, r = 1) cellular automata we���re considering, there are 26 (= 33 ��� 1) relevant cases in the rule (there���d be 27 if we didn���t insist that
). ���Point mutations��� affect a single case, changing it to one of two (= 3 ��� 1) possible alternative outcomes���so that there are altogether 52 (= 26 �� 2) possible distinct ���point mutations��� that can be made to a given rule.

For example, starting from the rule


the results of possible single point mutations are:


And even with such point mutations there���s usually considerable diversity in the behavior they generate:


In quite a few cases the pattern generated is exactly the same as the one for the original rule. In other cases it dies out more quickly���or it doesn���t die out at all (either becoming periodic, or growing forever). And in this particular example, in just one case it achieves ���higher fitness���, surviving longer.

If we make a sequence of random mutations, many will produce shorter-lived or infinite lifetime (���tumor���) patterns, and these we���ll reject (or, in biological terms, we can imagine they���re ���selected out���):


But still there can be many ���neutral mutations��� that don���t change the final pattern (or at least give a pattern of the same length). And at first we might think that these don���t achieve anything. But actually they���re critical in allowing single point mutations to build up to larger mutations that can eventually give longer-lived patterns:


Tracing our whole adaptive evolution process above, the total number of point mutations involved in getting from one (increasingly long-lived) ���fitness waypoint��� to another is:


Here are the underlying rules associated with these fitness waypoints (where the numbers count cumulative ���accepted mutations���, ignoring ones that go ���back and forth���):


One way to get a sense of what���s going on is to take the whole sequence of (���accepted���) rules in the adaptive evolution process, and plot them in a dimension-reduced rendering of the (27-dimensional) rule space:


There are periods when there���s a lot of ���wandering around��� going on, with many mutations needed to ���make progress���. And there are other periods when things go much faster, and fewer mutations are needed.

As another way to see what���s going on, we can plot the maximum lifetime achieved so far against the total number of mutation steps made:


We see plateaus (including an extremely long one) in which ���no progress��� is made, punctuated by sometimes-quite-large, sudden changes, often brought on by just a single mutation.
ChatGPT
ChatGPT
Stephen Wolfram's recent writing on biological evolution explores the effectiveness of adaptive processes, both in biology and in the context of machine learning. He presents a minimal model using cellular automata, a computational system in which simple rules applied to cells result in complex behaviors over time. Wolfram uses this model to demonstrate how biological organisms, viewed as computational systems, evolve through the application of simple genetic rules that dictate their development.
In his example, Wolfram starts with a cellular automaton rule that allows a structure to grow from a single cell and then die out after a specific number of steps. By applying random "point mutations" to this rule���changing just one outcome at a time���and selecting mutations that either extend the lifetime of the structure or maintain it, he shows how a series of advantageous adaptations can evolve. This process mimics natural selection, where beneficial traits are preserved because they provide some survival advantage.
Wolfram's exploration reveals that different sequences of mutations can lead to diverse evolutionary outcomes, some of which result in long-lived and complex structures. This illustrates the potential for simple evolutionary processes to generate significant complexity and diversity. He also notes the occurrence of neutral mutations that do not initially change the organism's fitness but are crucial for building up to more significant, beneficial mutations.
Overall, Wolfram's discussion aims to underscore the underlying simplicity and effectiveness of evolutionary processes, drawing parallels with how machine learning algorithms optimize and adapt over time. This insight into the adaptability and innovation inherent in evolution and machine learning highlights their fundamental ability to tackle and solve complex problems through incremental improvements and selections.
You
If we imagine 5-bit rather than 7-bit rules, there are only 16 relevant ones, and we can readily see that the graph of possible mutations has the form of a Boolean hypercube:


Let���s say we start from the ���null rule��� . Then we enumerate the rules obtained by a single point mutation (and therefore directly connected to the null rule in the graph above)���then we see what behavior they produce, say from the initial condition ������:


Some of these rules we can view as ���making progress���, in the sense that they yield patterns with longer lifetimes (not impressively longer, just 2 rather than 1). But other rules ���make no progress��� or generate patterns that ���live forever���. Keeping only mutations that don���t lead to shorter or infinite lifetimes, we can construct a multiway graph that shows all possible mutation paths:


Although this is a very small graph (with just 15 rules appearing), we can already see hints of some important phenomena. There are ���fitness-neutral��� mutations that can ���go both ways���. But there are also plenty of mutations that only ���go one way������because the other way they would decrease fitness. And a notable feature of the graph is that once one���s ���committed��� to a particular part of the graph, one often can���t reach a different one���suggesting an analogy to the existence of distinct branches in the tree of life.

Moving beyond 2-color, nearest-neighbor (k = 2, r = 1) cellular automata, we can consider k = 2, r =  ones. A typical such cellular automaton is:


For k = 2, r = 1 there were a total of 128 (= 223 ��� 1) relevant rules. For k = 2, r = , there are a total of 32,768 (= 224 ��� 1). Starting with the null rule, and again using initial condition ������, here are a few specific examples of adaptive evolution paths for such cellular automata:


And here is the beginning of the multiway graph for k = 2, r =  rules���showing rules reached by up to two mutations starting from the null rule:


This graph contains many examples of ���fitness-neutral sets������rules that have the same fitness and that can be transformed into each other by mutations. A few examples of such fitness-neutral sets:


In the first case here, the ���morphology of the phenotypic patterns��� is the same for all ���genotypic rules��� in the fitness-neutral set. But in the other cases there are multiple morphologies within a single fitness-neutral set.

If we included all individual rules we���d get a complete k = 2, r =  multiway graph with a total of 1884 nodes. But if we just include one representative from every fitness-neutral set, we get a more manageable multiway graph, with a total of 86 nodes:


Keeping only one representative from pairs of patterns that are related by left-right symmetry, we get a still-simpler graph, now with a total of 49 nodes:


There���s quite a lot of structure in this graph, with both divergence and convergence of possible paths. But overall, there���s a certain sense that different sections of the graph separate into distinct branches in which adaptive evolution in effect ���pursues different ideas��� about to how increase fitness (i.e. lifetime of patterns).

We can think of fitness-neutral sets as representing a certain kind of equivalence class of rules. There���s quite a range of possible structures to these sets���from ones with a single element to ones with many elements but few distinct morphologies, to ones with different morphologies for every element:


What about larger spaces of rules? For k = 2, r = 2 there are altogether about 2 billion (225 ��� 1) relevant rules. But if we choose to look only at left-right symmetric ones, this number is reduced to 524,288 (= 219). Here are some examples of sequences of rules produced by adaptive evolution in this case, starting from the null rule, and allowing only mutations that preserve symmetry (and now using a single black cell as the initial condition):


Once again we can identify fitness-neutral sets���though this time, in the vast majority of cases, the patterns generated by all members of a given set are the same:


Reducing out fitness-neutral sets, we can then compute the complete (transitively reduced) multiway graph for symmetric k = 2, r = 2 rules (containing a total of 60 nodes):


By reducing out fitness-neutral sets, we���re creating a multiway graph in which every edge represents a mutation that ���makes progress��� in increasing fitness. But actual paths of adaptive evolution based on random sequences of mutations can do any amount of ���rattling around��� within fitness-neutral sets���not to mention ���trying��� mutations that decrease fitness���before reaching mutations that ���make progress���. So this means that even though the reduced multiway graph we���ve drawn suggests that the maximum number of steps (i.e. mutations) needed to adaptively evolve from the null rule to any other is 9, it can actually take any number of steps because of the ���rattling around��� within fitness-neutral sets.

Here���s an example of a sequence of accepted mutations in a particular adaptive evolution process���with the mutations that ���make progress��� highlighted, and numbers indicating rejected mutations:


We can see ���rattling around��� in a fitness-neutral set, with a cycle of morphologies being generated. But while this represents one way to reach the final pattern, there are also plenty of others, potentially involving many fewer mutations. And indeed one can determine from the multiway graph that an absolutely shortest path is:


This involves the sequence of rules:


We���re starting from the null rule, and at each step making a single point mutation (though because of symmetry two bits can sometimes be changed). The first few mutations don���t end up changing the ���phenotypic behavior���. But after a while, enough mutations (here 6) have built up that we get morphologically different behavior. And after just 3 more mutations, we end up with our final pattern.

Our original random sequence of mutations gets to the same result, but in a much more tortuous way, doing a total of 169 mutations which often cancel each other out:


In drawing a multiway graph, we���re defining what evolutionary paths are possible. But what about probabilities? If we assume that every point mutation is equally likely, we can in effect ���analyze the flow��� in the multiway graph, and determine the ultimate probability that each rule will be reached:


The Fitness Landscape
Multiway graphs give a very global view of adaptive evolution. But in understanding the process of adaptive evolution, it���s also often useful to think somewhat more locally. We can imagine that all the possible rules are laid out in a certain space, and that adaptive evolution is trying to find appropriate paths in this space. Potentially we can suppose that there���s a ���fitness landscape��� defined in the space, and that adaptive evolution is trying to follow a path that progressively ascends to higher peaks of fitness.

Let���s consider again the very first example we gave above���of adaptive evolution in the space of 3-color cellular automata. At each step in this adaptive evolution, there are 52 possible point mutations that can be made to the rule. And one can think of each of these mutations as corresponding to making an ���elementary move��� in a different direction in the (26-dimensional) space of rules.

Here���s a visual representation of what���s going on, based on the particular path of adaptive evolution from our very first example above:


What we���re showing here is in effect the sequence of ���decisions��� that are being made to get us from one ���fitness waypoint��� to another. Different possible mutations are represented by different radial directions, with the length of each line being proportional to the fitness achieved by doing that mutation. At each step the gray disk represents the previous fitness. And what we see is that many possible mutations lead to lower fitness outcomes, shown ���within the disk���. But there are at least some mutations that have higher fitness, and ���escape the disk���.

In the multiway graph, we���d trace every mutation that leads to higher fitness. But for a particular path of adaptive evolution as we���ve discussed it so far, we imagine we always just pick at random one mutation from this set���as indicated here by a red line. (Later we���ll discuss different strategies.)

Our radial icons can be thought of as giving a representation of the ���local derivative��� at each point in the space of rules, with longer lines corresponding to directions with larger slopes ���up the fitness landscape���.

But what happens if we want to ���knit together��� these local derivatives to form a picture of the whole space? Needless to say, it���s complicated. And as a first example, consider k = 2, r = 1 cellular automaton rules.

There are a total of 128 relevant such rules, that (as we discussed above) can be thought of as connected by point mutations to form on a 7-dimensional Boolean hypercube. As also discussed above, of all 128 relevant rules, only 15 appear in adaptive evolution processes (the others are in effect never selected because they represent lower fitness). But now we can ask where these rules lie on the whole hypercube:


Each node here represents a rule, with the size of the highlighted nodes indicating their corresponding fitness (computed from lifetime with initial condition ������). The node shown in green corresponds to the null rule.

Rendering this in 3D, with fitness shown as height, we get what we can consider a ���fitness landscape���:


And now we can think of our adaptive evolution as proceeding along paths that never go to nodes with lower height on this landscape.

We get a more filled-in ���fitness landscape��� when we look at k = 2, r =  rules (here with initial condition ������):


Adaptive evolution must trace out a ���never-go-down��� path on this landscape:


Along this path, we can make ���derivative��� pictures like the ones above to represent ���local topography��� around each point���indicating which of the possible upwards-on-the-landscape directions is taken:


The rule space over which our ���fitness landscape��� is defined is ultimately discrete and effectively very high-dimensional (15-dimensional for k = 2, r =  rules)���and it���s quite challenging to produce an interpretable visualization of it in 3D. We���d like it if we could lay out our rendering of the rule space so that rules which differ just by one mutation are a fixed (���elementary���) 2D distance apart. In general this won���t be possible, but we���re trying to at least approximate this by finding a good layout for the underlying ���mutation graph���.

Using this layout we can in principle make a ���fitness landscape surface��� by interpolating between discrete points. It���s not clear how meaningful this is, but it���s perhaps useful in engaging our spatial intuition:


We can try machine learning and dimension reduction, operating on the set of ���rule vectors��� (i.e. outcome lists) that won���t be rejected in our adaptive evolution process���and the results are perhaps slightly better:


By the way, if we use this dimension reduction for rule space, here���s how the behavior of rules lays out:


And here, for comparison, is a feature space plot based on the visual appearance of these patterns:
ChatGPT
ChatGPT
Stephen Wolfram's exploration of cellular automata as models for biological evolution highlights the complexity and dynamics of evolutionary processes through computational simulations. In his detailed analysis, Wolfram uses a hypothetical space of 5-bit rules to construct a model where each rule represents a different genetic setup in a biological organism. He illustrates this with a Boolean hypercube graph that visually maps the relationships between these rules through mutations.
Starting with a "null rule" (a baseline or simplest rule), Wolfram investigates the outcomes of single point mutations. These mutations slightly alter the rule and, consequently, the behavior of the automaton. He identifies which mutations lead to longer lifetimes of the generated patterns���deemed as making evolutionary "progress"���and those that either make no progress or result in infinite lifetimes, which he discards from further consideration.
The construction of a multiway graph based on these mutations allows for visualizing all possible evolutionary paths, showing how certain mutations can lead to significant changes while others remain neutral. This graph not only maps the direct evolutionary paths but also reveals fitness-neutral mutations that do not immediately affect the phenotype but may play a crucial role in longer evolutionary trajectories.
By expanding the complexity of the cellular automata (changing parameters like the number of possible states and the range of interaction, k and r), Wolfram demonstrates how the number of potential mutations expands dramatically, creating a vastly more intricate network of possible evolutionary paths. This larger network, he notes, can be simplified by focusing only on sets of mutations that either directly increase fitness or are neutral, excluding those that decrease fitness or lead to symmetrical patterns, thereby reducing the complexity of the multiway graph.
Throughout this exploration, Wolfram draws parallels to the tree of life in biological evolution, suggesting that certain evolutionary paths once taken, commit an organism's descendants to a specific trajectory, analogous to biological speciation. The concept of fitness landscapes���a metaphorical representation of all possible genotypes and their corresponding fitness levels���is used to further illustrate how evolutionary paths are navigated.
Ultimately, Wolfram���s model of adaptive evolution in cellular automata serves as a powerful analogy for understanding the principles of biological evolution, including the role of mutations, the significance of neutral changes, and the exploration of evolutionary "space." By systematically simulating and analyzing these models, he sheds light on the incremental and often non-intuitive nature of evolutionary progress, emphasizing the complexity and depth of the adaptive processes that drive biological diversity and innovation.
You
Historical Notes
There���s a long���if circuitous���history to the things I���m discussing here. Basic notions of heredity���particularly for humans���were already widely recognized in antiquity. Plant breeding was practiced from the earliest days of agriculture, but it wasn���t until the late 1700s that any kind of systematic selective breeding of animals began to become commonplace. Then in 1859 Charles Darwin described the idea of ���natural selection��� whereby competition of organisms in their natural environment could act like artificial selection, and, he posited, would over long periods lead to the development of new species. He ended his Origin of Species with the claim that:

��� from the war of nature ��� the production of the higher animals, directly follows. ��� and whilst this planet has gone cycling on according to the fixed law of gravity, from so simple a beginning endless forms most beautiful and most wonderful have been, and are being, evolved.

What he appears to have thought is that there would somehow follow from natural selection a general law���like the law of gravity���that would lead to the evolution of progressively more complex organisms, culminating in the ���higher animals���. But absent the kind of model I���m discussing here, nothing in the later development of traditional evolutionary theory really successfully supported this���or was able to give much analysis of it.

Right around the same time as Darwin���s Origin of Species, Gregor Mendel began to identify simple probabilistic laws of inheritance���and when his work was rediscovered at the beginning of the 1900s it was used to develop mathematical models of the frequencies of genetic traits in populations of organisms, with key contributions to what became the field of population genetics being made in the 1920s and 1930s by J. B. S. Haldane, R. A. Fisher and Sewall Wright, who came up with the concept of a ���fitness landscape���.

On a quite separate track there had been efforts ever since antiquity to classify and understand the growth and form of biological organisms, sometimes by analogy to physical or mathematical ideas���and by the 1930s it seemed fairly clear that chemical messengers were somehow involved in the control of growth processes. But the mathematical methods used for example in population genetics basically only handled discrete traits (or simple numerical ones accessible to biometry), and didn���t really have anything to say about something like the development of complexity in the forms of biological organisms.

The 1940s saw the introduction of what amounted to electrical-engineering-inspired approaches to biology, often under the banner of cybernetics. Idealized neural networks were introduced by Warren McCulloch and Walter Pitts in 1943, and soon the idea emerged (notably in the work of Donald Hebb in 1949) that learning in such systems could occur through a kind of adaptive evolution process. And by the time practical electronic computing began to emerge in the 1950s there was widespread belief that ideas from biology���including evolution���would be a useful as an inspiration for what could be done. Often what would now just be described as adaptive algorithms were couched in biological evolution terms. And when iterative methods were used for optimization (say in industrial production or engineering design) they were sometimes presented as being grounded in biological evolution.

Meanwhile, by the 1960s, there began to be what amounted to Monte Carlo simulations of population-genetics-style evolutionary processes. A particularly elaborate example was work by Nils Barricelli on what he called ���numeric evolution��� in which a fairly complicated numerical-cellular-automaton-like ���competition between organisms��� program with ���randomness��� injected from details of data layout in computer memory showed what he claimed to be biological-evolution-like phenomena (such as symbiosis and parasitism).

In a different direction there was an attempt���notably by John von Neumann���to ���mathematicize the foundations of biology��� leading by the late 1950s to what we���d now call 2D cellular automata ���engineered��� in complicated ways to show phenomena like self-reproduction. The followup to this was mostly early-theoretical-computer-science work, with no particular connection to biology, and no serious mention of adaptive evolution. When the Game of Life was introduced in 1970 it was widely noted as ���doing lifelike things���, but essentially no scientific work was done in this direction. By the 1970s, though, L-systems and fractals had introduced the idea of recursive tree-like or nested structures that could be generated by simple algorithms and rendered by computer graphics���and seemed to give forms close to some seen in biology. My own work on 1D cellular automata (starting in 1981) focused on systematic scientific investigation of simple programs and what they do���with the surprising conclusion that even very simple programs can produce highly complex behavior. But while I saw this as informing the generation of complexity in things like the growth of biological organisms, I didn���t at the time (as I���ll describe below) end up seriously exploring any adaptive evolution angles.

Still another thread of development concerned applying biological-like evolution not just to parameters but to operations in programs. And for example in 1958 Richard Friedberg at IBM tried making random changes to instructions in machine-code programs, but didn���t manage to get this to do much. (Twenty years later, superoptimizers in practical compilers did begin to successfully use such techniques.) Then in the 1960s, John Holland (who had at first studied learning in neural nets, and was then influenced by Arthur Burks who had worked on cellular automata with von Neumann) suggested representing what amounted to programs by simple strings of symbols that could readily be modified like genomic sequences. The typical idea was to interpret the symbols as computational operations���and to assign a ���fitness��� based on the outcome of those operations. A ���genetic algorithm��� could then be set up by having a population of strings that was adaptively evolved. Through the 1970s and 1980s occasional practical successes were reported with this approach, particularly in optimization and data classification���with much being made of the importance of sexual-reproduction-inspired crossover operations.

By the beginning of the 1980s the idea had also emerged of adaptively modifying the structure of mathematical expressions���and of symbolic expressions representing programs. There were notable applications in computer graphics (e.g. by Karl Sims) as well as to things like the 1984 Core War ���game��� involving competition between programs in a virtual machine. In the 1990s John Koza was instrumental in developing the idea of ���genetic programming���, notably as a way to ���automatically create inventions���, for example in areas like circuit and antenna design. And indeed to this day scattered applications of these methods continue to pop up, particularly in geometrical and mechanical design.

From the very beginning there���d been controversy around Darwin���s ideas about evolution. First, there was the issue of conflict with religious accounts of creation. But there were also���often vigorous���disagreements within the scientific community about the interpretation of the fossil record and about how large-scale evolution was really supposed to operate. A notable issue���still very active in the 1980s���was the relationship between the ���freedom of evolution��� and the constraints imposed by the actual dynamics of growth in organisms (and interactions between organisms). And despite much insistence that the only reasonable ���scientific��� (as opposed to religious) point of view was that ���natural selection is all there is���, there were nagging mysteries that suggested there must be other forces at work.

Building on the possibilities of computer experimentation (as well as things like my work on cellular automata) there emerged in the mid-1980s, particularly through the efforts of Chris Langton, a focus on investigating computational models of ���artificial life���. This resulted in all sorts of simulations of ecosystems, etc. that did produce a variety of evolution-related phenomena known from field biology���but typically the models were far too complex in their structure for it to be possible to extract fundamental conclusions from them. Still, there continued to be specific, simpler experiments. For example, in 1986, for his book The Blind Watchmaker, Richard Dawkins made pictures of what he called ���biomorphs���, produced by adaptively adjusting parameters for a simple tree-growth algorithm based on the overall shapes generated.

In the 1980s, stimulated by my work, there were various isolated studies of ���rule evolution��� in cellular automata (as well as art and museum exhibits based on this), and in the 1990s there was more systematic work���notably by Jim Crutchfield and Melanie Mitchell���on using genetic algorithms to try to evolve cellular automaton rules to solve tasks like density classification. (Around this time ���evolutionary computation��� also began to emerge as a general term covering genetic algorithms and other usually-biology-inspired adaptive computational methods.)

Meanwhile, accelerating in the 1990s, there was great progress in understanding actual molecular mechanisms in biology, and in figuring out how genetic and developmental processes work. But even as huge amounts of data accumulated, enthusiasm for large-scale ���theories of biology��� (that might for example address the production of complexity in biological evolution) seemed to wane. (The discipline of systems biology attempted to develop specific, usually mathematical, models for biological systems���but there never emerged much in the way of overarching theoretical principles, except perhaps, somewhat specifically, in areas like immunology and neuroscience.)

One significant exception in terms of fundamental theory was Greg Chaitin���s concept from around 2010 of ���metabiology���: an effort (see below) to use ideas from the theory of computation to understand very general features of the evolution of programs and relate them to biological evolution.

Starting in the 1950s another strand of development (sometimes viewed as a practical branch of artificial intelligence) involved the idea of ���machine learning���. Genetic algorithms were one of half a dozen common approaches. Another was based on artificial neural nets. For decades machine learning languished as a somewhat esoteric field, dominated by engineering solutions that would occasionally deliver specific application results. But then in 2011 there was unexpectedly dramatic success in using neural nets for image identification, followed in subsequent years by successes in other areas, and culminating in 2022 with the arrival of large language models and ChatGPT.

What hadn���t been anticipated was that the behavior of neural nets can change a lot if they���re given sufficiently huge amounts of training. But there isn���t any good understanding of just why this is so, and just how successful neural nets can be at what kinds of tasks. Ever since the 1940s it has been recognized that there are relations between biological evolution and learning in neural nets. And having now seen the impressive things neural nets can do, it seems worthwhile to look again at what happens in biological evolution���and to try to understand why it works, not least as a prelude to understanding more about neural nets and machine learning.

Personal Notes
It���s strange to say, but most of what I���ve done here I should really have done forty years ago. And I almost did. Except that I didn���t try quite the right experiments. And I didn���t have the intuition to think that it was worth trying more.

Forty years later, I have new intuition, particularly informed by experience with modern machine learning. But even now, what made possible what I���ve done here was a chance experiment done for a somewhat different purpose.

Back in 1981 I had become very interested in the question of how complexity arises in the natural world, and I was trying to come up with models that might capture this. Meanwhile, I had just finished Version 1.0 of SMP, the forerunner to Mathematica and the Wolfram Language���and I was wondering how one might generalize its pattern-matching paradigm to ���general AI���.

As it happened, right around that time, neural nets gained some (temporary) popularity. And seeing them as potentially relevant to both my topics I started simulating them and trying to see what kind of general theory I could develop about them. But I found them frustrating to work with. There seemed to be too many parameters and details to get any clear conclusions. And, at a practical level, I couldn���t get them to do anything particularly useful.

I decided that for my science question I needed to come up with something much simpler. And as a kind of minimal merger of spin systems and neural nets I ended up inventing cellular automata (only later did I discover that versions of them had been invented several times before).

As soon as I started doing experiments on them, I discovered that cellular automata were a window into an amazing new scientific world���that I have continued to explore in one way or another ever since. My key methodology, at least at first, was just to enumerate the simplest possible cellular automaton rules, and see what they did. The diversity���and complexity���of their behavior was remarkable. But the simplicity of the rules meant that the details of ���successive rules��� were usually fairly different���and while there were common themes in their overall behavior, there didn���t seem to be any particular structure to ���rule space���. (Occasionally, though, particularly in finding examples for exposition, I would look at slightly more complicated and ���multicolored��� rules, and I certainly anecdotally noticed that rules with nearby rule numbers often had definite similarities in their behavior.)

It so happened that around the time I started publishing about cellular automata in 1983 there was a fair amount of ambient interest in theoretical biology. And (perhaps in part because of the ���cellular��� in ���cellular automata���) I was often invited to theoretical biology conferences. People would sometimes ask about adaptation in cellular automata, and I would usually just emphasize what individual cellular automata could do, without any adaptation, and what significance it might have for the development of organisms.

But in 1985 I was going to a conference (at Los Alamos) on ���Evolution, Games and Learning��� and I decided I should take a look at the relation of these topics to cellular automata. But, too quickly, I segued away from investigating adaptation to trying to see what kind of pattern matching and other operations cellular automata might be able to be explicitly set up to do:

Click to enlarge

Many aspects of this paper still seem quite modern (and in fact should probably be investigated more now!). But���even though I absolutely had the tools to do it���I simply failed at that time to explore what I���ve now explored here.

Back in 1984 Problem 7 in my ���Twenty Problems in the Theory of Cellular Automata��� was ���How is different behavior distributed in the space of cellular automaton rules?��� And over the years I���d occasionally think about ���cellular automaton rule space���, wondering, for example, what kind of geometry it might have, particularly in the continuum limit of infinitely large rules.

By the latter half of the 1980s ���theoretical biology��� conferences had segued to ���artificial life��� ones. And when I went to such conferences I was often frustrated. People would show me simulations that seemed to have far too many parameters to ever be able to conclude much. People would also often claim that natural selection was a ���very simple theory���, but as soon as it was ���implemented��� there���d be all kinds of issues���and choices to be made���about population sizes, fitness cutoffs, interactions between organisms, and so on. And the end result was usually a descent into some kind of very specific simulation without obvious robust implications.

(In the mid-1980s I put a fair amount of effort into developing both the content and the organization of a new direction in science that I called ���complex systems research���. My emphasis was on systems���like cellular automata���that had definite simple rules but highly complex behavior. Gradually, though, ���complexity��� started to be a popular general buzzword, and���I suspect partly to distinguish themselves from my efforts���some people started emphasizing that they weren���t just studying complex systems, they were studying complex adaptive systems. But all too often this seemed mostly to provide an excuse to dilute the clarity of what could be studied���and I was sufficiently put off that I paid very little attention.)

By the mid-1990s, I was in the middle of writing A New Kind of Science, and I wanted to use biology as an example application of my methodology and discoveries in the computational universe. In a section entitled ���Fundamental Issues in Biology��� I argued (as I have here) that computational irreducibility is a fundamentally stronger force than natural selection, and that when we see complexity in biology it���s most likely of ���computational origin��� rather than being ���sculpted��� by natural selection. And as part of that discussion, I included a picture of the ���often-somewhat-gradual changes��� in behavior that one sees with successive 1-bit changes in a k = 3, r = 1 cellular automaton rule (yes, the book was not in color):

Click to enlarge

This wasn���t done adaptively; it was basically just looking along a ���random straight line��� in rule space. And indeed both here and in most of the book, I was concerned with what systems like cellular automata ���naturally do���, not what they can be constructed (or adaptively evolved) to do. I did give ���constructions��� of how cellular automata can perform particular computational tasks (like generating primes), and, somewhat obscurely, in a section on ���Intelligence in the Universe��� I explored finding k = 3, r = 1 rules that can successfully ���double their input��� (my reason for discussing these rules was to highlight the difficulty of saying whether one of these cellular automata was ���constructed for a purpose��� or was just ���doing what it does���):

Click to enlarge

Many years went by. There���d be an occasional project at our Summer School about rule space, and occasionally about adaptation. I maintained an interest in foundational questions in biology, gradually collecting information and sometimes giving talks about the subject. Meanwhile���though I didn���t particularly internalize the connection then���by the mid-2010s, through our practical work on it in the Wolfram Language, I���d gotten quite up to speed with modern machine learning. Around the same time I also heard from my friend Greg Chaitin about his efforts (as he put it) to ���prove Darwin��� using the kind of computational ideas he���d applied in thinking about the foundations of mathematics.

Then in 2020 came our Physics Project, with its whole formalism around things like multiway graphs. It didn���t take long to realize that, yes, what I was calling ���multicomputation��� wasn���t just relevant for fundamental physics; it was something quite general that could be applied in many areas, which by 2021 I was trying to catalog:

Areas of multipcomputation

I did some thinking about each of these. The one I tackled most seriously first was metamathematics, about which I finished a book in 2022. Late that year I was finishing a (50-year-in-gestation) project���informed by our Physics Project���on understanding the Second Law of thermodynamics, and as part of this I made what I thought was some progress on thinking about the fundamental character of biological systems (though not their adaptive evolution).

And then ChatGPT arrived. And in addition to being involved with it technologically, I started to think about the science of it, and particularly about how it could work. Part of it seemed to have to do with unrecognized regularities in human language, but part of it was a reflection of the emerging ���meta discovery��� that somehow if you ���bashed��� a machine learning system hard enough, it seemed like it could manage to learn almost anything.

But why did this work? At first I thought it must just be an ���obvious��� consequence of high dimensionality. But I soon realized there was more to it. And as part of trying to understand the boundaries of what���s possible I ended up a couple of months ago writing a piece exploring ���Can AI Solve Science?���:

Can AI Solve Science?

I talked about different potential objectives for science (making predictions, generating narrative explanations, etc.) And deep inside the piece I had a section entitled ���Exploring Spaces of Systems��� in which I talked about science problems of the form ���Can one find a system that does X?������and asked whether systems like neural nets could somehow let one ���jump ahead��� in what would otherwise be huge exhaustive searches. As a sideshow to this I thought it might be interesting to compare with what a non-neural-net adaptive evolution process could do.

Remembering Greg Chaitin���s ideas about connecting the halting problem to biological evolution I wondered if perhaps one could just adaptively evolve cellular automaton rules to find ones that generated a pattern with a particular finite lifetime. I imagined it as a classic machine learning problem, with a ���loss function��� one needed to minimize.

And so it was that just after 1 am on February 22 I wrote three lines of Wolfram Language code���and tried the experiment:

Click to enlarge

And it worked! I managed to find cellular automaton rules that would generate patterns living exactly 50 steps:

Click to enlarge

In retrospect, I was slightly lucky. First, that this ended up being such a simple experiment to try (at least in the Wolfram Language) that I did it even though I didn���t really expect it to work. And second, that for my very first experiment I picked parameters that happened to immediately work (k = 4, lifetime 50, etc.).

But, yes, I could in principle have done the same experiment 40 years ago, though without the Wolfram Language it wouldn���t have been so easy. Still, the computers I had back then were powerful enough that I could in principle have generated the same results then as now. But without my modern experience of machine learning I don���t think I would have tried���and I would certainly have given up too easily. And, yes, it���s a little humbling to realize that I���ve gone so many years assuming adaptive evolution was out of the reach of simple, clean experiments. But it���s satisfying now to be able to check off another mystery I���ve long wondered about. And to think that much more about the foundations of biology���and machine learning���might finally be within reach.
ChatGPT
ChatGPT
Stephen Wolfram���s historical exploration traces the intellectual journey of evolutionary theory from its ancient roots through modern computational models. He reflects on the gradual evolution of our understanding of heredity and natural selection, initiated by early agricultural practices and formalized scientifically by Charles Darwin in the 19th century. Darwin���s idea of natural selection likened to artificial selection laid the groundwork for viewing biological evolution as a process of competition and gradual adaptation, which leads to the emergence of new species over time.
Simultaneously, Wolfram notes the parallel developments by Gregor Mendel, whose work on inheritance in peas established the fundamental laws of genetics, although the significance of his discoveries was not recognized until the turn of the 20th century. The integration of Mendel���s findings with Darwinian theory sparked the development of population genetics, significantly contributing to the mathematical modeling of genetic variation over generations.
Wolfram then shifts to describe the various technological and theoretical advancements that have shaped our modern understanding of evolution, such as the emergence of cybernetics, genetic algorithms, and ultimately, cellular automata. He underscores how these developments have facilitated a deeper computational approach to studying evolutionary processes, which has been enriched by the adoption of concepts from electrical engineering, cybernetics, and later, computer science.
Particularly notable in Wolfram���s discussion is his personal reflection on the missed opportunities and the evolution of his own understanding, highlighting how his early work on cellular automata in the 1980s could have been a prime opportunity to explore adaptive evolution computationally. His recounting of these events underscores a common theme in scientific inquiry: the significance of timing, intuition, and the readiness of technology, which can greatly influence the discovery process.
The synthesis of these historical perspectives with personal insights offers a comprehensive view of the theoretical and practical challenges that have shaped the scientific community���s understanding of biological and computational evolution. Wolfram's reflections also emphasize the ongoing nature of scientific exploration, where past insights lay the groundwork for future discoveries, and where new tools���like modern machine learning���can rejuvenate interest and provide fresh approaches to longstanding scientific questions.
You
So he was focused on individual cellular automata instead of focusing on selection constraint process in the possibility space?
ChatGPT
ChatGPT
Exactly, Stephen Wolfram's early work with cellular automata primarily focused on exploring the behavior of individual rules rather than examining how a selection or evolutionary process might operate across a space of possible rules. His research was oriented towards understanding the inherent complexities and capabilities of these systems when governed by simple rules. This approach led to significant insights into how complexity can arise in nature, but it initially overlooked the potential for studying adaptation and evolution within these models.
It wasn't until later that Wolfram considered how these systems could model evolutionary processes, such as through adaptive evolution where rules change over time based on some selection criteria. This shift reflects a broader exploration into the dynamics of rule spaces and how they can mimic the evolutionary constraints and possibilities observed in biological systems.
You
Can you give a full overview of the main points?
ChatGPT
ChatGPT
Certainly! Here's a full overview of the main points discussed in the historical notes and personal reflections:
Historical Context:
Early recognition of heredity and plant breeding in antiquity.
Systematic selective breeding of animals began in the late 1700s.
Charles Darwin introduced the concept of natural selection in 1859.
Gregor Mendel's work on inheritance in the 1900s laid the groundwork for population genetics.
Cybernetics and early computing in the mid-20th century led to the exploration of biological-like evolution in artificial systems.
Development of Computational Models:
Warren McCulloch and Walter Pitts introduced idealized neural networks in 1943.
Donald Hebb proposed learning in neural systems through adaptive evolution in 1949.
Genetic algorithms emerged in the 1960s as a method for evolving computational structures.
Evolutionary computation and genetic programming gained traction in optimization and data classification from the 1970s to 1980s.
Challenges in Evolutionary Biology:
Darwin's ideas faced challenges, including conflicts with religious accounts of creation and scientific disagreements about the fossil record.
Questions persisted about the relationship between natural selection and the dynamics of organism growth.
Despite advancements in molecular biology, overarching theoretical principles in biology remained elusive.
Artificial Life and Cellular Automata:
Chris Langton's work in the mid-1980s spurred interest in computational models of artificial life.
Cellular automata, particularly Wolfram's research, provided insights into complex behavior emerging from simple rules.
Theoretical biology conferences transitioned to artificial life conferences, but complexities in models often hindered fundamental conclusions.
Missed Opportunities and New Intuition:
Wolfram's early focus on cellular automata explored their inherent complexity but overlooked adaptive evolution.
Modern advances in machine learning and computational techniques sparked new intuition about exploring biological evolution.
Chance experiments and experiences with modern machine learning prompted a reevaluation of the relationship between computational and biological evolution.
Recent Developments:
Wolfram's experiments with cellular automata in 2020 revealed the potential for adaptive evolution in simple systems.
Insights from Wolfram's work on artificial intelligence and computational irreducibility led to a deeper understanding of the role of computational processes in biological evolution.
Ongoing exploration aims to bridge the gap between computational and biological evolution, with implications for understanding both natural and artificial systems.
Overall, the historical notes and personal reflections highlight the evolving relationship between computational models and biological evolution, from early theoretical frameworks to modern insights into the complexities of adaptive systems.
You
A summary of the whole conversation.
The previous model used in this conversation is unavailable. We've switched you to the latest default model.
ChatGPT
ChatGPT
Certainly! Here's a summary of the conversation:
The historical notes provide insights into the development of evolutionary biology and computational models, starting from early recognition of heredity to the emergence of artificial life simulations and genetic algorithms. These models, including cellular automata, neural networks, and genetic programming, offered new perspectives on evolution but often lacked adaptive evolution components.
Wolfram's personal reflections reveal missed opportunities in exploring adaptive evolution and the role of computational processes in biological evolution. Despite early focus on cellular automata and foundational questions in biology, Wolfram didn't fully explore adaptive evolution until chance experiments in 2020 led to breakthroughs in understanding the relationship between computational and biological evolution.
Recent developments, including experiments with cellular automata and insights from modern machine learning, have sparked new intuition about adaptive evolution. Wolfram's work aims to bridge the gap between computational and biological evolution, offering potential insights into both natural and artificial systems.
Overall, the conversation explores the historical context, missed opportunities, and recent developments in understanding the role of computational processes in biological evolution, highlighting Wolfram's journey from early explorations to current insights.
You
What is his current theory?
ChatGPT
ChatGPT
Wolfram's current theory revolves around the concept of computational irreducibility and its implications for understanding biological evolution. He proposes that the complexity observed in biological systems arises from computational processes rather than being solely sculpted by natural selection. By studying computational processes, such as those found in cellular automata and machine learning algorithms, Wolfram seeks to uncover fundamental principles that govern both natural and artificial systems. Through his recent experiments and reflections, Wolfram aims to elucidate the connections between computational and biological evolution, offering insights into the underlying mechanisms driving the emergence of complexity in living organisms.
You
I decided to call it cellular ruliad space
ChatGPT
ChatGPT
"Cellular Ruliad Space" sounds like an intriguing name! It captures the essence of Wolfram's exploration of the space of cellular automaton rules and their potential implications for understanding complex systems and biological evolution. It's a fitting term to describe the vast landscape of possibilities within cellular automata rule space.
You
Can you explain it?
ChatGPT
ChatGPT
Certainly! "Cellular Ruliad Space" would refer to the multidimensional space that encompasses all possible configurations and behaviors of cellular automata rules. In this space, each point represents a unique rule configuration, and the dimensionality corresponds to the parameters that define the rules, such as the number of states each cell can have, the neighborhood size, and the update function.
Exploring this space involves investigating the properties and behaviors of different cellular automaton rules, ranging from simple to complex. By studying patterns and emergent behaviors within this space, researchers can gain insights into the dynamics of cellular automata systems and potentially uncover fundamental principles underlying complex systems in general.
Wolfram's work has involved systematically exploring this space, looking for patterns, regularities, and interesting behaviors exhibited by different rules. This exploration has led to discoveries about the computational capabilities of simple systems and their relevance to understanding complex phenomena in biology, physics, and other fields.
You
Some everyday metaphors to help explain it.
ChatGPT
ChatGPT
Certainly! Explaining "Cellular Ruliad Space" with everyday metaphors:
Recipe Book
: Imagine each rule in Cellular Ruliad Space as a recipe in a vast cookbook. Each recipe represents a set of instructions for generating patterns in a cellular automaton. Just as different recipes produce different dishes, different rules produce distinct patterns and behaviors in cellular automata.
Music Playlist
: Think of Cellular Ruliad Space as a massive library of music playlists. Each playlist corresponds to a unique combination of rules for a cellular automaton. Just as playlists vary in genre, tempo, and mood, rules in Cellular Ruliad Space vary in their properties and behaviors, creating diverse patterns and dynamics.
Art Gallery
: Consider Cellular Ruliad Space as an expansive art gallery filled with diverse artworks. Each artwork represents a visualization of the patterns generated by a specific rule in a cellular automaton. Just as artworks vary in style, color, and composition, rules in Cellular Ruliad Space produce an array of visually striking and conceptually intriguing patterns.
These metaphors help illustrate how Cellular Ruliad Space encompasses a wide range of possibilities and behaviors, providing a rich landscape for exploration and discovery.
You
A clickbaity sardonic review.
ChatGPT
ChatGPT
"Cellular Ruliad Space: A Recipe Book for Chaos or a Symphony of Noise?
Step right up, folks, to witness the latest buzz in computational exploration: Cellular Ruliad Space! Is it a revolutionary roadmap to unravel the secrets of the universe, or just another cacophony of digital noise masquerading as science?
Imagine a world where every cellular automaton rule is a potential recipe for chaos, served up on a silver platter of mathematical abstraction. But beware! Behind the enticing facade of endless possibilities lurks a tangled web of complexity, where even the simplest rules can lead you down a rabbit hole of confusion.
In this grand symphony of digital noise, each rule plays its own discordant tune, creating a cacophony of patterns that dance across the screen like a drunken ballet. But amidst the chaos, could there be hidden gems waiting to be discovered, or are we just chasing shadows in a pixelated dream?
Enter the art gallery of Cellular Ruliad Space, where every pattern is a masterpiece waiting to be admired���or ridiculed. Marvel at the kaleidoscope of colors and shapes, or scratch your head in bewilderment at the seemingly random chaos unfolding before your eyes.
But wait, there's more! For the low, low price of your sanity, you too can dive headfirst into the abyss of Cellular Ruliad Space, where every click is a gamble and every rule is a wild card in the deck of digital destiny.
So, dear reader, will you dare to venture into the depths of Cellular Ruliad Space, or will you stick to the safe shores of mathematical certainty? The choice is yours. Just remember: in the game of cellular automata, chaos reigns supreme, and the only rule is there are no rules!"
ChatGPT can make mistakes. Consider checking important information.
?
ChatGPT

