ChatGPT
Open sidebar
ChatGPT
3.5
You
Naturalizing Relevance Realization: 
Why agency and cognition are fundamentally not computational



AUTHORS
Johannes Jaeger, Anna Riedl, Alex Djedovic, John Vervaeke, and Denis Walsh
ChatGPT
ChatGPT
It seems like you are mentioning a paper or an article titled "Naturalizing Relevance Realization: Why agency and cognition are fundamentally not computational" by authors Johannes Jaeger, Anna Riedl, Alex Djedovic, John Vervaeke, and Denis Walsh. How can I assist you with this? Are you looking for a summary, specific information within the paper, or something else?
You
Abstract 
The way organismic agents come to know the world, and the way algorithms solve problems, are 
fundamentally different. The most sensible course of action for an organism does not simply 
follow from logical rules of inference. Before it can even use such rules, the organism must tackle 
the problem of relevance. It must turn ill-def i ned problems into well-def i ned ones, turn semantics 
into syntax. This ability to realize relevance is present in all organisms, from bacteria to humans. It 
lies at the root of organismic agency, cognition, and consciousness, arising from the particular 
autopoietic, anticipatory, and adaptive organization of living beings. In this paper, we show that the 
process of relevance realization is beyond formalization. It cannot be captured completely by 
algorithmic approaches. This implies that organismic agency (and hence cognition as well as 
consciousness) are at heart not computational in nature. Instead, we show how the process of 
relevance is realized by an adaptive and emergent evolutionary dialectic, which manifests as a 
metabolic and ecological co-constructive dynamic. This results in a meliorative process that 
enables an agent to keep a grip on its arena, its reality. To be alive means to make sense of one's 
world. This kind of embodied ecological rationality is a fundamental aspect of life, and a key 
characteristic that sets it apart from non-living matter. 
Keywords: 
relevancerealization,open-endedevolution,radicalemergence,autopoiesis,anticipation, 
adaptation, natural agency, cognition, consciousness, embodied rationality
ChatGPT
ChatGPT
The abstract you provided is from a paper discussing the fundamental differences between the ways organisms understand the world and how algorithms solve problems. The key points of the abstract are:
Difference in Problem-Solving
: Organismic agents (living beings) and algorithms approach problem-solving differently. Organisms don't solely rely on logical rules of inference. They first need to determine what is relevant in a situation.
Relevance Realization
: This process of determining relevance is inherent in all organisms, from bacteria to humans. It's a critical component of agency, cognition, and consciousness, rooted in the unique organization of living beings, characterized as autopoietic, anticipatory, and adaptive.
Beyond Formalization
: The paper argues that the process of relevance realization cannot be fully captured by algorithmic methods, implying that the essence of organismic agency, cognition, and consciousness is not computational.
Adaptive and Emergent Evolutionary Dialectic
: The authors propose that relevance is realized through an adaptive, emergent evolutionary process. This process is described as a metabolic and ecological co-constructive dynamic, leading to a meliorative process that helps an agent maintain its grip on reality.
Embodied Ecological Rationality
: The paper emphasizes that being alive means making sense of one's world through an embodied ecological rationality. This form of rationality is a fundamental aspect of life and distinguishes living beings from non-living matter.
The paper seems to explore the philosophical and biological underpinnings of cognition and consciousness, contrasting them with computational approaches to problem-solving and intelligence.
You
���To live is to know.��� 
(Maturana, 1988) 
���Between the stimulus and the response, there is a space. And in that space lies our freedom and 
power to choose our responses.��� 
(Frankl, 1946/2020) 
���Voluntary actions thus demonstrate a ���freedom from immediacy���.��� 
(Haggard, 2008, channeling Shadlen & Gold, 2004) 
1. Introduction 
All organisms are limited beings that live in a world overf l owing with potential meaning (Varela et 
al., 1991; Weber, 2002; Thompson, 2007), a world profoundly exceeding their grasp (Stanford, 
2010). Environmental cues likely to be important in a given situation tend to be scarce, ambiguous, 
and fragmentary. Clear and obvious signals are rare (Felin & Felin, 2019)1. Very few problems we 
encounter in such a ���large world��� are well-def i ned (Savage, 1954). On top of all this, organisms 
constantly encounter situations they have never come across before. To make sense of such an 
ill-def i ned and open-ended world ��� in order to survive, thrive, and enact evolution ��� the organism 
must i rst realize what is relevant in its environment. It needs to solve the problem of relevance. 
In contrast, algorithms ��� broadly def i ned as automated computational procedures, i.e., i nite sets 
of symbols encoding operations that can be executed on a universal Turing machine ��� exist in a 
���small world��� (Savage, 1954). They do so by def i nition, since they are embedded and implemented 
within a predef i ned formalized ontology (intuitively: their ���digital environment��� or ���computational 
architecture���), where all problems are well-def i ned. They can only mimic (emulate, or simulate) 
partial aspects of a large world: algorithms cannot identify or solve problems that are not precoded 
(explicitly or implicitly) by the rules that characterize their small world (Cantwell Smith, 2019). In 
such a world, everything and nothing is relevant at the same time. 
This is why the way organisms come to know their world fundamentally differs from algorithmic 
problem solving or optimization (Roli et al., 2022). This elementary insight has profound 
consequences for research into artif i cial intelligence (Jaeger, 2023), but also for our understanding 
of natural agency, cognition, and ultimately also consciousness, which will be the focus of this 
paper. An organism���s actions and behavior are founded on the ability to cope with unexpected situations, with cues that are uncertain, ambivalent, or outright misleading (see Wrathall & Malpas, 
2000; Wheeler, 2012; Ratcliffe, 2012, for discussion). Algorithms do not have this ability ��� they 
cannot truly improvise, but only mimic improvisational behavior ��� due to their rigidly formalized 
nature. 
Contrary to an algorithm, the most sensible (and thus ���rational���) course of action for an organism 
does not simply follow from logical rules of inference, not even abductive inference to the best 
explanation (see, for example, Feyerabend, 1975; Arthur, 1994; Thompson, 2007; Gigerenzer, 2021; 
Roli et al., 2022; Riedl & Vervaeke, 2022). Before they can ���infer��� anything, living beings must i rst 
turn ill-def i ned problems into well-def i ned ones, transform large worlds into small, translate 
intangible semantics into formalized syntax (def i ned as the rule-based processing of symbols free 
of contingent, vague, and ambiguous external referents). And they must do this incessantly: it is a 
def i ning feature of their mode of existence. 
This process is called relevance realization (Vervaeke et al., 2012; Vervaeke & Ferraro, 2013a, 
2013b). The ability to solve the problem of relevance is a necessary condition and the def i ning 
criterion for making sense of a large world (Sperber & Wilson, 1986; Oaksford, 1995; Sperber & 
Wilson, 1996; Wilson & Sperber, 2012; Wilson & Niv, 2012; Wilson, 2017; Sumers et al., 2022). 
Indeed, we could say that it actively brings forth a world of meaning (Varela et al., 1991; Rolla & 
Figueiredo, 2023). 
In this paper, we shall argue that the ability to realize relevance ��� to bring forth a world ��� is present 
in all organisms, from the simplest bacteria to the most sophisticated human beings. In fact, we 
show that it is one of the key properties that sets apart living systems from algorithms and their 
concrete physical implementations, which we will call machines. The ability to solve the problem of 
relevance arises from the self-referential self-manufacturing dynamic organization of living matter, 
which enables organisms to attain a degree of self-determination, to act with some autonomy, and 
to anticipate the consequences that may follow from their actions.
ChatGPT
ChatGPT
The introduction of your paper delves into the fundamental differences between how living organisms and algorithms interact with and understand the world. Here are the key points:
Organisms in a Complex World
: Organisms exist in an "ill-defined and open-ended world," facing ambiguous and scarce environmental cues. Their challenges are not clearly defined, and they often encounter novel situations.
Problem of Relevance
: For organisms to survive and evolve, they need to determine what is relevant in their environment. This is a continuous process, essential for adapting to their complex world.
Algorithms in a Predefined World
: In contrast, algorithms operate in a "small world," a predefined, formalized environment. Their problems are well-defined within this context, and they can't identify or address issues outside their programmed rules.
Limitations of Algorithms
: Algorithms cannot truly improvise or adapt to unexpected scenarios. They are bound by their formal nature and can only mimic aspects of a more complex world.
Organismic Rationality
: The rational actions of organisms are not solely derived from logical rules. They first need to transform ill-defined problems into well-defined ones, a process beyond the capability of algorithms.
Relevance Realization
: This term describes the process by which living beings discern what is meaningful in their environment. It's a necessary condition for understanding and interacting with a complex world.
Self-Referential Organization of Living Matter
: The ability to realize relevance and act autonomously comes from the unique self-organizing nature of living systems. This self-referential dynamic allows organisms to anticipate consequences and act with a degree of autonomy.
Living Systems vs. Machines
: The paper argues that the ability to realize relevance is a key distinction between living systems and machines (or algorithms). This ability stems from the organizational complexity of living matter.
The introduction sets the stage for a deeper exploration into the cognitive and existential differences between living organisms and computational systems, emphasizing the unique adaptive and anticipatory capabilities of life.
You
All of this involves a radically context-dependent generative dialectic2called opponent processing 
��� the continual establishment of trade-offs and synergies between competing and complementary 
organismic behaviors and dynamics (Vervaeke et al., 2012). Such competing and synergizing 
processes also mediate an organism���s interactions with its living and non-living surroundings, 
interactions that are inherently and irreducibly semantic. This manifests as mutually co-creating 
(and thus collectively co-emergent) interrelations between a living agent���s intrinsic goals, its 
2 ���Dialectic��� is a term heavily burdened with different (often metaphysical and even political) interpretations. Here, we 
def i ne it to simply mean the dynamic of two or more interrelated processes whose interactions do not merely feed back 
on each other, but are reciprocally constituting. In other words, the interacting processes support each other���s 
existence by mutual co-construction. 4 
repertoire of actions, and the affordances that arise from the interactions of the organism with its 
experienced environment (Walsh, 2015). 
As we shall see, this dialectic and hierarchical tangle of processes forms the generative core of the 
phenomenon of natural agency, and therefore also of its evolutionary elaborations: cognition and 
consciousness (cf. Felin & Koenderink, 2022). There is nothing mystifying or obscurantist about 
this view. In fact, we can demonstrate that this dialectic is straightforwardly analogous to the 
dynamics of an evolving population of biological individuals, where different survival strategies are 
played out against each other to bring about adaptation through natural selection (Vervaeke et al., 
2012). It is, in essence, a Darwinian adaptive evolutionary dynamic. Our central claim in what 
follows is that this dialectic dynamic of relevance realization is not an algorithmic process. 
Therefore, natural agency, cognition, and consciousness are, at their very core, not computational.
ChatGPT
ChatGPT
This section of your paper discusses the concept of "opponent processing" as a key mechanism in understanding natural agency, cognition, and consciousness. Here are the main points:
Opponent Processing
: This term refers to a dynamic where competing and complementary behaviors and processes in organisms establish trade-offs and synergies. It's a generative dialectic that involves continuous negotiation between different organismic dynamics.
Definition of Dialectic
: In this context, 'dialectic' is defined as the interaction of two or more interrelated processes that are reciprocally constitutive. This means they not only interact but also mutually support each other's existence through co-construction.
Semantic Interactions with the Environment
: Organisms interact with their environment (both living and non-living) in ways that are inherently semantic. These interactions involve a co-creative relationship between the organism���s intrinsic goals, its action repertoire, and the affordances that arise in its environment.
Generative Core of Natural Agency
: This dialectic intertwines processes that form the core of natural agency, which also underpins the evolution of cognition and consciousness. The paper emphasizes that there is nothing mystical about this view.
Analogy with Evolutionary Dynamics
: The paper draws an analogy between this dialectic and the dynamics of an evolving population, where different survival strategies compete and lead to adaptation through natural selection. This is seen as a Darwinian adaptive evolutionary dynamic.
Non-Computational Nature of Agency, Cognition, and Consciousness
: The central claim is that the dynamic of relevance realization, which is a part of this dialectic, is not an algorithmic process. Consequently, the fundamental aspects of natural agency, cognition, and consciousness are not computational in nature.
This section thus argues for a non-computational understanding of how organisms interact with and make sense of their environment, emphasizing the complex, evolutionary, and co-constructive nature of these interactions.
You
We will carefully unpack this rather dense and compact mission statement in the following 
sections. As our starting point, let us take the analogy of relevance and evolutionary i tness implied 
above (see also Vervaeke et al., 2012)3. Both concepts are closely related in the sense of pertaining 
to a radically context-dependent match between an agent and its immediate task-relevant 
environment, or arena (Vervaeke et al., 2017). Neither ���f i tness��� nor ���relevance��� have any universal 
attributes: there is no trait that renders you i t in all environments, nor is there any factor that is 
relevant across all possible situations. Furthermore, both i tness and relevance can only be 
assessed in a relative manner: one individual in a specif i c population and environment is i tter than 
another, and some features of the world may be more relevant than others. In other words, these 
concepts are only explanatory when used in a comparative context. 
Because of this close conceptual analogy between relevance and i tness, an understanding of 
relevance realization ought to be of an evolutionary, ecological, and economic nature, formulated as 
the interplay of competing adaptive processes, situated in a particular setting, and phrased in 
terms of the variable and weighed commitments of organisms to a range of different goals. 
Opponent processing means that organisms constantly play different approaches against each 
other in a process that iteratively evaluates progress towards a problem solution (towards reaching 
a goal). This can include dynamically switching back and forth between opposing strategies, if the 
necessity arises. By identifying molecular, cellular, organismic, ecological, and evolutionary 
processes and relations that can implement such an adaptive dynamic, we can generalize the 
3 As is the case for all analogies, this one also has its limitations. One important way in which ���relevance��� and ���f i tness��� 
differ is that the former is a genuine property of the organism in its environment (the agent in its arena, see below), 
while the latter is only a property of an organism in a very attenuated sense: ���f i tness��� is an abstraction from all the 
things an organism can actually do to get by, a sort of projection of its prospects. This caveat is important to keep in 
mind when considering analogous properties of ���relevance��� and ���f i tness��� in what follows. 
5 
concept of relevance realization from the fundamental prerequisite for cognition in animals with 
nervous systems (including us humans, of course, Vervaeke et al., 2012) to the fundamental 
prerequisite underlying natural agency in all living organisms.
ChatGPT
ChatGPT
In this section, you're elaborating on the concept of relevance realization and its analogy with evolutionary fitness. The key points are as follows:
Analogy with Evolutionary Fitness
: The paper draws a parallel between the concepts of relevance and fitness. Both are context-dependent and pertain to the match between an agent and its task-relevant environment. This analogy serves as a starting point for further discussion.
Relative Nature of Fitness and Relevance
: Neither fitness nor relevance have universal attributes. There's no trait that ensures fitness in all environments, nor is there a factor that's relevant in all situations. Their assessment is comparative and relative, depending on specific environments and situations.
Evolutionary, Ecological, and Economic Understanding
: An understanding of relevance realization is proposed to be evolutionary, ecological, and economic in nature. It involves the interplay of competing adaptive processes within a particular setting, with organisms variably committed to different goals.
Opponent Processing in Problem-Solving
: Organisms engage in opponent processing, where different strategies compete, allowing for iterative evaluation of progress toward solving a problem or reaching a goal. This may involve dynamically switching between opposing strategies as needed.
Generalizing Relevance Realization
: By identifying relevant molecular, cellular, organismic, ecological, and evolutionary processes, the concept of relevance realization is extended from being a fundamental prerequisite for cognition in animals (particularly those with nervous systems) to a fundamental prerequisite underlying natural agency in all living organisms.
Caveat of the Analogy
: The paper notes a limitation in the analogy between relevance and fitness. Relevance is a genuine property of an organism in its environment, while fitness is more of an abstract concept, a projection of an organism's survival prospects.
This section of the paper is critical in setting up the framework for understanding relevance realization as a fundamental aspect of natural agency across all living organisms, connecting it with evolutionary and ecological dynamics.
You
This paper is structured as follows: Section 2 starts by outlining a number of problems we 
encounter when considering cognition (and the world) as some form of algorithmic computation 
and introduces our proposed alternative perspective. In section 3, we characterize the process of 
relevance realization, outlining its foundational role in cognition and in the choice of rational 
strategies to solve problems. Section 4 introduces the notion of biological organization, shows 
how it emerged as a novel kind of organization of matter at the origin of life, and demonstrates 
how it enables basic autonomy and natural agency through the organism���s ability to set its own 
intrinsic goals. The pursuit of its goals requires an organism to anticipate the consequences of its 
actions. How this is achieved even in the simplest of creatures is the topic of section 5. In section 
6, we examine the adaptive dialectic interplay between an organism���s goals, actions, and 
affordances. As the core of our argument, we bring this model to bear on the process of relevance 
realization itself, and show how this process cannot be captured completely by any kind of 
algorithm. In section 7, we synthesize the insights from the previous three sections, to show how 
the evolution of cognition in organisms with a nervous system, and perhaps also consciousness, 
can be explained as adaptations to realizing relevance in ever more complex situations. Finally, we 
conclude our argument by applying the concept of relevance realization to rational strategies for 
problem solving. We argue that a basic ecological notion of rational behavior is common to all 
living beings. In other words, organisms make sense of the world in a way that makes sense to 
them.
ChatGPT
ChatGPT
The structure of your paper is outlined as follows:
Section 2 - Problems with Algorithmic Computation in Cognition
: This section addresses the issues that arise when considering cognition and the world in terms of algorithmic computation. It introduces an alternative perspective to this view.
Section 3 - Characterizing Relevance Realization
: Here, the foundational role of relevance realization in cognition and in selecting rational strategies for problem-solving is detailed.
Section 4 - Biological Organization
: This section discusses the emergence of biological organization as a novel form of matter organization at the origin of life. It explores how this organization enables basic autonomy and natural agency through an organism's ability to set its own intrinsic goals.
Section 5 - Anticipating Consequences of Actions
: This part focuses on how organisms, even the simplest ones, anticipate the consequences of their actions.
Section 6 - Adaptive Dialectic Interplay
: The section examines the interplay between an organism's goals, actions, and affordances, emphasizing how this model influences the process of relevance realization. It argues that this process cannot be fully captured by algorithms.
Section 7 - Evolution of Cognition and Consciousness
: This section synthesizes insights from the previous sections to explain how the evolution of cognition and possibly consciousness in organisms with a nervous system can be seen as adaptations for realizing relevance in increasingly complex situations.
Conclusion - Relevance Realization in Rational Problem Solving
: The conclusion applies the concept of relevance realization to rational strategies for problem-solving. It proposes that a basic ecological notion of rational behavior is common to all living beings, suggesting that organisms make sense of the world in a way that is sensible to them.
Each section builds upon the previous to argue that cognition, consciousness, and rational behavior in living organisms are inherently different from algorithmic computation, emphasizing the unique, adaptive, and anticipatory nature of biological processes.
You
2. Agential Emergentism 
Contemporary approaches to natural agency and cognition take a very wide range of stances on 
what these two concepts mean, what they refer to, and how they relate to each other. Some of 
these approaches consider cognition a fundamental property of all living beings (see, for example, 
Maturana & Varela, 1980; Varela et al., 1991; Lyon, 2006; Baker & Stock, 2007; Shapiro, 2007; 
Thompson, 2007; Balu��ka & Levin, 2016; Birch et al., 2020; Lyon et al., 2021), some treat it as 
restricted to animals with suf i ciently complex internal models of the world (Djedovic, 2020; Sims, 
2021) or in possession of a nervous system (e.g., Moreno et al., 1997; Moreno & Etxeberria, 2005; 
Moreno & Mossio, 2015; Di Paolo et al., 2017). Some see natural agency as a phenomenon that is 
clearly distinct from cognition (see, for example, Rosen, 1985/2012; Kauffman, 2000; Barandiaran 
6 
& Moreno, 2008; Moreno & Mossio, 2015; Fulda, 2017), some consider the two to be the same (e.g., 
Maturana & Varela, 1980; Lyon, 2006; Thompson, 2007; Balu��ka & Levin, 2016). Among this 
diversity of perspectives, we can identify two general trends in attitudes. Let us call them agential 
emergentism and computationalism4. 
Computationalism encompasses various forms of cognitivism and connectionism (according to 
the classif i cation of (Thompson, 2007). It is extremely popular and widespread in contemporary 
scientif i c and philosophical thinking, the basic tenet being that both natural agency and cognition 
are special varieties of algorithmic computation. Computationalism formulates agential and 
cognitive phenomena in terms of (often complicated, nonlinear, and heavily feedback-driven) 
input-output information processing (see, Balu��ka & Levin, 2016; Levin, 2021, for a particularly 
strong and explicit example). In this framework, goal-directedness ��� sometimes unironically called 
���machine wanting��� (McShea, 2013) ��� tends to be explained by some kind of cybernetic 
homeostatic regulation (e.g., McShea, 2012, 2013, 2016; Lee & McShea, 2020). 
The strongest versions of computationalism assert that all physical processes which can be 
actualized (not just cognitive ones) must be Turing-computable. This pancomputationalist attitude 
is codif i ed in the strong (or physical) Church-Turing conjecture (also called Church-Turing-Deutsch 
conjecture; Deutsch, 1985, 1997; Lloyd, 2006)5. It is fundamentally reductionist in nature, an 
attempt to force the explanation of all of physical reality in terms of algorithmic computation 
based on lower-level mechanisms. For this reason, computation is not considered exclusive to 
living systems. Researchers in the pancomputationalist paradigm see agency and cognition as 
continuous with non-linear and self-organizing information processing outside the living world 
(see, for example, Levin, 2021; Bongard & Levin, 2023). On this view, there is no fundamental 
boundary between the realms of the living and the non-living, between biology and computer 
engineering. The emergence of natural agency and cognition in living systems is simply due to a 
(gradual) increase in computational complexity and capacity in the underlying physical processes.
ChatGPT
ChatGPT
In this section titled "Agential Emergentism," the paper discusses contemporary perspectives on natural agency and cognition, and introduces two dominant approaches: agential emergentism and computationalism. Here's a breakdown of the key points:
Diverse Views on Cognition and Agency
: There are varied interpretations of what constitutes cognition and natural agency. Some theories suggest cognition is a fundamental property of all living beings, while others restrict it to animals with complex internal models or a nervous system. Similarly, views on the relationship between natural agency and cognition vary, with some seeing them as distinct and others as synonymous.
Agential Emergentism
: This is one of the two identified trends. The paper doesn't elaborate much on it in this excerpt, but it presumably contrasts with computationalism, focusing on the emergent properties of agents and their cognition.
Computationalism
: This approach is popular in scientific and philosophical thinking. It views natural agency and cognition as special types of algorithmic computation. It explains agential and cognitive phenomena in terms of complex, nonlinear input-output information processing. Goals are often described in terms of cybernetic homeostatic regulation.
Pancomputationalism and the Church-Turing Conjecture
: The strongest form of computationalism, pancomputationalism, posits that all physical processes, cognitive or otherwise, must be Turing-computable. This view, also known as the physical Church-Turing conjecture, is reductionist, aiming to explain all of physical reality in terms of lower-level algorithmic computation.
No Distinct Boundary Between Living and Non-living
: In the computationalist view, there is no fundamental distinction between living and non-living systems. Agency and cognition are seen as continuations of non-linear and self-organizing information processing that occurs outside the living world. The emergence of agency and cognition in living systems is attributed to an increase in computational complexity in physical processes.
In summary, this section presents the conceptual backdrop against which the paper's arguments are positioned, contrasting the computational approach with what seems to be a more emergent, possibly holistic perspective on natural agency and cognition.
You
We consider this view of reality to be highly problematic. One issue with pancomputationalism is 
that physical processes and phenomena are generally not discrete by nature and are rarely 
deterministic in the sense that algorithmic processes are (Longo, 2009; Longo & Paul, 2011). We 
will not dwell on this here, but will focus instead on the relation between syntactic formal systems 
and a fundamentally semantic and ill-def i ned large world. In this context, it is crucial to distinguish 
the ability to algorithmically simulate (i.e., approximate) physical and cognitive processes from the 
5 Pancomputationalists often call it a ���principle,��� claiming that it is (or can be) empirically verif i ed, when in fact it remains 
nothing but philosophical conjecture (see, for example, Deutsch, 1997). 
4 The distinction between agential emergentism and computationalism is, of course, much richer and deeper than just 
considering agency and cognition the same or not. We will elaborate this in the following sections. 
7 
claim that these processes intrinsically are a form of computation. The latter view mistakes the 
map for the territory by misunderstanding the original purpose of the theory of computation: as 
def i ned by Church and Turing, ���computation��� is a rote procedure performed by a human agent (the 
original ���computer���) carrying out some calculation, logical inference, or planning procedure 
(Church, 1936; Turing, 1937; see, Copeland, 2020, for an historical review). The theory of 
computation was intended as a model of specif i c human activities, not a model of the brain or 
physical reality in general. Consequently, assuming that the brain or the world in general is a 
computer means committing a category mistake called the equivalence fallacy (Copeland, 2020). 
Treating the world as computation imputes symbolic (information) content onto physical 
processes that is only really present in our simulations, not in the physical processes that we 
model. The world we directly experience as living organisms is not formalized and, in fact, is not 
formalizable completely by any limited being, as we shall see in the next section. This poses an 
obvious and fundamental problem for the pancomputationalist view.
ChatGPT
ChatGPT
In this part of your paper, you present a critique of pancomputationalism and the broader computationalist view of reality, emphasizing the issues with treating all physical and cognitive processes as forms of computation. The key points are as follows:
Critique of Pancomputationalism
: The paper argues that physical processes and phenomena are generally not discrete or deterministic in the way that algorithmic processes are. This challenges the pancomputationalist view, which attempts to explain all physical phenomena in terms of computation.
Distinction Between Simulation and Reality
: There's a crucial difference between the ability to algorithmically simulate physical and cognitive processes and the claim that these processes are inherently computational. The paper argues that seeing these processes as computation is a misunderstanding, akin to confusing the map with the territory.
Original Purpose of Computation Theory
: Computation, as defined by Church and Turing, was initially a model for specific human activities, such as calculations and logical inferences, not a model of the brain or physical reality. The paper suggests that extending this model to the brain or the world is a category mistake, known as the equivalence fallacy.
Misattribution of Symbolic Content
: Treating the world as computation imputes symbolic or informational content onto physical processes that only exist in our simulations, not in the actual physical processes themselves.
Non-formalizability of the World
: The paper argues that the world experienced by living organisms is not and cannot be completely formalized, posing a fundamental problem for the pancomputationalist view.
In essence, this section of the paper challenges the reductionist approach of computationalism, highlighting the limitations of viewing cognitive and physical processes as inherently computational. The authors emphasize the importance of recognizing the non-computational, emergent aspects of reality, especially in the context of natural agency and cognition.
You
To better understand and ultimately overcome this problem, we adopt an alternative stance called 
agential emergentism (outlined in detail in Walsh, 2013, 2015). The basic idea is to provide a fresh 
and expanded perspective on life that allows us to bridge the gap between the syntactic and the 
semantic realms, between small and large worlds. Agential emergentism postulates that all 
organisms possess a kind of natural agency. Note that this is not the same as the so-called 
intentional stance (Dennett, 1987; recently reviewed in Okasha, 2018), which merely encourages us 
to treat living systems as if they had agency while retaining a thoroughly reductionist worldview 
(see also the teleonomy account of Mayr, 1974, 1982, 1992). In contrast, agential emergentism 
treats agency as natural and fundamental: the key property that distinguishes living from non-living 
systems (Moreno & Mossio, 2015; Walsh, 2015; Mitchell, 2023). Only organisms ��� not algorithms 
or machines ��� are true agents, because only they can act on their own behalf, for their own 
reasons, in pursuit of their own goals (Kauffman, 2000; Nicholson, 2013; Walsh, 2015; Roli et al., 
2022; Jaeger, 2023; Mitchell, 2023). 
We can def i ne natural agency in its broadest sense as the capability of a living system to initiate 
actions according to its own internal norms (Barandiaran et al., 2009; Moreno & Mossio, 2015; 
Djedovic, 2020; Walsh & Rupik, 2023). This capability arises from the peculiar self-referential and 
hierarchical causal regime that underlies the self-manufacturing organization of living matter (see 
section 4). A lower bound for normativity arises from such self-manufacture: the right thing to do is 
what keeps me alive (Di Paolo et al., 2017; Djedovic, 2020). This imposes a discrete discontinuity 
between the realms of the living and the non-living: algorithms and machines only possess 
extrinsic purpose, imposed on them from outside their own organization, while organismic agents 
can, and indeed must, def i ne their own intrinsic goals (Nicholson, 2013; Mossio & Bich, 2017).
ChatGPT
ChatGPT
This part of your paper explains the concept of agential emergentism, which is proposed as an alternative to the computationalist view. Here are the main points:
Agential Emergentism as an Alternative Stance
: This perspective aims to bridge the gap between the syntactic (formal, computational) and the semantic (meaningful, experienced) realms, offering a fresh view on life that acknowledges the differences between small (formalized) and large (complex, real-world) environments.
Natural Agency in Organisms
: Agential emergentism postulates that all organisms possess natural agency, which is fundamentally different from the intentional stance that treats living systems as if they had agency while maintaining a reductionist view. Here, agency is seen as a natural and fundamental property distinguishing living from non-living systems.
Definition of Natural Agency
: Natural agency is defined as the capacity of a living system to initiate actions based on its own internal norms. This is in contrast to algorithms or machines, which are seen as having only extrinsic purposes imposed from outside.
Self-Referential and Hierarchical Causal Regime
: The capability for natural agency arises from the unique self-referential and hierarchical organization of living matter. This organization underlies the self-manufacturing process of living organisms.
Normativity and Self-Manufacture
: A basic level of normativity arises from self-manufacture: the right action is that which sustains the organism's life. This perspective emphasizes a clear discontinuity between living and non-living realms.
Intrinsic vs. Extrinsic Goals
: Unlike machines and algorithms, which have externally imposed purposes, organismic agents are capable of defining their own intrinsic goals.
In summary, agential emergentism offers a perspective where natural agency is a key characteristic of living beings, inherently different from the computational models applied to machines and algorithms. This view underscores the self-driven, autonomous nature of living organisms and their capacity to act based on internal norms and self-defined goals.
You
This is why it makes good sense to treat relevance realization from an agential rather than 
computationalist perspective: the ability to solve the problem of relevance is intimately connected 
to the possession of intrinsic goals. To put it simply: if you do not truly want or desire anything, if 
there is nothing that is good or bad in your world, you cannot realize what is relevant for you. 
Phrased a bit less informally: the relevance of certain features of a situation to the organism is a 
function of the organism���s goals and how the situation promotes or impedes them. This is why 
algorithms in their small worlds cannot solve the problem of relevance: they never even encounter 
it! In addition, relevance realization requires an organism to assess potential outcomes of its 
behavior6. To realize what is relevant in a given situation, you have to be able to somehow 
anticipate the consequences of your actions. On top of all this, an organism must be motivated to 
pursue its goals. Motivation ultimately stems from our fragility and mortality (Jonas, 1966; 
Thompson, 2007; Deacon, 2011; Moreno & Mossio, 2015). While it is possible to impose external 
motivation on a system that mimics aspects of internal motivation, true internal motivation can 
only arise from precariousness. We must be driven to continue living. Without this drive, we do not 
get the proper Darwinian dynamics of open-ended evolution (as argued in detail in Roli et al., 2022; 
Jaeger, 2024a). In what follows, we develop a naturalistic evolutionary account of relevance 
realization that is framed based on this simple set of basic principles.
ChatGPT
ChatGPT
In this section, the paper argues for approaching the concept of relevance realization from an agential perspective rather than a computationalist one. Key points include:
Connection to Intrinsic Goals
: The ability to determine what is relevant is closely linked to having intrinsic goals. Without genuine desires or a sense of what is good or bad, an entity cannot discern relevance. The relevance of certain aspects of a situation is dependent on the organism's goals and how these goals are affected by the situation.
Limitation of Algorithms
: Algorithms, operating in their "small worlds," are unable to solve the problem of relevance because they do not encounter it. They lack the ability to assess potential outcomes of their behaviors, a necessary component for realizing relevance.
Anticipation of Consequences
: To understand what is relevant in a given situation, an organism must be able to anticipate the consequences of its actions. This foresight is beyond the capability of algorithmic processes.
Role of Motivation
: The motivation to pursue goals is rooted in the organism's fragility and mortality. While external motivations can be imposed on systems mimicking internal motivation, true internal motivation arises from the precariousness of life. This drive is essential for the Darwinian dynamics of open-ended evolution.
Naturalistic Evolutionary Account of Relevance Realization
: The paper proposes to develop an evolutionary account of relevance realization based on these principles, framing it within a naturalistic approach.
The emphasis in this section is on the unique characteristics of living organisms ��� their goals, motivations, and ability to anticipate ��� that enable them to discern and act upon what is relevant in their environment, distinguishing them from computational algorithms.
You
3. Relevance Realization 
For an organismic agent, selecting an appropriate action in a given situation poses a truly 
formidable challenge. How do living systems ��� including us humans ��� even begin to tackle the 
problems they encounter in their environment, considering that they live in a large world that 
contains an indef i nite (and potentially inf i nite) number of features that may be relevant to the 
situation at hand? To address this question, we must i rst clarify what kind of environment we are 
dealing with. 
It is not simply the external physical environment that matters to the organism, but its experienced 
environment, the environment it perceives (sometimes called the organism���s umwelt; von Uexk��ll, 
1909; Thompson, 2007; Walsh, 2012a), and with which it interacts. Both paramecia and porpoises, 
for example, live in the physical substance ���water,��� but due to their enormous size difference, they 
have to deal with very distinct sensorimotor contexts concerning their propulsion through that 
physical medium (Walsh, 2015). What matters most on the minuscule scale of the paramecium is 
6 Of course, assessing outcomes and improving performance based on this kind of assessment is the fundamental 
principle of reinforcement learning in computer science (Sutton & Barto, 1998). But this only happens in a strictly 
small-world context, as the target function of the learning process must be provided externally, and the algorithm is not 
intrinsically motivated by the reinforcement. 9 
the viscosity of water. It ���digs��� or ���drills��� its way through a very syrupy medium. The porpoise, in 
contrast, needs to solve problems of hydrodynamics at a much larger scale. It experiences almost 
none of the viscosity but all the l uidity of water, hence the convergent evolution of i sh-like body 
shape and structures like l ippers that enhance its hydrodynamic properties. 
This simple example illustrates an important general point: what is relevant to an organism in its 
environment is never an entirely subjective or objective feature. Instead, it is transjective, arising 
through the interaction of the agent with the world (Vervaeke & Mastropietro, 2021a,b). In other 
words, the organism enacts, and thereby brings forth, its own world of meaning and value (Varela 
et al., 1991; Thompson, 2007; Rolla & Figueiredo, 2023). This grounds the process of relevance 
realization in a constantly changing and evolving agent-arena relationship, where ���arena��� designates 
the situated and task-relevant portion of the larger experienced environment (see Vervaeke et al., 
2017, p. 104). The question of relevance then becomes the question of how an agent manages to delimit the appropriate arena, to single out the task-relevant features of its experienced 
environment, given its specif i c situation.
ChatGPT
ChatGPT
In this section titled "Relevance Realization," the paper delves into how organisms determine relevant actions in their complex environments. Here are the main points:
Challenge of Action Selection
: Organisms face a significant challenge in selecting appropriate actions due to the vast number of potentially relevant features in their environment.
Importance of Experienced Environment
: It's not just the external physical environment that matters, but the environment as experienced and perceived by the organism (its umwelt). Different organisms experience the same physical environment in distinct ways based on their sensorimotor contexts.
Example of Paramecia and Porpoises
: Paramecia and porpoises both live in water but experience it differently due to their size difference. The paramecium deals with water's viscosity, while the porpoise interacts with its fluidity, leading to different hydrodynamic challenges.
Transjective Nature of Relevance
: The concept of relevance is neither purely subjective nor purely objective. It is "transjective," arising from the interaction of the agent with the world. This means that organisms enact and bring forth their own world of meaning and value through these interactions.
Agent-Arena Relationship
: Relevance realization is grounded in the ever-changing relationship between the agent and its environment, termed the "arena." The arena is the situated and task-relevant portion of the larger experienced environment.
Delimiting the Appropriate Arena
: The key question for relevance realization is how an agent manages to delimit the appropriate arena, identifying the task-relevant features of its experienced environment based on its specific situation.
This section highlights the dynamic and interactive process by which organisms discern relevance in their environments, emphasizing the role of the organism's perspective and interaction with its surroundings in shaping what is considered relevant.
You
For the computationalist, singling out task-relevant features is indistinguishable from problem 
solving itself, and both must be subsumed under an algorithmic frame. If we take the human 
context of scientif i c inquiry as an example, inductive, deductive, and abductive inference ��� all 
adhering to explicitly formalized logical rules ��� are generally deemed suf i cient for identifying, 
characterizing, and solving research problems (see, Roli et al., 2022, for a critical discussion). 
Similarly, the general problem solving framework by Newell and Simon (1972) delimits a problem 
formally by requiring specif i c initial and goal states, plus a set of operators (actions) used by the 
problem-solving agent to transition from the former to the latter within a given set of constraints. A 
problem solution is then def i ned as a sequence of actions that succeeds in getting the agent from 
the initial state to the attainment of its goal. The agent���s task is prescribed as solving a formal 
optimization problem that identif i es solutions to a given challenge. To a computationalist, the 
foundation of natural agency and cognition is formal problem solving. 
This kind of computational framing can be very useful. For instance, it points our attention to the 
issue of combinatorial explosion, revealing that for all but the most trivial problems, the space of 
potential solutions is truly astronomical (Newell & Simon, 1972). For problem solving to be 
tractable under real-world constraints, agents must rely on heuristics, make-shift solutions that are 
far from perfect. Unlike algorithms (strictly def i ned), they are not guaranteed to converge towards a 
correct solution of a well-posed problem in i nite time. Still, heuristics are tried and tested to work 
well enough (to satisf i ce) in a range of situations which the agent or its ancestors have 
10 
encountered in the past, or which the agent deems in some way analogous to such past 
experiences (Simon, 1956, 1957, 1989; Gigerenzer & Gaissmaier, 2011; Gigerenzer, 2021). 
This notion of bounded rationality (Simon, 1957) is illustrated by the visual metaphor of Simon���s 
scissors with two blades that have to i t together (Fig. 1, and Simon, 1990): (1) the agent���s internal 
cognitive toolbox (with its particular set of heuristics and associated limitations), and (2) an 
experienced arena with a given structure of relevant features. Put simply, heuristics must be 
adapted to the task at hand, otherwise they do not work. On top of this, the physical body with its 
peculiar physiology, morphology, and sensorimotor abilities can be added to the metaphor as the 
pivot between the two scissor blades (Fig. 1, and Mastrogiorgio & Petracca, 2016; Gallese et al., 
2020), ref l ecting the notion of embodied bounded rationality (Gallese et al., 2020; Petracca, 2021; 
Petracca & Grayot, 2023), or evolved embodied heuristics (Gigerenzer, 2021).
ChatGPT
ChatGPT
In this section, you're discussing how the computationalist perspective approaches the problem of relevance realization and the limitations of this approach. Here are the key points:
Computationalist Approach to Problem Solving
: Computationalists view identifying task-relevant features as indistinguishable from problem-solving itself, typically within an algorithmic framework. This includes reliance on formalized logical rules like inductive, deductive, and abductive inference.
Formal Problem Definition
: Computational models, like the framework by Newell and Simon, formalize problems by defining specific initial and goal states, along with a set of actions (operators) to transition between these states. Problem-solving is thus seen as finding a sequence of actions that leads to the goal.
Limitations and Heuristics
: Computational models highlight issues like combinatorial explosion, where potential solutions become astronomically large for complex problems. This necessitates reliance on heuristics ��� practical, though imperfect, solutions based on past experiences or analogies.
Bounded Rationality
: The concept of bounded rationality, introduced by Simon, suggests that agents operate with a limited set of heuristics adapted to their experiences. This concept is illustrated metaphorically with Simon���s scissors, representing the interplay between the agent's cognitive toolbox and the structure of the experienced arena.
Embodied Bounded Rationality
: Adding to this metaphor, the physical body of the agent, with its unique physiology and sensorimotor abilities, acts as the pivot between the cognitive toolbox and the experienced environment. This concept reflects the idea of embodied bounded rationality or evolved embodied heuristics.
This section highlights the computationalist view's emphasis on formal problem solving and its use of heuristics to manage the vast complexity of real-world problems. It also acknowledges the role of the physical body and past experiences in shaping how problems are approached and solved.
You
Evolved embodied heuristics can effectively reduce the problem of intractably large search spaces. 
They are indispensable tools for limited beings in large worlds, because they enable us to ignore a 
vast amount of information that is likely to be irrelevant (Brighton, 2018). Yet, they leave one central 
issue untouched: how to link the use of specif i c heuristics to the identif i cation of underlying 
relevant cues (Felin et al., 2017; Felin & Koenderink, 2022). The problem of relevance thus persists. 
One reason for this is that heuristics remain conf i ned to a small world after all. They are still 
algorithms (automated computational procedures) in the broader sense of the term. 
This reveals a vicious circularity in the argument above (Vervaeke et al., 2012; Riedl & Vervaeke, 
2022): it presupposes that an agent can turn ill-def i ned problems into problems that are def i ned 
11 
precisely enough to be tractable heuristically. There must still be a well-def i ned goal and search 
space, a set of available actions, and the agent must be able to categorize its problems to judge 
whether a given situation is analogous to contexts encountered in the past (Vervaeke et al., 2012, 
see also Hofstadter & Sander, 2013). And here lies the crux: all of this requires the agent to 
distinguish relevant features in its experienced environment ��� to circumscribe its arena ��� before it 
can apply any heuristics. In other words, embodied heuristics presuppose a solution to the problem 
that they are meant to tackle in the i rst place.
ChatGPT
ChatGPT
This section discusses the limitations of evolved embodied heuristics in the context of relevance realization:
Role of Evolved Embodied Heuristics
: These heuristics help reduce the issue of large search spaces in problem-solving, enabling organisms to ignore vast amounts of potentially irrelevant information.
Central Issue with Heuristics
: Despite their usefulness, heuristics do not address how to identify underlying relevant cues. They are still essentially algorithms, confined to a 'small world' framework.
Vicious Circularity of Heuristics
: A critical problem is the circular nature of the heuristic approach. It assumes that an agent can transform ill-defined problems into well-defined ones that are tractable through heuristics. This process requires a pre-existing understanding of the problem, including a well-defined goal, search space, and a set of possible actions.
Requirement of Distinguishing Relevant Features
: Before applying any heuristics, an agent needs to identify relevant features in its environment and define its arena. This is a prerequisite for the effective use of heuristics.
Presupposition of Heuristics
: The paper argues that embodied heuristics presuppose the solution to the problem they are meant to address. Essentially, they require an initial discernment of relevance, which they are incapable of providing by themselves.
This section highlights the inherent limitation of heuristics in addressing the problem of relevance realization, as they operate within a predefined framework and depend on a prior understanding of relevant features in the environment.
You
Algorithmic approaches to relevance realization in a large world generally get us nowhere. A i rst 
challenge is that the search space required for formal optimization usually cannot be 
circumscribed precisely because the collection of large-world features that may be relevant in a 
given situation is indef i nite: it cannot be prestated explicitly in the form of a mathematical set (Roli 
et al., 2022). Indeed, the collection of potentially relevant features may also be inf i nite, because 
even the limited accessible domain of an organism���s large world can be inexhaustibly i ne-grained, 
or because there is no end to the ways in which it can be validly partitioned into relevant features 
(Kauffman, 1971; Wimsatt, 2007). Connected to this dif i culty is the additional problem that we 
cannot def i ne an abstract mathematical class of all relevant features across all imaginable 
situations or problems, since there is no essential general property that all of these features share 
(Vervaeke et al., 2012). What is relevant is radically mutable and situation-dependent. Moreover, the 
internal structure of the class of relevant features for any particular situation is unknown (if it has 
any predef i ned structure at all): we cannot say in advance, or derive from i rst principles, how such 
features may relate to each other, and therefore cannot simply infer one from another. Last but not 
least, framing the process of relevance realization as a formal optimization problem inexorably 
leads to an inf i nite regress: delimiting the search space for one problem poses a new optimization 
challenge at the next level (how to i nd the relevant search space limits and dimensions) that 
needs a formalized search space of its own, and so on and so forth. 
Taken together, these problems constitute an insurmountable challenge for any limited being 
attempting to construct a universal formal theory of relevance for general problem solving in a 
large world. In other words, relevance realization is not completely formalizable. This makes sense 
if we consider that relevance realization is the act of formalization, of turning semantics into 
syntax, as we will outline in detail below. This is exactly how David Hilbert def i ned ���formalization��� 
for the purpose of his ultimately unsuccessful program to put mathematics on a complete and 
consistent logical foundation (Zach, 2023). Hilbert���s failure was made obvious by G��del���s 
incompleteness theorems, which state that every suf i ciently complicated formal system remains 
incomplete, because there will always be valid propositions that are true but cannot be proven 
within the existing formalism (reviewed in Nagel & Newman, 2001). If systems of mathematical 
propositions cannot be completely formalized, even in principle, is it really surprising that the large 
world we live in cannot either?
ChatGPT
ChatGPT
This section elaborates on the challenges and limitations of algorithmic approaches to relevance realization in complex environments. Here are the key points:
Indefinite and Infinite Search Space
: In a large world, the collection of features that may be relevant in a given situation is indefinite and potentially infinite. This makes it impractical to circumscribe the search space for formal optimization, as the relevant features cannot be pre-stated explicitly.
No Universal Class of Relevant Features
: There is no abstract mathematical class encompassing all relevant features across situations because there is no general property shared by all such features. Relevance is highly mutable and dependent on the specific situation.
Unknown Internal Structure of Relevant Features
: The internal structure of relevant features for any given situation is unknown or may not have a predefined structure at all. It's impossible to infer one feature from another or to derive their relationships from first principles.
Infinite Regress in Formal Optimization
: Framing relevance realization as a formal optimization problem leads to an infinite regress. Each attempt to delimit the search space for one problem creates a new challenge at the next level, requiring its own formalized search space, and so on.
Limitation of Formalization
: The act of relevance realization, turning semantics into syntax, is not completely formalizable. This concept aligns with David Hilbert's definition of formalization, which faced challenges due to G��del���s incompleteness theorems. These theorems show that every sufficiently complex formal system remains incomplete, with valid propositions that are true but cannot be proven within the system.
Implication for Understanding the Large World
: If mathematical propositions cannot be completely formalized, it is not surprising that the large, complex world we live in cannot be completely formalized either.
The section concludes that the process of relevance realization in a large world is fundamentally beyond the scope of complete formalization, presenting a significant challenge for any attempt to construct a universal formal theory of relevance for general problem-solving in such environments.
You
Once we accept that organisms live in a large world, and that this world is not fully formalizable, we 
must recognize that natural agency and cognition cannot be grounded wholly in formal problem 
solving, or any other form of algorithmic computation. Before they can attempt to solve any 
problems, organisms must i rst perform the basic task of formalizing or framing the problem they 
want to solve. Without this basic framing, it is impossible to formulate hypotheses for abductive 
reasoning or, more generally, to select actions that are appropriate to the situation at hand. 
Algorithms are unable to perform this kind of framing. By their nature, they are conf i ned to the 
syntactic realm, always operating within some given formal frame ��� their predef i ned ontology ��� 
which must be provided and precoded by an external programmer (see also Jaeger, 2023)7. This is 
true even if the framing provided is indirect and implicit, and may allow for a diverse range of 
optimization targets, as is the case in many contemporary approaches to unsupervised machine 
learning. Indeed, the inability of algorithms to frame problems autonomously has been widely 
recognized as one of the fundamental limitations of our current quest for artif i cial general 
intelligence (see, for example, McCarthy & Hayes, 1969; Dreyfus, 1972/1979; Dennett, 1984; 
Dreyfus, 1992; Cantwell Smith, 2019; Roitblat, 2020; Roli et al., 2022). Algorithms cannot, on their 
own, deal with the ambiguous semantics of a large world. 
This has some profound and perhaps counterintuitive implications. The most notable of these is 
the following: if the frame problem, def i ned in its most general form as the problem of relevance 
(Dennett, 1984; Vervaeke et al., 2012; Riedl & Vervaeke, 2022), cannot be solved within an 
algorithmic framework, yet organisms are able to realize relevance, then the behavior and evolution 
of organisms cannot be fully captured by formal models based on algorithmic frameworks. 
More specif i cally, it follows that relevance realization cannot be an algorithmic process itself: to 
avoid vicious circularity and inf i nite regress, it must be conceptualized as lying outside the realm of 
purely syntactic inferential computation (Roli et al., 2022; Jaeger, 2023). As a direct corollary, it 
must also lie outside the domain of symbolic processing8, which is embedded in the realm of 
syntax, and is therefore completely formalized just like algorithmic computation (Vervaeke et al., 
2012). Note that this does not preclude that we can superf i cially mimic or emulate the process of 
relevance realization through algorithmic simulation or formal symbolic description. Remember 
8 Note that we use ���symbolic processing��� in the broad sense of ���processing something that stands for something else by 
reason of a relation��� (Pattee & R��czaszek-Leonardi, 2012). This is not the same as the more specif i c use of the term 
���symbolic��� that characterizes an algorithm based on high-level (human-readable) problem representations, in contrast 
to subsymbolic methods that are used in artif i cial intelligence research. 
7 An algorithm can be provided with several predef i ned frames, with appropriate rules to select between them. This 
simply constitutes a larger predef i ned (meta)frame, but not the ability to truly frame one���s own problems. 
13 
that we are formulating an incompleteness argument here, which suggests that a purely 
algorithmic (syntactic) approach will never be able to capture the process of relevance realization 
in its entirety. To any limited being, there always remains some semantic residue in its large world 
that def i es precise def i nition. To make sense of such a world, natural and cognitive agents cannot 
rely exclusively on algorithmic computation or symbolic processing.
ChatGPT
ChatGPT
In this section, the paper further develops the argument against the computationalist approach to natural agency and cognition, focusing on the limitations of algorithms in relevance realization. Here are the key points:
Non-formalizability of the Large World
: Accepting that organisms live in a large world that is not fully formalizable implies that natural agency and cognition cannot be entirely grounded in formal problem-solving or algorithmic computation.
Framing as a Prerequisite to Problem-Solving
: Before solving problems, organisms must first frame or formalize these problems. Algorithms, however, are confined to operating within a predefined formal frame and cannot autonomously frame problems.
Limitations of Algorithms
: Algorithms operate within a given syntactic realm and cannot autonomously handle the ambiguous semantics of a large world. This limitation is recognized as a fundamental challenge in developing artificial general intelligence.
Implications of the Frame Problem
: If relevance realization cannot be solved algorithmically, and organisms can realize relevance, then organism behavior and evolution cannot be fully captured by formal models based on algorithmic frameworks.
Relevance Realization Beyond Algorithmic Processes
: To avoid circularity and infinite regress, relevance realization must be conceptualized outside the realm of purely syntactic computation. This extends to symbolic processing, which is also embedded in the realm of syntax and formalization.
Incompleteness of Algorithmic Approaches
: Although the process of relevance realization can be superficially mimicked or emulated through algorithmic simulation, a purely algorithmic approach will never fully capture it. There is always some semantic aspect in the large world that defies precise definition.
Beyond Algorithmic Computation and Symbolic Processing
: To make sense of their complex world, natural and cognitive agents cannot rely solely on algorithmic computation or symbolic processing.
The section concludes that the complexities of relevance realization in the natural world exceed the capabilities of formal, algorithmic models, emphasizing the need for a broader understanding of cognition and agency that transcends purely computational frameworks.
You
How, then, are we to understand relevance realization if not in terms of formal problem solving? 
One possibility is through an economic perspective (Vervaeke et al., 2012; Vervaeke & Ferraro, 
2013a,b), which frames the problem of relevance based on commitment, i.e., the dynamic 
allocation of resources by an agent to the pursuit of a range of potentially conf l icting or competing 
goals. Opponent processing is seen as a meta-heuristic approach: the agent employs a number of 
complementary or even antagonistic heuristics that are played against each other in the presence 
of different kinds of challenges and trade-offs. The trade-offs involved can be subsumed under the 
general opposition of ef i ciency vs. resilience or, more specif i cally, as generality vs. specialization, 
exploration vs. exploitation, and focusing vs. diversifying (Vervaeke et al., 2012; Andersen et al., 
2024). On this account, resource allocation is fundamentally dialectic: the agent continually 
reassesses what strategy does or does not work in a given situation, and adjusts its goals and 
priorities accordingly, which in turn affects its appraisal of progress. This leads to a situated and 
temporary adaptive i t between agent and arena, which is continuously updated according to the 
experienced environment, anticipated outcomes of actions, and the inner state of the agent. 
Overall, it accounts for the context-specif i c nature of relevance realization in terms of localized 
adaptive dynamics.
ChatGPT
ChatGPT
In this section, the paper proposes an alternative understanding of relevance realization, moving away from formal problem solving and towards an economic perspective:
Economic Perspective on Relevance Realization
: This approach conceptualizes relevance realization in terms of commitment and the dynamic allocation of resources by an agent. It's about how an agent allocates its resources towards competing or conflicting goals.
Opponent Processing as a Meta-Heuristic
: Here, the agent uses a variety of complementary or antagonistic heuristics that are pitted against each other. This happens in response to different challenges and involves trade-offs.
Trade-Offs in Decision Making
: Trade-offs are key to this process and can be categorized as efficiency vs. resilience, generality vs. specialization, exploration vs. exploitation, and focusing vs. diversifying. These trade-offs reflect the agent's ongoing adjustments to its strategies.
Dialectic Resource Allocation
: The allocation of resources is seen as a dialectic process. The agent continually reassesses and adjusts its strategies based on the effectiveness in a given situation. This includes reevaluating goals, priorities, and the agent's perception of progress.
Situated and Temporary Adaptive Fit
: The agent's alignment with its environment is characterized as a situated and temporary adaptive fit. This fit is continuously updated in response to changes in the environment, anticipated outcomes, and the agent���s internal state.
Context-Specific Nature of Relevance Realization
: The economic perspective accounts for the context-specific nature of relevance realization. It emphasizes localized adaptive dynamics, highlighting how relevance realization varies according to the specific situation and needs of the agent.
This economic perspective provides a framework for understanding relevance realization as an adaptive, context-dependent process involving continuous assessment and reallocation of resources based on changing environmental conditions and internal states of the agent.
You
Such high-level adaptive dynamics can be embedded in a physical context through the notion of 
predictive processing (Friston, 2010, 2013; Clark, 2013; Hohwy, 2014; Clark, 2015; Colombo & 
Wright, 2021; Andrews, 2021; Seth, 2021; Andersen et al., 2024). Predictive processing means that 
an agent iteratively and recursively evaluates the relevance of its sensory input through the 
estimation of prediction errors. It does this by measuring the discrepancy between expectations 
based on its internal models of the world (see section 5) and the sensory feedback it receives from 
its interactions within its current arena. Higher weights are assigned to input with low prediction 
errors, while perceptions with persistent larger errors are preferentially discounted. Particular 
importance is attributed to error dynamics, the selection of actions and cognitive strategies that 
rapidly reduce prediction errors in a particular stream of sensory input (Friston et al., 2012; 
Kiverstein et al., 2019; Andersen et al., 2024). Predictive processing can ground the economic 
account of relevance realization by connecting it to the underlying perceptual and cognitive 
processes that account for the dynamic and recurrent weighing of prediction errors. 
14 
For our present purposes, however, both of these accounts exhibit several signif i cant limitations. 
The economic account was developed specif i cally in the context of human cognition, and it is not 
entirely clear whether it can be generalized beyond that scope. It takes agency (even intention) for 
granted without providing a naturalistic justif i cation for that assumption. The commitment of 
resources in the economic account, and the assignment of precision weights in predictive 
processing, presuppose that the agent has intrinsic goals in relation to which such actions can be 
taken (Andersen et al., 2022). This presupposition may be acceptable in the context of human 
cognition, with its evident and explicit intentionality, but poses a serious challenge for generalizing 
relevance realization to the domain of non-human and (even more so) non-cognitive living beings. 
On top of all this, both the economic account and formalized versions of predictive processing 
remain embedded in a thoroughly computationalist framework that views the allocation of 
relevance (and hence resources or precision weights) as a simple iterative and recursive 
algorithmic process. This begs the question where organismic goals come from in the i rst place, 
and how anticipated outcomes can affect the strategies and actions chosen. For these reasons, we 
will take a different route, with the aim of grounding the process of relevance realization in the 
basic organization of living beings and the kind of agent-arena relationship this organization 
entails. Our approach is not intended to oppose the economic account or the account based on 
predictive processing, but rather to ground them in the natural sciences with the aim of extending 
relevance realization beyond human cognition and intentionality. It is an evolutionary view of 
relevance realization, which also provides an explanation of why it is that the process cannot be 
completely captured by a purely syntactic or algorithmic approach.
ChatGPT
ChatGPT
In this section, the paper explores how the high-level adaptive dynamics of relevance realization can be understood in a physical context, particularly through predictive processing. It also discusses the limitations of current models and proposes a new approach:
Predictive Processing
: This concept involves an agent iteratively evaluating the relevance of sensory input by estimating prediction errors. It measures the discrepancy between expectations from internal models and actual sensory feedback. Inputs with low prediction errors are given higher weight, while those with larger errors are discounted.
Importance of Error Dynamics
: Error dynamics, involving actions and cognitive strategies that reduce prediction errors in sensory input, are crucial in predictive processing. This approach can ground the economic account of relevance realization by linking it to perceptual and cognitive processes.
Limitations of Existing Models
: The economic perspective, while insightful for human cognition, may not generalize well beyond this scope. It assumes agency and intention without a naturalistic justification. Similarly, the predictive processing model presupposes intrinsic goals, which can be problematic when applied to non-human or non-cognitive living beings.
Computationalist Framework Limitations
: Both the economic and predictive processing models remain within a computationalist framework. They treat the allocation of relevance, resources, or precision weights as an iterative, recursive algorithmic process. This approach fails to address the origins of organismic goals and how anticipated outcomes influence strategies and actions.
Proposed Evolutionary Approach
: The paper suggests an alternative route that grounds relevance realization in the basic organization of living beings and the agent-arena relationship. This approach aims to extend the concept of relevance realization beyond human cognition and intentionality, providing an evolutionary explanation for why it cannot be fully captured by syntactic or algorithmic methods.
The section concludes by emphasizing the need for a broader understanding of relevance realization that is rooted in the natural organization of life, moving beyond the limitations of current computationalist and human-centered models.
You
4. Biological Organization and Natural Agency 
The ability to solve the problem of relevance crucially relies on an agent setting intrinsic goals. 
Therefore, we i rst need to demonstrate that all organisms can def i ne and pursue their own goals 
without requiring any explicit intentionality, cognitive capabilities, or consciousness. Such basic 
natural agency does not primarily rely on causal indeterminacy or randomness. Instead, it rests in 
the peculiar self-referential and hierarchical causal regime that underlies the organization of living 
matter (see, for example, Rosen, 1958a, 1958b, 1959; Piaget, 1967; Rosen, 1972; Varela et al., 1974; 
Varela, 1979; Maturana & Varela, 1980; Rosen, 1991; Juarrero, 1999; Kauffman, 2000; Thompson, 
2007; Barandiaran et al., 2009; Louie, 2009; Deacon, 2011; Louie, 2013; Moreno & Mossio, 2015; 
Mont��vil & Mossio, 2015; Mossio & Bich, 2017; Louie, 2017a; DiFrisco & Mossio, 2020; Hofmeyr, 
2021; Harrison et al., 2022; Juarrero, 2023; K. Mitchell, 2023; Mossio, 2024a).
ChatGPT
ChatGPT
In this section titled "Biological Organization and Natural Agency," the paper discusses the foundation of natural agency in the context of biological organization:
Intrinsic Goals of Organisms
: The ability to solve the problem of relevance is closely linked to an agent's capacity to set intrinsic goals. It's argued that all organisms, regardless of explicit intentionality, cognitive capabilities, or consciousness, can define and pursue their own goals.
Basis of Natural Agency
: Natural agency doesn't primarily depend on causal indeterminacy or randomness. Instead, it is based on the unique self-referential and hierarchical causal regime that characterizes the organization of living matter.
Self-Referential and Hierarchical Causal Regime
: This regime refers to the way living systems are organized and how they interact with their environment. The paper cites numerous scholars and works that have explored this concept, emphasizing the complexity and uniqueness of living systems.
Organizational Distinctiveness of Living Matter
: The cited works collectively highlight the distinctiveness of living matter compared to non-living systems. This distinctiveness is what enables organisms to set and pursue their own goals, forming the basis of natural agency.
This section of the paper establishes that natural agency is fundamentally rooted in the unique organizational characteristics of living beings. It underscores that living organisms inherently possess the ability to set their own goals, which is essential for relevance realization and distinguishes them from non-living systems.
You
This peculiar organization of living matter is both the source and the outcome of the capacity of a 
living cell or multicellular organism to self-manufacture (Hofmeyr, 2021). Life is what life does. A 
free-living cell, for example, must be able to produce all its required macromolecular components 
from external sources of matter and energy, must render these components functional through 
constant maintenance of a suitable and bounded internal milieu, must assemble functional 
components in a way that upholds its self-maintaining and self-reproducing abilities throughout its 
life cycle and, if we want it to evolve, must pass this integrated functional organization on to future 
generations via reproduction with some form of reliable but imperfect heredity (Saborido et al., 
2011; Hofmeyr, 2021; Jaeger, 2024a; Pontarotti, 2024). This process of self-manufacture is 
encapsulated by the abstract concept of autopoiesis (Varela et al., 1974; Varela, 1979; Maturana & 
Varela, 1980; Thompson, 2007), which emphasizes the core ability of a living system to 
self-produce and maintain its own boundaries. 
Biological organization emerged at the origin of life, and is therefore shared among all organisms, 
from bacteria to plants to fungi to animals to humans. In fact, some of us have argued previously 
that it is a fundamental prerequisite for biological evolution by natural selection (see Walsh, 2015; 
Jaeger, 2019, 2023c, for details). As far as anyone knows, this kind of organization is unique to 
organisms.Nothingequivalentexistsanywhereoutsidetherealmof the living. While 
self-organizing physical processes, such as candle l ames, convection currents (B��nard cells), 
turbulent water l ows, or hurricanes, share some important properties with living systems, 
including the temporary reduction of entropy at the cost of the local environment, they are not able 
to self-manufacture in the sense described above (Kauffman, 2000; Deacon, 2011; Djedovic, 2020; 
Hofmeyr, 2021).
ChatGPT
ChatGPT
This section delves deeper into the unique organization of living matter and its implications for biological agency:
Self-Manufacture as a Defining Feature of Life
: The ability to self-manufacture is essential to living cells or multicellular organisms. This includes producing necessary macromolecular components, maintaining functional internal environments, and ensuring self-maintenance and reproduction across generations.
Concept of Autopoiesis
: Autopoiesis encapsulates the core ability of a living system to self-produce and maintain its own boundaries, highlighting the self-sustaining nature of biological organisms.
Biological Organization from the Origin of Life
: This type of organization emerged with the origin of life and is a common feature across all forms of life, from bacteria to humans. It's argued to be a fundamental prerequisite for biological evolution by natural selection.
Uniqueness of Biological Organization
: Biological organization, as it occurs in living organisms, is unique and has no equivalent in non-living systems. While certain self-organizing physical processes (like candle flames or hurricanes) share properties with living systems, such as temporary entropy reduction, they lack the capability for self-manufacture as seen in biological organisms.
The section emphasizes that the self-manufacturing ability of living organisms is a distinctive and defining characteristic that sets them apart from non-living systems. This ability underpins the biological organization and is fundamental to understanding natural agency and biological evolution.
You
Two aspects of biological organization are particularly important here. First, note that functional 
organization is not the same as physical structure: the capability to self-manufacture does not 
coincide with any specif i c arrangement of material parts, nor does it correspond to any i xed 
pattern of interacting processes (cf. Rosen, 1991; Louie, 2009). Instead, the systemic pattern of 
interactionsthatconstitutes biological organization is fundamentally l uid and dynamic: 
connections between components constantly change ��� in fact, have to change ��� for the capacity 
to self-manufacture to be preserved (see, for instance, Deacon, 2011; DiFrisco & Mossio, 2020; 
Hofmeyr, 2021; Jaeger, 2024a). 
Second, at the heart of all contemporary accounts of biological organization lies the concept of 
organizational closure (see, Letelier et al., 2011; Moreno & Mossio, 2015; Cornish-Bowden & 
C��rdenas, 2020; Mossio, 2024b, for reviews). Organizational closure is a peculiar relational pattern 
of collective dependence between the functional components of a living system: each component 
16 
process must be generated by, and must in turn generate, at least one other component process 
within the same organization (Mont��vil & Mossio, 2015; Moreno & Mossio, 2015; Mossio et al., 
2016). This means that individual components could not operate ��� or even exist ��� without each 
other. Let us illustrate this central concept using two complementary approaches. 
One useful way to think about biological organization is to separate the underlying processes 
(physico-chemical l ows) from the higher-level constraints that impinge on them by reducing their 
dynamical degrees of freedom (Juarrero, 1999; Deacon, 2011; Pattee & R��czaszek-Leonardi, 2012; 
Mont��vil & Mossio, 2015; Mossio et al., 2016; Juarrero, 2023). Constraints arise through the 
interactions between the component processes that make up the living system. Like the underlying 
l ows, they are dynamic, but change at different time scales. Constraints can thus be formally 
described as boundary conditions imposed on the underlying dynamics. An enzyme is a good 
example of a constraint: it alters the kinetics of a biochemical reaction without itself being altered 
in the process.
ChatGPT
ChatGPT
This section focuses on two crucial aspects of biological organization relevant to understanding natural agency:
Distinction between Functional Organization and Physical Structure
: The capacity for self-manufacture in living organisms is not tied to a specific arrangement of material parts or a fixed pattern of processes. Instead, biological organization is characterized by fluid and dynamic systemic patterns of interaction. These connections between components are constantly changing, which is essential for maintaining the ability to self-manufacture.
Concept of Organizational Closure
: At the core of biological organization is the concept of organizational closure. This refers to a unique relational pattern where each functional component of a living system is both generated by and helps generate other components within the same system. This interdependence means that individual components cannot operate or exist independently of each other.
To further elucidate these points:
Processes vs. Constraints
: Biological organization can be understood by differentiating between underlying physico-chemical processes and higher-level constraints that influence these processes. Constraints arise from interactions between components of the living system and are dynamic, albeit changing at different time scales compared to the underlying flows. They can be thought of as boundary conditions imposed on the dynamics of the system.
Example of Enzymes
: Enzymes serve as an example of such constraints. They alter the kinetics of biochemical reactions without being altered themselves, demonstrating how constraints operate within biological systems.
These insights into biological organization provide a deeper understanding of the complex and interdependent nature of living systems, highlighting how this organization is fundamentally different from non-living systems and essential for the concept of natural agency.
You
We can now conceptualize organizational closure as the closure of constraints (Mont��vil & Mossio, 
2015): the organism-level pattern of constraints restricts and channels the dynamics of the 
underlying processes in such a way as to preserve the overall pattern of constraints. Evidently, 
organizational closure is causally circular: it is a form of self-constraint (Juarrero, 1999; Mont��vil & 
Mossio, 2015; Juarrero, 2023). In this way, the organization of the system becomes the cause of its 
own relative stability: this is what equips an organism with identity and individuality (Deacon, 2011; 
Moreno & Mossio, 2015; Mont��vil & Mossio, 2015; Mossio et al., 2016; DiFrisco & Mossio, 2020). 
Organizational closure requires thermodynamic openness: it only occurs in physical systems that 
operate far from equilibrium. The basic reason for this is that the organism must constantly 
produce work by harvesting some entropy gradient in its environment to regenerate, repair, and 
replenish its set of constraints (Kauffman, 2000; Deacon, 2011). This leads to organizational 
continuity (DiFrisco & Mossio, 2020; Mossio & Pontarotti, 2020; Pontarotti, 2024). To revisit our 
previous example, think of all the enzymes in a living cell, enabling a set of interrelated biochemical 
l ows that lead to macromolecular synthesis and the continued replenishment of the pool of 
enzymes. This requires physical work (driven by ATP-dephosphorylation, and other exergonic 
reactions). Note that enzyme concentrations need not be kept constant over time. They only have 
to remain within the less stringent boundaries that ensure the future preservation of overall 
metabolic l ow. Metabolic l ow can (and indeed must) change adaptively in response to 
environmental conditions and the internal requirements of the organism, but if it ceases to repair 
and replenish itself, the organism dies.
ChatGPT
ChatGPT
This section further elaborates on the concept of organizational closure in biological systems, emphasizing its role in maintaining the identity and individuality of an organism:
Organizational Closure as Closure of Constraints
: Organizational closure is conceptualized as the closure of constraints within an organism. The pattern of constraints at the organism level restricts and channels the dynamics of underlying processes to preserve the overall pattern. This causal circularity is a form of self-constraint.
Self-Constrained Stability and Identity
: The self-constrained nature of organizational closure is what gives an organism its relative stability, identity, and individuality. It's a fundamental characteristic that distinguishes living organisms from non-living systems.
Thermodynamic Openness Requirement
: Organizational closure requires a system to operate far from equilibrium, meaning it must be thermodynamically open. This openness allows the organism to produce work by exploiting entropy gradients in its environment, which is essential for regenerating, repairing, and replenishing its constraints.
Organizational Continuity Through Work Production
: Continuous work production is necessary for the maintenance and adaptation of metabolic flows within an organism. This involves processes like ATP-dephosphorylation and other exergonic reactions.
Example of Enzymes and Metabolic Flow
: The example of enzymes in a living cell illustrates this concept. Enzymes enable interrelated biochemical flows leading to macromolecular synthesis and continuous replenishment of the enzyme pool. While enzyme concentrations may vary, they must stay within boundaries that ensure the preservation of overall metabolic flow.
Adaptability and Survival
: Metabolic flow must adapt to environmental conditions and internal requirements. If it fails to repair and replenish itself, the organism ceases to survive.
In summary, this section highlights the complexity of biological organization, focusing on how the self-constraint of organizational closure and thermodynamic openness contribute to the ongoing survival and adaptability of living organisms.
You
A more formal and abstract way to think about biological organization is Robert Rosen���s relational 
theory of metabolism-repair (M,R)-systems (Rosen, 1958a, 1958b, 1959, 1972, 1991), and its recent 
ref i nement to fabrication-assembly (F,A)-systems (Hofmeyr, 2021). It treats biological organization 
in the rich explanatory context of Aristotle���s four ���causes,��� or aitia (Rosen, 1991; Louie, 2009, 2013, 
2017a). Aitia go beyond our restricted sense of ���causality��� in the modern scientif i c sense. They 
correspond to different ways of answering ���why��� questions about some natural phenomenon 
(Falcon, 2023). As an example, take a marble sculpture depicting Aristotle: its material cause is the 
marble it is made of, its formal cause is what makes it a sculpture of Aristotle (and not of anyone 
else), its ef i cient cause is the sculptor wielding their tools to produce the sculpture, and its i nal 
cause is the sculptor���s intention to make a statue of Aristotle. 
Using the (meta)mathematical tool of category theory, Rosen constructs a rigorous formal 
framework that distinguishes material causes (physico-chemical l ows) from their processors, 
which are the ef i cient causes generating the particular dynamics that characterize a living system 
(Rosen, 1991, later extensively ref i ned by Louie, 2009, 2013, 2017a). Thinking of enzymes again as 
possible examples of ef i cient causes, we can see that this distinction is similar in spirit, but not 
equivalent, to the separation of processes and constraints above. Constraints, as we shall see, not 
only incorporate aspects of ef i cient but also of formal cause. 
Rosen���s central insight is that his (M,R)-system models are open to material (and energy) l ows but 
are closed to ef i cient causation (Rosen, 1991; Louie, 2009, 2013, 2017a)9. This is a form of 
organizational closure, meaning that each processor has as ef i cient cause another processor 
within the organization of the system. Formally, each processor must be part of a hierarchical cycle 
of ef i cient causation (ibid.). Such cycles represent a type of self-referential circularity that Rosen 
calls immanent causation, which represents more than mere cybernetic feedback, the latter being 
restricted to material causes (i.e., hierarchically ���f l at���) and only generating circular material l ows. 
Hierarchical cycles, in contrast, consist of nested cycles of interacting processors that preserve 
their own pattern of interrelations over multiple scales of space and time (ibid.). As an example, 
recall the circular multi-level relationship between intermediate metabolism/macromolecular 
biosynthesis, the internal milieu, and the regulated permeability of the boundaries of a living cell 
that enable its self-manufacturing capability (Fig. 2, and Hofmeyr, 2017, 2021). 
9 There is a debate to be had whether Rosen muddles up Aristotelian ef i cient and formal causes. We will revisit this 
problem when discussing Hofmeyr���s elaboration of Rosen���s model below. In the meantime, to avoid confusion, we will 
stick with Rosen���s own terminology in our description of his work.
ChatGPT
ChatGPT
This section introduces Robert Rosen's relational theory of metabolism-repair (M,R)-systems and its refinement into fabrication-assembly (F,A)-systems, framing biological organization in the context of Aristotle���s four causes:
Aristotle's Four Causes
: Aristotle's concept of causes (aitia) includes material, formal, efficient, and final causes. These causes offer different ways of explaining phenomena, each answering "why" questions from various perspectives. The example of a marble sculpture of Aristotle is used to illustrate these causes: the material cause (marble), the formal cause (the form of Aristotle), the efficient cause (the sculptor), and the final cause (the sculptor's intention).
Category Theory in Rosen's Model
: Using category theory, Rosen constructs a formal framework distinguishing material causes (physico-chemical flows) from efficient causes (processors generating dynamics in a living system). This distinction is akin to but not identical to the earlier discussed separation of processes and constraints.
Organizational Closure in Rosen's Model
: Rosen's (M,R)-systems are open to material and energy flows but closed to efficient causation. Each processor within the system's organization acts as an efficient cause for another, forming a hierarchical cycle of efficient causation. This self-referential circularity, termed "immanent causation," goes beyond cybernetic feedback.
Hierarchical Cycles and Self-Referential Circularity
: These cycles represent nested interactions of processors across multiple scales, preserving their pattern of interrelations. This concept is illustrated with the multi-level relationship between metabolism, internal milieu, and cell boundary permeability, which enable a cell's self-manufacturing capability.
Debate on Rosen���s Interpretation of Causes
: There's a discussion on whether Rosen conflated Aristotelian efficient and formal causes. The section notes that it will adhere to Rosen's terminology for the time being.
The section provides a formal and abstract approach to understanding biological organization, highlighting Rosen's significant contribution to conceptualizing the self-referential and hierarchical nature of living systems.
You
Figure 2: The triadic dialectic underlying cellular self-manufacture. 
As a consequence of this hierarchical circularity, ef i cient cause coincides with i nal cause in living 
systems (Rosen, 1991). This is precisely what is meant by autopoiesis or self-manufacture: the 
primary and most fundamental goal of an organism is to keep on producing itself. Biological 
organization is intrinsically and unavoidably teleological in this specif i c and well-def i ned sense 
(Deacon, 2011; Mossio & Bich, 2017). We will discuss the wider consequences of introducing this 
particular kind of i nality into the study of biological systems in the Conclusions. For now, let us 
simply assure the reader that it leads to none of the dif i culties usually associated with teleological 
explanation (as argued in detail in Walsh, 2015). 
Hofmeyr extends Rosen���s mathematical methodology in a number of crucial aspects. First, he 
integrates the missing formal cause into Rosen���s framework: its role is to determine the specif i c 
functional form of each ef i cient processor and/or material l ow (Hofmeyr, 2018, 2021). It is in this 
precise sense that the notion of ���constraint��� includes aspects of both formal and ef i cient cause. 
With this tool in hand, we can now extend Rosen���s framework and map it explicitly onto the cellular 
processes involved in self-manufacture ��� intermediary metabolism/macromolecular biosynthesis, 
maintenance of the internal milieu, and transmembrane transport (Fig. 2, and Hofmeyr, 2017, 
2021). The resulting model is called a fabrication-assembly (F,A)-system to ref l ect the fact that 
self-manufacture consists of two fundamental aspects: self-fabrication of required components, 
plus their self-assembly into a functional whole (Hofmeyr, 2007, 2017, 2021). 
(F,A)-systems highlight a number of features of biological organization that are not evident from 
Rosen���s original account.
ChatGPT
ChatGPT
In this section, the paper discusses the implications of hierarchical circularity in biological systems and Hofmeyr's extension of Rosen's framework:
Efficient Cause and Final Cause in Living Systems
: In living systems, efficient cause (the cause of an action) coincides with the final cause (the purpose or goal of an action). This alignment is central to the concept of autopoiesis or self-manufacture, where the primary goal of an organism is to continually produce itself. This makes biological organization inherently teleological in a specific and well-defined way.
Teleological Nature of Biological Organization
: The teleological aspect of biological organization, as outlined here, doesn't lead to the typical difficulties associated with teleological explanations. It's argued that this perspective is crucial for understanding biological systems.
Hofmeyr's Extension of Rosen���s Framework
: Hofmeyr integrates the concept of formal cause into Rosen���s mathematical methodology. The formal cause determines the specific functional form of each efficient processor or material flow. This integration means that constraints in biological systems include aspects of both formal and efficient causes.
Concept of Fabrication-Assembly (F,A)-Systems
: Hofmeyr���s model, termed F,A-systems, explicitly maps Rosen���s framework onto cellular processes involved in self-manufacture. This includes intermediary metabolism/macromolecular biosynthesis, maintenance of the internal milieu, and transmembrane transport. F,A-systems reflect that self-manufacture comprises both the self-fabrication of components and their self-assembly into a functional whole.
New Insights from F,A-Systems
: F,A-systems reveal aspects of biological organization not evident in Rosen���s original account. These systems provide a more detailed understanding of the intricate processes involved in the self-manufacture and organization of living cells.
The section emphasizes the complex, self-referential, and goal-oriented nature of biological organization. It shows how the concepts of autopoiesis and F,A-systems contribute to a deeper understanding of the inherent teleology in living organisms.
You
First of all, one of the major ef i cient causes of the model (the interior 
milieu) exists only at the level of the whole living system (or individual cell), and cannot be reduced 
or localized to any subset of component processes (Hofmeyr, 2007, 2017). If it wasn���t already clear 
before: biological organization is an irreducible systems-level property. This is perhaps why it is so 
dif i cult to study with purely reductionist analytical approaches (but see Jaeger, 2024b). 
Second, (F,A)-systems are closed to ef i cient cause but open to formal causation. This means that 
the specif i c form of their processors and l ows constantly changes while still maintaining 
organizational closure (Hofmeyr, 2021). This enables physiological and evolutionary adaptation by 
introducing heritable variability to Rosen���s formalism. It links the fundamental biological principles 
of organization and variability in a way that is not possible with the less ref i ned distinction between 
processes and constraints (cf. Mont��vil et al., 2016; Soto et al., 2016; Jaeger, 2024a). We will revisit 
this topic in section 6, when we start focusing on ecology and evolution. 
Finally, due to overall closure all ef i cient causes in the (F,A)-model are part of hierarchical cycles 
with the mathematical property of being self-referential in the sense of being collectively 
impredicative, which means that the processors involved mutually def i ne and generate each other, 
and thus cannot exist in isolation (Hofmeyr, 2021). This leads to an apparent paradox: without 
these processors all being present at the same time, already interacting with each other, none of 
them can ever become active in the i rst place. To compare and contrast it with Turing���s (1937) 
halting problem, Hofmeyr calls this kind of deadlock the starting problem of biological systems. 
With this conceptual toolkit in hand, we can now revisit and ref i ne the distinction between living 
and non-living systems, in order to better understand why the self-manufacturing organization of 
living matter cannot be fully formalized or captured by algorithmic computation. Rosen frames this 
problem in terms of complexity (Rosen, 1991, see also Louie, 2009; Louie & Poli, 2017; Hofmeyr, 
2021). He (re)def i nes a complex system through the presence of at least one hierarchical cycle 
among its functional components, while the category of simple systems comprises all those that 
are not complex (Rosen, 1991; Louie, 2009). Rosennean complex systems include living cells and 
organisms, plus systems that contain them (such as symbioses, ecologies, societies, and 
economies). This contrasts with more familiar def i nitions of ���complexity���, which rely on the 
number, nonlinearity, and heterogeneity of (interactions among) system components, on the 
presence of emergent properties, and/or on the algorithmic incompressibility of simulated system 
dynamics. Such def i nitions result in graded rather than categorical differences in the complexity of 
living vs. non-living systems (see, for example, Mitchell, 2009; Ladyman & Wiesner, 2020).
ChatGPT
ChatGPT
In this section, the paper delves into the unique characteristics of fabrication-assembly (F,A)-systems, which represent a sophisticated model of biological organization:
Irreducibility of Biological Organization
: Biological organization is a systems-level property that cannot be reduced to or localized within a subset of component processes. This irreducibility challenges purely reductionist analytical approaches, highlighting the need for a systems-level perspective.
Efficient Causes and Formal Causation in (F,A)-Systems
: These systems are closed to efficient causation but open to formal causation. This openness allows for the continual change in the form of processors and flows while maintaining organizational closure, facilitating physiological and evolutionary adaptation.
Incorporation of Variability
: By being open to formal causation, (F,A)-systems introduce heritable variability into Rosen���s formalism, effectively linking biological principles of organization and variability in a novel way.
Self-Referential Hierarchical Cycles
: The efficient causes in (F,A)-systems form hierarchical cycles with the property of being collectively impredicative. In these systems, processors mutually define and generate each other, making their existence interdependent and unable to exist in isolation.
Starting Problem in Biological Systems
: Hofmeyr identifies a 'starting problem' akin to Turing���s halting problem. This problem highlights the paradox where processors in a biological system must all be present and interacting for any of them to become active.
Distinction Between Living and Non-Living Systems
: Rosen's approach to defining complex systems is based on the presence of at least one hierarchical cycle among its functional components. In contrast, common definitions of complexity focus on component number, nonlinearity, and emergent properties. Rosen's definition categorically distinguishes living systems (complex) from non-living systems (simple).
Inability to Fully Formalize Living Systems
: The complex nature of living systems, as defined by Rosen, implies that they cannot be fully formalized or captured by algorithmic computation. This contrasts with graded definitions of complexity, which do not make a categorical distinction between living and non-living systems.
This section underscores the sophistication and interdependency inherent in biological organization and the challenges it presents to conventional computational and reductionist approaches. It also highlights the distinctive nature of living systems as complex entities in Rosen's framework.
You
Based on his categorical distinction between simple and complex systems, Rosen derives his most 
famous conjecture (Rosen, 1991; Louie, 2009, 2013, 2017a): he shows, in a mathematically 
rigorous manner, that only simple systems can be captured completely by analytical (algorithmic) 
models, while any characterization of complex systems in terms of computation must necessarily 
remain incomplete. This closely relates to our claims concerning the formalization of relevance 
realization from section 3. Rosen���s, like ours, is an incompleteness argument analogous to G��del���s 
proof in mathematics. It says that it may well be possible to approximate aspects of biological 
organization through algorithmic simulation, but it will never capture the full range of dynamic 
behaviors or the evolutionary potential of a living system completely. If true, this implies that the 
strong Church-Turing conjecture (or principle) ��� claiming that all physical processes in nature 
must be computable (Deutsch, 1985, 1997; Lloyd, 2006; see section 2) ��� is false, since biological 
organization provides a clear counterexample of a physical process that cannot be captured fully 
by computation. 
Here, we extend and recontextualize Rosen���s conjecture to arrive at an even stronger claim: it no 
longer makes sense to ask if organisms are computable if they are not formalizable in the i rst place. 
While discussions about computability focus on our limited ability to predict organismic behavior 
and evolution, our argument about formalization reveals even deeper limitations concerning our 
ability to explain living systems. 
To recognize these limitations for what they are, we need to return to the matter of intrinsic goals. 
Once a living system is able to maintain organizational continuity through self-constraint or 
immanent causation, it starts exhibiting a certain degree of self-determination (Mossio & Bich, 
2017). In other words, it becomes autonomous (Moreno & Mossio, 2015) because, ultimately, the 
process of maintaining closure must be internally driven. Even though the environment is a 
necessary condition for existence (not just as a source of food and energy, as we shall see in 
section 6), an organism does not behave in a purely reactive manner with regard to external inputs. 
Instead, future states of the system are dynamically presupposed by its own inherent organization 
at earlier points in time (Bickhard, 2000). This is exactly what we mean when we say an organism 
is its own i nal cause. If organizational continuity ceases, the organism dies and is thus no longer a 
living system10. It still engages in exchange with its environment (e.g., by getting colonized by 
saprophages), but the inner source of its aliveness is gone. According to Rosen, it has made the 
transition from complex to simple. Complexity, therefore, originates from within. And it remains 
opaque to any external observer, forever beyond full formalization. 
10 Actually, the situation is a bit more subtle than that, as argued by Egbert & Barandiaran (2011). Using a minimalistic 
metabolic model of self-manufacture and agency, they show that between the dynamic regimes of ���being 
(meta)stably alive��� and ���being dead��� lies a precarious zone in which the system is slowly dying, but still alive for a 
limited amount of time.
ChatGPT
ChatGPT
In this section, Rosen's work on complex systems and its implications for understanding biological organization are further explored:
Rosen���s Conjecture on Simple and Complex Systems
: Rosen argues that simple systems can be completely captured by analytical (algorithmic) models, whereas complex systems, such as living organisms, cannot be fully characterized by computation. This idea aligns with the paper���s earlier arguments about the formalization of relevance realization.
Incompleteness of Algorithmic Models for Complex Systems
: Rosen's conjecture, analogous to G��del���s incompleteness proof in mathematics, suggests that while aspects of biological organization can be approximated through algorithmic simulation, they can never fully capture the dynamic behaviors and evolutionary potential of living systems.
Challenge to the Strong Church-Turing Conjecture
: If true, Rosen's conjecture contradicts the strong Church-Turing conjecture, which claims that all physical processes are computable. Biological organization presents a counterexample of a physical process that cannot be fully captured by computation.
Beyond Computability to Formalizability
: The paper extends Rosen���s conjecture to argue that it is not just a question of whether organisms are computable, but whether they are formalizable at all. This perspective highlights deeper limitations in explaining living systems, not just predicting their behavior.
Organisms as Autonomous Systems with Intrinsic Goals
: Once a living system maintains organizational continuity through self-constraint, it exhibits a degree of self-determination and becomes autonomous. The organism's future states are dynamically presupposed by its inherent organization.
Organisms as Their Own Final Cause
: When organizational continuity ceases, the organism dies. While it may still physically interact with the environment, its internal source of "aliveness" is lost, marking a transition from complex to simple in Rosen���s terms.
Complexity as an Inherently Internal Feature
: Complexity in living systems is seen as originating from within and remaining opaque to external observers, forever beyond full formalization.
Dynamic Regimes of Life and Death
: The paper notes a more subtle situation between being alive and dead, where a system may be in a precarious state of slowly dying but still alive for a limited time.
This section emphasizes the inherent complexity and autonomy of living systems, arguing that their organizational and evolutionary dynamics cannot be fully captured by formal, algorithmic models. It underscores the uniqueness of biological organization and the limitations of external computational approaches in fully understanding living systems.
You
Taken together, all of the above def i nes in a minimal account of what it means for an organism to 
act for its own reasons, on its own behalf (Kauffman, 2000; Mitchell, 2023): basic natural agency is 
characterized by the ability to def i ne and attain the primary and principal goal of all living beings ��� 
to keep themselves alive. This is achieved through the process of autopoiesis or self-manufacture, 
implemented by a self-referential, hierarchical, and impredicative causal regime that realizes 
organizational closure. This simple model, which is completely compatible with the known laws of 
physics, provides a naturalistic proof of principle that organisms can (and indeed do) pursue at the 
very least one fundamental goal: to continue their own existence. It accounts for the organism���s 
fundamental constitutive autonomy (Moreno & Mossio, 2015). But this is not enough. What we 
need to look at next is another important dimension of an organism���s behavior: its agent-arena 
relations, which are guided by a kind of interactive autonomy (Moreno & Mossio, 2015; Vervaeke et al., 2017). A full-blown account of natural agency requires both organizational and ecological 
dimensions. The latter will be the topic of the next two sections.
ChatGPT
ChatGPT
This summary section encapsulates the key arguments made so far about the nature of natural agency in organisms:
Basic Natural Agency
: Organisms exhibit basic natural agency characterized by their ability to define and achieve the primary goal of all living beings ��� self-preservation. This goal is fundamental to their existence.
Autopoiesis and Self-Manufacture
: The process of autopoiesis, or self-manufacture, is central to how organisms maintain their existence. This process operates through a self-referential, hierarchical, and impredicative causal regime that achieves organizational closure.
Compatibility with Physical Laws
: The model of natural agency presented is fully compatible with known laws of physics, providing a naturalistic framework for understanding how organisms inherently pursue the fundamental goal of continuing their existence.
Constitutive Autonomy
: This approach to understanding organisms underscores their constitutive autonomy, a fundamental aspect of their natural agency as living systems.
Need for an Interactive Autonomy Perspective
: While constitutive autonomy is crucial, it's not the only dimension of an organism's behavior that needs consideration. The paper suggests that understanding natural agency also requires examining agent-arena relations, guided by interactive autonomy.
Organizational and Ecological Dimensions
: A comprehensive account of natural agency encompasses both organizational (internal self-maintenance) and ecological (interaction with the environment) dimensions. These aspects are key to understanding the full spectrum of natural agency in organisms.
The section sets the stage for the next parts of the discussion, which will focus on the ecological dimensions of natural agency, emphasizing the importance of understanding both internal organizational processes and external ecological interactions.
You
5. Basic Biological Anticipation 
The interactive dimension of natural agency is also called adaptive agency, because it is concerned 
with how an organism, once it has achieved basic self-manufacture, can adaptively regulate its 
state in response to its environment (Moreno & Mossio, 2015; Di Paolo et al., 2017). As an 
example, consider the paramecium again: its cilia beat as a consequence of its metabolism and 
the maintenance of its internal milieu, but their effect lies outside the cell, causing the organism to 
move towards food sources, or food to be brought into proximity through the turbulent l ow 
induced in its viscous watery surroundings. Thus, constraints subject to closure can (and indeed 
must) exert effects beyond the boundaries of the organism (ibid.). Agency is not only an 
organizational, but also an ecological phenomenon (Walsh, 2015). It is as much about the relations 
of the agent to its arena, as it is about internal self-manufacture. 
Once it has set itself a goal, the organism needs to be able to pursue it. Such pursuit presupposes 
two things: i rst, the organism must be motivated to attain its goal. Motivation ultimately springs 
from an organism���s fragility and mortality (Jonas, 1966; Thompson, 2007; Deacon, 2011; Moreno & 
Mossio, 2015; see also section 2). If a system cannot perish (or at least suffer strain or damage), it 
22 
has no reason to act. This is why the execution of an algorithm must be triggered by an external 
agent. It pursues nothing on its own11. 
Second, and more importantly, the organism must be able to identify appropriate combinations or 
sequences of actions, suitable strategies, that increase the likeliness of attaining its goals. This is 
what it means to make the right ���choice:��� to select an appropriate action or strategy from one���s 
repertoire that satisf i ces in a given situation. The chosen path may not be optimal ��� nothing ever 
is. But making adequate choices still requires the ability to assess, in some reliable way, the 
potential consequences of one���s actions. More precisely, it means that even the simplest organism 
must have the capacity to project the present state of the world into the future or, perhaps more 
appropriately, to pull the future back into the present (Rosen, 1985/2012; Louie, 2009; Kiverstein & 
Sims, 2021; Sims, 2021). Or simply put: any purposive system is able to perform an activity (rather 
than some other activity) because of its (likely) consequences. Recall that this cannot rely on 
intention or awareness, if we are to develop an account of relevance realization suitable for all 
living beings. Therefore, our next task is to show that even the most primitive organisms are 
anticipatory systems (Rosen, 1985/2012; Louie, 2009; Louie, 2012, 2017b).
ChatGPT
ChatGPT
This section introduces the concept of "basic biological anticipation" as a crucial aspect of adaptive agency in organisms:
Adaptive Agency
: Adaptive agency refers to an organism���s ability to regulate its state adaptively in response to environmental changes, extending beyond basic self-manufacture. This involves interactions between the organism and its environment.
Example of Paramecium
: The paramecium demonstrates adaptive agency. Its cilia beat due to internal processes (metabolism and internal milieu maintenance), but the effect is external, propelling it towards food or bringing food closer.
Agency as an Ecological Phenomenon
: Agency is not just an internal organizational property; it is also ecological. It encompasses the agent's relations with its environment (arena) as well as its internal self-manufacture.
Motivation from Fragility and Mortality
: An organism's motivation to pursue goals stems from its fragility and mortality. Unlike algorithms, which require external triggers, living organisms have intrinsic reasons to act due to the potential for perishing or experiencing harm.
Choice and Strategy Identification
: Organisms need to identify appropriate actions or strategies to achieve their goals. This "choice" involves selecting suitable actions from available options that satisfice (satisfy and suffice) in a given situation.
Anticipatory Systems
: Organisms must anticipate the consequences of their actions. This anticipation involves projecting the present state into the future or integrating future possibilities into present decision-making. This capability is required even for the simplest organisms.
Relevance Realization in All Living Beings
: The section sets out to demonstrate that all living organisms, not just those with intention or awareness, are anticipatory systems. This forms a part of developing an understanding of relevance realization applicable to all life forms.
The discussion emphasizes the importance of understanding how organisms adaptively interact with their environment and anticipate the outcomes of their actions as fundamental aspects of natural agency. This anticipatory aspect is integral to the concept of relevance realization in living beings.
You
An anticipatory system possesses predictive internal models of itself and its immediate 
environment (the accessible part of the large world it lives in; Rosen, 1985/2012). These models 
need not be explicit representations. They simply stand for an organism���s ���expectations��� in some 
generic way. Often, they manifest as evolved automatisms or habituated instinctive behaviors: 
selectors of actions inherited from ancestors that attained their goals to survive (and later 
reproduce) in comparable circumstances in the past12. Only exceptionally, in a small set of highly 
complex animals (including humans), can we speak of representations or even premeditated 
mental simulations of future events (Deacon, 2011). Most internal predictive models are much 
simpler, yet still anticipatory. Let us examine what the minimal requirements of such biological 
anticipation are. 
To start with a simple example: a bacterium can modify the frequency of change in its l agellar 
motion to swim up a nutrient gradient or, conversely, to avoid the presence of a toxin. This evolved 
12 An alternative explanation can be provided in terms of the ���free-energy principle��� (Kiverstein & Sims, 2021), which 
def i nes a set of minimal principles of organization for systems capable of adapting to their environments in terms of 
their capacity to ���minimize free energy,��� i.e., to seek out a path of least resistance. This can be interpreted as a simple 
instantiation of anticipatory behavior. However, this explanation remains embedded in an algorithmic (small-world) 
framework, as we discuss in the Conclusions. 
11 The doctrine of reinforcement learning (Sutton & Barto, 1998) relies on machine ���wanting��� in the sense of doling out 
���rewards��� and ���punishments��� to an algorithm for progressing towards a predef i ned goal, but the use of these terms is 
obviously metaphorical, as the target (as always in a machine context) is imposed externally (see footnote 4). In 
stark contrast, the intrinsic motivation of an organism must ultimately be rooted in its continuous drive to persist in a 
challenging environment. The tedium and futility of any kind of true immortality is philosophically pondered in 
Bernard Williams��� classical essay ���The Makropulos Case��� (Williams, 1973). 
23 
automatism anticipates the outcome of the bacterium���s actions in two ways: i rst, it enables the 
organism to discern between nutritious (good) and noxious (bad) substances in its surroundings. 
Second, it directs the bacterium���s movements towards an expected benef i cial outcome, or away 
from a suspected detrimental one. This process can and does go wrong: outside the laboratory 
there isn���t always an abundance of food at the top of the sugar gradient, and new dangers 
constantly await.
ChatGPT
ChatGPT
The section discusses the concept of biological anticipation in organisms:
Anticipatory Systems and Predictive Models
: Anticipatory systems possess internal predictive models of themselves and their environment. These models are not necessarily explicit representations but can be considered as the organism's generic "expectations," often manifesting as evolved automatisms or instinctive behaviors.
Simple Anticipatory Models in Most Organisms
: While complex animals, including humans, might have representations or mental simulations of future events, most internal predictive models in organisms are simpler yet still anticipatory.
Example of Bacterial Behavior
: A bacterium demonstrates biological anticipation by modifying its flagellar motion to navigate nutrient gradients or avoid toxins. This behavior is an evolved automatism that anticipates beneficial or detrimental outcomes.
Anticipation in Action Selection
: The bacterium's behavior illustrates how organisms discern between favorable and unfavorable conditions and direct their actions towards expected outcomes. This process is not infallible and can lead to incorrect anticipatory actions outside controlled environments.
Intrinsic Motivation and Environmental Challenges
: The inherent motivation in organisms to persist in challenging environments contrasts with the metaphorical use of "rewards" and "punishments" in reinforcement learning algorithms, where goals are externally imposed.
The discussion emphasizes that biological anticipation is a fundamental aspect of natural agency, enabling organisms to navigate their environment effectively. This anticipatory capacity is present even in simple organisms like bacteria, guiding their actions in pursuit of survival and adaptation.
You
It is important to repeat that there is nothing the bacterium explicitly intends to do, nor is it in any 
way aware of what it is doing, or how it selects an appropriate action. Its responses are evolved 
habits in the sense that there are few alternative paths of action, there is very little l exibility in 
behavior, and there is certainly no self-ref l ection. And yet, bacteria have evolved the capacity to 
distinguish what is good and what is bad for their continued existence, purely based on endless 
runs of trial-and-error in countless generations of ancestors. This is basic relevance realization 
grounded in adaptive evolution. And it qualif i es as basic anticipatory behavior: the expected 
outcome of an action inf l uences the bacterium���s present selection of actions and strategy. The 
fundamental requirement for a predictive model is fulf i lled: there is a subsystem in the bacterium���s 
physiology that induces changes in its present state based on expectations about what the future 
may bring. This is what we mean when we say that anticipatory systems can pull the future into the 
present. 
More generally, we can consider a living system organized in the way described in section 4, which 
contains predictive models as subsystems with effectors that feed back on its self-manufacturing 
organization. These effectors inf l uence system dynamics in two distinct ways (Louie, 2009; Rosen, 
1985/2012; Louie, 2012, 2017b). Either they modify the selection of actions (as in the bacterial 
example above), or they modulate the sensory inputs of the system (see also Kiverstein & Sims, 
2021). Our expectations constrain and color what we perceive. It is in this sense that anticipation is 
most essential for relevance realization. 
Let us consider human predictive processing once more (see section 3): on the one hand, people 
cannot help but project their expectations onto their environment. Our conscious perceptions are 
not only distorted by our beliefs, but very probably consist of nothing else than the contents of our 
projections (Seth, 2021). Moreover, it is hard to let go of preconceived notions: we only modify our 
expectations when we encounter errors and discrepancies of a magnitude we can no longer 
ignore. On the other hand, we also use opponent processing to great effect when we play predictive 
scenarios against each other while monitoring the streams of discrepancies they generate to 
prioritize between them. We will revisit such adaptive evolution of internal predictions in section 7. 

For now, it suf i ces to say that human beings are anticipatory systems par excellence, and our 
behavior cannot be understood unless we take seriously our abilities to plan ahead and strategize.
ChatGPT
ChatGPT
This section delves deeper into the concept of basic biological anticipation and its role in relevance realization:
Implicit Anticipatory Behavior
: The example of a bacterium illustrates basic anticipatory behavior. The bacterium doesn't have explicit intentions or awareness of its actions, but it has evolved the capacity to distinguish between beneficial and harmful conditions, a form of basic relevance realization.
Evolution of Habituated Responses
: Bacterial responses are evolved habits, representing trial-and-error adaptations across countless generations. These responses, while lacking flexibility or self-reflection, still qualify as basic anticipatory behavior.
Predictive Models in Physiology
: The bacterium's physiology contains subsystems that induce changes based on expectations about future conditions. This ability to anticipate and respond to potential future states is central to the concept of anticipatory systems.
Effectors and System Dynamics
: In living systems organized as described earlier, predictive models act through effectors that feedback on the organism's self-manufacturing organization. These effectors either modify action selection or modulate sensory inputs, influencing perceptions and actions.
Human Predictive Processing
: In humans, anticipatory behavior is exemplified by the projection of expectations onto the environment and the adjustment of those expectations based on encountered discrepancies. This process involves playing predictive scenarios against each other and monitoring discrepancies to prioritize actions.
Human Behavior and Anticipation
: Humans are considered anticipatory systems par excellence, with their behavior deeply influenced by the ability to plan ahead and strategize. Understanding human behavior requires acknowledging these anticipatory capabilities.
The discussion highlights that basic anticipatory behavior is a fundamental aspect of living organisms, enabling them to adaptively respond to their environment. This behavior, grounded in evolution and the organism's internal organization, forms a core part of relevance realization in both simple and complex life forms.
You
The internal organization of anticipatory systems is intimately related to the basic organization of 
living systems (Rosen, 1985/2012; Louie, 2012). There are familiar self-referential patterns (Fig. 3). 
Without going into too much detail, let us note that organisms generate their internal models of the 
world from within their own organization. These models, in turn, direct the organism���s behavior, its 
choice of actions and strategies, through their effectors. Actions have consequences and, thus, our 
internal models become modif i ed through the comparison of their predictions with actual 
outcomes. This leads to a dialectic adaptive dynamic, not unlike that which governs the 
interactions of self-manufacturing processes described in section 3 (compare Fig. 2 with Fig. 3). 
Figure 3: The triadic dialectic underlying anticipatory systems. 
As is the case with Rosennean complex systems, there are anticipatory systems that are not 
organisms. Economies, as a case in point, are heavily driven by internal (individual and societal) 
models of their own workings (e.g, Tuckett & Taf l er, 2008; Schotanus et al., 2020). Once somebody 
i nds out how to predict the stock market, for instance, its dynamics will immediately and radically 
change in response. We can thus say that all organisms are anticipatory systems, but not all 
anticipatory systems are organisms; similarly, all anticipatory systems are complex systems, but 
not all complex systems are anticipatory (Rosen, 1985/2012; Louie, 2009). 
25 
To summarize: all organisms, from bacteria to humans, are anticipatory agents. They are able to 
set their own goals and pursue them based on their expectations of the future. Organisms, 
essentially, are systems that solve the problem of relevance. In contrast, algorithms and machines 
are purely reactive: even if they seemingly do anticipate future sequences of operations in their 
small-world context, it is always in response to a task or target that is ultimately predefined and 
externally imposed.
ChatGPT
ChatGPT
This section further connects the concept of anticipatory systems to the basic organization of living systems:
Integration of Internal Models
: Organisms generate internal models of the world from within their own organization. These models influence the organism's behavior, guiding the choice of actions and strategies through effectors.
Feedback and Adaptation
: Actions lead to consequences, which modify internal models by comparing predictions with actual outcomes. This results in a dialectic adaptive dynamic, similar to the interactions of self-manufacturing processes discussed earlier.
Self-Referential Patterns
: The internal organization of anticipatory systems features self-referential patterns, highlighting a complex interplay between internal models, behavior, and feedback from the environment.
Anticipatory Systems Beyond Organisms
: Not all anticipatory systems are organisms. Economies, for example, are driven by internal models of their workings, and changes in these models can radically alter economic dynamics. This distinction emphasizes that while all organisms are anticipatory systems, not all anticipatory systems are organisms.
Complexity and Anticipation
: All organisms are complex systems and anticipatory agents, capable of setting goals and pursuing them based on expectations of the future. This ability to solve the problem of relevance is fundamental to organisms.
Contrast with Algorithms and Machines
: Algorithms and machines, in contrast, are described as purely reactive. They may appear to anticipate future operations, but only within a predefined and externally imposed small-world context.
This summary underscores the inherent ability of organisms, from the simplest bacteria to humans, to anticipate and adaptively respond to their environment. This capability is integral to their nature as complex, self-organizing systems and distinguishes them from non-living computational entities.
You
It is worth emphasizing at this point that nothing in our account violates any laws of logic or 
physics. In particular, we do not allow future physical states of the world to affect the present. The 
states of internal predictive models are as much physically embedded in the present as the 
organism of which they are a part. Also, the model can (and often does) go wrong. Consequences 
of actions are bound to diverge from expectations in some, often surprising and unexpected, ways. 
A good model is one where they do not diverge catastrophically. A bad model can be improved by 
experience through the monitoring and correction of errors. This yields the adaptive dialectic 
dynamic depicted in Fig. 3. Remember that every living system can do this. With this capacity in 
hand, we can now move to the bigger picture of how organisms evolve an ever richer repertoire of 
goals and actions through solving the problem of relevance (cf. Roli et al., 2022).
ChatGPT
ChatGPT
In this concluding part of the section on anticipatory systems, the paper emphasizes the alignment of its arguments with established principles of logic and physics:
Compliance with Logical and Physical Laws
: The account of anticipatory systems and their predictive models is consistent with the laws of logic and physics. It does not imply that future states of the world impact the present; rather, it focuses on how organisms use internal models to anticipate and respond to environmental changes.
Physical Embedding of Predictive Models
: The states of these internal predictive models are physically present within the organism. They are part of the organism���s real-time processing, not detached or external to it.
Fallibility of Predictive Models
: The models can, and often do, go wrong. Actions may lead to outcomes that differ from what was expected. The efficacy of a model is judged by how significantly its predictions diverge from actual outcomes, with the aim being to avoid catastrophic divergences.
Improvement through Error Correction
: Errors and discrepancies between expectations and actual outcomes serve as feedback, allowing organisms to improve their models. This process of monitoring and correcting errors contributes to the adaptive dialectic dynamic of living systems.
Universal Capability Among Living Systems
: This capacity for internal modeling and adaptation is a universal characteristic of all living systems. It is fundamental to how organisms evolve and diversify their goals and actions by solving the problem of relevance.
Evolution of Goals and Actions
: The paper suggests that this anticipatory capacity enables organisms to develop an increasingly rich repertoire of goals and actions over time, enhancing their ability to navigate and adapt to their environment.
The section reaffirms the naturalistic and scientifically grounded approach to understanding how organisms, through their anticipatory systems, continuously adapt and evolve in response to their environments.
You
6. Affordance, Goal, Action 
We now come to the core of our evolutionary account of relevance realization, which is based on an 
organism-centered agential perspective on evolution called situated Darwinism (Walsh, 2012a, 
2015). It is an ecological theory of agency and its role in evolution, which centers around the 
engagement of organisms with their experienced environment (ibid.). Situated Darwinism centers 
around the following three basic ingredients: (1) a collection of intrinsic goals for the organism to 
pursue (section 4), (2) a set of available actions (the repertoire of the agent, shaped with respect to 
its experience and expectations; section 5), and (3) affordances in the experienced environment. In 
what follows, we show that the dialectic co-emergent dynamics between these three components 
provide an evolutionary explanation of relevance realization. 
Affordances are what the environment offers an agent (Gibson, 1966, 1979; Chemero, 2003; 
recently reviewed in Heras-Escribano, 2019). They typically manifest as opportunities or 
impediments, def i ned with respect to an organismic agent pursuing some goal (Walsh, 2015). An 
open door, for example, affords us to pass through it, but when the door is shut it prevents us from 
entering. Similarly, gradients of nutrients and toxins provide positive and negative affordances to a 
bacterium seeking to persist and reproduce. In this context, perception becomes the active 
26 
detection of affordances. Actions are initiated in direct response to them. Affordances are a 
quintessentially relational, ecological, and thus transjective phenomenon: they do not reside 
objectively in the physical environment, but neither are they subjective. Instead, they arise through 
the interaction of an agent with particular attributes and aspects of its surroundings (Chemero, 
2003; Stoffregen, 2003; Walsh, 2015). They are what constitutes the agent���s arena, the task-relevant 
part of its experienced environment (see section 3). 
Affordances ground the agent-arena relationship in the world: organisms experience their physical 
environment as an affordance landscape (Walsh, 2014, 2015; Felin & Kauffman, 2019). This 
highlights the complementarity of agent and arena. The latter does not simply preexist, 
independent of the agent. Through their mutual interrelations, an organism���s goals, actions, and 
affordances continuously co-constitute each other through the kind of emergent dialectic dynamic 
we have already encountered in the last two sections (Fig. 4). The arena (as an affordance 
landscape) constantly co-emerges and co-evolves with the evolving set of goals and action 
repertoire of the agent.
ChatGPT
ChatGPT
This section introduces the concept of "situated Darwinism," an ecological theory of agency and its role in evolution, focusing on the interaction of organisms with their environment:
Three Basic Ingredients of Situated Darwinism
:
Intrinsic Goals
: The collection of intrinsic goals that an organism pursues, as discussed earlier, defines the organism's motivations and drives.
Available Actions
: The set of actions available to an organism, shaped by its experiences and expectations. This repertoire determines how the organism can interact with its environment.
Affordances in the Environment
: Opportunities or impediments offered by the environment in relation to the organism's goals.
Affordances as Opportunities or Impediments
: Affordances manifest as opportunities or impediments defined by the organism's goals. For example, an open door offers the affordance of passing through, while a closed door becomes an impediment.
Relational, Ecological, and Transjective Nature of Affordances
: Affordances are relational���they don't reside purely in the physical environment nor are they entirely subjective. They emerge through the interaction between the agent and specific aspects of its surroundings.
Perception as Active Detection of Affordances
: Organisms perceive their environment actively, detecting affordances and initiating actions in response to them. This perception is integral to how organisms navigate their affordance landscape.
Agent-Arena Relationship Grounded in Affordances
: Organisms experience their environment as an affordance landscape. This concept underscores the complementarity of the agent and its environment, where the arena does not preexist independently but co-emerges and co-evolves with the organism's goals and actions.
Emergent Dialectic Dynamic
: The interplay between an organism���s goals, actions, and affordances results in a co-constitutive, emergent dialectic dynamic. This dynamic characterizes the evolving relationship between the organism and its environment.
In summary, this section explains how organisms engage with their environment through a complex interplay of goals, actions, and affordances. This engagement is central to the evolutionary process and is a fundamental aspect of relevance realization in living beings.
You
Figure 4: The triadic dialectic underlying evolutionary adaptation and complexif i cation. 
This dialectic proceeds in the following way: an organismic agent identif i es affordances in its 
surroundings through some form of sensing or perception (which may be based on predictive 
processing as described in section 3), generating its arena by delimiting the task-relevant region of 
its larger experienced environment. This highlights the co-dependency of agent and arena: an 
27 
organism���s affordance landscape exists only in relation to the set of intrinsic goals that the 
organism may select to pursue13(section 5). This landscape represents a world of meaning, laden 
with value, where affordances are more or less ���good��� or ���bad��� with respect to attaining the agent���s 
goals. We cannot repeat often enough that this does not require any explicit intention, awareness, 
or cognitive or mental processing. The classif i cation of affordances as benef i cial or detrimental, 
and their effect on the process of selecting a goal, may be habituated by adaptive evolution 
through the inherited memory of the successes and failures of previous generations. 
To complicate the situation, different (even conf l icting or contradictory) goals can coexist at the 
same time, even in agents with very simple behavioral repertoires and predictive internal models. A 
bacterium, for instance, may encounter a nutrient gradient that coincides with the presence of a 
toxin, contradictory affordances which create conf l icting signals of attraction and avoidance. 
Moreover, the same goal can be assigned different weights (priorities) in different situations, and 
goals may build on each other in other non-trivial ways that tend to be radically dependent on 
context. All of this means that the goals of an agent come with a complicated and rich structure of 
interdependencies, intimately commingled with the affordances in its arena (Haugeland, 1998; 
Walsh, 2012a, 2014, 2015).
ChatGPT
ChatGPT
This section explains how the dialectic process between an organism and its environment leads to evolutionary adaptation and complexity:
Identification of Affordances
: Organisms identify affordances in their environment through sensing or perception, which may involve predictive processing. This process generates the organism���s arena by delimiting the task-relevant region of its larger experienced environment.
Co-dependency of Agent and Arena
: The affordance landscape of an organism exists in relation to its set of intrinsic goals. The landscape is a world of meaning, where affordances are classified as beneficial or detrimental based on their alignment with the organism's goals.
Intrinsic Goals and Affordances
: The process of identifying and responding to affordances does not require explicit intention, awareness, or complex cognitive processing. The classification of affordances and their influence on goal selection may be a result of adaptive evolution and inherited experiences of previous generations.
Complexity of Goals and Conflicting Affordances
: Organisms may face conflicting or contradictory goals, even with simple behavioral repertoires. For example, a bacterium might encounter both a nutrient gradient and a toxin, presenting conflicting signals. Additionally, the priority of goals can vary depending on the situation, and goals can have complex interdependencies with each other and the affordances in the environment.
Context-Dependent Goal Structures
: The structure of an organism���s goals is complex and deeply intertwined with the affordances it encounters. These structures and their relationships with affordances are highly dependent on the context.
This section emphasizes the intricate and context-dependent nature of how organisms interact with their environment, highlighting the dynamic interplay between an organism���s goals, actions, and the affordances present in its environment. This interplay is crucial for understanding the evolutionary adaptation and increasing complexity of living systems.
You
When an agent selects a particular goal to pursue, it collapses its set of goals down to one specif i c 
element. Similar considerations apply to the choice of an appropriate action, or a small set of 
actions that constitute a strategy, from the organism���s current repertoire to pursue the selected 
goal. This repertoire also comes with a complicated and rich internal structure: some actions are 
riskier, or more strenuous, or more dif i cult to carry out than others; some are quicker, more 
obvious, or more directly related to the attainment of the goal. Some actions only make sense if 
employed in a certain combination or temporal order. The potential usefulness of an action must 
be assessed through internal predictive models that take all these complications into account 
(section 5). Based on this, the agent collapses its repertoire to select a particular action, or 
combination or sequence of actions, which it will commit to carry out. 
All of this leads to the agent leveraging specif i c positive affordances in its arena, while trying to 
avoid or ameliorate negative ones, thereby also collapsing the set of available affordances (the 
arena) to some subset of itself. Taken together, all of the above results in a constant, coordinated, 
and co-dependent collapse and reconstruction of all three sets ��� affordances, goals, actions ��� 
13 Seen through the lens of embodied reinforcement learning, this seems to imply a simple grounding in the 
dopaminergic system (a mapping from perception to reward signal, which represents relevance; see, for example 
Gershman et al., 2015). But, once again, this leaves open the question where goals and affordances come from in the 
i rst place. 28 
ultimately committing the agent to a particular pursuit at any one time through a specif i c sequence 
of actions. This is how agential behavior is generated.
ChatGPT
ChatGPT
This section describes the process by which an organism selects goals and actions, and how this selection influences its interaction with the environment:
Selection of Specific Goals
: When an agent (organism) chooses a particular goal from its set of potential goals, it narrows its focus to one specific objective. This selection process collapses the broader set of goals into a single target.
Choice of Appropriate Actions or Strategies
: Similarly, the organism selects an action or a set of actions (a strategy) from its repertoire to pursue the chosen goal. The repertoire has a complex internal structure where actions differ in risk, effort, difficulty, speed, and relevance to the goal. Some actions are interdependent, making sense only in certain combinations or sequences.
Assessment of Actions via Predictive Models
: The potential usefulness of an action is assessed through the organism's internal predictive models, considering the aforementioned complexities. Based on this assessment, the organism selects a specific action or a combination of actions to commit to.
Leveraging Positive Affordances, Avoiding Negative Ones
: In pursuing its selected goal, the organism seeks to leverage positive affordances in its environment while avoiding or mitigating negative ones. This process also involves collapsing the set of available affordances to a subset relevant to the current goal and action.
Coordinated and Co-dependent Process
: The selection of goals, actions, and affordances is a coordinated and interdependent process. All three elements ��� affordances, goals, actions ��� are constantly being collapsed and reconstructed, leading to a commitment by the agent to a particular course of action at any given time.
Generation of Agential Behavior
: This dynamic and interactive process of selecting and pursuing goals and actions in response to environmental affordances is how agential behavior is generated in organisms.
The section highlights the complexity and adaptability of organisms in navigating their environments. It underscores the continuous process of decision-making and adaptation that organisms undergo to achieve their goals, emphasizing the interplay between internal goals, actions, and external affordances.
You
When an agent selects a particular goal to pursue, it collapses its set of goals down to one specif i c 
element. Similar considerations apply to the choice of an appropriate action, or a small set of 
actions that constitute a strategy, from the organism���s current repertoire to pursue the selected 
goal. This repertoire also comes with a complicated and rich internal structure: some actions are 
riskier, or more strenuous, or more dif i cult to carry out than others; some are quicker, more 
obvious, or more directly related to the attainment of the goal. Some actions only make sense if 
employed in a certain combination or temporal order. The potential usefulness of an action must 
be assessed through internal predictive models that take all these complications into account 
(section 5). Based on this, the agent collapses its repertoire to select a particular action, or 
combination or sequence of actions, which it will commit to carry out. 
All of this leads to the agent leveraging specif i c positive affordances in its arena, while trying to 
avoid or ameliorate negative ones, thereby also collapsing the set of available affordances (the 
arena) to some subset of itself. Taken together, all of the above results in a constant, coordinated, 
and co-dependent collapse and reconstruction of all three sets ��� affordances, goals, actions ��� 
13 Seen through the lens of embodied reinforcement learning, this seems to imply a simple grounding in the 
dopaminergic system (a mapping from perception to reward signal, which represents relevance; see, for example 
Gershman et al., 2015). But, once again, this leaves open the question where goals and affordances come from in the 
i rst place. 28 
ultimately committing the agent to a particular pursuit at any one time through a specif i c sequence 
of actions. This is how agential behavior is generated. 
Of course, this is not the end of the process. Committing to a specif i c action or strategy will 
immediately change the affordance landscape and will likely also affect the set of goals of the 
agent. Acting in one���s arena inevitably generates new opportunities and impediments, while 
modifying, suppressing, or removing others. The altered affordance landscape is then again 
perceived and assessed by the agent (through its internal predictive models), affecting the weights 
and relations of its goals, while generating new ones (and obsoleting others). All the while, the 
agent may learn to carry out new actions and to adjust old ones. This iterative evaluation and 
amelioration of behavioral patterns (Fig. 4) leads to an adaptive dynamic that induces a closer i t 
between the agent and its arena, a tighter and often more intricate agent-arena relationship, and 
thus a i rmer and broader grip on the world. In short, the agent may learn to behave more 
appropriately in its particular situation. 
This yields an organism-centered model of Darwinian evolution, which is very different from most 
other current approaches to evolutionary biology. It is thoroughly Darwinian, because the 
population-level selection of heritable variants remains central for stabilizing adaptive behavioral 
patterns across generations (see Walsh, 2012a, 2015). This is especially evident in simple 
organisms (like bacteria) with small and rather inf l exible sets of affordances, goals, and actions 
that show a high degree of genetic inf l uence and low l exibility in their behaviors. Yet, unlike 
reductionist accounts of Darwinian evolution, it also provides an explanation for how such simple 
behaviors can evolve into more complex and multi-layered interactions between an agent and its ��rena over time (ibid.).
ChatGPT
ChatGPT
This section explains the dynamic process of how organisms interact with their environment and evolve over time:
Selection and Commitment to Goals and Actions
: When an organism selects a specific goal, it narrows down its range of goals to one primary focus. Similarly, it chooses an appropriate action or a set of actions from its repertoire to achieve this goal. This selection process considers various factors like risk, effort, and effectiveness.
Interaction with the Environment
: The organism's actions interact with its environment, leveraging positive affordances while trying to avoid negative ones. This process results in a constant, coordinated reevaluation and adjustment of the organism's goals, actions, and the available affordances.
Continuous Adaptation and Learning
: Committing to specific actions changes the organism's affordance landscape, creating new opportunities and challenges. The organism continually reassesses its environment and adjusts its goals and actions accordingly. This iterative process leads to learning new behaviors and refining existing ones.
Adaptive Dynamic and Agent-Arena Relationship
: This ongoing evaluation and adjustment foster a closer fit between the organism and its environment, enhancing the agent-arena relationship and the organism's ability to navigate its world effectively.
Organism-Centered Model of Darwinian Evolution
: This approach to understanding evolutionary biology focuses on the organism's interaction with its environment. While heritable variation and population-level selection remain central to Darwinian evolution, this model also explains how simple behaviors evolve into more complex interactions over time.
Evolution of Complex Behaviors
: In contrast to reductionist accounts of evolution, this organism-centered model accounts for the development of complex, multi-layered interactions between an agent and its environment. This evolution is especially significant in simple organisms with limited behavioral flexibility.
The section highlights the organism's active role in shaping its behavior and evolutionary trajectory through continuous interaction and adaptation to its environment. This perspective offers a nuanced understanding of Darwinian evolution, emphasizing the organism's agency and its evolving relationship with the surrounding world.
You
Situated Darwinism implies that agents and arenas constantly co-evolve and co-construct each 
other (Walsh, 2014, 2015; Rolla & Figueiredo, 2023). This constant mutual engagement 
recapitulates Darwin���s original framing of evolution through the organism���s struggle for existence. 
In particular, it reunites the selection of appropriate behaviors by an agent during its lifetime 
(physiological and behavioral adaptation) with the organism���s ability to preserve and adjust its 
organization within and across generations (evolutionary adaptation; Saborido et al., 2011; DiFrisco 
& Mossio, 2020; Mossio & Pontarotti, 2020; Pontarotti, 2024). Several of us have argued in detail 
elsewhere that such an integration of adaptive processes within and across generations is a 
fundamental prerequisite for evolution by natural selection (Walsh, 2015; Jaeger, 2019, 2024). 
The account we present here provides a powerful framework for thinking about evolutionary 
innovation and the generally open-ended nature of evolutionary dynamics (as already argued in Roli 
et al., 2022 and Jaeger, 2024). Its underlying co-emergent and co-constructive dialectic grounds 
29 
the notion of the adjacent possible in autopoiesis, anticipation, and our integrated concept of 
adaptation (Kauffman, 2000). Think of an affordance landscape (at a specif i c time) as a map of 
possible actions/outcomes for an organism. Some of these actions/outcomes are not static or 
prespecif i ed: as organisms respond to affordances, they alter the structure or topography of the 
affordance landscape. What was once improbable, may become highly attainable (and vice versa). 
This provides an alternative to the widespread idea that evolution happens in a predef i ned space of 
possibilities which, though astronomical in size, can be prestated (i.e., precisely circumscribed) 
before any evolution has actually taken place (Fig. 5, left; see also Felin & Kauffman, 2019; Roli et 
al., 2022). The adjacent possible, in contrast, shows us that the box representing this space simply 
does not exist. It sees evolutionary possibilities as co-emerging with evolution, the adjacent 
possible being the space that contains everything that can actually happen next, given the current 
state of the world (Fig. 5, right). This space is in constant l ux, generated by the evolutionary 
process as it goes along. This leads to a radically open-ended view of evolution, in which possible 
future affordances, goals, and actions cannot possibly be prestated as well-def i ned sets ahead of 
them actually being jointly actualized (Roli et al., 2022). Kauffman (2000) calls this radical 
emergence.
ChatGPT
ChatGPT
This section elaborates on the concept of "Situated Darwinism," explaining how it integrates both physiological and evolutionary adaptation:
Co-evolution and Co-construction of Agents and Arenas
: Situated Darwinism posits that agents (organisms) and their arenas (environments) are in a constant state of mutual engagement, co-evolving and co-constructing each other. This perspective aligns with Darwin's original concept of evolution through the organism's struggle for existence.
Integration of Adaptive Processes
: The model integrates adaptive processes occurring within an organism's lifetime (physiological and behavioral adaptation) with its capacity to preserve and adjust its organization across generations (evolutionary adaptation).
Framework for Evolutionary Innovation
: This approach provides a robust framework for understanding evolutionary innovation and the open-ended nature of evolutionary dynamics. It emphasizes the co-emergent and co-constructive dialectic underlying evolutionary processes.
Adjacent Possible in Evolution
: The concept of the "adjacent possible" is grounded in autopoiesis, anticipation, and adaptation. It views the affordance landscape as a map of potential actions and outcomes for an organism, subject to change as organisms interact with their environment.
Dynamic Evolutionary Possibilities
: Contrary to the idea of evolution occurring in a predefined space of possibilities, the adjacent possible illustrates that evolutionary possibilities co-emerge with the evolutionary process itself. The space of what can happen next is constantly changing, driven by the evolutionary process.
Radical Open-Endedness of Evolution
: This perspective leads to a view of evolution as radically open-ended. Future affordances, goals, and actions cannot be precisely defined in advance; they emerge and are actualized through the evolutionary process.
Radical Emergence
: Coined by Kauffman, "radical emergence" refers to this ongoing, unpredictable emergence of new possibilities within the evolutionary process.
In summary, Situated Darwinism offers a holistic and dynamic view of evolution, highlighting the continuous interaction and mutual influence between organisms and their environments. This perspective underscores the open-ended and emergent nature of evolutionary change.
You
7. To Live is to Know 
A multifaceted and multilayered picture of relevance realization in living organisms is emerging. 
What we have so far are three different dialectic processes, at three different levels of organization: 
1.the process of autopoiesis (self-manufacture) ��� internal to the organism, established through 
collective co-constitution of macromolecular biosynthesis, maintenance of internal milieu, and 
regulated selective cross-boundary transport ��� which enables the agent to autonomously set 
its own intrinsic goals through self-determination (self-constraint, see section 4, Fig. 2); 
2.the process of anticipation ��� internal to the organism, but projective (about the environment), 
established through collective co-constitution of internal predictive models (���expectations���), 
the current state of the organism, and effectors modulating this state and the sensory inputs 
that feed it based on model predictions ��� which enables the agent to pursue intrinsic goals 
through selection of suitable actions and behavioral strategies (section 5, Fig. 3); and 
3.the process of integrated adaptation ��� transjective (grounded in the relation between agent 
and arena), established through collective co-constitution of the intrinsic goals, repertoires of 
action, and affordance landscapes of an organism-environment system ��� which amounts to 
relevance realization in its broadest evolutionary sense, a continuous tightening of the 
agent-arena relationship and hence the organism���s ���grip on reality��� (section 6, Fig. 4). 
What remains to be done is to join these three levels of dialectic dynamics into a unif i ed 
hierarchical model of open-ended organismic evolution, which explains how the different 
processes i t together to produce phenomena and behaviors of increasing adaptivity and 
complexity, including cognition and ultimately also consciousness (Fig. 6; see also Juarrero, 1999; 
Deacon, 2011; Walsh, 2015; Roli et al., 2022; Juarrero, 2023; Mitchell, 2023; Jaeger, 2024a).
ChatGPT
ChatGPT
The final section outlines how the various concepts discussed throughout the paper come together to form a comprehensive view of relevance realization in living organisms. It highlights three key dialectic processes, each representing a different level of organizational complexity:
Autopoiesis (Self-Manufacture)
:
Located internally within the organism.
Established through the collective co-constitution of macromolecular biosynthesis, maintenance of the internal milieu, and regulated transport across boundaries.
Enables the agent to set its own intrinsic goals through self-determination and self-constraint.
Anticipation
:
Also internal to the organism but projective about the environment.
Established through the collective co-constitution of internal predictive models ("expectations"), the organism's current state, and effectors that modulate this state and sensory inputs based on model predictions.
Allows the agent to pursue intrinsic goals by selecting suitable actions and behavioral strategies.
Integrated Adaptation
:
Transjective, grounded in the relationship between the agent and its arena (environment).
Established through the collective co-constitution of intrinsic goals, action repertoires, and affordance landscapes.
Represents relevance realization in an evolutionary sense, continuously enhancing the agent-arena relationship and the organism's "grip on reality."
The paper proposes a unified hierarchical model of open-ended organismic evolution, explaining how these processes interconnect to produce increasingly adaptive and complex phenomena and behaviors, including cognition and consciousness.
This comprehensive framework underscores the interconnectedness and layered complexity of biological processes that contribute to the evolutionary journey of living organisms. It highlights the importance of considering multiple levels of interaction and adaptation, from the internal mechanics of self-manufacture to the organism's engagement with its environment, in understanding the nature of life and evolution.
You
Figure 6: The hierarchical tangle of dialectic triads underlying open-ended evolution. 
The i rst step towards such a multi-level integration is the realization that all three processes share 
the same kind of underlying dialectic dynamics, in which a triad of interrelated aspects of the 
process collectively generate and uphold each other to produce a unif i ed, constructive, adaptive, 
and open-ended higher-level dynamic (Figs. 2���4, summarized in Fig. 6). Let us emphasize once 
again that this dialectic can only be emulated or mimicked (but not captured completely) by 
algorithmic simulation, due to its collectively impredicative organization (starting and halting 
problems, see section 4), its anticipatory rather than reactive nature (section 5), and its 
fundamental lack of prestatability and radical emergent open-endedness (expressed by the notion 
of the adjacent possible, see section 6). 
What we need to do next is to show that this seemingly paradoxical dialectic can be scientif i cally 
justif i ed ��� that it does not contradict any well-established empirical knowledge about the physical 
32 
or the living world. What we want, after all, is a naturalistic account of relevance realization. It 
requires no mysterious new forces or laws of physics. All that is needed is a simple shift of focus, 
away from the predictive laws governing state change in the underlying physico-chemical 
processes to the unpredictable historical succession of dynamic constraints (further ref i ned into a 
combination of closed ef i cient and open formal causes), which are imposed on these processes in 
a living system, continuously restricting and channeling their degrees of freedom as well as their 
rate and direction of change (Polanyi, 1968; Anderson, 1972; Juarrero, 1999; Pattee, 2001; Deacon, 
2011; Pattee & R��czaszek-Leonardi, 2012; Hofmeyr, 2018, 2021; Juarrero, 2023; Mitchell, 2023). 
The continuous collective co-constitution of constraints is what unites the three levels of dialectic 
dynamics. It occurs under the fundamental condition (or we could say: within the meta-constraint) 
of having to continuously maintain closure of constraints (section 4). It is what matters when we 
try to understand life and its evolution. It is what generates and maintains the closed organization 
of a cell or organism, its ability to anticipate, and the adaptive and constructive physiological, 
behavioral, and population-level processes that not only tighten the agent-arena relationship, but 
also account for the evolutionary trend towards increased complexif i cation. It is this process of 
increasingly intricate constraint construction that differentiates living from non-living systems, 
allows them to evolve by natural selection, and lends them their coherence across multiple levels 
of organization, which successively emerge through major transitions in evolution (Maynard Smith 
& Szathm��ry, 1995; Szathm��ry, 2015).
ChatGPT
ChatGPT
This concluding section synthesizes the key concepts presented in the paper and proposes a multi-level integration of these concepts, focusing on the dialectic dynamics underlying open-ended evolution:
Shared Dialectic Dynamics
: All three processes (autopoiesis, anticipation, and integrated adaptation) share a similar underlying dialectic dynamic. This dynamic involves a triad of interrelated aspects that collectively generate and uphold each other, leading to a unified, adaptive, and open-ended higher-level dynamic.
Limitations of Algorithmic Simulation
: These dialectic dynamics can only be emulated or mimicked, but not completely captured, by algorithmic simulation. This limitation is due to their collectively impredicative organization, anticipatory nature, and lack of prestatability, as well as their radical emergent open-endedness.
Scientific Justification of the Dialectic
: The paper aims to show that this dialectic is scientifically justifiable and does not contradict established knowledge about the physical or living world. It does not require new forces or laws of physics but instead requires a shift of focus from predictable state changes in physico-chemical processes to the unpredictable succession of dynamic constraints.
Continuous Co-constitution of Constraints
: The unification of the three levels of dialectic dynamics is achieved through the continuous collective co-constitution of constraints. These constraints are imposed on physico-chemical processes in a living system, continuously shaping their degrees of freedom and rate and direction of change.
Maintaining Closure of Constraints
: A fundamental condition for these dynamics is the continuous maintenance of closure of constraints. This maintenance is central to understanding life and its evolution.
Implications for Evolution and Complexity
: This process of increasingly intricate constraint construction distinguishes living from non-living systems. It allows living systems to evolve by natural selection and contributes to their coherence across multiple levels of organization. It also explains the trend toward increased complexification observed in evolution.
Major Transitions in Evolution
: The paper suggests that these processes are evident in the major transitions in evolutionary history, as outlined by Maynard Smith and Szathm��ry.
In summary, the paper presents a comprehensive, naturalistic account of relevance realization in living organisms, emphasizing the complex, dynamic, and emergent nature of life and its evolutionary processes. It highlights the importance of understanding the interplay of various constraints and the dialectic dynamics that drive the evolution and complexification of life.
You
On this view, the functional capacities and evolutionary potential of organismic agents are 
fundamentally unpredictable and radically open-ended. Biological organization is only enabled but 
not predetermined or driven by the underlying dynamical laws of physics whose possible outcomes 
it restricts. An organism���s individual life history and its evolution are full of consequential accidents 
(Polanyi, 1968; Pattee, 2001; Pattee & R��czaszek-Leonardi, 2012; Ruiz-Mirazo & Moreno, 2012). 
Due to their openness to formal cause (section 4), organisms constantly explore new structural 
variants within the general conf i nes of closure to ef i cient causation (Hofmeyr, 2018, 2021). This 
enables them to interact with their arena in truly unprecedented ways (Walsh, 2015). This does not 
have to happen frequently, it just has to be possible in principle for the future propensities of 
evolution to become radically uncertain: we cannot prestate them as an explicit probability 
distribution and, in fact, we cannot formalize them as a well-def i ned space of possibilities at the 
present time (section 3, and Kauffman, 2000; Roli et al., 2022). 
To understand better what this means, it is useful to look at the process of constraint construction 
from two complementary perspectives. So far, we have relied on a constitutive frame: it begins with 
the positive observation that each of the three aspects of a dialectic constraint-generation process 
33 
is absolutely necessary to bring about and uphold the other two. Even though each subprocess is 
distinguishable and describable in its own terms, they can never be physically separated or occur in 
isolation from each other. They must emerge from each other. They would not even exist without 
one another���s mutual support. They always have to actualize together. It is in this sense that they 
are collectively impredicative, the presence of one necessarily entailing the presence of the other 
two (see section 4), and that they are also concurrent, in exchange with each other all of the time 
(see section 6). In summary: the constitutive perspective focuses on the interrelations between 
physico-chemical processes that are simultaneously present to explain overall dynamics. 
In a complementary way, we can focus on what is not there but nevertheless exerts causal 
inf l uence on organismic dynamics (Deacon, 2011; Pattee & R��czaszek-Leonardi, 2012). We can call 
this approach the constraint frame. It seems perplexing at i rst sight. Think of it as the 
photographic negative of the constitutive angle. As we shall see, it turns out to be extremely useful 
for our purposes. Taking the constraint perspective begins with the observation that each 
subprocess in a triadic dialectic enables reciprocal support by establishing a coherence among the 
different aspects of the overall process. More specif i cally, the emergence of coherent overall 
dynamics requires reducing the degrees of freedom of each individual subprocess, to ensure that ��ll three fall into a regime that allows them to interact in a mutually supportive, constructive, and 
generative manner. The whole living organism, in this sense, is less than the sum of its parts 
(Deacon, 2011).
ChatGPT
ChatGPT
This section of the paper delves deeper into the unpredictable and open-ended nature of biological organization and evolution:
Unpredictability and Open-Endedness
: Organismic agents have functional capacities and evolutionary potential that are fundamentally unpredictable and radically open-ended. Biological organization is enabled, but not predetermined, by the dynamical laws of physics.
Role of Accidents in Life History and Evolution
: Individual life histories and evolutionary paths of organisms are filled with consequential accidents, indicating a non-deterministic nature of biological processes.
Openness to Formal Cause
: Due to their openness to formal causation, organisms continuously explore new structural variants within the confines of closure to efficient causation. This allows for unprecedented interactions with their environments.
Radical Uncertainty of Evolution
: The future propensities of evolution are radically uncertain. It's impossible to prestate them as an explicit probability distribution or to formalize them as a well-defined space of possibilities.
Two Perspectives on Constraint Construction
:
Constitutive Frame
: This approach focuses on the interrelations between physico-chemical processes that are simultaneously present, explaining overall dynamics. Each aspect of the dialectic constraint-generation process is necessary for the existence and support of the others.
Constraint Frame
: This perspective considers what is not present but still exerts causal influence on organismic dynamics. It involves establishing coherence among different aspects of the overall process by reducing degrees of freedom, enabling mutually supportive interactions.
Coherence and Reduction of Degrees of Freedom
: The emergence of coherent overall dynamics in organisms requires reducing the degrees of freedom of individual subprocesses. This ensures that all three aspects of the triadic dialectic interact in a supportive and generative manner.
Organism as Less Than the Sum of Its Parts
: From the constraint perspective, the whole living organism is seen as less than the sum of its parts, emphasizing the importance of the interaction and coherence among its components.
This section highlights the complexity and non-linearity of biological systems, emphasizing the significant role of constraints and the interplay of various processes in shaping the evolution and behavior of living organisms.
You
It may be useful to visualize the complementary nature of the two frames or perspectives in the 
following way. A physico-chemical process, given its current state and structure, always has a 
distribution of future probabilities associated with it ��� determined by a space of possibilities that 
in dynamical systems theory is called the conf i guration space of the system (see, for example, 
Jaeger et al., 2012; Jaeger & Monk, 2014). This abstract space can be represented as a (usually 
very high-dimensional) distribution of probabilities, and can be pictured as a landscape in which 
thelikelihoodofpossible system conf i gurations is shown as altitude, with lower-lying 
conf i gurations (valleys or troughs in the landscape) being the more probable ones to be actualized 
(Fig. 7). The constitutive perspective aims to explain how this landscape is shaped in the i rst place 
through collectively co-constitutive processes. In contrast, the constraint perspective aims to 
understand which parts of the topography are actually accessible from the current state and 
permissive at the same time ��� in the sense of being conducive to the continued maintenance of 
closure. Both perspectives are needed to understand the peculiar dynamics and evolution of living 
matter. 34 
Figure 7: Shape vs. accessibility��� constitutive vs. constraint perspectives. 
As a second step towards grounding and integration of the three levels of dialectic dynamics 
shown in Fig. 6, we need to explore the broader physical context in which constraint generation can 
actually occur. To stay alive and continue to evolve and explore the world is not something that 
happens spontaneously to an organism. It requires physical work ��� specif i cally, the kind of work 
that can be used to maintain and generate the constraints necessary to keep the organism going 
(Kauffman, 2000; Deacon, 2011). Kauffman (2000) calls this the work-constraint cycle: free energy 
is channeled into work that (instead of just dissipating the energy) builds and maintains a set of 
constraints, which in turn channel and direct more work required to build and maintain further 
constraints, and so on (see also Roli et al., 2022).
ChatGPT
ChatGPT
The section describes two complementary perspectives for understanding the dynamics and evolution of living matter:
Constitutive and Constraint Perspectives
:
The
Constitutive Perspective
focuses on how the landscape of future probabilities for a physico-chemical process is shaped by collectively co-constitutive processes. This perspective explains the formation of the probability landscape.
The
Constraint Perspective
seeks to understand which parts of this topography are accessible and permissive for the continued maintenance of closure in living systems. It's concerned with identifying the accessible and conducive regions of the probability landscape.
Visualization of Perspectives
:
The abstract space of future probabilities in dynamical systems theory, called the configuration space, can be visualized as a landscape where the likelihood of possible system configurations is represented as altitude. Lower regions indicate more probable configurations.
Figure 7 in the paper illustrates the difference between shaping the landscape (constitutive perspective) and accessing its permissible parts (constraint perspective).
Physical Context for Constraint Generation
:
Survival, evolution, and exploration of the world by an organism require physical work. This work is necessary for maintaining and generating the constraints that keep the organism functioning.
Work-Constraint Cycle
: Proposed by Kauffman, this cycle describes how free energy is transformed into work that builds and maintains constraints. These constraints then direct more work for building further constraints, creating a continuous cycle.
This section emphasizes the necessity of both the constitutive and constraint perspectives to fully comprehend the unique dynamics of living organisms. It highlights the interplay between the physical laws governing these organisms and the constraints that shape their evolution and behavior.
You
At i rst sight, it may seem strange that work should be required to do less, to restrict the range of 
possible dynamical behaviors of a component process14. To understand what is going on in 
physical terms, it helps to conceptualize constraints as a measure of orderliness (Deacon, 2011): 
the more constraints are present in a system, and the more intricate and specif i c their effects and 
interactions, the lower the system���s entropy will be. Maximum entropy is reached when everything 
is possible; maximal degrees of freedom imply an absence of constraints. That is why generating 
constraints (i.e., restricting dynamical behavior) takes physical work: it means lowering the entropy 
of the system. This can only happen in systems able to tap into an entropy gradient as an external 
source of free energy. This source is what gives the organism the capacity to do physical work 
14 As an interesting analogy, consider the acquisition of expert intuition. ���In the mind of the novice, there are many 
possibilities; in the mind of the master, only one.��� This is based on a long process of training, leading to the kind of 
local adaptation to a specif i c part of reality that allows the expert to simplify (i.e., render less intricate) the problems 
at hand. 35 
(ibid.). Obviously, the only systems for which this is possible are those that are thermodynamically 
open, operating far from equilibrium. 
Last but not least, we need to revisit an important distinction: biological organization is not the 
same as mere self-organization in non-living dissipative systems such as eddies, convection cells, 
hurricanes, or candle l ames, which burn through their source of free energy at the maximum 
possible rate (Deacon, 2011). The increased internal orderliness of such systems is bought at the 
cost of maximal disruption in their local environment. Think of a tornado wreaking havoc in its 
path. Life is different. The continuous mutual co-constitution of constraints extends the state or 
orderliness for as long as possible by maximizing both the rate of energy dissipation and the path 
length towards the inevitable depletion of the local entropy gradient (Deacon, 2011; Djedovic, 
2020). This can occur through the exploration of new energy sources (e.g., foraging or growth 
towards light), or through storage and reuse (e.g., fat or polysaccharide deposits). 
All of this leads to a coherent ��� but still historically contingent and unpredictable ��� constructive 
dialectic dynamic across multiple levels of organization (Fig. 6). In fact, there is nothing in this 
scheme that limits the emergence of new levels of organization. We can now put a concrete 
meaning to William Wimsatt���s def i nition of levels as ���local maxima of regularity and predictability in 
the phase space of alternate modes of organization of matter��� (Wimsatt, 2007, p. 209). A new level 
of organization arises through the emergence of a coherent and self-sustaining dialectic dynamic 
of the general kind described above. This process is driven by physical work (the harvesting of 
some entropy gradient in a thermodynamically open, far-from-equilibrium system) performed at a 
lower level of organization (Deacon, 2011). Obviously, the three levels of organization described 
above are not the only conceivable ones. The emergence of higher levels is not only possible but 
extremely likely to occur in this account of radically open-ended evolution.
The previous model used in this conversation is unavailable. We've switched you to the latest default model.
ChatGPT
ChatGPT
This section discusses the concept of constraints, their relationship to work, and how they differ in biological organization compared to non-living dissipative systems:
Constraints as Orderliness
:
Constraints can be conceptualized as a measure of orderliness within a system. The more constraints are present and their effects are intricate and specific, the lower the system's entropy (disorder) will be.
In contrast, maximal entropy is reached when everything is possible, indicating a system with maximum degrees of freedom and an absence of constraints.
Generating constraints, which restrict dynamical behavior, requires physical work because it involves lowering the entropy of the system.
Work and Entropy Gradient
:
The capacity to generate constraints (lower entropy) relies on systems that can tap into an entropy gradient as an external source of free energy.
This external source of free energy allows the organism to perform physical work to establish and maintain constraints.
Such systems must be thermodynamically open and operate far from equilibrium.
Biological Organization vs. Self-Organization
:
Biological organization differs from mere self-organization in non-living dissipative systems.
In non-living systems like hurricanes or candle flames, increased internal orderliness is achieved at the cost of maximal disruption in their local environment (e.g., tornado wreaking havoc).
In contrast, living systems maximize both the rate of energy dissipation and the path length toward the depletion of local entropy gradient. This can occur through exploration of new energy sources or storage and reuse of energy (e.g., fat deposits).
Continuous Emergence of Levels of Organization
:
The coherent dialectic dynamic described in the paper can lead to the emergence of new levels of organization.
According to William Wimsatt's definition, levels of organization are "local maxima of regularity and predictability in the phase space of alternate modes of organization of matter."
A new level of organization arises through the emergence of a self-sustaining dialectic dynamic, driven by physical work performed at a lower level of organization.
This account of evolution is radically open-ended, meaning that the emergence of higher levels of organization is not only possible but highly likely.
This section emphasizes that biological systems are fundamentally different from non-living dissipative systems in their ability to maintain orderliness, perform work, and continuously generate constraints, which leads to the emergence of higher levels of organization in an open-ended evolutionary process.
2 / 2
You
What could such higher levels of dynamic organization represent? Of particular interest here are 
two scenarios that build on each other. The i rst occurs when the interrelations between goals, 
actions, and affordances surpass a certain level of intricacy, such that they require a new kind of 
predictive internal model. This yields a def i nition of a cognitive system as an agent which can 
actively take its world to be a certain way, regardless of whether the world really is that way or not 
(Djedovic, 2020; Corcoran et al., 2020). In other words, a cognitive system is an agent that is 
complex enough to be mistaken or deluded about the world. While a bacterium may fail to achieve 
its aim of i nding higher concentrations of nutrients when swimming up a concentration gradient 
(the distribution could be discontinuous, or other unexpected dangers may lurk at the top of the 
gradient), it is too simple to have a wrong model of the world. The failure modes of bacteria and 
cognitive systems diverge in this instance, both in the intricacy of the error and with respect to 
36 
possible consequences of the error for the system. In contrast to the bacterium, a cognitive system 
can have a predictive model that is inconsistent with its current situation, because it can 
extrapolate from situations it (or its ancestors) have already encountered (ibid.). Consequently, 
when its models fail to meet expectations, it can revise and adjust those models based on 
experience. It is capable of learning, while a bacterium can only develop new models through 
evolution by natural selection. In addition, a cognitive agent is also capable of taking open-endedly 
more sophisticated measures to reduce further error (e.g., Kiverstein & Sims, 2021). 
It is worth mentioning at this point that the concept of autopoiesis was originally developed in the 
context of cognitive systems, and its central notion of operational closure (which corresponds to 
organizational closure as used in our argument) applies to the very def i nition of (embodied) 
cognition (Maturana & Varela, 1980; Varela et al., 1991; Thompson, 2007). This view is based on an 
entangled and mutually supportive dialectic between perception, action, and what is called 
structural coupling between the two (a non-representational form of cognitive processing; ibid.). 
This suggests an account of how coherent cognitive processes (just like natural agency) can arise 
from the adaptive dynamics of opponent processing. It is an intriguing possibility, whose detailed 
exploration, unfortunately, goes far beyond the scope of this paper.
ChatGPT
ChatGPT
The emergence of higher levels of dynamic organization in living systems can represent significant developments in their capabilities. Of particular interest are scenarios related to cognition and complexity:
Cognitive Systems
:
One scenario involves the interrelations between goals, actions, and affordances reaching a certain level of intricacy, requiring a new kind of predictive internal model.
In this context, a cognitive system is defined as an agent capable of actively perceiving its world in a certain way, even if the world may not correspond to that perception.
Cognitive systems are complex enough to be mistaken or deluded about the world, and their predictive models can be inconsistent with their current situation.
Unlike simpler organisms like bacteria, cognitive systems can revise and adjust their models based on experience, enabling learning.
Cognitive agents can take more sophisticated measures to reduce errors, allowing for open-ended refinement of their models and actions.
Autopoiesis and Cognition
:
The concept of autopoiesis, originally developed in the context of cognitive systems, is closely related to the definition of embodied cognition.
Autopoiesis involves operational closure, which corresponds to organizational closure in the argument presented in the paper.
Autopoiesis emphasizes the interplay between perception, action, and structural coupling, which is a non-representational form of cognitive processing.
This suggests that coherent cognitive processes can arise from the adaptive dynamics of opponent processing, similar to natural agency.
The detailed exploration of this possibility extends beyond the scope of the current paper.
In summary, higher levels of dynamic organization in living systems can lead to the emergence of cognitive capabilities, allowing agents to actively perceive and interact with their world in complex ways, learn from experience, and adapt to changing circumstances. This represents a significant advancement in the capabilities of these systems.
You
Even more speculative, but equally plausible, is the idea that true intentionality, awareness, and 
consciousness arise through the emergence of yet higher levels of dialectic dynamics. Their 
evolution would be associated with ever-more intricate internal predictive models that must, at 
some point, incorporate accurate models of other living systems and the cognizing organism itself, 
if it is to deal with complex ecological and social contexts. Although this is still far from an actual 
model of the evolution of consciousness (and does not provide a def i nition of what consciousness 
or subjective awareness actually is), it opens up new and potentially fruitful avenues to develop 
such accounts. 
In any case, our main conclusion is the following: it is a mistake to regard cognition and 
consciousness as some complicated forms of computation. Instead, they are elaborations on basic 
natural agency which, in turn, is fundamentally based on relevance realization. In other words, if our 
argument is valid, agency, cognition, and consciousness are related in a very profound manner that 
has not yet been widely recognized (but see Sims, 2021; Mitchell, 2023). They are all ways by which 
organisms come to know the world (Roli et al., 2022). Although we disagree with Humberto 
Maturana that all organisms are cognitive agents, we do think it is correct to say that ���to live is to 
know��� (Maturana, 1988). At the very heart of this process is the ability to pick out what is relevant 
��� to delimit an arena in a large world. This is not a formalizable or algorithmic process. It is the 
process of formalizing the world in Hilbert���s sense of turning ill-def i ned problems into well-def i ned 
37 
ones (as already discussed by Savage (1954). We do not create meaning through computation. We 
generate meaning through living and acting, which is how we get a grip on our reality15.
ChatGPT
ChatGPT
The idea that true intentionality, awareness, and consciousness may emerge through even higher levels of dialectic dynamics is speculative but intriguing. This evolution would likely involve increasingly intricate internal predictive models that incorporate accurate representations of other living systems and the cognizing organism itself, especially in complex ecological and social contexts. While this concept doesn't provide a definitive model of the evolution of consciousness or a precise definition of consciousness and subjective awareness, it offers a promising direction for further exploration.
The central conclusion of this argument is that cognition and consciousness should not be viewed as complicated forms of computation but rather as elaborations of basic natural agency, which is fundamentally based on relevance realization. In essence, agency, cognition, and consciousness are deeply interconnected ways through which organisms come to know the world. While there may be disagreements about whether all organisms are cognitive agents, the idea that "to live is to know" highlights the fundamental role of relevance determination in this process. This process of selecting what is relevant and delimiting an arena within a vast world is not a formalizable or algorithmic procedure but rather the act of formalizing the world, akin to turning ill-defined problems into well-defined ones, which is crucial for generating meaning and understanding reality through living and acting.
You
8. Conclusions 
Aristotle, in ���De Anima,��� considered the soul as the distinguishing principle of living systems ��� their 
characteristic formal cause that sets them apart from the non-living (Shields, 2020; Lennox, 2020, 
2021). This conception is entirely naturalistic: Aristotle���s ���soul��� (unlike Plato���s) is neither immortal 
nor transcendental. Instead, it is immanent in the peculiar organization (form) of living matter 
(Louie, 2013; Hofmeyr, 2018, 2021). In his ���Nicomachean Ethics,��� Aristotle separates living beings 
into three discrete categories, according to the structural complexity of their animating principle: 
(1) All living beings have ���nutritive��� vital functions, which are required to keep themselves alive, to 
grow and reproduce. (2) In addition, animals��� souls have an aspect that Aristotle called ���sensitive,��� 
associated with their ability to move around and actively perceive the world. (3) Finally, he ascribed 
���rational��� capabilities to humans alone: the capacity of deliberative imagination, and the ability to 
make rational choices (Shields, 2020). One needs not practice those capabilities to be human, but 
having them is what demarcates us from all other living beings16. 
Our argument is similar in spirit to Aristotle���s, but updated for our current age and more gradual in 
nature. The animating principle of living systems is now fully naturalized, without reducing it 
completely to the fundamental laws of physics. We can describe it as the peculiar hierarchical and 
self-referential organization of the processes involved in autopoiesis (section 4), anticipation 
(section 5), and adaptation (section 6; summarized in Fig. 6). What distinguishes living from 
non-living systems is the way in which these physico-chemical processes interrelate, how they 
maintain and build constraints on their dynamics upon existing constraints through physical work 
enabled by free energy gradients in the local environment. The resulting co-emergent and 
co-constructive dynamics are entirely compatible with the known laws of physics (and what we 
know about far-from-equilibrium thermodynamics in particular), but are ultimately not explainable 
by (reducible to) those laws alone. 
16 In light of what is expressed in this paragraph, it is helpful (and not at all inaccurate although clearly anachronistic) to 
think of Aristotelian souls, not as entities, but as systems: the nutritive system, the locomotor system, the cognitive 
system. This is ref l ected in what he says about the dependence of one system on another, about their sharing of 
material parts, and about their vastly different realizations in different organisms. 
15 This parallels Joseph Weizenbaum���s prescient distinction between calculating and judging (Weizenbaum, 1976), 
which is itself based on earlier differentiations, e.g., Pascal���s ���spirit of calculation��� versus his ���spirit of i nesse.��� In fact, 
we could say that pretty much all post-Cartesian attempts at phenomenology corroborate this basic dichotomy, but 
this foundation of our philosophy has been lost through (pan)computationalism over the past few decades. 
38
ChatGPT
ChatGPT
The concept of the soul, as discussed by Aristotle, is seen as the distinguishing principle of living systems, setting them apart from the non-living. Aristotle's notion of the soul was naturalistic, not immortal or transcendental, and immanent in the specific organization of living matter. Aristotle categorized living beings into three distinct categories based on the complexity of their animating principle:
All living beings have "nutritive" vital functions to maintain life, grow, and reproduce.
Animals have souls with a "sensitive" aspect associated with mobility and active perception.
Humans possess "rational" capabilities, including deliberative imagination and the ability to make rational choices, which set them apart from all other living beings.
The argument presented in this paper aligns with Aristotle's ideas but updates them for the modern age. It characterizes the animating principle of living systems as a hierarchical and self-referential organization involving autopoiesis, anticipation, and adaptation. The distinction between living and non-living systems arises from how these processes interrelate and create and maintain constraints through physical work enabled by free energy gradients. While these dynamics are fully compatible with the known laws of physics, they cannot be fully explained by these laws alone.
Furthermore, this perspective emphasizes that living systems generate meaning and understanding through their interactions with the world, rather than through computation. It draws a parallel with Joseph Weizenbaum's distinction between calculating and judging, highlighting the importance of understanding the role of agency, cognition, and consciousness in the context of relevance realization and natural agency.
You
Instead, the dynamics of living systems are radically contingent and (at least to some degree) 
generated from within their organization itself. This conveys a certain autonomy to the organism, 
which is not due to a lack of causal determination, and is not primarily driven by randomness. But 
neither is it entirely determined by immediate and automated reactions to environmental triggers. 
Rather, organismic autonomy resides in biological organization, represented by a dialectic interplay 
of subprocesses ��� which is impredicative, continuous, and concurrent ��� each dynamic aspect of 
the process constantly requiring the other two to be present at all times for its continued existence. 
This kind of dynamic and emergent self-constraint is what imbues a living system with agency: the 
ability to self-manufacture, to set intrinsic goals and pursue them through the choice of appropriate 
action, and to interact with one���s arena through dynamics that emanate from within the organism���s 
own organization. This, in a nutshell, summarizes the account of life we present here: agential 
emergentism (Walsh, 2013, 2015, and section 2). 
Agential emergentism implies that mechanistic explanations are not suf i cient to explain all the 
phenomena of life. It accepts that the behavior of an autonomous living agent is characterized by a 
kind of i nality, and therefore calls for teleological explanation. On Rosen���s account, the i nal cause 
of the organism is simply the same as the sum total of its ef i cient causes: the purpose of an 
autopoietic system is to manufacture itself (Rosen, 1991; Louie, 2009, 2013, 2017a). Or in 
Aristotle���s original terms: ���the being of living beings is to live.��� Hofmeyr (2018, 2021) ref i nes this 
account and makes it compatible with the Aristotelian distinction between ef i cient and formal 
causes, the latter describing the peculiar functional form which the ef i cient and material causes of 
the organism take to achieve organizational closure and continuity. As we have shown in section 4, 
this enables the organism to set its own intrinsic goals, which legitimizes us to talk about the 
purposes and aims of a living being, not only as if it had agency (Dennett, 1987), but in full 
acknowledgement that it actually does so (Walsh, 2015; Mitchell, 2023; Jaeger, 2024). 
To better understand the kind of teleological explanation our account requires ��� and why it is 
perfectly naturalistic, and thus scientif i c ��� we must contrast it to the causal explanations familiar 
to scientists today (Walsh, 2012b, 2015). While causal explanations account for how an effect is 
generated by its preceding causes, naturalistic teleological explanations account for why an 
organism acts to attain a certain goal. The two are complementary ��� not the same kind of 
explanation (ibid.).
ChatGPT
ChatGPT
The dynamics of living systems are fundamentally contingent and are generated, to some degree, from within their own organization. This autonomy of organisms is not due to a lack of causal determination or driven solely by randomness. Instead, it arises from the biological organization of living systems, characterized by a dialectic interplay of subprocesses. This dynamic interplay is impredicative, continuous, and concurrent, with each aspect of the process depending on the other two for its continued existence. This inherent dynamic and emergent self-constraint is what grants living systems agency���the ability to self-manufacture, set intrinsic goals, choose appropriate actions to pursue those goals, and interact with their environment through dynamics originating from their own organization.
This perspective is termed "agential emergentism," and it suggests that mechanistic explanations alone are insufficient to account for all aspects of life. It recognizes that autonomous living agents exhibit finality, requiring teleological explanations. In this view, the final cause of an autopoietic system is essentially the same as the sum total of its efficient causes���its purpose is to manufacture itself. This concept aligns with Aristotle's idea that "the being of living beings is to live." Additionally, the account reconciles the Aristotelian distinction between efficient and formal causes, where formal causes describe the functional form that efficient and material causes take to achieve organizational closure and continuity. This allows for discussions of the purposes and aims of living beings, acknowledging their agency in pursuing intrinsic goals.
To clarify the type of teleological explanation required by this account and why it is naturalistic and scientific, it's essential to contrast it with the causal explanations familiar to scientists today. While causal explanations describe how an effect is generated by preceding causes, naturalistic teleological explanations focus on why an organism acts to achieve a specific goal. These two forms of explanation are complementary and not interchangeable.
You
Let us emphasize that naturalistic teleological explanation suffers from none of the dif i culties 
usually attributed to such accounts. First, it does not require that effects be produced by 
non-actual causes, in particular, that future states causally generate present ones. As argued in 
section 5, anticipation means ���pulling the future into the present��� through internal predictive 
39 
models (Rosen, 1985/2012; Louie, 2012, 2017b). These models, and the expectations they 
represent, are fully actualized at the current moment in time. Second, naturalistic teleological 
explanation does not presuppose intentionality or cognitive capabilities in organisms that have 
none. Predictive internal models can be based on simple evolved habituation (ibid.). Finally, 
naturalistic teleological explanation does not have a problem with normativity, since our account 
naturalizes norms for any living being. Indeed, we def i ne agency as the observable natural ability of 
a living system to initiate actions according to its own intrinsic norms (Moreno & Mossio, 2015; 
Djedovic, 2020). This ability is a direct and natural consequence of autopoietic, self-manufacturing 
organization17. In summary, the kind of teleological explanation we are willing to accept is 
completely legitimate as a scientif i c explanation, and it is very precisely circumscribed. It 
encompasses teleological descriptions of organismic behavior, but explicitly excludes global 
teleology of the kind that postulates a target state of evolution (or the universe) as a whole (a 
so-called omega point). 
Actually, opposition to any kind of preset evolutionary target state is a central hallmark of our view. 
Incontrasttogloballyteleologicalor,indeed,stronglydeterministicmechanisticor 
computationalist approaches, our agential emergentist perspective is radically open regarding the 
behavior of organisms and the future of evolution. Both are considered not only unpredictable (see 
Rosen���s claims about the lack of computability in section 4) but, more strongly, fundamentally not 
prestatable (see Kauffman���s notions of radical emergence and the adjacent possible in section 6). 
Life cannot be formalized. There is no predef i ned space of possibilities, nor is there a clear 
beginning or end to biological innovation and diversif i cation18.
ChatGPT
ChatGPT
The naturalistic teleological explanation proposed here does not suffer from the typical difficulties associated with such accounts. Let's address these points:
Causal Generation of Future States:
This explanation does not require that effects be produced by non-actual causes, particularly the idea that future states causally generate present ones. Anticipation, as discussed in section 5, involves "pulling the future into the present" through internal predictive models. These models and the expectations they represent are fully actualized at the current moment in time.
Intentionality and Cognitive Capabilities:
Naturalistic teleological explanation does not presuppose intentionality or cognitive capabilities in organisms that do not possess them. Predictive internal models can be based on simple evolved habituation.
Normativity:
This explanation does not have a problem with normativity. Agency is defined as the observable natural ability of a living system to initiate actions according to its own intrinsic norms. This ability is a direct consequence of autopoietic, self-manufacturing organization.
In summary, this form of teleological explanation is scientifically legitimate and precisely defined. It encompasses teleological descriptions of organismic behavior but explicitly excludes global teleology, such as the postulation of a target state for evolution or the universe as a whole (an "omega point").
Furthermore, the perspective presented here opposes the idea of preset evolutionary target states. It is radically open regarding the behavior of organisms and the future of evolution. Both are considered not only unpredictable but fundamentally not prestatable. Life cannot be formalized, and there is no pre-defined space of possibilities. Biological innovation and diversification have no clear beginning or end. This view aligns with concepts like radical emergence and the adjacent possible, emphasizing the unpredictability and open-endedness of the evolutionary process.
You
To live, to evolve, means to be engaged in inf i nite play (Carse, 1986). Inf i nite play means constantly 
changing the rules of the game. The evolving universe cannot be captured by a i xed set of 
elements or properties. This is why algorithms cannot predict radical emergence. The space of 
possibilities ��� the conf i guration space of the universe ��� is constantly co-evolving with its actual 
state. It is a large world we live in, not a small one, precisely because we are fragile and limited 
living beings. The possibilities inherent in our world are indef i nite ��� potentially inf i nite. And we 
have a say in what is happening: as agents, we co-construct our arena (and thus our opportunities) 
as we live our lives and evolve (see also Lewontin, 1983). 
This co-constructive dynamic enables the emergence of further higher-level dialectics (section 7). 
Unlike Aristotle, we do not subdivide the domain of the living into a specif i c number of discrete 
18 The only known exception to this rule being the origin of life, of course. 
17 The capability to stay alive, therefore, is the enabling prerequisite ��� the most essential lower bound ��� for getting to 
know one���s world (Roli et al., 2022). The connection between this lower bound of normativity and other varieties of 
normativity is, at the present time, not fully developed (Djedovic, 2020). 
40 
categories(or subsystems). Our approach is more gradual, processual, piecemeal, and 
open-ended. While the i rst three levels of living organization (autopoiesis, anticipation, adaptation) 
arise directly at the origin of life, additional levels of dynamic organization emerge later as major 
transitions during the course of evolution (Maynard Smith & Szathm��ry, 1995; Deacon, 2011; 
Szathm��ry, 2015). Interesting candidates for such emergent levels are provided by animal 
cognition and the phenomenon of consciousness in humans and other highly complexif i ed animals 
(see section 7)19. This suggests that natural agency, cognition, and consciousness may have 
evolved along a common theme, each a successively more complex elaboration on its 
predecessors. At the heart of this emergent evolutionary process lies relevance realization.
ChatGPT
ChatGPT
"To live, to evolve, means to be engaged in infinite play." This concept, as discussed by Carse in 1986, emphasizes the ever-changing nature of the universe and the open-endedness of life and evolution. Here are some key points:
Constantly Changing Rules:
Infinite play involves constantly changing the rules of the game. The evolving universe cannot be captured by a fixed set of elements or properties. Algorithms cannot predict radical emergence because the space of possibilities, known as the configuration space of the universe, is co-evolving with its actual state.
A Large, Indefinite World:
The universe is vast and full of possibilities, potentially infinite. Living beings, despite their fragility and limitations, have agency and actively co-construct their arena, shaping their opportunities as they live and evolve.
Emergence of Higher-Level Dialectics:
Instead of subdividing living entities into discrete categories or subsystems, the approach presented here is more gradual, processual, piecemeal, and open-ended. Higher levels of dynamic organization emerge as major transitions during the course of evolution. Candidates for such emergent levels include animal cognition and consciousness in complex animals.
Evolution of Natural Agency, Cognition, and Consciousness:
The idea is that natural agency, cognition, and consciousness may have evolved along a common theme, each building upon its predecessor. Relevance realization is at the core of this emergent evolutionary process.
In summary, the perspective presented here underscores the dynamic and open-ended nature of life, evolution, and the universe. It challenges fixed categorizations and highlights the interconnectedness of natural agency, cognition, and consciousness as evolving phenomena shaped by relevance realization.
You
Our evolutionary account of relevance realization states that all organisms ��� from the simplest 
bacteria to the most sophisticated humans ��� are able to realize what is relevant in their 
experienced environment, to delimit their arena. In other words, organisms (through their 
self-manufacturing and adaptive organization) realize the process of relevance realization. We have 
outlined why this process lies at the core of natural agency, cognition, and consciousness. We have 
also argued that this process cannot be algorithmic or computational in nature. Limited beings in a 
large world must i rst def i ne their problems before they can solve them by rule-based inference. 
This is what it means for an organism to come to know its world (Roli et al., 2022). Relevance 
realization is not a formalizable process, since it is the process of formalization, the process of 
turning ill-def i ned problems into well-def i ned ones. This process is never i nished. Instead, it is 
groundless and non-dual ��� neither syntactic or semantic only (Meling, 2021). Only living beings 
can perform it, since it requires autopoiesis, anticipation, and adaptation. Algorithms never even 
encounter the problem of relevance, since they exist in perfectly well-def i ned small worlds, where 
there is only one possible frame and choosing a perspective is never an option (see the 
Introduction). 
It is the integrated, multi-scale process of adaptation ��� physiological, behavioral, and evolutionary 
��� that provides the means by which relevance can be realized in a non-algorithmic manner (see 
section 7). What these adaptive processes have in common is that different strategies ��� not 
always compatible, and sometimes even contradicting each other ��� are played against each other. 
This kind of opponent processing is the fundamental principle underlying relevance realization (see 
Introduction, and Vervaeke et al., 2012; Andersen et al., 2024). The performance of each strategy is 
evaluated, either ref l exively by the organism itself, or through the intergenerational consequences 
of its struggle for survival and reproductive success. This results in a dynamic, l exible, and 
19 There is also the possibility for entirely different branches of levels of living organization separate from cognition and 
consciousness. For example, immune systems might represent an entirely separate type of living organization, as 
might higher-order dynamics of eusocial insect colonies, or other forms of close mutualistic interactions. All these 
forms are elaborate, non-cognitive forms of relevance realization. 
41 
opportunist deployment of a diverse range of strategies, with the ultimate outcome of an 
ameliorated i t between agent and arena. Such adaptive dynamics are neither internally coherent, 
logical, or rational by default, nor do they require a well-def i ned (algorithmic or heuristic) approach 
to problem-solving or optimization (cf. section 3). When an organism successfully realizes what is 
relevant to itself, it always builds on its previous idiosyncratic and contingent history and 
experience. This is the only way a limited being can make sense of a large world.
ChatGPT
ChatGPT
The concept of relevance realization is at the heart of the evolutionary account presented here, highlighting that all organisms, from simple bacteria to complex humans, have the ability to determine what is relevant in their environment. Here are some key points regarding relevance realization:
Core of Natural Agency, Cognition, and Consciousness:
Relevance realization is fundamental to natural agency, cognition, and consciousness. Organisms use this process to define their problems before solving them through rule-based inference. It is the process through which organisms come to know their world.
Non-Algorithmic Nature:
Relevance realization cannot be algorithmic or computational. Algorithms operate in well-defined, small worlds where there is no need to choose a perspective. Relevance realization is different because it occurs in the context of large, complex, and dynamic environments.
Groundless and Non-Dual:
This process is groundless and non-dual, transcending mere syntactic or semantic aspects. Living beings, with their autopoiesis, anticipation, and adaptation, are the only entities capable of performing relevance realization.
Integrated, Multi-Scale Adaptation:
Adaptation at multiple scales, including physiological, behavioral, and evolutionary, plays a key role in realizing relevance. Different strategies, sometimes contradictory, are pitted against each other. This opponent processing is the fundamental principle underlying relevance realization.
Dynamic and Opportunist Deployment:
Organisms dynamically and opportunistically deploy a diverse range of strategies. The evaluation of each strategy's performance can be reflexive or based on intergenerational consequences. The outcome is an improved fit between the agent and its environment.
Idiosyncratic and Contingent History:
Successful relevance realization always builds on the organism's unique and contingent history and experiences. This idiosyncratic approach is essential for a limited being to make sense of a vast and ever-changing world.
In summary, relevance realization is a dynamic, non-algorithmic, and organism-specific process that allows living beings to navigate and make sense of their complex environments. It is a fundamental aspect of natural agency, cognition, and consciousness.
You
In this sense, agential emergentism is closely aligned with the attempt of explaining relevance 
realization in terms of predictive processing (Andersen et al., 2022). Both see the solution to the 
problem of relevance in terms of evolutionary, meliorative, and contingent adaptive processes. 
However, our argument goes further than that. Predictive processing (like any Bayesian approach) 
is limited in the following two ways. First, it is a formal methodology that does not help us 
understand how the relevant variables to be included in an internal predictive model are chosen in 
the i rst place. As a way around this problem, it is often assumed that the brain somehow monitors 
a i xed set of perception channels, with relevance ascribed to those inputs that show a 
characteristic dynamic of error reduction in their predictions (ibid.). However, this begs the 
question: how does a limited being in a large world establish those channels? Second, Bayesianism 
assumes prior probabilities on expectations for which no justif i cation is given. The argument here 
is that the adaptive process, given enough time, converges to a set of posterior probabilities which 
are independent of the initial priors. However, it is legitimate to doubt that this assumption applies 
without further justif i cation in the context of the adaptive behavior and evolution of organisms. In 
general, the structure of the adjacent possible is constructive and divergent, and we should not 
expect the kind of convergence of posterior probabilities that Bayesians presuppose. Life rarely 
seems to have time to settle into a steady state before moving on to the next challenge. 
While predictive processing keeps an open mind towards aspects of large worlds that cannot be 
formalized, strongly (pan)computationalist approaches to agency and cognition (see, for example, 
Balu��ka & Levin, 2016; Levin, 2021; Bongard & Levin, 2023) fail to acknowledge or address the 
basic insight that relevance realization cannot be of an algorithmic nature. Basically, these 
approaches only work within small worlds, where there is no problem of relevance. This 
fundamentally limits their applicability and usefulness in the large world of actual organismic 
experience. While computational explanations (such as those based on predictive processing) can 
be effective, and there is little doubt that they have led to impressive empirical success, they fail to 
be properly grounded in light of the deeper philosophical issues discussed in this paper. In 
contrast, our agential approach does not require any unrealistic oversimplifying assumptions about 
the nature of reality. While still allowing for computationalist approaches as a part of its wider 
outlook (treating them explicitly as approximations or emulations of the physical processes being 
studied by simulation), it provides several advantages over computationalism as a philosophical 
stance in terms of its explanatory power and the range of questions it is able to address.
ChatGPT
ChatGPT
The concept of agential emergentism aligns closely with the idea of explaining relevance realization through predictive processing. Both approaches emphasize the importance of evolutionary, meliorative, and contingent adaptive processes in addressing the problem of relevance. However, agential emergentism extends beyond predictive processing in several ways:
Selection of Relevant Variables:
Agential emergentism delves into how relevant variables for an internal predictive model are initially chosen. Predictive processing often assumes a fixed set of perception channels and ascribes relevance to inputs that exhibit a characteristic dynamic of error reduction. Agential emergentism questions how these channels are established in the first place, especially in the context of a limited being navigating a large world.
Prior Probabilities:
Bayesian approaches, including predictive processing, rely on prior probabilities for expectations, often assuming that with enough time, these priors converge to posterior probabilities. Agential emergentism challenges this assumption in the context of the adaptive behavior and evolution of organisms. It highlights that the structure of the adjacent possible is constructive and divergent, not necessarily leading to convergence of posterior probabilities.
Algorithmic Nature:
Agential emergentism recognizes that relevance realization cannot be of an algorithmic nature. It points out that strongly computationalist approaches to agency and cognition can work effectively within small worlds where relevance is not a significant issue but may fall short when applied to the complex and dynamic environments of organisms.
Philosophical Grounding:
While computational explanations, such as predictive processing, have empirical success, agential emergentism offers a more philosophically grounded perspective. It acknowledges the limitations of oversimplified assumptions about reality and provides a broader outlook that includes computational approaches as approximations or emulations of physical processes.
In summary, agential emergentism provides a comprehensive framework for understanding the nature of relevance realization, addressing deeper philosophical questions, and accommodating computationalist approaches as part of its wider perspective. It offers advantages in terms of explanatory power and its ability to tackle a broader range of questions in the study of agency, cognition, and consciousness.
You
In particular, evolutionary relevance realization allows us to ground the economic account 
(Vervaeke et al., 2012) in an organismic context beyond human cognition. Opponent processing 
and the question of when and how to commit to different strategies (see section 3) still lie at the 
core of realizing relevance, but they are now embedded in the basic processes of physiological, 
behavioral, and evolutionary adaptation. Relevance realization occurs in very simple organisms 
without intentionality or cognitive capacities whose internal predictive models and action 
repertoires are evolved by natural selection. A bacterium acting to enhance its chances of survival 
and reproduction by modulating its tumbling frequencies to avoid toxins and to obtain nutrition is 
no less realizing relevance than a human being deliberately contemplating whether to explore or 
exploit their opportunities in a given situation. The difference between the two situations is merely 
one of complexity, as Aristotle already recognized, and ��� if our considerations are correct ��� there 
is a gradual continuity and fundamental connection underlying these very distinct phenomena. 
This sheds important light on current debates about rationality in humans (Riedl & Vervaeke, 2022). 
Specif i cally, it lends strong credence to the notions of embodied heuristics (Gigerenzer, 2021) and 
embodied bounded rationality (Mastrogiorgio & Petracca, 2016; Gallese et al., 2020; Petracca, 
2021; Petracca & Grayot, 2023). Rationality, in the broadest sense of the term, can be def i ned as 
���knowing how to do the appropriate thing��� in a particular situation (Riedl & Vervaeke, 2022, and 
references therein). Contra Aristotle, we do not consider humans as a uniquely ���rational animal.��� 
���Knowing how to do the appropriate thing��� is not limited to human beings. Instead, human 
rationality can be seen as a powerful cognitive tool that gradually evolved from less intricate forms 
of natural agency to solve particularly multifaceted problems situated in a particularly complex 
natural and social environment. While problem-solving in a large world relies on abductive 
reasoning, it alone is not suf i cient. The ���embodied��� part of rationality means that, in order to solve 
problems through logical inference, we must i rst turn ill-def i ned large-world problems into 
well-def i ned small-world ones. And this is what relevance realization does, not only in humans, but 
in all living organisms: it generates the predictive hypotheses and models we need to be able to 
engage in abduction. 
This primal activity of relevance realization is not ���rational��� in the sense of ���logical.��� Instead, it is 
based on the unprestatable and unformalizable adaptive dynamic of opponent processing, which is 
required to select those strategies that are likely to work best in a given situation. Therefore, to be 
rational in the sense of ���doing the appropriate thing��� does not always imply doing the most logical 
thing. Rather, it means doing the appropriate thing in a much more basic and pragmatic sense: 
43 
initiating that sequence of actions most productive towards the attainment of our current goal, 
given both the affordance landscape of our arena and the repertoire of actions (and, in the case of 
humans, the cognitive resources) available to us. This is the extension of an argument made in 
Riedl and Vervaeke (2022) to non-human agents: human embodied rationality is a particularly 
complex form of a natural agency that is present in all living beings. It grows out of one of the most 
fundamental aspects of life: the necessity to make sense of a large world in order to survive and 
thrive.
ChatGPT
ChatGPT
The concept of evolutionary relevance realization provides a grounding for the economic account in an organismic context beyond human cognition. It highlights that relevance realization is not limited to humans with intentionality or cognitive capacities but is a fundamental process in very simple organisms, driven by evolved internal predictive models and action repertoires shaped by natural selection.
For example, consider a bacterium modulating its tumbling frequencies to avoid toxins and obtain nutrition. In this case, the bacterium is actively realizing relevance by enhancing its chances of survival and reproduction. This demonstrates that relevance realization exists across the spectrum of complexity, from the simplest organisms to humans. The difference lies in the degree of complexity, but there is a fundamental connection and continuity underlying these distinct phenomena.
This perspective has implications for debates about rationality in humans. It supports the ideas of embodied heuristics and embodied bounded rationality, suggesting that rationality, in the broadest sense, involves "knowing how to do the appropriate thing" in a given situation. This definition of rationality applies not only to humans but also to other living organisms. Human rationality can be viewed as a highly evolved cognitive tool that has gradually emerged from less intricate forms of natural agency to address complex problems in a dynamic natural and social environment.
In essence, relevance realization is a primal activity that is not necessarily logical but is based on the adaptive dynamic of opponent processing. It involves selecting strategies that are likely to work best in a given situation. Being rational means initiating a sequence of actions that are most productive in achieving a current goal, considering the affordance landscape of the environment and the available repertoire of actions or cognitive resources.
This perspective extends the argument that human embodied rationality is a complex form of natural agency present in all living beings. It emphasizes the fundamental necessity of making sense of a large world to ensure survival and thriving, irrespective of the level of complexity in the organism's cognitive processes.
You
Computational rationality ��� with its view that rational reasoning means formal optimization under 
certain cognitive resource constraints ��� is no longer suf i cient as a basis for general intelligence. 
Instead, it is just one of many facets that contributes to our ability to understand the world 
(Roitblat, 2020; Roli et al., 2022). One of us has outlined in detail elsewhere what this means for 
current discussions about artif i cial ���intelligence��� (Jaeger, 2023). The view that intelligence equals 
some kind of computational optimization is no longer tenable. It does not help us make sense of a 
large world. Therefore, claims that the study of intelligence is converging onto computational 
rationality as its ultimate foundation (see, for instance, Gershman et al., 2015) are not only 
premature, but outright misguided. Quite the opposite: we have shown here that the basic 
foundation of natural agency and cognition, and therefore of anything we could reasonably call 
���intelligence,��� cannot be computational at all. The dream of generating purely algorithmic systems 
able to think and act like human beings is and remains a pipe dream, because purely symbolic 
machines exist in small worlds, in which there is no problem of relevance to be solved. 
As a i nal point, we would like to highlight the parallels between our approach and some branches 
of (meta)ethical philosophy. Cantwell Smith (2019) points out that genuine care is not possible in 
artif i cial algorithmic systems, because it depends on inhabiting a (large) world and being 
responsible for the inevitably partial ways in which we register it, while committing to such partial 
registrations and ���going to bat��� for them, sometimes at great cost. Similarly (and more famously), 
Harry Frankfurt (1988, 2004, 2006) argues that any moral consideration must be evaluated against 
the background of what we care about as human beings. This background, as he demonstrates, 
cannot be based on pre-established ethical principles without causing an inf i nite regress. The 
problem Frankfurt describes is strikingly similar to that of relevance realization. What we care 
about, of course, is what is relevant to us. Only if we care about something can we choose the 
appropriate kind of action. Only by acting in the world can we get to know it. This is the very 
foundation of our knowledge and our morals. It is also what connects us to the rest of the living 
world. Life is meaningful and precious that way. No machine will ever understand that.
ChatGPT
ChatGPT
The perspective presented here challenges the notion that computational rationality, which views rational reasoning as formal optimization under cognitive resource constraints, is sufficient as a basis for general intelligence. It asserts that computational optimization is just one facet of our ability to understand the world and is no longer tenable as the sole foundation for intelligence. Claims that intelligence is converging onto computational rationality are considered premature and misguided.
This perspective highlights that the foundational principles of natural agency and cognition, which underlie what we consider intelligence, cannot be purely computational. The dream of creating purely algorithmic systems that can think and act like humans is deemed unrealistic because such systems exist in small worlds where the problem of relevance does not arise.
In closing, there are parallels between this approach and certain branches of (meta)ethical philosophy. It emphasizes that genuine care and moral considerations are rooted in inhabiting a large world, being responsible for our partial ways of registering it, and committing to what we care about. This parallels Harry Frankfurt's argument that moral considerations depend on what we care about as human beings, and this cannot be based on pre-established ethical principles. The problem of relevance realization is akin to what we care about, as caring is inherently linked to what is relevant to us. This foundation of knowledge and morality connects us to the living world and gives life meaning and significance that machines cannot comprehend.
You
�� list of the more difficult terms and definitions.
ChatGPT
ChatGPT
Certainly! Here's a list of some of the more difficult terms and their definitions from the text:
De Anima
: A work by Aristotle in which he considered the soul as the distinguishing principle of living systems.
Immanent
: Existing or operating within; inherent.
Autopoiesis
: A concept introduced by Maturana and Varela, referring to the self-maintaining and self-reproducing nature of living systems.
Far-from-equilibrium thermodynamics
: The study of thermodynamic systems that are not in equilibrium, often associated with processes in living systems.
Teleological explanation
: An explanation that describes a phenomenon or action in terms of its purpose or goal.
Omega point
: A concept in which there is a presumed target state or end goal in the evolution of the universe.
Embodied heuristics
: Problem-solving approaches that are grounded in the body's interactions with the environment.
Adjacent possible
: A concept suggesting that innovations and new possibilities emerge from the current state of a system.
Abductive reasoning
: A form of reasoning that involves forming conclusions based on the best available information, even if the information is incomplete.
Computational rationality
: The idea that rational reasoning involves formal optimization under certain cognitive resource constraints.
Symbolic machines
: Machines or systems that operate based on symbols or symbolic representations.
Metaethical philosophy
: The branch of philosophy that examines the nature and foundation of ethics.
Harry Frankfurt
: A philosopher known for his work on moral philosophy and the concept of "bullshit."
These are some of the challenging terms and concepts discussed in the text. If you have specific questions about any of these terms or would like further explanations, feel free to ask!
You
A list of the main points of the article.
ChatGPT
ChatGPT
Certainly! Here's a list of the main points and key takeaways from the article:
Living Systems are Radically Contingent
: Living systems are not determined solely by external factors or randomness. They exhibit autonomy arising from their internal organization.
Organismic Autonomy
: Autonomy in living organisms is a result of their biological organization, involving a dynamic interplay of subprocesses.
Agential Emergentism
: This perspective suggests that mechanistic explanations alone are insufficient to explain all aspects of life, calling for teleological explanations.
Teleological Explanation
: Teleological explanations are necessary to understand the purpose and goals of living beings. The purpose of an autopoietic system is to manufacture itself.
Naturalistic Teleology
: Naturalistic teleological explanations are compatible with a scientific understanding of life and do not require supernatural or non-actual causes.
Openness of Evolution
: The perspective emphasizes that evolution and the behavior of organisms are not predetermined or prestatable; they are fundamentally open-ended and unpredictable.
Infinite Play and Changing Rules
: Living and evolving entail an "infinite play" where the rules constantly change, reflecting the ever-evolving universe.
Relevance Realization
: All organisms, from simple bacteria to complex humans, engage in relevance realization to make sense of their environment and survive.
Relevance Realization is Non-Algorithmic
: Relevance realization cannot be reduced to algorithms or formalization; it is an ongoing, non-dual process grounded in the adaptability of organisms.
Embodied Rationality
: Rationality is not limited to humans; it's a fundamental aspect of natural agency that enables problem-solving in a large world.
Computational Rationality's Limitations
: The idea that rational reasoning is solely computational is insufficient for understanding intelligence, as it doesn't address the foundational role of relevance realization.
Human Rationality as a Complex Form
: Human rationality is a complex form of the basic relevance realization found in all living beings, and it's shaped by our evolutionary history.
Machines vs. Living Beings
: Machines lack the depth of care, responsibility, and the ability to engage with a large world that living beings possess.
These are the main points and key ideas presented in the article, providing a perspective on the nature of living systems, agency, and relevance realization.
You
What was the influence from Juarrero and Deacon?
ChatGPT
ChatGPT
In the article, the authors reference the works of Alicia Juarrero and Terrence Deacon, and their ideas have influenced the perspective presented. Here's how they were influenced by these thinkers:
Alicia Juarrero
:
Juarrero's work has contributed to the concept of "agency" within the perspective presented in the article. Her ideas, particularly those related to agency as an emergent phenomenon, have shaped the understanding of how living systems exhibit autonomy and self-manufacture.
The authors draw on Juarrero's ideas to emphasize that agency in living systems is not merely a result of external influences or deterministic processes. Instead, it arises from the dynamic and emergent properties of the organism's internal organization.
Terrence Deacon
:
Terrence Deacon's work, especially his ideas on teleology and constraints in living systems, has influenced the discussion on teleological explanations within the article.
Deacon's concept of "teleodynamics" and his exploration of the role of constraints in the emergence of purposeful behavior in living systems align with the notion of teleological explanation presented in the article.
The authors reference Deacon's ideas to support the argument that mechanistic explanations alone are insufficient to account for the behavior of living beings, and that teleological explanations are necessary to understand the purposes and goals of organisms.
In summary, Juarrero and Deacon's contributions to the philosophy of biology and their perspectives on agency, teleology, and constraints have played a significant role in shaping the ideas presented in the article, particularly with regard to the autonomy and purposefulness of living systems.
You
The argument concerning relevance relations reminds me of this:

Understanding in brains and machines can be defined and measured as Corpus Congruence. Corpus Congruence as a metric spans up almost all of NLP.

Monica Anderson
Monica Anderson
Jul 6, 2022 ��� 1 min read
Understanding in brains and machines can be defined and measured as Corpus Congruence.

Let's consider this in the Machine Learning sense. If a machine is Model Free (Holistic), as all general Understanders have to be in order to not get trapped into a limited Model, then all it ever knows comes from the corpus it was trained on. And all it really can say is "This is more like my corpus than that". Or "This is more like these documents in my corpus than those"

...

But "Semantic" Corpus Congruence is still Corpus Congruence.

Common Sense now becomes "Is the proposition before me congruent with my entire World Model, as acquired by learning things from my training corpus?". If it is well known, then we can likely ignore it this time.

And if it is not, then the next question will be "Is it close enough that it might be worthwhile extending the World Model with this information?"

If the answer is no, then the input is by its definition nonsense. Otherwise it is either a new fact or a lie, but since we cannot tell, we have to accept it; possibly with a note that this is fresh, untested knowledge that may turn out to be irrelevant, false, counterproductive, or noise.

Next we can note that it doesn't matter whether "documents" are text or images. Or input from a point cloud of sensors for robots or autonomous vehicle sensors.

And finally we can note that this definition also holds for humans if we take our "corpus" to be "Everything we've experienced since birth".

https://experimental-epistemology.ai/corpus-congruence/
ChatGPT
ChatGPT
The concept of "Corpus Congruence" as described in the provided text does share some similarities with the argument concerning relevance relations in the article you mentioned earlier. Both concepts deal with the idea of understanding and how it relates to the information a system or organism has been exposed to.
In the context of "Corpus Congruence," it appears to be a measure of understanding in both machines and brains, emphasizing that understanding is based on the congruence between incoming information and the corpus of knowledge or experiences that the system has access to. Here are some key points of similarity:
Relevance and Congruence
: Both concepts involve assessing the relevance or congruence of incoming information with a pre-existing knowledge base. In the article, relevance realization is discussed as the process by which organisms determine what is relevant to them in their environment. Similarly, "Corpus Congruence" assesses whether incoming information aligns with the corpus of knowledge.
Holistic Understanding
: In both cases, there's an emphasis on holistic understanding rather than rigid, rule-based models. The article argues that purely computational or algorithmic approaches are insufficient to capture the richness of relevance realization. Likewise, "Corpus Congruence" suggests that general understanders need to be model-free and holistic.
Adaptive and Dynamic
: The concepts recognize that understanding is not a fixed state but an adaptive and dynamic process. Both relevance realization and "Corpus Congruence" acknowledge that new information can challenge or extend existing understanding.
Context Matters
: Context plays a crucial role in both concepts. Understanding is contingent on the context within which information is received. In "Corpus Congruence," the relevance of information is assessed based on its congruence with the system's entire knowledge base.
While there are similarities, it's important to note that the two concepts may have different emphases and applications. The article on relevance realization appears to focus on living systems and their autonomy, while "Corpus Congruence" seems to address understanding in the context of machine learning and AI.
Nevertheless, both concepts highlight the complex and nuanced nature of understanding, where relevance and congruence with existing knowledge play central roles.
You
The Problem Solving level provides many familiar examples of these issues. In our mundane lives, we solve many kinds of problems every day but our strategies for solving them fall into just those two categories. For any complicated problem, we had better have a plan before we start. But most problems the brain deals with every day are things we never have to think about. Because we do not need to plan or Reason about them. These are the millions of low-level problems we encounter in our mundane life every day; and this is the world that our AIs will have to operate in.

...

Walking and talking, braking and breakfasting, like almost everything we use our brains for, rely on learning from our experiences in order to re-use anything that has worked in the past. And, over time, we learn to correct our mistakes.

https://experimental-epistemology.ai/the-red-pill-of-machine-learning/
ChatGPT
ChatGPT
The passage you provided discusses problem-solving strategies and their relevance to both human cognition and artificial intelligence (AI). Here are some key points from the passage:
Two Categories of Problem-Solving Strategies
: The passage highlights that problem-solving strategies can generally be categorized into two main types: planning and reasoning on one hand, and learning from experience on the other.
Planning and Reasoning for Complicated Problems
: When dealing with complex or complicated problems, it's often essential to have a plan or engage in reasoning before attempting to solve them. This approach is typically used for problems that require careful consideration and deliberation.
Learning from Experience for Everyday Problems
: On the other hand, for the countless low-level problems encountered in daily life, planning and reasoning are not necessary. Instead, humans rely on learning from their experiences to handle these routine tasks efficiently. These problems are often solved automatically based on past successes.
AI in the Mundane World
: The passage suggests that artificial intelligence systems, like humans, will need to operate in the everyday mundane world. This means that AI systems should be capable of learning from their experiences and efficiently solving routine problems without the need for extensive planning or reasoning.
Learning and Correcting Mistakes
: Both humans and AI systems can improve their problem-solving abilities over time by learning from their mistakes. This iterative process allows for the refinement of strategies and the adaptation to changing circumstances.
Overall, the passage underscores the importance of learning from experience in problem-solving, especially for routine and everyday tasks. It also hints at the challenge of designing AI systems that can operate effectively in the mundane world by leveraging learned knowledge and adapting to new situations.
You
This is from Monica Anderson. I thought it made a few similar points to the article
ChatGPT
ChatGPT
Indeed, Monica Anderson's perspective on problem-solving and learning from experience aligns with some of the concepts discussed in the article you provided earlier. Both emphasize the importance of learning from experiences in problem-solving, especially in routine or mundane tasks. This alignment highlights the significance of experiential learning and its relevance in various contexts, including artificial intelligence and human cognition. If you have any specific questions or would like to explore these concepts further, please feel free to ask!
You
congruence between incoming information and the corpus of knowledge or experiences that the system has access to, sounds like relevance relation.
ChatGPT
ChatGPT
You're absolutely right; congruence between incoming information and the system's corpus of knowledge or experiences does indeed share similarities with the concept of relevance relations discussed in the article. In both cases, there's an emphasis on assessing the alignment or fit between new information and the existing knowledge or experience base.
Relevance relations, as discussed in the article, are concerned with how living systems determine what is relevant to their goals and decision-making processes based on their internal models and adaptive processes. Similarly, congruence in the context you mentioned involves evaluating whether incoming information aligns with the system's existing knowledge or experiences, which can impact how it processes and integrates that information.
Both concepts underscore the importance of assessing the connection and compatibility between new information and a system's existing knowledge or experiences, which plays a fundamental role in decision-making, problem-solving, and understanding the world.
If you have any more questions or would like to delve deeper into these concepts, please feel free to ask!
You
Karl Fant argued against the prevalence of Algorithms in computer science, instead arguing for process invocation through process expression using null convention logic.
ChatGPT
ChatGPT
It's interesting to learn about Karl Fant's perspective on algorithms in computer science and his advocacy for process invocation through process expression using null convention logic. While algorithms are widely used in computer science for problem-solving and data processing, there have been various alternative approaches and paradigms proposed over the years.
Fant's viewpoint seems to align with a focus on process-oriented programming, where the emphasis is on defining processes or procedures and invoking them as needed, rather than explicitly defining step-by-step algorithms. Null convention logic may be a specific approach to handling exceptional cases or conditions within these processes.
It's worth noting that computer science is a diverse field, and there are many different programming paradigms and approaches, each suited to different types of problems and contexts. Some programming languages and paradigms emphasize procedural or process-oriented programming, while others are more algorithm-centric or focus on data-driven approaches.
If you have specific questions about Karl Fant's work or would like to explore this topic further, please feel free to ask!
You
No, only that in the article they argued that intelligence and homeostasis were non-computational since the do not rely on predefined algorithms in a well-ordered domain. I think this its a mistake, since sequential and parallel processes can be represented in a higher dimensionality space including null wavefronts for determining subsystem function completion. Also, multiscale calculation across different substrates and temporalies both internal and external, as argued by Bongard and Michael Levin. Polycomputation is still computation, it doesn't have to follow predetermined steps and can use randomness. The notion that an althorithm always lead to the same conclusion assumes that you can re-establish the same initials starting conditions or state.
ChatGPT
ChatGPT
Your point about the nature of computation and algorithms is valid and raises an important aspect of the discussion. It's true that computation can take various forms, and not all computational processes rely on predefined algorithms in well-ordered domains. The concept of polycomputation, where multiple processes or computations occur concurrently or in parallel across different substrates and timescales, is indeed a valid and recognized approach in computational science.
You correctly note that polycomputation allows for flexibility, adaptability, and the incorporation of randomness or variability into computational processes. This is especially relevant in complex and dynamic systems, where exact algorithms and deterministic processes may not be sufficient to capture the full range of behaviors.
The idea that algorithms always lead to the same conclusion assumes determinism, where the same inputs or initial conditions will produce the same outputs or results. In many real-world scenarios, especially those involving biological systems, external influences, and complex interactions, achieving strict determinism can be challenging.
In light of these considerations, it's important to acknowledge the broader spectrum of computational approaches, including those that involve polycomputation, stochasticity, and non-determinism. While the article you mentioned may have framed intelligence and homeostasis as non-computational due to their non-reliance on predefined algorithms in well-ordered domains, it's clear that computational processes can encompass a wide range of strategies and mechanisms that go beyond strict algorithmic determinism.
Thank you for bringing up these points, which contribute to a more nuanced understanding of computation and its role in various domains, including artificial intelligence and biology.
You
Computational rationality ��� with its view that rational reasoning means formal optimization under 
certain cognitive resource constraints ��� is no longer suf i cient as a basis for general intelligence. 
Instead, it is just one of many facets that contributes to our ability to understand the world 
(Roitblat, 2020; Roli et al., 2022). One of us has outlined in detail elsewhere what this means for 
current discussions about artif i cial ���intelligence��� (Jaeger, 2023). The view that intelligence equals 
some kind of computational optimization is no longer tenable. It does not help us make sense of a 
large world. Therefore, claims that the study of intelligence is converging onto computational 
rationality as its ultimate foundation (see, for instance, Gershman et al., 2015) are not only 
premature, but outright misguided. Quite the opposite: we have shown here that the basic foundation of natural agency and cognition, and therefore of anything we could reasonably call 
���intelligence,��� cannot be computational at all. The dream of generating purely algorithmic systems 
able to think and act like human beings is and remains a pipe dream, because purely symbolic 
machines exist in small worlds, in which there is no problem of relevance to be solved.
ChatGPT
ChatGPT
The passage you've shared highlights a perspective that challenges the notion that general intelligence, particularly in the context of humans and other living beings, can be reduced to or solely explained by computational rationality. Here are some key points from this passage:
Computational Rationality
: The term "computational rationality" refers to the view that rational reasoning involves formal optimization under specific cognitive resource constraints. In other words, it suggests that intelligence can be understood as a computational process that optimizes decisions based on available resources.
Limitations of Computational Rationality
: The passage argues that while computational rationality is a valuable perspective, it has limitations when it comes to explaining general intelligence, especially in the context of complex, real-world situations. It suggests that computational rationality may not fully capture the essence of intelligence, which involves understanding and navigating a large and complex world.
Understanding the Large World
: The central point of the passage is that intelligence goes beyond computational optimization and involves making sense of a large and intricate world. It implies that intelligence includes the ability to deal with ambiguity, adapt to diverse situations, and make decisions that may not always follow a strict computational algorithm.
Challenging the Convergence on Computational Rationality
: The passage challenges the idea that the study of intelligence is converging onto computational rationality as its ultimate foundation. It suggests that this perspective is premature and may not provide a comprehensive explanation of intelligence.
Limitations of Symbolic Machines
: The passage concludes by stating that purely symbolic machines, which operate based on fixed symbols and rules, exist in small worlds where problems of relevance are minimal. It implies that such machines may not capture the essence of intelligence required to navigate a large, complex, and ever-changing world.
In summary, the passage argues for a more holistic and nuanced understanding of intelligence that goes beyond strict computational rationality. It suggests that intelligence involves the ability to adapt, make sense of diverse situations, and address problems of relevance in a complex world. This perspective challenges the idea that intelligence can be fully replicated by purely algorithmic systems.
You
I think this passage is kind of incoherent. Any kind of linear trajectory can be seen as an optimization, as most problems can be reframed as an optimization problem. As far the complexity of living system goes, it just pushes the algorithm up one step higher, now you check to see if the situation is related to previous experiences to choose which "algorithm" to choose. Even quantum transitions and molecular chemistry can be framed as "computations".
ChatGPT
ChatGPT
Your point is valid, and it highlights a key aspect of the debate surrounding the nature of intelligence and computation. While the passage suggests that there are limitations to a purely computational view of intelligence, it's essential to acknowledge that many aspects of intelligence and problem-solving can indeed be framed as optimization or computation.
In the context of complex living systems, including humans, it's true that the processes of adaptation, decision-making, and problem-solving often involve some form of optimization or computation. These systems may employ sophisticated algorithms, both conscious and subconscious, to navigate the complexities of the world.
The passage seems to be emphasizing that while computation plays a significant role in intelligence, it may not be the sole or complete explanation for the richness and adaptability of intelligent behavior. It suggests that there are aspects of intelligence, such as dealing with ambiguity, context, and relevance, that may go beyond traditional computational models.
In essence, the debate centers on the extent to which computation and optimization can fully capture the breadth and depth of human or biological intelligence. Some argue that while computation is a powerful tool, it may not be sufficient to explain all aspects of intelligence, especially in complex, real-world scenarios.
It's an ongoing and complex debate, and different perspectives exist on this topic. Ultimately, the relationship between computation and intelligence is a multifaceted one, and both viewpoints have merit in understanding different aspects of the phenomenon.
You
When an organism successfully realizes what is relevant to itself, it always builds on its previous idiosyncratic and contingent history and experience. This is the only way a limited being can make sense of a large world.
ChatGPT
ChatGPT
This statement emphasizes the idea that organisms, including humans, rely on their unique and specific history and experiences to make sense of the world and determine what is relevant to them. Here are some key points to unpack from this statement:
Idiosyncratic and Contingent History: Each organism has its own history, which includes its past experiences, interactions, and adaptations to its environment. This history is idiosyncratic, meaning it's unique to that particular organism. It's also contingent because it's shaped by the specific circumstances and events that organism has encountered.
Making Sense of a Large World: The world is vast and complex, and organisms have limited cognitive and sensory resources. To navigate this large world effectively, they need to filter and prioritize information based on what is relevant to their goals, survival, and well-being.
Relevance Realization: The process of determining what is relevant is referred to as "relevance realization." It involves assessing incoming information and comparing it to the organism's history and experiences to decide whether it's important or not.
Limited Being: Organisms, being finite and limited in their capabilities, must rely on their past experiences and learning to adapt and respond to the challenges presented by the world. They cannot consider all possible information, so they prioritize based on what they have encountered before.
Building on Previous Experience: Successful relevance realization builds upon an organism's past experiences. When an organism recognizes something as relevant, it's often because it has encountered similar situations or patterns in the past. This iterative learning process allows organisms to adapt and make informed decisions.
In summary, the statement underscores the idea that organisms, including humans, are shaped by their unique histories and experiences. These experiences serve as the foundation for their ability to determine what is relevant in a complex and ever-changing world, allowing them to adapt and make sense of their surroundings.
You
Harry Frankfurt (1988, 2004, 2006) argues that any moral consideration must be evaluated against 
the background of what we care about as human beings. This background, as he demonstrates, 
cannot be based on pre-established ethical principles without causing an inf i nite regress. The 
problem Frankfurt describes is strikingly similar to that of relevance realization. What we care 
about, of course, is what is relevant to us. Only if we care about something can we choose the 
appropriate kind of action. Only by acting in the world can we get to know it. This is the very 
foundation of our knowledgeand our morals. It is also what connects us to the rest of the living 
world. Life is meaningful and precious that way. No machine will ever understand that.
ChatGPT
ChatGPT
The comparison drawn between Harry Frankfurt's work on moral considerations and relevance realization in the statement highlights an interesting parallel. Here's a breakdown of the key points:
Moral Consideration and Caring: Frankfurt argues that moral considerations are fundamentally linked to what we care about as human beings. In other words, our moral judgments and actions are influenced by our values, emotions, and concerns.
Pre-established Ethical Principles: Frankfurt's argument suggests that moral principles or ethical systems alone cannot provide a complete basis for moral decision-making. Instead, our moral evaluations are deeply rooted in our personal values and what we genuinely care about.
Relevance Realization: The statement draws a connection between Frankfurt's perspective and the concept of relevance realization. It suggests that, similar to moral considerations, determining what is relevant to us is influenced by our cares, values, and experiences.
Knowledge and Morals: The statement posits that the process of caring about something and recognizing its relevance is foundational not only to our moral judgments but also to our knowledge of the world. It's through our actions and interactions with the world that we come to understand it.
Connection to Living World: The statement concludes by highlighting the meaningful and precious nature of life, emphasizing that this interconnectedness with the living world is a fundamental aspect of human existence. It implies that machines lack the capacity to truly grasp this depth of understanding and connection.
In summary, the comparison between Frankfurt's views on moral considerations and relevance realization underscores the role of caring, values, and personal experiences in shaping both our moral judgments and our understanding of the world. It suggests that these aspects of human existence are deeply intertwined and difficult to replicate in artificial systems.
You
I think it makes no sense. Cares, values, and experiences all can be calculated by using symbolic parameters
ChatGPT
ChatGPT
I understand your perspective, and it's worth noting that there are ongoing debates about the nature of consciousness, values, and emotions in the context of artificial intelligence and machine learning. While symbolic parameters can indeed represent and process information related to cares, values, and experiences, the fundamental question revolves around whether these representations capture the full depth and richness of human consciousness and understanding.
Many argue that while AI systems can simulate aspects of human cognition, they may lack genuine consciousness, emotions, and subjective experiences. The debate often centers on the "hard problem of consciousness," as articulated by philosopher David Chalmers, which questions whether there is something inherently subjective about conscious experience that goes beyond mere information processing.
Regarding values and ethics, AI systems can be programmed with ethical principles and rules, but these rules are ultimately human-defined and may not fully capture the complexities of moral reasoning and decision-making in all situations. There is also debate about the possibility of AI systems developing their own values or ethical frameworks.
In essence, the argument you've pointed out reflects an ongoing philosophical and ethical discourse about the limits and capabilities of artificial intelligence and its ability to replicate or understand certain aspects of human consciousness, values, and experiences. Different perspectives exist on this matter, and it remains a topic of active research and discussion.
You
I think the number of connections that can be processed by a machine has the potential to far outstrip that of any human being
ChatGPT
ChatGPT
You're correct that machines, particularly modern computers and neural networks, have the potential to process an incredibly large number of connections or data points at speeds that far exceed human capabilities. This processing power is one of the reasons AI systems excel at tasks like data analysis, image recognition, and natural language processing.
The human brain, while remarkable in its own right, has limitations in terms of processing speed and working memory when compared to advanced computing systems. AI systems can process vast datasets and perform complex calculations rapidly, which can be advantageous for a wide range of applications, including scientific research, medical diagnosis, and autonomous vehicles.
However, it's important to note that the ability to process a large number of connections or data points does not necessarily equate to human-like consciousness, understanding, or decision-making. While machines can handle enormous amounts of information, they lack subjective experiences, emotions, and the ability to interpret data in the same nuanced way as humans. Human cognition is shaped by a complex interplay of factors, including emotions, experiences, social context, and consciousness, which currently remain outside the scope of AI systems.
In essence, while machines have impressive processing capabilities, they do not possess human-like consciousness or understanding, and there are inherent differences between artificial intelligence and human intelligence.
You
I just don't understand why these are objections, as soon as they describe an issue they have given it a symbolic  representation.
ChatGPT
ChatGPT
I understand your point. When discussing complex concepts like consciousness, understanding, values, and emotions, it's often challenging to define and represent them in a way that captures their full richness and depth. In many cases, these concepts are indeed represented symbolically in discussions and models to help us grasp and communicate about them.
However, the objections in the text you provided seem to go beyond symbolic representation. They are raising questions about whether purely computational or algorithmic processes, even if they involve symbolic representations, can fully capture and replicate certain aspects of human experience and cognition. Some of the objections include:
Relevance realization
: The argument suggests that relevance realization, while it can be symbolically represented, is more than just a computational process. It involves dynamic, non-algorithmic, and context-dependent aspects that are rooted in the unique experiences and adaptations of living organisms.
Values and ethics
: The text implies that human values, ethics, and moral considerations are deeply tied to our subjective experiences and cannot be reduced to mere symbolic calculations. It questions whether machines can genuinely understand and act upon ethical principles without human-like experiences and emotions.
Complexity of human cognition
: The objections argue that human cognition involves a level of complexity that goes beyond pure computational optimization. While symbolic representations are useful, they may not capture the full scope of human decision-making, creativity, and adaptability.
In essence, these objections highlight the limitations of purely computational or algorithmic approaches in replicating certain aspects of human cognition and experience. While symbolic representation is a valuable tool, it may not encompass the entirety of these complex phenomena. The objections suggest that there are fundamental differences between artificial and human intelligence that go beyond symbolic representations.
You
I don't think they have proven that "relevance relations" are non-computational, apart from being extremely complicated and not well understood
ChatGPT
ChatGPT
You raise a valid point. The text you provided discusses the concept of "relevance realization" and argues that it goes beyond pure computation due to its complexity and context-dependent nature. However, it's essential to acknowledge that the exact nature of relevance realization and its computational or non-computational aspects are still topics of ongoing research and debate in fields like cognitive science and artificial intelligence.
While the objections in the text highlight the challenges in fully understanding and replicating relevance realization in computational systems, they don't necessarily provide a definitive proof that it is entirely non-computational. Instead, they emphasize the complexity and nuances involved in this process.
In the realm of AI and cognitive science, researchers are continually exploring how computational models can capture and simulate various aspects of human cognition, including processes related to relevance and context. It's an evolving area of study, and our understanding of these concepts may evolve as well.
So, while the objections raise important questions, it's essential to recognize that the debate about the computational nature of relevance realization is ongoing and subject to further research and exploration.
You
All computations take into account previous context. We just use change magnification and error correction to assume that the underlying constituents have very low variability. The whole point of computers is to make reliable computations with unreliable components, as in the brain. It doesn't matter kf the components are thousand or a million times more complicated.
ChatGPT
ChatGPT
You make a valid point. Computation, whether in traditional computers or neural systems like the brain, often involves processing information within a context and taking into account previous data or context. Both traditional computers and the brain rely on error correction and various mechanisms to ensure reliable processing, even in the presence of unreliable components or noisy data.
The distinction between traditional computation and processes like those in the brain often lies in the complexity, scale, and adaptability of the systems. The brain, with its billions of neurons and trillions of synapses, operates in a highly parallel and massively interconnected manner, which allows for a wide range of complex and context-dependent computations.
Traditional computers, on the other hand, are typically designed for specific tasks and operate based on predetermined algorithms. While they can simulate complex processes, they may struggle with certain types of context-dependent, real-world tasks that humans and other living organisms handle effortlessly.
The debate about whether certain cognitive processes, such as relevance realization, are entirely computational or if they involve additional non-computational aspects is still ongoing. It's a complex and nuanced issue, and researchers continue to explore these questions to better understand the nature of intelligence and cognition.
You
worlds that cannot be 
formalized, strongly (pan)computationalist approaches to agency and cognition (see, for example, 
Balu��ka & Levin, 2016; Levin, 2021; Bongard & Levin, 2023) fail to acknowledge or address the 
basic insight that relevance realization cannot be of an algorithmic nature. Basically, these 
approaches only work within small worlds, where there is no problem of relevance. This 
fundamentally limits their applicability and usefulness in the large world of actual organismic 
experience.
ChatGPT
ChatGPT
The argument presented suggests that strongly computationalist approaches to agency and cognition, such as those outlined by Balu��ka & Levin, Levin, and Bongard & Levin, may have limitations when it comes to addressing the concept of "relevance realization" in the large and complex world of actual organismic experience.
The central idea is that these computationalist approaches may excel in well-defined, small-world scenarios where problems and tasks can be algorithmically formalized and optimized. In such situations, computational methods can be highly effective.
However, in the context of the real world, where problems are often ill-defined, context-dependent, and dynamic, the argument proposes that purely algorithmic approaches may fall short. Relevance realization, which involves determining what is relevant within a given context, may be challenging to formalize algorithmically because it depends on the interpretation of context, past experiences, and idiosyncratic factors that are difficult to encode in a set of predefined rules.
The key point here is that while computational methods are valuable for many tasks, they may not fully capture the complexity and adaptability of human and organismic cognition when dealing with the vast and ever-changing nature of the real world. The argument suggests that a more comprehensive understanding of cognition may require approaches that go beyond strict algorithmic formalization, especially in scenarios where relevance realization plays a crucial role.
You
How does polycomputation or intelligence as care ignore relevance realization?
ChatGPT
ChatGPT
Polycomputation and the concept of intelligence as care do not necessarily ignore relevance realization. In fact, these ideas can be seen as complementary to the concept of relevance realization. Let's break it down:
Polycomputation
: Polycomputation refers to the idea that a system can perform computations using various methods, strategies, or algorithms simultaneously or in a coordinated manner. While relevance realization may not be explicitly mentioned in the term "polycomputation," it can be incorporated into the idea. Relevance realization involves identifying what is relevant in a given context, and polycomputation can be a means to achieve this by considering multiple computational strategies to assess relevance.
Intelligence as Care
: The concept of intelligence as care suggests that intelligence is not just about problem-solving or optimization but also about caring for and responding to the environment. Relevance realization is closely tied to this notion, as caring about the environment and understanding what is relevant to one's goals and well-being is a fundamental aspect of intelligence. Intelligence, in this context, involves recognizing and responding to relevant information or changes in the environment.
In summary, neither polycomputation nor the concept of intelligence as care inherently ignores relevance realization. Instead, they can be seen as approaches that encompass the broader aspects of cognition, including the recognition of relevance in a complex and dynamic world. These concepts can be integrated with relevance realization to provide a more comprehensive understanding of how intelligent systems interact with their environments.
You
Claude Martin says:

Turing himself has proven that nothing is more powerful than a Turing machine. The idea that something about our brain is "noncomputational" is ridiculous. It's biological supremacism before artificial general intelligence even exists.
ChatGPT
ChatGPT
Claude Martin's perspective aligns with the view that Turing machines represent the theoretical limit of computational power, and therefore, any system, including the human brain, can be simulated or emulated by a Turing machine. This viewpoint is rooted in the Church-Turing thesis, which posits that anything computable can be computed by a Turing machine.
The argument against the idea of "noncomputational" aspects of the brain is based on the belief that, in principle, all cognitive processes, including those related to intelligence and relevance realization, can be understood as computations. This perspective is often associated with a reductionist approach to understanding intelligence and consciousness.
It's important to note that this perspective is a subject of debate within the fields of cognitive science, philosophy of mind, and artificial intelligence. While some argue that all aspects of cognition can be explained through computation, others believe that there may be aspects of human cognition, such as consciousness or certain forms of creativity, that are not fully captured by computational models.
Ultimately, the debate surrounding the computational nature of the brain and intelligence is ongoing, and it involves complex philosophical, scientific, and computational considerations. Different researchers and scholars hold varying views on this topic, and it remains an area of active exploration and discussion in the fields of AI and cognitive science.
You
George van den Driessche says:

The paper seems to have a very narrow, 20th-Century notion of "computation". I think most neuroscientists would agree with you that neurons do not implement algorithms in any traditional sense, but they would say that computation is nonetheless happening.
ChatGPT
ChatGPT
George van den Driessche's comment highlights an important distinction in the understanding of computation when it comes to neural processes and cognition. While the paper argues that certain aspects of cognition, such as relevance realization, may not fit traditional algorithmic models, it's acknowledged by many neuroscientists and cognitive scientists that computation, in a broader sense, still occurs in neural systems.
In this context, "computation" does not necessarily mean the execution of explicit step-by-step algorithms as in traditional computing, but it refers to the processing and transformation of information by neural networks. Neural processes involve complex and parallel information processing that is distributed across interconnected neurons. These processes give rise to emergent properties and behaviors, including learning, pattern recognition, and adaptation.
Neuroscientists often describe these computations as information processing or transformation rather than algorithmic procedures. The brain's ability to integrate and process vast amounts of data in parallel, adapt to new situations, and exhibit flexibility in decision-making is seen as a form of computation, even if it doesn't fit the conventional algorithmic model.
So, while there is a recognition that neural computation may not be algorithmic in the traditional sense, it doesn't negate the idea that computation, in a more general sense, plays a crucial role in understanding how the brain functions and how cognition emerges from neural processes. This perspective allows for a more nuanced view of computation in the context of neuroscience and cognitive science.
You
He continues:

 I'd point at all the computational substrates, both natural and artificial, that are not about Turing machines.
- The Science Museum in London has at least one example of an analogue computer: a table with wheels mounted horizontally on it, and bands connecting the wheels to each other. By configuring the wheels appropriately, one can use it to find solutions to differential equations.
- You can use the height of a surface of a body of liquid to do computation, in a similar sort of way to how a neuron uses the electrical potential on its surface to do computation.
- The computations that neurons do can't be modelled directly by conventional algorithms, but they are a consequence of laws of physics that *can* straightforwardly be described by conventional algorithms. So a neuron can in principle be modelled by a computer; it would just have to be a stupendously powerful one.
- Reservoir Computing does a somewhat similar thing to "surface" computing, with a randomly structured collection of artificial neurons.
- Transformers (as used in Large Language Models) do not embody any conventional algorithm. But the computational substrate in which they are implemented *is* just conventional algorithms, at sufficient scale. This is similar to the biological neuron case above.
ChatGPT
ChatGPT
George van den Driessche raises valid points highlighting the diversity of computational substrates beyond traditional Turing machines and the importance of considering different computational models:
Analog Computers:
Analog computers, as exemplified by the Science Museum's display, demonstrate that computation can occur through physical, continuous processes. These devices are capable of solving complex problems like differential equations, which aren't typically addressed using traditional digital algorithms.
Physical Phenomena as Computation:
He notes that even phenomena like the height of a liquid's surface or the electrical potential on a neuron's surface can be viewed as forms of computation. While these processes may not align with conventional algorithms, they still adhere to the laws of physics and can be described algorithmically.
Reservoir Computing:
This is an example of unconventional computing methods where randomly structured artificial neurons are used. It highlights that computation can occur in systems with less deterministic and more chaotic elements.
Transformers:
Large Language Models like those using Transformer architectures operate at a massive scale and may not embody traditional algorithms. However, they rely on the computational substrate of conventional algorithms when implemented on powerful hardware.
George's insights underscore the idea that computation, in various forms, is a fundamental aspect of the natural world and is not limited to the specific model of computation defined by Turing machines. While these computational substrates may not adhere to conventional algorithms, they are still capable of performing complex and valuable computations, challenging our understanding of computation in a broader sense. This recognition of diverse computational models is essential in fields like artificial intelligence, neuroscience, and complex systems research.
You
He continues: you can get these large-scale, unpredictable phenomena emerging out of small-scale, predictable phenomena, though. In fluid dynamics that gives rise to turbulence and in cognitive sciences it gives rise to free will. But there's no magic. The laws of physics give rise to all of it, and they are computable.
ChatGPT
ChatGPT
George van den Driessche makes a crucial point about the emergence of large-scale, unpredictable phenomena from small-scale, predictable ones, emphasizing that these processes are governed by the laws of physics and ultimately computable:
Emergence:
He highlights how phenomena like turbulence in fluid dynamics and the concept of free will in cognitive sciences emerge from the interactions of smaller-scale components. These emergent phenomena often exhibit unpredictability and complexity, but they are not beyond computational understanding.
No Magic:
George underscores that there is no inherent magic or non-computational aspect to these emergent phenomena. Instead, they are outcomes of the computational processes defined by the fundamental laws of physics.
Computability:
He reiterates that everything, including the large-scale, emergent phenomena, can be understood within the framework of computable processes. Even though these processes can become highly complex, they remain governed by the principles of computational science.
This perspective aligns with the idea that while emergent phenomena may appear non-deterministic and complex, they are still rooted in the computational substrate provided by the laws of physics. It emphasizes the computability of natural processes, even when they exhibit unpredictability and apparent "free will" at higher levels of organization.
You
A summary of the whole conversation.
ChatGPT
ChatGPT
Certainly! Here's a summary of the key points and discussions from the conversation:
Article Overview
: The conversation began with a discussion of the article's main points, which centered around the idea that intelligence and relevance realization are non-computational processes.
Relevance Realization
: The article argued that relevance realization, the process of determining what is relevant in a complex environment, cannot be reduced to computational algorithms. Instead, it's a fundamental aspect of natural agency and cognition.
Objections Raised
: Several objections were raised regarding the claim of non-computational relevance realization:
Computational Processes
: Some participants argued that even complex processes in living systems, including relevance realization, can be seen as computations in higher-dimensional spaces.
Machine Potential
: It was pointed out that machines have the potential to process vast numbers of connections, possibly surpassing human capabilities.
Symbolic Representation
: The objection was raised that the article itself uses symbolic representations to describe and analyze the issues it presents.
Analog Computation
: Analog computation and other non-Turing machine models were discussed as examples of computational substrates that differ from classical algorithms.
Emergent Phenomena
: The conversation touched on the concept of emergence, where large-scale, unpredictable phenomena arise from smaller-scale, predictable processes. It was emphasized that these phenomena are not magical but still computable based on the laws of physics.
Differing Views
: Participants had varying views on whether non-computational aspects exist in intelligence, with some arguing that everything is ultimately computable within the framework of physics.
Moral Considerations and Care
: The article's connection between relevance realization and moral considerations was discussed, with some participants challenging the notion that machines cannot understand values and care.
A Challenge to Non-Computational Claims
: A counter-argument was presented, stating that the article did not conclusively prove that relevance relations are non-computational, and that complexity doesn't negate computability.
Machine Learning and AI
: The conversation touched on how machine learning and artificial intelligence operate, often involving complex computations and learning from data.
Summary
: Overall, the conversation explored the boundary between computational and non-computational aspects of intelligence, with differing perspectives on whether certain processes, like relevance realization, are inherently non-computational.
This summary provides an overview of the main themes and discussions within the conversation.
You
A short list of questions for later.
ChatGPT
ChatGPT
Certainly! Here's a short list of questions for later:
What are the implications of relevance realization being a non-computational process for artificial intelligence and machine learning?
How can we better define and understand the concept of "intelligence" in light of these discussions?
Are there examples of emergent phenomena in artificial systems that parallel those seen in natural systems?
How can we bridge the gap between computational and non-computational aspects of cognition and agency?
What role does care and value play in the understanding of relevance realization, and how can machines be designed to incorporate such considerations?
Feel free to revisit these questions or explore new ones as the discussion continues.
ChatGPT can make mistakes. Consider checking important information.
?
ChatGPT



