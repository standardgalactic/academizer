Convergent Solutions to Frame Problem
Open sidebar
Convergent Solutions to Frame Problem
Model: Default (GPT-3.5)
Summarize: Predictive processing and relevance realization: exploring 
convergent solutions to the frame problem 
Brett P. Andersen1 �� Mark Miller2,3 �� John Vervaeke4 
Extended author information available on the last page of the article 1 3 
B. P. Andersen et al. 
referred to as the ���frame problem��� and cognitive scientists have long grappled with 
some version of this question (Dennett, 1987; McCarthy & Hayes, 1969; Vervaeke et 
al., 2012). In this paper we aim to show that two important frameworks for thinking 
about how we separate signal from noise have converged on a very similar answer, 
though they have used a dif f erent vocabulary and set of concepts to describe it. By 
establishing the connection between these frameworks, we aim to show that (a) the 
story they tell is more likely to be correct, since convergence on a single answer from 
two dif f erent frameworks is an indicator of plausibility, and (b) that these frameworks 
can mutually support and inform each other such that fruitful insight can be gained 
through their synthesis.
1 / 1
ChatGPT
ChatGPT
This paper by Brett P. Andersen, Mark Miller, and John Vervaeke explores convergent solutions to the "frame problem," a long-standing issue in cognitive science concerning how we discern meaningful information from irrelevant noise. The authors focus on two significant frameworks - Predictive Processing and Relevance Realization - arguing that they've each provided a similar answer to the frame problem, albeit using different terminologies and concepts.
The authors believe that the convergence of these two different frameworks on a single answer indicates its likely correctness. Moreover, they suggest that these frameworks can complement and inform each other, leading to insightful discoveries when synthesized. The ultimate aim of the paper is to underline the potential for a more robust understanding of cognitive processing, which can be achieved by integrating these two frameworks.
1 / 1
In the middle of the 20th century artif i cial intelligence researchers discovered 
what Dennett (1987) called a ���new, deep epistemological problem��� that came to be 
known as the frame problem. In its original form, this problem consisted of how to 
program an artif i cially intelligent agent to intelligently take into account the side 
ef f ects of its actions. For example, if a robot needs to retrieve a battery, but the bat- 
tery is on a wagon that also has a bomb on it, the robot must be able to realize that 
retrieving the battery will bring the bomb along with it (thus resulting in its own 
destruction). This may seem like a relatively simple issue, but it turned out to be 
incredibly complicated. The problem is that there are a nearly inf i nite number of 
potential side ef f ects to any particular action. How can we program the robot to take 
into account the relevant side ef f ects while intelligently ignoring the irrelevant ones? 
We cannot program the robot to systematically assess all of the possibilities because 
there are far too many. Furthermore, as artif i cial intelligence researchers quickly dis- 
covered, there is no algorithm that can solve this problem. This particular version of 
the frame problem turned out to be only one manifestation of a more general problem 
in cognitive science. How can a cognitive agent zero in on relevant aspects of the 
world (i.e., signal) and intelligently ignore irrelevant aspects of the world (i.e., noise; 
Vervaeke et al., 2012)? Indeed, this problem is so pervasive that Vervaeke and col- 
leagues (2012) label relevance realization as the criterion of the cognitive, suggest- 
ing that ���any attempt to engineer an intelligent system must ultimately focus on the 
development of a system that can realize relevance��� (p. 7). This cannot be a system 
where relevance is given to the system a priori. Relevance is not a stable class of 
entities because that which is relevant for an organism is always in fl ux. As such, an 
intelligent system must be able to continually realize what is relevant to it even as the 
context in which it is doing this is changing. 
Predictive processing (PP) is an emerging framework in cognitive science which 
depicts the mind as being engaged in a proactive process of prediction-error mini- 
mization (Clark, 2013, 2015; Friston, 2010; Hohwy, 2013). This framework sug- 
gests that we separate signal from noise by forming expectations about the ���precision��� 
(technically the inverse variance) of incoming prediction errors and assigning a 
higher ���weight��� to prediction errors which are treated as highly precise (Feldman 
& Friston, 2010). Highly precise prediction errors are then given more inf l uence in 
driving action and updating predictions (Clark, 2015). Importantly, the broad crite- 
rion which determines how the brain will assign precision is relevance, meaning that 
signals which are more pragmatically or epistemically relevant to the organism are 
assigned greater precision and thus have a greater ef f ect on downstream processing 
1 3 
Predictive processing and relevance realization: exploring convergent��� 
(Clark, 2017). The PP framework thus assigns the role of separating signal from 
noise to the process of precision-weighting, which serves to assign dif f erent weights 
to select sensory inputs, which also has the ef f ect of determining the relative inf l u- 
ence of bottom-up prediction errors and top-down predictions on our perceptions and 
actions. 
Relevance realization (RR) is another emerging framework in cognitive science 
which takes a dynamical systems perspective to explain how the mind separates sig- 
nal from noise (Vervaeke et al., 2012; Vervaeke & Ferraro, 2013). RR refers to a 
cognitive agent���s ability to intelligently ignore irrelevant information and zero in on 
those aspects of the world that are relevant to their goals. The RR framework sug- 
gests that the brain achieves this feat by attempting to balance the competing goals 
of remaining ef i cient in the current environment while also being resilient in the 
face of environmental perturbations. By self-organizing around a set of opponent- 
processing relationships related to this ef i ciency-resiliency tradeof f , the brain is able 
to zero in on relevant information. Vervaeke and colleagues (2012) identif i ed three 
lower-order tradeof f s related to the higher-order ef i ciency-resiliency tradeof f , which 
are the exploration-exploitation tradeof f , specialization-generalization tradeof f , and 
focusing-diversifying tradeof f . 
In this paper we will provide evidence for a continuum of individual dif f erences 
related to the diametric model of autism and psychosis (Andersen, 2022; Crespi & 
Badcock, 2008; Crespi & Dinsdale, 2019; Del Giudice et al., 2014; Dinsdale et al., 
2013) and show that dif f erences along this autism-schizotypy continuum are related 
to all three of these lower-order tradeof f s. Importantly, we will show that individual 
dif f erences in the way that people handle these tradeof f s can be explained through 
individual dif f erences in the way that precision is assigned to sensory input (e.g., Andersen 2022; Van de Cruys et al., 2014). This example will serve to demonstrate 
that the tradeof f s described by the RR framework are also inherent to precision- 
weighting, indicating that these dif f erent frameworks are pointing to the same under- 
lying process. 
Precision-weighting is sometimes said to be at risk of becoming a ���magic modu- 
lator���, a variable that can be adjusted without constraints to fi t every explanation 
(Litwin & Mi��kowski, 2020; Miller & Clark, 2018). By showing that precision- 
weighting simply is the PP account of RR, this concern should be largely alleviated. 
RR describes a set of trade-of f relationships that inevitably constrains what an organ- 
ism can fi nd relevant. If our thesis is correct, these constraints are also inherent to 
precision-weighting. Thus, connecting these frameworks should serve to enrich the 
PP story by describing the tradeof f s that inf l uence how an organism���s perceptual sys- 
tem assigns precision to select sensory inputs and top-down predictions. On the other 
hand, by connecting RR to precision-weighting, RR can be integrated into a large 
and growing framework which has been put forward as a way to unify the cogni- 
tive and psychological sciences (Hutchinson & Barrett, 2019). The tradeof f relation- 
ships described by RR can thus be used to suggest testable hypotheses to empirical 
researchers investigating cognition within a Bayesian or PP framework. Thus, our 
proposed synthesis between RR and PP should serve to mutually support and enrich 
these disparate frameworks.
1 / 1
ChatGPT
ChatGPT
This paper delves into the "frame problem" identified in artificial intelligence (AI) research. Originally, the problem was about how to program an AI agent to understand the consequences of its actions. For example, a robot must discern the potential risks of retrieving a battery from a wagon that also contains a bomb.
This problem is more complex than it appears, as there's a near-infinite number of potential side-effects for any action. Additionally, there's no algorithm that can solve it. The issue extends to a broader cognitive science problem - how a cognitive agent identifies relevant aspects (signal) of the world and discards irrelevant ones (noise).
The authors discuss two emerging cognitive science frameworks: Predictive Processing (PP) and Relevance Realization (RR). PP sees the mind as engaged in prediction-error minimization. This framework suggests that we separate signal from noise by forming expectations about the 'precision' of incoming prediction errors and assigning a higher 'weight' to prediction errors which are treated as highly precise.
RR takes a dynamical systems perspective to explain how the mind separates signal from noise. It refers to a cognitive agent���s ability to intelligently ignore irrelevant information and focus on what's relevant to their goals. This balance is achieved by self-organizing around efficiency-resiliency trade-offs.
The paper suggests that individual differences in handling these trade-offs can be explained through differences in how precision is assigned to sensory input. This example demonstrates that the trade-offs described by RR are also inherent to precision-weighting, indicating that these different frameworks are pointing to the same underlying process.
Linking these frameworks enriches the PP story by describing the trade-offs that influence how an organism���s perceptual system assigns precision to select sensory inputs and top-down predictions. Conversely, by connecting RR to precision-weighting, RR can be integrated into a broader framework aiming to unify cognitive and psychological sciences. Therefore, the proposed synthesis between RR and PP should serve to mutually support and enrich these disparate frameworks.
1 / 1
Our argument is structured as such: In Sect. 1 we introduce RR and describe the 
tradeof f s inherent to RR. In Sect. 2 we introduce PP and explain the role of precision- 
weighting in this framework. Section 3 contains the main argument of the paper. 
In Sect. 3 we introduce the diametric model of autism and psychosis, including its 
manifestation in non-clinical populations as the autism-schizotypy continuum. We 
show that the tradeof f s inherent to both precision-weighting and RR manifest along 
this autism-schizotypy continuum and can be understood as dif f erences in precision- 
weighting along this continuum. By demonstrating this overlap, we aim to demon- 
strate that precision-weighting and RR are dif f erent ways of looking at the same 
underlying process. Section 4 shows that the meta-tradeof f inherent to RR (ef i ciency 
vs. resilience) is the same as the meta-tradeof f inherent to the free energy principle 
(reducing redundancy vs. maximizing degeneracy). In the concluding Sect. 5, we 
detail out the implications of this overlap. 
1 Tradeof f s inherent to relevance realization 
Vervaeke and colleagues (2012) suggest that there is a constellation of problems 
within cognitive science that can all be considered as specif i c manifestations of the 
more general problem of relevance realization (RR). Vervaeke and colleagues (2012) 
put forward a theory of how intelligent systems achieve this feat through the ongo- 
ing pursuit of competing goals which are traded of f against each other. Vervaeke 
and colleagues (2012) argue for the existence of three important tradeof f s which are 
inherent to RR. These tradeof f s result from a cognitive system���s pursuit of compet- 
ing goals which are in an opponent processing relationship with each other such that 
���the mechanism behind relevance realization is ultimately the process that enables 
the brain to balance these competing goals��� (Vervaeke et al., 2012, p. 12). The auto- 
nomic nervous system provides an example of opponent processing that may serve to 
clarify the concept. The two parts of the autonomic nervous system ��� the sympathetic 
and parasympathetic systems ��� are in an opponent-processing relationship with each 
other. The sympathetic nervous system activates the fi ght or fl ight response, putting 
the body in a state of high alert when necessary. The parasympathetic nervous system 
is involved in returning the body to a state of calm. Thus, two systems which are (in 
some sense) pitted against each other are necessary for the regulation of arousal. Dys- 
function in either system leads to dysregulated arousal. The regulation of what we 
fi nd relevant is similar to this process in that RR also entails systems and goals which 
are pitted against each other in an opponent processing relationship. 
The tradeof f s inherent to RR are (a) the tradeof f between exploration and exploita- 
tion, (b) the tradeof f between specialization and generalization, and (c) the tradeof f 
between focusing and diversifying. There is also a higher-order tradeof f between 
ef i ciency and resiliency which encompasses the three lower-order tradeof f s. 
1.1 Exploration-Exploitation 
A pervasive problem faced by all organisms consists of deciding whether or not to 
exploit current opportunities or search for better ones (Carver & Scheier, 1998; Del 
1 3 
Predictive processing and relevance realization: exploring convergent��� 
Giudice & Crespi, 2018; Mehlhorn et al., 2015). Should I continue to eat from the 
current patch of berries or leave to search for a better one? Should I marry my current 
partner or keep dating? Should I buy the house being advertised to me or keep search- 
ing? These exploration-exploitation tradeof f s are ubiquitous in nature (Mehlhorn et 
al., 2015). Vervaeke and colleagues (2012) argue that a system which is optimizing 
for the dynamic balance between exploration and exploitation is engaging in rel- 
evance realization.
1 / 1
ChatGPT
ChatGPT
The paper is structured as follows: Section 1 introduces Relevance Realization (RR) and describes its inherent trade-offs. Section 2 introduces Predictive Processing (PP) and explains the role of precision-weighting in this framework. Section 3 is the crux of the paper, introducing the diametric model of autism and psychosis and its manifestation as the autism-schizotypy continuum in non-clinical populations. It shows how the trade-offs inherent to both precision-weighting and RR manifest along this continuum. By demonstrating this overlap, the authors aim to illustrate that precision-weighting and RR are different perspectives on the same process. Section 4 demonstrates that the meta-trade-off inherent to RR (efficiency vs. resilience) aligns with the free energy principle (reducing redundancy vs. maximizing degeneracy). The concluding Section 5 details the implications of this overlap.
Vervaeke and colleagues suggest that many cognitive science problems can be seen as specific manifestations of the broader problem of RR. They propose a theory of how intelligent systems manage this through the ongoing pursuit of competing goals that are traded off against each other. They identify three significant trade-offs intrinsic to RR, resulting from a cognitive system���s pursuit of competing goals which oppose each other.
The trade-offs inherent to RR are:
The trade-off between exploration and exploitation: This pervasive problem involves deciding whether to utilize current opportunities or search for better ones. A system that optimizes for the dynamic balance between exploration and exploitation is engaging in RR.
The trade-off between specialization and generalization.
The trade-off between focusing and diversifying.
There's also a higher-order trade-off between efficiency and resiliency, which encompasses the three lower-order trade-offs.
1 / 1
1.2 Specialist-generalist 
Another problem faced by all organisms consists of whether they should devote 
resources towards creating special-purpose machinery or general-purpose machinery 
(Chen et al., 2020; Zhou et al., 2005). Vervaeke and colleagues (2012) refer to this 
as the problem of cognitive scope. Should an organism focus on the particularities 
of specif i c situations (as in a ���microscope���) or zoom out to produce more generaliz- 
able machinery (as in a ���telescope���)? The optimal solution to this tradeof f depends 
on the volatility of the environment. Whereas specialists will tend to thrive in highly 
stable environments, generalists will do (relatively) better in highly volatile situa- 
tions (Chen et al., 2020; Zhou et al., 2005). However, an intelligent system must 
fi nd a way to balance between the competing goals of being highly specialized for a 
particular environment and producing generalizable solutions that will be useful even 
if the environment shifts. 
1.3 Focusing-diversifying 
All complex organisms have multiple motivational systems which they must fi nd a 
way to balance. For example, Schaller and colleagues (2017) posit the existence of 
fundamental motivations in people related to disease avoidance, status-seeking, mate 
acquisition/retention, and achieving basic physiological needs such as getting an 
adequate amount of food. Given limited time and resources, people will necessarily 
have to focus on one or more of these domains at the expense of others (Del Giudice 
et al., 2015). Vervaeke and colleagues (2012) suggest that RR entails an opponent- 
processing relationship between devoting ef f orts towards satisfying multiple motiva- 
tional systems (i.e., diversifying) and focusing ef f orts on one or a few motivations. 
1.4 Ef i ciency-resiliency 
The three trade-of f s outlined above can all be considered manifestations of a higher- 
order tradeof f between the need to be as ef i cient as possible in the current economy 
while simultaneously remaining resilient in the face of environmental changes (Ver- 
vaeke et al., 2012). In a process that is akin to natural selection, resiliency entails 
increased variation while ef i ciency involves selection, or a culling of unnecessary 
cognitive structures. The need to be ef i cient while remaining resilient results in the 
increasing complexif i cation (i.e., integration for ef i ciency and diversif i cation for 
resiliency) of brain functioning over the course of development (Vervaeke et al., 
2012; Vervaeke & Ferraro, 2013). All of these tradeof f s will be discussed further 
1 3 
B. P. Andersen et al. 
below in the context of the diametric model of autism and psychosis. We will now 
introduce PP before showing the convergence between PP and RR.
1 / 1
ChatGPT
ChatGPT
The second trade-off discussed is the Specialist-Generalist trade-off, a problem faced by all organisms where they must decide whether to allocate resources towards creating special-purpose or general-purpose machinery. This is referred to by Vervaeke and colleagues as the problem of cognitive scope. The optimal solution to this trade-off depends on the volatility of the environment. In stable environments, specialists tend to thrive, while generalists fare better in highly volatile situations. However, an intelligent system needs to balance between specializing for a particular environment and generating generalizable solutions that will still be useful if the environment changes.
The third trade-off, Focusing-Diversifying, arises from the fact that all complex organisms possess multiple motivational systems which need to be balanced. Given limited time and resources, individuals must focus on one or more of these domains at the expense of others. Vervaeke and colleagues propose that RR implies an opponent-processing relationship between devoting efforts towards satisfying multiple motivational systems (diversifying) and focusing efforts on one or a few motivations.
Finally, Efficiency-Resiliency is a higher-order trade-off that underlies the previous three. It describes the need to be as efficient as possible in the current economy while simultaneously remaining resilient to environmental changes. Like natural selection, resiliency requires increased variation while efficiency involves a selection or culling of unnecessary cognitive structures. This need for efficiency and resilience results in an increase in the complexity of brain functioning over the course of development, integrating for efficiency and diversifying for resiliency.
These trade-offs will be further discussed in the context of the diametric model of autism and psychosis. The paper will then introduce Predictive Processing (PP) before demonstrating the convergence between PP and RR.
1 / 1
2 The predictive processing framework 
According to this popular new theory emerging from computational neuroscience, 
the brain might best be described as a prediction error minimizing engine (Bubic et 
al., 2010; Clark, 2013; Hohwy, 2013; Nave et al., 2020). These sorts of engines, if 
we���re on the right track, are endlessly proactive ��� continually attempting to predict 
their own streams of sensory stimulation before they arrive. Predictive brains go 
about generating our rich perceptual experiences and adaptive behaviors by continu- 
ally learning about the temporal and spatial regularities that underlay the changing 
environment, and leveraging this information to generate increasingly better pre- 
dictions about the hidden causes that underlay our ongoing experiences. When top- 
down predictions match the bottom-up signals well enough, a perceptual experience 
occurs. When it doesn���t, the discrepancy between the prediction and the actual signal 
(referred to as ���prediction errors������) either moves forward through the system help- 
ing to ref i ne future predictions (e.g., that the hose alongside the house isn���t a snake), 
or it provokes actions aimed at making the sensory stream better fi t the predictions 
(e.g., placing my cof f ee cup back in its regular place on my desk). And so, when you 
see that steaming cof f ee-cup on the desk in front of you, your perceptual experience 
ref l ects the multi-level neural guess that best reduces visual prediction errors. To 
visually perceive the scene, if this story is on track, your brain attempts to predict the 
scene, allowing the ensuing error (mismatch) signals to ref i ne its guessing until a kind 
of equilibrium is achieved. 
A novel feature of this framework is the tight link it establishes between knowl- 
edge, perception, and action. The brain here uses prior knowledge to make probabi- 
listic predictions about the structure of the environment, which cashes out as both 
perception and world-altering action. In the process of continually attempting to pre- 
dict the next sensory input, and using any errors to update those predictions, the brain 
learns about the actionable world. This partnership between knowledge, perception, 
and action allows the human brain to leverage a lifetime���s worth of learning in order 
to respond to the newsworthy aspects of an otherwise chaotic stream of data. 
The whole predictive system is further nuanced by ongoing second order expec- 
tations it makes about the reliability of its own predictions in any given situation. 
In other words, part of what such systems are predicting moment to moment is the 
reliability of their own prediction errors. Precision weighting, formally the inverse 
variance of the prediction error signal, can be used to hone in on those streams of 
information that are most likely to yield adaptive predictions. Our experiences and 
active engagements with the world are not only a matter of the generative model 
instantiating a layered model of the causal structure of the world, it is also inf l ected 
at every level with constantly updating estimates about the reliability of those 
predictions. 
The system uses these second-order estimates, or what is known as precision- 
weighting, to fl exibly adjust the impact of prediction errors throughout the system. 
1 3 
Predictive processing and relevance realization: exploring convergent��� 
This variable weighting allows the system to highlight useful sources of reliable data 
in the world (high signal to noise ratio), and to adjust the degree to which the system 
relies on its own bottom-up sensory information or top-down predictions (Friston, 
2009, 2010). Attention, according to this framework, is an active sampling of sensory 
information that has high precision (Feldman & Friston, 2010, p. 17). However, pre- 
dictions about precision direct attention in at least two distinct ways: fi rst, attention 
is directed to those aspects of the scene where there is a high signal to noise ratio. 
Attentional processes here work to select information that is informative about the 
underlying causal structure of the world, highlighting data that has a high probability 
for leading to a more adaptive predictive model. The second process deploys atten- 
tion to opportunities to gain new useful information. This second type of process has 
been related to ���salience���. Precision is weighting on beliefs about actions that are 
likely to improve the system���s predictive grip of a scene. Notice that if some piece of 
information is already highly predicted then it becomes less valuable as a source to 
improve predictions. In this second set of processes, precision is deployed on policies 
that are likely to harvest unambiguous information that is not yet well predicted. For 
example, attending to the sudden barking of a nearby dog is likely to generate useful 
(prevent being attacked), but yet unknown (is the dog restrained by a fence of leash), 
information. Salience in this context can be thought of as relating to a reduction in uncertainty ��� by attending in this way I become more conf i dent about the causal 
structure underlying my environment (for a full account, see Parr & Friston 2019). 
While there are marked dif f erences between these aspects of attention, they are 
reconcilable within this account. We need only appreciate that both processes repre- 
sent beliefs about what sensory information is likely to help improve one���s predictive 
grip on a scene. The major dif f erence being the former concerns available data that 
are predicted in the here and now, while the later relates to data yet to be harvested. 
To play this role, precision estimation must be delicately tuned to a wide variety 
of information coming from both outside and inside the predictive system (Miller & 
Clark, 2018). Getting the balance right between high-level predictions and low-level 
sensory information, and between more habitual and more goal-directed behaviors, is 
highly context dependent (e.g., time pressures, degree of danger, metabolic resources, 
etc.). Precision plays the role of delicately inf l uencing the impact of every aspect of 
the prediction error signals in ways that ref l ect the brain���s best predictions given the 
task and context. It is this spectacular fl uidity that has led to some worry. Precision 
weighting allows the predictive processing framework to accommodate every con- 
ceivable perceptual and behavioral outcome from the simplest habitual ref l ex to the 
most complex and well-planned behaviors. Some worry that we may have inadver- 
tently imported an unexplanatory free variable into our explanatory schema (Litwin 
& Mi��kowski, 2020; Miller & Clark, 2018). We don���t agree, but we do appreciate 
the need to further explore and explain the various ways that precision is estimated 
within the framework. In many ways this is the current frontier of this research para- 
digm. In what follows we suggest that the relevance realization literature may help us to further explore and ref i ne the nature of precision estimations.
1 / 1
ChatGPT
ChatGPT
The Predictive Processing (PP) framework posits that the brain functions as a prediction error minimizing engine. It is perpetually proactive, attempting to predict incoming sensory information before it arrives. By continuously learning the temporal and spatial regularities of the changing environment, it creates increasingly better predictions about hidden causes behind our experiences.
When top-down predictions match the bottom-up signals well enough, a perceptual experience occurs. If there's a discrepancy (referred to as prediction errors), it either refines future predictions or provokes actions to make the sensory stream better fit the predictions. This system creates a rich perceptual experience and adaptive behaviors.
A unique feature of this framework is the tight link it creates between knowledge, perception, and action. The brain uses prior knowledge to make probabilistic predictions about the environment, which informs both perception and action. By continually predicting the next sensory input and using any errors to update those predictions, the brain learns about the actionable world.
The system also maintains second-order expectations about the reliability of its own predictions, predicting the reliability of their own prediction errors. This process, known as precision weighting, allows the system to focus on the streams of information most likely to yield adaptive predictions. The system uses these estimates to adjust the impact of prediction errors throughout the system.
Attention, according to this framework, is an active sampling of sensory information that has high precision. Predictions about precision direct attention in two distinct ways: first, to aspects of the scene with a high signal-to-noise ratio, and second, to opportunities to gain new useful information. This second type of process is related to "salience".
The precision must be delicately tuned to a wide variety of information from both outside and inside the predictive system. Balancing between high-level predictions and low-level sensory information and between habitual and goal-directed behaviors is highly context-dependent.
Some argue that precision weighting may lead to a potentially unexplanatory free variable in the PP framework, suggesting that this is the current frontier of the research paradigm. The authors argue that the relevance realization literature could further explore and refine the nature of precision estimations.
1 / 1
In predictive processing, the brain models itself, multiply recursive self-correcting fashion, in order to predict the world.
1 / 1
ChatGPT
ChatGPT
Yes, that's a concise and apt summary. The Predictive Processing (PP) framework proposes that the brain continuously forms and refines predictive models of the world, which includes itself, in a recursive and self-correcting fashion.
To make accurate predictions, the brain must have a good understanding of the causal structure of the world, which includes the brain's own processes and responses. By predicting its own reactions and the sensory feedback these reactions will produce, the brain can form an increasingly detailed and accurate model of both the external world and its own internal states.
When a prediction error occurs (i.e., the predicted outcome differs from the actual outcome), the brain updates its model to improve future predictions. This recursive, self-correcting mechanism helps the brain to continuously adapt and fine-tune its understanding of the world and itself, resulting in more effective actions and interactions with the environment.
It's also worth noting that this process is not just about modeling the static properties of the world and the brain, but also about understanding the dynamic changes and patterns that occur over time. This is why the PP framework is often linked to concepts like learning, adaptation, and cognition.
1 / 1
The brain is trying to reduce the degree to which it surprises itself.
1 / 1
ChatGPT
ChatGPT
Absolutely. In the Predictive Processing (PP) framework, the overarching goal of the brain is to minimize what is known as 'prediction error' - the difference between what the brain predicts and what it actually experiences. By minimizing prediction error, the brain effectively reduces the amount of surprise it encounters.
This framework suggests that the brain does this through a process of generating predictions about upcoming sensory input, comparing those predictions with the actual sensory input it receives, and then updating its predictive models based on the discrepancies, or 'errors', between the predictions and the reality.
The idea here is that a brain that can accurately predict its own sensory inputs is a brain that is effectively understanding and interacting with the world. By continuously working to reduce its own surprise, the brain is able to navigate the complexities of our environment with more precision and adaptability.
This continual process of prediction, comparison, and adjustment is thought to underpin a wide range of cognitive and behavioral phenomena, from perception and motor control to learning and decision-making.
1 / 1
Active Entity.Ontology.
Active Entity Ontology for..
Copy doc
Entity Class
Entity Type
Definition
Example
Internal States
Primary
Knowledge
Artfact
@Knowledge Artifact that is initial dataset/database
raw data outcome.
Digital content ofthe
@Knowledge Artifact
Secondary
Knowledge
Artifact
@Knowledge Artifact thatis made _Things that representthe
by@Research investigator when outcomes of analysis: paper,
code and outputs,
they @Analyzes
@Primary Knowledge Artifact
tools/dashboards, grants that
fund generation of knowledge
artfacts, audio/video content,
live session designs and
deployments, conferences and
gatherings
Digital content ofthe
@Knowledge Artifact
Tertiary + Higher
Knowledge
Artifact
@Knowledge Artifact that is made Livestream discussing the
by @Research investigator based @Secondary Knowledge
Artifact
upon
@Secondary Knowledge Artifact
Metadata specification for
nottobea"research product" but secondary knowledge arfacts
to communicate ,educate,
summarize, discuss, annotate, etc.
Digital content otthe
@Knowledge Artifact
Fungible Asset
Digital asset ortoken typified by
being functionally equivalent
within a class (ref). Includes
Crypto and Fiat fungible payment-
type tokens.
ETH
Digital content ofthe
@Knowledge Artifact
Non-Fungible
Asset
Digital asset or token typified by
Curio Cards, ENS address
being NOT functionaly equivalent
within a class (ref). Includes
Certificates, Keys, "Non-Fungible
Tokens" NFTs,
Digital content ofthe
@Knowledge Artifact
Dataset
@Knowledge Artifact consisting ofDatabase(s), data fle(s), data Digital content ofthe
@Knowledge Artifact
set ofinformation, ranging from lake(s)
single celof information, to large
database
paper
Article written with scientitfic
content,
Stochastic Chaos and Markov Digital content ofthe
Blankets
@Knowledge Artifact
Intelectual
Property
Material that has ownership and
legal considerations.
A patent
Digital content ofthe
@Knowledge Artifact
Smart Contract
Executable code in a blockchain
@Computer System
Gnosis multisig smart contractState variables of
https://gnosis-safe.iol @Smart Contract
Code
Executable strings that run on
@Computer System
Github repo, interactive
notebooks
Digital content ofthe
@Knowledge Artifact
Grant
Mechanism for providing funding
to research @Team
Grant from
@Research Agency
(Government)
suchasNSF e.g. this
Digital content ofthe
@Knowledge Artifact
Metadata
Structure of information about
Metadata passed along with
search request, @Metadata
other information is a type of
@Knowledge Artifact and can beabout a citation
@Primary Knowledge Artifact or
@Secondary Knowledge Artifact
Digital content of the
@Knowledge Artifact
Blockchain
Sequential cryptographic
database
Bitcoin
Digital content of the
@Knowledge Artifact
Digital content ofthe
@Knowledge Artifact
Project Catechism Question-and-Answer formatted
@Knowledge Artifact used for
project documentation
Examples presented in the
appendix of COGSEC'S NIM
1 / 1
ChatGPT
ChatGPT
It seems like you've pasted a description of a classification or ontology scheme for various types of knowledge artifacts and related entities, especially in the context of digital and computational systems. This ontology seems to differentiate between primary, secondary, and higher-order knowledge artifacts, as well as between different types of digital assets (fungible and non-fungible), data sets, and other related entities like code, smart contracts, and blockchains.
Here are the definitions based on your input:
Primary Knowledge Artifact:
The initial dataset or database, essentially the raw data outcome.
Secondary Knowledge Artifact:
Made by a research investigator when they analyze the primary knowledge artifact. Examples include the outcomes of analysis like a paper, code and outputs, tools/dashboards, etc.
Tertiary + Higher Knowledge Artifact:
Made by a research investigator based upon the secondary knowledge artifact. Examples include livestream discussions, metadata specifications etc.
Fungible Asset:
Digital asset or token typified by being functionally equivalent within a class. Examples include crypto and fiat fungible payment-type tokens like ETH.
Non-Fungible Asset:
Digital asset or token typified by being not functionally equivalent within a class. Examples include certificates, keys, Non-Fungible Tokens (NFTs) like Curio Cards, ENS addresses, etc.
Dataset:
A knowledge artifact consisting of a set of information, ranging from a single cell of information to a large database.
Paper:
An article written with scientific content.
Intellectual Property:
Material that has ownership and legal considerations, like a patent.
Smart Contract:
Executable code in a blockchain computer system. An example is the Gnosis multisig smart contract.
Code:
Executable strings that run on a computer system. Examples include a GitHub repository, interactive notebooks, etc.
Grant:
A mechanism for providing funding to a research team, such as a grant from a research agency (e.g., the NSF).
Metadata:
The structure of information about other information. It's a type of knowledge artifact and can be a primary or secondary knowledge artifact.
Blockchain:
A sequential cryptographic database like Bitcoin.
Project Catechism:
A question-and-answer formatted knowledge artifact used for project documentation.
Each of these entity types is associated with a digital content of the knowledge artifact, suggesting that this classification might be used in a system where these different types of entities are being catalogued, linked, or otherwise manipulated.
1 / 1
Affordances
= Arodances are the actions from which an
@Active E Entity Types selects.
The selection of generative model of a
specifies the internal states,
EB Entity Types
then the connection of two Entities (oActve
@Activer @Active- @informational, @lnformational-C @lnformational) gives
the Action (outgoing, on the acting
entity) and Sense (incoming, on the
recipient entity) states.
Affordances
Edge subtypes
Acts friendly towards
Defintion
Examples
Example Motif
For a human to act in a sociable
Repeat collaborators who are
a
and nice way towards
friends
@Human @Acts frien
@Human
Acts trusting towards
For a human to act in high-trust P rotocol or platform entrusted
with private information
way
@Human @Acts trust
@Community of Pract
Analyzes
To examine or investigate
Analyzing data for a paper
@Human @Research
@Analyzes @Dataset
Audits
To assess for veracity
Financial or @Scientific Review
@Research Agency (F
@Audits @DAO
Communicates Asynchronously To @Communicates Toin a
Two colleagues on different
remote/distance context (to a
TO
continents on an online video
@Human or @Computer System chat.
@Human
@Communicates Syn'
To
@Computer System
Communicates In-Person To
To @Communicates To in a
Working in the same room
physically-located context (to a together and talking
@Human or @Computer System
@Human
@Communicates In-P
@Computer System
Communicates Synchronously
To
To @Communicates To in a
Two colleagues on different
remote/distance context (to a
continents on an online video
@Human or @Computer System chat.
@Human
@Communicates Syn
To
@Computer System
Communicates To
To be a @Communication sende o speak to
@Computer System
@Communicates To
@Cryptographic ldent
Computer communicates to
Human
To be a @Communication sender Computer displaying data
@Computer System
a
from a @Computer System to a visualization to @Human,or an @Computer communi
audio-video feed
@Human
Human
@Human
Engages in governance
To vote, have a say, or otherwise Voting in a @DAO
e
play a role in decision-making of
@Organization
Human communicates to
Computer
To be a @Communication sender Human speaking into a
from a @Computer System to a icrophone or typing on a
or
@Human
keyboard
@Human
@Computer communi
Human
@Computer System
1 / 1
ChatGPT
ChatGPT
It seems like you're describing a classification of various types of actions, or "affordances," that can occur between different entities in a system. These actions can happen between various active entities and can involve communication, analysis, trust, governance, and other types of interaction. Here are the definitions based on your input:
Acts friendly towards:
For a human to act in a sociable and nice way towards another human. Example: Repeat collaborators who are friends.
Acts trusting towards:
For a human to act in a high-trust way towards a community of practice. Example: A protocol or platform entrusted with private information.
Analyzes:
To examine or investigate. Example: A researcher analyzing data for a paper.
Audits:
To assess for veracity. Example: A research agency or a scientific review auditing a DAO.
Communicates Asynchronously To:
To communicate to in a remote/distance context. Example: Two colleagues on different continents on an online video chat.
Communicates In-Person To:
To communicate to in a physically-located context. Example: Two people working in the same room together and talking.
Communicates Synchronously To:
To communicate to in a remote/distance context. Example: Two colleagues on different continents on an online video chat.
Communicates To:
To be a communication sender or speaker to.
Computer communicates to Human:
To be a communication sender from a computer system to a human. Example: A computer displaying data visualization to a human, or an audio-video feed.
Engages in governance:
To vote, have a say, or otherwise play a role in decision-making of an organization. Example: A person voting in a DAO.
Human communicates to Computer:
To be a communication sender from a human to a computer system. Example: A person speaking into a microphone or typing on a keyboard.
Each of these affordances corresponds to a specific type of interaction that can occur between entities in this system, providing a rich set of possibilities for representing and analyzing the behavior of these entities.
1 / 1
Active Entity Ontology...
Active Entity Ontology for ...
Copy doc
Active Entity Ontology for S...
Action-Perception States
The EE Action-Perception States table describes the
type of node to include as Sense or
Action (Markov/Friston B/anket) states in
the model, at a specific scale of
analysis. We will learn more about these
as we experiment with
B Action-f Perception States
early applications of the E Entity
Types
Action-Perception States
State
Asynchronous
Audio/visual
Cryptographic
Fungible Asset
Grant
Informational
Non-Fungible Asset
None
Scientific Review/Evaluation
Synchronous
1 / 1
ChatGPT
ChatGPT
It appears you are laying out various states related to action-perception within a model of active entities. Here's a quick interpretation of the states:
Asynchronous:
This state probably refers to actions or perceptions that do not occur simultaneously, such as in asynchronous communication where sending and receiving messages happens at different times.
Audio/visual:
This state likely refers to actions or perceptions that are received through auditory or visual means. This could encompass everything from spoken words to visual cues in an environment.
Cryptographic:
In this state, the actions or perceptions are probably related to cryptographic processes, such as encryption and decryption, key generation, or digital signatures.
Fungible Asset:
This state likely involves actions or perceptions related to fungible assets, which are assets that are interchangeable with other identical assets, such as certain cryptocurrencies or tokens on a blockchain.
Grant:
The grant state likely involves actions or perceptions related to grants, which could be monetary funding for research or projects.
Informational:
This is likely a broad category encompassing any action or perception that involves the exchange or processing of information.
Non-Fungible Asset:
This state is likely concerned with actions or perceptions involving non-fungible assets, which are unique and cannot be interchanged on a one-for-one basis with any other asset. An example would be Non-Fungible Tokens (NFTs) on a blockchain.
None:
This could be a placeholder state, perhaps representing the absence of action or perception, or waiting for a state to be assigned.
Scientific Review/Evaluation:
This state likely involves actions or perceptions tied to the process of reviewing or evaluating scientific work, such as the peer-review process in academic publishing.
Synchronous:
This state probably refers to actions or perceptions that occur simultaneously, like in synchronous communication where sending and receiving messages happens at the same time.
These states might be used to inform the behaviors or responses of active entities in your model, or they could be used to categorize or analyze interactions between entities.
1 / 1
Zenodo
December 26, 2022Journal article Open Access
An Active Inference Ontology for Decentralized Science: from Situated Sensemaking to the Epistemic Commons
 Friedman, Daniel;  Applegate-Swanson, Shaun;  Balbuena, Jessica Angeli;  Choudhury, Arhan;  Cordes, RJ;  El Damaty, Shady;  Gu��nin���Carlut, Avel;  Knight, V. Bleu;  Metelkin, Ivan;  Shrivastava, Siddhant;  Singh, Amit Kumar;  Sm��kal, Jakub;  Tuttle. Caleb;  Vyatkin, Alexander

In this work, we examine science from the vantage points of blockchain technology and its connection to decentralized science (DeSci). We consider science as a collective process using Active Inference, an integrative framework that models the cognitive processes of perception, planning, and action selection in terms of Bayesian probabilities and updating. We present the Active Entity Ontology for Science (AEOS, available at coda.io/@active-inference-institute/active-entity-ontology-for-science-aeos) as a composable and versionable system for modeling various science systems, using the Active Inference entity partitioning. Such DeSci systems are considered from the perspective of BOLTS (Business, Operations, Legal, Technical, Social). Further steps for developing and utilizing AEOS in the context of scientific ecosystems are provided.
1 / 1
ChatGPT
ChatGPT
It sounds like the paper you're referring to discusses an innovative approach to modeling and understanding science through the lens of active inference, a framework that's based on Bayesian statistics and primarily used to model cognitive processes.
This paper particularly focuses on decentralized science (DeSci), which is science conducted in a non-hierarchical and collaborative way. This might be facilitated by technologies such as blockchain, which allow for secure, transparent, and decentralized data management.
The authors introduce the Active Entity Ontology for Science (AEOS), which seems to be a system for modeling various scientific systems through the partitioning of active inference entities. This system appears to be highly adaptable and able to keep track of different versions.
Finally, the paper seems to use the BOLTS (Business, Operations, Legal, Technical, Social) perspective to examine these decentralized science systems. This holistic perspective could help in considering the various implications of such systems.
The goal of the paper might be to pave the way for a more inclusive, efficient, and transparent approach to scientific research and discovery. They likely also provide guidelines on how to further develop and use the AEOS in the context of scientific ecosystems.
1 / 1
Driving Questions 
Centralized Science (CeSci): Historical science operations, community, and practices 
���What are successful, effective, and productive scientific practices for communities and individuals? 
���What frameworks and tools can help form and support communities of practicing researchers to 
promote long-term collaboration and impact? 
���How are preferences and expectations aligned and communicated in ecosystems of scientific 
collaboration? 
���How do we avoid perverse incentives in systems of scientific inquiry? 
���How do we ensure effective and transparent resource allocation and funding as research becomes 
more interdisciplinary, interorganizational, and international? 
���How can scientific careers be started and nurtured, increasing the accessibility and vitality of 
science as a community and body of knowledge? 
���What are fair and effective means of elevating voices to scientific thought leadership roles? 
���What are good ways to identify strategic priorities for scientific funding, intellectual capital 
allocation, and focused development? 
���How to deal with new opportunities and challenges related to increases in remote work? 
���How to enable efficient data and code access? 
Decentralized Science (DeSci): The future of coordination and Knowledge Engineering 
���How can decentralized teams and organizations coordinate research using effective distributed 
mechanisms? 
���What scientific outputs are to be expected of Decentralized Science (DeSci)? 
���How will DeSci produce traditional research products such as papers, as well as other outcomes, 
such as products, services, platforms, tools, and protocols? 
���What artifacts and design patterns will stimulate the development of integrated DeSci systems? 
���How can Distributed Autonomous Organizations (DAOs) scaffold and catalyze research, grants, 
education, and community development? 
���What methods for value capture and financialization improve the process of scientific discovery, 
and which methods result in poor outcomes that are at odds with open science community values? 
���What improves the reliability of outcomes and accountability of funds in emergent collaborations? 
���What are the relations between the trajectories of scientific governance, and 
social/ecological/political change and collapse? 
���How can scientific careers become more accessible to researchers who are non-PhD holders, and 
those with other commitments such as family, participation in industry, etc? 
���How can we use blockchain and related technologies to cultivate cultures of fair work attribution, 
through records of contribution to knowledge artifacts and proof-based protocols? 
���How can we maintain a favorable signal-to-noise ratio for DeSci work output? 
���Can the Active Inference framework and ontology be used to understand complex sociotechnical 
systems such as epistemic communities? 
���How are epistemic commons created and maintained in an era of Human-Computer collaboration? 
3 
Introduction 
Science is a cumulative, collective endeavor that augments a single human's 
sensemaking ability with tools, practices, and processes we use together to observe, 
measure, and understand the world around us and to agree on a shared reality. Even 
before the invention of modern scientific instruments such as microscopes and particle 
accelerators, humans relied on their senses to observe the environment and on their 
brains to make inferences about these observations. This is still true today. Any study of 
how knowledge is accumulated must consider how the brain works when making 
predictions based on observations and incomplete data. Additionally, as the information 
required for scientific research extends far beyond the cognitive capacity of a single 
unaided human, tools for scientific organization, knowledge management, and 
communication become increasingly necessary to consider as well. 
Science and the Epistemic Commons 
A recent shift in science is the move towards greater recognition of the complex 
nature of systems such as brains or societies [1,2]. For example, cognitive science has 
largely moved away from the ambition to discover universal laws of behavior to focus more 
on the causal structure of the brain and its patterns of activity in different scenarios [3]. 
Utilitarian scientific models today strive to explain natural phenomena by piecewise 
integration of generative models expected to match the causal structure of the target 
system at the relevant scale of behavior
1 / 1
ChatGPT
ChatGPT
These driving questions are aimed at understanding the shift from Centralized Science (CeSci) - conventional scientific operations and practices, towards Decentralized Science (DeSci) - a more distributed and collaborative approach to scientific research.
Under the CeSci, the questions seem to address the issues of promoting long-term collaboration, effective communication, avoiding perverse incentives, resource allocation, nurturing scientific careers, fair leadership roles, strategic funding allocation, and dealing with remote work challenges as well as ensuring efficient access to data and code.
As for DeSci, the questions mainly focus on how research coordination can be achieved in decentralized teams, what types of scientific outputs can be expected from DeSci, and how traditional research products will be produced. The questions also address the role of Distributed Autonomous Organizations (DAOs), the use of blockchain and related technologies for fair work attribution, how a favorable signal-to-noise ratio can be maintained, and the potential use of the Active Inference framework and ontology for understanding complex sociotechnical systems.
The introduction emphasizes that science is a collective endeavor that has evolved over time to include advanced tools and methods to augment human sensemaking capabilities. It recognizes the shift in science towards understanding complex systems, such as brains or societies, and acknowledges the importance of integrating generative models to explain natural phenomena at the relevant scale of behavior.
1 / 1
Relevance realization
1 / 1
ChatGPT
ChatGPT
Relevance realization is a term coined by cognitive scientist John Vervaeke. It's a process through which an individual or a system navigates and filters through a vast amount of information in order to find what is meaningful or relevant to the task at hand. This is important because in any given moment, we are bombarded with an overwhelming amount of sensory data, most of which is irrelevant to what we're doing or trying to achieve.
For example, when you are reading a book, there are countless details in your environment that your brain could focus on: the sound of the wind outside, the texture of the chair you're sitting on, the temperature of the room, etc. However, your brain largely ignores these irrelevant details and focuses on the words on the page, which are relevant to the task of reading.
The process of relevance realization is highly dynamic and context-dependent. What's relevant in one situation may be irrelevant in another. For example, the sound of the wind outside might become relevant if you're trying to figure out if you should take an umbrella when you go outside.
In the context of science and knowledge creation, relevance realization could be a crucial process in identifying what data, information, or patterns are meaningful and warrant further investigation. As the volume of data available for analysis grows, the capacity to effectively discern what is relevant becomes increasingly important.
This concept is also linked to the idea of salience landscapes, a metaphor used to describe how different stimuli or pieces of information stand out to us in different contexts based on their perceived relevance.
In the realm of artificial intelligence, the concept of relevance realization is a major challenge because it involves not just the processing of data, but a nuanced understanding of context, significance, and meaning.
1 / 1
Precision-weighting and relevance realization 
Vervaeke and colleagues (2012) suggest that RR ���is a dynamic, self-designing, self- 
organizing process that is not equated with an immutable identity��� (p. 9). This is 
similar to how Clark (2015) describes the prediction-error minimization framework: 
By self-organizing around prediction error, these architectures thus deliver a 
multiscale grip upon the organism-salient features of the world���a grip whose 
signature is the capacity to engage that world in ongoing cycles in which per- 
ception and action work together to quash high-precision prediction error. (p. 
271) 
What is the connection between prediction error and relevance realization? Clark 
(2015) suggests, the functional role of a prediction error signal is ���to guide fl uent 
engagements with those aspects of the world relevant to our current needs and proj- 
ects��� (p. 272). In particular, however, it is high-precision prediction errors which tend 
to drive perception and action. By assigning a higher precision to a sensory prediction 
error, a perceptual system is increasing the ef f ect it will have on downstream process- 
ing. Assigning high precision is thus the perceptual system���s way of labelling an error 
signal as being particularly relevant and thus in need of greater attention. Assigning 
low precision to an error signal is a way of deeming it irrelevant. Thus, less weight 
will be given to that signal such that it will not have a large ef f ect on subsequent 
action and perception. All of this suggests that precision-weighting simply is how 
relevance is realized within the PP framework. 
One of the central contributing factors for how precision is set on action policies is 
changes in the rate at which error is reduced over time relative to expectations (Hesp 
et al., 2021; Kiverstein et al., 2019; Van De Cruys, 2017). In other words, changes in 
how fast or slow prediction errors are being reduced (relative to expectations) helps 
to inform the system about how conf i dent it should be in any particular action policy 
selection. If we suddenly do much better at reducing prediction error, those actions 
are good candidates for future successes in similar contexts. These changes in the 
rate of error reduction (also known as ���error dynamics���) are expressed as changes 
in af f ective states of the body. The result is that when we improve our predictive 
grip we feel good, and those good feelings help to tune the system to opportuni- 
ties to improve. And when we fail to achieve a good predictive grip (i.e., errors are 
amassing at unexpected rates) this feels bad, and those negative feelings readjust our 
conf i dence in our selected behaviors. As we have already outlined above, precision 
weighting determines to what degree we rely on habits (i.e., exploiting what we have 
already learned about the environment) or go about exploring the environment in 
search of new information that may increase our ability to reduce error in the future. 
Error dynamics plays an important role here as well, helping to balance the agent���s 
selection of pragmatic and epistemic action policies (Kiverstein et al., 2019). 
If precision is af f ected by changes in how well or poorly we are able to reduce 
error over time then we will naturally fi nd ourselves attracted to opportunities for 
improving our predictive abilities. We will be slope-chasers: motivated to seek out 
and benef i t from opportunities to improve the slope of prediction error minimiza- 
1 3 
Predictive processing and relevance realization: exploring convergent��� 
tion. That af f ective drive towards opportunities to improve our predictive grip will 
inevitably lead such agents to frequent those spaces that are just beyond their current 
capabilities. If some task or context is too well known, then it will cease to produce 
those prediction errors that are interesting for the agent to attempt reducing; and if the task is too complex, then the agent will not be well suited to manage the prediction 
errors. In both cases the agent will fail to reduce error at their expected rate. When 
there is too little error we feel bored and when there is too much we feel frustration 
and anxiety. Agents that are tuned by error dynamics in this way will naturally fi nd a 
so- called ���goldilocks zone���- places with just the right mixture of predictability and 
novelty or uncertainty and what is already well-predicted, thereby allowing them to 
make the most learning progress (and feel the best; Kidd et al., 2012; Kiverstein et 
al., 2019; Van De Cruys, 2017). Error dynamics will often lead agents to destroy their 
own fi xed policies for exploiting what is already highly predictable, in favor of more 
itinerant wandering policies for exploration (Friston et al., 2012; Miller et al., 2021). 
As we will see in the sections to come, a non-typical sensitivity to these dynamics 
plays a special role in characterizing many of the dif f erences in relevance realization 
between people high in autistic-like traits and people high in positive schizotypy. 
3.1 Precision, reliability, and relevance 
Precision-weighting is generally construed as a neural estimate of the ���reliability��� of 
select sensory inputs (Clark, 2015; Hohwy, 2013). A more reliable input is one with 
a greater ratio of signal to noise, relative to the predictions of the agent (Feldman & 
Friston, 2010). This construal, however, has given rise to some confusion in the PP 
literature. For example, Ransom and colleagues (2020) claim that neural estimations 
of the reliability of sensory input cannot explain why we would pay attention to an 
unexpected occurrence, such as a dog barking at us while we walk down the street. 
Unexpected events are unreliable by def i nition, so how can estimations of reliability 
explain why we orient our attention towards them? This objection, however, results 
from a confusion about what precisely ���reliability��� means within the PP framework. 
As Clark (2013, 2017) has repeatedly argued, ���reliability��� and ���relevance��� are equiva- 
lent within the PP framework. Indeed, the very concept of signal and noise doesn���t 
make sense outside of an agent with goals. What constitutes signal? Everything that 
is relevant to my goals. What constitutes noise? Everything that is irrelevant to my 
goals. In the PP framework, goals are understood as high-precision proprioceptive 
predictions (Clark, 2013). The estimation of reliability in relation to these predictions 
(i.e., the signal to noise ratio of sensory input) is therefore equivalent to the estima- 
tion of relevance. Why would we direct our attention towards a barking dog? Because 
we have some high-precision proprioceptive prediction which states something like 
���I will avoid bodily injury��� and the barking dog (and any other unexpected loud noise) 
reliably provides information which is likely to be relevant to that prediction (see 
Parr & Friston 2019 for a full discussion of this point). In other words, precision- 
weighting simply is the PP account of RR.
1 / 1
ChatGPT
ChatGPT
The passage discusses the connection between precision-weighting and relevance realization (RR) in the context of the predictive processing (PP) framework. This framework postulates that the brain is a prediction machine that constantly tries to minimize the difference (or error) between its predictions and sensory inputs.
In the PP framework, precision is essentially a weighting factor that represents the reliability or certainty of sensory input. High precision indicates a reliable (or relevant) sensory prediction error, which is given more weight in downstream processing, i.e., it has more influence on perception and action. Low precision represents less reliable (or irrelevant) sensory prediction error, which is given less weight and thus has less influence.
According to the authors, precision is affected by the rate of error reduction over time relative to expectations. This concept is linked to affective (emotional) states - when we get better at reducing prediction errors (i.e., our predictions become more accurate), we feel good, and these positive feelings can tune the system to seek out opportunities for improvement. Conversely, if we fail to improve our predictive grip (i.e., errors accumulate at unexpected rates), this feels bad, and these negative feelings can adjust our confidence in our selected behaviors.
The authors also introduce the idea of error dynamics, which play a crucial role in balancing pragmatic and epistemic action policies, essentially governing the trade-off between exploiting what we already know about the environment and exploring it for new information that could help reduce prediction errors in the future.
Interestingly, the authors suggest that agents guided by these error dynamics will naturally gravitate towards a "goldilocks zone" ��� situations that provide just the right mixture of predictability and novelty, allowing for optimal learning progress.
The authors also highlight that within the PP framework, 'reliability' and 'relevance' are equivalent concepts. What's considered as 'signal' is everything that is relevant to the agent's goals, and 'noise' is everything that is irrelevant to those goals.
In summary, this passage presents a rich view of how the PP framework, through the process of precision-weighting, provides an account of relevance realization, i.e., how the brain determines what is relevant or important in a given context.
1 / 1
Given the incentive misalignment and power imbalances between administrators 
and practitioners, the scarcity of resources, competition over resources both between 
researchers and research institutions, and the inflexible nature of the bureaucracies which 
connect and govern extant research institutions, there are few mechanisms available for 
improving traditional research institutions aside from increasing funding. Luckily, human 
prosociality has taken many forms throughout our evolutionary history from which we can 
draw inspiration. We could develop tools and protocols which treat the outcomes of 
research as contributions to an epistemic commons, a web of informational or 
knowledge-oriented systems which would allow individuals with disparate motivations, skill 
sets, and beliefs to collaborate at the intersection of their interests and tackle specific 
questions or systems with the most contextually relevant tools, in the best interest of 
cumulative, collective scientific knowledge. In other words, we argue that relaxing the 
constraints of legibility associated with bureaucracy and its ���view from above��� could help 
develop the "view from the ground" (i.e., pragmatic understanding by practitioners) as well 
as the "view from within" (i.e., scientific knowledge, in the classical sense of an objective 
description of system organization and activity). 
Human prosociality has contributed to the persistence of our species. The emergent 
structure of social organization is variable but can develop towards hierarchical, top-down 
5 
control which are transactional and mutually beneficial [15,16]. However, hierarchical 
control can lead to the sequestration of wealth and power over time, and a centralized 
motivation that does not always act in broader society's best interest or satisfy all relevant 
perspectives. Hierarchical structures develop cognitive biases over time that limit the 
ability to parse multiple, conflicting streams of information that do not fit into the standard 
decision making templates of those on top. Decentralized structures may be more capable 
of acting on divergent information streams, however decentralization alone is not a 
mechanism that provides intelligent coordination for effective collective action [17,18]. 
Decentralized Autonomous Organizations (DAOs) are an emerging form of coordination 
between humans that enables new kinds of cyber-physical communities mediated by 
immutable, cryptography-protected code [19,20] and other artifacts. DAOs allow for 
programmable digital social structures, embedded mechanisms for consensus, 
intermediation of trust-requiring actions, and independent operation of workstreams with 
multiple leaders instead of a top-down hierarchy. Coordinating such decentralized 
communities of practice, or more generally governing "complex commons", is novel, 
difficult, and high-stakes work, often without the scaffolds and norms that traditional offline 
governance benefits from [21]. For example, systems that are decentralized in principle 
may still be functionally centralized in terms of power or asset distribution [22]. 
We propose that epistemic drives and norms can grow organically from 
communities of practice, defined by open questions, shared value, interoperable 
processes, methodological synergies, personal affinities, diverse contributions, 
serendipitous encounters, and Ontologies, Narratives, Formal documents, and Tools 
(ONFT, [23]). In this paper, we model the similarities and differences between 
Decentralized Science (DeSci) and Centralized Science (CeSci) through the Active 
Inference framework, understood here as a framework addressing how living systems 
create an understanding of their environment [24] and act based on this understanding. 
The Active Inference formalism affords an integrated account of the multiscale dynamics 
shaping research, from the constitution of epistemic affordances shaping scientific 
practices [25] to the coevolution of epistemic beliefs and communities [26], as a process of 
uncertainty reduction (technically described by the descent of a gradient of variational free 
energy [27,28]). This model implies that cognitive understanding derives from adaptive 
control in agentive engagement rather than explicit representation [29���31], and that the 
activity of epistemic communities is shaped by the sociocultural constraints defining their 
structure rather than individual states of mind [32]. Based on these considerations, we will 
articulate a conceptual framing and Active Entity Ontology for Science (AEOS).
1 / 1
ChatGPT
ChatGPT
The provided text discusses the drawbacks of traditional research institutions and proposes an alternative model that emphasizes decentralization and prosociality, called Decentralized Science (DeSci).
Traditional research institutions are criticized for the misalignment between administrators and practitioners, resource scarcity, inflexible bureaucracies, and competition over resources. These issues limit the capacity for these institutions to improve, other than through increasing funding.
As an alternative, the authors suggest drawing inspiration from human prosociality to develop new methods for scientific research. They suggest treating the outcomes of research as contributions to an "epistemic commons," which would encourage collaboration between individuals with varying motivations, skills, and beliefs. This idea aims to relax the constraints of bureaucracy, allowing for a more ground-up approach to scientific understanding and knowledge generation.
The authors also address the limitations of both hierarchical (centralized) and decentralized structures. Hierarchical structures can lead to concentration of wealth and power, and can develop cognitive biases over time that limit the ability to parse conflicting information streams. Decentralized structures, while potentially more capable of acting on divergent information streams, do not automatically provide intelligent coordination for effective collective action.
Decentralized Autonomous Organizations (DAOs), based on immutable and cryptographic code, are highlighted as a potential solution. DAOs provide programmable digital social structures, trust intermediation, and independent operation of workstreams. However, coordinating decentralized communities and governing "complex commons" is challenging, particularly as these systems often lack the norms and scaffolding present in traditional governance.
Finally, the authors propose a model where epistemic drives and norms grow organically from communities of practice, defined by factors like open questions, shared value, interoperable processes, methodological synergies, personal affinities, and diverse contributions. This proposal is framed within the Active Inference framework, which focuses on how living systems create an understanding of their environment and act based on this understanding. The Active Inference formalism provides an integrated account of research dynamics from the constitution of epistemic affordances to the coevolution of epistemic beliefs and communities.
In summary, the passage proposes a new model for scientific research and discovery, known as Decentralized Science, which draws from prosocial behavior and decentralization concepts. This model is seen as a potential alternative to traditional hierarchical research institutions, which are criticized for their inflexibility, competition over resources, and potential for concentration of power.
1 / 1
Before we dive deep into head-on contrastive definitions of CeSci and DeSci, a 
primer on decentralized systems is crucial. We would like the first definition not to be 
simply an anti-definition of its counterpart, as we aim to incentivize effective research and 
6 
set up collaborative relations between emergent DeSci and incumbent CeSci, not simply 
to ignite controversy. Both CeSci and DeSci will exist in collaboration in the future, in the 
sense that scientific systems will vary in their extent of centralization. Therefore, even 
though here we will use the terminology of decentralization, a host of related terms may 
also be relevant [22,33���35]. One interesting perspective to apply here is that of ���Self 
Certifying Systems��� [36]. These self-certifying systems are those in which an entity 
validates its own existence in the system, and the incentive mechanism of the system is 
intrinsic to it. For instance, a dataset in a database system such as InterPlanetary File 
System (IPFS) [37,38] validates its own legitimacy by hashing the contents using a 
cryptographic hash function. In these dynamics, the root of trust lies within the network 
entity itself, and not necessarily through legitimation by sources outside of the system. 
Centralized Science (CeSci) and Decentralized Science (DeSci) 
Decentralized Science (DeSci) is a relatively new term, introduced by Web3 
collectives to describe the use of recent digital tools for funding, training, planning, 
coordination, execution, dissemination and archival of scientific activities and assets by 
digitally connected communities. DeSci is an emerging area with multiple, potentially even 
incompatible, forming senses, so all explorations here should be considered preliminary 
and partial. The term DeSci suggests, by contrast, the existence of Centralized Science 
(CeSci), which would stand for the continued status quo organization of science as a 
highly bureaucratic activity managed by select academic and private institutions. Some 
motifs or patterns that are found in CeSci and DeSci can be found in Table 1 and Figures 
6-8. DeSci can be defined as the use of Web3 technologies to introduce epistemic 
markets through the deployment of open source and financial tools. In this view, DeSci 
represents the introduction of commodity markets for scientific assets and services where 
such markets were previously impossible (e.g. financialization through tokenization of 
intellectual property, scientific platform governance, peer review or curation services, or 
access privileges to data or infrastructure). In another perspective, DeSci is seen as a set 
of mechanisms for bottom-up individual sensemaking. From this perspective, DeSci is the 
capability of individual agents or communities of practice to make sense of the world 
autonomously, by defining their own questions, language and methodology. These 
disparate views represent the distinction (without preference or judgment) between DeSci 
as a set of emerging Web3 tools and DeSci as a research ecology, respectively. 
Tool use, including markets and organizational technologies like DAOs, are 
fundamental to the ecological view of science [39]. However, proponents of DeSci do not 
conceive of this distinction as a purely technological one, for example simply describing 
7 
the fact that DeSci organizes with the Internet while CeSci utilizes paper as well as digital 
media is an insufficient distinction. For example DAOs don't replace off-chain or offline 
human organization, they augment it with on-chain guarantees and some automatic 
processes for human organization (i.e. voting is still a human process, but once the 
parameters are set the voting itself may be automated and free of human corruption). The 
broader perspective on DeSci is that it aims to reform the organization of scientific activity 
itself, which is expected and preferred to translate into an increased ability for Science to 
fulfill its mandate and align with social values [40]. We fully agree that this expectation is 
warranted, at least in principle, as the socio-epistemic dynamics we call Science clearly 
derive, at some level, from the concrete organization producing it. We will therefore 
attempt to characterize the distinction between CeSci and DeSci in terms of their 
respective organizational and structural aspects.
1 / 1
ChatGPT
ChatGPT
This passage further explains the ideas behind Centralized Science (CeSci) and Decentralized Science (DeSci), emphasizing that they are not meant to be antagonistic, but can coexist and collaborate to enhance scientific research.
Before discussing the differences between CeSci and DeSci, the authors touch on the concept of "Self Certifying Systems." These are systems where entities can validate their own existence, with trust placed within the network entity itself, rather than external sources. A good example is the InterPlanetary File System (IPFS), where data validates its own legitimacy using cryptographic hash functions.
Decentralized Science (DeSci) is a new concept that refers to using digital tools to carry out a wide range of scientific activities, from funding and training to planning and disseminating research. DeSci is still an emerging field with multiple interpretations, so the discussion here is preliminary. Centralized Science (CeSci), on the other hand, represents the current dominant paradigm in scientific research, characterized by hierarchical and bureaucratic structures primarily in academic and private institutions.
DeSci can be seen from two perspectives: as a mechanism to introduce markets for scientific assets and services using open-source and financial tools, or as a means for individual or community-led bottom-up sensemaking, with researchers defining their own questions, language, and methodology.
The authors clarify that the distinction between DeSci and CeSci is not purely technological. For example, while Decentralized Autonomous Organizations (DAOs) are part of DeSci, they don't replace human organization, but enhance it with automated processes and safeguards. The authors assert that DeSci's aim is to reform the organization of scientific activity to better fulfill its mandate and align with societal values. As such, the distinction between CeSci and DeSci is also defined by their different organizational and structural aspects.
1 / 1
Both CeSci and DeSci aim at knowledge discovery, cultivation, and curation, but 
they differ in their means to this end in terms of their incentives, structure, and norms, or 
more generally, in terms of their research ecology. In CeSci, the language, methods for 
discovery, and strategic priorities are imposed from the top down by a core group of 
decision makers acting out the mandate of government policy positions. Core groups of 
decision makers also receive external input and constraints, for example in the case of 
peer review. In DeSci, methods and norms emerge from the bottom-up interactions of a 
web of loosely connected communities of practices with diverse coordination and 
prioritization mechanisms. Therefore, CeSci and DeSci diverge significantly in terms of 
their sensemaking; one imposes specific meaning, understanding, and other cognitive 
constraints to scientific activity so as to keep it legible to the "view from above", the other 
cultivates the "view from the ground" by allowing those same cognitive objects to unfold 
spontaneously throughout the course of the scientific activity. 
Though there is fundamental overlap, and perhaps more similarity than not between 
CeSci and DeSci at this incipient stage, those terms stand for a fundamental divergence in 
the social and epistemic dynamics shaping the organization of research. Here we explore 
some of those dynamics by considering key differences between DeSci and CeSci. 
CeSci: Reducing Sense-Making Complexity Through Centralizing Institutions 
CeSci is characterized by the presence of centralizing agents (such as government 
institutions, philanthropic foundations, private businesses, or universities) having the 
power and willingness to establish and enforce rules, goals, ontologies, and other informal 
constraints within the wider scientific ecosystem. Its purpose can be understood as 
pragmatic rather than purely epistemic, in that CeSci institutions are funded and 
motivated, internally and externally, to build epistemic value (i.e. knowledge) that can 
8 
assist other institutional actors and stakeholders understand and manipulate reality in 
terms of their objectives, for better or worse. An example of this is the 19th Century 
development of statistics, which was explicitly intended to help the developing modern 
States to perceive and control their population through the collection and analysis of 
demographic data, and effectively shaped what it meant to "think like a State" [32]. Due to 
extrinsic mandates, CeSci orients the sensemaking activity of its participant researchers 
toward specifical technical and pragmatic purposes. 
Although the goal of scientific research has largely extended beyond war and 
administration, the modern logic of centralization and technical management is largely 
continued in contemporary research. The managerial role over the epistemic commons 
was granted to modern academic institutions, and complemented their role of supporting 
technological development through research on the property of chemicals, mechanical 
systems, and the like. These institutions have a core mandate of assisting outside 
institutions in their pragmatic endeavors. Their overarching goals are to accumulate 
epistemic value in that direction. Influence over research institutions by external 
organizations can be direct or indirect. In the first case, it may mean cadres of 
administrators exercising direct control over what research objectives should be, what 
funding agencies can be or should be approached, and recruiting based on compliance 
with external mandates. Indirect influence can be exerted, for example, by external 
organizations offering funding based on use of specific language or alignment with 
pragmatic research outcomes. 
Accordingly, the production of knowledge artifacts, such as journal articles, is 
currently enacted according to a hierarchical structure of funding agencies, scientists, 
institutions, and publishers. There are in-groups and out-groups, as well as unspoken 
rules to obtain funding for and publish results of scientific literature. Moreover, there are 
agendas driving all agencies that fund scientific research, which are not necessarily 
transparent. Many basic research questions are framed in a way that adheres to these 
agendas. For example, researchers trying to characterize a mechanism by which a brain 
protein folds will need to emphasize its supposed role in curing Alzheimer's disease, when 
in fact any actionable outcome may be unclear or distant from the research [41]. This 
situation provides a strong incentive for researchers to leverage the information advantage 
they have over administrators to grab their attention by making incredibly grandiose, 
possibly dishonest claims on the meaning of their research. Administrators simply lack 
time or incentive to check on such claims, and active researchers lack the power to modify 
the incentive structure and would risk their job if they refused to follow them. 
One aspect of the difficulty in communicating between administrators and active
1 / 1
ChatGPT
ChatGPT
This passage continues to delve deeper into the differences between Centralized Science (CeSci) and Decentralized Science (DeSci), focusing on their respective structural characteristics and incentive structures.
Centralized Science (CeSci) is characterized by top-down control from central institutions such as government entities, philanthropic organizations, private businesses, or universities. These entities define rules, objectives, ontologies, and other structural constraints for scientific research. CeSci is described as having a pragmatic function, in that its main goal is to produce knowledge that helps other stakeholders understand and manipulate reality in line with their own objectives.
The authors use the development of statistics in the 19th century as an example of this: Statistics were developed to help states understand and control their populations, thus shaping how states operate.
The authors also note that the goal of scientific research has evolved beyond mere administrative and war-oriented purposes, but the centralizing logic remains prevalent. Modern academic institutions act as managers of the epistemic commons and support technological development through research. They are mandated to assist other institutions in their pragmatic goals and to accumulate knowledge in that direction. Influence over these research institutions can be either direct or indirect, with external organizations imposing their goals through funding or the use of specific language.
The production of scientific knowledge, such as journal articles, happens within a hierarchical structure that includes funding agencies, scientists, institutions, and publishers. This hierarchy often results in in-groups and out-groups, with unspoken rules and agendas determining funding and publishing opportunities. This system can lead to research questions being framed to align with these agendas, even if the practical outcome is unclear or far removed from the actual research.
The authors also highlight the problematic incentives this creates. Researchers may be driven to make exaggerated or potentially dishonest claims about their research's significance in order to secure funding or attention from administrators. At the same time, administrators often lack the time or motivation to verify such claims, and researchers who refuse to engage in this system could risk their jobs.
1 / 1
The opportunity for knowledge appropriation (via legal enclosure [42] through 
intellectual property institutions, as well as siloing via disciplinary boundaries) relates the 
development of scientific knowledge to a broader, well-studied category of collective action 
problems: the governance of common goods [43]. Common goods (commons) are defined 
as resources that are non-excludable (one cannot be forbidden from accessing them). The 
potential for misuse or pollution of the commons consequently necessitates governance at 
the scale of communities of stakeholders, and regulation needs to follow certain conditions 
that were initially formalized in economic sociology [11,12] and recently generalized in 
evolutionary theory [44���46]. 
Roughly, the implementation of governance systems for commons entails: 
1. the unambiguous definition of a problem to solve; 
2. the construction of a community of stakeholders willing to help solve this problem; 
3. the institution of a decision system allowing participation on an equal footing by all 
members of the community; 
4. agreement on a set of rules (which are interactive and mutable with validity checks 
over time), which fairly reward active cooperation within the community; 
5. the iteration of (1)-(4) at higher scales where the community as a whole is 
confronted with a situation requiring governance. 
Thus far, the distinction we have made between Centralized and Decentralized 
Science is largely organizational. For example, early European academia emerged from 
the clerical legitimation of scholarly "guilds," professional associations similar to 
contemporary trade unions or cartels, which effectively restricted who could practice a 
certain craft or access a specific kind of knowledge within a certain area (generally a city). 
Thus, patterns of sensemaking were immune from any outside oversight, and were 
imposed by the community on each and every one of its individual members. Centralizing 
institutions can constrain community members with respect to important aspects of their 
11 
intellectual autonomy, and enacted autonomous agency (see Thinking like a State [32] for 
a discussion of institutional autonomy). In contrast, decentralization facilitates broad 
access to the epistemic commons, for example as in the case of the printing press. When 
we highlight the differences between CeSci and DeSci, we aim to frame a discussion on 
how specific kinds of organization can facilitate differences in the integration of information 
about the world over multiple dynamical scales, and what it means for the broader 
scientific community. 
Today, digital technologies provide clear opportunities for proponents of DeSci. 
They facilitate the widespread diffusion of information with a relatively low entry bar, and 
therefore facilitate the voluntary cooperation of multiple communities of practice engaged 
in situated sensemaking. This encourages the decentralized adoption of standardized 
methodologies and languages, transparency over code and data management, and 
willingness to produce information of clear value to outsiders. We see the success of such 
a decentralized yet unifying project in Wikipedia, which is beyond any doubt the most 
important example of a largely standardized, accessible, and transparent knowledge 
system, and is based entirely on voluntary and decentralized cooperation. At the moment, 
there is however no appropriate, analogous system to use in the organization of scientific 
activity, as an alternative (or complement) to the currently dominant role of centralizing 
institutions.
1 / 1
ChatGPT
ChatGPT
The passage discusses how knowledge appropriation, through intellectual property rights or the delineation of disciplinary boundaries, presents a challenge for the scientific community akin to the well-documented problem of managing common goods. The governance of common goods���resources that are non-excludable and thus subject to misuse or pollution���requires a community-wide approach.
The authors lay out a sequence for implementing a governance system for such commons:
Define the problem unambiguously.
Construct a community of stakeholders invested in solving the problem.
Establish a decision system that allows for equal participation from all community members.
Agree on a set of rules that encourage cooperation and can be updated as necessary.
Iterate on this process at higher levels when the whole community confronts a situation needing governance.
The authors then go on to compare this model to the way science is currently organized. They point out that Centralized Science (CeSci) evolved from early European academia, which was essentially a collection of exclusive guilds that monopolized certain types of knowledge. This kind of structure can limit individual intellectual autonomy.
In contrast, Decentralized Science (DeSci) supports widespread access to knowledge, akin to the spread of information enabled by the invention of the printing press. The distinction between CeSci and DeSci, the authors argue, lies in how they manage the integration of information about the world.
They highlight the potential of digital technologies in furthering DeSci, by providing easy access to information and fostering the cooperative exchange of ideas among diverse communities. The authors refer to Wikipedia as an example of successful voluntary, decentralized cooperation leading to a standardized, accessible, and transparent knowledge system.
However, the authors note that no analogous system currently exists for organizing scientific activity, to complement or provide an alternative to the prevalent role of centralizing institutions.
1 / 1
Implementing Decentralized Science in the Web3 Era 
Contemporary digital tools have the potential to establish a distributed and 
transparent scientific community with open participation, where every participant has root 
level access to all knowledge and the rules for its production. Online communities have 
seized the opportunity to develop and utilize such digital tools for funding, training, 
planning, coordinating, executing, disseminating, and archiving scientific assets and 
activities, therefore establishing the blueprint of a Web3 DeSci. There is no defining 
characteristic of the whole set of Web3 DeSci tools. Nonetheless, some features 
characterize a larger subset of these tools and are worth highlighting. 
First, Web3 tools allow for more interactions (including economic transactions) 
between economically- and geographically-diverse groups. Second, Web3 tools can 
increase the transparency of products, activities, and interactions that are themselves 
digital, or that can be represented digitally. Third, Web3 tools allow for the introduction of 
novel markets that, in some pockets, might increase decentralization but in others, might 
increase centralization. Instead of using general terms to elaborate on each of these 
aspects, we hope to demonstrate their reality and significance as we overview more 
specific features of and developments toward a Web3 DeSci implementation. 
Web3 Terminology 
Before heading into some details about the implementation of DeSci (which may 
just be one iteration or genre of the infinite game of Science), the reader should be 
equipped with familiarity around some basic Web3 terms. Note: the following terms are 
just current technological means to building a desired framework, and are presented here 
as introductory, not as comprehensive reviews or final answers. 
���Web3 
���Blockchain 
���Smart contract 
���Token (fungible and nonfungible) 
Web3 First, "Web3" is an imprecise term referring to an ethos that values digital 
self-sovereignty and, more important for our purposes, recent developments in 
peer-to-peer protocols that service this ethos. Part of the Web3 ethos is to value open 
source software and the personal control of one's data and assets [47]. These values have 
13 
influenced and continue to influence the design and adoption of these protocols. Indeed, 
the term "Web 3.0" was introduced by Gavin Wood [48], a key figure in the development of 
the Ethereum and Polkadot protocols, who proposed Web3 as a "post-Snowden" Web, a 
decentralized Web similar to the Web1 of the early internet and in contrast to Web2 where 
a small number of centralized agents control people's data, access to websites, and the 
web applications that many use every day [49]. Web3 protocols are diverse, but the ones 
at the heart of most functional systems are so-called "blockchain" or distributed ledger 
technology (DLT) protocols that support complex smart contracts. 
Blockchain 
Recent developments in peer-to-peer (i.e. decentralized, distributed) protocols, 
particularly blockchain protocols such as ones that facilitate Distributed Autonomous 
Organizations (DAOs [20,21,50]), are the biggest enablers of a Web3 DeSci 
implementation. Without going into detail, a blockchain protocol enables a network of 
self-interested, competing computer nodes to agree on the state and immutable history of 
a shared ledger. Anyone with an internet connection and enough funds can append the 
ledger or verify its integrity, though it is still possible to implement access control with 
smart contracts. Blockchains are a natural fit for building currencies, which historically 
emerged as an extension to bookkeeping by institutional actors [51], and currency building 
in fact constitutes their most widely known application today. However, the principles of 
data integrity and access apply just as well to running any record or application that must 
be tamperproof. Blockchains can be used to establish ownership of digital assets.
1 / 1
ChatGPT
ChatGPT
This section explores how modern digital tools can lay the foundation for a decentralized and transparent scientific community where everyone has unrestricted access to all knowledge. The term 'Web3 DeSci' refers to this decentralized scientific process enabled by digital technologies, with Web3 (Web 3.0) embodying the ethos of digital self-sovereignty.
The authors highlight several key features of Web3 tools:
They enable more interactions (including economic transactions) between economically and geographically diverse groups.
They enhance transparency of products, activities, and digital interactions.
They introduce new markets that could either increase decentralization or centralization.
The authors also provide a brief overview of basic Web3 terminology:
Web3: Refers to recent developments in peer-to-peer protocols emphasizing digital self-sovereignty. The ethos of Web3 values open source software and personal control of data and assets. It's envisioned as a decentralized web, contrasting the centralized nature of Web2 where a few entities control data, access to websites, and daily web applications.
Blockchain: A peer-to-peer (decentralized, distributed) protocol, particularly significant for facilitating Distributed Autonomous Organizations (DAOs). Blockchains allow a network of self-interested, competing computer nodes to agree on the state and immutable history of a shared ledger. Blockchain technology can be used to establish the ownership of digital assets.
Smart Contract: A self-executing contract where the terms of the agreement between buyer and seller are directly written into code. They run on the blockchain and can execute transactions without the need for a trusted third party.
Token: Digital tokens represent a certain fungible and tradable asset or a utility that is often found on a blockchain. Tokens can be fungible (interchangeable with others of the same type) or nonfungible (unique and not interchangeable).
These digital tools offer a new approach for implementing decentralized scientific practices in the era of Web3.
1 / 1
Active Inference, Systems Engineering, and Science 
In this section we justify the use of Active Inference in systems modeling, introduce 
an entity description for science modeling consistent with Active Inference and Systems 
Engineering models, and revisit patterns in CeSci and DeSci. 
What is Active Inference? 
Active Inference is a framework for the integrated modeling of entity perception, 
cognition, action, and impact in the environment. Active Inference draws upon the 
formalism of the free energy principle, which provides a single statistical imperative 
underpinning the assembly of organic and inorganic matter: the minimization of 
informational free energy [89���91]. This principle applies to systems at every scale. The 
process of free energy minimization has been positioned as the driver of autopoietic 
processes in living systems ranging from cells to cities [92,93]. Its core meaning is that it 
allows a goal-oriented, agentic account of self-organization across scales [90]. The 
minimisation of free energy at the system's scale entails the minimisation of variational 
free energy for each of its constituting particles, which can be interpreted as the 
optimisation of a Bayesian model describing the particle's structure (more specifically, the 
difference between model Complexity and Accuracy) [94]. Because of this 
correspondence, we can claim that entities aggregate in virtue of reducing their uncertainty 
about future sensory and active states [95,96]. 
The related framework of Active Inference leverages this formalism to model one or 
multiple interacting entities as involved in continual perception and action angled towards 
reducing the expected uncertainty about their perceptual flow and action selection [97,98]. 
They can do so either by altering internal states so as to infer the causes of sensory 
states, or by altering external states so as to cause expected states. Both processes 
participate in a common control architecture based on predictive processing, which can be 
interpreted as a hierarchy of "algorithms" matching input to output over nested time scales 
[99]. In this hierarchical model, previously-acquired beliefs about controlling behavior in 
different contexts are internally encoded, and result in adaptive arbitration between 
epistemic and pragmatic value choices (i.e. exploration vs exploitation, [100]). Thus, the 
framework of Active Inference allows us to model the observations, beliefs, and 
predictions (i.e. expected states) of agents as statistical dependencies, or Bayesian 
probability distributions. 
28 
Much of the focus in the Active Inference literature has been on organisms, 
especially in the context of human behavioral neuroscience [101]. However, Active 
Inference has also been applied to various other informational and cyberphysical settings 
such as human communication [102], remote teams [23], human conflict [103], trust 
interactions with robotics [104], and social media discourse [26]. Here we apply Active 
Inference and Systems Engineering to the case of modeling centralized and decentralized 
science. 
Active Inference and Science 
Evidence of collective intelligence, understood as the capability of human societies 
to solve problems, surrounds us. In most cases, it is instantiated in cultural artifacts or 
cognitive gadgets [105] that follow from a process of cumulative cultural evolution dating 
from the branching of the Homo genus [106,107]. We are surrounded by living fossils of 
this cumulative process, from smartphones to hospitals, from net fishing to general 
agreements about the recognition of private property. Our capability to understand and 
navigate the world does not simply follow from information in our minds, but it is (to some 
extent) entailed by the very structure of the ecological niche and the social constraints that 
shape our behavior. This means that entities are, to some extent, autonomous or 
displaying agency regarding their own cognition [32]. Entities engaged in Science as a cognitive endeavor are no exception.
1 / 1
ChatGPT
ChatGPT
In this section, the authors propose using Active Inference for systems modeling in science and elaborate on the principles of Active Inference and its application in science.
Active Inference is a framework for the integrated modeling of an entity's perception, cognition, action, and impact on the environment. It uses the formalism of the free energy principle, which suggests that all systems, both organic and inorganic, seek to minimize informational free energy. This principle has been proposed as the driving force behind self-organization processes in living systems of various scales, from cells to cities. It implies a goal-oriented, agentic account of self-organization across scales.
Active Inference allows modeling one or multiple entities continuously perceiving and acting towards reducing the expected uncertainty about their perceptual flow and action selection. It does this either by altering internal states to infer the causes of sensory states or by altering external states to cause expected states. This is based on a common control architecture, predictive processing, which matches input to output over nested time scales.
In the context of science, the authors argue that human societies display collective intelligence, or the ability to solve problems, which is often seen in cultural artifacts that have emerged from cumulative cultural evolution. This capability to understand and navigate the world is not just internal but is also shaped by the structure of our ecological niche and social constraints. Thus, entities involved in science display a level of autonomy or agency in their cognition.
By applying Active Inference to science, the authors aim to better understand and model centralized and decentralized scientific processes. They argue that this approach provides a useful framework for understanding and predicting behavior in these contexts.
1 / 1
Like other instances of collective intelligence involving stigmergy (collective 
behavior mediated through modification of a shared niche) [108,109], Science is a 
cumulative endeavor that relies on previously-acquired beliefs and established 
communities of practice. Scientists and other cognitive entities perceive stigmergic cues 
from the niche (including epistemic resources, as well as other social entities), update their 
cognitive models (learning), and act to modify the niche in the form of research outputs 
(Figure 2). As scientists follow new leads or choose to ignore them, communities coalesce 
and disperse, and scientific theories are created, developed, and maintained or forgotten. 
Frequently, scientific endeavors are undertaken with multiple, potentially competing, goals 
in mind. For example, scientists may work with an aim to achieve some or all of the 
following outcomes: earn a paycheck, improve their reputation, improve the reputation of 
their company or institution, conduct empirical research without bias, solve a particular 
problem, or discover something novel, simple, or beautiful. 
29 
Figure 2. Two active entities interacting via their shared epistemic niche. For more 
detail on the entity perception-cognition-action loop in Active Inference, and the Markov 
Blanket formalism comprising the partition shown here, see [90]. 
Active Inference is relevant for model-based understanding of scientific systems 
because it offers a composable multiscale ontology and an integrative framework for entity 
and system behavior [93,110]. Thus the usage of Active Inference can help us understand 
the entanglement of multiple processes occurring at nested scales of behavior during 
scientific research. In Active Inference, actions across scales are modeled as a systematic 
attempt by cognitive entities (i.e. scientists and institutions) to reduce uncertainty about 
aligning their future perceptions with their preferences, so as to ensure their persistence of 
their defining organization. For example, the development of administrative systems and 
agriculture was described within Active Inference formalism as a product of City-States��� 
attempt to understand and control their reality [32], analogously to the process of 
morphogenesis as a process of cells manifesting a body plan which reduces their 
uncertainty about their cellular niche [95]. 
Importantly, the Active Inference account is not limited to conservative 
(homeostatic) behavior, but also to more complex phenomena such as memory, 
anticipation, abductive logic, and autopoiesis. For example, Active Inference has been 
used to model the systematic alteration of one���s niche [99,111,112], as well as the creation 
of new tools and their incorporation into one���s cognitive identity [95]. Therefore, it very 
much provides grip on innovation, by contextualizing subjective systems of meaning in relationship to the concrete (biological and sociocultural) organizations which underlie 
cognition [113]. 
In the context of action selection related to research (e.g. experimental design, 
decisions about scientific communication, acquiring funding), Active Inference provides a 
division between two kinds of motivation in research: epistemic value (informational gain 
related to e.g. new research findings or knowledge) and pragmatic value (reward 
associated with increases in wealth, longevity, or status). Any innovation in institutional or 
cognitive processes will affect the broader system both epistemically, by defining the social 
norms which entail scientific activity, its cognitive underpinnings, and the kind of cues and 
actions scientific activity involves; as well as pragmatically, by reinforcing the specific 
behaviors which help the relevant (institutional or human) agent to reduce (subjective) 
uncertainty about future sensorimotor states. When viewed through this lens, the scientific 
process balances action selection based upon the both epistemic and pragmatic value, 
and this process plays out across multiple scales of nested organization. For example, at 
different stages of their day/career, the individual human researcher prioritizes more 
exploratory/learning activities, while at other times prioritizes more exploitative/productive 
activities. At the scale of an individual, institution, or even scientific field, the epistemic 
activities are reflected by basic research, while the pragmatic activities can be considered 
as translational or application-oriented research, or engineering. 
As metascience and sociology of science typically focus on the motivations and 
systems of incentive on the scale of individuals and institutions, we consider the multiscale 
nature of Active Inference to provide a relevant angle for future research. This work 
reflects early steps towards leveraging this framework into a more detailed understanding 
of how scientific entities interact, and how contemporary changes associated with the 
challenges and opportunities of DeSci could improve on the status quo.
1 / 1
ChatGPT
ChatGPT
This section describes the application of Active Inference to scientific systems, particularly within the framework of collective intelligence and stigmergy, which is the principle of indirect communication and coordination between agents through changes in their shared environment.
Science is a cumulative endeavor in which researchers perceive cues from their environment (including intellectual resources and social entities), update their cognitive models (learning), and produce outputs that further modify their shared intellectual environment. These processes may be influenced by multiple, potentially competing, objectives, such as personal income, reputation enhancement, unbiased empirical research, problem-solving, or the discovery of something new, simple, or beautiful.
The authors propose Active Inference as a useful tool for understanding scientific systems due to its composable multiscale ontology and an integrative framework for entity and system behavior. This framework allows us to understand the intertwined processes occurring at nested scales of behavior during scientific research. Actions are modeled as cognitive entities (such as scientists and institutions) systematically attempting to reduce uncertainty about their future perceptions aligning with their preferences.
The framework of Active Inference is not limited to conservative (homeostatic) behavior. It can account for complex phenomena such as memory, anticipation, abductive logic, and autopoiesis. This is evidenced by the application of Active Inference in modeling niche alteration and tool creation.
Regarding action selection related to research (e.g. experimental design, decisions about scientific communication, acquiring funding), Active Inference distinguishes between two types of motivation: epistemic value (informational gain) and pragmatic value (reward associated with increases in wealth, longevity, or status).
The scientific process balances action selection based on both epistemic and pragmatic value. This balance plays out across multiple scales of nested organization, from the individual human researcher to institutions or scientific fields. It leads to a fluctuation between prioritizing exploratory (learning) activities and more exploitative (productive) activities.
The authors propose that this multiscale approach to Active Inference provides a promising avenue for future research into the motivations and incentive systems at various scales in the scientific process. They also suggest it could provide a better understanding of how scientific entities interact and how decentralized science (DeSci) could improve the status quo.
1 / 1
Active Entity Ontology for Science (AEOS) 
Here we describe the attributes and structural basis of a descriptive entity-oriented 
ontology for Science, consistent with the principles of Active Inference and Systems 
Engineering previously described. This project has the working title and acronym Active 
Entity Ontology for Science (AEOS). Previously, among many other use cases, ontologies 
have been used for schematic mapping of cryptographic systems and knowledge 
ecosystems [114]. Additionally, approaches for complex systems modeling based upon 
entities and their affordances have precedence in economics [115] and other areas. We 
build on this work to create a useful and versionable resource which stands to be 
developed and extended by researchers and practitioners in the coming years. This work 
is meant to be a starting point for the construction of active entity-oriented ontologies of 
31 
science. See coda.io/@active-inference-institute/active-entity-ontology-for-science-aeos 
for an interactive site that provides an updated version of AEOS. 
Table 1 below provides example entity interaction motifs for CeSci and DeSci 
ecosystem models. These motifs are presented as initial drafts on the specification and 
visualization of subsystems/modules that are important for larger networks of interacting 
entities. 
Area of ConcernExample CeSci MotifExample DeSci Motif 
Funding Team Publishes Knowledge Artifact (Grant), 
then Requests Funding From Funding 
Agency, which Scientifically Assess the 
Grant. 
Funding Agency Provides Opportunity for 
Researcher, Provides Constraints for 
Researcher, and Sends Fungible Asset to 
the Team 
Team Publishes Knowledge Artifact 
(Grant), then Requests Funding From a 
DAO which Scientifically Assesses the 
Grant 
The DAO Engages in governance 
regarding the Grant and Sends Fungible 
Asset to the Team 
Communication Academic University Communicates 
Asynchronously To Lab via Computer 
System 
Human Communicates Asynchronously 
or Synchronously To Human via the 
Computer System 
Cryptographic 
Relationship 
Research investigator uses Cryptographic 
Identity on Computer System to Provides 
Funding To Team and Provides Updates to 
Funder like Research Agency (Government) 
Research investigator Team transfers 
Intellectual Property as Non-Fungible 
Asset to a DAO Cryptographic Identity 
that is a Smart Contract . 
Scientific 
Review 
A Research investigator Sends Fungible 
Asset to Journal/Publisher to Publish 
Knowledge Artifact like a Paper. The 
Journal/Publisher Requests Scientific 
Review from other Research investigators 
After Publishing a preprint Paper, the 
Research investigator receives a 
Fungible Asset as a function of the use of 
the Knowledge Artifact 
Research & 
Analysis 
Research investigators in Lab Team 
Creates, Scientifically Assesses, then 
Publishes Knowledge Artifact 
Research investigators in DAO 
Community of Practice Creates, 
Scientifically Assesses, then Publishes 
Knowledge Artifact 
Publishing After Scientific Review, a Research 
investigator Publishes Knowledge Artifact at 
Journal/Publisher. 
A Research investigator Publishes 
Knowledge Artifact like a Paper on a 
DAO-produced knowledge market. AEOS Entity Classes and Types 
The fundamental object or kind of thing in the AEOS is the Active Entity, which in 
online settings is almost always interacting with Informational Entities [23]. Drawing upon 
the Active Inference framing of a system, this entity is a system of interest that is 
partitioned from its niche surroundings based upon its capacity for persistence, thus 
making it a "thing" [122,123]. 
In AEOS, there are two Classes of Entity (Figure 3): Active epistemic entities (which 
select action policies and enact affordances), and Informational entities (which contain 
information and are acted upon). There are multiple Entity Types within each Class. In the 
digital/online setting, Active Entities are always intermediated by Informational entities 
(e.g. People can talk online through modification of a shared epistemic niche reflected by a 
computer system). Informational entities are always intermediated by Active entities (e.g. 
two databases can only communicate with each other through a computer system). The 
distinction between "Adaptive" and "Mere" Active Inference entities (e.g. those that engage 
sentiently and adaptively in the world) in introduced in [124]. 
Figure 3. Entity Classes in Active Entity Ontology for Science (AEOS). Active 
Entities (blue boxes) are any kind of organization with agency at any scale, for example 
humans, teams, organizations, institutions, and DAOs. Informational Entities (orange 
circle) is any type of computational data or epistemic resource, for example a dataset, 
grant, article, or fungible/non-fungible asset. 
34 
Both classes of entities (Active and Informational) inherit the same type of Active 
Inference partitioning scheme described above. See the AEOS site for an updated list of 
the diverse types of entities currently modeled. Some examples of Active entities in AEOS 
include Human, Computer System, Organization, Team, DAO, Academic University, and 
Community. Of special note are the Organizational entities, composed of groups of 
humans, computer systems, or other organizations (e.g. a university made up of 
departments, made up of labs, made up of people), along with their informational 
resources. As with any other Active Entity, Organizational entities engage in outgoing 
actions from a set of discrete or continuous options (affordances), and also can be the 
recipient/target of action from other entities. 
Entities of the Informational class are those which are being modeled for their 
informational content, and are solely acted upon. Some types of Informational entities may 
also display agentic qualities when used by Organizational and Computer System entities, 
for example a software program. The Informational entities are used as epistemic 
resources in the niche of other Agent-class entities. Some examples of Informational 
entities in AEOS include Knowledge Artifact, Fungible Asset, Non-Fungible Asset, 
Dataset, Metadata, Paper, Intellectual Property, Code, Grant, and Blockchain. 
AEOS Policy Selection, Areas of Concern, and Roles
1 / 1
ChatGPT
ChatGPT
In this section, the authors introduce an ontology called the Active Entity Ontology for Science (AEOS), designed to describe scientific processes in line with the principles of Active Inference and Systems Engineering. Ontologies have previously been used in a wide range of applications, including mapping cryptographic systems and knowledge ecosystems, and modeling complex systems based on entities and their affordances. The authors envision AEOS to be a continually evolving resource that can be extended and refined by researchers and practitioners over time.
As examples of the application of AEOS, the authors present a set of comparison tables illustrating the ways in which certain entity interaction motifs might be specified in Centralized Science (CeSci) and Decentralized Science (DeSci) ecosystem models. These comparisons span various areas of concern, including funding, communication, cryptographic relationships, scientific review, research & analysis, and publishing. The contrasts between CeSci and DeSci models are highlighted in each example.
Within the AEOS framework, the authors categorize entities into two primary classes: Active Epistemic Entities, which select action policies and enact affordances, and Informational Entities, which contain information and are acted upon. These categories include various types of entities. In a digital/online setting, Active Entities interact through Informational Entities, and vice versa. For instance, people communicate online by altering a shared epistemic niche represented by a computer system.
The authors clarify that both classes of entities in AEOS are subject to the same kind of Active Inference partitioning scheme previously described. They provide a link to an updated list of the diverse entity types currently modeled in AEOS. Examples include active entities such as Humans, Computer Systems, Organizations, Teams, DAOs, Academic Universities, and Communities, as well as informational entities like Knowledge Artifacts, Fungible Assets, Non-Fungible Assets, Datasets, Metadata, Papers, Intellectual Property, Codes, Grants, and Blockchains.
The authors note that some types of Informational Entities may display agentic qualities when used by Organizational and Computer System entities. As with any other Active Entity, Organizational entities can engage in outgoing actions from a set of discrete or continuous options (affordances) and can also be the recipient/target of action from other entities. The authors suggest that AEOS's policy selection, areas of concern, and roles are the next topics to be discussed.
1 / 1
BOLTS and Reliability for Science Systems 
It is important to provide reliability in all of these BOLTS dimensions, as new 
technologies and systems can easily fail if there are repeated bad experiences or 
unexpected incompatibilities. Even if the technical and legal aspects of DeSci funding 
out-perform CeSci funding, failure of DeSci to provide a smooth integration from the social 
and business perspectives could delay or prevent wide adoption. For example, traditional 
funding agencies often come in at middle-to-late stages of research projects, which is why 
so much preliminary work is required for a NSF/NIH grant. It is often said grants are not 
���for ideas���, but rather they are for seriously-developed avenues of specific tractable 
research. In DeSci, some more speculative vehicles might exist (e.g. a ���Learner���s Fund���), 
but we cannot expect these new vehicles to back-propagate the risk-tolerance of DeSci 
into legally- and organizationally-bound CeSci funding agencies. 
A priority of both CeSci and DeSci is to ensure reliability of outcomes and high 
levels of accountability, in complex scientific commons. If a team has been funded, 
disintegration or failure to produce work doesn���t just mean a negative outcome for the 
team, it means a negative outcome for the funder, which has the potential for network 
impacts on trust within the entire market. This means that teams within the DeSci space 
would not only need to vastly outperform CeSci in terms of cost, time-to-impact, and 
efficiency, but would also need to effectively be perceived as high-reliability organizations 
in order for the market to survive. Given that DeSci teams are likely to be emergent, they 
may not be able to rely on intimate trust between one another, and instead will have to rely 
heavily on shared Ontology, Narrative, Formal documents, and Tools [23]. The team 
working environment should be designed to create the best possible conditions for the 
cognitive security of the individuals on teams, such that they stay on task, maintain 
consistency in terms of goals and intents, and understand their impact on the team and 
the future of the market as a whole. This type of system design also means high cognitive 
security on the part of the funder, which means high visibility and high quality narrative 
information management tools at their disposal [41], the ability to do retroactive analysis of 
track-records of individuals and collections of individuals, the ability to rapidly compare 
projects, and the ability to negotiate cost as a basis to reduce risk based on current 
42 
information. Additionally, transparency ensures that when things do go wrong, it reduces 
the negative sentiment of the funder on the network, and might be mitigated by insurance 
options (e.g. community stake in research) or in-house recourse options (e.g. sanctions 
and penalties on negligent and bad-faith actors) 
While we detailed the BOLTS conflicts related to funding processes as DeSci 
practices are integrated into existing CeSci practices, this framework can be applied to 
several other aspects of this integration such as the publication of knowledge artifacts, 
scientific review of knowledge artifacts, communicating research results at conferences, 
analyzing data, training and mentoring new researchers, and developing scientific 
software. CeSci and other fields already have successful aspects which should be 
preserved as DeSci is integrated, such as specific mentorship, individual, and peer 
development programs. As a framework that furthers the holistic design of 
transdisciplinary systems for science, we we suggest that Active Inference provides 
additional insights and directions related to DeSci, which have been outlined in the this 
work. Discussion 
This paper evaluated the opportunity to implement decentralized science in Web3 
technologies from the perspective of Active Inference. 
We first highlighted the distinction between two approaches to scientific research, 
respectively Centralized Science (CeSci), where research is driven from the top-down 
perspective of centralizing institutions, and Decentralized Science (DeSci), where it is 
driven from the bottom up through situated sensemaking by communities of practices. 
Both approaches may work together, without either approach dominating the other. We 
argued that the DeSci stance can facilitate the governance of scientific knowledge 
(understood as an epistemic common good) by providing both the incentive and the 
opportunity to build a detailed understanding of various systems and problems in an 
integrated language. 
We consequently reviewed potential avenues to implement DeSci in the era of 
Web3. We underlied a major limitation to marketization and tokenization, one of the main 
mechanisms of Web3 technologies, namely that creating real world value for the token 
renders it vulnerable to speculative investment and hoarding (and other corruptive 
influence). We discussed the potential roles and benefits of modern affordances, including 
online teams, blockchain, tokenization, and smart contracts. Finally, we discussed several 
practical aspects of integrating DeSci concepts and practices into CeSci, such as 
business, operations, legal, technical, and social (BOLTS) aspects of this transition. 
Finally, we discussed the role of the Active Inference framework in describing 
scientific ecosystems. As a formalism relating the basic activity of dynamical systems to 
epistemic inference, we argued it is a natural fit to describe science as a socio-institutional 
system. We outlined an Active Entity Ontology for Science (AEOS), intended to define key 
Entity Classes, Entity Types, Areas of Concern, Roles, Affordances, and Action-Perception 
States involved in conducting scientific work, whether CeSci or DeSci, with examples 
illustrating particular embodiments of this ontology. We hope that further development of 
research within the scope of AEOS would yield fruitful progress in our ability to design and 
evaluate possible forms of scientific organization. 
Some specific next steps include: 
���In the open source Active Blockference package [131], we are developing Active 
Inference models that are implemented in the complex system modeling framework 
cadCAD [132], with a goal of enabling description, analysis, and simulations of 
complex cognitive ecosystems of ���shared intelligence��� [28]. 
44 
���Exploration of Active Inference ontologies and relationships with category theory 
[116] and other formalisms. 
���Creation of Graphical User Interface for DeSci (DeSciCAD), to enable the real-time 
use of AEOS in science ecosystem design and operation. For example, a user 
could select entity types, assign them roles, connect the entities with 
affordance-based edges, and engage in simulation and parameter optimization. The 
front end of such a design interface would ideally be accessible (via visual, textual 
and other modalities) and enable productive creation of composable Active 
Inference simulations. 
���Exploring system designs in AEOS that scaffold and incentivize different kinds of 
research such as basic/theoretical, translational/applied, and quantitative/qualitative 
work. One specific application would be to use AEOS in behavioral modeling of 
incentive gaps, such as getting people to publish data even if they don't publish the 
paper, or finding ways to accept modular contributions, so that in the case of 
retraction or deciding not to publish, pieces can still be made available and citable. 
We hope that this work has provided a useful understanding of DeSci with respect 
to the current CeSci system in terms of what is possible now and in the future, and an 
interactive modeling framework in AEOS which we will continue to develop and apply.
1 / 1
ChatGPT
ChatGPT
This document seems to provide a detailed analysis of the current transition occurring in scientific research, from a traditional centralized model (CeSci) to a more decentralized model (DeSci). The decentralized model, often underpinned by Web3 technologies like blockchain, tokens, and smart contracts, offers a more bottom-up approach, fostering local sensemaking and decision-making in research communities.
This transition isn't without challenges, especially in terms of integration with the existing centralized model. The authors propose a BOLTS (Business, Operations, Legal, Technical, and Social) framework to identify and address these challenges. In addition, the authors introduce an Active Entity Ontology for Science (AEOS) that includes specific concepts such as entity classes and types, areas of concern, roles, affordances, and action-perception states. The purpose of AEOS is to provide a comprehensive description and modeling of scientific work, whether it falls under the CeSci or DeSci model.
The authors highlight the need for more research in areas such as developing active inference models in the cadCAD modeling framework, exploring relationships between active inference ontologies and other formalisms like category theory, creating a graphical user interface for DeSci, and designing systems that encourage various kinds of research work.
The overall aim is to facilitate a smoother transition towards DeSci, while leveraging the benefits of CeSci, thereby creating a more inclusive, responsive, and resilient scientific research ecosystem.
1 / 1
A list of everything we have discussed.
1 / 1
ChatGPT
ChatGPT
Sure, here's a summary of our conversation thus far:
Decentralized Science (DeSci) and Centralized Science (CeSci):
We discussed the transition from traditional centralized science (CeSci) to a more decentralized model (DeSci). The former model follows a top-down approach, while the latter promotes a bottom-up, community-driven approach to scientific research.
Web3 Technologies:
We highlighted the role of Web3 technologies, such as blockchain, tokens, and smart contracts, in facilitating the shift to DeSci. These technologies could improve transparency, collaboration, and efficient resource allocation in scientific research.
Active Entity Ontology for Science (AEOS):
We delved into the Active Entity Ontology for Science (AEOS), a framework proposed to better understand and model both CeSci and DeSci ecosystems. This includes concepts like Entity Classes and Types, Areas of Concern, Roles, Affordances, and Action-Perception States.
BOLTS Framework:
We discussed the BOLTS (Business, Operations, Legal, Technical, and Social) framework. This approach is suggested to identify and handle potential challenges in integrating DeSci practices into the existing CeSci structures.
Reliability in Science Systems:
We touched upon the need for reliability in both CeSci and DeSci models, emphasizing the importance of trust, accountability, and cognitive security in these scientific ecosystems.
Future Research Directions:
We looked at some potential areas for future research, including developing Active Inference models, exploring relationships between active inference ontologies and formalisms like category theory, creating a Graphical User Interface for DeSci, and investigating systems that encourage various types of research work.
The goal of these discussions and future research directions is to facilitate the transition from CeSci to DeSci while ensuring the benefits of both models are fully realized.
1 / 1
A list of all of the topics and themes: we started Predictive processing and relevance realization: exploring 
convergent solutions to the frame problem
1 / 1
ChatGPT
ChatGPT
Here are the main topics and themes we have covered:
Predictive Processing:
We discussed this as a cognitive theory where the brain constructs a model of the world and uses it to predict sensory input. This model is continuously updated based on the differences between predicted and actual sensory input.
Relevance Realization:
This term refers to the cognitive process of determining what information is relevant in a given context. It is a critical aspect of cognition and problem-solving.
Convergent Solutions to the Frame Problem:
The "Frame Problem" is a philosophical issue in the field of artificial intelligence and cognitive science relating to how a cognitive agent determines what is and isn't relevant when making a decision or prediction. We discussed the ways in which predictive processing and relevance realization may provide convergent solutions to this problem.
Decentralized Science (DeSci) and Centralized Science (CeSci):
We explored the transition from traditional centralized science to a more decentralized model of scientific research.
Web3 Technologies and Science:
We discussed how Web3 technologies, such as blockchain and smart contracts, could aid the shift to a decentralized model of science.
Active Entity Ontology for Science (AEOS):
We examined this proposed framework to better understand and model both CeSci and DeSci ecosystems.
BOLTS Framework:
The BOLTS (Business, Operations, Legal, Technical, and Social) framework was explored as a means to address potential challenges in the integration of DeSci practices into existing CeSci structures.
Reliability in Science Systems:
The importance of trust, accountability, and cognitive security in both CeSci and DeSci was discussed.
Future Research Directions in DeSci:
We outlined several potential areas for future research to facilitate the transition from CeSci to DeSci and to maximize the benefits of both models.
These discussions covered a wide range of topics, from cognitive science and philosophy of mind to the application of novel technologies and theoretical frameworks in the restructuring of scientific practice.
1 / 1
Connections with the following: 

Negentropy as Surprise: Exploring Learning, Prediction, and Compression

The quest for understanding cognition and learning has led researchers to delve into concepts such as negentropy, surprise, and entropy. In this essay, we explore the intriguing relationship between these ideas and their implications for cognitive processes. 

Specifically, we investigate how learning can be viewed as a means to reduce surprise by harnessing negentropy through prediction and compression.

Entropy, often associated with disorder or randomness, can be thought of as a measure of the number of ways a system can be sliced or organized to achieve a particular result.

Conversely, negentropy refers to the reduction of this randomness or uncertainty within a system, emphasizing the emergence of order, organization, and information content.

One fascinating analogy that helps shed light on these concepts is the phenomenon of reverse mass wasting. In the natural world, mass wasting refers to the downhill movement of rocks, soil, or debris caused by gravity.

Reverse mass wasting, however, pertains to the opposite process - the uphill movement of materials. Similarly, in the realm of cognition, the reduction of uncertainty and the emergence of order through learning can be seen as a form of reverse mass wasting.

At the heart of this exploration lies the notion of surprise. Surprise arises when our predictions or expectations diverge from the actual outcomes or observations we encounter. Learning, then, can be seen as a process of inoculation against surprise.

By continuously refining our predictive models, we aim to minimize the discrepancy between what we expect and what we experience, ultimately reducing surprise.

Prediction and compression play crucial roles in this framework. Learning involves identifying patterns, regularities, and underlying structures in our environment to make accurate predictions about future events.

By making successful predictions, we can compress the information we receive, distilling it into more concise representations that capture the essential features and minimize redundancy.

Drawing on the analogy of entropy, where slicing a system in various ways can yield similar results, we explore how learning enables us to uncover meaningful ways to organize and represent information.

Through the reduction of uncertainty and the compression of data, we strive to increase the efficiency and effectiveness of our cognitive processes, enhancing our ability to navigate and understand the world around us.

By understanding the interplay between negentropy, surprise, and entropy, we gain valuable insights into the nature of learning and cognition.

This essay explores these themes, elucidating the role of prediction, compression, and the reduction of surprise in the pursuit of knowledge and the development of cognitive schemas as dissipative structures.
1 / 1
The previous model used in this conversation is unavailable. We've switched you to the latest default model.
ChatGPT
ChatGPT
The topics discussed in your essay on negentropy, surprise, and entropy have connections with our previous discussions. Here's how they relate to the topics we covered:
Predictive Processing and Surprise
: The concept of surprise, which arises when predictions diverge from actual observations, aligns with the notion of prediction error in predictive processing. In our discussions, we explored how the brain constructs predictive models and updates them based on the level of surprise or prediction error.
Learning and Reduction of Surprise
: Learning can be seen as a process of reducing surprise by updating our predictive models to align with observed data. We discussed how learning is a means to minimize the discrepancy between expectations and reality, thereby reducing surprise.
Compression and Information Representation
: The idea of compressing information by distilling it into more concise representations aligns with the notion of efficient coding in cognitive processes. We explored how learning involves identifying patterns and regularities to make accurate predictions and compress the information we receive.
Negentropy and Order Emergence
: The concept of negentropy, which refers to the reduction of randomness or uncertainty, connects with the notion of order and organization that emerges through learning and cognitive processes. We discussed how learning can lead to the emergence of order and increase the efficiency of cognitive systems.
Entropy and Disorder
: The concept of entropy, associated with disorder or randomness, can be related to the unpredictability or surprise in cognitive processes. We explored how reducing entropy through learning and prediction allows for more effective navigation and understanding of the world.
Overall, the themes discussed in your essay on negentropy, surprise, and entropy complement the topics we explored, providing additional insights into the nature of learning, cognition, and the quest for knowledge.
1 / 1
A summary of our conversation
1 / 1
ChatGPT
ChatGPT
Throughout our conversation, we discussed various topics related to cognition, science, and the implementation of decentralized science in the Web3 era. Here's a summary of the key points we covered:
Predictive Processing and Relevance Realization
: We explored the concept of predictive processing and its role in cognition, emphasizing its connection to the frame problem and the importance of relevance realization for effective information processing.
Decentralized Science (DeSci) and Centralized Science (CeSci)
: We discussed the differences between DeSci and CeSci, highlighting the organizational aspects and the potential benefits of decentralized approaches in terms of access to information, collaboration, and innovation.
Web3 and the Potential for DeSci
: We explored the opportunities provided by Web3 technologies, such as blockchain, smart contracts, and decentralized autonomous organizations (DAOs), for establishing a distributed and transparent scientific community with open participation.
Active Inference and Science
: We delved into the framework of Active Inference, which integrates entity perception, cognition, action, and impact in the environment. We discussed how Active Inference can be applied to modeling scientific systems and understanding the dynamics of scientific research.
Active Entity Ontology for Science (AEOS)
: We introduced AEOS, an entity-oriented ontology for science that aligns with Active Inference and provides a descriptive framework for modeling scientific entities, interactions, and roles.
Reliability and BOLTS
: We emphasized the importance of reliability and accountability in both CeSci and DeSci systems. We discussed the need for high-reliability organizations in DeSci and the role of transparency, cognitive security, and effective narrative information management in ensuring reliability.
Negentropy, Surprise, and Learning
: We explored the relationship between negentropy, surprise, and learning in the context of cognition. We discussed how learning can be seen as a process of reducing surprise by harnessing negentropy through prediction, compression, and the reduction of uncertainty.
By discussing these topics, we aimed to gain insights into the nature of cognition, the governance of scientific knowledge, and the potential of decentralized approaches in transforming scientific practices.
1 / 1
Self organizing  criticality at all levels of the brain
1 / 1
ChatGPT
ChatGPT
Self-organizing criticality (SOC) refers to a concept in complex systems theory where a system naturally evolves to a critical state, characterized by a balance between order and chaos. This concept has been applied to various domains, including the brain.
In the context of the brain, self-organizing criticality suggests that neural activity exhibits critical dynamics, where the system operates near a phase transition between order and disorder. This critical state is thought to enable the brain to efficiently process and integrate information, facilitating complex cognitive functions.
At all levels of the brain, from individual neurons to large-scale neuronal networks, self-organizing criticality has been observed. Neuronal avalanches, which are cascades of neural activity that spread through the brain, have been found to exhibit power-law distributions, a characteristic of critical systems. These avalanches occur across spatial and temporal scales, reflecting the presence of self-organized critical dynamics.
The idea behind self-organizing criticality in the brain is that it allows for the emergence of collective behaviors and the integration of information across different brain regions. It provides a framework for understanding how the brain dynamically balances stability and flexibility, adapting to environmental demands and facilitating cognitive processes such as perception, attention, and learning.
While self-organizing criticality in the brain is an intriguing concept, its precise role and implications for brain function are still being explored. Researchers continue to investigate how SOC contributes to the brain's ability to process information, adapt to changing circumstances, and support complex cognitive processes.
1 / 1
High-speed memory scanning: a behavioral argument for a serial oscillatory model
B Burle et al. Brain Res Cogn Brain Res. 2000 Jun.
Show details

Full text links
Cite

Abstract
In order to account for the memory span [G.A. Miller, The magical number seven, plus minus two: some limits on our capacity for processing information, Psychol. Rev. 63 (1956) 81-97.], the magical number seven, plus minus two, and high-speed scanning in human memory ��S. Sternberg, High speed scanning in human memory, Science 153 (1966) 652-654., Lisman and collaborators [O. Jensen, J.E. Lisman, An oscillatory short-term memory buffer model can account for data on the Sternberg task, J. Neurosci. 18 (1998) 10688-10699; J.E. Lisman, M.A.P. Idiart, Storage of 7+/-2 short-term memories in oscillatory subcycles, Science 267 (1995), 1512-1515.] proposed an oscillatory short-term memory buffer model. In this neurophysiological model: "a single brain network can separately maintain up to seven memories by a multiplexing mechanism that uses theta and gamma brain oscillations for clocking. A memory is represented by groups of neurons that fire in the same gamma cycle" ��O. Jensen, J.E. Lisman, An oscillatory short-term memory buffer model can account for data on the Sternberg task, J. Neurosci. 18 (1998) 10688-10699, p. 10688. To test this model, we tried to modify the memory scanning time by shifting the gamma oscillation frequency. To this aim, we replicated the visual short-term memory scanning task ��S. Sternberg, High speed scanning in human memory, Science 153 (1966) 652-654., and we simultaneously used the protocol that Treisman ��M. Treisman, A. Faulkner, P.L.N. Naish, D. Brogan, The internal clock: evidence for a temporal oscillator underlying time perception with some estimates of its characteristics frequency, Perception 19 (1990) 705-743. designed to drive, slowing down or speeding up, a temporal oscillator acting in the gamma range ��J.G.R. Jefferys, R.D. Traub, M.A. Whittington, Neuronal networks for induced "40 Hz rhythms, Trends Neurosci. 19 (1996) 202-208; W. MacKay, Synchronized neuronal oscillations and their role in motor processes, Trends Cog. Sci. 1 (1997) 176-183; M. Treisman, N. Cook, P.L.N. Naish, J.K. MacCrone, The internal clock: electroencephalographic evidence for oscillatory processes underlying time perception, Q. J. Exp. Psychol. 47A (1994) 241-289.. In this protocol, an auditory periodic stimulus (click train) was delivered at various frequencies during the task. The reaction time (RT), the slope, and the intercept of the linear function associating RT to memorized list length showed systematic modulations according to the stimulation frequency. The predicted driving effects due to the click trains were obtained, consisting of localised modulations of performance on the stimulation frequency band. We argue that memory scanning is indeed paced by a temporal oscillator, thus providing behavioral arguments for the serial oscillatory model of Lisman
1 / 1
ChatGPT
ChatGPT
The study by Burle et al. (2000) investigates the concept of high-speed memory scanning and provides behavioral evidence in support of the serial oscillatory model proposed by Lisman and collaborators. The serial oscillatory model suggests that a single brain network can maintain multiple memories by using theta and gamma brain oscillations as a clocking mechanism.
To test this model, the researchers replicated the visual short-term memory scanning task and manipulated the gamma oscillation frequency by using an auditory periodic stimulus (click train) at various frequencies. They measured reaction time (RT) and analyzed the relationship between RT and the length of the memorized list.
The results showed systematic modulations of RT, slope, and intercept of the linear function relating RT to list length, depending on the stimulation frequency. These modulations aligned with the predicted effects of the click trains, demonstrating localized performance changes in the frequency band of stimulation.
Based on these findings, the researchers argue that memory scanning is paced by a temporal oscillator, providing behavioral support for the serial oscillatory model proposed by Lisman and colleagues. This model suggests that memory representations are encoded by groups of neurons firing in the same gamma cycle, allowing for efficient high-speed scanning of information.
Overall, this study contributes to our understanding of the neural mechanisms underlying memory scanning and provides empirical evidence for the role of oscillatory activity in this process.
1 / 1
The structure of short-term memory scanning: an investigation using response time distribution models

Chris Donkin et al. Psychon Bull Rev. 2012 Jun.

Show details

   

Abstract    PubMed    PMID  

Full text linksCite

Abstract

A classic question in cognitive psychology concerns the nature of memory search in short-term recognition. Despite its long history of investigation, however, there is still no consensus on whether memory search takes place serially or in parallel or is based on global access. In the present investigation, we formalize a variety of models designed to account for detailed response time distribution data in the classic Sternberg (Science 153: 652-654, 1966) memory-scanning task. The models vary in their mental architectures (serial exhaustive, parallel self-terminating, and global access). Furthermore, the component processes within the architectures that make match/mismatch decisions are formalized as linear ballistic accumulators (LBAs). In fast presentation rate conditions, the parallel and global access models provide far better accounts of the data than does the serial model. LBA drift rates are found to depend almost solely on the lag between study items and test probes, whereas response thresholds change with memory set size. Under slow presentation rate conditions, even simple versions of the serial-exhaustive model provide accounts of the data that are as good as those of the parallel and global access models. We provide alternative interpretations of the results in our General Discussion.
1 / 1
ChatGPT
ChatGPT
The study by Donkin et al. (2012) investigates the structure of short-term memory scanning in the context of the classic Sternberg memory-scanning task. The aim of the study is to determine whether memory search occurs serially, in parallel, or through global access.
The researchers propose and formalize different models that account for response time distribution data obtained from the memory-scanning task. These models vary in their mental architectures, including serial exhaustive, parallel self-terminating, and global access models. The component processes within these architectures, which involve making match/mismatch decisions, are formalized as linear ballistic accumulators (LBAs).
The study finds that in conditions with fast presentation rates, the parallel and global access models provide better accounts of the data compared to the serial model. The drift rates of the LBAs, which reflect the speed of information accumulation, are primarily influenced by the lag between study items and test probes. On the other hand, response thresholds, representing the amount of evidence required for a decision, vary with memory set size.
Under conditions with slow presentation rates, even simpler versions of the serial-exhaustive model can account for the data as effectively as the parallel and global access models.
The results suggest that the structure of short-term memory scanning depends on the presentation rate of stimuli. Fast presentation rates favor parallel or global access models, while slow presentation rates allow for the viability of serial-exhaustive models.
In the General Discussion section of the paper, the researchers present alternative interpretations of the results and discuss their implications.
Overall, this study contributes to our understanding of the mechanisms underlying memory scanning and provides insights into the nature of memory search processes in short-term recognition tasks.
1 / 1
HYPOTHESIS AND THEORY article
Front. Psychol., 03 December 2018
Sec. Cognitive Science
Volume 9 - 2018 | https://doi.org/10.3389/fpsyg.2018.02421
A Predictive Processing Model of Perception and Action for Self-Other Distinction
Sebastian Kahl* and Stefan Kopp
Social Cognitive Systems Group, CITEC, Bielefeld University, Bielefeld, Germany
During interaction with others, we perceive and produce social actions in close temporal distance or even simultaneously. It has been argued that the motor system is involved in perception and action, playing a fundamental role in the handling of actions produced by oneself and by others. But how does it distinguish in this processing between self and other, thus contributing to self-other distinction? In this paper we propose a hierarchical model of sensorimotor coordination based on principles of perception-action coupling and predictive processing in which self-other distinction arises during action and perception. For this we draw on mechanisms assumed for the integration of cues for a sense of agency, i.e., the sense that an action is self-generated. We report results from simulations of different scenarios, showing that the model is not only able to minimize free energy during perception and action, but also showing that the model can correctly attribute sense of agency to own actions.

1. Introduction
In everyday social interaction we constantly try to deduce and predict the underlying intentions behind others' social actions, like facial expressions, speech, gestures, or body posture. This is no easy problem and the underlying cognitive mechanisms and neural processes even have been dubbed the ���dark matter��� of social neuroscience (Przyrembel et al., 2012). Generally, action recognition is assumed to rest upon principles of prediction-based processing (Clark, 2013), where predictions about expected sensory stimuli are continuously formed and evaluated against incoming sensory input to inform further processing. Such a predictive processing does not only inform our perception of actions of others, but also our action production in which we constantly predict the sensory consequences of our own actions and correct them in case of deviations. Both of these processes are assumed to be supported by the structure of the human sensorimotor system that is characterized by perception-action coupling (Prinz, 1997) and common coding of the underlying representations.

It seems natural to assume that these general mechanisms of prediction-based action processing underly also the perception and generation of social behavior when we interact with others. However, in dynamic social interaction, perception, and action often need to be at work simultaneously and for both, actions of self and other. If the motor system is to be involved in both processes, this simultaneous processing and attribution of actions to oneself and the interaction partner must be maintained during social interaction without confusion.

As of yet, it is not clear how self-other distinction is reflected in, or possibly even constituted by the sensorimotor system. What role does it play in distinguishing social actions of the self and the other? What are the underlying prediction-based processes? And how do they interact with higher-level cognitive processes like mentalizing to solve the social differentiation problem? Evidence from cognitive neuroscience suggests that the motor systems may be involved differentiately in processing self-action and other-action, indicating a role in social cognition (Sch��tz-Bosbach et al., 2006) and the selective attribution of beliefs, desires, and intentions during the dynamic process of intersubjective sense-making. We contribute a computational modeling perspective. In previous work we devised a model of the interplay of mentalizing and prediction-based mirroring during social interaction (Kahl and Kopp, 2015). In that work two virtual agents interacted in a communication game, each of which equipped with models of a mirroring system and a mentalizing system, respectively. This demonstrated how mentalizing���even with minimal abilities to account for beliefs, desires, and intentions���affords interactive grounding and makes communication more robust and efficient. However, both agents took separate and successive turns such that their mirroring systems worked either for perception or production of social actions (albeit with activations being carried on).

In this paper, we present an extended Bayesian model of a sensorimotor system based on a prediction-based processing hierarchy, called Hierarchical Predictive Belief Update (HPBU). Our aim is to explore how such a prediction-based sensorimotor system can be able to differentiate by itself actions of its own (predicted for production) from potential actions of the interaction partner (predicted for perception), thus contributing to self-other distinction in social interaction.

For our computational model of sensorimotor processes and the model of sense of agency we rely on assumptions from the predictive processing framework. Specifically, the model will rely on principles of active inference and free energy minimization (Friston et al., 2010) based on assumptions in accord with the predictive brain hypotheses (Clark, 2013) and hierarchical predictive coding (Rao and Ballard, 1999). From that follows a hierarchical organization of ever more abstract predictive representations. These representations are also generative processes, which together form a hierarchical generative model which maps from (hidden) causes in the world to their perceived (sensory) consequences. The tight coupling between action and perception in active inference means, that following prediction errors, either the model hypotheses have to be updated or action in the world is necessary to make future sensory evidence meet the model predictions. Free energy is merely the term for the negative log model evidence of a perceived event given the model prediction, i.e., the prediction error which is to be minimized. Technically, variational free energy is an upper bound on Bayesian model evidence, such that minimizing free energy corresponds to minimizing (precision-weighted) prediction error���or, equivalently, maximizing model evidence or marginal likelihood.

Also, we will identify, integrate and then test mechanisms and processes in the SoA (sense of agency) literature that are compatible with a predictive processing view and that have reliably been identified to contribute to sense of agency. Our goal here is to present a conceptual computational model of the sense of agency which is functionally embedded in a hierarchical predictive processing model for action production and perception. The model of sense of agency itself integrates different aspects important for sensorimotor processing and motor control. At the core of our argument for the presented modeling approach is the assumption that we strongly rely on the predictability of our own body to be able to not only identify our own hands or arms, but also to differentiate between our own and other's actions through the information gathered especially on the unpredictability of others. It is that unpredictability of their actions and its timing that can help to differentiate. The functional simulation at the end of our paper helps to evaluate whether the identified mechanisms implemented in the model are sufficient to correctly infer own actions, given altered feedback to its action production.

We start with introducing HPBU and how it forms, tests, and corrects so-called motor beliefs. Then we discuss how this model can be extended with a mechanism for differentiating between actions produced by oneself from actions produced by a potential interlocutor in social situations. The mechanism includes the ability to flexibly integrate predictive and postdictive cues to form a sense of agency (SoA). Finally, we present results from simulations that test the model's ability to infer SoA for its own actions in different test scenarios. We then discuss our results with the literature concerning the mechanisms underlying SoA and discuss the mechanism's implications for the process of attributing beliefs during communication.

2. Hierarchical Predictive Belief Update
We adopt a Bayesian approach to computationally model the human sensorimotor system at a functional level. The model, called Hierarchical Predictive Belief Update (HPBU) realizes an active inference and free energy minimization. Doing so it is able to form, test, and correct so-called motor beliefs in perception and production of actions. Based on our previous work (Sadeghipour and Kopp, 2010) and other attempts to model the sensorimotor system (Wolpert et al., 2003), we chose to make use of a hierarchical representation of increasing abstractions over representations of movement. Each level contains a generative model that infers probabilities to perceive (and produce) these variants of abstractions over actions in the form of discrete probability distributions about discrete representations that can be influenced both bottom-up, in the form of evidence for its last prediction from the next lower level, and top-down in the form of a prediction by the next higher level. Following the assumption that the main flow of information is top-down and that motor control is also just top-down sensory prediction or ���active inference," all levels receive their next higher level's prediction and evaluate it for their own bottom-up prediction in the next time step. The distinction to previous models of the sensorimotor system is that in active inference we solely rely on each level's generative process to map from (hidden) causes to their (sensory) consequences. Without separate inverse models the generative process itself is inverted to predict the next steps in the next lower level and thus, explain away or suppress prediction errors. In the lowest level of the hierarchy this suppression can take the form of triggering the production of actions and change the environment as to minimize prediction errors.

The representations in our hierarchy code for both, the perception and production of an action and in that follow the common-coding theory of perception-action coupling (Prinz, 1997), a defining characteristic for representations in the mirror neuron system (Gallese et al., 1996). The human mirror neuron system has indeed also been attributed to have a hierarchical organization, which is distributed across interconnected brain areas (Grafton and Hamilton, 2007) and similarly, predictive coding and active inference have repeatedly been linked to the mechanisms underlying the function of the mirror neuron system (Kilner et al., 2007; Friston et al., 2010).

Also, in the predictive coding and active inference literature the attribution of agency was attributed to rely on mechanisms central also to the model presented in this paper, i.e., the correct prediction of the consequences of producing actions of handwriting (Friston et al., 2011). But other than the mechanisms we will later go into, they rely heavily on the proprioceptive information which is missing when perceiving other's actions in contrast to actions performed by oneself. We will argue that there is sufficient information already available in the visual information only.

HPBU can be described as a three-level hierarchy of motor beliefs as abstractions over primitive motor acts (see Figure 1). At the top, in the Schema level (C) we represent abstract clusters of action sequences grouped by similarity. Below that, the Sequence level (S) represents sequences of motor acts. Levels in our hierarchy are loosely associated with the following (sub-)cortical structures: The Vision level corresponds to early level V5 in the visual cortex for its direction selectivity in the perception of motion, while the Motor Control level corresponds to the reflex arcs embedded in the tight coordination of basal ganglia, spinal cord, and cerebellum. The Sequence and Schema levels are loosely associated with primary motor and premotor areas that code for representing action sequences. We assume these representations to be the basis for active inference for both action perception and production. Further, we assume the representations to be multimodal, i.e., combining visual, motor, and proprioceptive aspects of action, if available. Consequently, they are used as more or less high-level or visuomotor representations of action and their outcomes. This is based on converging evidence for the multimodal nature of representations that can be found in somatosensory, primary motor, and premotor areas of the human brain, which can code for both visual and proprioceptive information (Wise et al., 1997; Graziano et al., 2000; Fogassi and Luppino, 2005; Pipereit et al., 2006; Gentile et al., 2015). The lowest levels in the model hierarchy allow for action production and visual and proprioceptive input and feedback in the form of two separate models; the Vision level (V) and Motor Control level (M) that will be further described below.

Figure 1
www.frontiersin.org
FIGURE 1. Hierarchical Predictive Belief Update, based on predictive processing and perception-action coupling. Predictions are sent top-down and compared with sensory (bottom-up) evidence to drive belief updates within the hierarchy. We have loose associations with the displayed cortical and subcortial structures. The connections shown will be explained in great detail below. At the top, in the Schema level (C) we represent abstract clusters of action sequences grouped by similarity. Below that, the Sequence level (S) represents sequences of motor acts. The lowest levels in the model hierarchy allow for action production, and proprioceptive feedback in Motor Control level (M) and visual input and action feedback in the Vision level (V). Red and blue lines represent bottom-up and top-down information propagation, respectively. The blue dotted line from V represents a visual prediction without any effect on the world, while the blue line from M has a causal effect. The red dotted line from M represents a long range connection, further explained below.

2.1. Motor Coordination
In motor control two problems have to be solved. First, how to learn action sequences in order to reach a goal, i.e., a mapping from an extrinsic coordinate frame (describing the action perception) into an intrinsic frame (describing the muscle movement) and second, how to activate the appropriate muscles to reach a goal, i.e., from an intrinsic frame to an extrinsic frame to produce the desired movement. What makes this problem hard is that there are many possibilities how the intrinsic frame could produce the extrinsic frame.

To solve the problem of action production toward a goal often the planning of an optimal trajectory was assumed using forward models trying to find an optimal sequence of muscle activations leading to the reached goal before the action even starts (Kawato, 1999). Todorov and Jordan (2002) brought up a different solution trying to explain the high variability in the detailed movements that occured even in repeated actions. They proposed a control strategy that allowed for variability in redundant task dimensions during the action production. That is, during action production feedback is used to only correct variability that interferes with reaching the goal. The use of feedback was often discussed in this context, famously the MOSAIC model by Wolpert et al. (2003) proposed how using a comparison of produced action and its sensory feedback could stabilize and guide action. What counts as feedback in this context are the visually perceived positions of the joints controlled by the muscles and the proprioceptive feedback by the muscle spindles surrounding the muscles.

An important distinction on such models of optimal control is highlighted by Friston (2011) in that the forward models in motor control are not the generative models used in perceptual inference and hence should not be conflated. He argues that one could get rid of the forward models for action by replacing the control problem with an inference problem over motor reflex arcs and in that simplifying optimal control to be active inference. In active inference the extrinsic frame can be utilized as action-production tools, to circumvent the need for detailed programming of motor commands.

We follow this argumentation. First, we transform the perceived action into a gaze- or vision-centered oculomotor frame of reference that has been shown to also code the visual targets for reaching and other actions (Russo and Bruce, 1996; Engel et al., 2002; Ambrosini et al., 2012). Using those we are also able to circumvent the need for detailed programming of motor commands. Instead, the oculocentric frame of reference can guide the actions or parts of an action.

The lowest levels of the hierarchy represent two aspects in active inference that are necessary for motor coordination. The Vision level receives continuous coordinates of a writing trajectory at discrete points in time, which is perceived in the form of a discrete probability distribution over a discrete set of writing angles at each point in time. Following the narrative by Zacks et al. (2007) and Gumbsch et al. (2017) on event segmentation using surprise as a separator, we identify surprising deviations of the current writing angle given the writing angles of the past. In the context of free energy minimization, a sudden increase in the amplitude of prediction errors���induced by a surprising event���is reflected by free energy increases in the Vision level. The surprising stroke consists of the writing angle and its length, which are both transformed into the oculocentric reference frame, i.e., into relative polar coordinates with the last surprising stroke coordinates at its center. This information is send to the Sequence level, together with the time passed since the last surprising stroke. The Sequence level stores these sequences of surprising events in the oculocentric reference frame, which can also be used for generation. Following the argument by Friston (2011) we circumvent the need for detailed programming of motor commands by utilizing the surprising events consisting of relative polar coordinates as action targets, which are send to the Motor control level. There, a reflex arc in the form of a damped spring system (inspired by Ijspeert et al., 2013) will realize the motion toward the action target following simple equations of motion with the spring's point of equilibrium at the relative polar coordinate of the action target. This implementation of active inference is formally related to the equilibrium point hypothesis (Feldman and Levin, 1995). In other words, the top-down or descending predictions of the proprioceptive consequences of movement are regarded as setting and equilibrium or set point to which the motor plant converges, via the engagement of motor reflexes. This will later be explained in more detail.

An important aspect in motor coordination model can be seen in Figure 1, where the Motor Control level has no direct feedback connection to the Sequence level. This is for three reasons. First, we would like to see if sequential motor coordination as well as the inference of a sense of agency are possible with visual feedback only. Second, other than Friston et al. (2011) who rely heavily on proprioceptive information we want to allow for visual input to drive motor coordination and a sense of agency. Instead, we close the motor coordination loop using a direct long range connection that is used by the Motor Control level to inform the Vision level when it is done coordinating actions to reach a subgoal (see red dotted line in Figure 1). Vision level will then check if visual information can confirm the movement, then sending the information to the Sequence level, closing the motor coordination loop. Third, making the model's sequence coordination independent from direct proprioceptive feedback allows for future developments that can associate actions in the world with intended effects that not directly influence the motor system, e.g., switching on a light or influencing another agent's beliefs.

During action perception, we further assume that the correspondence problem is solved in the sense that an observed action by another agent is mapped into one's own body-centered frame of reference. That is, we feed the perceived action trajectory directly and bottom-up into HPBU. The next section will describe the active inference and free energy minimization in the model hierarchy.

3. Model Update Details
The HPBU model is defined as a hierarchical generative model which learns to predict and explain away prediction errors and in this sense minimize the free energy. This section will briefly introduce our free energy minimization strategy and the generative model updates, which we have implemented and extended to encompass and allow the distinction of self and other in the context of action production.

In the hierarchical generative model, each level maps the internal discrete state space from one level in the hierarchy to the domain of its next lower level. Each level contains a discrete probability distribution about that level's discrete states. The difference between continuous and discrete states in the context of active inference is well discussed in Friston et al. (2017a). All levels of the hierarchy are updated sequentially starting at the top in Schema level C, i.e., they are updated in sequence from its next higher and next lower levels, learning to represent and produce the states in the next lower level and the environment. At the top, the Schema level C represents clusters of similar representations of its next lower level, which is the Sequence level S. S represents sequences of representations of Vision level V that occured over time. Also, representations that can map to V are compatible with representations in Motor Control level M. In each level posteriors are updated bottom-up and top-down and free energy is calculated with respect to prior and posterior distributions as described in the following. These mappings can be understood as generative processes, where one level predicts the states of the level below. In the Motor Control level M this mapping results in action production.

3.1. Free Energy Minimization
Free energy describes the negative log model evidence of a generative model that tries to explain hidden states, i.e., the environment. Evidence corresponds to probabilities of data from the environment, given the model at hand.

The free energy in system X is expressed as the sum of surprise and a cross entropy of two states (a posterior P, and a prior Q before evidence has arrived). When free energy is minimized the cross entropy becomes zero, thus leaving free energy to be just surprise (entropy with regard to the posterior) (Equation 1).

F(X)=H(P(X))+DKL(P(X)||Q(X))             =������iP(Xi) lnP(Xi)+���iP(Xi) ��� lnP(Xi)Q(Xi)    (1)
In our interpretation the difference between perception and production lies in the question which signal drives the updates in calculating free energy, the bottom-up signal or the top-down signal? When it comes to calculating free energy in perception the posterior distribution (for calculating surprise and the cross-entropy) is the top-down signal Ptd and the prior, i.e., the driving signal is the bottom-up signal Pbu, so that F = H(Ptd) + DKL(Ptd||Pbu). In production the top-down signal Ptd becomes the driving signal for the free energy update F = H(Pbu) + DKL(Pbu||Ptd). The deviation is then calculated with respect to Pbu (see the yellow box in Figure 2). To update level beliefs, both posteriors will be combined to form the current level posterior Pt, in which the bottom-up signal will be combined similarly as in the identified microcircuitry for predictive coding (Bastos et al., 2012). There, connections between cortical columns are mostly inhibitory. In this setting, the bottom-up and top-down posteriors in Equation (1) play the role of predictions. This means that we can treat the differences in the bottom-up and top-down predictions as a prediction error and enter them into a Kalman filter. In this formulation, the Kalman gain is used to differentially weight bottom-up and top-down predictions and plays the role of a precision. Crucially, this precision is a function of the free energy computed at each level in the hierarchical model���such that a very high free energy (i.e., prediction error) emphasizes top-down predictions. We model this effect during perception as a top-down inhibitory influence on the bottom-up signal using a Kalman filter Pt = Pbu + Kt(Ptd ��� Pbu) with a Kalman gain Kt=FF+�� calculated from the level free energy F and precision �� to integrate this filter into the model context (see below in Equation 5 for a more detailed description). Again, the current driving signal can invert the belief update so that during production Pt = Ptd + Kt(Pbu ��� Ptd). The level posterior Pt will be send to the next higher level in the hierarchy and to the next lower level. In the following time step the level posterior will be used as an empirical prior for calculating Pbu and Ptd respectively. Figure 2 examplifies our belief update scheme in Sequence level S. There posteriors and relevant likelihoods are combined to calculate updated top-down and bottom-up posteriors necessary to calculate the free energy within level S and the final belief update step which combines top-down and bottom-up posteriors. For more details on our generative model hierarchy please refer to the Supplementary Materials.

Figure 2
www.frontiersin.org
FIGURE 2. To exemplify the belief update scheme in HPBU, here the updating of posteriors and free energy within Sequence level S are shown. Within S the top-down and bottom-up posteriors are calculated from posteriors of C and V. That information is used to update free energy either for production (prod) or for perception (perc). The updated free energy and precision (��) are used to calculate the Kalman gain necessary for calculating the level posterior P(S) using a Kalman filter, again either for production or perception. The green boxes show the calculated likelihoods necessary for updating within S or in the levels above and below (Pbu(C|S) is one example). For more details please refer to the Supplementary Materials.

Following the assumption in active inference that overt action is basically action-oriented predictive processing (Friston et al., 2010), we allow strongly predicted next actions of representations in the Sequence level to be acted out. Without any constraints this leads to overt automatic enactment, similar to the automatic imitation seen in patients suffering from echopraxia (Ganos et al., 2012). To control this motor execution, we introduced a gating signal into the top-level of the hierarchy, which acts as a motor intention for a specific schema, including a strong boost of this schema's probability (acting as a trigger to act-out an abstract motor belief). This intention percolates down the hierarchy to boost associated representations and inform the intention to act. Once it reaches the lowest level of the hierarchy, the act to produce the motor representation will be allowed.
1 / 1
ChatGPT
ChatGPT
The article "A Predictive Processing Model of Perception and Action for Self-Other Distinction" by Sebastian Kahl and Stefan Kopp presents a hierarchical model of sensorimotor coordination based on principles of perception-action coupling and predictive processing. The model aims to explain how the motor system distinguishes between self and other actions during social interaction.
The authors draw on the concept of predictive processing, where predictions about expected sensory stimuli are continuously formed and evaluated against incoming sensory input. They propose that this predictive processing framework, combined with perception-action coupling, can support the differentiation between self and other actions in social interaction.
The model incorporates mechanisms for the integration of cues related to a sense of agency, which is the sense of being the agent of one's own actions. Through simulations of different scenarios, the authors demonstrate that the model can minimize free energy during perception and action, and correctly attribute a sense of agency to one's own actions.
The Hierarchical Predictive Belief Update (HPBU) model is introduced as a computational framework for sensorimotor processes. It consists of a hierarchy of motor beliefs, representing abstract clusters of action sequences (Schema level), sequences of motor acts (Sequence level), and sensory representations (Vision level) that can be influenced by both perception and production of actions.
The model employs active inference and free energy minimization, following the principles of predictive processing and hierarchical predictive coding. It uses top-down and bottom-up signals to update beliefs at each level of the hierarchy and minimize prediction errors. The authors argue that this hierarchical generative model can effectively differentiate between self and other actions in social interaction.
The article discusses the role of motor coordination and the control of action production in the model. It also highlights the multimodal nature of representations involved in perception and production, combining visual, motor, and proprioceptive aspects of action. The authors propose that the model can leverage the predictability of one's own body and the unpredictability of others' actions to differentiate between self and other.
The authors present simulations that test the model's ability to infer a sense of agency for one's own actions in different scenarios. They discuss the implications of their results in relation to the mechanisms underlying the sense of agency and the attribution of beliefs during communication.
Overall, this article contributes to the understanding of how the sensorimotor system distinguishes between self and other actions in social interaction. The predictive processing model provides insights into the cognitive mechanisms involved in perception and action and their role in self-other distinction.
1 / 1
3.2. Motor Coordination Loop
In active inference and the actual production of an action, predictions guide the minimization of free energy, the Motor level receives position (xi) and timing (��t) goals from Sequence level S. The realization of the movement goal within the Motor Control level is left to an action-proprioception loop modeled as a dampened spring system. This models the angular movements of a single joint, which in our simulations will represent a writing pencil. A similar approach was used by Friston et al. (2011) but instead of a system with two joints following one attractor-state at a time in attractor space we model just one joint which moves toward the spring system's point of equilibrium at the relative polar coordinate of the action goal. To allow for smooth and curving trajectories that are similar to handwriting in spatial and temporal properties, we were inspired by work on dynamic movement primitives (DMP) that are used for modeling attractor behaviors of autonomous non-linear dynamical systems with the help of statistical learning techniques (Ijspeert et al., 2013). We will not make use of the DMPs ability to learn and reproduce trajectories, but will configure a dampened spring system similarly to a DMP and instead of applying a forcing term that activates the system's non-linear dynamics over time we make use of an obstacle avoidance technique mentioned in Hoffmann et al. (2009) which we adpoted and inverted its force to actually move toward the goal in a forcing function g (see Equation 2). The reason for this is that when we simply applied the spring system to each goal sequentially, we would accelerate toward and slow down at the goal. To keep up the momentum we need to look ahead several goals xi+3 (here 3 steps ahead) in the core spring system, but with a goal forcing function that sequentially tries to visit each goal xi. �� = 25, �� = 6.25, �� = 10, and ��=1�� are constants that specify the behavior of the system. �� is the angle to the goal (or its velocity, see Equation 3) and y is the current position.

��=��xi�����y������=�� �� e�����|��|    (2)
g=(xi���y) ����y��=��(��(xi+3���y)���y��)+g    (3)
With this hierarchical model in place, we set out to investigate how a sensorimotor system can distinguish activations that stem from own actions from those arising due to the observation of an interaction partner's actions. In particular we are interested in how self-other distinction is realized within the system itself based on its prediction-based processing. This ability would be a prerequisite for the assumed dual use of the sensorimotor system (in perception and action) in dynamic social interaction. Note that, at a higher cognitive level, self-other distinction will have additional components based on sensory modalities like vision (e.g., seeing who the agent of an action is) or proprioception, as well as awareness of control of own actions (e.g., feeling or knowing that one is executing an action). Here we are interested in how a more fundamental sensorimotor basis for self-other distinction can contribute in correctly attributing a perceived sensory event to self-action or other-action���a process that would be likely to underlie many of the these additional higher-level components. To that end, we extended HPBU to include a sensorimotor account of sense of agency (SoA), i.e., the sense that an action is self-generated.

4. Self-Other Distinction and Sense of Agency
How does the human brain distinguish between information about ourselves and others? Or to be more specific, how can we distinguish ourselves from others so that we do not falsely attribute an action outcome to ourselves? These questions are related to the general mechanisms that give rise to a sense of ���feeling of control,��� agency, and ���self.���

Reviews on the neural mechanisms of the SoA and the social brain (David et al., 2008; Van Overwalle, 2009) show a strong overlap of differential activity during SoA judgement tasks with functional brain areas of the human mirror-neuron system and the mentalizing network. Especially noteworthy is TPJ (temporo-parietal junction) as a candidate to infer the agency of a social action, spanning areas STS (superior temporal sulcus) which mainly responds to biological motion, to IPL (inferior parietal lobule) which may respond to the intentions behind someone's actions, connecting to mPFC (medial prefrontal cortex) which probably hold trait inferences or maintains different representations of self- or other-related intentions or beliefs (please see the mentioned reviews for a more thorough analysis). Generally, a person's SoA is believed to be influenced through predictive and postdictive (inferential) processes, which when disturbed can lead to misattributions of actions as in disorders such as schizophrenia (van der Weiden et al., 2015). In Schizophrenia as a deficit of sensory attenuation, but also hallucinations, we can point to disfunctional precision encodings as a core pathology, i.e., the confidence of beliefs about the world (Adams et al., 2013). Precision as such is believed to be encoded in dopaminergic neuromodulation and can as such be linked to the sensory attenuation effects during the attribution of agency in healthy subjects (Brown et al., 2013). We aim to identify mechanisms in order to model these processes and their integration into a combined SoA.

4.1. Predictive Process in Sense of Agency
The predictive process makes use of people's ability to anticipate the sensory consequences of their own actions. It allows to attenuate, i.e., decrease the intensity of incoming signals which enables people to distinguish between self-caused actions and their outcomes and those actions and outcomes caused by others. One account to model these processes is based on inverse and forward models to account for disorders of awareness in the motor system and delusion of control (Frith et al., 2000). This view suggests that patients suffering from such disorders of awareness can no longer link their intentions to their actions, that is they can become aware of the sensory consequences of an action, but may have problems to integrate them to the intention underlying the action, making it hard to ascribe actions to oneself or another agent. Research on schizophrenia has shown that reliable and early self-other integration and distinction is important not only for the correct attribution of SoA, but also for the correct attribution of intentions and emotions to others in social interaction (van der Weiden et al., 2015). Weiss et al. (2011) also showed that there is a social aspect to predictive processes that influence SoA by comparing perceived loudness of auditory action effects in an interactive action context. They found that attenuation occured also in the interactive context, comparable to the attentuation of self-generated sound in an individual context.

Another aspect of the processing of differences between predictions and feedback from reality is the intrinsic robustness and invariance to unimportant aspects in the sensory input. The kinds of predictive processing hierarchies we talk about, that concern themselves with allowing ourselves to act in (and perceive) the ever-varying nature of our environments, are able to ignore or explain away the prediction-errors that aren't surprising enough to lead to any form of adaptation. That this is also likely true for temporal prediction-errors was found in Sherwell et al. (2016), who using EEG saw significant N1 component suppression in predicted stimulus onset timings. In a predictive processing perspective this is possible through higher levels in the hierarchy correctly predicting the next lower level's state, and by taking into account its generative model's precision, minimize its prediction-error. Or as Clark states: ���[���] variable precision-weighting of sensory prediction error enables the system to attend to current sensory input to a greater or lesser degree, flexibly balancing reliance upon (or confidence in) the input with reliance upon (or confidence in) its own higher level predictions��� (Clark, 2016, p. 216). Consistent with this perspective is work by Rohde and Ernst (2016), who investigated if and in which cases we can compensate for sensorimotor delay, i.e., the time between an action and its sensory consequence. They find that if an error signal (a discrepancy between an expected and an actual sensory delay) occurs we recalibrate our expectations only if the error occurs systematically. This kind of temporal adaptation is a well studied finding (e.g., Haering and Kiesel, 2015 for sense of agency or Cunningham et al., 2001 in motor control). What interests us for the here presented model of self-other distinction are the unexpected, unsystematic and sudden deviations that cannot be explained away easily. These are the temporal aspects of sensorimotor processing that we will focus on next.
1 / 1
ChatGPT
ChatGPT
In their study, Kahl and Kopp (2018) propose a hierarchical model of sensorimotor coordination based on principles of perception-action coupling and predictive processing to explain self-other distinction in action perception and production. The authors aim to investigate how the motor system distinguishes between actions produced by oneself and those produced by an interaction partner during social interaction.
The authors adopt a Bayesian approach and develop a computational model called Hierarchical Predictive Belief Update (HPBU) to simulate sensorimotor processes. The model is based on the predictive processing framework and active inference, which involves continuously forming and evaluating predictions about expected sensory stimuli. The HPBU model consists of three levels: Schema level (C), Sequence level (S), and Motor Control level (M). Each level represents different abstractions of motor acts and is associated with specific brain areas.
The motor coordination loop in the HPBU model involves the realization of movement goals within the Motor Control level. The authors use a dampened spring system inspired by dynamic movement primitives (DMP) to model the angular movements of a single joint, representing a writing pencil. The system receives position and timing goals from the Sequence level and produces the desired movement by minimizing free energy through action-proprioception loops.
To explore self-other distinction and the sense of agency (SoA), the authors extend the HPBU model. They highlight the importance of predictive processes in distinguishing between self-caused actions and actions caused by others. The ability to anticipate the sensory consequences of one's own actions enables individuals to attenuate incoming signals and differentiate between self-generated and externally generated actions.
The authors discuss the neural mechanisms of SoA, including the involvement of brain areas such as the temporo-parietal junction (TPJ), superior temporal sulcus (STS), inferior parietal lobule (IPL), and medial prefrontal cortex (mPFC). They emphasize the role of predictive and postdictive processes in SoA and how disruptions in these processes can lead to misattributions of actions, as seen in disorders such as schizophrenia.
Furthermore, the authors highlight the intrinsic robustness of predictive processing hierarchies, allowing the system to ignore or explain away prediction errors that are not surprising enough to lead to adaptation. They discuss the compensation for sensorimotor delay and the recalibration of expectations when error signals occur systematically.
In summary, the study by Kahl and Kopp (2018) presents a computational model that integrates principles of perception-action coupling, predictive processing, and active inference to explore self-other distinction and the sense of agency in social interaction. The model provides insights into how the motor system contributes to self-other distinction and the mechanisms underlying the perception and production of social actions.
1 / 1
The HPBU model is defined as a hierarchical generative model which learns to predict and explain away prediction errors and in this sense minimize the free energy. This section will briefly introduce our free energy minimization strategy and the generative model updates, which we have implemented and extended to encompass and allow the distinction of self and other in the context of action production.

In the hierarchical generative model, each level maps the internal discrete state space from one level in the hierarchy to the domain of its next lower level. Each level contains a discrete probability distribution about that level's discrete states. The difference between continuous and discrete states in the context of active inference is well discussed in Friston et al. (2017a). All levels of the hierarchy are updated sequentially starting at the top in Schema level C, i.e., they are updated in sequence from its next higher and next lower levels, learning to represent and produce the states in the next lower level and the environment. At the top, the Schema level C represents clusters of similar representations of its next lower level, which is the Sequence level S. S represents sequences of representations of Vision level V that occured over time. Also, representations that can map to V are compatible with representations in Motor Control level M. In each level posteriors are updated bottom-up and top-down and free energy is calculated with respect to prior and posterior distributions as described in the following. These mappings can be understood as generative processes, where one level predicts the states of the level below. In the Motor Control level M this mapping results in action production.

3.1. Free Energy Minimization
Free energy describes the negative log model evidence of a generative model that tries to explain hidden states, i.e., the environment. Evidence corresponds to probabilities of data from the environment, given the model at hand.

The free energy in system X is expressed as the sum of surprise and a cross entropy of two states (a posterior P, and a prior Q before evidence has arrived). When free energy is minimized the cross entropy becomes zero, thus leaving free energy to be just surprise (entropy with regard to the posterio r.)
1 / 1
ChatGPT
ChatGPT
In the HPBU model, the goal is to minimize free energy, which is a measure of how well the generative model explains the hidden states of the environment. Free energy consists of two components: surprise and cross entropy. Surprise represents the discrepancy between the predicted and observed states, while cross entropy quantifies the difference between the posterior distribution (after incorporating new evidence) and the prior distribution (before incorporating evidence).
The process of minimizing free energy involves updating the posterior distributions at each level of the hierarchy. The updates are performed sequentially, starting from the top-level Schema level (C) and progressing to the lower levels, such as the Sequence level (S) and the Motor Control level (M). Each level's posterior is updated using bottom-up and top-down connections, allowing information to flow from higher to lower levels and vice versa.
By minimizing free energy, the model learns to better represent and predict the states in the lower levels and the environment. In the Motor Control level (M), this process leads to the production of actions based on the predictions and goals provided by the higher levels.
The concept of free energy minimization is central to the HPBU model, as it captures the model's goal of generating accurate predictions and explanations of sensory data and maintaining consistency between different levels of the hierarchy. By minimizing free energy, the model can refine its representations and improve its ability to distinguish self-generated actions from externally generated actions.
1 / 1
In our interpretation the difference between perception and production lies in the question which signal drives the updates in calculating free energy, the bottom-up signal or the top-down signal? When it comes to calculating free energy in perception the posterior distribution (for calculating surprise and the cross-entropy) is the top-down signal Ptd and the prior, i.e., the driving signal is the bottom-up signal Pbu, so that F = H(Ptd) + DKL(Ptd||Pbu). In production the top-down signal Ptd becomes the driving signal for the free energy update F = H(Pbu) + DKL(Pbu||Ptd). The deviation is then calculated with respect to Pbu (see the yellow box in Figure 2). To update level beliefs, both posteriors will be combined to form the current level posterior Pt, in which the bottom-up signal will be combined similarly as in the identified microcircuitry for predictive coding (Bastos et al., 2012). There, connections between cortical columns are mostly inhibitory. In this setting, the bottom-up and top-down posteriors in Equation (1) play the role of predictions. This means that we can treat the differences in the bottom-up and top-down predictions as a prediction error and enter them into a Kalman filter. In this formulation, the Kalman gain is used to differentially weight bottom-up and top-down predictions and plays the role of a precision. Crucially, this precision is a function of the free energy computed at each level in the hierarchical model���such that a very high free energy (i.e., prediction error) emphasizes top-down predictions. We model this effect during perception as a top-down inhibitory influence on the bottom-up signal using a Kalman filter Pt = Pbu + Kt(Ptd ��� Pbu) with a Kalman gain Kt=FF+�� calculated from the level free energy F and precision �� to integrate this filter into the model context (see below in Equation 5 for a more detailed description). Again, the current driving signal can invert the belief update so that during production Pt = Ptd + Kt(Pbu ��� Ptd). The level posterior Pt will be send to the next higher level in the hierarchy and to the next lower level. In the following time step the level posterior will be used as an empirical prior for calculating Pbu and Ptd respectively. Figure 2 examplifies our belief update scheme in Sequence level S. There posteriors and relevant likelihoods are combined to calculate updated top-down and bottom-up posteriors necessary to calculate the free energy within level S and the final belief update step which combines top-down and bottom-up posteriors
1 / 1
ChatGPT
ChatGPT
In the HPBU model, the distinction between perception and production lies in the direction of the signal that drives the updates for calculating free energy. In perception, the driving signal is the bottom-up signal (Pbu), while in production, the driving signal is the top-down signal (Ptd).
During perception, the posterior distribution (Ptd) is the top-down signal used to calculate surprise and cross entropy for free energy. The prior distribution (Pbu) serves as the bottom-up signal. The free energy is calculated as F = H(Ptd) + DKL(Ptd||Pbu), where H represents entropy and DKL represents the Kullback-Leibler divergence.
In contrast, during production, the roles of the top-down and bottom-up signals are reversed. The top-down signal (Ptd) becomes the driving signal for free energy updates, and the bottom-up signal (Pbu) becomes the prior. The free energy is calculated as F = H(Pbu) + DKL(Pbu||Ptd), with the deviation being calculated with respect to the bottom-up signal.
To update the beliefs at each level, the bottom-up and top-down posteriors are combined to form the current level posterior (Pt). This combination follows a similar process as in the predictive coding framework, where connections between cortical columns are predominantly inhibitory. The difference between the bottom-up and top-down predictions is treated as a prediction error and entered into a Kalman filter. The Kalman gain (Kt) is used to weight the bottom-up and top-down predictions based on the precision, which is a function of the free energy computed at each level. A high free energy (i.e., prediction error) emphasizes top-down predictions.
During perception, the Kalman filter is used to apply a top-down inhibitory influence on the bottom-up signal, leading to the update equation Pt = Pbu + Kt(Ptd - Pbu). During production, the equation is inverted, and the update equation becomes Pt = Ptd + Kt(Pbu - Ptd). The resulting level posterior (Pt) is then sent to the next higher level in the hierarchy and the next lower level for further processing.
In each subsequent time step, the level posterior is used as an empirical prior for calculating the bottom-up and top-down signals (Pbu and Ptd) respectively, and the belief update process continues.
Figure 2 illustrates the belief update scheme in the Sequence level (S) of the hierarchy, showing how the posteriors and relevant likelihoods are combined to calculate updated top-down and bottom-up posteriors. This process is necessary to compute the free energy within level S and perform the final belief update step, which combines the top-down and bottom-up posteriors.
Overall, this belief update scheme allows the model to integrate bottom-up and top-down signals, capture prediction errors, and refine its representations and predictions at each level of the hierarchical generative model.
1 / 1
Frontiers in Psychology
Sections 
Articles
Research Topics
Editorial Board
About journal 
About us 
All journals
All articles
Submit your research

10,837
Total views
1,497
Downloads
View article impact
Article has an altmetric score of 11
HYPOTHESIS AND THEORY article
Front. Psychol., 03 December 2018
Sec. Cognitive Science
Volume 9 - 2018 | https://doi.org/10.3389/fpsyg.2018.02421
A Predictive Processing Model of Perception and Action for Self-Other Distinction
Sebastian Kahl* and Stefan Kopp
Social Cognitive Systems Group, CITEC, Bielefeld University, Bielefeld, Germany
During interaction with others, we perceive and produce social actions in close temporal distance or even simultaneously. It has been argued that the motor system is involved in perception and action, playing a fundamental role in the handling of actions produced by oneself and by others. But how does it distinguish in this processing between self and other, thus contributing to self-other distinction? In this paper we propose a hierarchical model of sensorimotor coordination based on principles of perception-action coupling and predictive processing in which self-other distinction arises during action and perception. For this we draw on mechanisms assumed for the integration of cues for a sense of agency, i.e., the sense that an action is self-generated. We report results from simulations of different scenarios, showing that the model is not only able to minimize free energy during perception and action, but also showing that the model can correctly attribute sense of agency to own actions.

1. Introduction
In everyday social interaction we constantly try to deduce and predict the underlying intentions behind others' social actions, like facial expressions, speech, gestures, or body posture. This is no easy problem and the underlying cognitive mechanisms and neural processes even have been dubbed the ���dark matter��� of social neuroscience (Przyrembel et al., 2012). Generally, action recognition is assumed to rest upon principles of prediction-based processing (Clark, 2013), where predictions about expected sensory stimuli are continuously formed and evaluated against incoming sensory input to inform further processing. Such a predictive processing does not only inform our perception of actions of others, but also our action production in which we constantly predict the sensory consequences of our own actions and correct them in case of deviations. Both of these processes are assumed to be supported by the structure of the human sensorimotor system that is characterized by perception-action coupling (Prinz, 1997) and common coding of the underlying representations.

It seems natural to assume that these general mechanisms of prediction-based action processing underly also the perception and generation of social behavior when we interact with others. However, in dynamic social interaction, perception, and action often need to be at work simultaneously and for both, actions of self and other. If the motor system is to be involved in both processes, this simultaneous processing and attribution of actions to oneself and the interaction partner must be maintained during social interaction without confusion.

As of yet, it is not clear how self-other distinction is reflected in, or possibly even constituted by the sensorimotor system. What role does it play in distinguishing social actions of the self and the other? What are the underlying prediction-based processes? And how do they interact with higher-level cognitive processes like mentalizing to solve the social differentiation problem? Evidence from cognitive neuroscience suggests that the motor systems may be involved differentiately in processing self-action and other-action, indicating a role in social cognition (Sch��tz-Bosbach et al., 2006) and the selective attribution of beliefs, desires, and intentions during the dynamic process of intersubjective sense-making. We contribute a computational modeling perspective. In previous work we devised a model of the interplay of mentalizing and prediction-based mirroring during social interaction (Kahl and Kopp, 2015). In that work two virtual agents interacted in a communication game, each of which equipped with models of a mirroring system and a mentalizing system, respectively. This demonstrated how mentalizing���even with minimal abilities to account for beliefs, desires, and intentions���affords interactive grounding and makes communication more robust and efficient. However, both agents took separate and successive turns such that their mirroring systems worked either for perception or production of social actions (albeit with activations being carried on).

In this paper, we present an extended Bayesian model of a sensorimotor system based on a prediction-based processing hierarchy, called Hierarchical Predictive Belief Update (HPBU). Our aim is to explore how such a prediction-based sensorimotor system can be able to differentiate by itself actions of its own (predicted for production) from potential actions of the interaction partner (predicted for perception), thus contributing to self-other distinction in social interaction.

For our computational model of sensorimotor processes and the model of sense of agency we rely on assumptions from the predictive processing framework. Specifically, the model will rely on principles of active inference and free energy minimization (Friston et al., 2010) based on assumptions in accord with the predictive brain hypotheses (Clark, 2013) and hierarchical predictive coding (Rao and Ballard, 1999). From that follows a hierarchical organization of ever more abstract predictive representations. These representations are also generative processes, which together form a hierarchical generative model which maps from (hidden) causes in the world to their perceived (sensory) consequences. The tight coupling between action and perception in active inference means, that following prediction errors, either the model hypotheses have to be updated or action in the world is necessary to make future sensory evidence meet the model predictions. Free energy is merely the term for the negative log model evidence of a perceived event given the model prediction, i.e., the prediction error which is to be minimized. Technically, variational free energy is an upper bound on Bayesian model evidence, such that minimizing free energy corresponds to minimizing (precision-weighted) prediction error���or, equivalently, maximizing model evidence or marginal likelihood.

Also, we will identify, integrate and then test mechanisms and processes in the SoA (sense of agency) literature that are compatible with a predictive processing view and that have reliably been identified to contribute to sense of agency. Our goal here is to present a conceptual computational model of the sense of agency which is functionally embedded in a hierarchical predictive processing model for action production and perception. The model of sense of agency itself integrates different aspects important for sensorimotor processing and motor control. At the core of our argument for the presented modeling approach is the assumption that we strongly rely on the predictability of our own body to be able to not only identify our own hands or arms, but also to differentiate between our own and other's actions through the information gathered especially on the unpredictability of others. It is that unpredictability of their actions and its timing that can help to differentiate. The functional simulation at the end of our paper helps to evaluate whether the identified mechanisms implemented in the model are sufficient to correctly infer own actions, given altered feedback to its action production.

We start with introducing HPBU and how it forms, tests, and corrects so-called motor beliefs. Then we discuss how this model can be extended with a mechanism for differentiating between actions produced by oneself from actions produced by a potential interlocutor in social situations. The mechanism includes the ability to flexibly integrate predictive and postdictive cues to form a sense of agency (SoA). Finally, we present results from simulations that test the model's ability to infer SoA for its own actions in different test scenarios. We then discuss our results with the literature concerning the mechanisms underlying SoA and discuss the mechanism's implications for the process of attributing beliefs during communication.

2. Hierarchical Predictive Belief Update
We adopt a Bayesian approach to computationally model the human sensorimotor system at a functional level. The model, called Hierarchical Predictive Belief Update (HPBU) realizes an active inference and free energy minimization. Doing so it is able to form, test, and correct so-called motor beliefs in perception and production of actions. Based on our previous work (Sadeghipour and Kopp, 2010) and other attempts to model the sensorimotor system (Wolpert et al., 2003), we chose to make use of a hierarchical representation of increasing abstractions over representations of movement. Each level contains a generative model that infers probabilities to perceive (and produce) these variants of abstractions over actions in the form of discrete probability distributions about discrete representations that can be influenced both bottom-up, in the form of evidence for its last prediction from the next lower level, and top-down in the form of a prediction by the next higher level. Following the assumption that the main flow of information is top-down and that motor control is also just top-down sensory prediction or ���active inference," all levels receive their next higher level's prediction and evaluate it for their own bottom-up prediction in the next time step. The distinction to previous models of the sensorimotor system is that in active inference we solely rely on each level's generative process to map from (hidden) causes to their (sensory) consequences. Without separate inverse models the generative process itself is inverted to predict the next steps in the next lower level and thus, explain away or suppress prediction errors. In the lowest level of the hierarchy this suppression can take the form of triggering the production of actions and change the environment as to minimize prediction errors.

The representations in our hierarchy code for both, the perception and production of an action and in that follow the common-coding theory of perception-action coupling (Prinz, 1997), a defining characteristic for representations in the mirror neuron system (Gallese et al., 1996). The human mirror neuron system has indeed also been attributed to have a hierarchical organization, which is distributed across interconnected brain areas (Grafton and Hamilton, 2007) and similarly, predictive coding and active inference have repeatedly been linked to the mechanisms underlying the function of the mirror neuron system (Kilner et al., 2007; Friston et al., 2010).

Also, in the predictive coding and active inference literature the attribution of agency was attributed to rely on mechanisms central also to the model presented in this paper, i.e., the correct prediction of the consequences of producing actions of handwriting (Friston et al., 2011). But other than the mechanisms we will later go into, they rely heavily on the proprioceptive information which is missing when perceiving other's actions in contrast to actions performed by oneself. We will argue that there is sufficient information already available in the visual information only.

HPBU can be described as a three-level hierarchy of motor beliefs as abstractions over primitive motor acts (see Figure 1). At the top, in the Schema level (C) we represent abstract clusters of action sequences grouped by similarity. Below that, the Sequence level (S) represents sequences of motor acts. Levels in our hierarchy are loosely associated with the following (sub-)cortical structures: The Vision level corresponds to early level V5 in the visual cortex for its direction selectivity in the perception of motion, while the Motor Control level corresponds to the reflex arcs embedded in the tight coordination of basal ganglia, spinal cord, and cerebellum. The Sequence and Schema levels are loosely associated with primary motor and premotor areas that code for representing action sequences. We assume these representations to be the basis for active inference for both action perception and production. Further, we assume the representations to be multimodal, i.e., combining visual, motor, and proprioceptive aspects of action, if available. Consequently, they are used as more or less high-level or visuomotor representations of action and their outcomes. This is based on converging evidence for the multimodal nature of representations that can be found in somatosensory, primary motor, and premotor areas of the human brain, which can code for both visual and proprioceptive information (Wise et al., 1997; Graziano et al., 2000; Fogassi and Luppino, 2005; Pipereit et al., 2006; Gentile et al., 2015). The lowest levels in the model hierarchy allow for action production and visual and proprioceptive input and feedback in the form of two separate models; the Vision level (V) and Motor Control level (M) that will be further described below.

Figure 1
www.frontiersin.org
FIGURE 1. Hierarchical Predictive Belief Update, based on predictive processing and perception-action coupling. Predictions are sent top-down and compared with sensory (bottom-up) evidence to drive belief updates within the hierarchy. We have loose associations with the displayed cortical and subcortial structures. The connections shown will be explained in great detail below. At the top, in the Schema level (C) we represent abstract clusters of action sequences grouped by similarity. Below that, the Sequence level (S) represents sequences of motor acts. The lowest levels in the model hierarchy allow for action production, and proprioceptive feedback in Motor Control level (M) and visual input and action feedback in the Vision level (V). Red and blue lines represent bottom-up and top-down information propagation, respectively. The blue dotted line from V represents a visual prediction without any effect on the world, while the blue line from M has a causal effect. The red dotted line from M represents a long range connection, further explained below.

2.1. Motor Coordination
In motor control two problems have to be solved. First, how to learn action sequences in order to reach a goal, i.e., a mapping from an extrinsic coordinate frame (describing the action perception) into an intrinsic frame (describing the muscle movement) and second, how to activate the appropriate muscles to reach a goal, i.e., from an intrinsic frame to an extrinsic frame to produce the desired movement. What makes this problem hard is that there are many possibilities how the intrinsic frame could produce the extrinsic frame.

To solve the problem of action production toward a goal often the planning of an optimal trajectory was assumed using forward models trying to find an optimal sequence of muscle activations leading to the reached goal before the action even starts (Kawato, 1999). Todorov and Jordan (2002) brought up a different solution trying to explain the high variability in the detailed movements that occured even in repeated actions. They proposed a control strategy that allowed for variability in redundant task dimensions during the action production. That is, during action production feedback is used to only correct variability that interferes with reaching the goal. The use of feedback was often discussed in this context, famously the MOSAIC model by Wolpert et al. (2003) proposed how using a comparison of produced action and its sensory feedback could stabilize and guide action. What counts as feedback in this context are the visually perceived positions of the joints controlled by the muscles and the proprioceptive feedback by the muscle spindles surrounding the muscles.

An important distinction on such models of optimal control is highlighted by Friston (2011) in that the forward models in motor control are not the generative models used in perceptual inference and hence should not be conflated. He argues that one could get rid of the forward models for action by replacing the control problem with an inference problem over motor reflex arcs and in that simplifying optimal control to be active inference. In active inference the extrinsic frame can be utilized as action-production tools, to circumvent the need for detailed programming of motor commands.

We follow this argumentation. First, we transform the perceived action into a gaze- or vision-centered oculomotor frame of reference that has been shown to also code the visual targets for reaching and other actions (Russo and Bruce, 1996; Engel et al., 2002; Ambrosini et al., 2012). Using those we are also able to circumvent the need for detailed programming of motor commands. Instead, the oculocentric frame of reference can guide the actions or parts of an action.

The lowest levels of the hierarchy represent two aspects in active inference that are necessary for motor coordination. The Vision level receives continuous coordinates of a writing trajectory at discrete points in time, which is perceived in the form of a discrete probability distribution over a discrete set of writing angles at each point in time. Following the narrative by Zacks et al. (2007) and Gumbsch et al. (2017) on event segmentation using surprise as a separator, we identify surprising deviations of the current writing angle given the writing angles of the past. In the context of free energy minimization, a sudden increase in the amplitude of prediction errors���induced by a surprising event���is reflected by free energy increases in the Vision level. The surprising stroke consists of the writing angle and its length, which are both transformed into the oculocentric reference frame, i.e., into relative polar coordinates with the last surprising stroke coordinates at its center. This information is send to the Sequence level, together with the time passed since the last surprising stroke. The Sequence level stores these sequences of surprising events in the oculocentric reference frame, which can also be used for generation. Following the argument by Friston (2011) we circumvent the need for detailed programming of motor commands by utilizing the surprising events consisting of relative polar coordinates as action targets, which are send to the Motor control level. There, a reflex arc in the form of a damped spring system (inspired by Ijspeert et al., 2013) will realize the motion toward the action target following simple equations of motion with the spring's point of equilibrium at the relative polar coordinate of the action target. This implementation of active inference is formally related to the equilibrium point hypothesis (Feldman and Levin, 1995). In other words, the top-down or descending predictions of the proprioceptive consequences of movement are regarded as setting and equilibrium or set point to which the motor plant converges, via the engagement of motor reflexes. This will later be explained in more detail.

An important aspect in motor coordination model can be seen in Figure 1, where the Motor Control level has no direct feedback connection to the Sequence level. This is for three reasons. First, we would like to see if sequential motor coordination as well as the inference of a sense of agency are possible with visual feedback only. Second, other than Friston et al. (2011) who rely heavily on proprioceptive information we want to allow for visual input to drive motor coordination and a sense of agency. Instead, we close the motor coordination loop using a direct long range connection that is used by the Motor Control level to inform the Vision level when it is done coordinating actions to reach a subgoal (see red dotted line in Figure 1). Vision level will then check if visual information can confirm the movement, then sending the information to the Sequence level, closing the motor coordination loop. Third, making the model's sequence coordination independent from direct proprioceptive feedback allows for future developments that can associate actions in the world with intended effects that not directly influence the motor system, e.g., switching on a light or influencing another agent's beliefs.

During action perception, we further assume that the correspondence problem is solved in the sense that an observed action by another agent is mapped into one's own body-centered frame of reference. That is, we feed the perceived action trajectory directly and bottom-up into HPBU. The next section will describe the active inference and free energy minimization in the model hierarchy.

3. Model Update Details
The HPBU model is defined as a hierarchical generative model which learns to predict and explain away prediction errors and in this sense minimize the free energy. This section will briefly introduce our free energy minimization strategy and the generative model updates, which we have implemented and extended to encompass and allow the distinction of self and other in the context of action production.

In the hierarchical generative model, each level maps the internal discrete state space from one level in the hierarchy to the domain of its next lower level. Each level contains a discrete probability distribution about that level's discrete states. The difference between continuous and discrete states in the context of active inference is well discussed in Friston et al. (2017a). All levels of the hierarchy are updated sequentially starting at the top in Schema level C, i.e., they are updated in sequence from its next higher and next lower levels, learning to represent and produce the states in the next lower level and the environment. At the top, the Schema level C represents clusters of similar representations of its next lower level, which is the Sequence level S. S represents sequences of representations of Vision level V that occured over time. Also, representations that can map to V are compatible with representations in Motor Control level M. In each level posteriors are updated bottom-up and top-down and free energy is calculated with respect to prior and posterior distributions as described in the following. These mappings can be understood as generative processes, where one level predicts the states of the level below. In the Motor Control level M this mapping results in action production.

3.1. Free Energy Minimization
Free energy describes the negative log model evidence of a generative model that tries to explain hidden states, i.e., the environment. Evidence corresponds to probabilities of data from the environment, given the model at hand.

The free energy in system X is expressed as the sum of surprise and a cross entropy of two states (a posterior P, and a prior Q before evidence has arrived). When free energy is minimized the cross entropy becomes zero, thus leaving free energy to be just surprise (entropy with regard to the posterior) (Equation 1).

F(X)=H(P(X))+DKL(P(X)||Q(X))             =������iP(Xi) lnP(Xi)+���iP(Xi) ��� lnP(Xi)Q(Xi)    (1)
In our interpretation the difference between perception and production lies in the question which signal drives the updates in calculating free energy, the bottom-up signal or the top-down signal? When it comes to calculating free energy in perception the posterior distribution (for calculating surprise and the cross-entropy) is the top-down signal Ptd and the prior, i.e., the driving signal is the bottom-up signal Pbu, so that F = H(Ptd) + DKL(Ptd||Pbu). In production the top-down signal Ptd becomes the driving signal for the free energy update F = H(Pbu) + DKL(Pbu||Ptd). The deviation is then calculated with respect to Pbu (see the yellow box in Figure 2). To update level beliefs, both posteriors will be combined to form the current level posterior Pt, in which the bottom-up signal will be combined similarly as in the identified microcircuitry for predictive coding (Bastos et al., 2012). There, connections between cortical columns are mostly inhibitory. In this setting, the bottom-up and top-down posteriors in Equation (1) play the role of predictions. This means that we can treat the differences in the bottom-up and top-down predictions as a prediction error and enter them into a Kalman filter. In this formulation, the Kalman gain is used to differentially weight bottom-up and top-down predictions and plays the role of a precision. Crucially, this precision is a function of the free energy computed at each level in the hierarchical model���such that a very high free energy (i.e., prediction error) emphasizes top-down predictions. We model this effect during perception as a top-down inhibitory influence on the bottom-up signal using a Kalman filter Pt = Pbu + Kt(Ptd ��� Pbu) with a Kalman gain Kt=FF+�� calculated from the level free energy F and precision �� to integrate this filter into the model context (see below in Equation 5 for a more detailed description). Again, the current driving signal can invert the belief update so that during production Pt = Ptd + Kt(Pbu ��� Ptd). The level posterior Pt will be send to the next higher level in the hierarchy and to the next lower level. In the following time step the level posterior will be used as an empirical prior for calculating Pbu and Ptd respectively. Figure 2 examplifies our belief update scheme in Sequence level S. There posteriors and relevant likelihoods are combined to calculate updated top-down and bottom-up posteriors necessary to calculate the free energy within level S and the final belief update step which combines top-down and bottom-up posteriors. For more details on our generative model hierarchy please refer to the Supplementary Materials.

Figure 2
www.frontiersin.org
FIGURE 2. To exemplify the belief update scheme in HPBU, here the updating of posteriors and free energy within Sequence level S are shown. Within S the top-down and bottom-up posteriors are calculated from posteriors of C and V. That information is used to update free energy either for production (prod) or for perception (perc). The updated free energy and precision (��) are used to calculate the Kalman gain necessary for calculating the level posterior P(S) using a Kalman filter, again either for production or perception. The green boxes show the calculated likelihoods necessary for updating within S or in the levels above and below (Pbu(C|S) is one example). For more details please refer to the Supplementary Materials.

Following the assumption in active inference that overt action is basically action-oriented predictive processing (Friston et al., 2010), we allow strongly predicted next actions of representations in the Sequence level to be acted out. Without any constraints this leads to overt automatic enactment, similar to the automatic imitation seen in patients suffering from echopraxia (Ganos et al., 2012). To control this motor execution, we introduced a gating signal into the top-level of the hierarchy, which acts as a motor intention for a specific schema, including a strong boost of this schema's probability (acting as a trigger to act-out an abstract motor belief). This intention percolates down the hierarchy to boost associated representations and inform the intention to act. Once it reaches the lowest level of the hierarchy, the act to produce the motor representation will be allowed.

3.2. Motor Coordination Loop
In active inference and the actual production of an action, predictions guide the minimization of free energy, the Motor level receives position (xi) and timing (��t) goals from Sequence level S. The realization of the movement goal within the Motor Control level is left to an action-proprioception loop modeled as a dampened spring system. This models the angular movements of a single joint, which in our simulations will represent a writing pencil. A similar approach was used by Friston et al. (2011) but instead of a system with two joints following one attractor-state at a time in attractor space we model just one joint which moves toward the spring system's point of equilibrium at the relative polar coordinate of the action goal. To allow for smooth and curving trajectories that are similar to handwriting in spatial and temporal properties, we were inspired by work on dynamic movement primitives (DMP) that are used for modeling attractor behaviors of autonomous non-linear dynamical systems with the help of statistical learning techniques (Ijspeert et al., 2013). We will not make use of the DMPs ability to learn and reproduce trajectories, but will configure a dampened spring system similarly to a DMP and instead of applying a forcing term that activates the system's non-linear dynamics over time we make use of an obstacle avoidance technique mentioned in Hoffmann et al. (2009) which we adopted and inverted its force to actually move toward the goal in a forcing function g (see Equation 2).
2 / 2
ChatGPT
ChatGPT
The paper titled "A Predictive Processing Model of Perception and Action for Self-Other Distinction" by Sebastian Kahl and Stefan Kopp presents a hierarchical model of sensorimotor coordination based on principles of perception-action coupling and predictive processing. The aim of the model is to explain how self-other distinction arises during action and perception in social interaction.
The authors propose a computational model called Hierarchical Predictive Belief Update (HPBU) that incorporates active inference and free energy minimization. The model consists of a hierarchy of levels, each representing different levels of abstraction in the sensorimotor system. The levels include the Schema level (C), the Sequence level (S), the Vision level (V), and the Motor Control level (M).
The authors emphasize the distinction between perception and production in terms of the driving signal for free energy updates. In perception, the posterior distribution (Ptd) is the top-down signal used to calculate surprise and cross entropy for free energy, while the prior distribution (Pbu) serves as the bottom-up signal. Therefore, the free energy calculation in perception is F = H(Ptd) + DKL(Ptd||Pbu). In production, the roles of the top-down and bottom-up signals are reversed, and the free energy update becomes F = H(Pbu) + DKL(Pbu||Ptd).
To update beliefs at each level, the bottom-up and top-down posteriors are combined to form the current level posterior (Pt). The combination is similar to the microcircuitry for predictive coding, where connections between cortical columns are mostly inhibitory. The differences between the bottom-up and top-down predictions are treated as prediction errors and entered into a Kalman filter. The Kalman gain (Kt) is used to weight the predictions based on the precision, which is a function of the free energy computed at each level. A high free energy (prediction error) emphasizes top-down predictions.
During perception, a top-down inhibitory influence on the bottom-up signal is implemented using a Kalman filter (Pt = Pbu + Kt(Ptd - Pbu)). During production, the belief update is inverted (Pt = Ptd + Kt(Pbu - Ptd)). The level posterior (Pt) is sent to the next higher level in the hierarchy and the next lower level for further processing. In the next time step, the level posterior is used as an empirical prior for calculating the bottom-up and top-down signals (Pbu and Ptd).
The HPBU model also incorporates mechanisms for motor coordination and action production. The lowest levels of the hierarchy represent the Vision level and the Motor Control level, which are responsible for action production and receiving visual and proprioceptive feedback. The motor coordination loop is realized through a dampened spring system that guides the movement toward action targets.
The authors provide simulations and results to demonstrate the model's ability to differentiate between actions produced by oneself and actions produced by an interaction partner. They also discuss the implications of the model for understanding the sense of agency and attributing beliefs during communication.
Overall, the HPBU model offers a computational framework that integrates predictive processing, perception-action coupling, and self-other distinction in social interaction. It provides insights into the mechanisms underlying sensorimotor coordination and the role of prediction in action perception and production.
1 / 1
We can change the world by altering our perspective
1 / 1
ChatGPT
ChatGPT
Indeed, changing our perspective can have a profound impact on how we perceive and interact with the world. Our perspective shapes our beliefs, attitudes, and behaviors, influencing how we interpret events and how we engage with others. By altering our perspective, we can:
Foster empathy and understanding: Gaining a different perspective allows us to see things from someone else's point of view, promoting empathy and understanding. It helps us recognize the diversity of experiences and challenges that others face, fostering compassion and tolerance.
Encourage personal growth: Embracing new perspectives challenges our existing beliefs and assumptions, opening doors to personal growth and development. It allows us to expand our knowledge, challenge biases, and embrace new ideas and possibilities.
Facilitate problem-solving: Approaching problems from different angles and considering various perspectives can lead to innovative solutions. It helps us break free from rigid thinking patterns and encourages creative problem-solving by considering diverse viewpoints.
Enhance relationships and communication: Taking the time to understand and appreciate others' perspectives improves communication and fosters positive relationships. It promotes effective dialogue, reduces conflicts, and cultivates a sense of collaboration and teamwork.
Drive social change: By adopting a new perspective, we can gain insights into social issues and inequalities, motivating us to take action and advocate for positive change. It empowers us to challenge the status quo, address injustices, and work towards a more inclusive and equitable society.
Cultivate gratitude and resilience: Shifting our perspective allows us to find gratitude and meaning in challenging situations. It enables us to reframe difficulties as opportunities for growth and resilience, fostering a positive mindset and enhancing overall well-being.
Promote self-reflection: Altering our perspective encourages self-reflection and introspection. It prompts us to question our beliefs, biases, and assumptions, leading to increased self-awareness and personal development.
Remember, changing our perspective is a continuous process that requires an open mind, curiosity, and a willingness to challenge our own viewpoints. It allows us to see the world in new ways, empowering us to make a positive impact on ourselves and others.
1 / 1
I was referring to active inference
1 / 1
ChatGPT
ChatGPT
Apologies for the misunderstanding. In the context of active inference, altering our perspective can indeed have implications for how we perceive and interact with the world. Active inference is a theoretical framework that suggests our perception and actions are driven by minimizing the difference between our predictions (based on internal models) and sensory input from the external world.
By altering our perspective within the framework of active inference, we can influence the way we generate and update our predictions about the world. Here's how changing our perspective can impact active inference:
Updating priors: Our perspective shapes our prior beliefs about the world. By consciously shifting our perspective, we can update our prior expectations and incorporate new information into our generative models. This can lead to more accurate predictions and a better alignment between our internal models and the external reality.
Sensory selection: Active inference involves selectively attending to and processing sensory information based on its relevance to our goals and predictions. Altering our perspective can influence which sensory inputs we prioritize and how we interpret them. This, in turn, affects the flow of information and the updating of our beliefs and predictions.
Precision weighting: Precision, in the context of active inference, refers to the relative reliability or certainty assigned to sensory inputs and predictions. Our perspective can influence the precision weighting process by adjusting the confidence we place in different sources of information. Changing our perspective may lead to a reassessment of the precision assigned to specific predictions or sensory evidence.
Exploration and action selection: Active inference involves a balance between exploiting existing knowledge (making predictions based on prior beliefs) and exploring the environment to gather new information. Altering our perspective can influence our exploration strategies, leading us to seek out different types of information or engage in different actions to gather more relevant data and update our predictions accordingly.
Higher-level inference: Active inference occurs across multiple hierarchical levels, with predictions and beliefs cascading from higher to lower levels. Changing our perspective can influence the higher-level inference processes, such as the integration of beliefs and predictions from different domains or the selection of appropriate action policies based on global goals and context.
In summary, altering our perspective within the framework of active inference can impact various aspects of the inference process, including priors, sensory selection, precision weighting, exploration, action selection, and higher-level inference. It highlights the role of our subjective experiences and beliefs in shaping the active inference process and offers the potential for updating our internal models to better align with the external world.
1 / 1
Connections to the topics discussed earlier.
1 / 1
ChatGPT
ChatGPT
Certainly! Let's draw connections between the concept of altering our perspective and the topics discussed earlier, including the hierarchical generative model, self-other distinction, and free energy minimization in active inference:
Hierarchical Generative Model: In the hierarchical generative model presented earlier, altering our perspective can be seen as a process of updating the representations and beliefs at different levels of the hierarchy. By changing our perspective, we can modify the predictions and expectations at higher levels, which in turn influence the processing and predictions at lower levels. This flexibility allows us to adapt our models to different contexts and refine our understanding of the world.
Self-Other Distinction: Altering our perspective is crucial for the distinction between self and other in the context of active inference. By adjusting our perspective, we can differentiate between actions produced by ourselves and those produced by others. This distinction arises from the integration of bottom-up and top-down signals, where the top-down predictions, driven by our perspective, play a role in emphasizing self-relevant information and minimizing prediction errors. This process enables us to attribute a sense of agency to our own actions and differentiate them from external actions.
Free Energy Minimization: Active inference involves minimizing free energy, which corresponds to reducing prediction errors and updating our beliefs to better explain the observed data. Altering our perspective can impact the calculation of free energy by influencing the weighting of top-down and bottom-up signals. By changing our perspective, we can adjust the balance between the driving signals for free energy updates in perception (top-down signal as driving) and production (bottom-up signal as driving). This adaptive weighting allows us to prioritize different sources of information and optimize the free energy minimization process.
Perception and Production: Altering our perspective can influence both perception and production processes in active inference. In perception, changing our perspective can lead to a reevaluation of the top-down predictions and bottom-up sensory evidence, potentially leading to revised beliefs and improved perception of the external world. In production, altering our perspective can guide the generation of actions, influencing the predictions and precision weighting of the motor control processes. By actively adjusting our perspective, we can optimize both perception and action production within the active inference framework.
In summary, altering our perspective has connections to the topics discussed earlier, including the hierarchical generative model, self-other distinction, and free energy minimization in active inference. It highlights the role of perspective in shaping our models, differentiating self and other, optimizing free energy minimization, and influencing perception and production processes.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT May 24 Version
ChatGPT



