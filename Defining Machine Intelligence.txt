Defining Machine Intelligence
Open sidebar
Defining Machine Intelligence
GPT-4
Universal Intelligence: 
A Def i nition of Machine Intelligence 
Shane Legg 
IDSIA, Galleria 2, Manno-Lugano CH-6928, Switzerland 
shane@vetta.orgwww.vetta.org/shane 
Marcus Hutter 
RSISE@ANU and SML@NICTA, Canberra, ACT, 0200, Australia 
marcus@hutter1.netwww.hutter1.net 
December 2007 
Abstract 
A fundamental problem in artif i cial intelligence is that nobody really knows what 
intelligence is. The problem is especially acute when we need to consider artif i cial 
systems which are signif i cantly dif f erent to humans. In this paper we approach this 
problem in the following way: We take a number of well known informal def i nitions 
of human intelligence that have been given by experts, and extract their essential 
features. These are then mathematically formalised to produce a general measure of 
intelligence for arbitrary machines. We believe that this equation formally captures 
the concept of machine intelligence in the broadest reasonable sense. We then show 
how this formal def i nition is related to the theory of universal optimal learning 
agents. Finally, we survey the many other tests and def i nitions of intelligence that 
have been proposed for machines.

3.3A formal def i nition of machine intelligence 
In order to def i ne an overall measure of performance, we need to i nd a way to combine 
an agent���s performance in many dif f erent environments into a single overall measure. As 
there are an inf i nite number of environments, we cannot simply take a uniform distribution 
over them. Mathematically, we must weight some environments higher than others. But 
how? 
Consider the agent���s perspective on this situation: There exists a probability measure 
that describes the true environment, however this measure is not known to the agent. 
The only information the agent has are some past observations of the environment. From 
these, the agent can construct a list of probability measures that are consistent with the 
observations. We call these potential explanations of the true environment, hypotheses. 
As the number of observations increases, the set of hypotheses shrinks and hopefully the 
remaining hypotheses become increasingly accurate at modelling the true environment. 
The problem is that in any given situation there will likely be a large number of 
hypotheses that are consistent with the current set of observations. Thus, if the agent 
3.3A formal def i nition of machine intelligence21 
is going to predict which hypotheses are the most likely to be correct, it must resort to 
something other than just the observational information that it has. This is a frequently 
occurring problem in inductive inference for which the most common approach is to invoke 
the principle of Occam���s razor: 
Given multiple hypotheses that are consistent with the data, the simplest should 
be preferred. 
This is generally considered the rational and intelligent thing to do [Wal05], indeed IQ 
tests often implicitly test an individual���s ability to use Occam���s razor, as pointed out in 
Subsection 2.1. 
3.3 Example.Consider the following type of question which commonly appears in 
intelligence tests.There is a sequence such as 2, 4, 6, 8, and the test subject needs 
to predict the next number. Of course the pattern is immediately clear: The numbers 
are increasing by 2 each time, or more mathematically, the kthitem is given by 2k. An 
intelligent person would easily identify this pattern and predict the next digit to be 10. 
However, the polynomial 2k4��� 20k3+ 70k2��� 98k + 48 is also consistent with the data, 
in which case the next number in the sequence would be 58. Why then, even if we are 
aware of the larger polynomial, do we consider the i rst answer to be the most likely one? 
It is because we apply, perhaps unconsciously, the principle of Occam���s razor. The fact 
that intelligence tests def i ne this as the ���correct��� answer, shows us that using Occam���s 
razor is considered the intelligent thing to do. Thus, although we do not usually mention 
Occam���s razor when def i ning intelligence, the ability to ef f ectively use it is an important 
facet of intelligent behaviour. 
In some cases we may even consider the correct use of Occam���s razor to be a more 
important demonstration of intelligence than achieving a successful outcome. Consider, 
for example, the following game: 3.4 Example.A questioner lays twenty?10 notes out on a table before you and then 
points to the i rst one and asks ���Yes or No?���. If you answer ���Yes��� he hands you the 
money. If you answer ���No��� he takes it from the table and puts it in his pocket. He then 
points to the next?10 note on the table and asks the same question. Although you, as an 
intelligent agent, might experiment with answering both ���Yes��� and ���No��� a few times, by 
the 13thround you would have decided that the best choice seems to be ���Yes��� each time. 
However what you do not know is that if you answer ���Yes��� in the 13thround then the 
questioner will pull out a gun and shoot you! Thus, although answering ���Yes��� in the 13th 
round is the most intelligent choice, given what you know, it is not the most successful 
one. An exceptionally dim individual may have failed to notice the obvious relationship 
between answers and getting the money, and thus might answer ���No��� in the 13thround, 
thereby saving his life due to what could truly be called ���dumb luck���. 
What is important then, is not that an intelligent agent succeeds in any given situation, 
but rather that it takes actions that we would expect to be the most likely ones to lead 
to success. Given adequate experience this might be clear, however often experience is 
not suf i cient and one must fall back on good prior assumptions about the world, such as 
Occam���s razor. It is important then that we test the agents in such a way that they are, 
223A DEFINITION OF MACHINE INTELLIGENCE 
at least on average, rewarded for correctly applying Occam���s razor, even if in some cases 
this leads to failure. 
There is another subtlety that needs to be pointed out. Often intelligence is thought 
of as the ability to deal with complexity. Or in the words of the psychologist Gottfred- 
son, ���...g is the ability to deal with cognitive complexity ��� in particular, with complex 
information processing.���[Got97b] It is tempting then to equate the dif i cultly of an envi- 
ronment with its complexity. Unfortunately, things are not so straightforward. Consider 
the following environment: 
3.5 Example.Imagine a very complex environment with a rich set of relationships 
between the agent���s actions and observations. The measure that describes this will have 
a high complexity.However, also imagine that the reward signal is always maximal 
no matter what the agent does. Thus, although this is a very complex environment in 
which the agent is unlikely to be able predict what it will observe next, it is also an 
easy environment in the sense that all policies are optimal, even very simple ones that do 
nothing at all. The environment contains a lot of structure that is irrelevant to the goal 
that the agent is trying to achieve.
1 / 1
ChatGPT
It seems you've shared a section from a research paper by Shane Legg and Marcus Hutter regarding a formal definition of machine intelligence, specifically touching on Occam's razor and the complexities of defining intelligence in a machine.
The paper addresses the fundamental problem of defining intelligence and approaches this issue by extracting essential features from known informal definitions of human intelligence. By mathematical formalization, the authors provide a general measure of intelligence for machines.
The passage also explores the principle of Occam's razor, the preference for simpler hypotheses that are consistent with the observed data. This principle is linked to human intelligence and is considered an essential aspect of intelligent behavior.
Examples are provided to elucidate the complexity of defining intelligence, illustrating that intelligence is not merely about success in a given situation, but about taking actions most likely to lead to success. This includes the ability to deal with cognitive complexity and making wise choices, even if they might sometimes lead to failure.
In summary, the excerpt emphasizes the multifaceted nature of intelligence and the importance of considering factors such as simplicity, complexity, and experience in formulating a comprehensive definition for machine intelligence.
1 / 1
From this perspective, a problem is thought of as being dif i cult if the simplest good 
solution to the problem is complex. Easy problems on the other hand are those that have 
simple solutions. This is a very natural way to think about the dif i culty of problems, or 
in our terminology, environments. 
Fortunately, this distinction does not af f ect our use of Occam���s razor. When we talk 
about an hypothesis, what we mean is a potential model of the environment from the 
agent���s perspective, not just a model that is suf i cient with respect to the agent���s goal. 
From the agent���s perspective, an incorrect hypothesis that fails to model much of the 
environment may be optimal if the parts of the environment that the hypothesis fails to 
model are not relevant to receiving reward. However, when Occam���s razor is applied, we 
apply it with respect to the complexity of the hypotheses, not the complexity of good 
solutions with respect to an objective. Thus, to reward agents on average for correctly 
using Occam���s razor, we must weight the environments according to their complexity, not 
their dif i culty. 
Our remaining problem now is to measure the complexity of environments. The Kol- 
mogorov complexity of a binary string x is def i ned as being the length of the shortest 
program that computes x: K(x) := min 
p {l(p) : U(p) = x}, 
where p is a binary string which we call a program, l(p) is the length of this string in bits, 
and U is a pref i x universal Turing machine U called the reference machine. 
To gain an intuition for how this works, consider a binary string 0000...0 that consists 
of a trillion 0s. Although this string is very long, it clearly has a simple structure and 
thus we would expect it to have a low complexity. Indeed this is the case because we 
can write a very short program p that simply loops a trillion times outputting a 0 each 
time. Similarity, other strings with simple patterns have a low Kolmogorov complexity. 
On the other hand, if we consider a long irregular random string 111010110000010... 
then it is much more dif i cult to i nd a short program that outputs this string. Indeed it 
is possible to prove that there are so many strings of this form, relative to the number 
3.3A formal def i nition of machine intelligence23 
of short programs, that in general it is impossible for long random strings to have short 
programs. In other words, they have high Kolmogorov complexity. 
An important property of K is that it is nearly independent of the choice of U. To see 
why, consider what happens if we switch from U, in the above def i nition of K, to some 
other universal Turing machine U���. Due to the universality property of U���, 
there exists a 
program q that allows U���to simulate U. Thus, if we give U���both 
q and p as inputs, it can 
simulate U running p and thereby compute U(p). It follows then that switching from U to 
U���in 
our def i nition of K above incurs at most an additional cost of l(q) bits in minimal 
program length. The constant l(q) is independent of which string x we are measuring 
the complexity of, and for reasonable universal Turing machines, this constant will be 
small. This invariance property makes K an excellent universal complexity measure. For 
an extensive treatment of Kolmogorov complexity see [LV97] or [Cal02]. 
In our current application we need to measure the complexity of the computable 
measures that describe environments. It can be shown that this set can be enumerated 
��1,��2,��3,... (see Theorem 4.3.1 in [LV97]). Using a simple encoding method we can 
express each index as a binary string, written hii.In 
a sense this binary string is a 
description of an environment with respect to our enumeration. This lets us def i ne the 
complexity of an environment ��ito be K(��i) := K(hii). Intuitively, if a short program 
can be used to describe the program for an environment ��i, then this environment will 
have a low complexity. 
This answers our problem of needing to be able to measure the complexity of envi- 
ronments, but we are not done yet. In order to formalise Occam���s razor we need to have 
a way to assign an a priori probability to environments in such a way that complex en- 
vironments are less likely, and simple environments more likely. If we consider that each 
environment ��iis described by a minimal length program that is a binary string, then the 
natural way to do this is to consider each additional bit of program length to reduce the 
environment���s probability by one half, ref l ecting the fact that each bit has two possible 
states. This gives us what is known as the algorithmic probability distribution over the 
space of environments, def i ned 2���K(��). This distribution has powerful properties that es- 
sentially solve long-standing open philosophical, statistical, and computational problems 
in the area of inductive inference [Hut07a]. Furthermore, the distribution can be used to 
def i ne powerful universal learning agents that have provably optimal performance [Hut05].
1 / 1
ChatGPT
The passage you provided delves into the complexity and subtleties of defining machine intelligence. It discusses the use of Occam's razor in modeling environments and explains how complex systems can be understood and evaluated. Additionally, it introduces the concept of Kolmogorov complexity, a measure of the computational complexity of objects, and demonstrates how it can be used to quantify the complexity of environments.
In summary, the text explores the idea of intelligence as the ability to deal with complexity, and it presents a mathematical formalization to evaluate machine intelligence. By incorporating principles like Occam's razor and Kolmogorov complexity, the authors provide a nuanced perspective on how to define and measure machine intelligence, considering both simple and complex environments. The text also alludes to the utilization of the algorithmic probability distribution, highlighting its profound implications in inductive inference and the design of optimal learning agents.
1 / 1
Bringing all these pieces together, we can now def i ne our formal measure of intelligence 
for arbitrary systems. Let E be the space of all computable reward summable environ- 
mental measures with respect to the reference machine U, and let K be the Kolmogorov 
complexity function. The expected performance of agent �� with respect to the universal 
distribution 2���K(��)over the space of all environments E is given by, 
��(��) := X 
�����E 
2���K(��)V 
�� 
��. 
We call this the universal intelligence of agent ��. 
Consider how this equation corresponds to our informal def i nition. We needed a mea- 
sure of an agent���s general ability to achieve goals in a wide range of environments. Clearly 
present in the equation is the agent ��, the environment �� and, implicit in the environment, 
a goal. The agent���s ���ability to achieve��� is represented by the value function V 
�� 
��. By a 
���wide range of environments��� we have taken the space of all well def i ned reward summable 
environments, where these environments have been characterised as computable measures 
243A DEFINITION OF MACHINE INTELLIGENCE 
in the set E. Occam���s razor is given by the term 2���K(��)which weights the agent���s perfor- 
mance in each environment inversely proportional to its complexity. The def i nition is very 
general in terms of which sensors or actuators the agent might have as all information 
exchanged between the agent and the environment takes place over very general commu- 
nication channels. Finally, the formal def i nition places no limits on the internal workings 
of the agent. Thus, we can apply the def i nition to any system that is able to receive and 
generate information with view to achieving goals. The main drawback, however, is that 
the Kolmogorov complexity function K is not computable and can only be approximated. 
This is an important point that we will return to later.
1 / 1
ChatGPT
This passage outlines a formal definition of machine intelligence for arbitrary systems, based on the concepts previously discussed such as Kolmogorov complexity and Occam's razor.
The universal intelligence of an agent,
��
(
��
)
\Upsilon(\pi)
��
(
��
)
, is defined as the expected performance of the agent across all environments
E
E
E
, weighted by their complexity. It's an integration over all possible environments, with each environment's complexity used to scale the agent's performance in that environment. The less complex the environment, the more it contributes to the agent's intelligence measure.
Here's a summary of the key components in the definition:
Agent
��
\pi
��
: The entity whose intelligence is being measured.
Environment
��
\mu
��
: The space of all possible environments that can be described as computable measures.
Value Function
V
��
��
V^\pi_\mu
V
��
��
���
: Represents the agent's ability to achieve goals within a specific environment.
Kolmogorov Complexity Function
K
K
K
: Used to weight the agent's performance inversely proportional to the complexity of the environment.
Universal Distribution
2
���
K
(
��
)
2^{-K(\mu)}
2
���
K
(
��
)
: Reflects Occam's razor principle by emphasizing simple environments.
The definition is broad, encompassing various sensors, actuators, communication channels, and internal workings of the agent. However, a critical drawback is the non-computability of the Kolmogorov complexity function, meaning it can only be approximated. This limitation acknowledges that while the definition is theoretically robust, practical application may require further consideration and adjustment.
1 / 1
See if you can explain it a bit simpler, including how the formula works
1 / 1
ChatGPT
Certainly! Let's break down the concept of universal intelligence and the formula in a more accessible way.
We're trying to measure how smart a machine (the agent) is. To do this, we test how well the agent performs in a wide range of different scenarios (environments).
Agent
: The machine or system we're testing.
Environment
: Different situations or problems the agent might face.
Ability to Achieve Goals
: How well the agent does in each environment.
Now, let's look at the formula:
��
(
��
)
:
=
���
��
���
E
2
���
K
(
��
)
V
��
��
\Upsilon(\pi) := \sum_{\mu\in E} 2^{-K(\mu)}V^{\pi}_{\mu}
��
(
��
)
:=
���
��
���
E
���
2
���
K
(
��
)
V
��
��
���
Summation (
���
\sum
���
)
: We're adding up the agent's performance across all different environments.
2
���
K
(
��
)
2^{-K(\mu)}
2
���
K
(
��
)
: This part gives more weight to simple environments and less weight to complex ones. Think of it as a fairness factor to ensure that doing well in simple situations counts, but not as much as doing well in hard ones.
V
��
��
V^{\pi}_{\mu}
V
��
��
���
: This tells us how well the agent is doing in each specific environment.
Putting it all together, the formula measures the agent's intelligence by checking its performance across many situations, giving more importance to doing well in complex problems. It tries to capture the idea that an intelligent agent should not just solve easy tasks but also be capable of handling more difficult ones.
One complexity in applying this in the real world is that the measure of complexity used in the formula (Kolmogorov complexity) is theoretical and can't be computed exactly. So, while the formula provides a powerful way to think about intelligence, using it directly can be challenging.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT August 3 Version
?
ChatGPT



