Dynamic Terraformation
ChatGPT
Historial del chat
ChatGPT
ChatGPT
Nuspeak Translator
Jain Hive Tree
Explorar GPT
Hoy
Perceptual Figuration
Dynamic Terraformation
Orthodromic Rivers
Ayer
Remove Control Characters Vim
Language Learning Through Reading
FFmpeg GIF Alternation Command
Update GitHub Page Content
7 d��as anteriores
Transformer Language Models Primer
Script Processing Issues
Critical Discourse Analysis Overview
IrfanView Color Inversion Shortcut
Control and Curiosity
Eloi Morlocks Story Outline
Overview of Psych Series
Auditory Operating System
Funes Memore et Linguistica
Funes Memorius et Theoriae
Cosmic Background Simulator
Overview of Psych Series
Overview of Psych Series
Semantic Ladle Theory
30 d��as anteriores
Kriegslied ��bersetzung und Analyse
Keen Psyop
Diffusion Models as Evolutionary Algorithms
Ancestral Knowledge
Relativity and Proper Time
Update WSL Instructions
Metaphysics vs Ontology
Agregar un espacio de trabajo de Team
Colabora en un plan Team
Nathaniel Guimond
Abrir barra lateral
ChatGPT
4
ChatGPT
4
Compartir
Dijiste:
Understanding Society

Daniel Little

Menu
Posted onDecember 28, 2019 by Daniel Little
High reliability organizations

Charles Perrow takes a particularly negative view of the possibility of safe management of high-risk technologies in Normal Accidents: Living with High-Risk Technologies. His summary of the Three Mile Island accident is illustrative: ���The system caused the accident, not the operators��� (12). Perrow���s account of TMI is chiefly an account of complex and tightly-coupled system processes, and the difficulty these processes create for operators and managers when they go wrong. And he is doubtful that the industry can safely manage its nuclear plants.

It is interesting to note that systems engineer and safety expert Nancy Leveson addresses the same features of ���system accidents��� that Perrow addresses, but with a greater level of confidence about the possibility of creating engineering and organizational enhancements. A recent expression of her theory of technology safety is provided in Engineering a Safer World: Systems Thinking Applied to Safety (Engineering Systems) and Resilience Engineering: Concepts and Precepts. 

In examining the safety of high-risk industries, our goal should be to identify some of the behavioral, organizational, and regulatory dysfunctions that increase the likelihood and severity of accidents, and to consider organizational and behavioral changes that would serve to reduce the risk and severity of accidents. This is the approach taken by a group of organizational theorists, engineers, and safety experts who explore the idea and practice of a ���high reliability organization���. Scott Sagan describes the HRO approach in these terms in The Limits of Safety:

The common assumption of the high reliability theorists is not a naive belief in the ability of human beings to behave with perfect rationality, it is the much more plausible belief that organizations, properly designed and managed, can compensate for well-known human frailties and can therefore be significantly more rational and effective than can individuals. (Sagan, 16)

Sagan lists several conclusions advanced by HRO theorists, based on a small number of studies of high-risk organizational environments. Researchers have identified a set of organizational features that appear to be common among HROs:

Leadership safety objectives: priority on avoiding altogether serious operational failures
Organizational leaders must place high priority on safety in order to communicate this objective clearly and consistently to the rest of the organization
The need for redundancy. Multiple and independent channels of communication, decision-making, and implementation can produce a highly reliable overall system
Decentralization ��� authority must exist in order to permit rapid and appropriate responses to dangers by individuals closest to the problems
culture ��� recruit individuals who help maintain a strong organizational culture emphasizing safety and reliability
continuity ��� maintain continuous operations, vigilance, and training
organizational learning ��� learn from prior accidents and near-misses.
Improve the use of simulation and imagination of failure scenarios
Here is Sagan���s effort to compare Normal Accident Theory with High Reliability Organization Theory:


The genuinely important question here is whether there are indeed organizational arrangements, design principles, and behavioral practices that are consistently effective in significantly reducing the incidence and harmfulness of accidents in high-risk enterprises, or whether on the other hand, the ideal of a ���High Reliability Organization��� is more chimera than reality.

A respected organizational theorist who has written on high-reliability organizations and practices extensively is Karl Weick. He and Kathleen Sutcliffe attempt to draw some useable maxims for high reliability in Managing the Unexpected: Sustained Performance in a Complex World. They use several examples of real-world business failures to illustrate their central recommendations, including an in-depth case study of the Washington Mutual financial collapse in 2008.

The chief recommendations of their book come down to five maxims for enhancing reliability:

Pay attention to weak signals of unexpected events
Avoid extreme simplification
Pay close attention to operations
Maintain a commitment to resilience
Defer to expertise
Maxim 1 (preoccupation with failure) encourages a style of thinking ��� an alertness to unusual activity or anomalous events and a commitment to learning from near-misses in the past. This alertness is both individual and organizational; individual members of the organization need to be alert to weak signals in their areas, and managers need to be receptive to hearing the ���bad news��� when ominous signals are reported. By paying attention to ���weak signals��� of possible failure, managers will have more time to design solutions to failures when they emerge.

Maxim 2 addresses the common cognitive mistake of subsuming unusual or unexpected outcomes under more common and harmless categories. Managers should be reluctant to accept simplifications. The Columbia space shuttle disaster seems to fall in this category, where senior NASA managers dismissed evidence of foam strike during lift-off by subsuming it under many earlier instances of debris strikes.

Maxim 3 addresses the organizational failure associated with distant management ��� top executives who are highly ���hands-off��� in their knowledge and actions with regard to ongoing operations of the business. (The current Boeing story seems to illustrate this failure; even the decision to move the corporate headquarters to Chicago, very distant from the engineering and manufacturing facilities in Seattle, illustrates a hands-off attitude towards operations.) Executives who look at their work as ���the big picture��� rather than ensuring high-quality activity within the actual operations of the organization are likely to oversee disaster at some point.

Maxim 4 is both cognitive and organizational. ���Resilience��� refers to the ���ability of an organization (system) to maintain or regain a dynamically stable state, which allows it to continue operations after a major mishap and/ or in the presence of a continuous stress���. A resilient organization is one where process design has been carried out in order to avoid single-point failures, where resources and tools are available to address possible ���off-design��� failures, and where the interruption of one series of activities (electrical power) does not completely block another vital series of activities (flow of cooling water). A resilient team is one in which multiple capable individuals are ready to work together to solve problems, sometimes in novel ways, to ameliorate the consequences of unexpected failure.

Maxim 5 emphasizes the point that complex activities and processes need to be managed by teams incorporating experience, knowledge, and creativity in order to be able to confront and surmount unexpected failures. Weick and Sutcliffe give telling examples of instances where key expertise was lost at the frontline level through attrition or employee discouragement, and where senior executives substituted their judgment for the recommendations of more expert subordinates.

These maxims involve a substantial dose of cognitive practice, changing the way that employees, managers, and executives think: the importance of paying attention to signs of unexpected outcomes (pumps that repeatedly fail in a refinery), learning from near-misses, making full use of the expertise of members of the organization, ���. It is also possible to see how various organizations could be evaluated in terms of their performance on these five maxims ��� before a serious failure has occurred ��� and could improve performance accordingly.

It is interesting to observe, however, that Weick and Sutcliffe do not highlight some factors that have been given strong priority in other treatments of high-reliability organizations: the importance of establishing a high priority for system safety in the highest management levels of the organization (which unavoidably competes with cost and profit pressures), the organizational feature of an empowered safety executive outside the scope of production and business executives in the organization, the possible benefits of a somewhat decentralized system of control, the possible benefits of redundancy, the importance of well-designed training aimed at enhancing system safety as well as personal safety, and the importance of creating a culture of honesty and compliance when it comes to safety. When mid-level managers are discouraged from bringing forward their concerns about the ���signals��� they perceive in their areas, this is a pre-catastrophe situation.

There is a place in the management literature for a handbook of research on high-reliability organizations; at present, such a resource does not exist.
ChatGPT dijo:
ChatGPT
The excerpt from Daniel Little's blog "Understanding Society" discusses the theories and practices surrounding high reliability organizations (HROs), which are pivotal in managing high-risk industries like nuclear power. The content delves into the contrasting views of Charles Perrow and Nancy Leveson on the feasibility of safe management of high-risk technologies, with Perrow being more skeptical and Leveson more optimistic about the potential for systemic improvements.
The article extensively references Scott Sagan���s interpretation of HRO theory, emphasizing that while humans are not infallible, properly managed organizations can significantly mitigate human errors. It outlines various organizational features that are common among HROs, such as prioritizing safety, redundancy, decentralization, a strong safety culture, continuous operations, organizational learning, and simulation practices.
Additionally, Karl Weick and Kathleen Sutcliffe's work is cited, focusing on specific maxims for enhancing reliability in organizations. These include being attentive to weak signals of failure, avoiding oversimplification, maintaining close oversight of operations, building resilience, and deferring to expertise. Each of these principles is meant to enhance an organization's capability to manage unexpected events and to prevent disasters.
The text suggests that despite extensive theorizing on HROs, practical applications in the field vary, and there is room for further empirical research and literature, especially a comprehensive handbook on HRO practices. This indicates an ongoing evolution in how high reliability is understood and implemented in high-stakes environments.
4
Dijiste:
The Five Principles of High Reliability Organizations 
(or HROs) 
In their book ���Managing the Unexpected: Resilient Performance in an Age of Uncertainty,��� Drs. 
Karl E Weick and Kathleen M. Sutcliffe examine ways that people and organizations organize for 
high performance settings where the potential for error is overwhelming.1 For example, nuclear 
aircraft carriers, air traffic control and operations systems, hostage negotiation teams and 
emergency medical treatment centers share a singular demand: they have no choice but to 
operate reliably.2 
Weick and Sutcliffe attribute the success of HROs to their determined efforts to act ���mindfully.��� 
HROs organize themselves in such a way that they are better able to notice the unexpected and 
halt its development.3 The following five principles have been identified4 by Drs. Weick & 
Sutcliffe to underlie HRO performance and capacity to anticipate, respond, and contain the 
���unexpected.��� 
1. Preoccupation with failure. 
Attention on close calls and near misses (���being lucky vs. being good���); focus more on 
failures rather than successes. 
2. Reluctance to simplify interpretations. 
Solid ���root cause��� analysis practices. 
3. Sensitivity to operations. 
Situational awareness and carefully designed change management processes. 
4. Commitment to resilience. 
Resources are continually devoted to corrective action plans and training. 
5. Deference to expertise. 
Listen to your experts on the front lines (ex. authority follows expertise). 
Weick and Sutcliffe advise that failure to move towards this type of mindful infrastructure 
magnifies the damage produced by unexpected events and impairs reliable performance.5
ChatGPT dijo:
ChatGPT
Karl Weick and Kathleen Sutcliffe���s five principles of High Reliability Organizations (HROs) focus on creating a mindful infrastructure within organizations that routinely operate in high-risk environments. These principles are designed to enhance the capacity to anticipate, respond to, and contain unexpected events. Here's a breakdown of each principle:
Preoccupation with Failure
: HROs constantly focus on close calls and near misses, emphasizing learning from these incidents rather than solely celebrating successes. This principle encourages a culture where every hint of failure is taken seriously as an opportunity for improvement, fostering an environment vigilant against potential disasters.
Reluctance to Simplify Interpretations
: This principle advocates for thorough and complex analysis over superficial understanding. HROs engage in solid root cause analysis to avoid oversimplification that can overlook deeper systemic problems. By doing so, they ensure that they grasp the full complexity of issues and avoid the pitfalls of inadequate solutions.
Sensitivity to Operations
: Maintaining situational awareness is crucial in high-stakes environments. This principle stresses the importance of being acutely aware of the operational aspects of the organization at all times. Carefully designed change management processes ensure that even small changes are managed with precision to prevent disruptions.
Commitment to Resilience
: HROs invest continuously in building and maintaining their capacity to recover from setbacks. This includes allocating resources to corrective actions and ongoing training, which prepares the organization to bounce back quickly and effectively from crises.
Deference to Expertise
: This principle emphasizes the importance of valuing and listening to front-line experts, recognizing that authority should follow expertise rather than hierarchy. By deferring to those with the most relevant knowledge, especially in critical situations, HROs can make informed decisions quickly and accurately.
Together, these principles guide organizations in high-risk sectors by encouraging a detailed and attentive approach to operations, fostering a culture that is finely tuned to the nuances of their complex environments. This framework helps minimize errors and enhances the overall reliability and safety of operations.
4
Dijiste:
Toward High-Reliability Artificial Intelligence 
Thomas G. Dietterich, Distinguished Professor (Emeritus) 
Former President, AAAI (Association for the Advancement of Artificial Intelligence) 
Former President, IMLS (International Machine Learning Society) 
Fellow AAAI, ACM, AAAS 
Oregon State University, Corvallis, OR USA 97331 
HighHigh- -Reliability Human Organizations 
(HROs)Reliability 
Human Organizations (HROs) 
Todd LaPorte, Gene Rochlin, and Karlene Roberts (Weick, et al., 1999) 
Organizations that achieve consistently low error rates over long 
periods of time 
Prior belief: There are unknown failure modes in the system. The role 
of the organization is to discover and fix them 
1. Maintain continuous situational awareness 
2. Detect anomalies and near misses 
3. Generate and evaluate multiple hypotheses 
4. Design, implement, and test solutions 
5. Final decision is made by the person with the most expertise 
2AI 
Ethics and Development Forum 2021 
Impact of HRO 
PrinciplesImpact 
of HRO Principles 
��� Cockpit Resource Management: 
��� Train aircraft pilots and co-pilots to 
detect and recover from novel failures 
��� Patient Safety Movement: 
��� Eliminate all preventable medical 
mistakes 
��� My Goal: AI Safety Movement 
��� Eliminate all preventable AI mistakes http://patientsafetymovement.org 
3AI 
Ethics and Development Forum 2021 
Lessons for AI: Two 
ScenariosLessons 
for AI: Two Scenarios 
��� Scenario 1: Autonomous AI System as an HRO 
��� Scenario 2: Human organization + AI System as an HRO
ChatGPT dijo:
ChatGPT
Thomas G. Dietterich���s work on applying High-Reliability Organization (HRO) principles to the realm of artificial intelligence (AI) presents an insightful approach toward achieving high-reliability in AI systems. By drawing parallels from proven HRO strategies in human organizations, Dietterich proposes a framework that can significantly enhance the safety and reliability of AI systems. Here���s a detailed exploration of the proposed approach and its implications:
Applying HRO Principles to AI
Maintain Continuous Situational Awareness
: Just as in human-operated high-reliability organizations, AI systems need to continuously monitor their environment and their performance. This involves real-time data processing and the ability to adjust to changing conditions, ensuring that the AI remains aware of all operational factors that could impact its decisions.
Detect Anomalies and Near Misses
: AI systems should be equipped with mechanisms to detect deviations from normal operations, which can be indicators of potential failures. By identifying and analyzing these anomalies, AI can initiate corrective measures before failures occur.
Generate and Evaluate Multiple Hypotheses
: When anomalies are detected, AI systems should be capable of generating multiple hypotheses regarding the cause and potential solutions. This involves sophisticated reasoning algorithms that can consider various scenarios and determine the most effective course of action.
Design, Implement, and Test Solutions
: After hypothesizing potential solutions, AI systems need the capability to design and test these solutions, either through simulations or controlled real-world interventions. This iterative process helps refine the AI's decision-making capabilities and ensures solutions are effective before full-scale implementation.
Final Decision is Made by the Person with the Most Expertise
: In scenarios where AI systems work alongside humans, the final decisions should be made by the most knowledgeable entity, whether it���s the AI or a human expert. This principle ensures that the most reliable and informed party handles critical decisions, maximizing the safety and effectiveness of operations.
Impact of HRO Principles on AI
Dietterich highlights specific areas where HRO principles have already made significant impacts, such as cockpit resource management and patient safety movements. By extending these principles to AI, the goal is to minimize or eliminate preventable AI mistakes, thereby enhancing the reliability and safety of these systems in critical applications.
Lessons for AI: Two Scenarios
Autonomous AI System as an HRO
: This scenario involves designing AI systems that independently adhere to HRO principles. Such systems would be capable of self-assessment and self-correction, crucial for applications where human oversight is limited or impractical.
Human Organization + AI System as an HRO
: This scenario integrates AI systems within human-operated organizations that follow HRO principles. The synergy between human expertise and AI capabilities can enhance the overall reliability and responsiveness of the organization.
Conclusion
Dietterich���s approach advocates for a proactive and systematic application of HRO principles to the development and operation of AI systems. This not only aims to mitigate risks but also enhances the ability of AI systems to handle unexpected challenges effectively. As AI technology continues to evolve and integrate into various sectors, adopting such high-reliability frameworks will be critical in ensuring these systems are safe, dependable, and capable of adapting to complex operational environments.
4
Dijiste:
Designing AI Systems to be HROs: 
Designing AI Systems to be HROs: 
Situational 
AwarenessSituational 
Awareness 
��� Probabilistic models provide a powerful and well-understood method 
for tracking the state of a system 
��� ������������������������������������������������������������������������ ������������������������������������ ������������������������������������ 1,���,������������������������������������������������������������������������ = ������������������������������������������������������������������������ 0 ��������������������������������������� =1 
������������������������������������ ������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ ���1 ������������������������������������ (������������������������������������ ������������������������������������ |������������������������������������ ������������������������������������ ) 
������������������������������������ 1 ������������������������������������ 2 ������������������������������������ 3 
������������������������������������ 1 ������������������������������������ 2 ������������������������������������ 3 
Dynamical 
Model 
Observation 
Model 
������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ ���1 
������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ 
State variables position, velocity, 
acceleration, ��� 
Observations: video, audio, GPS, cell 
signals, ��� 
5AI 
Ethics and Development Forum 2021 
Detecting Anomalies as Violated 
ExpectationsDetecting 
Anomalies as Violated Expectations 
��� Compare predicted observation ������������������������������������ (��� ������������������������������������ ������������������������������������ |������������������������������������ ������������������������������������ ) to actual observation ������������������������������������ ������������������������������������ 
��� Surprisal: ���log������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ 
��� Distance: ��� ������������������������������������ ������������������������������������ ��� ������������������������������������ ������������������������������������ 
��� Difference in state space: compare �������������������������������������� ������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ ���1 to �������������������������������������� ������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ 
��� Point difference: �� ������������������������������������ ������������������������������������ ��� �� ������������������������������������ ������������������������������������ 
��� Distributional distance: ������������������������������������ �������������������������������������������������������������������������� ������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ ���1 ,�������������������������������������� ������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ 
������������������������������������ 1 ������������������������������������ 2 ������������������������������������ 3 
������������������������������������ 1 ������������������������������������ 2 
��� ������������������������������������ 3 
������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ ���1 
������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ 
������������������������������������ 1 ������������������������������������ 2 �� ������������������������������������ 3 
������������������������������������ 1 ������������������������������������ 2 ������������������������������������ 3 
������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ ���1 
������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ 
������������������������������������ 3 
���? 
�� ������������������������������������ 3 
���? 
6AI 
Ethics and Development Forum 2021 
Deep Learning 
Challenge:Deep 
Learning Challenge: 
Learned 
RepresentationsLearned 
Representations 
��� Deep Learning creates its own 
representations (e.g., for ������������������������������������ and ������������������������������������ ) 
��� These do not always give useful 
distances or probability densities 
��� This makes it difficult to compute 
��������������������������������������� ��� �� ������������������������������������ 
��������������������������������������� ��� ��� ������������������������������������ 
��� etc. Learned representations of 
���6 known categories (dark colors) 
���4 novel categories (light green) 
7AI Detecting Near 
MissesDetecting 
Near Misses 
��� Near Miss: ���If I had taken a slightly different action, the result would 
have been much worse��� 
��� This is a ���counter-factual��� statement and requires a causal model (Pearl, 
2009) 
��� The model can be analyzed to measure sensitivity of the outcome to small 
changes in the inputs 
��� Very little research in this area 
8AI 
Ethics and Development Forum 2021 
Formulating Hypotheses and 
Formulating Hypotheses and 
Implementing 
FixesImplementing 
Fixes 
��� Search in a space of model changes to 
find a model that can account for the 
observations 
��� What if no such modification can be 
found? 
��� Can AI systems ���think outside the box���? 
��� Hypothesize and refine novel properties, 
structures, relationships, causal 
pathways? 
��� Existing work focuses on a narrow set 
of models. Example: Digital circuits 
��� Substitute gate (NAND ���AND) 
��� Add/remove connection 
��� Add/remove path to ground 
Model 
Modification 
Operators 
��������� 0 
��������� 1 
��������� 2 
��������� 3 
��������� 4 
��������� 5 
������������������������������������ ������������������������������������ 4 
������������������������������������ ������������������������������������ 2 
������������������������������������ ������������������������������������ 2 
������������������������������������ ������������������������������������ 3 
������������������������������������ ������������������������������������ 7 
9AI 
Ethics and Development Forum 2021 
Designing a Human + AI Team to be an 
HRODesigning 
a Human + AI Team to be an HRO 
��� Every AI system will be surrounded by a 
human team 
��� Risk that inserting AI technology into a 
human HRO may destroy its reliability 
��� Historical example: Aircraft Autopilots 
��� Autopilot is a primitive type of AI system 
��� The autopilot had poor situational awareness 
��� co-pilot needed to enter waypoint coordinates 
into the autopilot system 
��� Pilots had poor insight into the state of the 
autopilot system 
��� Result: crashes during hand-off from 
autopilot to human pilots
ChatGPT dijo:
ChatGPT
In Thomas G. Dietterich���s presentation on designing AI systems to be High-Reliability Organizations (HROs), several critical concepts and methodologies are outlined to enhance the reliability of AI systems. Here���s an overview of the main ideas and approaches discussed:
Situational Awareness
Probabilistic Models
: Dietterich emphasizes the use of probabilistic models for tracking the state of a system. This involves creating mathematical frameworks that can represent uncertainties in system states and observations, allowing for better situational awareness. The models include:
Dynamical Models
: These describe how state variables (like position, velocity, and acceleration) change over time.
Observation Models
: These incorporate various types of observations (e.g., video, audio, GPS) to update the system's understanding of its state.
Detecting Anomalies as Violated Expectations
Anomaly Detection
: To ensure high reliability, AI systems must be able to detect when something goes wrong. This involves:
Comparing Predicted and Actual Observations
: By evaluating discrepancies between expected and actual observations, the AI can identify anomalies.
Quantifying Surprisal and Distance
: Metrics like surprisal (-log probability) and state differences help assess how far actual observations deviate from predictions, guiding the system in recognizing unexpected events.
Deep Learning Challenges
Learned Representations
: While deep learning allows AI to create its own representations of data, these representations may not always support effective distance or probability calculations. This complicates the detection of anomalies and the formulation of hypotheses since:
Learned representations might not accurately reflect the relationships or probabilities necessary for reliable decision-making.
Detecting Near Misses
Counterfactual Analysis
: Near misses represent situations where different actions could have led to worse outcomes. To analyze near misses, AI systems must:
Utilize causal models to understand how small changes in inputs can significantly alter outcomes.
Conduct research in this area to establish methods for AI to evaluate sensitivity to changes effectively.
Formulating Hypotheses and Implementing Fixes
Model Modification and Hypothesis Testing
: AI systems should be able to search for potential modifications to models to account for unexpected observations. Key challenges include:
Exploring a diverse space of model changes and considering innovative solutions, rather than relying solely on existing frameworks.
Developing the ability for AI to "think outside the box" to propose and evaluate novel causal relationships or structural modifications.
Designing Human + AI Teams as HROs
Human-AI Interaction
: Recognizing that AI systems will function within human teams is crucial for reliability. Dietterich points out:
The introduction of AI must enhance, rather than undermine, the reliability of existing HROs. Historical examples, like aircraft autopilots, illustrate potential pitfalls:
Autopilots often lacked adequate situational awareness and required human input to function effectively.
Poor transitions between AI control and human operation have led to accidents, highlighting the need for clear communication and understanding of AI states.
Conclusion
Dietterich���s framework emphasizes the importance of integrating HRO principles into AI system design to ensure reliability and safety. By adopting methodologies for continuous situational awareness, anomaly detection, hypothesis generation, and fostering effective human-AI collaboration, AI systems can achieve higher reliability and be better equipped to operate in high-stakes environments. The overall goal is to create AI systems that can autonomously maintain high reliability while effectively collaborating with human operators.
1/2
4o mini
Dijiste:
HumanHuman- -AI Situational 
AwarenessAI 
Situational Awareness 
��� The Human is aware of some aspects 
of the world 
��� The AI is aware of some aspects of the 
world 
��� Human must have an accurate model 
of the AI 
��� AI must have an accurate model of the 
humanObservation and 
Communication 
11AI 
Ethics and Development Forum 2021 
Anomaly and Near Miss 
DetectionAnomaly 
and Near Miss Detection 
��� AI must model the humans as well as the physical system 
��� detect unusual behavior of the humans 
��� detect near miss events (e.g., where humans almost made a serious mistake) 
������������������������������������ 1 ������������������������������������ 2 ������������������������������������ 3 
������������������������������������ 1 ������������������������������������ 2 ������������������������������������ 3 
Dynamical 
Model 
Observation 
Model 
������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ ���1 
������������������������������������������������������������������������ ������������������������������������ ������������������������������������ ������������������������������������ 
State variables include state of each 
human and AI 
Observations: video, audio, chat 
between team members 
12AI 
Ethics and Development Forum 2021 
Formulating Hypotheses and Implementing 
Formulating Hypotheses and Implementing 
FixesFixes 
��� Human and AI system must work together to construct and 
evaluate hypotheses 
��� How can the humans communicate hypotheses to the AI system? 
��� The AI system needs to be able to represent outside-the-box hypotheses 
��� How can the AI system communicate its hypotheses to the 
humans? 
��� Hypotheses must be interpretable to the humans 
��� How can the AI system support improvisational problem solving? 
��� Probably need to practice working with humans

Missing Technology for 
HumanMissing 
Technology for Human- -AI HROsAI 
HROs 
��� Deep language understanding 
��� Complex conversations 
��� Recursive Theory of Mind 
��� Methods for expanding the model space 
��� Models of human improvisational problem solving 
��� Models of human behavior (especially in high-stress situations) 
14AI 
Ethics and Development Forum 2021 
Fundamental 
ConclusionFundamental 
Conclusion 
��� AI should not be deployed (either autonomously or as part of a human-AI 
joint team) until we can assure that they are highly reliable 
��� We must develop standards and measurement techniques for evaluating 
the reliability of AI and joint Human-AI systems 
��� In certain applications, it may not be feasible to achieve high-reliability 
��� self-driving cars? 
��� autonomous weapons systems? 
��� autonomous medical systems? 
��� We should not deploy AI in those applications 
��� risk of catastrophic failures 15AI 
Ethics and Development Forum 2021 
Bibliography 
��� Dietterich, T. G. (2019). Robust artificial intelligence and robust 
human organizations. Frontiers in Computer Science, 13(1), 1���3. 
��� Pearl, J. (2009). Causality. Cambridge University Press. 
��� Pearl, J., & Mackenzie, D. (2018). The Book of Why. Basic Books. 
��� Weick, K., Sutcliffe, K., & Obstfeld, D. (1999). Organizing for high 
reliability: Processes of collective mindfulness. In R. S. Sutton & B. M. 
Staw (Eds.), Research in Organizational Behavior (Vol. 1, pp. 81���123). 
Jai Press.
ChatGPT dijo:
ChatGPT
The concepts detailed in the section from the AI Ethics and Development Forum 2021 focus on enhancing situational awareness and improving the interaction between humans and AI in high-reliability settings. Here's an analysis of the key ideas and their implications for Human-AI collaborative systems:
Human-AI Situational Awareness
The framework emphasizes the need for both humans and AI to have a comprehensive understanding of each other's capabilities and limitations:
Human Understanding of AI
: It's crucial for humans to have an accurate model of what AI can perceive and decide. This understanding allows humans to predict AI behaviors and integrate AI contributions effectively into decision-making processes.
AI Understanding of Humans
: Similarly, AI systems need to develop sophisticated models of human actions, intentions, and potential errors. This two-way awareness is critical for ensuring that both entities can anticipate and support each other's actions accurately.
Observation and Communication Models
The integration of dynamic models and observation tools (like video, audio, and chat) facilitates continuous feedback between human team members and AI systems. This setup helps in tracking the state of each entity (human and AI) and ensures that all participants in the operation are kept up-to-date with the latest situational changes.
Anomaly and Near Miss Detection
Modeling Human Behavior
: AI systems should be capable of detecting unusual behavior in humans as well as identifying near miss events, where a human action could have led to a serious mistake but was avoided, often by chance. This capability is vital for preemptive interventions and learning from potential errors without the cost of actual failure.
Formulating Hypotheses and Implementing Fixes
Collaborative Hypothesis Evaluation
: Both humans and AI must be able to propose, communicate, and evaluate hypotheses together. This involves:
Communication
: Developing mechanisms for effective communication where humans can understand AI-generated hypotheses and vice versa.
Interpretability
: Ensuring that AI systems can explain their reasoning in ways that are understandable to human operators.
Improvisational Problem Solving
: AI should support and perhaps participate in human-like improvisational problem solving, which is often needed in dynamic, real-world scenarios.
Missing Technology for Human-AI HROs
The document highlights several areas where technology needs to advance to support effective Human-AI HROs:
Deep Language Understanding
: Crucial for nuanced and complex communications.
Recursive Theory of Mind
: Ability for AI to understand human beliefs and thoughts recursively and vice versa.
Expanding Model Space
: Technologies to enhance how AI systems and humans can expand their hypothesis spaces to include novel and out-of-the-box ideas.
Fundamental Conclusion
Reliability Standards
: Before deployment, AI systems, especially those in critical applications (like self-driving cars or autonomous medical systems), must meet stringent reliability standards.
Evaluation of Joint Systems
: There should be standardized methods to measure and evaluate the reliability of joint Human-AI systems.
Risk Management
: Applications with a high risk of catastrophic failures should avoid deploying AI until high reliability can be guaranteed.
This comprehensive approach to designing Human-AI systems as HROs emphasizes the importance of mutual understanding, robust communication, and the ability to adaptively respond to emergent situations. These systems must be developed with careful consideration of the ethical implications and potential risks to ensure they enhance, rather than impair, operational reliability in high-stakes environments.
4
Dijiste:
A kind of scathing and sardonic critique, called Low Reliability Organizations such as individual humans and animals where individual casual events are not isolated but situational and contingent and effects might not be seen for decades or hundreds of years.
ChatGPT dijo:
ChatGPT
A sardonic critique styled as "Low Reliability Organizations" (LROs), when applied to individual humans and animals, would highlight the inherent unpredictability and the often chaotic nature of individual behaviors and their long-term impacts. Here���s how such a critique might be structured:
Definition of Low Reliability Organizations (LROs)
LROs, in a sardonic sense, could be defined as systems or entities where processes are highly contingent, outcomes are uncertain, and actions taken may have unforeseen consequences that only manifest over extended periods. Unlike High Reliability Organizations that strive for utmost precision and predictability, LROs operate in a realm where causality is murky, and reliability is more of an ideal than a reality.
Application to Individuals and Animals
1. Unpredictability of Individual Actions:
Individual humans and animals are portrayed as LROs due to their unpredictable nature. Each decision and action is influenced by a complex confluence of genetic predispositions, environmental factors, and personal experiences, leading to highly situational and contingent behaviors.
2. Cascading Effects of Decisions:
Decisions made by individuals can have cascading effects that are difficult to predict or control. A decision made today might seem inconsequential but could lead to significant impacts years or even decades later. For example, lifestyle choices such as smoking can have health effects that don't appear until much later in life.
3. Isolation and Contingency:
Unlike in HROs where processes are designed to be isolated from disturbances to prevent cascading failures, in LROs, events are interconnected in ways that make isolation nearly impossible. For example, an individual���s mood can affect their decision-making processes, which in turn affect their interactions with others, potentially leading to wide-ranging effects on their social and professional networks.
4. Long-Term Consequences:
The effects of actions taken by individuals may not be apparent for decades, or they may influence generations to come, akin to ecological changes that slowly manifest over centuries. This long-term impact makes it challenging to trace back to specific decisions or actions, complicating efforts to learn from past mistakes.
Sardonic Elements
The critique might use sardonic humor to underscore the absurdity of expecting high reliability from inherently unpredictable entities like individual humans and animals. It could mock the idea of applying rigorous organizational principles to managing life���s chaos, suggesting instead that living systems are fundamentally designed to be unreliable and that this unreliability is what drives evolution and adaptation.
Conclusion
By framing individual humans and animals as LROs, this critique serves as a humorous yet insightful commentary on the limitations of applying organizational theories to biological entities. It highlights the nuanced and often whimsical nature of life, where unpredictability is not a bug, but a feature that enables complexity and diversity in the natural world. This perspective invites a more humble and perhaps a more curious approach to understanding life���s inherent unpredictability.
4
Dijiste:
MORTAL COMPUTATION: A FOUNDATION FOR 
BIOMIMETIC INTELLIGENCE 
Alexander Ororbia Karl Friston 
Rochester Inst i tute of Technology VERSES AI Research Lab 
Rochester, NY 14623 Los Angeles, CA 90016, USA 
ago@cs.rit.edu karl.friston@verses.ai 
ABSTRACT 
This review mot i vates and synthesizes research ef f orts in neuroscience-inspired art i i cial 
intelligence and biomimet i c comput i ng in terms of mortal computat i on. Specif i cally, we 
characterize the not i on of mortality by recast i ng ideas in biophysics, cybernet i cs, and cognit i ve 
science in terms of a theoret i cal foundat i on for sent i ent behavior. We frame the mortal 
computat i on thesis through the Markov blanket formalism and the circular causality entailed by 
inference, learning, and select i on. The ensuing framework ��� underwrit t en by the free energy 
principle ��� could prove useful for guiding the construct i on of unconvent i onal connect i onist 
computat i onal systems, neuromorphic intelligence, and chimeric agents, including sent i ent 
organoids, which stand to revolut i onize the long-term future of embodied, enact i ve art i i cial 
intelligence and cognit i on research. 
Keywords Mortal computat i on �� Biomimet i c intelligence �� Free energy �� Homeorhesis 
1 Introduct i on Life can only be understood backwards; but it must be lived forwards. 
-S��ren Kierkegaard [195] 
A key aspect of biomimet i cs is that of biomimicry or, rather, emulat i ng natural or biological systems, when craf t ing 
mathemat i cal, computat i onal processes or technological art i facts. This is done generally with the aim of solving a 
complex problem, potent i ally facilitat i ng bionics ��� and the engineering of a nature-oriented system ��� for real- 
world applicat i ons. It follows that biomimet i c and bionic intelligence research seeks to construct the cognit i ve 
funct i onality and processes that underwrite intelligence by imitat i ng or emulat i ng natural minds and brains, the 
products of countless centuries of evolut i on. 
Life itself serves as an unceasingly fecund source of inspirat i on, capturing the at t ent i on of countless theoret i cians 
and engineers; ranging from biology to physics ��� to philosophy to computer science. Living systems, from single- 
cell microorganisms to complex creatures such as plants and animals, of f er a remarkable example of how 
homeorhesis (and related not i ons of allostasis and autopoiesis) ��� the self-regulat i ng processes employed by 
biological systems to assemble and maintain themselves [71, 72, 53] ��� can support the emergence of adapt i ve and 
complex behavior. From the computat i onal point-of-view, homeorhesis shapes and directs the ���calculat i ons��� 
conducted by the organism as it interacts with its environment; specif i cally, its ability to infer, learn, and evolve. 
From the standpoint of cybernet i cs, emulat i ng the computat i onal propert i es of living systems goes far back, notably 
within the framework of self-reproducing cellular automata [345, 148, 335, 359]. 
Our central argument is that if the aim is to craf t mechanist i c, computat i onal systems capable of the vast array of 
animal or human-like behaviors, the thrust of machine intelligence will need to change over the coming decades, 
similar in spirit to the call for a shif t from symbolic to non-symbolic processing [107, 106, 26], which mot i vated 
classical connect i onism and stat i st i cal learning. Machine intelligence research may need to focus on the processes 
that realize its nonlinear self-organizat i on and ef i cient adaptat i on; such a move is towards the development of 
survival-oriented processing that embodies computat i onal not i ons of life/mortality, a sort of naturalist i c machine 
intelligence. Specif i cally, we argue that a crucial pathway ��� on the way to art i i cial general intelligence (AGI) ��� lies 
Preprint 
2 
in mortal comput i ng, a framework that we seek to develop in this art i cle, hoping to engage researchers pursuing 
the sciences of the art i i cial [311]. 
At this point, one might ask: what is mortal computat i on? ���Mortal computat i on���, originat i ng in [170] and further 
developed and advocated for in [262, 254], asserts that the mathemat i cal calculat i ons/processes that underlie 
informat i on processing in a biological or art i i cial system are inseparable from the physical substrate that 
implements and executes them, i.e., the ���sof t ware��� cannot be divorced from the ���hardware���. This stands in strong 
contrast with the not i on of computat i on in Computer Science: here, sof t ware is decoupled from hardware and 
sof t ware is ���immortal���, which means that it can be copied to dif f erent hardware and st i ll be executable. Any machine 
learning algorithm, which can be viewed as program that adjusts itself in accordance with data, also relies upon 
this separat i on (and is designed with this in mind). Furthermore, immortal computat i on means that a program, 
even an adapt i ve one, e.g., an ���intelligent system���, develops characterist i cs and acquires knowledge irrespect i ve of 
the medium upon which it is instant i ated. In contrast, mortal computat i on means that once the hardware medium 
upon which a program is implemented within fails, or ���dies���, the knowledge, behavior, and specif i c funct i onality, 
including its ���quirks���, will also cease to exist. This is much akin to what would happen to the knowledge/behavior 
acquired/developed by a biological organism once it is no longer able to maintain itself. 
We argue that, at least for AGI, it may be necessary to consider mortal computat i on, if not ent i rely abandoning 
immortal computat i on. Transit i oning to a kind of computat i on that is ti ghtly bound to its substrate���s fate might at 
fi rst appear unnecessary or even foolhardy; given that that such programs could be brit t le and lack the universality 
of t en sought in intelligent systems research. However, part i cularly when considering some of the pressing global 
challenges we face today, e.g., climate change, we will foreground the advantages that at t end mortal computat i on 
��� advantages which are dif i cult to realize in the context of immortal computat i on. Furthermore, ef f orts that 
embrace such a transit i on may fi nd useful developments surprisingly easy. In general, the phrase mortal 
computat i on af f ords many perspect i ves on one central truth ��� intelligent behavior, whether manifest in biological 
or art i i cial form, is inextricably intertwined with persistence in the face of an environment that could bring about 
its end. This important not i on unif i es many ideas that have been art i culated over the decades, across dif f erent 
disciplines, including philosophy, cybernet i cs, biophysics, computer science, cognit i ve science, and physiology, and 
has implicat i ons for a large swath of applicat i on domains in computat i onal neuroscience, neuromorphic comput i ng, 
and neurorobot i cs [79].
ChatGPT dijo:
ChatGPT
The abstract from Alexander Ororbia and Karl Friston presents a compelling and innovative perspective on integrating principles from biophysics, cybernetics, and cognitive science into artificial intelligence through what they term "mortal computation." This concept seeks to bridge the gap between biological intelligence and artificial systems by emphasizing the mortality of computation ��� the inseparability of software and hardware where the end of the physical medium also spells the end for the operational functions it supports. Here���s a deeper look into the key elements and implications of their thesis:
Mortal Computation
Definition and Concept
: Mortal computation posits that the computations underpinning information processing are intrinsically linked to the physical substrates that execute them. This contrasts starkly with traditional views in computer science, where software (seen as immortal) can be transferred and executed across various hardware systems without loss of functionality. In mortal computation, the demise of the hardware results in the loss of the software���s functionality, mirroring biological systems where the death of an organism results in the cessation of its cognitive functions.
Implications for Artificial General Intelligence (AGI)
: The authors argue that for AGI, considering mortal computation may be crucial. This approach might initially seem limiting due to the brittleness and lack of universality it implies for programs. However, they suggest that this very limitation could be beneficial, especially when tackling complex, real-world problems like climate change, where the coupling of computation to a physical substrate can result in more robust, adaptive responses.
Biomimetic Intelligence
Biomimicry in Computing
: The approach also heavily leans on biomimicry ��� emulating the computational properties of natural systems to solve complex problems. By mirroring the adaptive, self-regulating capabilities observed in biological entities, from single cells to complex organisms, biomimetic computing aims to achieve similar levels of resilience and adaptability.
Homeorhesis and Adaptation
: Central to this discussion is the concept of homeorhesis, the process by which biological systems maintain their trajectories within a dynamic environment through self-regulation. The authors connect this idea to computational systems, suggesting that AI, too, can be designed to self-regulate and adapt dynamically to its operational environment.
Theoretical Foundations and Methodologies
Markov Blanket Formalism and Circular Causality
: The mortal computation framework is structured around the Markov blanket formalism, which models the boundary between a system and its environment. This formalism supports the concept of circular causality ��� the continuous, reciprocal interactions between a system and its environment, encompassing inference, learning, and evolutionary selection.
Free Energy Principle
: Underpinning the framework is the free energy principle, which posits that all adaptive systems (biological and artificial) act to minimize the difference between predicted and actual states. This principle is foundational in explaining how systems can maintain stability and adaptiveness through prediction and correction mechanisms.
Applications and Future Directions
Neuromorphic Computing and Neurorobotics
: By applying mortal computation, the fields of neuromorphic computing and neurorobotics could see significant advancements. Systems designed under this paradigm would inherently possess capabilities for more naturalistic, adaptive responses, potentially leading to breakthroughs in how machines interact with and learn from their environments.
Sentient Organoids and Chimeric Agents
: The abstract hints at the revolutionary potential for creating sentient organoids and chimeric agents, which could further blur the lines between biological and artificial systems, providing deep insights into both artificial intelligence and cognitive science.
In summary, Ororbia and Friston���s work on mortal computation challenges conventional paradigms by proposing a model where the fate of computation is inherently tied to its physical embodiment. This concept not only aims to make artificial systems more life-like but also aligns machine behavior more closely with ecological and biological realities, thereby fostering a new era of truly adaptive, resilient artificial intelligence.
4
Dijiste:
Connections with our earlier discussion
ChatGPT dijo:
ChatGPT
Alexander Ororbia and Karl Friston's concept of
mortal computation
interestingly intersects with our earlier discussions on
High Reliability Organizations (HROs)
and the theory of
Low Reliability Organizations (LROs)
. Here are some specific connections:
1.
Reliability and Mortality in Computation:
Mortal Computation
proposes that AI systems should embrace their physical limitations and vulnerabilities (similar to biological organisms), where the end of the hardware results in the end of its computational functions. This acknowledges that like biological entities, systems can fail and cease to exist, challenging the traditional notion of perpetually reliable (immortal) software.
High Reliability Organizations (HROs)
, in contrast, strive to prevent failures through meticulous attention to potential faults and fostering resilience against operational mishaps. While HROs seek to manage and mitigate human errors within complex systems, mortal computation accepts and integrates the inevitability of system "death" into the AI's operational framework.
2.
Adaptation and Complexity:
Both
mortal computation
and
HROs
focus on adaptation to complex environments. Mortal computation leverages biological principles such as homeorhesis to maintain a trajectory towards stability in changing conditions, resonating with how HROs continuously adapt to avoid catastrophic failures.
Low Reliability Organizations (LROs)
, as we discussed, highlight the inherent unpredictability and situational nature of individual decisions, which may lead to unexpected long-term consequences. Mortal computation similarly integrates the unpredictability of life-like behaviors into AI, acknowledging that not all outcomes can be controlled or predicted.
3.
System Integration and Environmental Interaction:
Mortal computation
utilizes concepts like the Markov blanket formalism to delineate the interactions between a system and its environment, focusing on the circular causality of inference, learning, and selection. This reflects an HRO���s emphasis on sensitivity to operations and understanding the impact of external and internal changes on system reliability.
Both mortal computation and the critique of LROs emphasize the importance of understanding the broader context within which individual and system behaviors occur. This broader awareness can guide the development of systems that are both aware of and responsive to their operational environments.
4.
Philosophical and Ethical Implications:
The shift from immortal to mortal computation can be seen as a philosophical stance on the nature of intelligence and existence, much like the conceptual discussion surrounding LROs challenges our expectations of reliability and control in complex systems.
There are ethical implications in designing systems that inherently accept their mortality. This could lead to a new paradigm in how we build, deploy, and interact with technology, much like how understanding LROs changes our approach to managing and expecting reliability in human and animal behaviors.
In essence, the discussion of mortal computation adds a rich layer to our understanding of how artificial systems can be designed not only to mimic life's adaptive complexities but also its finite and inherently unpredictable nature. This parallels the ongoing discussions about HROs and LROs in the management of risk and reliability in human-centric systems.
4
Dijiste:
A Cognit i ve-Philosophical Grounding for Mortal Comput i ng: 5E Theory 
Thus far, we have established an implementat i onal view of mortal computat i on through biophysics and an analyt i c 
view of it through cybernet i cs. Building on these results, we now consider its cognit i ve-philosophical grounding. 
Concretely, we break down a mortal computer into its ���cognit i ve slices��� to manifest what we will call a 5E Theory of 
Cognit i on. In cognit i ve science, 4E cognit i ve theory [146, 337, 248] categorizes processing into four groups: 
embodied, enact i ve, embedded, and extended cognit i on. In this work, mortal computat i on is cast in terms of a 
form of 4E theory that we extend to include ���elementary cognit i on��� or, in biology, ���basal cognit i on���, which 
characterizes the behavior inherent to all living ent i i es based on funct i onality that existed prior to nervous systems 
[219, 224, 123, 124]. This gives rise to a 5E theory of cognit i on, depicted in Figure 4, described below: 
1. Elementary: Cognit i on stands on fundamental funct i ons and structures that enable act i ng and tracking aspects of a 
niche to ensure survival, i.e., fi nding food, avoiding danger, and to reproduce [229, 275] ��� this is basal cognit i on [219, 
224], which manifests through a system���s autopoiesis; 
2. Embodied: Cognit i on cannot be described in terms of abstract mental processes and representat i ons alone, i.e., it 
must involve the ent i re body/morphology of the living system (the body serves as a constraint on the brain and/or a 
distributor/realizer of cognit i on) [18, 128] ��� this is the embodiment thesis [18, 9, 128, 342, 308]; 
3. Enact i ve: Cognit i on is the set of meaningful relat i onships determined by an adapt i ve two-way exchange between the 
biological and phenomenological complexity of living creatures and the environments they inhabit and act i vely shape 
[291, 331, 147] ��� this is enact i vism; 
4. Embedded: Cognit i on is not an isolated event, separated from the living ent i ty���s econiche, i.e., an ent i ty displays layers 
of co-determinat i on with physical, social, and cultural aspects of the world [329, 82, 63, 278, 38] ��� this is situated 
cognit i on or situatedness [293]; and 
5. Extended: Cognit i on is of t en of l oaded into biological beings and non-biological devices to serve as funct i ons that 
would be impossible/too dif i cult to achieve by only relying on the agent���s own mental processes ��� this is extended 
mind theory [86, 356, 84, 185] (the mind extends beyond the boundaries of an individual). 
11 This is a more physical, grounded manner in which to interpret the cybernet i cal not i on of variety. 
Preprint 
13 
Not i ce that, when account i ng for all fi ve of its tenets, the above 5E theory connects not only an ent i ty���s mental 
processes to its life-sustaining processes [339, 234], its body or morphological structure, and its biological niche 
but also to the collect i ve dynamics/processes beyond the individual system, e.g., mult i -agent groups, abstract 
organizat i onal constructs. This can include elements that are not physical manifestat i ons, e.g., social constructs and 
cultural expectat i ons that situate cognit i ve funct i on [293], as well as non-biological objects, e.g., technological 
art i facts such as pen/paper or intelligent phones.
ChatGPT dijo:
ChatGPT
The 5E Theory of Cognition outlined in the discussion of mortal computation provides a comprehensive, cognitive-philosophical grounding for understanding how AI and computational systems can be designed to interact more naturally and effectively within their environments. This extension of the well-established 4E theory includes an additional dimension���elementary cognition���which emphasizes basal or fundamental cognitive processes essential for survival in biological entities. Here���s a breakdown of each element and its implications for the design of computational systems:
1. Elementary Cognition
Concept
: Focuses on the basic survival functions such as finding food, avoiding danger, and reproduction, which are inherent to all living entities. This form of cognition is linked to autopoiesis, the process by which an organism maintains and renews itself.
Implication for AI
: By integrating elementary cognitive functions into AI systems, designers can ensure these systems are capable of autonomous self-maintenance and basic decision-making processes that prioritize survival and adaptation.
2. Embodied Cognition
Concept
: Argues that cognition cannot be separated from the physical body of the organism. The body influences and constrains the brain's cognitive processes and can itself be a medium of cognition.
Implication for AI
: Emphasizes the importance of designing AI systems that are aware of and can interact with their physical surroundings, ensuring that their "bodies" (hardware and form factors) are suited to the tasks and environments they are expected to operate in.
3. Enactive Cognition
Concept
: Views cognition as a product of the dynamic interaction between an organism and its environment. It stresses the significance of these interactions in shaping an entity���s cognitive abilities.
Implication for AI
: Suggests that AI systems should be capable of learning from continuous feedback loops with their environments, adapting their behaviors based on these interactions to enhance their functionality and effectiveness.
4. Embedded Cognition
Concept
: Recognizes that cognition is deeply influenced by the socio-cultural and physical contexts in which an entity exists. This situates cognition within a broader ecological and social framework.
Implication for AI
: Guides the integration of AI into broader systems, considering not just the individual AI���s capabilities but also how it interfaces with other agents, societal norms, and environmental factors.
5. Extended Cognition
Concept
: Proposes that cognitive processes can extend beyond the brain to include tools and other external devices, which become integral parts of the cognitive system.
Implication for AI
: Supports the design of AI systems that can seamlessly integrate and cooperate with other devices and tools, extending their cognitive reach beyond their immediate physical form.
Connecting to Mortal Computation
By applying the 5E theory to mortal computation, we can conceptualize AI not just as tools performing designated tasks but as integrated systems that exhibit life-like behaviors and cognitive processes. This approach champions a more holistic design philosophy, where AI systems are not isolated but are part of a larger, interactive tapestry involving biological and non-biological elements. The philosophical and practical implications of this approach advocate for AI systems that are deeply integrated into the fabric of life, capable of more natural interactions with human beings and other elements of their environment. This theory aligns closely with the principles of mortal computation by emphasizing the interconnectedness and interdependence of AI with the physical and social realms they inhabit, potentially leading to more sustainable, adaptable, and intuitive artificial systems.
4
Dijiste:
I discussed this concept with the pneumatic endomarrionettes which are robots made of paper and yogurt and can eat lawn mower mulch and paper in order to repair themselves
ChatGPT dijo:
ChatGPT
The concept of pneumatic endomarrionettes, as described, serves as a fascinating example of the principles laid out in the 5E Theory of Cognition, particularly aligning with
elementary
and
embodied cognition
within the context of mortal computation. These robots, crafted from unconventional materials like paper and yogurt, and capable of self-repair by consuming lawn mower mulch and paper, embody the concepts of autopoiesis and embedded cognition. Here���s how these unique features relate to the broader theoretical framework:
Elementary Cognition
Self-Maintenance
: The ability of these endomarrionettes to repair themselves by consuming available materials directly reflects the basal or elementary cognitive functions necessary for survival. This autonomous self-repair mechanism aligns with biological processes where organisms utilize available resources to maintain and repair their bodily functions.
Embodied Cognition
Material and Form
: The choice of materials (paper and yogurt) highlights the embodied aspect of cognition. These materials not only determine the physical structure and capabilities of the robots but also their interactions with the environment. The biodegradable and flexible nature of paper, combined with the biological properties of yogurt, could offer unique adaptive advantages in certain environments.
Embedded Cognition
Environmental Interaction
: By utilizing lawn mower mulch and paper, which are presumably abundant in their operational environment, the endomarrionettes are an example of embedded cognition. They are designed to operate within a specific ecological niche, using its resources, which influences their operational strategies and survival mechanisms.
Enactive Cognition
Interactive Adaptation
: If these robots are designed to interact with their environments dynamically (responding to environmental changes or damage by seeking out repair materials), this would exemplify enactive cognition. Their survival and functioning would depend on continuous interaction with and adaptation to their immediate surroundings.
Extended Cognition
Utilizing External Resources
: The use of external materials (mulch and paper) for self-repair could also be viewed under the lens of extended cognition. These materials, while not originally part of the robot, become crucial components of their operational framework, effectively extending their cognitive and operational capacities.
Integration with Mortal Computation
These pneumatic endomarrionettes embody the concept of mortal computation through their inherent design limitations and dependence on their physical structure. Their functionality and survival are directly tied to their ability to maintain their structural integrity using resources derived from their environment. This ties back to the mortal computation's emphasis on the inseparability of hardware and software, where the "death" or degradation of the robot���s physical body (hardware) due to inability to repair would lead to the cessation of its functionality (software).
Incorporating these designs into AI and robotics research can lead to the development of more sustainable, adaptive, and ecologically integrated robots. Such designs challenge traditional robotics paradigms and push the boundaries of how we conceptualize and implement robotic and artificial systems, making them more life-like and capable of integrating seamlessly into human and natural environments.
4
Dijiste:
Ororbia states elsewhere: so what are the

role of um Markov blankets in Mortal

computation a everything so I again as

you said earlier forian uh so we cast

mortal computation and that's where uh

again mortal computation can be probably

done and hopefully we Inspire other

generations to carry this further um but

that was our first formalism to say that

because we are in the act of trying to

avoid thermodynamic

disintegration uh we can also say

identity is all about boundary

preservation so the free energy

principle and there's a lot of different

ways to speak about it um is that you

have internal density dynamics that are

conditionally independent of the

environment and conditional means you

need something else to be conditional on

that's the markov blanket it's that

boundary that has active in sensory

States and this is where you can see how

active inference is also a part of this

Mortal computation is naturally

integrated it's just another correlator

that depends on you need active

inference you need active sample

selection uh and you're always and it

also has that flavor or that notion of

self- evidencing right that's also one

of Carl's favorite words and I've

embraced his favorite words um but uh

it's the idea that you're preserving

that Mark of blanket you are essentially

interacting that world through those

sensory States through or perceiving

those sensory States through the active

States um and you are preserving your

internal density Dynamics and so uh

mortal blankets is the formalism to

describe how this works and as I'm sure

you're also very familiar with you can

Nest them so this is how you start to

build nested or hierarchical or complex

systems out of Marco blankets you have

markof blankets of markov blankets of

markov blankets and that gives us a a

beginning point but only the starting

point towards how you'd begin designing

the atomic elements of a mortal computer

and you could think of them all as well

little cells are essentially markof

blankets or at least that's the

interpretation because of my work with

Carl I chose to embrace um and cells

have their internal you know components

their Dynamics and that's the thing that

they are preserving the boundary is the

cell wall that's their markcov blanket

then we have our Niche and it's very

important to account for what the niche

is to Mortal computation says the type

of mortal computer has depends on where

it is right um and you're in this

process of energy exchange and substrate

exchange as well and removing toxins and

that's what cells are in the business of

doing and I think that's a great place

to start for thinking about what are the

fundamental elements of how we could

build intelligence systems and it could

look towards cells I mean maybe we build

artificial they don't have to be I mean

I do like Mike's work on xenobots and

anobot and they are mortal computers

according to our framework too they are

great examples of work that's been done

um but we could look to that and maybe

study the principles of xenobots and

then um essentially building nested

systems of markov blankets I think
ChatGPT dijo:
ChatGPT
Alexander Ororbia's discussion about the role of Markov blankets in mortal computation provides a profound insight into the foundational elements of this emerging field. By integrating concepts from biophysics, cybernetics, and cognitive sciences, particularly through the lens of the free energy principle, Ororbia elucidates how identity and survival hinge on the ability to maintain boundaries ��� both physical and informational. Here���s a detailed exploration of these ideas:
Markov Blankets and Mortal Computation
Boundary Preservation
: A Markov blanket is a concept used to define the boundary between a system and its environment. It effectively describes how a system can remain conditionally independent from its external environment by having a boundary that only allows specific types of interactions. In the context of mortal computation, maintaining the integrity of the Markov blanket is crucial for sustaining the system���s identity and functionality.
Active Inference and Self-Preservation
: Active inference is a process where a system actively engages with its environment to obtain evidence (sensory inputs) that supports its continued existence. This process relies on the system's ability to make predictions about the world and update these predictions based on actual sensory feedback. In mortal computation, this is essential for the system to adapt and respond to changes, thereby preserving its Markov blanket and, by extension, its identity and internal dynamics.
Nested Hierarchical Systems
Complex Systems Design
: Ororbia highlights that Markov blankets can be nested within each other, forming hierarchical or complex systems. This nesting allows for the construction of systems where each layer or component has its own semi-independent identity but is part of a larger whole. Such an architecture mirrors biological systems where cells, organs, and organisms represent different layers, each with its own boundaries yet contributing to the overall organism's survival.
Application to Artificial Systems
Designing Intelligent Systems
: The principles outlined by Ororbia suggest a roadmap for designing intelligent systems that are robust and adaptive. By considering each component as a cell-like entity with its own Markov blanket, designers can create systems that are capable of maintaining their structure and function in dynamic environments.
Xenobots and Anobots
: The reference to xenobots and anobots as examples of mortal computers indicates a direction where synthetic biology intersects with artificial intelligence. These systems, which are designed to perform specific functions and interact with their environments in very controlled ways, represent practical implementations of mortal computation. They showcase how systems can be designed to handle tasks like energy exchange, substrate exchange, and toxin removal, analogous to biological cells.
Broader Implications
Philosophical and Practical Considerations
: The discussion also touches on philosophical implications about what constitutes the fundamental elements of intelligence and life. This might lead to new ways of thinking about AI, not just as tools or simulations but as entities with their own forms of 'life' and 'identity' that interact with and adapt to their environments.
Future Research Directions
: By studying systems like xenobots under the framework of mortal computation and nested Markov blankets, researchers can explore new forms of resilience and adaptability in artificial systems. This could lead to breakthroughs in how we design, implement, and deploy intelligent systems across various domains.
Ororbia's articulation offers a sophisticated framework that blends theoretical rigor with practical design strategies, opening up numerous possibilities for the future of AI and robotics. This approach promises to lead to more naturalistic and robust systems that mimic the adaptive, self-preserving characteristics of biological entities.
4
Dijiste:
Connections with our earlier discussions.
ChatGPT dijo:
ChatGPT
Alexander Ororbia's discussion of Markov blankets in the context of mortal computation deeply connects with our earlier explorations into High Reliability Organizations (HROs), Low Reliability Organizations (LROs), and the broader 5E cognitive framework. Here are some ways these discussions interlink:
1.
Boundary Management and Reliability
Markov Blankets and HROs
: HROs focus on managing boundaries through meticulous oversight and adaptation to avoid failures. Similarly, Markov blankets delineate a system's boundary, maintaining conditional independence by managing interactions between the system and its environment. This parallels HRO strategies of boundary management to ensure reliability and safety.
LROs and Adaptability
: In contrast, LROs, with their inherent unpredictability, could benefit from the concept of Markov blankets by better defining the interactions that lead to unreliable outcomes. Understanding these boundaries could help in predicting and managing the cascading effects of individual actions over time.
2.
Nested Systems and Organizational Complexity
Complex Systems in HROs
: HROs often operate as complex, nested systems where different layers (from individual roles to departmental structures) must interact reliably. Markov blankets provide a model for understanding these interactions as each layer or unit maintains its functionality while contributing to the overall system's goals.
Designing AI Systems with 5E Theory
: The nesting of Markov blankets mirrors the 5E cognitive framework, particularly in how extended cognition involves interactions beyond the individual's immediate cognitive processes. This nesting could inform how AI systems are designed to interact within larger ecological and social systems, enhancing their ability to function reliably in diverse environments.
3.
Cognition and System Design
Elementary and Embodied Cognition
: The basic functioning and survival mechanisms described in the 5E Theory can be understood through the lens of Markov blankets, which help a system maintain essential internal states necessary for elementary processes like energy and waste management. In AI, this could translate to systems that are better integrated with their physical environments, enhancing their embodied cognition capabilities.
Enactive and Embedded Cognition
: The interaction of a system with its environment, crucial in both enactive and embedded cognition, is managed through the Markov blanket by allowing only relevant environmental interactions to influence the system's internal states. This selective interaction is crucial for AI systems to be truly responsive and adaptive to their specific contexts.
4.
Practical Applications in AI and Robotics
Xenobots and Anobots as Models
: The discussion of xenobots and anobots as examples of systems embodying mortal computation aligns with the idea of creating AI and robotics that are not just tools but participants in their environments. These models exemplify how advanced AI can be grounded in biological principles, potentially leading to innovations in how AI systems self-maintain and adapt in real-world settings.
Ororbia's integration of Markov blankets into the discourse on mortal computation provides a robust theoretical and practical framework that enhances our understanding of how complex, adaptive systems can be designed and maintained. Whether in the form of high-reliability AI systems or more philosophically grounded approaches to machine cognition, these concepts offer valuable insights into creating more naturalistic, effective, and reliable systems.
4
Dijiste:
There were ancient mountain temples with instructions at the bottom of the stairs to bring up a bucket of rocks as you come up.
ChatGPT dijo:
ChatGPT
The practice of carrying a bucket of rocks up the stairs to ancient mountain temples is a compelling metaphor that encapsulates several profound concepts. This ritual could have been used as a form of physical and spiritual discipline, offering both literal and symbolic lessons for those undertaking the climb. Here are some potential interpretations and the significance behind this practice:
1.
Physical and Spiritual Endurance
Carrying a bucket of rocks up steep stairs is a task that requires considerable physical strength and endurance. This act serves as a physical trial or test, preparing the pilgrim mentally and physically for the sacred space they are about to enter. The difficulty of the task could symbolize the hardships one must endure in life, emphasizing that the path to enlightenment or spiritual fulfillment is neither easy nor without burden.
2.
Symbolism of the Rocks
The rocks in the bucket can symbolize various burdens or sins that one carries through life. By physically carrying them up the mountain and perhaps leaving them at the temple, this act can symbolize the release or absolution of these burdens. Alternatively, each rock could represent a prayer, wish, or offering, making the act of carrying them a deeply personal pilgrimage of faith and devotion.
3.
Meditative Practice
The repetitive and strenuous nature of climbing stairs with a heavy load can also serve as a form of moving meditation. The focus required to maintain balance and the rhythm of the steps can turn the action into a meditative practice, helping the climber to achieve a meditative state that enhances spiritual awareness and connection.
4.
Preparation for the Sacred
Entering a sacred space often requires preparation and purification. The physical act of carrying rocks up to a temple might serve to prepare the pilgrim by clearing the mind and focusing on the sacred experience ahead. It sets the tone for reverence, humility, and respect as one approaches the sacred space, physically manifesting the internal journey towards spiritual purity.
5.
Teaching Humility
The task could also be a lesson in humility, reminding the pilgrim of their place within the larger cosmos. The physical burden of the rocks, combined with the ascent to a high, often secluded temple, can make one feel small against the vastness of nature and the divine, fostering a humble attitude as one enters a place of worship.
6.
Community and Shared Burden
If this practice was a common requirement for all who ascended to the temple, it could also foster a sense of community and shared burden among pilgrims. Seeing others struggle with the same task can create a bond of mutual understanding and support, reinforcing social and spiritual connections within the community of believers.
These interpretations are rooted in the understanding that physical actions in religious practices are often loaded with deeper spiritual meanings, designed to engage the body, mind, and soul. This particular practice of carrying rocks to a mountain temple beautifully illustrates how physical exertion can be intertwined with spiritual quests, each enhancing the other to create a rich, multifaceted experience of devotion.
4
Dijiste:
Ok I thought it was an example of a system that maintains itself by making it easier to self repair
ChatGPT dijo:
ChatGPT
Ah, I see! The idea of carrying rocks up to an ancient mountain temple as a way of maintaining the structure itself offers a practical and literal interpretation that complements the symbolic ones. This pragmatic approach is indeed an example of a self-sustaining system that cleverly incorporates necessary maintenance work into a ritual act. Here���s a more detailed exploration of this interpretation:
Maintenance of the Physical Structure
By requiring visitors or pilgrims to bring rocks as they ascend, the temple ensures a steady supply of materials that can be used for its upkeep and repair. Mountain temples, often exposed to harsh weather and prone to erosion or other natural wear, would need regular maintenance. The rocks could be used to repair pathways, reinforce walls, or construct new parts of the temple. This system cleverly integrates the practical need for physical upkeep with the spiritual journey of the visitors.
Sustainability and Resource Efficiency
This method of maintenance is also an example of sustainable practice and resource efficiency. Instead of a dedicated team transporting materials up the mountain���which would be labor-intensive and costly���the burden is shared among many, making it part of the pilgrimage experience. It ensures that the resources needed for the temple���s upkeep are continuously replenished without extra effort or cost, leveraging the pilgrims' visits as a functional part of temple maintenance.
Community Participation in Upkeep
Incorporating the task of carrying rocks into the pilgrimage ritual also fosters a sense of community ownership and participatory upkeep. Pilgrims who partake in this practice may feel a stronger connection to the temple, knowing that they have contributed physically to its preservation. This act can strengthen the bond between the community and the temple, making its maintenance a shared responsibility rather than a centralized one.
Educational Value
For new visitors, the act of carrying rocks can serve as a tactile, memorable way to educate them about the importance of maintaining such sacred sites. It highlights the ongoing effort required to preserve cultural and historical heritage, making participants more aware of and appreciative of the work needed to sustain these important places.
Symbolic Representation of Contribution
While the physical contribution of bringing rocks helps maintain the temple, it also symbolically represents the visitors' contribution to the life and longevity of the temple. Just as the temple offers spiritual benefits to those who visit, the visitors reciprocate by supporting the temple's physical existence. This mutual exchange enriches the relationship between the temple and its visitors.
Viewing the practice through this lens offers a clear example of how ancient systems could ingeniously align practical and spiritual needs, creating a self-sustaining mechanism that ensures both the physical and spiritual upkeep of important cultural and religious sites. This pragmatic yet profound approach exemplifies how ancient wisdom can integrate maintenance and worship in a seamless, effective manner.
4
Dijiste:
I mean in terms of our earlier discussion, the temple is a self maintaining system if it also has instructions along the way on how to use the rocks to fill holes in the stairs, at the top on how to repair the temple, which makes it easier for other visitors. By making the temple more attractive it encourages further visitors
ChatGPT dijo:
ChatGPT
Absolutely, the concept of a self-maintaining temple where pilgrims contribute to its upkeep by carrying rocks and using them for repairs ties in closely with the discussions on High Reliability Organizations (HROs), Low Reliability Organizations (LROs), and principles of system design like those seen in mortal computation.
Connections to High Reliability Organizations (HROs)
Anticipation of Problems and Distributed Responsibility
: Just as HROs are characterized by their anticipation of potential failures and a distributed approach to responsibility, the temple system encourages all visitors to participate in maintaining the infrastructure. This proactive maintenance helps to prevent the deterioration of the temple and its paths, ensuring reliability and safety for all visitors.
Resilience through Community Involvement
: HROs prioritize resilience, often through redundancy and continuous adaptations. In the case of the temple, resilience is achieved through the ongoing contributions of rocks by visitors, which ensures that materials for repairs are always available, echoing the HRO practice of maintaining capacity for response to incidents.
Connections to Mortal Computation
System Survival and Adaptation
: In mortal computation, the focus is on how systems adapt to their environment and maintain their function until their eventual demise. The temple system, by instructing visitors to participate in its upkeep, turns the maintenance process into a communal adaptive strategy that extends the temple���s usability and lifespan, similar to how biological entities use resources from their environment to survive.
Nested Systems and Markov Blankets
: The temple and its visitors can be seen as nested systems where each visitor maintains their individual responsibility (their own "Markov blanket") while interacting with the larger system of the temple. The boundary conditions (the temple���s physical state) are continually updated by the actions of the visitors, reflecting the dynamic interplay described in theories involving Markov blankets.
Connections to Low Reliability Organizations (LROs)
Reduction of Unpredictability and Increase in System Reliability
: Although LROs often deal with unpredictability and the long-term effects of individual actions, the temple system mitigates these aspects by channeling individual efforts into structured, beneficial actions (repairing and maintaining). This structured participation transforms a potentially low reliability system (an unmaintained temple) into a higher reliability one through community effort and clear instructions.
Broader Implications
Cultural and Social Sustainability
: By making the temple more attractive and easier to visit, the system not only preserves the physical structure but also enhances its cultural and social significance. This increased attractiveness encourages more visitors, potentially boosting local tourism and fostering a deeper connection between the community and the temple.
Educational and Symbolic Value
: The act of contributing to the temple���s upkeep can serve as an educational experience about the importance of preservation and community effort, and it can also symbolize the shared responsibility we have towards cultural heritage.
This approach exemplifies how ancient practices can inform modern systems thinking by illustrating how distributed responsibility and proactive maintenance can enhance system reliability and sustainability. The temple becomes more than just a physical location; it embodies principles of resilience, communal effort, and continuous adaptation, which are crucial for the longevity and relevance of both cultural sites and modern organizations.
4
Dijiste:
I think the implication is that buildings can have agency
ChatGPT dijo:
ChatGPT
The concept of buildings having agency is a fascinating extension of the discussion around the self-maintaining temple system. It introduces a broader philosophical question about the nature of agency and how it might be attributed to non-living entities like buildings or other structures. Let's delve into this idea:
Agency in Buildings and Structures
Definition of Agency
: Typically, agency is attributed to entities capable of making decisions and taking actions independently. This usually applies to living beings. However, the concept of agency can be extended to buildings or structures if we consider their ability to cause effects or enact changes through their designed features or through interaction with their users.
Buildings Influencing Behavior
: Buildings can be said to have agency if we consider how they influence or control human behavior. For example, the design of a building can dictate the flow of movement within it, encourage or discourage interactions among its occupants, and even affect the mood and well-being of those people. The temple requiring visitors to carry rocks for maintenance could be seen as an exercise of agency, as the building directly influences visitor behavior to achieve specific outcomes (i.e., its own maintenance).
Interactive and Adaptive Buildings
: Modern architecture and smart building technologies allow structures to react to environmental conditions and the needs of their occupants. For example, buildings equipped with sensors and IoT (Internet of Things) devices can adjust lighting, temperature, and even physical spaces in response to how the spaces are being used. In this way, buildings are not just passive settings but active participants in providing comfort and functionality.
Buildings as Agents in a System
Systemic Impact
: The temple system, where the structure itself prompts visitors to contribute to its upkeep, showcases a form of systemic agency. Here, the temple is an agent within a larger system of cultural preservation and community engagement. It actively "recruits" visitors into its maintenance regime, sustaining itself through this loop of interaction.
Architectural Agency
: Architects often discuss the concept of a building having a "dialogue" with its surroundings. This can be extended to the idea of architectural agency, where the design of a building intentionally affects how it interacts with its environment and users. The temple���s design requiring rock carrying as part of the pilgrimage is an example where the architectural design extends beyond physical form to dictate specific user interactions.
Philosophical and Ethical Considerations
Ethical Implications of Building Agency
: If buildings are considered to have agency, there are ethical implications concerning their design and use. Designers and urban planners would need to consider how buildings influence users and take responsibility for those effects, which could include issues of accessibility, safety, and environmental impact.
Cultural and Community Agency
: Buildings like the temple also embody the cultural and communal agency, representing collective values and historical continuity. They act as custodians of heritage and play active roles in shaping cultural identity and community practices.
In summary, considering buildings as agents expands our understanding of their role in our lives. It highlights the dynamic interaction between human beings and their built environment and encourages more thoughtful, responsible design and interaction with our physical spaces. Buildings, through their design and the behaviors they engender, do indeed exercise a form of agency that impacts their users and the broader environment.
4
Dijiste:
I would say that an alphabet or a language can be a self-maintaining structure and can have agency if the letters are used to write literature explaining how to use the letters and demonstrating pragmatic utility
ChatGPT dijo:
ChatGPT
That's a compelling notion! Thinking of language, including its alphabet, as a self-maintaining structure that exhibits a form of agency is a sophisticated abstraction that aligns well with the way certain systems are conceptualized in both cognitive and information sciences. Here���s a breakdown of how this could be understood:
Language as a Self-Maintaining System
Self-Maintenance through Use
: Language maintains itself through its usage. As people use the language to communicate, they inherently reinforce its rules and norms. This occurs both in spoken and written forms. Literature, being a documented and often revered form of language use, plays a crucial role in this process. It not only preserves the language but also demonstrates its capabilities, nuances, and expressive power.
Evolution and Adaptation
: Languages evolve over time as speakers adapt and alter them to suit new circumstances and ideas. This evolution is also a form of self-maintenance as the language remains relevant and useful to its speakers. In this sense, literature (and other written records) acts as both a snapshot of the language at a certain time and a mechanism for introducing and popularizing new language forms and uses.
Agency of Language
Influencing Thought and Culture
: Language can be said to have agency in that it shapes and influences the thoughts, behaviors, and cultures of its users. The structure of a language, from its grammar to its vocabulary, can affect how people think���the Sapir-Whorf hypothesis, for example, suggests that the structure of a language influences its speakers' perception and categorization of the world.
Propagating Norms and Ideas
: Literature, as a use of language, can propagate social norms, values, and ideas. By demonstrating how language can be used, literature influences future uses of the language, thus guiding and maintaining the linguistic structure. It serves as an instructional tool not just in the direct sense���teaching how to use the language���but also in a broader cultural sense, teaching what can be expressed within the language and how.
Practical Examples
Literary Works as Language Guardians
: Classical literary works often preserve older forms of a language and can serve as reference points for both everyday language use and the language used in later literary works. For example, Shakespeare's plays in English or Dante���s "Divine Comedy" in Italian have both shaped and maintained the use of their respective languages through centuries.
Language as a Tool for Social Change
: Literature can also challenge linguistic norms and introduce new concepts that require new vocabulary or new uses of old words, thus actively participating in the evolution of the language. This kind of literature demonstrates language's agency in its capacity to effect change through communicating new ideas.
Ethical and Cultural Considerations
Responsibility of Speakers and Writers
: If language has agency, then those who use it���particularly influential users such as writers, politicians, and public figures���carry a responsibility for how they use this powerful tool. Their use of language can perpetuate stereotypes, incite violence, or alternatively, promote understanding and peace.
Cultural Preservation and Imperialism
: Languages can also act as agents of cultural preservation or as tools of imperialism. The spread of a dominant language can undermine and erode minority languages and cultures, reshaping them in profound ways.
Viewing language as a self-maintaining structure with agency provides a rich framework for understanding its dynamic role in human society. It highlights how language is not just a passive medium of communication but an active, evolving force that has a profound impact on social and cultural landscapes.
4
Dijiste:
Nexus and there'll be agency smuggling

to a certain extent because we'll be

kind of directing them and teaching them

yeah that's true yes but that will be

part of it you are right that we through

this uh manipulation or guiding you are

robbing of their agency to some degree

right but uh think that that's going to

happen if we embed them in you know the

world that we live in and we sort of

that's going to be the way you train a

mortal computer or at least a starting

point I mean there's an interesting

discussion there around um coherence

because of course you know nothing

exists um in in a vacuum right you know

we we're all embedded in in this in this

big soup together and and we influence

each other in very complex ways but we

should move on to your brain inspired

machine intelligence survey paper can

can you tell us about that because you

weren't not a fan of back prop no I'm

one of its strongest uh critics um okay

so biological or brain inspired

intelligence uh and it again there's

decades and Decades of work that we try

to review in that paper is this idea

that uh there's got there has to be a

way to play the credit assignment game

what do I mean by credit assignment it's

the blame game essentially when you have

an objective function which again that

means you can describe and write down

how performance you know is a function

of what you're looking for like oh if I


structure is depends on what's your

choice of morphology and how do you

write down the physics of that system if

you're going to simulate it you need to

be able to say what are the properties

of that morphology I mean all of this is

great so you're describing this kind of

distributed asynchronous predictive

processing architecture that can do um

you know learning and inference and and

even and even um structure learning as

well you know so it's very biometic it's

beautiful but let's let's have a

concrete example because let's say I I

built a mortal computer to control a

thermostat and and at some point because

you know like the the juer position here

is in the olden days software was

designed whereas this this type of

software kind of it's grown it it

emerges so I need to shape or tune or

optimize this thing to do what want it

to do how how do I do that okay so this

gets at something that Mike was also uh

Michael Lan was talking about

programmability or you know how do you

you know direct this and it's

interesting at first glance this is very

difficult to do with Mortal computation

because like you said growing it right

it is a uh an entity that now wants to

optimize its own directive right it

wants to preserve its own identity

you're not really at least at first

glance you're not in much control right

so I think it starts with how do you

specify first of all the environment in

which it exists because you need to

under you need to say what the niche is

what is the body that all these dynamics

that I've just described earlier are

going to occur and then of course you

can maybe write down and specify then

what was the inference learning and

selection I think that is your chance to

program what you want the system to

rough it's a very loose way there is no

like oh I want it to do a predictive

task like I would maybe the better way

to think about this actually I just

realized is if you think of it as a

living entity you would have to start

thinking of this how would you teach a

child to do a certain task right you

would be interacting with it so again

there is the part where Michael Levan

talks about you know the genetic

programmability that what I'm describing

is kind of like that foundational part

you can start at the beginning because

you get to play the role of sort of like

the Creator right you're we're also

skipping another part that you know you

could simulate but I'm not saying we

have to is all Evolution right you know

we we're going to skip ahead and say you

can install also the right priors and

the right inductive biases which are

morphology is going to encode some of

those priors right you're going to be

encode what are those homeostatic

variables that the system does so you

have control at that level but if you

wanted to do certain tasks right like

the machine learning Paradigm you

brought up supervised learning you'd

have to now interact with it as since

you are a mortal computer and we are

supposed to be in an environment of

mortal computers of all kinds

um you would be teaching it like a child

and I think this starts to get at things

like educational curriculums now we

don't talk about this in the P I think

that's a wonderful question that I

should give more thought to but I think

you would have to start treating it as

another entity and how would you

interact by training that right and say

uh if you show a child an object and you

say this is a block right now they are

learning that mapping as well you're

communicating with it you are also

dealing with another aspect of mortal

computation uh you're eded added with it

right so I do think that if we are

talking about things that want to also

serve Humanity we have to understand

that we're going to coexist with these

entities because if you don't want it to

just for example say I need to live and

uh to achieve that directive you're in

my way and we don't want negative

outcomes right we don't want destruction

we want these to benefit humanity and we

want to coexist peacefully uh with you

know the other Mortal computers uh we

need to think of it as we're going to be

a collective right because the other

part of this picture that mortal

computation by itself doesn't explain is

there's other Mortal computers and we

are in a collective system and then of

course there's the extended part we have

objects that are not mortal that

interact with this process so you would

be basically saying you want it to do

prediction uh you're going to be guiding

it as if you were guiding a fellow human

right to learn certain tasks what those

curriculums look like will not be

identical obviously to how humano human

interaction happens um but I think that

will change the fundamental Paradigm of

how we do things like supervised

learning um you can look to the

framework of reinforcement learning to

some degree as a a way to think about

how would we teach a computer to do

classification uh with positive and

negative reinforcement but again you got

to think about it as this is also going

to have that active inference element to

it and intrinsic curiosity is at play so

I could keep going on but I don't know

if that helps shape what you were

looking for what's really interesting I

spoke with Thomas par about this because

you know um he wrote a book on active

inference and an act of inference is

basically a theory of agency and to what

extent is it agency if we're kind of

telling it what to do and of course

these you know these mortal computers

will be embedded in in our cognitive

do classification uh accuracy or some

soft approximation the higher it is the

better it is or the lower it is the

better it is and vice versa um and so
ChatGPT dijo:
ChatGPT
The discourse around mortal computation, as discussed by Ororbia and others, intersects deeply with themes of agency, learning, environment shaping, and the coexistence of intelligent systems within human systems. The conversation touches on several sophisticated concepts that are crucial for the development of systems that are not only technically efficient but also socially and ethically integrated.
Key Concepts from the Discussion
1. Agency and Programmability in Mortal Computation
Defining Agency
: Agency in mortal computers involves their ability to act based on their programming and interactions with the environment. The concept of agency here is similar to active inference in cognitive science, where entities act in ways that minimize their free energy, essentially making decisions based on predictions of their environment.
Guiding Development
: The idea that these systems could be "taught" or "guided" like children introduces a dynamic of shaping these systems' behaviors through interaction rather than static programming. This reflects a more nurture-over-nature approach, akin to how humans learn and adapt.
2. Environment and Interaction
Role of Environment
: The environment in which a mortal computer operates defines much of its functionality and the scope of its agency. By specifying and designing the right environment, developers can influence how these systems evolve and respond.
Embedded Learning and Interaction
: The interaction with the environment and other agents (including humans) is crucial for the learning process of these systems. This interaction isn't just about data input but involves complex dynamics that include feedback, reinforcement, and adaptation.
3. Instructional and Evolutionary Development
Teaching as Interaction
: Similar to educating a child, teaching a mortal computer involves a continuous, dynamic interaction that helps shape its capabilities and functions. This method of teaching goes beyond simple command input and moves into a realm where behavioral norms, ethics, and social functionalities are imparted through ongoing interactions.
Coexistence and Collective Systems
: The acknowledgment that mortal computers will exist as part of a broader collective of similar agents emphasizes the need for systems that can not only operate independently but also coexist harmoniously with other agents and systems. This coexistence requires an understanding of shared spaces and mutual benefits.
Implications for System Design and Ethics
1. Ethical Programming and Design
By recognizing the inherent agency in mortal computers and their capacity to learn and adapt, developers and designers are tasked with the ethical responsibility to ensure these systems are programmed under guidelines that respect autonomy and promote beneficial behaviors.
Social Integration
: The design and programming should consider how these systems will integrate into human societal structures, ensuring they contribute positively and do not disrupt social norms or ethical standards.
2. Collective Dynamics and System Interactions
Understanding System Interactions
: As mortal computers are embedded in a "big soup" of interactions, understanding and designing for these interactions becomes crucial. This involves not just technical design but also understanding sociocultural dynamics.
Design for Coexistence
: Systems must be designed not only to fulfill their specific tasks but also to operate within a framework that considers other agents, both biological and synthetic. This requires a new kind of systems thinking that considers the ecology of intelligent agents.
3. Future Learning Frameworks
Beyond Supervised Learning
: The traditional paradigms of machine learning (like supervised learning) may need to be adapted or expanded to accommodate the type of interactive, dynamic learning processes suited to mortal computation systems. Concepts from reinforcement learning and active inference could provide foundational frameworks for these new learning paradigms.
4. Adaptation and Evolution
Systems should be capable of not only learning from the environment but also evolving with it. This adaptation involves not just updating algorithms but fundamentally evolving in response to environmental changes, much like biological entities.
This dialogue on mortal computation reflects a broader shift in how we conceive of and interact with intelligent systems, emphasizing a more integrated, responsive, and ethically aware approach to artificial intelligence.
4
Dijiste:
A list of all of the topics we've discussed.
ChatGPT dijo:
ChatGPT
Certainly! Here's a list of the topics we've covered in our discussion:
High Reliability Organizations (HROs)
Definition and characteristics of HROs
How HROs manage reliability and predictability
Low Reliability Organizations (LROs)
Concept and characteristics of LROs
Unpredictability and the long-term effects of individual actions within LROs
Mortal Computation
Definition and principles of mortal computation
How mortality influences the behavior and design of computational systems
Markov Blankets
Role in defining system boundaries in mortal computation
How they help maintain conditional independence from the environment
Agency in Buildings and Structures
Concept of buildings having agency through design and interaction
How architectural choices influence user behavior
Language as a Self-Maintaining Structure
How language maintains itself through use and evolves over time
The agency of language in influencing thought and culture
Ancient Mountain Temples and Self-Maintenance
Symbolic and practical reasons for pilgrims carrying rocks to temples
The temple as a self-maintaining system through communal effort
Brain-Inspired Machine Intelligence
Critiques of traditional machine learning techniques like backpropagation
The concept of credit assignment and its importance in learning processes
Teaching and Training Intelligent Systems
Analogies between teaching mortal computers and educating children
The role of environment and interaction in developing intelligent systems
Ethical and Social Implications of Intelligent Systems
Responsibilities in designing systems with agency
Social integration and collective dynamics of intelligent systems
Each of these topics delves into aspects of system design, reliability, agency, and the ethical implications of advanced computational systems and architectures. If there's any particular topic you'd like to revisit or explore further, let me know!
4
Dijiste:
We also discussed pneumatic endomarrionettes
ChatGPT dijo:
ChatGPT
Absolutely, let's include that in our recap:
Pneumatic Endomarrionettes
Description of robots made from unconventional materials like paper and yogurt, capable of self-repair by consuming lawn mower mulch and paper.
Reflection on how these endomarrionettes serve as an example of embodied and elementary cognition within the 5E Theory of Cognition.
These endomarrionettes illustrate innovative concepts in robotics and AI, tying into broader discussions about system maintenance, autonomy, and integration into environmental and cultural ecosystems. If you need more detail on any topic or another area connected to our discussion, feel free to ask!
4
Dijiste:
I wanted to describe an education system where each student experimented with terraformation schemes and technology trees and building code deployment strategies with civilization simulators and the best solutions were used to terraform our own planet
ChatGPT dijo:
ChatGPT
That's a fascinating and visionary idea for an education system, merging theoretical knowledge with practical application using simulation technologies. Here���s how you might describe this innovative education system:
Concept Overview
The education system is designed as a dynamic and interactive learning environment where students engage in a hands-on, experiential learning process centered around terraforming schemes, technology trees, and building code deployment strategies. The core of the curriculum uses advanced civilization simulators that allow students to experiment with and manage complex ecosystems and infrastructures in a controlled, virtual setting.
Educational Objectives
Critical Thinking and Problem Solving
: Students are challenged to think critically about environmental, technological, and societal challenges as they design and implement terraforming projects and infrastructure development.
Innovation and Creativity
: Encourages creativity in solving problems related to sustaining life on other planets, adapting and integrating new technologies, and optimizing resource use and sustainability.
Interdisciplinary Learning
: Combines elements from science, technology, engineering, mathematics (STEM), environmental science, and urban planning, providing students a holistic understanding of the interconnected systems within a civilization.
Implementation through Simulation
Civilization Simulators
: Students use sophisticated software that simulates the environmental, economic, and social dynamics of a planet. These simulators allow students to apply theoretical knowledge in virtual scenarios, exploring the consequences of different actions and strategies in real-time.
Technology Trees
: Part of the curriculum involves understanding and developing technology trees���diagrams that represent the sequential, multi-path strategies for technological development. Students learn to make strategic decisions about which technologies to pursue to best meet the environmental and societal needs of their simulated civilizations.
Building Code Strategies
: Students also explore building codes that are optimal for different environmental conditions and technological levels. They learn to craft and modify these codes to improve the efficiency, sustainability, and safety of infrastructure.
Feedback and Iteration
Testing and Feedback
: Each student���s project undergoes simulations to test its viability and effectiveness. Feedback is provided based on a set of criteria including sustainability, efficiency, and the ethical implications of the terraforming strategies.
Peer Review
: Students engage in peer review sessions where they present their strategies and receive feedback from classmates, fostering a collaborative learning environment.
Real-World Application
Implementation of Successful Strategies
: The most successful strategies and solutions developed by students could be considered for real-world application. This aspect of the program not only motivates students by showing the real-world impact of their work but also provides a platform for innovation in actual terraforming and urban planning projects on Earth.
Collaboration with Researchers and Planners
: The education system collaborates with scientists, urban planners, and policymakers, ensuring that the solutions proposed by students are grounded in current science and are practical for implementation.
Conclusion
This educational system aims to not only equip students with knowledge and skills but also to actively involve them in solving some of the most pressing challenges facing humanity. By harnessing the power of simulation technology, the program prepares students to contribute meaningfully to discussions and actions surrounding sustainable development and planetary management, potentially even shaping the future of real-world terraforming efforts on Earth and beyond.
4
ChatGPT puede cometer errores. Comprueba la informaci��n importante.
?

