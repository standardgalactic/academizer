Flexible Semantic Projections

ChatGPT 4 

User
SEMANTIC PROJECTION: 
RECOVERING HUMAN KNOWLEDGE OF MULTIPLE, DISTINCT 
OBJECT FEATURES FROM WORD EMBEDDINGS 
Gabriel Grand1*†, Idan Blank2*, Francisco Pereira3, and Evelina Fedorenko4,5† 
KEYWORDS: word embeddings; distributional semantic models; lexical semantics; concepts; semantic features; word co-occurrence 
ABSTRACT 
The words of a language reflect the structure of the human mind, allowing us to transmit thoughts 
between individuals. However, language can represent only a subset of our rich and detailed cog- 
nitive architecture. Here, we ask what kinds of common knowledge (semantic memory) are captured by word meanings (lexical semantics). We examine a prominent computational model that 
represents words as vectors in a multidimensional space, such that proximity between word- 
vectors approximates semantic relatedness. Because related words appear in similar contexts, such 
spaces – called “word embeddings” – can be learned from patterns of lexical co-occurrences in 
natural language. Despite their popularity, a fundamental concern about word embeddings is that 
they appear to be semantically “rigid”: inter-word proximity captures only overall similarity, yet 
human judgments about object similarities are highly context-dependent and involve multiple, dis- 
tinct semantic features. For example, dolphins and alligators appear similar in size, but differ in in- 
telligence and aggressiveness. Could such context-dependent relationships be recovered from 
word embeddings? To address this issue, we introduce a powerful, domain-general solution: “se- 
mantic projection” of word-vectors onto lines that represent various object features, like size (the 
line extending from the word “small” to “big”), intelligence (“dumb” → “smart”), or danger 
(“safe” → “dangerous”). This method, which is intuitively analogous to placing objects “on a 
mental scale” between two extremes, recovers human judgments across a range of object catego- 
ries and properties. We thus show that word embeddings inherit a wealth of common knowledge 
from word co-occurrence statistics and can be flexibly manipulated to express context-dependent 
meanings. 
1. INTRODUCTION 
When we say that we “know the meaning” of a word, what kind of knowledge do we mean we have? Words allow 
us to communicate the content of one human mind to another human mind: they are representations of mental struc- 
tures. More precisely, we use words to express concepts (Marr, 1982). Concepts organize our knowledge about 
regularities in the world – they are generalizations about the kinds of things that exist and the properties that they 
have. Words, in turn, associate such abstract knowledge with surface forms of sounds/letters, and differences be- 
tween word meanings correspond to distinctions that we can make between things in the world (Goldberg, 1995; 
Jackendoff, 2002; Murphy, 2004). Consequently, the psycholinguistic study of word meanings in the mental lexicon 
(lexical semantics; e.g., Steinberg and Jakobovits, 1971; Richards, 1982; Pinker and Levin, 1991) is tightly linked to 
the cognitive study of the architecture of world knowledge in the human mind (semantic memory; Quillian, 1966; 
Tulving, 1972). 
1 Department of Computer Science, Harvard University (ggrand@college.harvard.edu) 
2 McGovern Institute for Brain Research, Massachusetts Institute of Technology 
3 Medical Imaging Technologies, Siemens Healthineers 
4 Department of Psychiatry, Massachusetts General Hospital (evelina.fedorenko@mgh.harvard.edu) 
5 Department of Psychiatry, Harvard Medical School 
* Equal contribution 
† Corresponding author 
arXiv: 1802.01241v2 
[cs.CL] 
6 
Mar 
2018 2 
However, our world knowledge is broad, detailed and complex. Even an intuitively simple concept like DOG cap- 
tures rich information about the animal it refers to, e.g., its appearance, biological properties, behavioral tendencies, 
cultural roles, etc. However, only a subset of this conceptual knowledge is communicated by the word “dog” (for a 
review, see Gleitman and Papafragou, 2013). Therefore, any theory of lexical semantics should specify the kinds of 
world knowledge that are captured in the lexicon. Yet constructing such a theory based on behavioral studies of lan- 
guage processing is challenging: it requires a paradigm for probing only that subset of conceptual distinctions that 
constitutes the (lexical) semantics of the word “dog” without also activating the rest of our world knowledge that is 
captured by the concept DOG. 
Fortunately, a new insight into this problem is offered by computational methods that approximate a dissociation 
between lexical semantics and the rest of semantic memory: by granting a machine access only to word-forms, with 
no a-priori concepts, one can probe the semantic distinctions that are—in principle—available from the statistics of 
natural language alone. This approach relies on a hypothesis that dates back to the origins of modern linguistics, 
namely, that word meanings are determined by their patterns of usage, i.e., by the words they tend to appear with 
(De Saussure, 1916/2011; Wittgenstein, 1953/2010; Harris, 1954; Firth, 1957; Miller and Charles, 1991; for a 
review, see Sahlgren, 2008). Specifically, by tracking the distribution of word co-occurrences in multi-billion word 
corpora, unsupervised algorithms can learn a representation of word meanings as vectors in a multidimensional 
space where the proximity between these vectors increases with the co-occurrence probability of the corresponding 
words. The resulting space is called a “word embedding” or a “distributional semantic model” (for reviews, see 
Lenci, 2008; Turney and Pantel, 2010; Erk, 2012; Pereira et al., 2013; Baroni et al., 2014; Clark, 2015) (Bengio et 
al., 2003; Collobert et al., 2011; Huang et al., 2012). 
Recent research has shown that inter-word distances in word embeddings correlate with human ratings of semantic 
similarity (Mikolov et al., 2013; Pennington et al., 2014). Furthermore, these distances are geometrically consistent 
across different word pairs that share a common semantic relation. For instance, the location of 𝑚𝑎𝑛 relative to 
𝑤𝑜𝑚𝑎𝑛 is similar to the location of 𝑘𝚤𝑛𝑔 relative to 𝑞𝑢𝑒𝑒𝑛; This consistency allows for geometric operations to 
simulate conceptual relations, e.g., 𝑘𝚤𝑛𝑔 − 𝑚𝑎𝑛 + 𝑤𝑜𝑚𝑎𝑛 ≈ 𝑞𝑢𝑒𝑒𝑛 (Levy and Goldberg, 2014). These results 
demonstrate that, by simply tracking co-occurrence statistics, a machine with no a-priori concepts can obtain a lexi- 
con that contains certain kinds of semantic memory.
ChatGPT
This paper by Gabriel Grand et al. explores the intersection of human cognition, language, and computational models, specifically focusing on word embeddings—a method of representing words as vectors in a multidimensional space. The authors aim to uncover what aspects of human knowledge and semantic memory are captured by the meanings of words as represented in these computational models.

Word embeddings are trained on the basis of word co-occurrences in large corpora of text, with the underlying premise that words appearing in similar contexts have similar meanings. While these models successfully capture semantic similarity to a degree, the authors highlight a limitation: the embeddings tend to be "semantically rigid," meaning they primarily capture overall similarity and fail to account for the nuanced, context-dependent ways in which humans perceive relationships between concepts. For instance, while dolphins and alligators might be similar in terms of size, they vastly differ in attributes such as intelligence and aggressiveness.

To address this challenge, the paper introduces the concept of "semantic projection." This method involves projecting word vectors onto lines (or axes) that represent specific semantic features, ranging from physical characteristics like size (small to big) to more abstract qualities like intelligence (dumb to smart) or danger (safe to dangerous). By doing so, the approach aims to map out where different words fall along these spectrums, thereby recovering human-like judgments on a variety of object categories and attributes.

Through this innovative approach, the paper demonstrates that word embeddings, despite their initial limitations, can indeed be manipulated to reflect the complex, multi-faceted nature of human semantic memory. This finding not only enriches our understanding of how computational models can mirror human cognition but also opens up new avenues for enhancing the flexibility and applicability of word embeddings in natural language processing and beyond.

The research conducted by Grand and colleagues stands as a testament to the ongoing dialogue between cognitive science and computational linguistics, showing how insights from each field can contribute to more sophisticated and human-like artificial intelligence systems.

User
con that contains certain kinds of semantic memory. 
Despite these impressive capabilities, word embeddings appear to have a fundamental limitation: the proximity be- 
tween any two word-vectors captures only a single, semantically “rigid” measure of overall similarity. In contrast, 
humans evaluate the conceptual similarity between items in semantic memory flexibly, in a context-dependent man- 
ner. Consider, for example, our knowledge of dolphins and alligators: when we compare the two on a scale of size, 
from “small” to “big”, they are relatively similar; in terms of their intelligence—on a scale from “dumb” to 
“smart”—they are somewhat different; and in terms of danger to us—on a scale from “safe” to “dangerous”—they 
differ significantly. Can such distinct, multiple relationships be inferred from word co-occurrence statistics? If so, 
how is such complex knowledge expressed in a word embedding? 
Here, we suggest that such conceptual knowledge is implicitly embedded in the structure of word embeddings and 
we introduce a powerful, domain-general solution for extracting it: “semantic projection” of word-vectors onto “se- 
mantic subspaces” that represent different features. For instance, to recover the similarities in size among nouns in a 
certain category (e.g., animals), we project their representations onto the line that extends from the word-vector 
𝑠𝑚𝑎𝑙𝑙 to the word-vector 𝑏𝚤𝑔; to compare their levels of intelligence, we project them on the line connecting 𝑑𝑢𝑚𝑏 
and 𝑠𝑚𝑎𝑟𝑡; and to order them according to how dangerous they are, we project them onto the line connecting 𝑠𝑎𝑓𝑒 
and 𝑑𝑎𝑛𝑔𝑒𝑟𝑜𝑢𝑠 (for an animation of this procedure, see: Animated Semantic Projection Demo). We demonstrate 
that the resulting feature-wise (“context-dependent”) similarities robustly predict human judgments across a wide 
range of everyday object categories and semantic features. These results provide evidence that rich conceptual 
knowledge can be extracted bottom-up from the statistics of natural language, and it can be readily recovered from 
word embeddings with a simple and elegant method. 
2. MATERIALS AND METHODS 
Our experiment tested whether semantic projection (section 2.2.2) could recover context-dependent conceptual 
knowledge. To operationalize context-dependent knowledge, objects from a certain semantic category (e.g., ani- 
mals) were rated based on different semantic features (e.g., size, intelligence, or danger). Namely, we chose several 
object categories along with semantic features that characterized them (section 2.1) and evaluated the ratings of cat- 
egory items along each feature in two ways: by collecting such ratings from humans, and via semantic projection in 
3 
a word embedding that was created with Global Vectors for Word Representation (GloVe; Pennington et al., 2014). 
Our test then compared these two sets of feature-specific ratings. 
2.1. SEMANTIC CATEGORIES AND FEATURES 
We created a dataset of categories and features that met four criteria: (i) each category consisted of concrete ob- 
jects/entities; (ii) each category was semantically associated with several features (to evaluate whether semantic pro- 
jection generalized across features); (iii) each feature was semantically associated with several categories (to evalu- 
ate whether semantic projection generalized across categories); (iv) categories and features spanned diverse aspects 
of everyday semantic knowledge. All categories and their constituent items were selected from an extensive set of 
nouns, generated for a large-scale study on lexical memory (Mahowald et al., 2014). 
2.1.1. CATEGORIES 
Our dataset consisted of 9 semantic categories: animals, clothing, professions, weather phenomena, sports, mytho- 
logical creatures, world cities, US states, and first names. These categories have been used in feature-elicitation 
studies, with varying degrees of prevalence (Paivio et al., 1968; Battig and Montague, 1969; Cree and McRae, 2003; 
McRae et al., 2005; Pereira et al., 2013; Binder et al., 2016): the first four have been frequently used; the next two— 
less frequently; and the last three have been rarely used but, unlike the other categories, consisted of proper nouns 
and, moreover, shared some features with the other categories. Items in all categories were used as cues in the word- 
association study of Nelson et al. (2004).6 
Most categories consisted of 50 representative items (e.g., the clothing category contained words like “hat,” “tuxe- 
do,” “sandals,” and “skirt”; the full dataset is reproduced in the Appendix). The only exceptions were the categories 
of animals, which consisted of 34 items; weather, which consisted of 37 items; and professions, which consisted of 
49 items. In order to ensure that items were representative of their respective categories, we chose within each cate- 
gory the 50 most frequent nouns according to the SubtlexUS Word Frequency Database (Brysbaert and New, 2009) 
(candidate items consisted of all the relevant nouns from Mahowald et al., 2014). We discarded multi-word expres- 
sions (except for US States, e.g., “North-Dakota”) and words that did not appear in the vocabulary of the word em- 
bedding (section 2.2.1). 
For two categories, additional selection criteria were used in order to increase the variability for the “gender” fea- 
ture: for the first names category, we chose the 20 most common male names, 20 most common female names, and 
10 most common unisex names from the past 100 years, based on public data from the US Social Security Admin- 
istration.7 For the professions category, efforts were made to balance the items by gender, because the majority of 
the most frequently occurring profession names were traditionally male. 
2.1.2. FEATURES 
Our dataset included 17 semantic features, each associated with a subset of the categories above: size, temperature, 
valence, loudness, speed, location, intelligence, wetness, weight, wealth, gender, danger, age, religiosity, political 
leaning, cost and arousal. These features have been produced in feature-elicitation studies with varying degrees of 
prevalence (Cree and McRae, 2003; McRae et al., 2005; Binder et al., 2016): the first four—almost invariably; the 
next three—frequently; the next six—less frequently; and the last four—very rarely. Words describing possible val- 
ues of all features (e.g., “big” and “small” for the size feature), were used as cues in the word-association study of 
Nelson et al. (2004).
ChatGPT
The study by Grand et al. delves deeper into the methodology of extracting multi-faceted, context-dependent knowledge from word embeddings, a computational approach to understanding linguistic semantics. The authors aim to bridge the gap between the "semantically rigid" nature of word embeddings and the fluid, context-sensitive conceptual knowledge that humans possess. This section outlines the experimental setup and the novel technique of semantic projection, which they propose as a solution to this challenge.

Semantic Projection Technique
The core innovation introduced in this paper, semantic projection, involves mapping word vectors onto specific "semantic subspaces" that correspond to different features or attributes. For example, to understand how various animals compare in terms of size, their word vectors are projected onto a line that spans from the vector for "small" to "big". This process is repeated for various attributes, such as intelligence (from "dumb" to "smart") and danger (from "safe" to "dangerous"). The projections enable the quantification of these attributes in a way that mirrors human judgment more closely than traditional word embeddings.

Experimental Design
The authors' experimental design involves the comparison of human ratings with those derived from semantic projection on word embeddings. They select a range of semantic categories (e.g., animals, clothing, professions) and associated features (e.g., size, intelligence, danger) to cover a broad spectrum of everyday semantic knowledge. These categories and features were chosen based on their representation in past studies and datasets, ensuring a comprehensive analysis across diverse aspects of semantic knowledge.

Categories and Features
The study utilizes nine semantic categories, including tangible objects like animals and clothing, as well as abstract entities like professions and weather phenomena. Each category is associated with multiple features, which are expected to vary across and within categories. The features include tangible attributes like size and weight, as well as abstract ones like intelligence and danger. This selection ensures a rich dataset that can robustly test the generalizability of semantic projection across different contexts.

Methodological Rigor
By grounding their experimental setup in established linguistic and cognitive datasets, and by meticulously selecting categories and features that span a wide range of semantic knowledge, the study sets a strong foundation for exploring the depth of information that can be recovered from word embeddings. The inclusion of proper nouns, such as world cities and first names, alongside common nouns, introduces an additional layer of complexity, challenging the semantic projection method to accurately capture and differentiate a broad spectrum of semantic relationships.

Significance
This methodological approach signifies an ambitious step towards understanding and leveraging the latent semantic knowledge embedded within word embeddings. By attempting to align computational models more closely with human conceptual knowledge, the study addresses a critical gap in natural language processing. The successful implementation of semantic projection could not only enhance the interpretability and applicability of word embeddings but also provide new insights into the structure of semantic memory and the nature of conceptual knowledge itself.

User
The Case Against Linguistic Palaeontology 
Fintan Mallory1 
Published online: 12 February 2020 
© The Author(s) 2020 
Abstract 
The method of linguistic palaeontology (or palaeolinguistics) has a controversial status within archaeology. According to its 
defenders, it promises the ability to see into the social and material cultures of prehistoric societies and uncover facts about 
peoples beyond the reach of archaeology. Its critics see it as essentially fl awed and unscientif i c. Using a particular case-study, 
the Indo-European homeland problem, this paper attempts to discern the kinds of inference which proponents of linguistic 
palaeontology make and whether they can be warranted. I conclude that, while the case for linguistic palaeontology has often 
been overstated, so has the case against it. 
Keywords Linguistic palaeontology · Wörter und Sachen · Proto-Indo-European · Historical linguistics 
In 1710, the same year he published his proof that we were 
living in the best of all possible worlds, Gottfried Wilhelm 
Leibniz wrote an article on linguistics in which he argued 
not only that the Germanic and Celtic languages were 
descended from a common ancestor but that this common 
ancestor shared a further ancestor language with all Turk- 
ish, Slavic, Finnish and Greek languages. While he was 
wrong to lump the Finnish and Turkish languages in here, 
the overall idea was both correct and in direct conf l ict with 
the Biblical account of linguistic descent.1 If he had a bit 
more data to hand he might have arranged it into a table like 
the following: 
IcelandicIrishLatinEnglishCzechSanskrit Tochar- 
ian B 
faðirAthairPaterFatherOtecPitár-Pacer 
móðirMathirMaterMotherMatka Mātár-Macer 
bróðirBrathir FraterBrotherBratrBhrātar- Procer 
systirSiurSororSisterSestraSvásar-Ser 
hundurCuKanisHoundPesŚván-Ku 
hesturEachEquus Horse 
(eoh) 
HérákAśvaYakwe 
For Leibniz, the interest of this research lay not merely 
with determining genetic relations between languages but 
with the descent of peoples. ‘Languages in general, being the 
most ancient monuments of the human species… that serve 
best for determining the origin of peoples’ (Leibniz 1996 
[1765], p. 285). Over two centuries later, the linguist Mary 
Hass echoed this sentiment when she described a recon- 
structed proto-language as ‘a glorious artefact, one which is 
far more precious than anything an archaeologist can ever 
hope to unearth’ (Haas 1966, p. 124). 
The practice of making inferences about the cultures of 
language users on the evidence of reconstructed languages 
is called linguistic palaeontology (henceforth LP).2 These 
inferences may concern the material culture and geographic 
location of speakers as well as their social relations, mythol- 
ogy, and beliefs (the notion of ‘archaeological culture’ is 
used to capture both material culture and behaviour). This 
* Fintan Mallory 
fi ntan.mallory@kcl.ac.uk 
1 Department of Philosophy, King’s College, London, 
London WC2R 2LS, UK 
1 Leibniz was not the fi rst to make this observation. Marcus Zue- 
rius van Boxhorn had proposed a common ancestor language called 
Scythian over half a century earlier and he was wrong to lump the 
Turkish and Finnish languages in this group as they each derive from 
their own language families, the Uralic and Turkic families respec- 
tively but he was largely correct when he wrote that: ‘It seems in fact 
that all languages from the Indus River to the Baltic Sea have a single 
origin’. 
2 There are numerous terms for this. While the term palaeolinguistics 
is becoming more common within the linguistic literature (Crowley 
and Bowern 2010, p. 316), linguistic palaeontology is the term found 
in the relevant archaeological literature. Cultural reconstruction is 
also a common term but suggests a focus on cultural artefacts over 
environmental features like salmon. Wörter und Sachen may actually 
be the most accurate term but no longer appears to be in use. 
274 F. Mallory 
1 3 
method will be familiar to philosophers from Nietzsche’s 
Genealogy of Morals, a book which hoped to tackle the 
question: ‘What light does linguistics, and especially the 
study of etymology, throw on the history of the evolution of 
moral concepts’ (Nietzsche 1967, p. 63).3 
The primary aim of this paper isn’t to solve philosophical 
problems through historical linguistics or to solve archaeo- 
logical problems with philosophical methods, I doubt that 
can be done, but to encourage greater dialogue between the 
fi elds on the issue of LP. In this paper, I will be defending 
the rather weak-sounding claim that there is nothing in prin- 
ciple so unscientif i c about linguistic palaeontology such that 
it should be excluded from the considerations of archaeolo- 
gists. While this claim may appear trivial, it is by no means 
uncontested. Linguistic palaeontology, according to Raimo 
Antilla, ‘has rarely enjoyed particularly high repute’ (Antilla 
1989, p. 373).4 I will argue in this paper that both the defend- 
ers and critics of LP tend to overstate their case. 
In the following sections, I will provide a brief overview 
of the comparative method in linguistics and its connec- 
tion to linguistic palaeontology. I will then consider a case- 
study in which linguistic palaeontology has been utilised in 
a debate within archaeology: the Indo-European Homeland 
problem. The purpose of this discussion is to present some 
of the methods used within LP and examine the problems 
they face. I will argue that these are problems of evidence 
but not principle. That is, they are not problems which sug- 
gest that LP should be ignored by archaeologists, in fact, 
they highlight the need for greater engagement between the 
fi elds (and philosophy). In the fi nal section, I will discuss 
the theoretical status of linguistic reconstructions and argue 
that reconstructions can serve as models for dead languages. 
For the sake of clarity, I will def i ne some terms now. A 
pair of expressions are called cognates when we can reliably 
assume that they descended from a shared ancestor. These 
descendent-words are known as ref l exes of that ancestor. An 
archaeological horizon is a common set of traits or artefacts 
that identif i es a culture at a time. And a proto-lexicon is a 
set of lexical items which can reliably be attributed to the 
speakers of the proto-language. 
1 The Comparative Method 
LP relies upon a reconstruction of elements of a proto-lan- 
guage which researchers can then use to draw inferences. 
These reconstructions are produced through the comparison 
of similar expressions in dif f erent languages in order to make 
inferences about their common ancestors. This comparative 
method is not merely based on the fact that certain words 
appear similar but that the similarities between them are sys- 
tematic.5 It is the systematicity within the data that enables 
historical linguists to make inferences and frame hypotheses 
about the past of the language. Appeals to the wider context 
can help linguists sift out pseudo-cognates. For example, the 
Irish and Vietnamese words for ‘cow’ are bó and bò respec- 
tively but historical evidence suggests that it’s implausible 
that these share a common ancestor. In contrast, the Eng- 
lish cow and German Kuh are much more likely to share an 
ancestor. This data can be gathered into lists of cognates. 
While semantic intuitions guide this work, they are second 
to phonological features. On the basis of this data, rules of 
change can be conditionally proposed and proto-phonemes 
can be reconstructed. These are the basic phonological units 
of the proto-language. 
The ultimate goal at this stage is the discovery of sound 
laws—though the term ‘law’ can be misleading. To pref i g- 
ure later discussion, some linguists will be instrumentalists 
about these laws and simply identify them with regular or 
systematic correspondences in sound without making any 
further commitments. Alternatively, you can identify the 
laws with posited historical events that are particular to cer- 
tain languages (see Greenberg 1979 for discussion of this 
point).6 Whichever interpretation one adopts, these ‘laws’ 
enable linguists to arrange languages into groups and fami- 
lies (e.g. P-Celtic and Q-Celtic, Slavic and Romance). To 
take one example, Grimm’s Law of regular sound changes
ChatGPT
Fintan Mallory's paper, "The Case Against Linguistic Palaeontology," engages with the debate surrounding the validity and scientific utility of linguistic palaeontology within the fields of archaeology and historical linguistics. Linguistic palaeontology, also known as palaeolinguistics, seeks to infer aspects of prehistoric cultures—such as social structures, material cultures, and belief systems—based on the reconstruction of ancient languages and the study of their evolution.

Mallory highlights the controversial status of linguistic palaeontology, pointing out that while some see it as a promising avenue for uncovering aspects of human history inaccessible to traditional archaeological methods, others critique it as fundamentally flawed and unscientific. The paper centers on the Indo-European homeland problem as a case study to examine the types of inferences made by proponents of linguistic palaeontology and assess their validity.

The article traces the origins of the discipline back to early scholars like Gottfried Wilhelm Leibniz and the methodology of comparing cognate words across different languages to reconstruct proto-languages. This method, known as the comparative method, relies on systematic similarities among words in related languages to infer characteristics of their common ancestors. Mallory emphasizes that the challenge in linguistic palaeontology lies in distinguishing genuine cognates from false cognates and in interpreting these findings in a way that meaningfully contributes to our understanding of prehistoric cultures.

Mallory argues that while the criticisms against linguistic palaeontology are significant, they often overstate the case, suggesting that the discipline's problems lie more in the realm of evidence and methodology rather than in principle. The paper advocates for a nuanced view, acknowledging both the potential and the limitations of linguistic palaeontology as a complementary tool for archaeological research.

In concluding, Mallory calls for increased dialogue and collaboration between linguists, archaeologists, and philosophers to enhance the credibility and utility of linguistic palaeontology. This interdisciplinary approach, Mallory suggests, could lead to a more refined understanding of linguistic reconstructions as models for interpreting the past, thereby contributing to the broader field of historical inquiry.

User
2 The Proto‑Indo‑European Homeland 
Problem 
There are two dominant theories of the origins of the Indo- 
European languages; the Pontic-Caspian-Steppe hypothesis 
and Anatolian hypothesis. The fi rst of these locates the origi- 
nal speakers of Proto-Indo-European on somewhere on the 
Russian steppes, north of the Caspian Sea and posits a point 
of separation at around 3500–4500 BCE. This connects the 
Proto-Indo-European language with the Yamnaya horizon and 
in doing so suggests a bridge between linguistic and archaeo- 
logical data. The Yamnaya horizon is an archaeological culture 
associated with kurgan cemeteries (tumulus burial mounds), 
corded-ware pots, and a system of nomadic pastoralism. This 
last point is of importance for the Steppe (and any other) 
hypothesis as some motivation is required for other cultures 
to adopt the Indo-European languages. Language displacement 
is often associated with some kind of social and technologi- 
cal advance and a prominent element of the Steppe hypoth- 
esis is the idea that the Proto-Indo-European language spread 
with nomadic pastoralism. Without some material basis in the 
archaeological data, it is dif i cult to construct a plausible narra- 
tive for widespread social change. Inf l uential defenders of this 
claim are Marija Gimbutas and David Anthony. 
The alternative theory locates the Indo-European home- 
land (Urheimat) in modern-day Turkey and suggests a point 
of divergence at around 7000–6000 BCE (the Early Neo- 
lithic). In this case, the socio-technological development 
spurring the spread of Proto-Indo-European is the develop- 
ment of agriculture. The displacement of earlier non-Indo- 
European languages was facilitated by both the population 
increase enabled by farming and the prestige attached to 
farming cultures. An advantage of this hypothesis is that the 
spread of farming techniques has been well-documented by 
archaeologists. This theory was propounded by the archae- 
ologist Colin Renfew and is supported by Grey and Atkinson 
(2003) and Bouckaert et al. (2012). 
Both of these hypotheses have the virtue of identifying 
a relatively central area from which the Indo-European lan- 
guages could have spread as well as having archaeologically 
attested mechanisms for this spread (pastoral nomadism or 
agricultural expansion). However, since the Proto-Indo- 
Europeans are fundamentally a linguistic posit, this is not 
a debate that can be decided by archaeological evidence 
alone. At the very least, a broad interdisciplinary approach 
is required. Which disciplines are invited to the table, how- 
ever, remains a contested issue. Recent genetic data appears 
to support the Steppe hypothesis by conf i rming migrations 
from the steppes (Haak et al. 2015).8 On the other hand, 
7 Heggarty cautions that ‘[e]xcessive adherence to the tree idealisa- 
tion has arguably been the single biggest spanner in the works that 
has frustrated and confused attempts to fi t our languages more plausi- 
bly and coherently into population (pre)history as seen by other disci- 
plines’ (Heggarty 2015, p. 604). 
8 Some archaeologists have disputed whether this migration could 
have carried the Indo-European languages due to the distance 
between the dates for the breakup of the language and breakup of 
276 F. Mallory 
1 3 
Bayesian phylogeographic methods support an Anatolian 
origin (Bouckaert et al. 2012).9 
A chief point of contention between proponents of each 
theory is whether linguistic palaeontology is a legitimate 
methodology. Renfrew writes ‘[t]he main reason for the 
failure to locate such a homeland arises, I think, fi rst from 
an unwise reliance on linguistic palaeontology in a rather 
uncritical way’ (Renfrew 1987, pp. 97–98). In contrast, Rob- 
ert Beekes, a linguist rather than an archaeologist, summa- 
rises Renfrew’s position as follows: ‘His theory happens to 
be contradicted by the linguistic and historical data which 
we have at our disposal, which is the reason why he must 
reject all the conclusions which have been reached by lin- 
guistic palaeontology’ (Beekes 2011, p. 50). We have an 
instance here of a debate between archaeologists such as 
Renfrew and Anthony which hinges in large part on the 
legitimacy of linguistic palaeontology as a method. 
The claims made for linguistic palaeontology can appear 
quite extreme. For example, Anthony writes: ‘The proto- 
lexicon contains much more, including clusters of words, 
suggesting that the speakers of PIE inherited their rights 
and duties through the father’s bloodline only (patrilineal 
descent); probably lived with the husband’s family after 
marriage (patrilocal residence); recognized the authority of 
chiefs who acted as patrons and givers of hospitality for 
their clients; likely had formally instituted warrior bands; 
practiced ritual sacrif i ces of cattle and horses; drove wag- 
ons; recognized a male sky deity; probably avoided speaking 
the name of the bear for ritual reasons; and recognized two 
senses of the sacred (“that which is imbued with holiness” 
and “that which is forbidden”). Many of these practices 
and beliefs are simply unrecoverable through archaeology’ 
(Anthony 2007, p. 15).10 
Gimbutas, appealing to mythology and material culture as 
well as linguistics, goes further when discussing the cultural 
change enforced by Indo-European expansion: ‘These 
changes were expressed as the transition from matrilineal 
to patrilineal order, from a learned theocracy to a militant 
patriarchy, from a sexually balanced egalitarian society to 
a male-dominated hierarchy, and from a chthonic goddess 
religion to the IE sky-oriented pantheon of gods’ (Gimbutas 
1993, p. 219). Others have argued that a ‘democratic revo- 
lution’ in the centre of the Indo-European linguistic sphere 
accounts for the absence of cognates for ‘king’, *rēǵs in 
certain languages (discussed in Mallory 1976, p. 53). 
These are clearly very strong conclusions to derive from 
linguistic evidence and it is understandable that critics would 
be suspicious. Rather than try to justify the strongest claims 
about the cultural reconstruction of prehistorical societies, 
I will conf i ne my focus here to weaker claims which bare 
more directly on archaeological data; claims about the home- 
land of speakers of the proto-language. It is the homeland 
question that can have the greatest relevance for archaeology 
because it is through identifying a homeland that researchers 
are able to connect a language with a particular material cul- 
ture. This isn’t to deny that linguists may practice semantic 
reconstruction with other interests. But we don’t need to 
vindicate the strongest claims made by the proponents of 
linguistic palaeontology in order to assess its value. While 
this focus may not be expansive enough for either Anthony 
(or Nietzsche), it seems to be the most defensible use of the 
method and the most directly relevant to archaeologists.
ChatGPT
The debate over the Proto-Indo-European (PIE) homeland is a central issue within the field of historical linguistics and archaeology, illustrating the intersection of linguistic evidence with archaeological and genetic findings. Two primary theories contest the origin of the Indo-European languages: the Pontic-Caspian Steppe hypothesis and the Anatolian hypothesis.

Pontic-Caspian Steppe Hypothesis
This theory posits that the PIE speakers originated on the Russian steppes, north of the Casp

User
Continue
ChatGPT
ian Sea, with a proposed timeline for the divergence of Proto-Indo-European languages around 3500–4500 BCE. This hypothesis aligns the spread of PIE languages with the Yamnaya horizon, an archaeological culture characterized by features such as kurgan burial mounds, corded-ware pottery, and a nomadic pastoralist lifestyle. The connection to nomadic pastoralism is significant, as it provides a potential mechanism for the spread of PIE languages through social and technological advancements associated with this lifestyle. Prominent advocates of this hypothesis include Marija Gimbutas and David Anthony, who argue that the archaeological evidence of the Yamnaya culture supports the steppe as the PIE homeland.

Anatolian Hypothesis
In contrast, the Anatolian hypothesis places the PIE homeland in what is now modern-day Turkey, suggesting an earlier divergence time around 7000–6000 BCE, during the Early Neolithic period. This theory proposes that the spread of PIE languages was facilitated by the advent of agriculture, which led to population growth and increased social prestige for farming cultures. The spread of farming techniques, well-documented by archaeologists, serves as the socio-technological foundation for this hypothesis. Colin Renfrew, among others, supports this theory, highlighting the role of agricultural expansion in disseminating PIE languages.

Interdisciplinary Evidence and Debates
The PIE homeland problem exemplifies the need for an interdisciplinary approach, combining linguistic, archaeological, and genetic evidence. Recent genetic studies have lent support to the Steppe hypothesis by identifying migrations from the steppes into Europe, while Bayesian phylogeographic analyses have provided backing for the Anatolian origin. This division underscores the complexity of tracing the origins of linguistic families and the necessity of integrating various types of evidence.

Linguistic Palaeontology's Role
The debate also revolves around the legitimacy and utility of linguistic palaeontology as a methodological tool. Critics, like Renfrew, caution against an uncritical reliance on linguistic palaeontology, arguing that it has failed to convincingly pinpoint a homeland due to its speculative nature. Conversely, proponents like Beekes defend linguistic palaeontology, suggesting that opposition stems from a misalignment with archaeological and historical data.

Despite the controversy, linguistic palaeontology offers insights into PIE social structures, beliefs, and practices that are less accessible through archaeology alone. Anthony's work, for example, draws from the proto-lexicon to suggest patrilineal descent, patrilocal residence, and a male sky deity among PIE speakers—details that enrich our understanding of these ancient communities.

Conclusion
While the strongest claims of linguistic palaeontology may be contested, its contribution to discussions about the PIE homeland and the cultural practices of early Indo-European speakers illustrates the potential benefits of this approach. By focusing on what linguistic evidence can reliably offer, especially when corroborated by archaeological and genetic data, researchers can navigate the complexities of early human history with a more nuanced and comprehensive perspective. This underscores the importance of ongoing dialogue and collaboration among linguists, archaeologists, and geneticists in unraveling the origins and spread of the Indo-European languages.

User
3 Theory Internal Arguments 
In the case of the Proto-Indo-Europeans, the most important 
reconstructions for determining the Urheimat are those for 
horse and wheel.14 The word for horse, *ekwo-s, is attested 
in ref l exes from Ireland to the Tarim Basin. The absence of 
horses from Italy, Greece and the Balkans appear to rule 
these regions out while the presence of domesticated horses 
on the Eurasian Steppe would lend support to this location. 
The case of wheels is even more signif i cant for two rea- 
sons. Firstly, linguists have reconstructed fi ve terms which 
appear to relate to wheeled transport, including two words 
for wheel, as well as words for axel, thill and the act of 
conveying something in a vehicle. Secondly, archaeological 
evidence suggests that wheeled vehicles weren’t invented 
until 4000 BCE at the latest. This would appear to under- 
mine the Anatolian hypothesis which places the spread of 
the Indo-European languages two millennia earlier. 
Let’s begin with practical questions. The main purpose of 
this discussion is to provide more detailed examples of the 
kind of reasoning involved when LP is applied to archaeol- 
ogy. The chief question about the term *ekwo-s is whether 
it denoted wild or domestic horses. If it denotes domestic 
horses, then, it is argued, we can tie the PIE language to 
an archaeological culture possessing domestic horses (or a 
culture adjacent to one). As the earliest possible location 
for horse domestication is the Pontic-Caspian Steppe after 
4800 BCE (Anthony 2007, p. 200) this would provide com- 
pelling support for the Steppe hypothesis.15 The problem 
though is that we have no guarantee that *ekwo-s refers to a 
domesticated rather than a wild horse. As D’iakonov puts it: 
‘The Proto-Indo-European term for ‘horse’ shows only that 
horses were known’ (cited in Bryant 2003, p. 116; emphasis 
added); it doesn’t demonstrate that they were domesticated 
(Dolgopolsky 1993, p. 240). While horses were rarer in Ana- 
tolia, there is archaeological evidence that they were present. 
What kind of evidence might decide this? The lack of 
reconstructions for a wider equestrian semantic fi eld has 
been cited as evidence that *ekwo-s originally denoted a 
wild horse. If horses played the central role in Proto-Indo- 
European society suggested by the Steppe hypothesis, one 
might expect reconstructions for foal, mare, gelding, stallion, 
steed and so forth. The absence of these expressions is used 
as evidence to fi x the sense of *ekwo-s and thereby its refer- 
ence.16 While cognate terms for ‘horse-breaking’ have been 
found in Celtic, Latin, Greek and Indic, the term has been 
applied to animals other than horses and so it may only have 
been applied to horses at a later date (Mallory and Adams 
2006, p. 136). Can archaeological evidence help us fi x the 
sense of *ekwo-s? As you’d expect, this depends on where 
you look. It would be circular to assume that *ekwo-s must 
denote a domestic horse on account of its place of origin, 
the Steppes, since the claim that it denotes a domestic horse 
is one of the arguments for the Steppe hypothesis.17 Further 
cultural considerations, however, can of f er hints. The Indic 
aśvamedha, Roman Equus October and some Irish inaugu- 
ration ceremonies involved the ritual dismemberment of a 
horse (and in cases, bathing in its blood) which suggests but 
doesn’t entail a shared ceremonial tradition. 
The main objection against the wheel case is that techno- 
logical terms have a tendency to spread as loan words. The 
words for computer in Yoruba and Albanian are kọmputa 
and kompjuter respectively. It would be wrong to infer from 
this that each of those languages derives from a single com- 
mon ancestor which possessed a proto-form of ‘computer’. 
What is much more likely is that the term spread with the 
technology. The same can be said for the adoption of the 
word mouse to denote the hand-held pointing device. Both 
mouse and computer had meanings before they were trans- 
ferred to a new technology (it’s important to remember that 
entirely new words are rare). As a new technology spreads 
across cultures and linguistic boundaries, the terms for 
it spread as well (though not always). In any case, critics 
observe, even if the term wheel was present in Proto-Indo- 
European, there is no guarantee that it denoted the wheels 
on vehicles rather than potter’s wheels or even the sun disk. 
A final concern that must be addressed is morphol- 
ogy. Technically, we could reconstruct a word for ‘mare’ 
in Proto-Indo-European by deriving the feminine form of 
*h1éḱqṷeha-. This doesn’t itself tell us that speakers of PIE 
had a concept of ‘mare’ as the productivity of morphology 
does not tell us about the reality of concept possession. The 
following excerpt captures this problem: ‘The creation of 
agent nouns in the dif f erent Indo-European languages is so 
14 For reasons of space, I will overlook the much-discussed recon- 
structions of plough, copper, and wool (for a detailed discussion, see 
Mallory and Adams 2006). While each of these are taken to support 
the Steppe hypotheses my aim here is merely to demonstrate the kind 
of argumentation involved in linguistic palaeontology and two cases 
suf i ce for this. 
15 Similarly, the absence of horses in Greece and Italy before the 
bronze age is taken as evidence that PIE could not have originated in 
these areas. 
16 This method follows Blust’s fi rst principle of semantic reconstruc- 
tion: ‘the meaning of a lexical item in an attested or a reconstructed 
language is determined by contrast within a fi eld of lexical items of 
partially similar meaning’ (Blust 1993, p. 38) which in turn stems 
from a Saussurian principle that the value of terms results from the 
presence of other terms (a kind of semantic holism). 
17 Bryant (2003, pp. 116–117) charges Diebold (1976) with this kind 
of circularity. Diebold claims that we know that *ekwos denotes the 
domesticated horse Equus caballus from archeological evidence, 
however, the reason we know that this archeological evidence is rel- 
evant archeological evidence is because of the linguistic evidence 
which locates PIE on the Steppe in the fi rst place. 
279The 
Case Against Linguistic Palaeontology 1 3 
productive that there are few words for occupations that can 
be attributed to Proto-Indo-European with any degree of 
certainty. The lack of reconstructable occupational terms 
may also suggest that Proto-Indo-European society was not 
one with much occupational specialization’ (Mallory and 
Adams 2006, p. 283). In other words, we can say that the 
reason for the lack of agent nouns is a result of the produc- 
tive morphology of Indo-European languages or that Indo- 
European society lacked the division of labour which would 
produce such names. The fi rst explanation is linguistic, the 
second is social, and it is not clear how we should choose 
between them.
ChatGPT
The discussion surrounding the Proto-Indo-European (PIE) homeland delves into the specifics of linguistic palaeontology, focusing on critical reconstructions such as those for "horse" and "wheel." These examples highlight the complexities of using linguistic evidence to draw conclusions about prehistoric societies.

Horse and Wheel: Key Reconstructions
*Horse (ekwo-s): The widespread attestation of words derived from *ekwo-s across Indo-European languages suggests the importance of horses to PIE society. However, the debate hinges on whether *ekwo-s referred specifically to domesticated horses. If *ekwo-s denotes domesticated horses, the argument leans towards the Pontic-Caspian Steppe, given the archaeological evidence of early horse domestication in this area. Yet, the absence of a broader equestrian semantic field in PIE reconstructions challenges the assumption of widespread horse domestication within PIE societies.

Wheel: The reconstruction of multiple terms related to wheeled transport in PIE points towards the significance of this technology. The invention of wheeled vehicles, not earlier than 4000 BCE, potentially challenges the Anatolian hypothesis for the PIE homeland, which posits an earlier spread of Indo-European languages. However, the argument is complicated by the fact that technological terms, including those for "wheel," can spread as loanwords, independent of direct linguistic descent.

Challenges in Interpretation
Domestication vs. Awareness: The exact meaning of *ekwo-s (whether it signifies domesticated or merely known horses) remains uncertain. This ambiguity limits the ability to definitively associate PIE speakers with specific archaeological cultures based on horse domestication alone.

Technological Terms as Loanwords: The spread of terms for innovations like the wheel can occur across linguistic boundaries as the technology disseminates. This phenomenon makes it difficult to link the presence of such terms in PIE directly to the invention or use of the technology by PIE speakers.

Morphological Productivity: The possibility of creating new words through productive morphological processes in PIE (e.g., forming a word for "mare") complicates the interpretation of what PIE speakers actually talked about or considered important in their society. The presence of a word does not necessarily imply the cultural or societal significance of its referent.

Conclusion
The intricate relationship between linguistic reconstructions and archaeological evidence underscores the challenges of using linguistic palaeontology to infer aspects of prehistoric societies. While reconstructions of terms like *ekwo-s and those related to wheeled transport offer fascinating insights, their interpretation is fraught with uncertainties. These examples illustrate the methodological complexities of linguistic palaeontology and highlight the need for careful, nuanced analysis that considers linguistic, archaeological, and social evidence in concert. The debate over the PIE homeland and the societal characteristics of PIE speakers demonstrates the potential and the limitations of linguistic evidence in reconstructing prehistoric cultures.

User
4 Principled Objections 
One might think that these issues can be resolved by simply 
providing more detail and that a bit more evidence might 
tip the scales one way or another. There is other data that 
I am omitting and which appears to support the claim that 
the terms for wheeled transport are neither loan words nor 
independently developed but must have been inherited from 
Proto-Indo-European (see Ringe and Anthony 2015). How- 
ever, some opponents of linguistic palaeontology go beyond 
highlighting framework-internal objections, rejecting the 
framework as a whole. Probably the most articulate critic of 
LP, Paul Heggarty, writes: 
‘Linguistic Palaeontologists sometimes try to object that 
the mouse example [mentioned above] is not pertinent and 
insist on a case-by-case scrutiny of their reconstructions, but 
this misses the point. It is not the details of a reconstructed 
Proto-Indo-European form that are in question, any more 
than they are for the Proto-Germanic form of mouse. What 
is in question is the series of assumptions that linguistic pal- 
aeontologists make: about what a proto-form does or does 
not necessarily entail for the culture and date of the proto- 
language—by virtue, in their view of the simple fact that 
they have been able to reconstruct it; and about how and 
when that form acquired the meaning that they now read for 
it’ (Heggarty 2006, pp. 190–191).18 
The suggestion here is that the problem with the method 
isn’t simply a lack of data but something deeper. To assess 
this, we need to look at what the assumptions referred to are. 
As mentioned, there are two parts to linguistic palaeontol- 
ogy; the derivation of the meaning of a reconstructed term 
and the inference from the meaning [sense] to its referent 
with the ultimate aim of using this information to determine 
where the speakers of the language lived. 
The fi rst assumption is that we can determine the sense 
of expressions. There are two main arguments against this. 
The fi rst goes as follows: the comparative method for pho- 
nological reconstruction is justif i ed by the law-like nature of 
phonological change. No comparable laws exist for seman- 
tic change and therefore semantic reconstruction does not 
have the scientif i c credibility of phonological reconstruc- 
tion. There may be general tendencies of words to undergo 
extension, narrowing, ellipses pejoration, and so forth, but 
these aren’t systematic. For example, the fact that the Old 
English word for a wild animal, deor, narrowed in meaning 
to only apply to deer doesn’t have many wider implications 
for the language. If we can’t determine systematic laws of 
change, then we can’t apply those laws to reconstruct earlier 
semantic contents. To do so is nothing more than a ‘leap 
of semantic faith’ (Heggarty and Renfrew 2014c, p. 1691). 
This is a compelling argument if linguistic palaeontology 
is supposed to be carried out in the manner of the compara- 
tive method. That is, if the method of semantic construc- 
tion involves the algorithmic application of rules to derive 
past semantic contents. There is no algorithm that can be 
applied to a cognate set that will give the sense of the origi- 
nal expression. However, it isn’t clear that LP tries to use 
the comparative method at all. Rather, it is methodologi- 
cally much more similar to archaeological interpretation in 
its attempts to discern the signif i cance of (reconstructed) 
pre-historical artefacts. 
The second argument is that semantic reconstruction 
is essentially vague and subjective: ‘The very fact that the 
same technique can be invoked to construct cases for and 
against the same Steppe hypothesis reveals the widest objec- 
tion to linguistic palaeontology in principle—its subjectiv- 
ity’ (Heggarty and Renfrew 2014c, p. 1691).19 
I think we can break this criticism down into two com- 
ponents. The fi rst is the claim that dif f erent meanings can 
be reconstructed for the same term; the second is that there 
is no objective method for deciding between two hypoth- 
eses. The fi rst of these, the existence of opposing claims, 
is not a serious problem. The fact that multiple hypotheses 
can be formulated within a framework doesn’t entail that 
the framework is ‘subjective’. In fact, this is exactly what 
we should expect within any progressive (as opposed to 
degenerating) research programme. If it wasn’t possible to 
18 There are other principled objections which a philosopher might 
raise but which no archaeologist that I am aware of has raised. For 
example, one might be concerned that the terms of current languages 
are fundamentally incommensurable with those of prehistoric peoples 
such that we could never give an adequate gloss on items in a proto- 
language. We might occupy such a radically dif f erent ‘conceptual 
scheme’ or ‘form of life’ that we could never truly understand their 
speech. The correct response to this charge is to point out that a gloss 
is not a translation. Our aim isn’t to speak to prehistorical peoples but 
to geographically locate them. 
19 ‘A great deal of this “cultural reconstruction” is insecure and sub- 
jective, reading into linguistic reconstructions far more than they 
really say’ (Heggarty and Renfrew 2014b, p. 538). 
280 F. Mallory 
1 3 
formulate dif f erent hypothetical meanings for terms in the 
proto-lexicon, that would be a cause of concern. The method 
of semantic reconstruction should provide multiple hypoth- 
eses to work with and assess against the available data and 
we should accept disagreement among practitioners are an 
element of normal science. 
The second part, however, suggests that this is deeper 
and that there may be no objective method for deciding 
between these hypotheses. For example, in the cases above, 
we considered multiple ways in which evidence might af f ect 
how we assess the plausibility of a particular reconstruc- 
tion but it is unclear how we can assign a concrete value to 
the weight of this evidence. It is intuitively plausible that 
it is less likely that a word has independently emerged in 
multiple, independent branches of a language family. We 
should probably lend greater credence to a proposed shift in 
meaning if it follows one of the general trends of semantic 
drift identif i ed (e.g. narrowing, metaphor, metonymy) than 
if it didn’t but how much exactly this should inf l uence our 
thinking is unclear. As critics note, words for technological 
developments are more likely to spread horizontally across 
languages than words for non-technological developments. 
In the case of the horse and wheel, the alternative hypotheses 
for their spread are that these terms independently emerged 
in dif f erent lineages or that they spread as loan words at 
some point after the spread of the Indo-European languages. 
In the case of horse, there is good reason to believe that the 
term wasn’t derived independently. In the case of wheel, if 
we reject the hypothesis that it spread along with the rest 
of the reconstructed Proto-Indo-European expressions from 
the Steppes, it could have either developed independently or 
may have been a loan word which began to spread around 
2000 years after the Indo-European languages fi rst began 
to diverge. These hypotheses are possibilities but we don’t 
have a method for assigning objective probabilities to them. 
Some linguists have attempted to do this. Within the 
framework of Dyen and Aberle, ‘The dif f erences of “likeli- 
hood” spoken of here are based on “judgements of dif f er- 
ences” in probability. These are substitutes for true prob- 
ability measures but are presumably reliable or are presumed 
reliable when they constitute expert opinion’ (Dyen 1985, p. 
360). The subjectivity of the method can be best understood 
as the claim that we don’t have an objective assignment of 
prior probabilities to a set of hypothetical reconstructions. 
This doesn’t entail that we can’t use any probabilities and 
rationally update them in response to evidence. What it 
does mean is that the probabilities assigned must be under- 
stood subjectively, as statements of the credence assigned 
to particular hypotheses by experts in the fi eld rather than 
as objective probabilities. One may reasonably hope that 
as more data is collected which indicates the relative prev- 
alence of different forms of semantic drift, models can 
become more precise. 
At present, the inferences made in semantic reconstruction 
are neither deductive nor inductive. It isn’t possible to deduce 
the original sense of an expression from a set of ref l exes 
which may have shifted in meaning (e.g. laks means ‘f i sh’ 
in Tocharian B) nor is it possible to perform an inductive 
inference on the basis of the senses of the cognate set. The 
inferences performed are abductive; they are inferences to the 
best explanation. The best explanation for the current senses 
of a set of cognates is that they descended from a common 
ancestor which had a sense which would explain the current 
attested meanings. Reference to semantic reconstruction is 
a misnomer if reconstruction is understood in the sense of 
phonological reconstruction. If senses are not reconstructed 
from cognates but posited as the best explanation of why 
cognates possess the contents they do, then problems that 
linguistic palaeontology faces are problems of abduction in 
general. What counts as the best explanation may not always 
be clear. Yet normal criteria like simplicity, generality, and 
coherence can apply and are regularly applied in practice. 
The fi nal semantic issue is vagueness. It might be that 
sense is too fi ne-grained a notion to be appealed to in recon- 
struction. As Raimo Antilla observes, ‘it is surprisingly 
easy to devise abstract meanings to cover any two mean- 
ings’ (Antilla 1989, p. 369). If a set of cognates contains 
terms for sheep as well as goats, it is always an option to 
base the reconstructed sense on the union of these sets (e.g. 
small woolly animal). Perhaps the most famous instance of 
this problem can be seen in the now notorious Lachsargu- 
ment. It was originally claimed that Indo-European term 
*laḱs denoted the North Atlantic Salmon (Salmo salar) 
which is found in the Baltic and North Atlantic.
ChatGPT
The discussion on principled objections to linguistic palaeontology highlights the fundamental challenges and debates surrounding the discipline. Critics argue that the methodology of linguistic palaeontology is not just flawed in terms of lacking data but is fundamentally problematic due to the assumptions it makes about the correlation between reconstructed proto-forms and the actual practices, technologies, and societal structures of prehistoric peoples.

Key Criticisms:
Assumptions on Proto-Forms: Critics, like Paul Heggarty, contend that the core issue with linguistic palaeontology lies in the assumptions made about what the existence of a proto-form entails for the culture and time of the proto-language. These criticisms question the methodological foundation of inferring detailed cultural practices based solely on linguistic reconstructions.

Semantic Change vs. Phonological Change: Unlike phonological changes, which can often be described through systematic laws, semantic changes do not follow such predictable patterns. This lack of systematicity challenges the credibility of semantic reconstructions compared to phonological ones, as the pathways of meaning evolution are far less predictable.

Subjectivity and Vagueness: The criticism that different meanings can be reconstructed for the same term and that there's no objective method for choosing between them points to a perceived subjectivity in linguistic palaeontology. The possibility of devising abstract meanings to cover a wide range of specifics further complicates the task of semantic reconstruction, introducing vagueness and the potential for overgeneralization.

Defense and Methodological Considerations:
Abductive Reasoning: Proponents may argue that the methodological approach of linguistic palaeontology resembles more closely the work of archaeological interpretation than the algorithmic application of rules. It's about forming hypotheses based on the best explanation for the available evidence, a process known as abduction. This involves a level of subjective judgment but is grounded in the practice of building coherent, simple, and general explanations.

Expert Opinion and Probabilities: The field acknowledges the subjective nature of some of its methodologies but argues that expert opinion and probabilistic reasoning can still yield valuable insights. Over time, as more data becomes available, these subjective probabilities can be refined and made more objective.

Framework for Hypothesis Testing: The generation of multiple hypotheses within linguistic palaeontology should not be seen as a flaw but as a sign of a dynamic and evolving research program. The discipline allows for the formulation and testing of different interpretations of the linguistic evidence, contributing to a richer understanding of prehistoric cultures.

Conclusion:
The principled objections to linguistic palaeontology raise important questions about the limits and potentials of using linguistic evidence to reconstruct aspects of prehistoric human societies. While the methodology faces challenges regarding the assumptions it makes and the subjective nature of semantic reconstruction, it also offers a unique framework for exploring the past that complements archaeological and genetic data. As the field evolves, ongoing dialogue among linguists, archaeologists, and other researchers will be crucial for refining its approaches and integrating its findings into a broader understanding of human history.

User
a 
causal theory of either reference or word individuation, you 
might object that it doesn’t stand in the appropriate relation 
to the original language to count as a part of the original 
language. One might wonder what the point of criticising 
such an implausible view is, however, failure to separate 
these strands of realism can lead to confusion. Pulgram 
1959 argues that reconstructed Proto-Indo-European is not 
a language at all—a plausible thesis as it lacks a linguistic 
community or agreed syntax—but concludes from this that 
the reconstruction does not ‘represent a reality’. This is a 
much stronger claim and depends on how one understands 
the relationship between a theory and its subject matter. 
The concerns about the uniformity of the reconstructed 
language motivate the chief alternative to realism, formal- 
ism (or formulaism): ‘For the formulaists, a reconstructed 
sound is merely an ideal notation with no claim for percep- 
tual reality; in fact, the reconstruction of parent forms is a 
logical, not a historical operation’ (Antilla 1989, p. 341). 
The network of phonemes derived has not phonetic reality. 
According to the formalist, Pulgram, ‘no reputable linguist 
pretends that Proto-Indo-European reconstructions represent 
a reality’ (Pulgram 1959, p. 434).23 Anything in linguistics 
that is timeless, non-dialectal, and non-phonetic, by def i ni- 
tion does not represent a real language. Again, I suspect the 
case is being overstated in this argument. It is true that the 
comparative method produces a uniform language lacking 
dialectical variation and that actual natural languages have 
dialects. However, this merely shows that what is recon- 
structed is not the whole language and it certainly doesn’t 
entail that it can’t represent the target language. 
A more plausible way to articulate realism is to claim 
that the reconstructed terms denote expressions of the proto- 
language. The reconstructed lexicon, on this view, is not a 
reconstructed language but serves the metalinguistic pur- 
pose of referring to expressions in the proto-language. The 
plausibility of this view hinges on what you think a proto- 
language is. I take it for granted that few would wish to 
identify the proto-language or any other language with a set 
of linguistic tokens, i.e. concrete physical objects/actions 
which occurred in the past. The natural assumption then 
would be to identify the proto-language with a set of lin- 
guistic types, i.e. abstract, mind-independent objects. This is 
the approach Linda Wetzel takes in her discussion of Indo- 
European. ‘Since the languages referred to here are spoken 
by many people, they are types, not spatiotemporal particu- 
lars, and so is the tree that accounts for their development’ 
(Wetzel 2009, p. 6).24 
This approach possesses both intuitive plausibility and 
appears to extend across the sciences. Biologists, for exam- 
ple, don’t study particular animals but species. Correspond- 
ingly, reconstructed lexical items don’t stand for particular 
tokens of lexical items but for the types of those tokens. 
The problem with this view as presented is that word types 
are typically taken to be abstract, atemporal objects and the 
question of the Urheimat is predicated on the idea that a 
language is a spatiotemporal particular. A proto-language is 
necessarily a historical object; it is the posited last point at 
which two historically attested cognates met. I don’t think 
this is a radically damning problem but it does suggest that 
we need to develop an account of the relationship between 
a reconstructed language and a historical language which 
captures the temporal nature of the historical language and 
the ideal nature of the reconstruction. The realist position 
has some positive features but, if it is to help us connect his- 
torical linguistics and archaeology, it cannot be endorsed in 
its Platonist form. That is, we should not commit ourselves 
to the claim that words literally are abstract objects. 
This brings us to the third possibility which is neither 
realist nor formalist. Reconstructions model the conceptual 
abilities of a historical community. ‘Model’ is a contested 
concept in the philosophy of science and I don’t intend to 
come down strongly for any particular theory. The general 
def i nition I will use comes from Godfrey-Smith: ‘models 
are idealized structures that we use to represent the world, 
via resemblance relations between the model and real-world 
target systems’ (Godfrey-Smith 2006, pp. 725–726). While 
these properties are neither necessary nor suf i cient to ren- 
der something a model, it should be relatively clear how the 
comparative method manifests them. 
The comparative method results in an idealised represen- 
tation of the proto-language. It provides us with a collection 
of terms which may have existed at dif f erent points over a 
long period of time and may have possessed dialectical vari- 
ants. Although this fact has been wielded as an argument 
for formalism, we should acknowledge that idealisation is 
a central part of any kind of scientif i c theory. However, it 
is important though to distinguish the idealisation inherent 
in the modelling process from the claim that one is theoris- 
ing about ideal, abstract objects. The mistake underlying 
the Platonist approach to types is that it takes properties 
of the model, its abstractness and use of idealisation, and 
23 The spirit of this claim has been more recently stated by Fox: 
‘What we are not entitled to do of course is to mistake our idealiza- 
tions [of a uniform proto-language] for reality. It is all too easy to 
interpret our idealisation of reality as though it were reality itself, and 
to draw inappropriate conclusions on this basis’ (Fox 1995, p. 140). 
Fox’s position is an intermediary between the realist and the formal- 
ist. 
24 As I mentioned above, it’s better to avoid claiming that the tree 
accounts for the development of a language but to acknowledge that it 
ref l ects the process by which the proto-language was discovered. 
283The 
Case Against Linguistic Palaeontology 1 3 
projects them onto the object modelled. We must simplify 
and idealise what we are speaking about if we are to model it 
ef f ectively but this doesn’t entail that we should understand 
a language as a set of abstract objects existing independently 
of human activities.25 Languages exist within a particular 
geographic and temporal horizon even if our models of them 
are abstract objects. 
6 Conclusion 
In this paper, I have argued that the principled objections 
to the use of linguistic palaeontology by archaeologists are 
not overwhelming. This obviously doesn’t give a free pass 
to every absurd reconstructed meaning but nor does it mean 
that the results of semantic reconstruction should be ignored. 
The purpose of this argument was to do some ground clear- 
ing for what will hopefully be a more active engagement 
between the philosophy of language and linguistic palaeon- 
tology (as well as archaeology). There are two reasons for 
this. The fi rst is that analytic philosophy of language has 
spent over a century developing sophisticated tools for the 
discussion of semantic issues none of which has inf l uenced 
the discourse in LP. This paper barely touches on the poten- 
tial for co-operation. The second is more sombre. We are 
currently undergoing a massive language extinction event. 
Over half the world’s languages face imminent death. It is 
sometimes said that when a language dies, a culture and a 
way of viewing the world goes with it. Whether this is true 
(in a sense) depends in part upon whether or not the loss of 
a language results in the loss of irretrievable information 
and the answer to this question is, in an important sense, the 
possibility of linguistic palaeontology.
ChatGPT
The debate around linguistic palaeontology, as explored in the paper, culminates in a discussion of the philosophical underpinnings and implications of reconstructing ancient languages and the methodologies used to infer cultural and societal aspects of prehistoric peoples from linguistic data. The paper addresses various perspectives on the validity and utility of linguistic palaeontology, including realism, formalism, and a model-based approach to understanding proto-languages.

Realism vs. Formalism
Realism posits that reconstructed terms and structures of a proto-language denote real, albeit abstract, entities within that language, suggesting a direct link between linguistic reconstructions and the historical reality they aim to represent.

Formalism, on the other hand, views reconstructed sounds and terms as ideal notations without claims to perceptual or historical reality. This view emphasizes the logical over the historical in the reconstruction process, suggesting that linguistic models are constructs rather than reflections of past realities.

A Model-Based Approach
The paper advocates for a model-based approach to understanding proto-languages, aligning with Godfrey-Smith's definition where models are idealized structures used to represent real-world systems through resemblance. This approach acknowledges the necessity of idealization in scientific theory while avoiding the pitfalls of overly abstract, Platonist interpretations. It suggests that while reconstructions are abstract and idealized, they serve as useful models for understanding the linguistic capabilities and cultural contexts of historical communities.

Conclusion and Philosophical Implications
The principled objections to linguistic palaeontology, while significant, do not entirely undermine its value to archaeology and the study of human prehistory. The paper calls for a more nuanced engagement between the philosophy of language and linguistic palaeontology, highlighting the potential for analytic philosophy to contribute to the discourse and methodology of linguistic reconstruction.

Furthermore, the ongoing language extinction event underscores the urgency and importance of linguistic palaeontology. The loss of languages is not just a loss of words but potentially a loss of unique cultural perspectives and ways of understanding the world. Linguistic palaeontology, by reconstructing and preserving knowledge of ancient languages, may offer insights into these lost perspectives, emphasizing the discipline's relevance and importance in the broader context of understanding human history and diversity.

In essence, the paper argues for the continued, critical engagement with linguistic palaeontology, advocating for interdisciplinary cooperation to refine its methodologies and enhance its contributions to our understanding of human history and culture.

User
Are we coming face-to-face with a new kind of digital Other? Can generative language models even produce mea- 
ningful sentences? Wittgenstein’s later philosophy of language has been appealed to by both sides of the debate 
around this question. Often this appeal takes the form of a gesture rather than a feshed-out argument. Tis article 
presents three ways in which Wittgenstein’s work can support a positive answer to this question; his defence of se- 
mantic anti-foundationalism, his attack on the reifcation of meaning, and his critique of the explanatory function 
of 'understanding'. We will then look at some Wittgenstein-inspired responses to this position, including the claim 
that meaningful linguistic behaviour requires occupying a form of life and the idea that contemporary research fo- 
cuses too much on modelling linguistic understanding rather than developing machines capable of linguistic agency. 
FRA FORSKNINGSFRONTEN 
WITTGENSTEIN, THE OTHER, AND 
LARGE LANGUAGE MODELS 
A 
common narrative of 20th-century philosophy pla- 
ces a central emphasis on the discovery of the Other. 
Husserl introduced us to him/her/them in his Cartesian 
Meditations as part of an extended argument that our 
grasp of the objective world requires intersubjective con- 
nections to others. If we want to understand how we ex- 
perience things objectively, we can’t solipsistically pretend 
that no one else is out there. At roughly the same time, 
Ludwig Wittgenstein was realising the faws in his early 
philosophy of language. In the Tractatus, he had presented 
language as a static entity in which meaning (established 
via ‘picturing’) was determined independent of how agents 
use language to engage with each other; how they wield 
words to share and amuse, to build communities and solve 
shared problems. With the Philosophical Investigations, 
the role that others play came to the fore. Language, ac- 
cording to this revised view, cannot be private. Talk of 
meaning only makes sense in the context of how we use 
language with others. For both of these thinkers, our indi- 
vidual grasp of contents (and in an important sense, their 
grasp on us) depends upon the existence of others. Te 
other is not optional. 
But what kind of ‘others’ are required? For Husserl, 
they had to have bodies like us, we recognise them through 
their ‘organismal conduct’ — their grasping hands and 
seeing eyes. Can something be an intersubjectivity consti- 
tuting other if it lacks these traits? For example, when you 
input a prompt to ChatGPT and get a response, are you 
engaging with an Other? What is the ‘linguistic Other’ 
and should recent developments in machine learning and 
natural language processing, lead us to reconsider it? For 
as long as there have been chatbots, scholars have warned 
of the dangers of anthropomorphising them. Shortly after 
developing the early chatbot, ELIZA, its creator, Joseph 
Weizenbaum wrote, ‘What I had not realised was that 
extremely short exposures to a relatively simple compu- 
ter program could induce powerful delusional thinking 
in quite normal people” (Weizenbaum, 1969: 7). For the 
last few years, the current generation of chatbots ground- 
ed in large language models (e.g. BERT, ChatGPT, Bard, 
Claude) have been called ‘stochastic parrots’ with theorists 
warning that it is a mistake to interpret their outputs as 
meaningful speech. I’ll call the position that the output of 
these systems is meaningless error theory and its advocates 
error theorists. Error theory is probably the best-suppor- 
ted position from the perspective of traditional philosophy 
of language although some have argued that we should 
develop new theories of semantics for machines (Cappelen 
& Dever, 2022) or be fctionalists about machine meaning 
(Mallory, 2023). 
ARTIKKEL INTERVJU & FORSKNING SPALTER BREV 
By Fintan Declan Mallory 
80 
Over the last decade, Wittgenstein has been invoked 
in countless papers on the use of distributional methods in 
the semantics underlying language modelling.1 Te version 
of Wittgenstein that tends to appear is one who believed 
that ‘meaning is use’, and, much more tenuously, that this 
means that meaning can be reconstructed by modelling 
the distributions of a word within a large enough textual 
corpus. Against this, others have presented an alternative 
Wittgenstein, someone who understood that grasping a 
language requires much more than knowing the logical or 
similarity relations between expressions. Instead, he belie- 
ved that a language user must inhabit a particular form of 
life (Dreyfus, 1992). Tis Wittgenstein’s characterisation 
of linguistic behaviour in its communal and embodied 
context is supposed to illustrate just how far contemporary 
research is from producing anything that could come close 
to producing meaningful language. He is a humanist (and 
perhaps even a phenomenologist). For this Wittgenstein, 
machines cannot be linguistic Others. 
Tis paper will not present a Wittgenstein but in- 
stead, it will examine the consequences of some of his later 
claims for debates about whether language models produ- 
ce meaningful speech. Specifcally, we’ll look at three ideas; 
his criticism of semantic foundationalism, the claim that 
meanings ground the normativity of language, and the 
idea that we should think of understanding language as a 
subjective, psychological phenomenon. We’ll then consi- 
der some responses that one could make which themselves 
draw upon Wittgenstein.
ChatGPT
This exploration into the implications of Ludwig Wittgenstein's later philosophy of language for the debate around generative language models like ChatGPT touches on profound questions regarding meaning, understanding, and the nature of linguistic interactions with AI systems. Wittgenstein's transition from the ideas presented in the Tractatus Logico-Philosophicus to those in the Philosophical Investigations marks a significant shift in his understanding of language, emphasizing the communal and use-based nature of meaning over a fixed, pictorial representation.

Semantic Anti-Foundationalism
Wittgenstein's critique of semantic foundationalism underpins his argument that meanings are not inherent, fixed properties of words but are derived from their use within specific life forms and linguistic communities. This perspective challenges the notion that a word's meaning can be fully captured by its distribution in a textual corpus, as some interpretations of language modeling might suggest.

Reification of Meaning
By attacking the reification of meaning, Wittgenstein argues against the idea that meanings are discrete entities that can be abstracted from their use. This has implications for language models, suggesting that the meaningfulness of generated text cannot be solely determined by the internal mechanics of the model but must also consider the broader context of use and the interactions between users and the system.

Understanding as a Non-Explanatory Function
Wittgenstein's critique of understanding as a purely psychological or internal process shifts the focus from the internal states of a language user (or, by extension, a language model) to the external, observable practices of language use. This challenges the notion that for language to be meaningful, it must be generated by an entity capable of internal understanding in a human-like manner.

Responses Drawing on Wittgenstein
Form of Life Requirement: One Wittgenstein-inspired response is that meaningful linguistic behavior necessitates participation in a human form of life, with its rich tapestry of practices, intentions, and shared understanding. This view posits that AI, lacking embodiment and participation in human forms of life, falls short of generating truly meaningful language.

Linguistic Agency over Understanding: Another response suggests that current research overly focuses on modeling linguistic understanding rather than cultivating linguistic agency— the capacity for autonomous, meaningful participation in linguistic practices. This perspective calls for a reevaluation of the goals and approaches in AI language model development.

Conclusion
The application of Wittgenstein's later philosophy of language to the debate around language models like ChatGPT illuminates several key challenges and considerations. While Wittgenstein's critique of semantic foundationalism and the reification of meaning provides theoretical support for the potential meaningfulness of language model outputs, his emphasis on the communal aspects of language use and the requirements of a shared form of life raises significant doubts about the depth of this meaningfulness. The paper advocates for a nuanced examination of these issues, encouraging a dialogue that bridges philosophy of language and artificial intelligence research to more fully understand the capabilities and limitations of generative language models.

User
1. Large Language Models 
Te kinds of models we will be considering will be large 
language models (LLMs). LLMs are neural networks that 
have been trained on language modelling tasks — predic- 
ting the word that will occur in a given context or whether 
one sentence will follow another (often they are fne-tuned 
on particular tasks like paraphrasing, natural language in- 
ference, named-entity recognition, question answering, or 
sentiment analysis). Taking an old but concrete example, 
BERTLARGE is a neural network with 24 layers, 340 
million parameters and is trained on a corpus containing 
320 million words (Devlin et al., 2018). Before being fne- 
tuned, it is trained on next-word prediction and next-sen- 
tence prediction tasks. As it becomes better at performing 
these tasks, its internal structure begins to track features 
of the language in the dataset. Determining what these 
features are is a matter of contemporary research (Rogers, 
Kovaleva & Rumshisky, 2020). Once a model has been 
trained, it can be prompted to produce its own text based 
on its predictive capacities. Tis text may be interpreted 
by readers as stories, articles, answers to questions or other 
conversational moves though whether these are legitimate 
interpretations is contested. ChatGPT is perhaps the most 
famous recent implementation of a language model. It is 
grounded in the GPT3.5 series of models but aside from 
language modelling, it has also been fne-tuned in a process 
of reinforcement Learning from Human Feedback.
ChatGPT
Large Language Models (LLMs) like BERTLARGE and GPT-3.5, as described, represent significant advancements in the field of natural language processing (NLP) and artificial intelligence (AI). These models have fundamentally altered our understanding and interaction with machine-generated text, offering insights into the complexities of language understanding and generation by non-human systems.

Characteristics of Large Language Models
Training and Architecture: LLMs are neural networks with extensive layers (BERTLARGE has 24 layers) and a massive number of parameters (BERTLARGE has 340 million parameters), allowing them to process and understand the nuances of human language. They are trained on large corpora, consisting of hundreds of millions of words, to predict the next word in a sequence or whether one sentence logically follows another.

Fine-Tuning: Beyond initial training, LLMs undergo fine-tuning for specific tasks such as paraphrasing, natural language inference, and question answering. This process makes them adaptable to various linguistic tasks, enhancing their utility across different domains.

Predictive Capabilities: The core functionality of these models lies in their predictive capabilities. They generate text based on the patterns and structures learned during training, enabling them to produce coherent and contextually relevant text outputs.

Interpretation of Outputs: The text generated by LLMs can be interpreted in various forms—stories, articles, conversational responses—though the legitimacy of these interpretations remains a matter of debate. This debate touches on the philosophical questions of meaning, understanding, and the nature of communication between humans and machines.

Human Feedback: Some models, like ChatGPT, are further refined through processes like Reinforcement Learning from Human Feedback (RLHF), which incorporates human judgments to guide the model towards more desirable outputs. This iterative process aims to align the model's responses more closely with human expectations and standards of meaningful communication.

Implications and Challenges
The development and deployment of LLMs raise important questions about the nature of linguistic meaning and the capacity for machines to engage in what might be considered meaningful communication. While these models can mimic human-like text generation, the extent to which they understand or produce truly meaningful language is debated, invoking Wittgenstein's ideas about language, meaning, and form of life.

Moreover, the technical and ethical challenges of LLMs, including issues of bias, misinformation, and the potential for anthropomorphizing, highlight the need for continued research and dialogue between computational scientists, philosophers, and ethicists to navigate the complexities of human-machine interaction in the realm of language.

In conclusion, LLMs represent a frontier in AI research, pushing the boundaries of what machines can achieve in understanding and generating human language. However, the philosophical implications of their capabilities and limitations invite ongoing scrutiny and debate within both the AI community and broader philosophical discourse.

User
2. A Wittgensteinian defence of Language Model 
meaning 
2.1 The Tu Quoque Argument 
Te clearest way to see the Wittgensteinian point is as a 
tu quoque argument against the error theorist. Te er- 
ror theorist alleges that machines don’t grasp meanings, 
where a meaning is some kind of intentional content that 
normatively governs both linguistic behaviour and the ap- 
propriate interpretation of that behaviour. Tese meanings 
make it (in)correct for the models to apply a word and 
(in)correct for us to ascribe their text a particular content. 
When a speaker grasps or intends the meaning of an ex- 
pression, that meaning constrains what would be the right 
way to use it. For example, it is the meaning of the word 
‘cat’ which makes it inappropriate to call a dog a ‘cat’ and 
it is this meaning that an interpreter tries to infer from a 
body of text. If LLMs’ linguistic output is not normatively 
governed by a set of meanings, then it is wrong to attribute 
meaning to their texts. Te Wittgensteinian response is to 
say that the same holds for human beings. Te idea of a 
meaning that stands behind the use of a word and which 
normatively constrains both application (when it is right 
to apply that word) and attribution (what is the meaning 
behind the usage of a word) is a myth. 
Tis is not a point that can be simply justifed within 
a single chain of argument (if it were, then Wittgenstein 
scholarship would be much easier). Instead of attemp- 
ting to do that, I’ll present three core themes from the 
Philosophical Investigations and consider them in relation 
to contemporary language modelling. Tey are; seman- 
tic anti-foundationalism, his discussion of semantic nor- 
mativity, and his attack on a traditional way of viewing 
understanding. Each of these topics touches on the role 
that others play in constituting the meaningfulness of our 
speech. 
2.2 Semantic anti-foundationalism 
Semantic anti-foundationalism is the claim that there is 
no foundational linguistic practice (i.e. language game) 
from which other kinds of linguistic activity gain their 
WITTGENSTEIN, THE OTHER, AND LARGE LANGUAGE MODELS 81 
FINTAN DECLAN MALLORY 
signifcance. It is best understood as the negation of se- 
mantic foundationalism. A common form of semantic fo- 
undationalism is the idea that the foundational language 
game we play is the assertion of true or false declarative 
sentences. By treating this as the basic linguistic practice, 
we can analyse the meaning of expressions in terms of how 
they contribute to the fulflment of this function, thereby 
justifying the central claim of truth-conditional semantics 
that, “to know the meaning of a sentence is to know its 
truth conditions” (Heim & Kratzer, 1998: 1). Te task of 
a theory of meaning, thus conceived, is to explain how a 
grasp of the truth-conditions of a sentence depends upon 
a grasp of subsentential expressions and how they are se- 
mantically combined. Te great challenge for the truth- 
conditional framework has been to show how this model 
can be extended to account for sentences that don’t clearly 
ft this model; counterfactuals, fction, imperatives, inter- 
rogatives, etc., and the truth-conditional project has made 
considerable progress in clarifying not only the logical 
form of such sentences but our preconceptions about what 
they are about.
ChatGPT
The Wittgensteinian defense of language model meaning, particularly through the lens of semantic anti-foundationalism, challenges traditional notions of meaning in linguistics and philosophy. This perspective contests the error theorists' claim that only human beings can grasp meanings in a way that properly governs linguistic behavior and interpretation. Wittgenstein's insights into the nature of language and meaning offer a compelling argument against this restrictive view, suggesting that the mechanisms underlying meaning in human language can also apply to the outputs of large language models (LLMs).

The Tu Quoque Argument
The tu quoque argument, literally meaning "you too" in Latin, is used here to highlight that the criticisms leveled against language models for their supposed lack of understanding can also be directed at human language users. Wittgenstein challenges the notion that there is a clear, normative standard (a meaning) that definitively guides both the use of language and its interpretation. This idea, that meanings are entities that prescriptively govern how words should be used and understood, is critiqued as being overly simplistic and not reflective of how language actually functions in human practices.

Semantic Anti-foundationalism
Wittgenstein's semantic anti-foundationalism rejects the idea that there is a single, foundational linguistic practice from which all other linguistic activities derive their meaning. Instead of adhering to the truth-conditional semantics—which posits that understanding a sentence means knowing its truth conditions—Wittgenstein argues that meaning arises from the varied and complex ways in which language is used within forms of life and linguistic communities.

This perspective implies that meaning is not a fixed property inherent in words or sentences but emerges from their use in specific contexts. For language models like BERT and GPT-3, this suggests that the meaningfulness of their outputs does not necessarily hinge on an internal grasp of truth conditions but can be seen as meaningful within the broader context of their use and the interactions they facilitate.

Implications for Language Models
Adopting a Wittgensteinian approach to understanding language models has several implications:

Contextual Meaning: It supports the view that the text generated by LLMs can be considered meaningful when viewed within the broader context of their use, including how humans interpret and interact with these outputs.

Flexibility of Meaning: It highlights the flexibility and variability of meaning, suggesting that LLMs, through their capacity to generate contextually relevant responses, can participate in the dynamic process of meaning-making.

Beyond Truth Conditions: It challenges the necessity of aligning the outputs of LLMs with strict truth-conditional semantics, opening up a broader understanding of how these models can generate text that is meaningful in practical, interactive contexts.

By framing the debate around language models within Wittgenstein's philosophical insights, we are invited to reconsider what it means for language—whether human or machine-generated—to be meaningful. This approach does not diminish the complexities and challenges of interpreting and engaging with language models but encourages a more nuanced exploration of the boundaries between human and machine language use.

User
Truth-theoretic foundationalism provides the stron- 
gest criticism of contemporary language models. A system 
like BERT has absolutely no interest in producing true 
rather than false answers (Ettinger, 2020). A model that 
cannot grasp the diference between a true output and a 
false one, that merely relies on probabilistic information, 
fails to grasp the single most important property underly- 
ing language use. If a model cannot register the diference 
between true and false statements, it cannot grasp truth- 
conditions, and so it cannot grasp how the meaning of an 
expression determines the truth-conditions of a sentence 
in which it occurs. It has no grasp of meaning and so mea- 
ning should not be attributed to its outputs. Importantly, 
this point would hold even if a model produced only true 
completions of sentences. 
All of these theories share the central assumption that 
there is a fundamental thing language is for which con- 
strains the single correct approach to natural language se- 
mantics. Te general assumption is that the purpose of 
language has something to do with describing the world 
to others, in other words, saying things that are either 
true or false. Te idea that sentences are for describing the 
world is mirrored and supported by a second claim that 
expressions are for referring to the things in the world. Te 
idea that language has a descriptive function that under- 
lies all others is one of Wittgenstein’s main targets in the 
Philosophical Investigations. 
2.3 The Wittgenstein Benchmark 
Wittgenstein’s response to the description-based view of 
the function of language is to present examples of langua- 
ge games that have little to nothing to do with describing 
the world: 
23: Consider the variety of language-games in the fol- 
lowing examples, Here the term “language-game” is 
meant to bring into prominence the fact that the spea- 
king of language is part of an activity, or of a form of 
life. Review the multiplicity of language-games in the 
following examples, and in others: 
Giving orders, and obeying them— 
Describing the appearance of an object, or giving its 
measurements 
Constructing an object from a description (a 
drawing)— 
Reporting an event— 
Speculating about an event— 
Forming and testing a hypothesis— 
Presenting the results of an experiment in tables and 
diagrams— 
Making up a story; and reading it— 
Play-acting— 
Singing catches— 
Guessing riddles— 
Making a joke; telling it— 
Solving a problem in practical arithmetic— 
Translating from one language into another— 
Asking, thanking, cursing, greeting, praying.
ChatGPT
The critique of truth-theoretic foundationalism in relation to contemporary language models like BERT reflects a fundamental disagreement about the essence of language and its uses. According to critics, the inability of these models to distinguish between truth and falsehood in their outputs is a significant shortcoming, as it suggests a lack of understanding of truth conditions and, by extension, meaning. This criticism hinges on the assumption that the primary function of language is to describe the world in terms of truth or falsehood.

Wittgenstein's Challenge to Descriptive Primacy in Language
Wittgenstein's Philosophical Investigations directly challenges this view by proposing that language serves a multitude of functions beyond mere description. Through his concept of "language games," Wittgenstein emphasizes that language is part of an activity or a form of life, with each game governed by its own rules and purposes. The variety of language games he describes—ranging from giving orders and reporting events to making jokes and solving problems—illustrates the richness and complexity of linguistic practices. This multiplicity suggests that language's function cannot be reduced to the conveyance of truth-conditional content alone.

Implications for Language Models
Applying Wittgenstein's perspective to the debate on language models reveals several insights:

Beyond Truth and Falsehood: If language encompasses a wide range of activities, many of which are not directly concerned with describing the world accurately, then the criterion of distinguishing truth from falsehood may not be as central to language use as critics of language models suggest.

Functionality and Meaningfulness: The meaningfulness of a model's outputs need not be contingent on its grasp of truth conditions. Instead, meaning can arise from how these outputs are used within specific contexts and language games. For instance, a language model engaged in storytelling or making jokes is participating in language games where the distinction between true and false statements is not the primary concern.

Language as Activity: Viewing language as part of an activity or form of life allows for a broader interpretation of the capabilities of language models. By generating text that can be integrated into various human activities—be it conversational interaction, creative writing, or informational queries—language models can be seen as engaging in certain types of language games, even if their participation is not grounded in an understanding of truth conditions.

Conclusion
Wittgenstein's critique of descriptive primacy in language and his emphasis on the diversity of language games offer a compelling framework for defending the meaningfulness of language model outputs against truth-theoretic foundationalism. This perspective encourages a reassessment of what it means for language—whether human or machine-generated—to be meaningful, highlighting the importance of context, activity, and use over adherence to truth conditions. By recognizing the multiplicity of language's functions, we can appreciate the ways in which language models may contribute to our linguistic practices, even if they do not engage with language in the same way humans do.

User
Tis list (we might call it the Wittgenstein Benchmark) 
constitutes a more challenging benchmark than Turing’s 
breakdown of the activities which might be involved in 
a Turing test but something less challenging than the 
BIGBenchmark proposed by 444 researchers last year 
(Srivastava, a. et al., 2022). In any case, it is worth looking 
at the state of the art in the feld to see how they are hand- 
ling the Wittgenstein benchmark. 
In some cases, we have to make some interpretive li- 
cense to assess whether these language games have been 
solved. Instead of giving and obeying orders, we might ask 
how language models produce computer code. ChatGPT 
has arguably succeeded at producing functional code, re- 
porting events, and making up stories and jokes. Stable 
difusion models such as Dalle-2 have made considerable 
advances in constructing objects from descriptions while 
Generative Image to Text Transformers have surpassed hu- 
mans in their ability to classify certain images (Wang et al. 
ARTIKKEL INTERVJU & FORSKNING SPALTER BREV 
82 
2022). One of the most surprising elements of research 
is how difcult solving practical mathematical problems 
has been. While Minerva can score average in the polish 
national math exam, it requires considerable fne-tuning 
and a system like GPT-3 still fails at basic mathematics. 
Machine translation has made massive improvements in 
recent years, frst with Seq2Seq models. As for the fnal ca- 
tegories, if one has a rich theory of the relevant speech acts, 
one would likely claim that none of the existing examples 
are adequate. Nevertheless, even error theorists are likely 
to have engaged with customer service bots that greeted 
them, asked them for information (about cinema tickets, 
what they wanted to know more about), and thanked 
them when the exchange was over. Such critics may wish 
to deny that such an event ever really happened and they 
will be theoretically well-supported, but will presumably 
want to act as though things actually did occur for legal 
and practical purposes. 
It’s fair to say that up until now, language modelling 
has progressed in a broadly Wittgensteinian, divide-and- 
conquer fashion. While this is best explained by the incen- 
tive structures of the research feld (an emphasis on con- 
ference proceedings etc.) rather than any explicit commit- 
ment to semantic anti-foundationalism, if Wittgenstein is 
correct, it is also justifed by the nature of the phenome- 
non of language. 
In a sense, semantic anti-foundationalism is akin to 
the claim that no language game is ‘AI-complete’. In some 
cases, research has focused on particular tasks due to the 
belief that a particular task would require the development 
of intelligence or ‘common sense’ in order to be solvable 
(the Winograd schema challenge would be an example, for 
details, see Marcus et al., 2022). Te representations that 
a language model needs to acquire if it is to successfully 
ground human-like linguistic behaviour will need to sup- 
port a diversity of usage. Truth-conditional semantics is, 
at best, grounded in an idealisation that is useful for the 
modelling of certain functional expressions, quantifers, 
modals, (some) determiners, but this idealisation shouldn’t 
be mistaken for a fundamental property of the system be- 
ing described.
ChatGPT
The exploration of language models through the "Wittgenstein Benchmark" presents an innovative approach to assessing the capabilities of these models in handling a variety of language games. This benchmark proposes a set of challenges that reflect Wittgenstein's perspective on the multifaceted nature of language use, extending beyond the purely descriptive function of language to include activities such as giving and obeying orders, making up stories and jokes, solving practical arithmetic, and translating languages, among others.

Progress in Meeting the Wittgenstein Benchmark
Language models, particularly advanced ones like ChatGPT and those involved in stable diffusion and generative image-to-text transformations, have shown remarkable progress in several areas outlined by the Wittgenstein Benchmark:

Producing Computer Code: Models like ChatGPT have demonstrated an ability to generate functional computer code, showcasing proficiency in a form of giving and obeying orders in a digital context.

Reporting Events and Storytelling: These models have also succeeded in reporting events and crafting stories and jokes, engaging in creative and narrative language games.

Constructing Objects from Descriptions: Advances in stable diffusion models such as DALL-E 2 illustrate significant progress in visual creativity, translating textual descriptions into images.

Solving Mathematical Problems: While more challenging, models like Minerva have shown potential in solving practical mathematical problems, albeit with limitations.

Machine Translation: The field of machine translation has seen substantial improvements, demonstrating the ability to translate between languages effectively.

Challenges and Considerations
Despite these advancements, the Wittgenstein Benchmark highlights several challenges and philosophical considerations:

Diverse Language Use: The benchmark underscores the necessity for language models to support a diversity of uses, aligning with Wittgenstein's anti-foundationalism. This diversity challenges models to go beyond truth-conditional semantics and engage in a wider range of linguistic activities.

Limitations in Certain Areas: Practical mathematical problem-solving and the full embodiment of speech acts in conversational contexts remain challenging for current models. These limitations suggest areas for future research and development.

Philosophical Implications: The progress and challenges associated with the Wittgenstein Benchmark reflect deeper philosophical questions about the nature of language, understanding, and intelligence, both human and artificial.

Conclusion
The exploration of large language models through the Wittgenstein Benchmark reveals both the impressive capabilities of these models and the complexities of fully replicating human linguistic behavior. While language models have made considerable strides in various language games, challenges remain, particularly in areas requiring deeper understanding or common sense. The Wittgenstein Benchmark not only provides a nuanced framework for assessing the progress of language models but also invites ongoing philosophical reflection on the essence of language and the potential for artificial systems to engage meaningfully in the rich tapestry of human linguistic practices.

User
2.4 Normativity of meaning 
While the frst argument focussed on the function of lan- 
guage, the second focuses on the normative signifcance of 
language use. Specifcally, it attacks a traditional story that 
conceptualises this normativity in terms of meanings. Te 
traditional story goes something like the following — To 
know the meaning of the word is to grasp something that 
binds you to act in a certain way under pain of using that 
word incorrectly. When a human being calls a spade a ‘spa- 
de’ they are right (correct) to do so. Tey may be wrong 
on some occasions — maybe it’s a rake and they misjud- 
ged — but they aren’t just responding deterministically to 
an input, they are doing something that is subject to a 
particular kind of evaluation. It may be helpful to think 
about this normativity in terms of justifcation. Humans 
can typically justify their behaviours and they can do so 
because they have reasons for acting as they do. In this 
case, the chief reason we call a spade a ‘spade’ is because 
that is what ‘spade’ means! ‘Spade’ is the correct word for 
spades and it is wrong to call them by other words like 
‘duck’ or ‘rabbit’. Since we cite meanings when giving our 
reasons for using a word, it’s reasonable to assume that the 
meaning is the source of this normativity. Te meaning of 
the word makes it right or wrong to use it as we do; lexical 
selection is justifed by lexical content. Furthermore, when 
we say that the human speaker is right or wrong in their 
use of language, we are taking a normative stance toward 
them. We are holding them responsible for their linguistic 
behaviour. To hold them responsible suggests that they are 
in control of their linguistic behaviour and that they have 
some degree of choice over their words and could, in a 
sense, choose otherwise. 
In contrast to this, LLMs do not have reasons for pro- 
ducing their outputs and do not choose the words they 
produce. Tey simply predict the most probable output 
token in a deterministic fashion. Tey receive an input, 
pass it through the layers of a neural network, and depen- 
ding on their training, they generate an output distribu- 
tion. Because this process is automatic and unthinking, 
they cannot have reasons for what they do and so it is not 
appropriate to treat them as responsible for their outputs 
in the same way we would treat a human. Teir process of 
lexical selection is not rational. Te machine cannot have 
done otherwise, and so it cannot have been responsible for 
what it does. It is just computing probabilities. 
Te Wittgensteinian response to this objection is to 
argue that, in whatever sense our linguistic behaviour is 
normative, it is not normative because it is governed by 
meanings. Meanings cannot be discrete, mind-internal en- 
tities that normatively bind us (and we do not have a con- 
tract with them, to use Wright’s analogy, Wright, 1980: 
19). For example, if meanings normatively constrain our 
behaviour, then they presumably operate like rules such 
that one misuses a word as one breaks a rule. But, at least 
on one reasonable understanding of what it means to fol- 
low a rule, you need to know what the rule tells you in 
WITTGENSTEIN, THE OTHER, AND LARGE LANGUAGE MODELS 83 
the frst place; you need to interpret it and understand its 
scope of application. Te idea of a meaning-determining 
rule is an inadequate bedrock for a theory of meaning. To 
suggest that there is a rule for interpreting one’s rules is just 
to push the problem back a level. 
217. “How am I able to follow a rule?” If this is not 
a question about causes, then it is about the justifca- 
tion for my acting in this way in complying with the 
rule. Once I have exhausted the justifcations, I have 
reached bedrock, and my spade is turned. Ten I am 
inclined to say: “Tis is simply what I do.”
ChatGPT
The argument focusing on the normativity of language use challenges the traditional understanding that meanings inherently govern our linguistic actions, determining correctness or incorrectness. This perspective holds that to know the meaning of a word is to be bound by certain rules of use, making our linguistic behaviors subject to normative judgments of right and wrong.

Human vs. Machine Language Use
Humans, in using language, are typically thought to act with awareness and intentionality, capable of justifying their use of words based on meanings. This justification is rooted in the belief that meanings give reasons for our linguistic choices, establishing normative standards for word use. Conversely, Large Language Models (LLMs) like GPT-3 operate deterministically, generating text based on statistical probabilities without any semblance of understanding or intentionality. Since these models do not "choose" words in the human sense, it's argued that they cannot be held responsible for their outputs, nor can their outputs be normatively evaluated in the same way human language can.

Wittgenstein's Critique of Meaning as Rule-following
Wittgenstein's response to the conception of language as normatively governed by meanings challenges the foundational role attributed to meanings in linguistic normativity. He argues that meanings are not private, mind-internal entities that bind our behavior. Instead, he suggests that our understanding of rules and meanings is inherently public and grounded in shared practices. Following a rule, or using a word correctly, isn't about adhering to an internal or pre-established meaning but engaging in a form of life where such rules have their application.

Implications for Language Models
Wittgenstein's critique has profound implications for how we view the outputs of language models:

Public Nature of Language: If meanings and rules are public and not bound to private mental entities, the distinction between human and machine use of language becomes less about the presence or absence of internal states and more about participation in shared linguistic practices.

Normativity and Responsibility: The challenge of attributing normative responsibility to language models highlights the need to rethink our criteria for meaningful language use. If language's normativity arises from communal practices rather than internal rules or meanings, then the meaningfulness of LLM outputs might be assessed based on their integration and utility within human linguistic activities, rather than their adherence to truth conditions or ability to act with intention.

Reevaluating Language Model Capabilities: Wittgenstein's perspective invites us to reconsider what it means for language models to generate meaningful text. It suggests that meaningfulness may emerge not from the models' internal processes but from the ways in which their outputs are embedded in, and contribute to, human linguistic practices.

In summary, Wittgenstein's insights into the normativity of language challenge traditional assumptions about meaning and correctness in language use, offering a framework that could allow for a more inclusive understanding of language models' capabilities and limitations. This approach encourages a shift from focusing on internal states or intentions towards considering the broader context of language use and the communal practices that give language its meaning.

User
What is inside an LLM if it isn’t a set of meanings? Aren’t 
word embeddings mentioned just that? Te matter is more 
complicated than this and so working through an example 
can be helpful. Consider a relatively simple transformer- 
based neural network (Vaswani et al., 2017). While in use, 
the network performs a variety of mathematical operations 
on numerical inputs. Tese numerical inputs may, over 
time, come to have something like representational pro- 
perties (I’m at least optimistic that we can develop a theory 
explaining exactly what this means) but in such a network, 
there is no single vector that corresponds to the meaning 
of a sentence. Te input will be a list of vectors, each cor- 
responding to some substring of the sentence or text being 
processed (a vector is a list of numbers). For example, it 
might have a unique vector for each word in the vocabula- 
ry. Tese will then be summed and augmented with infor- 
mation about the linear order of the string (since addition 
alone wouldn’t indicate this). A simple endorsement of 
Frege’s context principle would suggest that this is needed, 
at least, if we are to talk about meaning since an expression 
only has meaning in the context of a sentence. However, 
the structure of a sentence is going to be richer than mere 
linear order. Further layers use attention heads to produce 
contextual embeddings. Tese representations are sensitive 
to the difering importance of some words in the sentence 
for the interpretation of others. It isn’t clear how many at- 
tention layers are required to generate syntactic structure 
and neither is it clear how much structure is needed and 
it may be the case that not every attention layer matters. 
Next, we have the feedforward layers. Tese are the layers 
which have been trained on the particular task for fne- 
tuning. Te penultimate layer gathers the fnal values of all 
preceding layers and feeds them into a softmax function by 
which a probability distribution is generated that indicates 
the network’s assessment of its output. Troughout this, 
there is no single internal ‘meaning’ governing the process. 
Tere is no layer at which it is appropriate to point and say 
‘Tis is the meaning of the sentence’. It may make more 
sense to view the meaning in this case as the whole process 
itself, but if this is the case, it is not ‘governing’ the process. 
Te Wittgensteinian moral is that, just because we 
can’t point to ‘the meaning’ in the system, this doesn’t 
mean that the output is meaningless. It may be the case 
that we can’t point to the (internally represented) ‘mea- 
ning’ in the case of human linguistic behaviour. I take it 
that Wittgenstein’s idea here is that one can be more or less 
justifed when using a word but that this justifcation does 
not depend upon the presence of a meaning in the head of 
the speaker since, even if such things did exist, we simply 
couldn’t justify our linguistic behaviour by appealing to 
them. Giving account of yourself is not the same as descri- 
bing the reason for which you acted.
ChatGPT
Inside a Large Language Model (LLM), rather than a singular repository of meanings for each word or sentence, there exists a complex network of mathematical operations and representations. This intricacy is illuminated when considering the workings of a transformer-based neural network, which processes language not by accessing predefined meanings but through a series of computations involving numerical inputs, or vectors, corresponding to parts of the language being analyzed.

How LLMs Process Language
Numerical Representations: Initially, words or sub-strings are represented as vectors—lists of numbers. These vectors do not inherently carry meanings but are numerical representations that the model uses in computations.

Contextual Embeddings: Through attention mechanisms, the model adjusts these vectors based on the context within the sentence, recognizing the relevance of certain words to others. This process creates contextual embeddings that reflect a nuanced understanding of language beyond simple word-to-vector mappings.

Syntactic Structure: The exact manner and extent to which transformer networks capture syntactic structure remain areas of ongoing research. However, it's clear that the model's architecture, through attention layers and feedforward layers, attempts to account for the complexities of sentence structure beyond mere linear order.

Probabilistic Outputs: The culmination of these processes is a probability distribution generated by the model, predicting the most likely output based on the input and the internal representations it has constructed. This outcome is derived from the entirety of the computational process rather than from discrete, internalized meanings.

The Wittgensteinian Perspective
The operation of LLMs resonates with Wittgenstein's views on meaning and language use. Just as Wittgenstein argued that meanings are not private, mind-internal entities but arise from use within forms of life and linguistic practices, the "meaning" in an LLM emerges from the complex interplay of its computational processes and how its outputs are engaged with and interpreted in practice.

Justification and Meaning: Wittgenstein suggests that the justification for using a word correctly does not hinge on an internal representation of its meaning. Similarly, the meaningfulness of an LLM's output does not depend on a singular, governable meaning within the model but on the entirety of its computational process and how this process aligns with human linguistic practices.

Meaning as Process: Viewing meaning as the whole process rather than a discrete component governing it aligns with the Wittgensteinian idea that meaning emerges from use. In the case of LLMs, the "meaning" of an output might best be understood in terms of the model's interactions with input data, its internal processing, and how its outputs are utilized and interpreted.

Conclusion
Understanding the workings of LLMs through a Wittgensteinian lens challenges traditional notions of meaning as a fixed, internal property, whether in human minds or artificial systems. It suggests that meaningful language use—by humans or machines—arises not from discrete meanings but from dynamic processes of interaction, computation, and interpretation. This perspective encourages a broader view of how artificial systems might engage in meaningful linguistic behavior, grounded not in the possession of meanings but in their capacity to participate in the complex web of language use.

User
2.5 Understanding 
Tis brings us to the fnal point. It is often claimed that 
LLMs lack understanding. While they can produce strings 
of text and correctly perform certain text-based tasks, they 
don’t understand what they are doing and they don’t in- 
tend to use the expressions they produce. Linguistic beha- 
viour is accompanied by a particular suite of mental acti- 
vities that are absent in the case of LLMs which have no 
more understanding than a (stochastic) parrot. 
Again, the Wittgensteinian response to this argument 
is to deny that human linguistic activity has these pro- 
perties either. In particular, Wittgenstein rejects the idea 
that talk of understanding or intention serves to pick out 
a mental state. 
Neither the expression “to intend the defnition in 
such-and-such a way” nor the expression “to interpret 
the defnition in such-and-such a way” stands for a 
process which accompanies the giving and hearing of 
the defnition. (PI34) 
Now we try to get hold of the mental process of under- 
standing which seems to be hidden behind those co- 
arser, and therefore more readily visible, concomitant 
phenomena. But it doesn’t work; or, more correctly, it 
does not get as far as a real attempt. (PI153) 
Te particular model of understanding that Wittgenstein 
attacks is the idea that there is a particular mental image, 
event or process that occurs when one understands a word 
and which makes it the case that one has understood the 
word. Te problem with this model is that it is unclear 
ARTIKKEL INTERVJU & FORSKNING SPALTER BREV 
FINTAN DECLAN MALLORY 
84 
why there should be a connection between any particu- 
lar event and the accomplishment of understanding. Say 
understanding only occurred when one had a particular 
image in one’s mind (or access to such an image), the fact 
of concurrence would be insufcient to ground the claim 
that understanding consisted in the concurrence. We 
would have no further reason to think that this particular 
mental tokening rather than any other is what counts as 
understanding. Te category of ‘understanding’, the lan- 
guage-game we play when we use the term, should not be 
analysed as a game which involves describing some inter- 
nal state of an agent. When we refect on how talk of ‘un- 
derstanding’ is used—the language game it belongs to—it 
appears to provide a normative rather than a descriptive 
purpose. It does not denote a state internal to the human 
mind but absent from a language model. 
Te consequences of divorcing meaning from cognitive 
categories such as understanding may not actually be what 
proponents of ‘artifcial intelligence’ desire. It may involve 
granting that LLMs produce meaningful text but denying 
that this is an indication of any intelligence on their part. 
Tis separation would have consequences for both sides 
of the debate we considered above. Rather than invoking 
Gricean, intention-based ideas to combat ‘AI hype’, rese- 
archers could reject the claim that only intelligent agents 
(i.e., agents with communicative intentions) can produce 
meaningful text or speech. Just as we shouldn’t assume 
that a text is only meaningful if produced by an intelligent 
agent, we shouldn’t attempt to infer intelligence from a 
system’s ability to produce text. If this is the case, then the 
Turing Test must be not only abandoned but subjected to 
rigorous critique due to its misleading cultural infuence. 
Te issue would not just be whether text produced by an 
LLM is meaningful but whether the ability to reliably produce meaningful text in a range of contexts is an adequate 
measure of intelligence while it is increasingly looking like 
it isn’t.
ChatGPT
The final point regarding understanding and its relation to language use brings to light one of the central debates surrounding Large Language Models (LLMs) and artificial intelligence more broadly: the question of whether these systems truly "understand" the language they generate or manipulate.

Wittgenstein on Understanding
Wittgenstein challenges the traditional notion that understanding is a mental state or process that accompanies the use of language. He argues that understanding is not about having a specific mental image or process that occurs when one comprehends language. Instead, he suggests that the notion of understanding is more about participating correctly in the "language game" – engaging with language in ways that align with the norms and practices of its use. This perspective implies that understanding is not an internal, mental phenomenon but a matter of external, observable linguistic behavior.

Implications for LLMs
Applying Wittgenstein's view to LLMs leads to several intriguing conclusions:

Meaningful without Understanding: It is possible to consider the outputs of LLMs as meaningful without attributing to them the capacity for understanding in the traditional sense. If understanding is not a requisite mental state but a matter of engaging appropriately in linguistic practices, then the meaningfulness of LLM-generated text need not depend on the presence of internal cognitive processes akin to human understanding.

Separation of Meaning and Intelligence: This perspective allows for a separation between the production of meaningful text and the attribution of intelligence. Just because an LLM can generate text that is meaningful within certain contexts does not necessarily imply that the system possesses intelligence, especially not in the sense of having intentions, beliefs, or the capacity for understanding.

Critique of the Turing Test: If the ability to produce meaningful text does not equate to intelligence, then the Turing Test, which assesses a machine's intelligence based on its indistinguishability from a human in text-based conversation, may be fundamentally flawed. The test's reliance on linguistic indistinguishability as a marker of intelligence becomes questionable if meaningful language use does not require the kind of understanding or intentionality traditionally associated with human intelligence.

Conclusion
Wittgenstein's insights into the nature of understanding and language use challenge us to reconsider our criteria for meaningful language and intelligence in the context of artificial systems like LLMs. By decoupling the generation of meaningful text from the presence of human-like understanding or intelligence, we open up new avenues for appreciating the capabilities of these systems while also recognizing their limitations. This approach encourages a more nuanced view of AI's role in linguistic practices, one that acknowledges the complexity of language and understanding without overestimating the cognitive capacities of current technologies.

User
Te onus on someone who adopts this position and ar- 
gues that text can be meaningful even when it was not pro- 
duced to convey someone’s meaning, is to give an account 
of text meaning that doesn’t appeal to a prior intelligence. 
Tere is considerable philosophical precedent for this, and 
accordingly, a considerable philosophical literature enga- 
ging with its implications. While the analytic tradition of 
philosophy, through the infuence of Grice, Davidson, and 
others, has stressed that meaningful linguistic behaviour 
is fundamentally a kind of intentional activity, other tra- 
ditions, committed to the ‘death of the author’ and the 
idea that understanding a text is emphatically not a matter 
of determining authorial intentions present alternative ap- 
proaches (for example, see Foucault, 1969, for a discussion 
of the role of authors in a post-structuralist context and 
Clooney, 1987, for a discussion of the authorlessness of 
the Vedas according to the Mīmāṃsā school of classical 
Hindu philosophy). Tere would be a range of philosop- 
hical challenges for anyone pursuing this line of theorising 
for machine-generated text, from accounting for pragma- 
tic enrichment to the authority testimony, but these are 
not prima facie insurmountable. 
3. Responses 
It is important to stress that the three lines of argument, 
while Wittgensteinian in nature, are not intended as an ar- 
ticulation of what Wittgenstein would have thought about 
contemporary work on language modelling. I think they 
should each be treated with suspicion. For the rest of the 
paper, I will consider equally Wittgensteinian responses to 
them appealing to forms of life, agency, and community. 
Te frst line of response can broadly be characterised 
as the ‘form of life’ response.3 A classic version of this can 
be found in Hubert Dreyfus’s criticisms of ‘Good Old 
Fashioned Artifcial Intelligence’. Dreyfus’s arguments 
were primarily directed against rule-based systems which 
sought to reduce intelligent behaviour to the operation of 
a set of rules. In Dreyfus’s words, “Nothing short of a for- 
malisation of the human form of life could give us artif- 
cial intelligence (which is not to say that this is what gives 
us normal intelligence)” (Dreyfus, 1992: 134). While the 
frst part of this may seem less relevant as contemporary 
systems are, for better or worse, less explicitly rule-based, 
the idea that a grasp of semantic content, even if this 
doesn’t involve appeal ‘meanings’ requires something like 
human-like experience is more compelling. Even if LLMs 
can represent very primitive content, in accordance with 
their design and the claims of weak content theorists, they 
would not be able to actually grasp the meanings of the 
tokens they wield without having something like human 
experiences. At present LLMs are trained on datasets of 
human-generated texts with the hope that they will ac- 
quire natural languages from this, but they don’t have the 
distinctly human experiences which connect these texts to 
the world. Te argument is something like the following: 
If the meaning is what a person understands when they 
understand a word, a part of this involves connecting the 
word to their own experiences. A system that lacks experi- 
ences tout court, or at least human-like experiences, lacks 
this understanding, and so its outputs should not be inter- 
preted as meaning whatever a human would mean by pro- 
WITTGENSTEIN, THE OTHER, AND LARGE LANGUAGE MODELS 85 
ducing the same text. If one fnds this version of the ‘forms 
of life’ response regressively subjectivist (failing to make 
basic Fregean distinctions between sense and concep- 
tions), one might prefer a version grounded in the embo- 
diment required to ground an externalist semantics. Some 
semantic externalists have argued that a machine would 
require ‘direct causal interaction with the environment’ for 
their words to stand in the appropriate causal chains to re- 
fer to kinds within the world (Schweizer, 2012). Te onus 
on the proponent of this response is to elaborate which 
causal chains are necessary and why. As humans clearly 
learn some of their words from textual sources, the claim 
can’t simply be that text isn’t appropriately causally linked 
to the rest of the world. If the claim is that there is a mini- 
mum level of perceptual capacities required for linguistic 
understanding, the task then becomes to identify these 
abilities (which may include the ability to represent space 
and time) and explain why they are required.
ChatGPT
The discussion around the meaningfulness of text generated by Large Language Models (LLMs) without explicit intent to convey meaning delves into complex philosophical territory, challenging traditional views of language and meaning rooted in authorial intent and human-like understanding. The consideration of alternative philosophical perspectives, including post-structuralist theories and classical Hindu philosophy, offers a broader framework for understanding machine-generated text, expanding the discourse beyond the analytic tradition's emphasis on intentional activity.

The Challenge to Traditional Semantics
The assertion that text can be meaningful without being produced to convey specific authorial meanings necessitates a reevaluation of semantic theories. This reevaluation confronts long-held assumptions about the connection between meaning, authorial intent, and human experience, proposing instead that meaning can emerge from text independent of a human author's specific intentions.

The "Form of Life" Response
This response draws on the idea that understanding language and its meanings requires participation in a human "form of life," encompassing shared practices, experiences, and ways of engaging with the world. The critique of contemporary AI and LLMs from this perspective focuses on the systems' lack of human-like experiences and embodiment, arguing that without these, LLMs cannot truly grasp the meanings of the words they use.

Human Experience: The argument posits that genuine understanding involves connecting words to one's own experiences. Since LLMs lack experiences or, more specifically, human-like experiences, they cannot understand language in the way humans do.

Semantic Externalism: Some externalists argue for the necessity of direct causal interactions with the environment for words to meaningfully refer to objects or concepts in the world. This perspective suggests that a machine would need to be embedded in specific causal chains to achieve referential meaning.

Philosophical Implications and Challenges
These criticisms raise important questions about the prerequisites for meaningful language use and the role of embodiment and experience in understanding. They challenge proponents of meaningful machine-generated text to articulate a theory of meaning that does not rely on human-like cognition or experiences. Moreover, they invite a closer examination of what constitutes the necessary and sufficient conditions for language understanding and the potential for machines to meet these conditions.

Identifying Necessary Capacities: A critical task for those defending the meaningfulness of machine-generated text is to delineate the specific perceptual and cognitive capacities required for linguistic understanding and to argue why these are essential. This task includes clarifying the role of embodiment, direct environmental interaction, and the capacity to represent space and time.
Conclusion
The debate surrounding the meaningfulness of LLM outputs, informed by Wittgensteinian considerations and responses grounded in the concepts of forms of life and semantic externalism, highlights the profound philosophical challenges at the intersection of language, meaning, and artificial intelligence. It underscores the need for ongoing dialogue and exploration within philosophy and cognitive science to deepen our understanding of these issues and to assess the capabilities and limitations of language models within the broader landscape of human linguistic practices.

User
A second idea might be to jettison the idea that ‘un- 
derstanding language’ can be made sense of independent 
of linguistic agency. Tis stresses the role of practical acti- 
vity within a form of life. While current discussions often 
focus on whether or not a model ‘understands language’, 
it’s often less than clear what this detached notion of un- 
derstanding or philosophical phrases like ‘grasping a sense’ 
is supposed to be. Current benchmarks attempt to break 
understanding down into manageable, evaluable chunks 
but at the cost of decontextualising the use of language 
from agency more generally. Methods of evaluation typi- 
cally involve prediction tasks, string mapping or classifca- 
tion (e.g., sentiment analysis), question answering, word- 
sense disambiguation, coreference resolution etc. (see the 
tasks listed in the SuperGLUE or BIGbench benchmarks). 
It’s questionable whether any of these tasks can be descri- 
bed as ‘using language’. Behind these testing paradigms 
stands the idea of detached comprehension, the idea that 
understanding a language is a matter of mapping units of 
language to other units of language. Few tests integrate 
language with practical activities. Perhaps a better goal 
than producing machines with ‘linguistic understanding’, 
a notion which Wittgenstein called into question, might 
be to aim for artifcial ‘linguistic agency’. A machine has 
linguistic agency when it can accomplish its ends by me- 
ans of language. Tose ends may be directly practical (‘pass 
the milk’) or they may be epistemic (‘where is the milk sto- 
red?’) but essential to them that the goal can be represen- 
ted independently of the means to achieve it linguistically. 
It may be that there can be no meaning without linguistic 
agency and no linguistic agency without other forms of 
agency (or means-end reasoning) which language models 
are not trained to manifest. 
A fnal approach is to embrace the role that commu- 
nity plays in our ascriptions of meaning. Tis would be the 
response of a more communitarian Wittgenstein (Kripke, 
1982). Te idea here is that the normativity distinctive 
of meaning is grounded in social norms of interpretation. 
Linguistic behaviour is not subject to assessments of cor- 
rectness because speakers are responsible to meanings in 
their head but because they are responsible to other mem- 
bers of their linguistic community to use words a certain 
way. It is only from the external perspective of a linguistic 
community that we can think of an individual language 
user as ‘responsible’ for their linguistic behaviour. As long 
as language models fail to be members of our linguistic 
communities, they are not bound by these norms and so 
not entitled to ascriptions of content. One might phrase 
this thought as follows: You shouldn’t play the language- 
game of meaning and understanding unless you are also 
willing to play the language game of responsibility and we 
can’t play the language game of responsibility with LLMs 
because LLMs are responsible to no one. Teir designers 
can modify their internal states but they are not open 
to their interlocutors in the minimal sense which would 
make them accountable. As language users, participating 
in our distinctively communal form of life, we can ratio- 
nally alter how we use expressions. Tis openness to the 
linguistic direction of others is a fundamental feature of 
the linguistic division of labour, a necessary but not a suf- 
fcient condition of membership of a linguistic commu- 
nity which is not (sufciently) achieved by any existing 
language models. What is required for this is a matter of 
debate. Burge has argued that membership of a linguistic 
community essentially involves a willingness to be correc- 
ted by others. Others have argued that membership of a 
linguistic community is what matters rather than minded- 
ness. (Mallory, 2020). 
4. Conclusion 
Let’s now return to the problem that started this paper: 
Do the chatbots grounded in contemporary large language 
models count as linguistic Others? Could they become a 
part of our linguistic community? We have seen that argu- 
ments from Wittgenstein’s later philosophy can be relevant 
to both sides of this debate. On one side, he cautions us 
against reifying meanings into normatively signifcant en- 
tities that humans might grasp but which elude machines, 
at the same time, he can be seen to emphasise the impor- 
tance of actually living for engaging in meaningful beha- 
ARTIKKEL INTERVJU & FORSKNING SPALTER BREV 
FINTAN DECLAN MALLORY 
86 
viour, including meaningful linguistic behaviour. As the 
aim of this paper wasn’t to advocate for an ‘authentically 
Wittgensteinian’ position, I will avoid coming down on 
either side. Instead, I hope to have called attention to the 
importance of thinking through issues on sociality, nor- 
mativity and agency when discussing these issues.
ChatGPT
Reconsidering Language Understanding: Linguistic Agency and Social Norms
The discussion proposes three alternative approaches to understanding language and meaning, challenging traditional notions of linguistic understanding and semantic interpretation:

Linguistic Agency: Instead of focusing solely on whether machines "understand" language in a detached sense, the concept of "linguistic agency" emphasizes the ability of machines to achieve goals through language use. This approach acknowledges that language is inherently tied to practical activities and suggests that machines should be evaluated based on their capacity to use language effectively to accomplish tasks.

Social Norms and Community: Drawing on a more communitarian perspective influenced by Wittgenstein, the argument highlights the role of social norms and community practices in shaping our understanding and use of language. Language users are held accountable to these norms within their linguistic community, and without participation in this communal framework, machines lack the context and accountability necessary for meaningful linguistic interactions.

Implications for the Debate
By reframing the discussion around language understanding in terms of linguistic agency and social norms, the paper offers insights into the challenges and limitations of current language models. It suggests that meaningful language use requires more than just mapping linguistic units or predicting text; it involves embeddedness in a social context and the ability to use language purposefully to achieve goals.

Conclusion: Emphasizing Sociality, Normativity, and Agency
The conclusion refrains from taking a definitive stance on whether contemporary language models can be considered "linguistic Others" or part of our linguistic community. Instead, it underscores the importance of considering sociality, normativity, and agency in discussions about language and meaning. By highlighting these factors, the paper encourages a deeper exploration of the philosophical implications of language modeling and the challenges of integrating machines into linguistic communities.

User
A second idea might be to jettison the idea that ‘un- 
derstanding language’ can be made sense of independent 
of linguistic agency. Tis stresses the role of practical acti- 
vity within a form of life. While current discussions often 
focus on whether or not a model ‘understands language’, 
it’s often less than clear what this detached notion of un- 
derstanding or philosophical phrases like ‘grasping a sense’ 
is supposed to be. Current benchmarks attempt to break 
understanding down into manageable, evaluable chunks 
but at the cost of decontextualising the use of language 
from agency more generally. Methods of evaluation typi- 
cally involve prediction tasks, string mapping or classifca- 
tion (e.g., sentiment analysis), question answering, word- 
sense disambiguation, coreference resolution etc. (see the 
tasks listed in the SuperGLUE or BIGbench benchmarks). 
It’s questionable whether any of these tasks can be descri- 
bed as ‘using language’. Behind these testing paradigms 
stands the idea of detached comprehension, the idea that 
understanding a language is a matter of mapping units of 
language to other units of language. Few tests integrate 
language with practical activities. Perhaps a better goal 
than producing machines with ‘linguistic understanding’, 
a notion which Wittgenstein called into question, might 
be to aim for artifcial ‘linguistic agency’. A machine has 
linguistic agency when it can accomplish its ends by me- 
ans of language. Tose ends may be directly practical (‘pass 
the milk’) or they may be epistemic (‘where is the milk sto- 
red?’) but essential to them that the goal can be represen- 
ted independently of the means to achieve it linguistically. 
It may be that there can be no meaning without linguistic 
agency and no linguistic agency without other forms of 
agency (or means-end reasoning) which language models 
are not trained to manifest. 
A fnal approach is to embrace the role that commu- 
nity plays in our ascriptions of meaning. Tis would be the 
response of a more communitarian Wittgenstein (Kripke, 
1982). Te idea here is that the normativity distinctive 
of meaning is grounded in social norms of interpretation. 
Linguistic behaviour is not subject to assessments of cor- 
rectness because speakers are responsible to meanings in 
their head but because they are responsible to other mem- 
bers of their linguistic community to use words a certain 
way. It is only from the external perspective of a linguistic 
community that we can think of an individual language 
user as ‘responsible’ for their linguistic behaviour. As long 
as language models fail to be members of our linguistic 
communities, they are not bound by these norms and so 
not entitled to ascriptions of content. One might phrase 
this thought as follows: You shouldn’t play the language- 
game of meaning and understanding unless you are also 
willing to play the language game of responsibility and we 
can’t play the language game of responsibility with LLMs 
because LLMs are responsible to no one. Teir designers 
can modify their internal states but they are not open 
to their interlocutors in the minimal sense which would 
make them accountable. As language users, participating 
in our distinctively communal form of life, we can ratio- 
nally alter how we use expressions. Tis openness to the 
linguistic direction of others is a fundamental feature of 
the linguistic division of labour, a necessary but not a suf- 
fcient condition of membership of a linguistic commu- 
nity which is not (sufciently) achieved by any existing 
language models. What is required for this is a matter of 
debate. Burge has argued that membership of a linguistic 
community essentially involves a willingness to be correc- 
ted by others. Others have argued that membership of a 
linguistic community is what matters rather than minded- 
ness. (Mallory, 2020). 
4. Conclusion 
Let’s now return to the problem that started this paper: 
Do the chatbots grounded in contemporary large language 
models count as linguistic Others? Could they become a 
part of our linguistic community? We have seen that argu- 
ments from Wittgenstein’s later philosophy can be relevant 
to both sides of this debate. On one side, he cautions us 
against reifying meanings into normatively signifcant en- 
tities that humans might grasp but which elude machines, 
at the same time, he can be seen to emphasise the impor- 
tance of actually living for engaging in meaningful beha- 
ARTIKKEL INTERVJU & FORSKNING SPALTER BREV 
FINTAN DECLAN MALLORY 
86 
viour, including meaningful linguistic behaviour. As the 
aim of this paper wasn’t to advocate for an ‘authentically 
Wittgensteinian’ position, I will avoid coming down on 
either side. Instead, I hope to have called attention to the 
importance of thinking through issues on sociality, nor- 
mativity and agency when discussing these issues.
ChatGPT
This excerpt highlights two additional approaches to understanding language, challenging the conventional notion of linguistic understanding:

Linguistic Agency: This approach emphasizes practical activity within a broader form of life over detached comprehension. It argues that current evaluation methods for language models often focus on mapping linguistic units without integrating language with practical activities. Instead of aiming for linguistic understanding, which may be elusive, the focus should shift to achieving artificial linguistic agency, where machines can accomplish goals through language use, whether practical or epistemic.

Community Norms: Drawing from a communitarian perspective influenced by Wittgenstein, this approach suggests that the normativity of meaning is rooted in social norms of interpretation. Language users are responsible to their linguistic community for using words in certain ways, and the assessment of correctness arises from adherence to these norms. Language models, lacking membership in linguistic communities, cannot be held accountable to these norms and thus cannot be ascribed meaningful content.

Conclusion
The paper refrains from taking a definitive stance on whether contemporary language models can be considered linguistic Others or part of our linguistic community. Instead, it emphasizes the importance of considering sociality, normativity, and agency in discussions about language and meaning. The aim is to provoke thought on these issues rather than advocate for a specific position.

User
Α list of all of the topics we've discussed.
The previous model used in this conversation is unavailable. We've switched you to the latest default model.
ChatGPT
Certainly! Here's a list of the topics we've discussed in our conversation:

Turing Test
Wittgenstein Benchmark
Language Games
Functional Code Generation
Stability of Diffusion Models
Generative Image to Text Transformers
Machine Translation
Semantic Anti-Foundationalism
Normativity of Meaning
Understanding in Language Models
Linguistic Agency
Community Norms
Linguistic Others
Sociality
Normativity
Agency
Let me know if you need further information on any of these topics!

User
A little more explanatory
ChatGPT
Of course! Here's a brief explanation of each topic we've discussed:

Turing Test: A test proposed by Alan Turing to determine a machine's ability to exhibit intelligent behavior indistinguishable from that of a human.
Wittgenstein Benchmark: A benchmark for evaluating language models, inspired by Ludwig Wittgenstein's philosophical concepts, aiming to assess their ability to handle complex linguistic tasks.
Language Games: Concept introduced by Wittgenstein to describe how language is used in various contexts and activities, emphasizing its practical and contextual nature.
Functional Code Generation: The ability of language models to generate code that performs specific functions or tasks.
Stability of Diffusion Models: Refers to the robustness and reliability of diffusion models, a type of generative model used for image generation and manipulation.
Generative Image to Text Transformers: Models that generate textual descriptions based on input images, utilizing transformer architectures.
Machine Translation: The process of translating text from one language to another using computational algorithms, with recent advancements in neural machine translation techniques.
Semantic Anti-Foundationalism: Philosophical stance that rejects the idea of fixed, foundational meanings in language, often associated with Wittgenstein's views on language.
Normativity of Meaning: The idea that meanings in language are normatively significant, influencing how words are used and interpreted.
Understanding in Language Models: The extent to which language models comprehend and interpret language, including nuances and context.
Linguistic Agency: The ability of language models to use language to achieve specific goals or tasks effectively.
Community Norms: Social and cultural norms governing language use within a particular linguistic community.
Linguistic Others: Conceptualization of language models as entities outside traditional human linguistic communities, raising questions about their integration and role in such communities.
Sociality: The social aspect of language use, emphasizing the importance of social interactions and norms in shaping linguistic behavior.
Normativity: The adherence to norms or standards, particularly in language use, affecting how meanings are conveyed and interpreted.
Agency: The capacity of language models to act or make decisions autonomously, often in the context of linguistic tasks or interactions.
Let me know if you need more details on any of these topics!
