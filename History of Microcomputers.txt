History of Microcomputers
Open sidebar
History of Microcomputers
Model: Default (GPT-3.5)
Summarize: SAMEDICALJOURNAL27MARCHi982485 
Themlcro- 
teachingaid 
study 
orhomecomputerasa 
inpostgraduatemedical 
P.DU.P.LAGRANGE, 
Summary 
D. J.COUPER the formofa floppy (plastic) disc which is inserted into the disc 
drive before switchingonthecomputer.Themachineisthen 
ready for use according to the supplied instructions. 
Thehomecomputer'magic'portrayedbythe 
advertisingmedia,supposedtobringcomputer 
sciencetothefingertipsofevery man,womancnd 
child,is assessed by a practicalmedicallecturer. 
Reviewabledatabanksfromwhichdata can be 
retrievedalmostinstantaneously,theeliminationof 
filingcabinets andstockpilesofnotes, andthe 
efficientstorageofclinicalpatientdatatogether 
withtherelativelylowcostand easeofoperation 
makethecompu~eroneofthemostexciting 
additionstomodernteachingaids. 
S.Atr. med.J..61,485(1982). 
Whatisa home computer? 
Themodernmicrocomputeradvertised regularly in the lay press 
usually consistsofthecomputerassuch, a viewing screen,adisc 
driveortaperecorderandpreferably also a printer.Itcan doas 
muchasormorethanthe large computers prevalent about10 
years ago. Whereasthemicrocomputer isaboutthesizeofatype- 
writerwitha very similar keyboardandcosts onlyafractionofits 
biggerbrother,whetherthemodernorold version,'true' 
computers are bigandusually have tobekept in special air- 
conditioned rooms wheretheycan be operated onlybyspecially 
trained technicians. However,themicrocomputercan bekeptin 
any clean, habitableroom-office, laboratory or library.The 
fact that the microcomputer has a very limited memory necessi- 
tatestheuseofan extensiontoitsmemoryfacilities, for which 
purposeeithera tape recorderora disc drive canbeemployed. 
Touse amicrocomputerfor the purposes describedinthis article 
one needs no knowledgeofcomputerlanguagesorthe writingof 
programmes,althoughthewritingofhighlytechnical 
programmes is wellwithinthe capabilityofthe microcomputer. 
Thisisveryusefulifoneistrainedtowritecomputer 
programmes,butcreatesnoproblemasprofessionalprogramme 
writersare availableandaremorethanwilling to write 
programmestoorder. 
Witha microcomputer system one would normallybuythe 
'software'or'pack', as these finished programmes are called, in 
DepartmentofAnaesthesia,MedicalUniversityofSouthern 
Africa,Pretoria 
P.DUP. LAGRANGE,ARTS EXAMEN(NEDERLAND),M.MED.(ANAES.), 
Professor 
DepartmentofStatisticsandOperationsResearch, 
UniversityofSouthMrica,Pretoria 
D.J.COUPER,B.sc.HONS.,Leccurer 
Date received: 5 June1981. 
Reprint requestsro:Prof. P.duP.laGrange, [mernal Box 205, Medunsa, 0204 RSA. 
The microcomputer 
Buyingthemicrocomputer 
Although one need notknowmuchaboutcomputerscience to 
operate a microcomputeritisoftheutmostimportancetoselecta 
dealer knowledgeable about what he sells.Oneshould insiston 
the dealerdemonstratinghis claims for aspecific microcomputer 
andalsoonhis ability tocoachthe buyerinreproducingonthe 
machinetheresults claimed.Thiswill give thebuyeran 
opportunityto judgewhethertheprogrammeisindeed what is 
wanted.Inotherwords,expertadviceisneededbefore buying 
either amicrocomputerorits accompanying software.Aswe 
shall see later, a sophisticated subject like statisticscancause 
considerableembarrassmentifthemicrocomputerandsoftware 
are usedwithoutthe necessary insight. 
After reading this, onecouldseriouslydoubtthe rational use 
ofmicrocomputersbythe average householderandit is indeed 
surprisingthatprofessional people make so little useofthem, 
especiallyoftheirfunction as word processors. Perhapsthename 
'homecomputer'putsthemoff! 
Learningtouseahomecomputer
1 / 1
ChatGPT
ChatGPT
This article from the South African Medical Journal, published in March 1982, examines the potential of the home computer as a micro-teaching aid in postgraduate medical study. Authored by P.DU.P.LAGRANGE and D. J.COUPER, the paper emphasizes the computer's benefits, such as quick data retrieval, efficient storage of clinical patient data, and ease of operation.
The term "home computer" refers to a microcomputer setup that usually includes the computer itself, a screen, a disk drive or tape recorder, and preferably a printer. These devices are capable of performing at a level comparable to larger computers prevalent a decade before the publication. They are compact, affordable, and user-friendly, suitable for operation in any clean, habitable room like an office, lab, or library.
The article states that no extensive knowledge of computer languages or programming is needed to use a microcomputer for the purposes they describe. While the microcomputer has limited memory, additional memory facilities can be utilized via a tape recorder or disk drive.
When purchasing a microcomputer, it is crucial to choose a knowledgeable dealer who can demonstrate the capabilities of the system and provide coaching to the buyer. Even though the use of microcomputers is not widespread among average householders and professionals at the time, especially as word processors, the authors note the potential of these devices in facilitating learning and data management.
1 / 1
Oneoftheauthorsboughtawell-knownmakeof 
microcomputerwith a screen,printerandthenecessary 
software,andtook about3weekstolearn to operate the system, 
mainlyatnight.Theinitial reason forbuyingitwas towrite,edit 
andstore lecturesandtalksaswellasto storeandretrieve 
relevant data forthepreparationoftheabove.Asexperience was 
gained, itsurprisedtheauthormoreandmorethatthis system 
wasnotgenerally usedbyall teachingdepartments,whatever 
their subjects, especially asitisso simplethatany reasonably 
intelligentpersoncanlearnto useitwithin daysorweeks, 
dependingontheamountoftimespentin practice. 
Whenaneditingprogrammeisused, atrainedtypist learning 
howtooperateonealreadyhasan advantage because reasonably 
good typing is morethanhalftheartofmastering the system. 
Owing tothespecial characteristicsofthemicrocomputer 
editingsystemeven typingiseasy for abeginnerasonecan 
correct errors immediately,orat a latermoreconvenient stage, 
thecomputerautomatically respacing linesandparagraphs 
whenever anylenerisremovedorinserted, rightdowntotheend 
ofthe text. 
Costofpurchaseandinstallation 
Lest peoplegetthe ideathatthesecomputersare prohibitively 
expensive, let me hasten topointoutthat, including the necessary 
software,theauthor'ssystem cost lessthana good hi-fi setand 
weighsatmost 5 kg., including the screen,printeranddiscdrive, 
while it occupies roughly40X 50cmofdesk spacewiththe 
486SAMEDIESE TYDSKRIF27MAART1982 
highest point being35cm. The author's set conslsongof 
computer, screen (ordinary portable black and whiteTVset), 
disc driveandprintercost less than R4 000. Installation consists 
onlyofsimple electrical connection by plugs. 
Datastorageandretrievalonadiscdrive 
One item needing some explanationisthe so-called disc drive 
which canbecompared with a superfast tape recorder which, 
insteadofstoring information on a tape, stores it on a disc made 
ofmaterial similar to the tapeofan ordinary tape recorder.The 
main differenceisthat adiscismore fragileandtherefore needs a 
little more care than a normal tape.Itwill, for instance, not 
withstand the high temperaturesofa car's cubbyhole, or sand, 
fingerprintsorbending.Thesizeisabout13cm in diameter and 
it can store 140000 characters. Dependingonthe styleoftyping, 
between50and70 typed pages can be stored on one disc costing 
R7,00.Forreasons ofsafety itisadvisable to duplicate the discs, 
so that one can store 50 -70pages at a costofRI4,00. Once this 
discisin the machine,orasthey sayin programmer's jargon 'the 
DOSSis booted', which takes about a minute, one can retrieve 
any information from that disc within a matter of seconds.The 
tape recorder, which could alsobeused for this purpose,ismuch 
cheaperbutalso much slower and really unsuitable for serious 
work.Asthediscs aresosmall, they can be stored in a minute 
space.Theauthorstores hisinanenvelope glued to the inside 
hard coverofan exercise book measuring21X15X 0,5 cm, the 
book servingasindexorcatalogue for the subjects recorded on 
those particular discs. 
Once the informationisretrieved and scrutinized on the 
monitor screen, in our case a portableTVset, it can be printedif 
desired. Depending on the typeofprinterused, this takes at most 
a few minutes (the manuscriptofthis articlewasprinted in10 
minutes on the cheapest available printer).Iteliminates the need 
for stacksofnotes awaiting rewriting and retyping for editing 
purposes.Thesaving in writing and typing paper speaks for 
itself, not to mention the saving in time.
1 / 1
ChatGPT
ChatGPT
One of the authors purchased a home microcomputer system and took about three weeks to learn to operate it. The initial reason for the purchase was to write, edit, and store lectures and talks, as well as to store and retrieve data for their preparation. With increasing experience, it surprised the author that this system was not more widely used in teaching departments of various subjects, given its simplicity and usability by any reasonably intelligent person.
An editing program was used in this system, which provided an advantage for a trained typist. However, the microcomputer editing system is user-friendly even for a beginner, as one can correct errors immediately or at a later, more convenient stage. The computer automatically resizes lines and paragraphs whenever any letter is removed or inserted, right down to the end of the text.
The cost of the author's system, including the necessary software, was less than a good hi-fi set. It weighs at most 5 kg, including the screen, printer, and disk drive, and takes up roughly 40 X 50 cm of desk space. The system's components consisted of a computer, screen (ordinary portable black and white TV set), disk drive, and printer, which cost less than R4 000. Installation only required simple electrical connections.
Data is stored and retrieved using a disk drive, which is compared to a superfast tape recorder. The disk drive uses a disc made of a material similar to a tape recorder, and can store 140,000 characters, equivalent to 50-70 typed pages. It costs R7,00 per disc, and for safety reasons, it is advisable to duplicate the discs. Information from a disc can be retrieved in a matter of seconds. Despite the tape recorder being a cheaper option, it is slower and unsuitable for serious work.
Once the data is retrieved and reviewed on the monitor screen, it can be printed if desired. This process eliminates the need for stacks of notes awaiting rewriting and retyping for editing purposes, thus saving both paper and time.
1 / 1
Studentinvolvementandteachingwiththe 
microcomputer 
Thenormal practice in teaching departmentsisto stockpile 
lecture reprints for the benefitofstudents; this can also be done 
away with, as retrievalandprinting ofthe exactamountofcopies 
requiredisa simple matteroftyping a code into the computer 
which takes no more than afew minutes todeliver exactly whatis 
asked for.Thepreviously mentioned abilityofentering and 
changingthetextatany timeorplace by insertionordeletionof 
letters, words or sentences without the necessityofretyping the 
whole text, while thecomputerautomatically corrects spacing, 
linesandparagraphs, opensupyet another possibility, namely 
thatofthe teaching staff having access to written material 
preparedbystudents.Theycaneither edit the text on the screen 
orretrievethewanted manuscript, have it printed, then correct it 
andthenlet the typist delete the wrong information. Note that 
the textisnotretyped as a whole. Letters, words orsentences are 
merely inserted. Better still, mistakes can be left where they are 
and corrections inserted in brackets nextto the original text.The 
edited versionisthen stored again on the same disc area where 
the pre-edited text formerly was.Fromhere itisagain available 
for students to learn from their mistakes with no disc space 
wastedandno filing cabinet disturbedoreven used for that 
matter (one exercise book was takenoffa shelfandadisc inserted 
into a machine). 
The. obvious questionishow students get their notes onto the 
computer.Witha little effort they soon learn to type notes in, 
and could evenbuyandkeep their own discs.Theless ambitious 
ones can letthesecretary type theirs into the computer,butthis 
will naturally rob them of the opportunity of editing their work 
asthey go along. Whichever way thestudentuses the system to 
feed in information, he or she can always print from any discas 
wellasobtainingasmany copiesofa discasare required. 
Buildingupandupdatingadatabank 
Itneeds little imagination'to realize what a vastdatapool can 
bebuiltupononecornerofanordinaryofficedeskanywhere ina 
laboratory, library or office,beitthatofthe consultantor 
secretary, where it canberevised and updated continually with 
no rearrangementoffIles or books.Theresponsible person 
merely enters the text changes neededandstores the re-edited 
version onthesame disc space as before, from which itis 
immediately available for usebythe wholed 
Scanning,siftingandcommentonjournal 
articles 
Theidea becomes even more attractive in relation to journals, 
asone can keep trackofa certain subject, updating it as new 
articles appear, keeping afull recordoffacts, reference dates plus 
whatever other informationisrequired. However, this cannot 
serveasa substitute for' retrieval systems likeMEDLARS, 
which are used to scan world literature. 
Thesystemdescribedlendsitselfideallytouseby 
postgraduatemedicalstudentswhospecializeincertain 
directions. We have a limitednumberofstudents with common 
interestsandproblems, the biggestofwhichisgathering material 
from a wide varietyofjournals, too many tobescanned 
effectively by one person and often containing material which 
cannot be evaluated properlybytheinexperienced.The 
solution? Pooled data bya limited group which canbeeditedby 
the leading opinion-makers (headsofthe departments)of 
particular study-groups.Forthe consultant whose task itisto 
review this work, I can thinkofno easier wayofbeing kept 
informedonthe latest trends in a particular specialty. With the 
minimumoftime and effort, itismore than likely that many 
departments will have enough senior people willingtobe 
involved ina.'computer word-processing system' like the one 
described. 
Limitedscanninganddataretrievalfrom 
selectedjournals 
Another fascinating possibilitywithjournals would be to have 
a secretary type in summariesofarticles from the most popular 
journals read by a departmental group,undera common 
heading. 
The following question will naturallybeasked -how canone 
retrieve specific information? Thisissimply a matteroftyping a 
code on the keyboard; the computer will then searchfor all words 
orphrases linked to this code.Theinformation retrieved in this 
way can, by useofanother code, be transferredandsavedundera 
new headingonthe same disc,andcanbere-editedandprintedif 
necessaty.Theinformationsotransferredisnotcannibalized, 
butremains in the original text. 
Writingathesis 
Forpostgraduate studentswntmga thesis,theuseofa 
microcomputer word-processor will probably more than pay for 
itselfiftypist's wages, costofpaper, timeandcostofprintingare 
considered.Thepossibilityofstoring referencesandfacts to 
which thestudentcan come back constantly, with the facility to 
take often-used paragraphs or partsofthe textandinsert these 
into the main text without retypingthewhole section, shouldin 
itself be a tremendous boon.
1 / 1
ChatGPT
ChatGPT
The author discusses the potential of using microcomputers in teaching departments and student involvement. The typical practice of stockpiling lecture reprints can be replaced by the computer's ability to retrieve and print exact numbers of copies needed. Furthermore, text can be entered and altered at any time, which opens up the possibility of teaching staff accessing student-written material. Corrections can be made on the screen and the edited version stored again on the same disc area.
Students can learn to type notes into the computer, or let the secretary do it, although this option deprives them of the opportunity to edit their work as they go along. Regardless of how information is entered into the system, it can be printed from any disc and multiple copies of a disc can be produced as needed.
The author also mentions the potential of building and updating a databank. A large pool of data can be built up on one corner of an ordinary office desk. It can be continually revised and updated without the need for rearranging files or books. The edited version can be stored on the same disc space and is immediately available for use.
In relation to journal articles, the system allows for keeping track of certain subjects, updating as new articles appear, and keeping a full record of facts, reference dates, and other required information. This approach, however, does not substitute for retrieval systems like MEDLARS, used to scan world literature.
The system is particularly useful for postgraduate medical students specializing in certain directions. By pooling data from a wide variety of journals, it allows for efficient data collection and evaluation. For consultants reviewing this work, the system offers an easy way to stay informed about the latest trends in a particular specialty.
Additionally, the system could be used to have a secretary type in summaries of articles from popular journals read by a departmental group. Information retrieval is as simple as typing a code on the keyboard, and the retrieved information can be transferred, saved under a new heading on the same disc, and re-edited and printed if necessary.
Lastly, for postgraduate students writing a thesis, the use of a microcomputer word-processor can be economical when considering typist's wages, cost of paper, time, and printing costs. It also offers the possibility of storing references and facts to which the student can constantly return, and the ability to insert often-used paragraphs or parts of the text into the main text without retyping the whole section.
1 / 1
Storageofpatientdata 
The word 'computer' naturally conjures up visions ofresearch 
for which one needs clinical data.This,as weallknow only too 
well,iswhere most intended research dies a natural death, even 
that needing computersandtechnicians.Thebreakdown seems 
tobedue to an unavoidable communications gap. With a 
microcomputer the person who wants the data also operates the 
computer and seestoit that the information wantedisfed in. 
mthis field packages are available with which data canbe 
processedandretrieved at will. Oneoftheseisthe Visicalc 
System designed for accounting which enables storageofwhole' 
sheetsofinformation suchasanaesthetic charts. With this 
system one can also incorporate formulae for instantaneous 
processingofdata. Retrievalofdataissimpleandeffective with 
the normal printing facilities available.TheDataBaseisanother 
package ideally suited for use in this situation. 
Fortheprivate practitionerwho wants the microcomputernot 
only as a word-processor to keepupwith his reading, the 
Visicalc Systemcanalso be usedasa perfect book-keeping 
system.Thiscommercial useofthe microcomputer by medical 
practitioners willnotbediscussed here except to say that 
packages are available with which the private practitionercando 
anything, from mailingaccounts to storingand retrievingclinical 
data regarding patients. 
Statisticsandmicrocomputers 
Microcomputers can alleviate problems with statIstIcs,but 
owing to a worldwide shortageofprogrammers, especially those 
with a sound knowledgeofstatistics, this potentialisunlikely to 
be realized in the foreseeable future. 
Inthis field the most useful programmes are those produced 
by statistical groupsatuniversitiesandresearch establishments 
which develop setsofprogrammes (packages) on their large 
computersandthenmake these available to other groups with 
suitable computing facilities. Unfortunately the costofthese 
packages and the types of computers for which they are 
developed make them unsuitable for use on microcomputers. 
Thestatistical package available locally for microcomputersis 
not particularly usefulandisopen to abuseofstatistics, as 
untrained users are not warnedofthe assumptions thatmustbe 
made about dataandhow to check whether these assumptions 
are met before manipulating the dataifthe results are to have any 
meaning.Theprogrammes on larger computers have this 
problem to a lesser extent,asthey are usually well documented 
andare less likely to be used by amateur statisticians. 
One way to partially overcome thispmblemisto provide a 
practical courseinstatistics for medical researchers. Most 
statisticscourses concentrate on mathematical theoryand 
SAMEDICALJOURNAL27MARCH1982487 
numerical calculation.Whatisneeded isacourserunonthe lines 
ofone presentedatthe UniversityofKentucky, USA. There 
statisticsistaughtasa language.1-3Thestudentsare taught some 
terminology without being taught formulae or theory and, 
among other things, they are taught to criticize the useof 
statistics by the media.Inourcontext the statistical theory can be 
lefttothe programmerandthe microcomputer can evaluate the 
formulae,butstudents must be taught the terminology,asthey 
can converse more constructively with statisticians and can 
understand what to feed into, and what comesoutofthe 
computer. Students could also be taught to criticize the useof 
statistics in journal articles. Usersofstatistics should note, 
however, that a statisticianismore valuable (but leastoften used) 
during the planning stageofanexperimentand thatastatistician 
consultedthenmay be abletorecommend the useofparticular 
programmes so that the experiment can be carriedoutand the 
data analysed without his further assistance. 
Conclusion 
Inthe above context one can safely say that microcomputers in 
their capacityasword-processors should be a common sight in 
all teaching departments, regardlessofthe subject taught. 
The low-cost homecomputershould find a wide varietyof 
usesin postgraduate medical teaching, bothasan easily 
updateable data bank through which opinion makers can 
influence their departments effectively, even where junior staff 
cannot always be presentatall lectures and discussionsasa result 
oftheir normal hospital duties. 
Libraries are ideally suited to the housingofone or more 
microcomputersystemswheretrainedassistancecanbe 
provided. Laboratoriesanddepartmental offices should likewise 
beideal stations. 
Intensive care wards, where patients undergoing specialized 
surgery are nursed, should really be considered underequipped 
without a system like the one described. Proper note-keeping 
andclinicalresearchwillbeaidedimmenselybya 
microcomputer.Itcanbeoperated by the secretary, ward 
matronorthe doctor,andcanserveall the patients inaparticular 
intensive care unit, while costing less than anECGmonitor with 
channels for temperatureandpressure monitoring. 
The uses mentioned in the article will probably multiply a 
hundred-fold as the awarenessofits usesandapplications 
increases within the different specialties. 
REFERENCES 
1.Haack, D. G. (1977): CommunicationsinStatistics, AS, 943. 
2. Idem(1979): Teaching Statistics,1,74. 
3.Idem(1980):Ibid.,2,22.
1 / 1
ChatGPT
ChatGPT
The author further elaborates on the utility of microcomputers in healthcare, highlighting various potential applications.
Patient data storage: The use of microcomputers can address the typical challenges in clinical research, which often dies due to communication gaps and operational issues. By using a microcomputer, the person who needs the data also operates the computer, ensuring that the required information is fed in. Packages like Visicalc and DataBase enable data processing and retrieval. The Visicalc system can also be used by private practitioners for book-keeping and storing patient data.
Statistics and microcomputers: Microcomputers can alleviate problems with statistics, but due to a shortage of programmers, especially those with a sound knowledge of statistics, this potential is not likely to be realized in the near future. The author criticizes the current statistical packages available for microcomputers due to their potential misuse by untrained users. The author suggests that a practical course in statistics, focusing on understanding the language and application of statistics, rather than the mathematical theory, can help medical researchers use statistical programs more effectively.
Conclusion: The author concludes by arguing that microcomputers, in their capacity as word-processors, should be a common sight in all teaching departments, regardless of the subject taught. They can serve as an easily updateable databank and could be beneficial in libraries, laboratories, departmental offices, and especially in intensive care units where they could aid in proper note-keeping and clinical research. The author predicts that as awareness of the potential uses of microcomputers in different specialties increases, their usage will multiply exponentially.
1 / 1
This was 40 years ago.
1 / 1
ChatGPT
ChatGPT
It's fascinating to look back at how technology has progressed over the past 40 years. The concept of utilizing microcomputers in various healthcare sectors that was outlined in the original text is now essentially the reality of electronic health records (EHRs), clinical decision support systems, telemedicine, and more.
These systems enable the storage and retrieval of vast amounts of patient data, facilitate complex statistical analyses, and significantly improve communication between healthcare providers. The development of Health Information Technology (HIT) has allowed for the consolidation of patient data into digital files that can be shared across different healthcare settings, enhancing the continuity of care.
Moreover, the use of AI and machine learning in healthcare has further revolutionized the field. These technologies are now used in predictive modeling, image analysis, genomics, and personalized medicine, among other applications.
It's interesting to note how accurately the author predicted the utility of these technologies, even though the technology of their time was still relatively primitive compared to today's standards. The rapid pace of advancement suggests that the healthcare technology landscape will continue to evolve and potentially in ways we cannot yet foresee.
1 / 1
SoulhAfricanJournalofScience Vol.8? JanuarylFebruaryJ99J 
Computer programming: is it computer science? 
Judy M. Bishop 
Department of Computer Science, University of the Witwatersrand, P.O. Wits, 2050 Johannesburg, South Africa 
Programming! In the world of computers, no subject is more basic, 
none too all-pervasive in its impact (for good or ill) on the perform- 
ance of computing systems. 
Kenneth Owen, The art and science of programming, 
. IFIP TC2 Report, 1983. 
Programs-what can they do? They can: Help restore the Statue 
of Liberty, 1 manage the British Nationality Act,z make our 
dreams of robots come true/ present word processing in Arabic, 
Hebrew or Chinese,4.s recognise the structure of proteins,6 relive 
earthquakes,7 search for extraterrestrial intelligence,S represent 
and analyse the OED,9 draw amazingly beautiful pictures,1O 
enjoy music and have a sense of humour. II���12 All of these ex- 
amples are taken from the Communications oj the ACM, the 
flagship journal of computer scientists. They represent the use 
of programming in a staggering variety of fields, and the articles 
tell of the programming efforts required. But ... 
Computer programming: is it computer science? The question 
is a maddening one as a title because it can be taken many ways. 
From the computer scientist's side, the question is whether com- 
puter programming qualifies as a serious branch of computer 
science, or whether it is merely an ancillary technology, essen- 
tial, but not worthy of study in its own right. From the point 
of view of other scientists, of industry, business and the com- 
puter hobbyist, the question is whether programming is or should 
be the preserve of computer scientists, or whether it can be gain- 
fully and adequately practised independently of the members of 
this profession. 
Let us be blunt and acknowledge that the answer to the second 
view is that, of course, programming can be-and is-practised 
without a computer scientist being in the same room, or even in 
the building. Nevertheless, the question still arises because it is 
in the natural order of things that each profession carves out the 
activities that it regards as best practised by its members and, 
as time goes by, these demarcations achieve the acceptance of 
the community as well as, often, the sanction of law. Where 
should the line be drawn with computer programming? 
Consider an analogy in the field of electrical endeavour. Elec- 
trical engineers practise their profession, well guarded by the law, 
and electricians ply their trade similarly protected. Yet the man 
in the street, given a manual and some tools, can quite easily 
perform the simpler tasks done by either, if it suits him or he 
sees it as interesting. An amateur can design and build a TV set, 
a housewife can rewire a bedroom. The arm 01.' the law comes 
in to protect the jobs of professionals, and led to the caustic com- 
ment by Shaw, in 'The Doctor's Dilemma', that 'All professions 
are conspiracies against the laity.' 
But perhaps of more relevance to this discussion, the law is 
also concerned with safety. A job must be certified by a licensed 
practitioner at a certain level, so that lives are not at risk because 
of untrained personnel. In the case of electrical work, the jobs 
and levels have been established and refined over decades. 
The same tiered approach and protection of the public can be 
seen in other professions-medicine, law, accounting-but does 
not apply to the scientific disciplines-physics, botany, mathe- 
matics, say. If one views the sciences as the bases of engineer- 
ing, with science providing the theory and engineering the prac- 
tice, then having controls appliedto engineers but not to scien- 
tists is wholly appropriate. Where does this leave computer 
science? Is it a science which forms a basis for the engineering 
practice of programming, or is computer science, including com- 
puter programming, an engineering discipline in its own right, 
for which the tiered approach and the protection of the public 
apply? And if the latter, where do we draw the line between tiers 
and what sort of protection can be applied? Before we can answer 
these questions we must follow the advice of Sherlock Holmes: 
'It is a capital mistake to theorise before one has data,' and go 
back in time-not too far, I grant you-to gain an understand- 
ing of what computers, computer science and computer program- 
ming are all about. I shall then endeavour to answer the ques- 
tions: Is computer programming worthy of study within com- 
puter science? Should some of computer programming be done 
only by computer scientists? 
The Origins of computers 
The popular belief that computers were invented by the 
Americans after the Second World War is only partially 
correct. 13 -16 Certainly, it was the scientists of the 1940s who first 
constructed a practical computer, but the origins of computers 
go back more than a century earlier, to post-Regency Britain, 
when George IV was on the throne, the steam age was just get- 
ting under way, the romantic poets Byron, Shelley, Wordsworth 
and Scott held sway in the arts, and the sciences were alive with 
innovators and inventors. It was also the age of Charles Dickens 
and to him we owe the earliest literary quotation on the subject: 
Two other departments (among rubbish-tip pickers) called the 
"soft-ware" and the "hard-ware", are very important. The former 
includes all vegetable and animal matters-everything that will 
decompose. These are selected and bagged at once, and carried 
off as soon as possible to be sold as manure for ploughed land, 
wheat, barley, &C. Under this head, also, the dead cats are 
composed. Charles Dickens, Household Words, 13 July 1850 
The contribution oj Charles Babbage 
The person who has the centre stage for computer science, 
though, is Charles Babbage, born in Southwark in 1791, educated 
at Trinity College, Cambridge, a Fellow of the Royal Society at 
25 and, from 1828, Lucasian Professor of Mathematics (Fig. 1). 
Early on in his career, Babbage became interested in the history 
of mathematics and together with John Herschel was responsi- 
ble for getting Leibnitz's notation for calculus-the now familiar 
dy/dx-accepted over that of Newton's x. 
Babbage was fascinated with all things mechanical-though 
he had a distinct aversion to organ grinders-and he was also 
thoroughly disgruntled with the errors in the logarithm and 
trigonometric tables that in those days were all produced by hand. 
He consequently hit on the idea of calculating the tables by 
machine, and, using the method of differences pioneered by Sir 
Thomas Harriot, he successfully built a difference engine between 
1820 and 1822. This machine was capable of producing and print- 
ing tables of the important common functions such as logs, sines, 
cosines and nautical information to 6 to 8 figures. The difference 
engine worked well and had pride of place in the Babbage house- 
hold (Fig. 2).
1 / 1
ChatGPT
ChatGPT
This article, authored by Judy M. Bishop and published in the South African Journal of Science in 1991, poses and explores the question, "Computer programming: is it computer science?" Bishop discusses the dichotomy between computer science as a field and the practice of computer programming, questioning whether programming should be seen as a subset of computer science, or if it can be performed independently of the discipline.
Bishop begins by presenting several examples of the myriad ways programming is used across different fields, such as restoration of historic sites, legislation management, robotics, linguistics, and more. This leads to her main questions: Is programming a legitimate area of study within computer science? Should programming be performed exclusively by computer scientists?
She acknowledges that programming can be performed outside the realm of computer science, similar to how many technical tasks can be performed without the presence of a professional in that field. However, she also acknowledges the importance of professional boundaries, which are established to ensure safety, quality, and appropriate skill sets are used in specific tasks. Bishop likens this to the distinctions between electricians and electrical engineers, noting that both professions are protected by laws, but individuals can perform some tasks within these fields independently.
Continuing, Bishop questions whether computer science, including computer programming, should be regarded as an engineering discipline with different levels of expertise and protections for the public. She also suggests that computer programming could be seen as an engineering practice based on computer science.
The article further delves into the origins of computers and acknowledges Charles Babbage, born in 1791, as a central figure in the history of computer science. Babbage developed an early machine capable of producing and printing mathematical tables, which Bishop suggests was a precursor to modern computing.
Overall, this article probes deep into the relationship between computer programming and computer science, asking whether programming should be classified within the academic discipline of computer science, and who should be allowed to engage in programming. It's a valuable piece for understanding the historical context and ongoing discussions surrounding these topics.
1 / 1
Almost immediately, Babbage embarked on a new and more 
powerful engine that could handle sixth-order differences and 
numbers up to twenty places. Although of independent means, 
Babbage sought and obtained financial support from the govern- 
ment and worked for ten years on the design and implementa- 
tion of his new machine, the Analytic Engine. The engineering 
problems were immense, and when Babbage fell out with his 
master tool-builder, Joseph Clement, having already spent 
��17000, the government put a stop to the funding. This did not 
stop Babbage from continuing his research, and in 1833 he made 
his scientific breakthrough of 'the engine eating its own tail'. The 
output from the difference mechanism would be accumulated in 
a register and fed back into the engine in an appropriate way_ 
From this followed a whole host of new ideas. First there was 
a store, not a passive store, but a dynamic one in which numbers 
could be stored, then withdrawn and operated upon and then 
stored again. This led to the need for instructions, and Babbage, 
with his interest in mechanical machines, was able to draw on 
the punched cards of the weaving loom developed by Joseph- 
Marie Jacquard in the previous century. Instructions and impor- 
tant numbers could be punched on the cards and fed in over and 
over again. Thus, by 1837, Babbage's Analytic Engine had all 
the essential features of a modern-day computer consisting of 
a store, an arithmetic unit (the mill), punched card input and out- 
put and a card-controlled sequencing mechanism that provided 
both iteration and conditional branching (Fig. 3). It provided for 
multiple precision arithmetic and for overcoming the limitations 
of storage size by punching out intermediate results on cards. 
Output was on copper-plates or on pen-drawn graphs. But most 
importantly, Babbage grasped the universality of his design and 
the importance of programming when he claimed: 
It appears that the whole of the conditions which enable ajinile 
machine to make calculations of unlimiled extent are fulfilled in 
the Analytic Engine. _ .. I have converted the infinity of space, 
which was required by the conditions of the problem, into the in- 
finity of time. 
Charles Babbage, Passages from Ihe Life of a Philosopher, 1864. 
Sadly, the design of the Analytic Engine was too far ahead of 
the engineering capabilities of the time and only the mill was even- 
tually builL Babbage died in 187 I, his dreams unrealised. 
Babbage left the contents of his workshop to his youngest son, 
Major General H.P. Babbage, who with renewed enthusiasm put 
together parts of the machine and in 1874 was able to compute 
the I st to 44th multiples of 1f to 29 places (Fig. 4). The output 
of this experiment remains with us today, and is endearing in that 
it reveals the very errors that still plague us: 1f was entered incor- 
rectly in the first place, for the 16th digit should have been 9, 
not 8, and the printing mechanism made errors when printing 
81f, 91f and ll1f. 
In 1879, the government again considered the funding of a 
realisation of Babbage's ideas, but eventually decided against it, 
although they too recognised the value of the machine-though 
with typical civil service caution: 
If all sorts of heavy work, such as the calculation of Benoulli's 
numbers, could be easily and quickly, as well as certainly, done, 
by merely selecting or punching a few Jacquard cards and turn- 
ing a handle, not only much saving of labour would result, but 
much which is now out of human possibility would be brought 
within easy reach. 
If intelligently directed and saved from wasteful use, such a 
machine might mark an era in the history of computation, as 
decided as the introduction of logarithms in the seventeenth century 
did in trigonometrical and astronomical arithmetic. The old 
reproach is probably true that more work has been spent upon 
making tables than has been saved by their use. Yet, on the whole, 
there can be no reasonable doubt that the analytical engine would 
repay itself over and over again, whatever it cost, if we could be 
assured of its success. The Merrifield Report, 1878. 
The first programmer 
Whereas Babbage is renowned for his contribution to hard- 
ware design, the pioneer of software, and indeed the world's first 
programmer, was Ada Augusta, Countess of Lovelace (Fig. 5). 
She was the only (legitimate) child of Lord Byron and had an 
enlightened education, her mother being friendly with the De 
Morgans. Augustus de Morgan was a famous mathematician who 
contributed to the theory of sets and Boolean algebra. Through 
him, Lovelace met Babbage and they struck up a friendship and 
worked together for several years from 1841. Lady Lovelace 
translated an account of the Analytic Engine made by the Italian 
L.F. Menabrea at a meeting in Turin, and added a series of 
lengthy notes, including a quite sophisticated program to com- 
pute Bernoulli numbers, which had initially been drawn up by 
Babbage. In explaining the power and scope of the Analytic 
Fig. 2. Babbage's difference engine, completed in 1822. 
Reproduced 
by 
Sabinet 
Gateway 
under 
licence 
granted 
by 
the 
Publisher 
(dated 
2010). 
24 Number Variable 
card card 
1 
2 
3 
4 1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
Operation 
card Places a on column 1 of Store 
Places b on column 2 of Store 
Places c on column 3 of Store 
Places d on column 4 of Store 
Brings a from Store to Mill 
Brings b from Store to Mill 
Directs a x b = P 
Takes p to column 5 of Store 
Brings p into Mill 
Brings c into Mill 
2 Directs p + C = q 
Takes q to column 6 of Store 
Brings d into Mill 
Brings q into Mill 
3 Directsdxq=r 
Takes r to column 7 of Store Brings d into Mill 
Brings q into Mill 
3 Directsdxq=r 
Takes r to column 7 of Store 
Takes r to output 
(printer, card puncher etc.) 
Fig. 3. A program to compute (ab + c) d for Babbage's Analytic 
Engine. 
Engine, Lady Lovelace refers to the effect it will have on broaden- 
ing the horizons of science: 
There is no finite line of demarcation which limits the powers of 
the Analytic Engine. These powers are coextensive with the know- 
ledge of the laws of analysis itself ... and our actual working 
powers in this department of human study will be enabled more 
effectually than heretofore to keep pace with our theoretical 
knowledge of its principles and laws. 
Ada Augusta, Countess of Lovelace, Notes on the Analytic 
Engine, 1843. 
A quote that reveals more to us about Ada the person is one 
passed on to me by Professor Rolf Braae, a great fan of Bab- 
bage's: 'I shall be a more famous programmer than my father 
was ever a poet.' Given the decline in the importance of a classical 
education for our children, and the fact that one of the main pro- 
gramming languages of the 1980s is named Ada in Lady Love- 
lace's honour, this prophecy may still come truel
1 / 1
ChatGPT
ChatGPT
The text you've shared is an account of the historical development of computing, focused mainly on the works of Charles Babbage and Ada Lovelace.
Charles Babbage was a 19th-century mathematician and inventor who is known for conceiving the idea of programmable computers. He first designed the Difference Engine, a mechanical device that could compute mathematical tables, but he didn't stop there. Babbage soon envisioned a much more powerful machine known as the Analytic Engine, which could handle far more complex calculations and had the ability to be programmed using punched cards, a technology borrowed from the textile industry.
Unfortunately, due to financial constraints and engineering difficulties of the time, Babbage's Analytic Engine was never fully realized during his lifetime. However, Babbage's youngest son, Major General H.P. Babbage, managed to construct parts of the machine after his father's death, proving the practicality of Babbage's designs.
Ada Lovelace, a mathematician and the daughter of the famous poet Lord Byron, worked with Babbage and is often regarded as the world's first programmer. She is most known for her work on Babbage's Analytic Engine, where she developed an algorithm intended to be processed by the machine. The significance of Lovelace's contributions was her understanding that such a device could go beyond mere number crunching and could conduct any form of computation given appropriate programming and inputs, which is a fundamental principle behind all modern computers.
Babbage's Analytic Engine and Lovelace's notes on it set the stage for the development of modern computing, even though the technology of their time could not fully realize their visions. The importance of their contributions to the field of computing is widely recognized, as reflected in the naming of the Ada programming language in honor of Ada Lovelace.
1 / 1
The turn of the century 
As we have seen, the discipline of computation was already 
well-established in the nineteenth century. Following Babbage, 
there was a lull in the development of computing hardware until 
the 1880s, when Herman Hollerith, responding to the challenge 
of the US National Census, developed his famous tabulating 
machine (Figs 6 and 7). It is this machine which ever after gave 
its name to the cards used in programming (Hollerith cards) and 
to the H-format in FORTRAN (Fig. 8). Hollerith's universal 
tabulator was used in the 1890 census and involved the punching 
and tabulating of 56 million cards. At first the new system was 
strongly criticised because the American population turned out 
to be somewhat smaller than generally expectedl Although 
Hollerith's machines worked on punched cards very similar in 
concept to the cards of a Jacquard loom, there is no evidence 
to suggest that he even knew of the Italian's work. 
Somewhat later, and independently, Leonardo Torres Y 
Quevedo, following in the footsteps of Babbage, devoted his life 
to the design and reconstruction of an astonishing variety of 
calculating devices and automata. The most interesting of these 
was the first fully automatic machine for playing a chess end- 
game of king-rook vs king, constructed in 1911. Torres wrote 
widely and lectured in Spain and France on the advantages of 
Babbage's analytical engine, but it was not until the 1939-1945 
World War that the desirability of large-scale fully-automatic 
calculating machines became so clear that the necessary environ- 
ment was created for Babbage's concept to become a reality. 
Reproduced 
by 
Sabinet 
Gateway 
under 
licence 
granted 
by 
the 
Publisher 
(dated 
2010). 
Suid-Afrikaanse Tydskrif vir Welenskap Vo/.S7 ianuariei Februarie 1991 25 
Fig. 6. Herman Hollerith, inventor of the tabulating machine and 
punched card (1860-1929). 
The war years 
From the war years onwards, computing hardware developed 
from nothing to the sophisticated machines of today. It is general- 
ly accepted that the significant advances were made independently 
in three countries. In Germany in the early 1930s, Konrad Zuse 
had already mastered the basic design of a floating point binary 
computer, controlled by a program tape consisting of a sequence 
of instructions, each of which specified an operation code, two 
operand addresses and a result address, and most importantly, 
he was able to turn his design into reality. Operational in 1941, 
the Z3 is believed to be the world's first general-purpose program- 
controlled computer. Most of the machines did not survive the 
war, and it was many years before Zuse's work took its rightful 
place in the chronology of computer development. 
In the United States, it was work of Howard Aiken (Harvard 
University), Grace Hopper (US Navy) and Wallace Eckert 
(Columbia University), which, with the financial backing of IBM, 
produced the Harvard Mark I computer in 1944. A massive 
machine, fifty feet long, the Mark I was in continual use at 
Harvard until 1959. It is notable that the Americans had not taken 
serious notice of Babbage's work, since even in 1837, in his clear 
Fig. 7. The Hollerith Electric Tabulating System (built 1887). 
Fig. 8. An example of a punched card. 
description of the programming of his machine, Babbage made 
mention of the importance of conditional branching, a feature 
that was missing from the Mark I, as it was from Zuse's Z3. To 
gain an idea of the speed of these machines, Eckert reports that 
the IBM SSEC, which was very much in the tradition of the Mark 
I and completed in 1948, could perform 50 multiplications per 
second, whereas your typical1980s personal computer will happily 
churn out IO 000 (Fig. 9). 
The honours for the first large-scale electronic computer to 
become operational belong to John Mauchly of the Moore 
School, University of Pennsylvania, who with Eckert built the 
ENIAC 1945. Although ENIAC was in use through to 1953, the 
time taken to set up a problem was discouraging, and even before 
it was completed, the Moore team had embarked on EDVAC. 
On the other side of the Atlantic, work was proceeding through- 
out the war on encryption machines (known as the Secret War), 
and it was not until the war was over, that British scientists were 
able to turn their attention to computers. It is believed that 
F.C. Williams and Thomas Kilburn of Manchester University 
were responsible for the first stored program computer, which 
was a small machine built in 1948 to test the Williams-tube type 
Fig. 9. The IBM Selective Sequence Electronic Calculator, 1948. 
of electrostatic store. The first practical stored program computer, 
the EDSAC, was built by a team under Maurice Wilkes at Cam- 
bridge University, and executed its first program in May 1949_ 
This computer was a modest machine by today's standards, with 
512 words of delay-line storage and incorporating some 3000
1 / 1
ChatGPT
ChatGPT
valves, but it heralded a new era. To quote Maurice Wilkes, writing of this time in his book 'Memoirs of a Computer Pioneer':
css
Copy code
"The realisation came over me with full force that
a
good part of the remainder of my life was going
to
be spent in finding errors in my own programs."
This reflects an important shift in focus from hardware to software, a transition which remains relevant today as the complexity of software often eclipses that of the hardware it runs on. The EDSAC itself marked the beginning of the modern computing era, as it was the first computer that was practical for a wide variety of applications, not just specific mathematical or scientific problems.
The following years saw rapid advances in computer technology, with improvements in memory storage, processing speed, and programming techniques. This era laid the groundwork for the development of the modern computing industry. Many of the concepts pioneered during this time, such as the use of binary code, machine language, assembly language, and high-level programming languages, are still in use today.
As the 20th century progressed, computers became smaller, more powerful, and more affordable. This led to the proliferation of personal computers in the 1980s and 1990s, and eventually to the ubiquitous presence of computing technology in our lives today.
Herman Hollerith, Leonardo Torres Y Quevedo, Konrad Zuse, Howard Aiken, Grace Hopper, Wallace Eckert, John Mauchly, F.C. Williams, Thomas Kilburn, and Maurice Wilkes are just some of the pioneers who made significant contributions to the development of modern computing. Their work, combined with the efforts of many others, has shaped the world we live in today and will continue to influence the technology of the future.
1 / 1
valves. A noteworthy feature was the set of 'initial orders', a 
wired-in program that provided what would now be called a 
rudimentary assembler and loader. This was to be the first of 
many valuable contributions made by the Cambridge team to the 
practice of programming. 
The next forty years -1948 to 1988 
From this point on, the development of hardware did not look 
back. Encouraged by the growing electronics revolution, and 
Reproduced 
by 
Sabinet 
Gateway 
under 
licence 
granted 
by 
the 
Publisher 
(dated 
2010). 
26 
spurred on by the seemingly unreasonable demands of physicists 
and the like, the computer companies took over, and milestone 
after milestone was reached-vacuum tubes, transistors, inte- 
grated circuits, VSLI; peripheral processors, multiprocessors, 
array processors; drums, tapes, disc, cassettes, floppies, video- 
disk; punched cards, teletypewriters, VDUs, graphics terminals; 
line printers, daisy wheel, matrix and laser printers; core memory, 
electronic memory, bubble memory; 8-bit, 24-bit, l6-bit, 60-bit 
and 32-bit words; memory in lOOs of words, then kilobytes, then 
megabytes; speeds in flops, kilo flops and now megaflops and 
gigaflops; mainframes, minicomputers, microcomputers, personal 
computers, supercomputers and workstations. In my personal 
acquaintance with computers, which dates back to 1969, I have 
seen every one of these, and watched each replaced by a successor, 
in order to feed the insatiable need of the world for more and 
faster computing power. But behind every piece of hardware lies 
a world of software, and it is to this that we must now turn our 
attention. 
What is computer science? 
Origins 
Computer science as a discipline could not exist before the 
advent of computers, but it did have its roots in specific work 
done by mathematicians and others in the past three hundred 
years. What differentiates this work from mathematics is the 
desire to quantify the thought processes. Gottfried Leibnitz, the 
great mathematician-philosopher, described binary arithmetic in 
1674, and then wrestled with the concept of a logical analytical 
calculus which would enable deductions to be made from state- 
ments written in a symbolic language. Leibnitz did not succeed 
in his quest, and it was left to George Boole in 1849 to define 
'The mathematical analysis of logic', ever afterwards known as 
Boolean Algebra, although in a later paper, Boole referred to 
his work as 'The laws of thought '. This was followed in the early 
1930s by Claude E. Shannon, who realised the power of boolean 
algebra for simplifying relay and switching circuits and developed 
the idea to the stage where it could be of practical use. Thereafter, 
Warren E. McCulloch and Walter Pitts worked on a mathematical 
model of the way nerves work, which was published in 1943, and 
developed a simple, idealised model of a nerve cell or neuron and 
a logical calculus of nervous activity. Other notable contributions 
to the beginnings of the science were made by Michael Rabin and 
Dana Scott, who defined the finite state automaton and the theory 
of regular expressions, and Noam Chomsky, a linguist, whose 
concept of context-free grammars is the basis for most of the 
theory of programming language translation today. 
Of the early pioneers, two stand out, and have given their 
Fig. 10. John yon Neumann, pioneer of computer design (1903- 
1957). 
South Africanlournal of Science Vol. 87 lanuary/FebruaryJ99J 
Fig. 11. Alan Turing, pioneer of computer theory (1912-1954). 
names to models of computing whose relevance and importance 
is still being felt. The first is John von Neumann, of Princeton 
University, who formalised and described the basic design of elec- 
tronic stored program computers (or instruments, as he called 
them) in four lengthy reports in 1946 and 1947 (Fig. 10). The 
von Neumann machine became a reference point thereafter for 
the design of all computers in the next thirty years, and is still 
the basis for most sequential architectures. Incidentally, it is also 
Von Neumann who was responsible for the invention of the flow 
chart, which was an essential tool for programmers during the 
early days of assembly coding.
1 / 1
ChatGPT
ChatGPT
The second pioneer of note is Alan Turing. In 1936, prior to the development of the electronic computer, Turing described an abstract machine (later known as the Turing machine) which is still used today as a fundamental model of computation. This machine, with its tape of infinite length and a simple set of rules for reading, writing, and moving the tape, could carry out any calculation that could be described algorithmically. This concept of a universal computing machine was a critical step in the development of computer science, and Turing's work provided the foundation for theories of computability and complexity. Turing is now widely recognized as one of the fathers of computer science (Fig. 11).
One of Turing's most significant contributions was his work on the problem of decidability, or determining whether a particular problem can be solved by a computer. His proof that the halting problem (the problem of determining whether a computer program will finish running or continue to run forever) is undecidable has major implications for computer science, particularly in the areas of programming and software development.
Following Turing and von Neumann, there was an explosion of research and development in both the hardware and software aspects of computing. As hardware became more powerful and sophisticated, so did the software that ran on it. Programming languages evolved from the simple assembly languages of the early computers, to the high-level languages that we use today. These languages made it possible to write more complex and sophisticated programs, which in turn drove the development of more powerful hardware.
The advances in computer hardware and software in the 20th century have had a profound impact on nearly every aspect of our lives, from communication and entertainment, to business and scientific research. As we continue to push the boundaries of what is possible with computers, we owe a great deal to the pioneers of computer science who laid the groundwork for the technology that we use today.
1 / 1
early days of assembly coding. 
While the von Neumann design is now being challenged and 
superseded by advances in parallel architectures, the conceptually 
simpler model developed by Alan Turing, a British scientist, is 
destined to survive as probably the most important theoretical 
result in the field of computation. Turing published in 1936 his 
famous work entitled 'On computable numbers, with an applica- 
tion to Entscheidungsproblem' (halting problem), in which he 
described what came to be known as the Turing machine. This 
very simple machine operates on a tape with a read-write head, 
and Turing proved that if a table can be constructed to give the 
machine a description of how to behave at each moment, then 
the instructions given can be executed by a Turing machine. In 
one sense, Turing had proved the obvious, but his results also 
defined what was theoretically feasible, and gave support to those 
who were trying to build practical computers. Turing died tragical- 
ly at the age of 42, while still engaged on many exciting and far- 
reaching projects. His contribution to computer science is recog- 
nised by the prestigious Turing Award, made annually to an in- 
dividual computer scientist (Fig. 11). 
The emergence of computer science 
Following the war years and the advent of readily available 
computer time, more and more researchers came to regard com- 
puting as their primary profession, yet they fonned an intellec- 
Reproduced 
by 
Sabinet 
Gateway 
under 
licence 
granted 
by 
the 
Publisher 
(dated 
2010). 
Suid-AfrikaanseTydskrifvir Wetenskap Vol. 87 lanuarielFebruarie 1991 27 
tual community without a home until the mid-1960s. It was not 
until then that computer science departments started to become 
established and computer science courses taught, largely through 
the impetus provided by this small group. 
Much of the credit for the emergence of computer science as a 
discipline rests with the dedication and commitment of a relative- 
ly small number of researchers who had a vision of the potential 
of computing and the perseverance to make this vision a reality. 
John E. Hopcroft, Turing Award Lecture, 1987." 
In 1947, some of this small community banded together to form 
the Association of Computing Machinery, which has served as 
a world-wide flagship for the discipline ever-since. In 1968, the 
ACM published a model curriculum for computer science, known 
as Curriculum '68, which had a profound effect on teaching for 
the next decade. In a matter of years, computer science started 
to be offered as a major course all over the world. In 1978, a 
revised curriculum emerged, and had a similar impact. New cur- 
ricula for Computer Science I and Computer Science II came out 
in 1984, and finally, in 1989, a task force produced a far-reaching 
proposal for a new approach. 
18 
Definitions 
So what is computer science? Is it a science, an engineering 
discipline, a technology or just an inventor and purveyor of pro- 
ducts? The first stated definition was: 'Computer science is the 
study of computers and the major phenomena that surround 
them.',9 However, within the space of twenty years, the study 
of the machinery itself has become only a branch of computer 
science, and the focus has moved towards knowledge and the 
understanding of the intellectual process, in fact back to the prob- 
lems tackled by Leibnitz and Boole. Backing up a bit, we see that 
in the fifties computer science was concerned with machines, in 
the sixties it was data, in the seventies information and in the 
eighties knowledge. To quote Hopcroft again: 
The potential of computer science, if fully explored and developed, 
will take us to a higher plane of knowledge about the world. Com- 
puter science will assist us in gaining a greater understanding of 
intellectual processes, the thinking process and the reasoning pro- 
cess. Computer science will provide models and conceptual tools 
for cognitive sciences. Just as the physical sciences have dominated 
man's intellectual endeavours during this century as researchers 
explored the nature of matter and the beginning of the universe, 
today we are beginning the exploration of the intellectual universe 
of ideas. 
I think computer science will transcend computers. It will give 
us the tools to understand what language is and how language 
shapes our thoughts. Computer science will also help us to under- 
stand the nature of knowledge and how to manipulate it.17 
These thoughts echo those expressed by Edsger Dijkstra*, a 
prominent computer scientist from the Netherlands, in 1972: 
Computers are extremely flexible and powerful tools and many 
feel that their application is changing the fact of the earth ... [Butl 
their influence as tools might turn out to be but a ripple on the 
surface of the culture, whereas I expect them to have a much more 
profound influence in their capacity as intellectual challenge.'9 
Edsger W. Dijkstra, Turing Award Lecture, 1972.'0 
Peter Denning, director of NASA's Research Institute for 
Advanced Computer Science, and a past president of the ACM 
and professor at Purdue University, explains that computer 
science forms the common medium of the sciences, engineering 
and even the humanities. 
"Although we now like to credit Lady Lovelace with being the first pro- 
grammer, Edsger Dijkstra tried very hard to be the first programmer in 
the Netherlands. When he married in 1957, he put down his profession 
as 'programmer', but the marriage officer in Amsterdam told him not 
to be so ridiculous, there was no such profession, and replaced it with 
'theoretical physicist'! 
Compu ter science is not only the science and engineering of 
building and running a computer, it also informs what may be 
computed, and it promotes interactions among the different 
applications .... Like philosophy computer science is able to set 
forth methods for many other disciplines." 
Perhaps it is Donald E. Knuth who really put it plainly when he 
said that 'We computer scientists are good at computers because 
we have a way of structuring knowledge, of organising things 
in our heads.'12 
Another way of defining computer science is to list a core cur- 
riculum, as in the Denning Report of 1989Y 
algorithms and data structures 
artificial intelligence and robotics 
computer architecture 
databases and information retrieval 
human-computer interaction 
numerical and symbolic computation 
operating systems 
programming languages 
software methodology and engineering 
Notice that 'programming' or even 'problem solving' does not 
appear per se. 
Still another way is to find out what computer scientists do. 
A look at some recent advertisements can be revealing. In October 
1987, a large firm in the USA, that 'creates challenges for in- 
dividuals at the MS/PhD level in computer science', advertised 
for areas of expertise in 
software reusability 
programming environments 
services for intelligent networks 
information retrieval 
intelligent data base management 
applied expert systems 
performance engineering and 
simulation 
Science or technology? 
rapid proto typing 
enterprise analysis and business 
modelling 
logic programming 
machine learning 
operating systems 
connectionist modelling 
executable specifications 
SCIENCE: expert's skill, as opposed to strength or natural ability 
TECHNOLOGY: science of the industrial arts.
1 / 1
The previous model used in this conversation is unavailable. We've switched you to the latest default model.
ChatGPT
ChatGPT
Computer science is a discipline that encompasses the study of computers, computation, and the processes and principles that underlie them. It involves both theoretical and practical aspects, focusing on topics such as algorithms, data structures, programming languages, computer architecture, artificial intelligence, human-computer interaction, and software engineering.
While computer science has its roots in the development of computers, it has evolved beyond the study of hardware to encompass a broader understanding of information processing, problem-solving, and the intellectual processes involved in computing. Computer science seeks to advance knowledge and understanding of computation and its applications, including the manipulation of data, the modeling of complex systems, and the exploration of intellectual processes.
Computer science is considered both a science and an engineering discipline. It combines scientific inquiry and experimentation with the practical aspects of designing, building, and using computer systems and software. Computer scientists develop theories, algorithms, and models to solve problems and advance knowledge in various domains.
Computer science has become a foundational discipline that intersects with many other fields of study, including mathematics, physics, biology, economics, linguistics, and psychology. It provides tools and techniques that have practical applications in various domains, from business and industry to scientific research and societal challenges.
Ultimately, computer science is a dynamic and evolving field that continues to shape the world we live in. Its influence extends beyond computers themselves, impacting how we think, communicate, and interact with the world around us.
1 / 1
Although fully half of Denning's list of topics relates to intellec- 
tual activities as challenging as any analysis or chemistry course, 
there is still a feeling that computer science is the only branch 
of science that teaches the technology in the core and the science 
in the electives! If true, this attitude is certainly changing, and 
computer scientists want it to change. There is a feeling that any 
chemistry major student can 'pick up' computer science, but not 
vice versa. I believe that this is no longer the case: programming 
in BASIC maybe, but computer science no. As evidence of this, 
I can report on the change that has been wrought in our first 
year syllabus in Southampton, based on work at Wits in 1988. 
Although the lion's share of the lecture time was still devoted 
to programming, the emphasis in the laboratories and the assess- 
ment is shifted to cover the science of computing, and in par- 
ticular, an introduction to algorithms. The result is encouraging 
in two ways. The students are able to cope with the new material 
and the overall results are better than they had been when the 
examination consisted only of programming. 
Nevertheless, there is room for concern here. Despite a sizeable 
body of knowledge, tools and techniques, the science base of com- 
puter science is not developing as rapidly as it should and there 
is too great a temptation to focus simply on writing software. 
Hopcroft claims that the reason is that 
Computer science has grown explosively, more rapidly than any 
other discipline in history .... Other fields, such as molecular 
biology, had the advantage of emerging from broader disciplines 
that could contribute researchers of all ages, along with resources 
and structures. Computer scientists came from many backgrounds 
Reproduced 
by 
Sabinet 
Gateway 
under 
licence 
granted 
by 
the 
Publisher 
(dated 
2010). 
28 �� .. and began without a sufficient number of recognised senior 
scientists and without existing support structures to facilitate and 
channel growth." 
There is a science base to computer science, that enables us 
to regard as routine those tasks which would have been research 
twenty years ago. For example, in the sixties, a FORTRAN com- 
piler took 20 to 50 man-years of effort: today we set our students 
projects to compile languages far more sophisticated than 
FORTRAN. However, more effort and resources are still required 
to enable us to build up the science, rather than worrying about 
the technology. 
Scientist or engineer? 
SCIENTIST: one dealing with material phenomena and based mainly on 
observation, experiment and induction 
ENGINEER: one who designs and constructs public works. 
There is an old saying that any discipline worthy of being a science 
does not need 'science' in its name-take domestic science, social 
science or management science, for instance. Computer science 
therefore has to struggle against the odds, as did cookery in the 
sixteenth century: 
Cookery has become an art, a noble science: cooks are gentlemen. 
Robert Buxton (1577-1640), Democritus to the Reader 
The bedrock of science is experimentation: every biologist. 
anthropologist, chemist and physicist knows how to design the 
experiment, collect the data, analyse the results and share the 
findings. On the other hand. the central process in engineering 
is design: when designing a device, any civil, chemical, electrical 
or mechanical engineer will state requirements and specifications; 
implement the device; test the device and share the findings. The 
point is that neither experimentation nor design is the more 
fundamental-they are intricately intertwined. Scientists have to 
know how to design experimental apparatus or data collection 
procedures, and engineers have need to verify hypotheses about 
the requirements or experiment with different settings of a 
simulator. As Denning concludes:21 
Computer science sits at the crossroads between the central pro- 
cesses of science and engineering. It is a unique blend of inter- 
action between experimentation and design. The binding forces 
are common interests in: 
��� experimentation and design prooesses as information transformers 
��� computational support for the stages of those processes, and 
��� a common interest in efficiency. 
Thus computer science could comfortably live in a faculty of 
engineering, and indeed that is the case with many cOI1lPuter 
science departments in the USA and UK today. What dis- 
tinguishes computer science from the other engineering disciplines 
is the complexity that results from computer science's independ- 
ence from certain physical laws. 
Computer science is the first engineering discipline ever in which 
the complexity of the objects created is limited by the skill of the 
creator and not limited by the strength of raw materials. If steel 
beams were in finitely strong and couldn't be bent no matter wha t 
you did, then skyscrapers could be as complicated as computers. 
Brian Reid, Grace Mary Hopper Award, 1982.22
1 / 1
ChatGPT
ChatGPT
Computer science is a unique blend of science and engineering. It sits at the crossroads between the central processes of science, which involve experimentation and the collection of data, and engineering, which focuses on design and implementation. Computer science involves both experimentation and design processes as information transformers. It utilizes computational tools and techniques to support these processes and is driven by a common interest in efficiency.
While computer science shares common interests and methodologies with both science and engineering, it has certain distinguishing characteristics. One significant difference is that the complexity of the objects created in computer science is limited by the skill of the creator rather than the physical properties of raw materials. Unlike other engineering disciplines, computer science is not bound by the limitations of physical laws. This unique aspect of computer science allows for the creation of complex systems and technologies that can surpass the capabilities of traditional engineering disciplines.
Due to its interdisciplinary nature, computer science departments can be found in both science and engineering faculties. However, computer science's independence from certain physical laws and its focus on information processing make it distinct from other engineering disciplines. It requires a deep understanding of computational concepts, algorithms, and programming languages, as well as the ability to design and analyze complex systems.
Computer science continues to evolve and expand its scientific and engineering foundations. As technology advances and new challenges emerge, computer scientists strive to develop new theories, algorithms, and methodologies to address these challenges and advance our understanding of computation.
1 / 1
But Reid laments the lack of scientific training and a tendency 
to major only in computer science among undergraduates. Com- 
puter science devoid of an application area is terribly incestuous, 
he claims. 
To summarize, computer science can easily be an engineering 
discipline, but it is also closely linked to the sciences. Whereas 
the engineering aspects of design have been pushed in the past 
decade, experimentation has lagged behind, and it is high time 
we put the 'science' back into computer science. 
SoulhA/riconlournolo/Science Vol. 87 lanuarylFebruaryl991 
What is computer programming? 
So now we tum to programming. What is it? It is certainly 
not the expression of instructions to a computer in a given pro- 
gramming language. If so, everyone could program and the results 
would be nonsense. The well-established theorem 'Garbage in, 
garbage out' has a corollary: for every good set of data there 
exists a program that will tum it into garbage. Nevertheless, the 
language we choose shapes the way we think and defines our con- 
ceptual horizons. For example, if a program needs to add and 
subtract times on the 24-hour clock, we would like to be able 
to say: lecture_end_-time : = lecture_start_time + lecture_length; 
but cannot because programming languages assume that we are 
working in decimal, and we want to work in decimal, modulo 
sixty, with two 'sixtial' places. What one can do in modern 
languages is overload the plus operator by giving it a new mean- 
ing specific to a new type appropriate for times. We can then 
quite easily say the above and the language will realise that we 
are talking about times and therefore mean + times not + decimal' 
Programming languages-the learning years 
Programming languages really began in the late fifties, when 
our two senior citizens came on the scene-FORTRAN and COBOL. 
Thirty years on, FORTRAN and COBOL are still in use though they 
have undergone several facelifts since. After FORTRAN II, there 
was FORTRAN IV, FORTRAN 77 and FORTRAN 8X is on the way. 
none of them truly upwardly compatible, and most of the im- 
plementations dependent on the particular installation, despite 
the standards put out by ANSI. It is generally held among com- 
puter scientists that other scientists will write in any language pro- 
vided it is called FORTRAN, and that if PLlI, which was an IBM- 
supported effort to combine FORTRAN and COBOL, had been call- 
ed FORTRAN VI, it would have been adopted immediately by 
physicists world-wide. 
Computer scientists don't like FORTRAN. Dijkstra, who gave 
the first Turing Award lecture in 1972, put it like this: 
The sooner we can forget that FORTRAN ever existed, the better, 
for as a vehicle of thought it is no longer adequate: it wastes our 
brainpower, and is too risky and expensive to use. FORTRAN's 
tragic fate has been its wide acceptance, mentally chaining 
thousands and thousands of programmers to our past mistakes. 
I pray daily that more of my fellow-programmers may find the 
means of freeing themselves from the curse of compatibility.20 
Sixteen years on, Dijkstra's prayers seem to echo unanswered in 
the dusty decks from Los Alamos to the Humphrey Raikes 
Building! 
COBOL is also not approved of by computer scientists-it is 
static, long-winded, cumbersome and is a language for process- 
ing data, not for transforming information, and certainly not one 
that fosters new ideas. Many computer science departments are 
forced by commercial pressures to teach their students COBOL, 
but if there is any part of computer science that is technology, 
this is it. At Wits, we exposed our first years to COBOL-one 
projector slide of it! But then, Wits is fortunate in having a com- 
plementary major in business information systems taught by the 
department of accounting, where COBOL can be exercised in the 
milieu in which it is comfortable. 
Dijkstra does not mention COBOL in his lecture but does refer 
to PLlI, and dismisses it thus: 
When FORTRAN has been called an infantile disorder full PLiI 
with its growth characteristics of a dangerous tumour:could t 
out to be a fatal disease.2o 
Fortunately, the disease was fatal-to pUI-and the language 
effectively died about five years ago.
1 / 1
ChatGPT
ChatGPT
The author expresses a dissatisfaction with the state of programming languages, particularly FORTRAN and COBOL. While these languages have undergone updates and revisions over the years, they are criticized for their limitations and lack of compatibility. Computer scientists often view FORTRAN as inadequate and hindering progress, while COBOL is seen as static and cumbersome, primarily used for data processing rather than information transformation or fostering new ideas.
The sentiment among computer scientists is that FORTRAN and COBOL have been widely accepted, chaining programmers to outdated practices and impeding innovation. The author quotes Dijkstra, a prominent computer scientist, who expresses the desire to forget FORTRAN and free programmers from the curse of compatibility. However, the reality is that these languages are still in use due to various factors, including the preferences of other scientific communities and commercial pressures.
The author also mentions PL/I, a language that aimed to combine features of FORTRAN and COBOL. However, PL/I did not gain widespread adoption and is dismissed by Dijkstra as a potentially dangerous growth that fortunately faded away.
Overall, the author suggests that programming languages need improvement and calls for putting the "science" back into computer science. There is a desire to move away from outdated languages and embrace more advanced and versatile programming tools and languages that facilitate new ideas and enable efficient information transformation.
1 / 1
The Tower of Babel 
There has been over the past 
Babel of languages. back, 
a mere handful that have survived the 
puters, compilers and unreasonable users, or have influenced later 
languages in some way. These are shown in 12. 
1958 
1964 
1968 
1974 
1978 Fig. 12. Genealogy of imperative programming languages (1958- 
1978). 
Two examples will serve to highlight the difference between 
the languages of the sixties and those we are (or should 
now. In the sixties we had to SHOUT AT THE COMPUTER IN UPPER 
CASE-perhaps in the hope that it would do what we not 
what we had punched on the cards, but in the programs 
are neatly laid out and eminently readable. the follow- 
ing two textbook extracts which perform 
tures: DO 100 I = 2, 100 
ILB(l) = 0 
IRB(I) = 0 
I J = I 
2 IF (AU) .GT. A(J�� GO TO 5 
5 IF (ILBU) .EQ. 0) GO TO 4 
J = ILB(J) 
GO TO 2 
4 IRB(I) = -J 
ILBO) = 1 
GO TO 100 
5 IF (IRB(J) .LE. 0) GO TO 6 
J IRB(J) 
GO TO 2 
6 lRBU) = IRBU) 
IRB(J) = I 
100 CONTINUE A. Colin Day, Fortran Techniques, 1972. 
FUNCTION treesearch (root:tonodes; key:keys) :tonodes; 
BEGIN 
if root nil then treesearch : = nil 
else 
if key = rooCkey then treesearch : = root else 
if key < roof .key then treesearch : == treesearch (roof .left, key) 
else treesearch : == treesearch (rool' . righi, key); 
END; Itreesearchl 
D.W. Barron and J.M. Bishop, Advanced Programming, 1984. 
The second difference concerns the values of a type versus its 
representation. In FORTRAN or BASIC there is a fixed selection of 
types to choose from-integer, real, double precision, complex, 
string, say. When clearing the type of an object, one chooses from 
the list the predefined type closest to it, even though many of 
the thus supplied are redundant. For example, minutes 
have the values 0 to 59 when used on a clock. In FORTRAN one 
would declare minutes as integer, and receive over 4 million 
positive and negative values, together with access to operations 
such as multiplication and division which would not be "1J1""'",,U1<;; 
In COBOL the situation is slightly better in that one can picture 
the size of a number and declare it as two digits long, say. In 
our example, this would still give minutes the values 0 to 99, and 
all the accompanying operations. It was Wirth who decided that 
the language should allow types to be restricted to only those 
values that are genuine in the problem domain. This is n 
one of the Pascal language's greatest contributions, and has been 
extended and improved in language ever since. 
The dangers of this overrepresentation should not be under- 
estimated. The Johannesburg City Council installed a new com- 
puter system for their utility billing in 1988, and I was the reci- 
of bills for over half a million rand at a time, my balance 
reading, despite desperate corrections on their part, a 
Rl 229810.82. The cause-when entering a gas-meter 
two were interchanged, so that the difference between 
the previous and present readings became negative. But the 
COBOL program had not anticipated negative numbers and so in- 
te-nnrl"tl"ri this amount as a very large positive usage-all of 41909 
of gas. There is no way that this would have occurred 
in a Pascal or Ada program, since the type gigajoules would have 
been declared as running from 0 to some large number, and any 
attempt to have a negative value would be uum';"",:""l] 
as an error and dealt with accordingly. 
E!-Jf.neiW7;lenUlllon and maturity 
The seventies were characterized by a period of intense ex- 
pelrllflentalloll, with new being proposed at every con- 
ference. From this era, one language stands out-Pascal. Named 
after Blaise Pascal, the seventeenth-century mathematician, Pascal 
was in 1971 single-handedly by a Swiss professor, 
Niklaus Wirth, almost as a protest over the enormous, cumber- 
some, intellectually fine, languages that were being design- 
ed by committees. With its simplicity, clarity and efficiency, 
Pascal through the academic world like wild-fire and is 
still the most widely accepted language for teaching. Teaching 
the of was, of course, Wirth's primary 
and much of the criticism that was levelled against Pascal 
missed this Like an earlier teaching vehicle, BASIC, Pascal 
was soon to perform in all sorts of ill-suited cir- 
cumstances. Nevertheless, it has survived, and in its syntax and 
semantics is the foundation of all the other languages 
of the era. 
So what do we have now, in 19881 Well, there is FORTRAN and 
COBOL as always, and BASIC around in all the smaller 
computers, then there is C, a fairly 10w-levellaul:>u"l:><O 
with the system UNIX and would 
death wish from There is Wirth's successor 
to Pascal (but not such a and there is Ada. 
Ada was the result of an initiative of the US of 
Defence to rationalise their from 
over 700 down to one. In the late seventies drew up a list 
of specifications, known as and put out to tender. 
There were four serious and the winner 
was a by a French consortium headed Jean 
Ichbiah. Like Wirth, Ichbiah believed in but the sheer 
volume of the DoD meant that Ada is a 
langmlge. While holes in blew 
of the DoD and the fact that 
have never used the l<U15""'5v' on a 
PC-AT and the fully validated cost 
l is a most difficult task, as one is con- 
stantly v .. ,,, .. , ....... o 
tial from the nice-lo-have. 
Modula-2 and Oberon, he still 
and out the essen- 
Wirth has gone on to 
well of his first child,
1 / 1
ChatGPT
ChatGPT
The passage discusses the evolution of programming languages and highlights the differences between languages from the 1960s and those of the time the article was written (1988). It mentions the Tower of Babel, referring to the multitude of programming languages that have been developed over the years.
In the 1960s, programming languages such as FORTRAN and COBOL required uppercase letters, which gave the impression of shouting at the computer. However, modern languages have adopted a more readable and structured approach to programming.
One notable difference between the languages of the sixties and the later languages is the concept of type and representation. In earlier languages, programmers had to choose from a fixed selection of types, even if they were not the best fit for the problem at hand. Later languages, starting with Pascal, allowed for more precise type definitions that matched the problem domain, leading to improved accuracy and error handling.
The passage also mentions the dangers of overrepresentation in programming. An example is given where a COBOL program did not anticipate negative numbers, leading to a significant error in utility billing. Languages like Pascal and Ada, which allow for more precise type restrictions, could have prevented such errors.
The 1970s saw a period of experimentation with new languages, and Pascal emerged as a widely accepted language for teaching due to its simplicity, clarity, and efficiency. Despite criticisms and being used in unsuitable circumstances, Pascal survived and influenced the syntax and semantics of subsequent languages.
By 1988, FORTRAN, COBOL, BASIC, and C were still in use, along with Pascal's successor (likely Modula-2 or Oberon) and Ada, which was developed as a result of a US Department of Defense initiative to standardize their programming languages.
The passage concludes by mentioning that Niklaus Wirth, the creator of Pascal, went on to develop other languages and continued to make significant contributions to the field of programming.
1 / 1
Pascal, and certainly Ichbiah believes that he got it right with 
Ada: '. see Ada as a cathedral, with all the architectural lines 
interwoven in a harmonious manner. I would not do it differently 
if I had to do it again. >23 There is evidence indeed that the scien- 
tific base for programming language design is crystallizing: we 
are no longer stabbing around in the dark, but have a firm idea 
of how features interact, and what they cost. Within this paradigm 
of imperative language it is unlikely that we shall see radical 
changes in the future. 
A different drummer 
Our chart does not show a separate family of languages 
descending from LISP. LISP was developed by John McCarthy at 
the Massachusetts Institute of Technology in the early sixties and 
is radically different from the languages we have mentioned so 
far. LISP has no assignments, no ifs or loops, and is based en- 
tirely on recursive functional expressions. A typical LISP expres- 
sion to reverse a list might be: 
(LABEL REVERSE 
(LAMBDA (LIST) (COND ��EQ LIST NIL) NIL) 
(T (APPEND (REVERSE (CDR LIST�� (CONS (CAR LIST) 
NIL)))))) 
A different drummer indeed! Nevertheless, LISP has survived and 
prospered, largely through association with the artificial in- 
telligence community. Dijkstra as usual gets to the heart of the 
matter: 
LISP has jokingly been described as "the most intelligent way to 
misuse a computer". I think that description a great compliment 
because it transmits the flavor of liberation: it has assisted a number 
of our most gifted fellow humans in thinking previously impossi- 
ble thoughts.20 
Certainly, the quest for languages in which we can think led to 
the others in this family. Of those that have survived, APL, 
designed by Iverson at IBM in the sixties, is a precise tool for 
scientists, focusing on vector manipulation, and Prolog enables 
the expressing of predicates and logical combinations of them. 
If we hark back to the desires of Leibnitz and Boole for a Law 
of Thought, it is in this area that the great leaps will come. 
Real programming 
Real programming, the computer science way, involves the use, 
of a good language appropriate for the task, of modern method- 
ologies for organising one's thoughts and harnessing complexi- 
ty, and of good tools that assist in realising programs on com- 
puters. We have talked about the languages. Of the method- 
ologies, three stand out over the past thirty years: 
.. structured programming which confines the control within 
a program to the three fundamental structures of sequenc- 
ing, selection and repetition; 
.. data abstraction which encourages the definition of a data 
type together with the operations applicable to it, and enables 
their realisation to be hidden; 
(I object-oriented programming which follows on from data 
abstraction and allows classes of types to inherit properties 
from other types, and incorporates dynamic binding. 
The one that I have espoused in the past eight years is data 
abstraction, and I would like to present an example of how I have 
tried to stretch the languages we have, to achieve a higher level 
of expression, higher even than that intended by the original 
designers! 
From loops to iterators 
One of the fundamental structures in programming is the loop. 
Through it, a set of instructions can be repeated. There are two 
South Africanlournal of Science Vol. 87 lanuarylFebruaryJ99J 
kinds of loops-counting loops that repeat a fixed number of 
times, and conditional loops that repeat until a specified con- 
dition changes state. Languages have provided reasonable sup- 
port for counting loops (DOs and FORs, for instance) but only 
primitive structures for conditional loops. Consider the follow- 
ing loop: 
Start with last year's exam timetable 
REPEAT 
Request data from departments 
If no more data forthcoming, exit 
Combine data to form a new timetable 
Try the timetable out on the students 
I f there are no clashes, exit 
Resolve clashes 
UNTIL deadline reached 
Publish the new timetable 
There are two separate concerns here: the flow of the loop, and 
the computations involved. The flow of the loop can be represent- 
ed by the following template: 
Initialise 
REPEAT 
Action J 
Conditional exit 1 
Action 2 
Conditional exit 2 
Action 3 
UNTIL condition 
Follow-up action 
The computations are obviously specific to the problem domain, 
which is examination timetables. The difficulty with such loops 
is that the flow is error-prone: typically, one may forget to 
initialise, or put the exits in the wr'ong place. What I identified 
was that there were standard patterns to many conditional loops, 
and I devised a way of representing these as templates using a 
feature known in Ada as generic packages. These templates are 
called iterators and can be stored in a library and reused with other 
problem domains. The skill lies in defining the parameters of the 
i in a sufficiently general way that it is applicable across 
more than a couple of domains. The above iterator could be used, 
for instance, to handle a standard linear search on a list, where 
the conditions would be the finding of a given key, or the reaching 
of the end of a list. 
As the control flow becomes more complex, so the iterators 
start to payoff and this work is certainly in line with the widely 
held view that software must become reusable-we cannot afford 
to live with disposable code much longer. 
Literate programming 
The structured programming revolution in the 1970s con- 
tributed greatly to the improvement of programming style and 
productivity in all walks of life. Moreover, t of high- 
level languages, which weregenerally machine-independent, led 
to an increase in portable programming, i.e. programs that could 
be transferred from machine to machine, even though they were 
of different makes. Following on from this, Knuth proposed a 
methodology whereby programs could be more easily read and 
exchanged among humans. 
The past ten years have witnessed substantial improvements in 
programming methodology. This advance, carried out under the 
banner of "structured programming" has led to programs that 
are more reliable and easier to comprehend. I believe the time is 
ripe for significantly better documentation of programs, and that 
we can best achieve this by considering programs as works of 
literature. Hence my title "Literate programming". 
The practitioner of literate programming strives for a program 
that is comprehensible because its concepts have been introduced 
Reproduced 
by 
Sabinet 
Gateway 
under 
licence 
granted 
by 
the 
Publisher 
(dated 
2010). 
Suid-AfrikaanseTydskrif vir Welenskap Vo/.87 lanuarielFebruarie 1991 31 
in an order that is best for human understanding, using a mixture 
of formal and informal methods that nicely reinforce each 
other.24 
Knuth designed and implemented a system that would allow pro- 
grams to be developed in fragments, with labels to fragments that 
were yet to be written or appeared later in the document. Unfor- 
tunately, the system, called WEB and TANGLE, was a batch system 
and tied to Pascal. 
In 1987, an Honours student, Kevin Gregson, and I embark- 
ed upon a project to implement an interactive editor for literate 
programs. This has been through two iterations, and is now a 
thriving and marketable product. 2S The editor, called L1PED, 
operates on a series of views of a document. All editing is done 
in the lit.prog view, then at the touch of a function key, the pro- 
grammer can switch to the code view and see just the program 
code, but now arranged in the correct order for compilation. 
Other views provide a table of contents, a cross reference between 
fragments, and a header. The editor is language independent and 
can be linked up to any compiler. After compiling, the user is 
returned to the lit.prog view and shows where errors, if any, have 
occurred (Fig. 13). 
Such a tool has provided a valuable aid in constructing class 
notes, in writing programs for journal papers, and in develop- 
ing fairly large systems. The next step is to rewrite L1PED itself 
as a literate program, and this is under way. 
The science of programming 
A methodology that I have not yet used in anger is program 
transformation as espoused in the text by David Gries of Cornell 
University, The Science of Programming.26 Here one establishes 
predicates about the state of a program at a particular point and 
then uses transformation rules to get to the next point in a 
verifiable way. A portion of page 145 out of the section on loops 
gives the flavour of the approach. Gries' work is based on that 
of another eminent computer scientist, C.A.R. (Tony) Hoare of 
Oxford��University, whose Programming Research Group is at 
the forefront of these techniques. 
IQ) 
(inv P: the invariant) 
Ibound I: the bound function) 
(11.8) do B, -s, 
I ... 
I Bn -Sn 
od 
IR) 
When faced with a loop with form (11.8), according to theorem 
(11.6) the reader need only check the points given in (11.9) to 
understand that the loop is correct. 
(11.9) Checklist for understanding a loop: 
I. Show that P is true before execution of the loop begins. 
2. Show that IP"B,) S; iPl, for J ~i~n. That is, execution 
of each guarded command terminates with P true, so 
that P is indeed an invariant of the loop. 
3. Show that P" BB => R, i.e. upon termination the desired 
result is true. 
4. Show that P"BB => (/>0), so that I is bounded from 
below as long as the loop has not terminated. 
5. Show that IP"B,) 11:= I; S; 1/<11), for I ~i~n, so 
that each loop iteration is guaranteed to decrease the 
bound function. D 
There is obviously a question as to whether deriving programs 
this way is feasible in practice. I can only report on the answer 
given by Niklaus Wirth after he had delivered a lecture on the 
subject. Wirth said that of course he did not use program transfor- 
mation techniques to find the greatest common denominator of 
two numbers, but he certainly did use them when he had a par- 
l __ ,...--------t, 
m' -'" '-------:---..' 
Developing a 
Literate 
Program Fig. 13. The literate programming system, LIPED. 
Executable 
Lilet1lte 
Program 
Printed 
Literale 
Program 
ticularly difficult and sensitive piece of code to write_ In other 
words, the science of programming comes into play when the 
going gets tough. 
Algorithms 
While the work of Gries and Hoare has not yet filtered into 
our curriculum, there is one subdiscipline that has been waiting 
in the wings for a while ,md has now moved to centre stage. This 
is the study and analysis of algorithms. If there is one area which 
is not claimed by any other science, it is this. The term algorithm, 
as opposed to program, is given to a realisation of a solution to 
a problem that is presented in a systematic and deterministic way. 
The science base in the area of algorithms is vast, and students 
who are exposed to it at the very start of their careers can move 
on confidently into the more technological areas of operating 
systems, databases and networks. 
Perhaps algorithms have taken a while to come into their own 
because of dry, unexciting presentation in textbooks. However, 
the book by David Harel, Algorithmics-the spirit of com- 
puting,27 marks a milestone in this regard. To give an idea of 
the field, consider a transparency from the first-year course 
(Fig. 14). The emphasis is on estimating efficiency, and under- 
standing the order of an algorithm, with recursion being presented 
as the fundamental algorithmic method. In later years, one goes 
on to discover the bounds on computability, and of how to 
analyse the complexity of an algorithm. Richard Karp, in his 1985 
Weary algorithms 
The minimal spanning tree connects all nodes at 
least cost. Sometimes we just want to get from 
A to B at least cost i.e. find the minimal path. 
Suppose we have a network of cities connected 
so that 
��� there is a direction to each path 
��� there are no circular routes. 
(This is known as a directed acyclic graph.) 
The greedy solution would produce the route 
A- D- G- B at a cost of I s. But greed does 
not pay! A cleverer solution would take the 
route A- C- E- B, costing only 13. 
Fig. 14. About weary algorithms-material used in a first year 
course.
1 / 1
ChatGPT
ChatGPT
The passage discusses various aspects of programming and computer science, including the development of programming languages, methodologies, and the study of algorithms.
The author mentions the belief of Pascal and Ichbiah that they got it right with the Ada programming language. Ada was designed to be a comprehensive and well-structured language, particularly suited for complex applications and large-scale systems. The author sees Ada as a well-organized and harmonious language.
The passage also introduces LISP, a radically different programming language developed by John McCarthy in the 1960s. LISP is based on recursive functional expressions and is associated with the field of artificial intelligence. Despite its uniqueness, LISP has survived and thrived in the AI community, enabling new and innovative ways of thinking.
The author discusses the importance of good programming languages, methodologies, and tools in real programming. Structured programming, data abstraction, and object-oriented programming are highlighted as significant methodologies that improve program organization, readability, and reusability.
The concept of literate programming is introduced, which involves treating programs as works of literature. The author describes the implementation of an interactive editor called L1PED that facilitates literate programming by allowing programmers to switch between different views of the program, including a code view arranged in the correct order for compilation.
The passage also mentions program transformation, a methodology proposed by David Gries and based on the work of C.A.R. Hoare. Program transformation involves establishing predicates about the program's state and using transformation rules to progress verifiably from one state to another. Although not extensively used in practice, program transformation techniques are employed for particularly difficult and sensitive pieces of code.
Lastly, the study and analysis of algorithms are discussed as a subdiscipline of computer science. The passage emphasizes the importance of algorithms and their systematic and deterministic approach to problem-solving. Efficient algorithms are crucial for various areas of computer science, such as operating systems, databases, and networks. The book "Algorithmics - The Spirit of Computing" by David Harel is mentioned as a milestone in presenting algorithms in an engaging and accessible manner.
1 / 1
Turing Award Lecture, pieces together a conceptual jigsaw puzzle 
of the field, concluding that: 
Our tools are so powerful, the vistas so great, the range for 
applications is so enormous, that there's a great temptation to plow 
ahead. And we should plow ahead. But we also have to remember 
that we are a scientific discipline, not just a branch of high 
technology. Richard Karp, Turing Award Lecture, 1986.28 
Breaking the speed barrier-parallelism 
The analysis of algorithms can tell us how long a program will 
take to run, and for some applications in the physical world, this 
can be very long indeed. Solving systems of equations or pro- 
cessing a digital image can still take days, if not weeks on today's 
computers. Although faster and faster hardware will give us 
percentage improvements, to achieve a real breakthrough we need 
parallelism. Put simply, parallelism enables many processors to 
work together to solve a problem. Thus if a calculation takes one 
hour on a given processor, theoretically, it should take six minutes 
on ten processors. This is called linear speedup and it is certainly 
possible. So is superlinear speedup. If one regards the base as 
the best algorithm on a given sequential computer, then it may 
well be that the provision of mUltiple processors, say p, in itself 
leads to a new algorithm, which when run on the p processors 
is more than p times faster than the base. 
Parallelism takes on several forms, but three are commonly 
identified. First, there are the vector and pipeline processors, such 
as the Cray supercomputer, which has several subunits that can 
execute together when a vector operation needs to be done. Then 
there are the array processors, such as the ICL-Dap, which are 
separate processors which work in lock step, each performing 
the same instruction on one part of the data. Most of these share 
a common memory accessed through a multibus. Finally, there 
are the multiprocessors, which are truly independent chips, link- 
ed together, but each able to operate on its own. 
As an example, consider how to add 16 numbers using 16 pro- 
cessors. We put one value on each processor, then employ divide- 
and-conquer to add half to the other half repeatedly until we have 
the single answer. This takes logzn steps, or in our case, four. 
The first steps are shown in Fig. 15.30 What is interesting is that 
-~ 
@ :-~""nL.../i')-'Y', 
I ,~~�� .... 
~ 
I ~-I-+-9 I 
6 -~---14 I 
~ __ ~ 
G --. 
! 
~- I 
---, '0 
' 0=--- 
----- 
11oInI_ 
" 
~ ~-=ul.- 
~ 
I 9 -I -T or}( I 
18 '-+"- 
3- 
Secoad_ 
Fig. 15. Addition in parallel on a hypercube. 
SOulh A/ricanJournai o/Science Vol.B7 JanuarylFebruaryl991 
Fig. 16. Part of the Mandelbrot set. 
the part of the hypercube which is to be collapsed is defined by 
the processors with indices that are all the same in a particular 
bit. For example, in the first iteration, all the processors on the 
right have 4th bit = I, and their values are combined with their 
corresponding processors on the left, so S goes to 0, 10 goes to 
2, etc. This makes the expression of the algorithms for hyper- 
cubes very simple. 
The issue with multiprocessors is how to ensure that they syn- 
chronise their operations, and this is a whole new branch of com- 
puter science called concurrent programming. One of the classic 
problems is concurrency is the Dining Philosophers, in which five 
hungry monks around a table want to eat, but each needs two 
of the five forks at a time. The trick is to ensure that no-one loses 
out indefinitely. 
In the past few years there has been an upsurge of interest in 
concurrency with the development of the transputer, a powerful 
chip which has its own memory and four high-speed links, en- 
abling it to be easily connected to other transputers. The 
transputer was designed by a Bristol-based firm, (NMOS, with 
David May being a driving force. May also designed, in conjunc- 
tion with the transputer, a theoretically sound programming 
language called occam, in which one can clearly define processes 
and the interactions between them.z9 I have been using 
transputers and occam for several years now and am delighted 
with the results. It is certainly true that concurrent programs are 
far more difficult to write and debug that the ones we are used 
to, but the pay-offs are tremendous. 
One of the programs which is going the rounds at the moment 
is a simple little formula which calculates a Mandelbrot set by 
iterating a simple function on the points of the complex plane.3o 
Some of the points cycle, some diverge. Of those that cycle, we 
consider the number of iterations they take and for each group 
set a colour. The reSUlting pictures are fascinating. The beauty 
of fractals, as they are called, is that they are never-ending: any 
area can be recomputed at a deeper intensity and new and even 
repetitive patterns emerge (Fig. 16). 
To draw a full set on a little PC will take you about three hours. 
On a single transputer, which is a faster chip, the set is drawn 
in half an hour, but putting five transputers to the task we can 
get it out in 7 minutes and 23 seconds. These figures are for the 
older T414 transputers. With the new TSOOs, the times reduce 
to 2 minutes for one and a matter of seconds for five. It is the 
question of cost that is so amazing-five TSOOs on a board in 
a PC comes to about R25 000, all in with software. The next four 
T800s will cost only R8000. Thus the scientist can now look 
towards having almost supercomputer power on his desk at a price 
he can afford. A truly useful product from the computer scien- 
tists at last!
1 / 1
ChatGPT
ChatGPT
The passage discusses the concept of parallelism as a means to break the speed barrier in computing. Parallelism involves utilizing multiple processors to work together on a problem, resulting in faster processing times. The author explains that parallelism can be achieved through various forms, such as vector and pipeline processors, array processors, and multiprocessors.
The author provides an example of adding 16 numbers using 16 processors, where each processor holds one value, and a divide-and-conquer approach is employed to combine the values until a single answer is obtained. This parallel approach significantly reduces the computational time.
Concurrency and concurrent programming are also mentioned as essential aspects of parallel computing. The author introduces the concept of synchronizing operations in multiprocessors and highlights concurrent programming as a new branch of computer science. The Dining Philosophers problem is mentioned as a classic example of concurrency, illustrating the challenge of coordinating processes to avoid conflicts indefinitely.
The author discusses the emergence of the transputer, a powerful chip designed by NMOS, and its impact on concurrent programming. The transputer, along with the programming language occam, allows for clear definition and interaction between processes. The author expresses satisfaction with the use of transputers and occam, acknowledging the greater complexity of concurrent programming but emphasizing the significant benefits it brings.
Furthermore, the passage mentions the Mandelbrot set, a mathematical concept visualized through the iteration of a simple function on complex numbers. Drawing the Mandelbrot set on a PC takes several hours, but using transputers significantly reduces the computation time. The author highlights the affordability of transputers, mentioning the cost of having multiple transputers on a board in a PC, which provides almost supercomputer power at a reasonable price.
Overall, the passage emphasizes the potential of parallelism and concurrent programming to revolutionize computing by significantly enhancing processing speed and affordability.
1 / 1
The answers 
So finally we have to answer the questions: Is computer pro- 
gramming worthy of study within computer science? Should some 
of computer programming be done only by computer scientists? 
My answers, and I hope you will now agree with me, are yes and 
yes. Computer programming is one of the most challenging in- 
tellectual activities there is: it is both a constructive and creative 
art, and an exact science, overlaid with the whole design process 
of engineering. The art, the science and the engineering all can 
be studied, taught and researched. There is no shortage of material 
here, and one can only agree with Dijkstra when he said 
We shall do a much better programming job, provided that we 
approach the task with a full appreciation of its tremendous dif- 
ficulty, provided that we stick to modest and elegant program- 
ming languages, provided that we respect the intrinsic limitations 
of the human mind and approach the task as Very Humble Pro- 
grammers.20 
As to the second question, I am not proposing job reserva- 
tion, nor that computer scientists should immediately be burdened 
with all the programming jobs in the world. What I hope the 
above discourse has shown, however, is the vast contribution that 
computer scientists have made, and are still making, to the goal 
of making programs more readable, writable and reliable. There 
is a crying need for these advances to be more widely known and 
accepted, and for computer scientists to take their rightful places 
as the experts in the programming arena, to be called in, as Wirth 
says, when the going gets tough. 
For such a change to come about in our society and even in 
our universities, we need to acknowledge that computer science 
is still a fledging discipline, without seniority or a solid resource 
base. Computer scientists do not walk in the corridors of power, 
and too often their needs and the contributions they can make 
are ignored or misread. It is not enough simply to let them get 
on with the business of getting older and richer: it is going to 
be necessary to nurture them for a while, find out what makes 
them tick, what they have to offer, encourage them and respect 
them. I have no doubt that if we do this, we will find that we 
are sitting on a veritable gold mine of talent that will see the 
sciences through to the next century and beyond.
1 / 1
ChatGPT
ChatGPT
The passage concludes by answering the questions posed earlier: Is computer programming worthy of study within computer science? Should some of computer programming be done only by computer scientists?
The author firmly believes that computer programming is worthy of study within computer science. They describe it as one of the most challenging intellectual activities, combining elements of art, science, and engineering. Computer programming can be studied, taught, and researched as it encompasses various disciplines. The author agrees with Dijkstra's viewpoint that programming should be approached with an appreciation of its difficulty and with a focus on modest and elegant programming languages.
Regarding the second question, the author does not propose job reservation or exclusive programming rights for computer scientists. However, they emphasize the significant contributions computer scientists have made and continue to make in making programs more readable, writable, and reliable. The author argues that computer scientists should be recognized as experts in the programming field and called upon when complex programming tasks arise.
The author acknowledges the need for a change in society's perception and acceptance of computer science as a discipline. They highlight that computer science is still relatively young and lacks seniority and solid resources. The author calls for nurturing, understanding, and respecting computer scientists, acknowledging their talent and potential contributions to science in the present and future.
In conclusion, the author believes that by valuing and supporting computer scientists, society can tap into their immense talent and propel scientific advancements into the next century and beyond.
1 / 1
This was from 30 years ago
1 / 1
ChatGPT
ChatGPT
Apologies for the confusion. Since the passage you provided is from 30 years ago, it's important to note that the field of computer science has significantly evolved since then. While the fundamental principles and concepts remain relevant, there have been advancements in programming languages, methodologies, and technologies. It would be advisable to consider more recent sources and developments to gain a comprehensive understanding of the current state of computer science and its relationship with computer programming.
1 / 1
A list of all of the topics we have discussed
1 / 1
ChatGPT
ChatGPT
Certainly! Here is a list of the topics that have been discussed in the provided passage:
Tower of Babel and the evolution of programming languages.
Contrasting programming languages from the 1960s to the present.
The difference between type values and their representation in programming languages.
Pascal and its significance in language design and education.
The concept of literate programming and its benefits.
The science of programming and program transformation.
The analysis of algorithms and its importance in computer science.
The potential of parallelism and its various forms.
The development of concurrent programming and its challenges.
Fractals and their computational complexity.
The role of computer programming within computer science.
The need for readable, writable, and reliable programs.
The importance of nurturing and respecting computer scientists.
Please note that this list may not cover every detail mentioned in the passage, but it captures the main topics discussed.
1 / 1
First we discussed microcomputers in 1982
1 / 1
ChatGPT
ChatGPT
I apologize for the confusion. Based on the given passage, the topics discussed are as follows:
Microcomputers and their significance in 1982.
Please let me know if there are any other specific topics or details you would like me to include.
1 / 1
A summary
1 / 1
ChatGPT
ChatGPT
In 1982, the discussion revolved around microcomputers and their importance during that time. Microcomputers, also known as personal computers, were gaining significant attention and recognition. They were seen as a revolutionary technology that brought computing power and capabilities to individuals and small businesses.
The emergence of microcomputers marked a shift from large, mainframe computers to more accessible and affordable computing devices. These machines offered users the ability to perform various tasks such as word processing, data analysis, and basic programming.
During this period, microcomputers were becoming increasingly popular, with their widespread adoption in homes, offices, and educational institutions. They were seen as tools that could enhance productivity, facilitate learning, and empower individuals to engage with technology in new and exciting ways.
The discussion likely explored the impact of microcomputers on different aspects of society, including education, business, and personal use. It may have covered topics such as the evolution of microcomputer technology, the range of available software and applications, and the potential benefits and challenges associated with their use.
Overall, the focus of the discussion was on the significance of microcomputers and their role in shaping the computing landscape of the early 1980s.
1 / 1
Statistics and microcomputers: Microcomputers can alleviate problems with statistics, but due to a shortage of programmers, especially those with a sound knowledge of statistics, this potential is not likely to be realized in the near future. The author criticizes the current statistical packages available for microcomputers due to their potential misuse by untrained users. The author suggests that a practical course in statistics, focusing on understanding the language and application of statistics, rather than the mathematical theory, can help medical researchers use statistical programs more effectively.

Conclusion: The author concludes by arguing that microcomputers, in their capacity as word-processors, should be a common sight in all teaching departments, regardless of the subject taught. They can serve as an easily updateable databank and could be beneficial in libraries, laboratories, departmental offices, and especially in intensive care units where they could aid in proper note-keeping and clinical research. The author predicts that as awareness of the potential uses of microcomputers in different specialties increases, their usage will multiply exponentially.
1 / 1
ChatGPT
ChatGPT
The discussion on microcomputers and their role in statistics highlights several key points.
First, microcomputers have the potential to alleviate problems with statistics by providing accessible tools for data analysis and statistical calculations. They offer a more affordable and user-friendly alternative to traditional mainframe computers, making statistical analysis more accessible to a wider audience.
However, the shortage of programmers, particularly those with a solid understanding of statistics, poses a challenge to fully realizing the potential of microcomputers in this field. Without skilled programmers, the development of effective statistical software and the proper utilization of statistical packages may be hindered.
The author also criticizes existing statistical packages for microcomputers, expressing concerns about their potential misuse by untrained users. This highlights the importance of proper training and education in statistics to ensure the accurate and appropriate use of statistical software.
The suggestion of a practical course in statistics, focusing on understanding the language and application of statistics rather than the mathematical theory, aims to address this issue. By providing researchers with the necessary knowledge and skills to effectively utilize statistical programs, they can avoid potential errors and misinterpretations of data.
The conclusion emphasizes the broader potential of microcomputers beyond statistics. The author argues for their integration as common tools in teaching departments across various subjects. Microcomputers can serve as easily updateable databanks, aiding in note-keeping, research, and data management in different fields, including medical research and clinical settings.
The author predicts that as awareness of the potential uses of microcomputers increases, their usage will multiply exponentially across different specialties. This highlights the growing recognition of microcomputers as versatile tools with wide-ranging applications in various domains.
1 / 1
This was from 1982
1 / 1
ChatGPT
ChatGPT
Apologies for the confusion. Based on the information provided, here is a revised summary:
The discussion on microcomputers and their role in statistics, which took place in 1982, highlights their potential to address statistical challenges. Microcomputers were seen as affordable and user-friendly alternatives to mainframe computers, making statistical analysis more accessible. However, the shortage of skilled programmers, particularly those with a strong understanding of statistics, hindered the realization of their full potential.
Existing statistical packages for microcomputers were criticized for their potential misuse by untrained users. To address this, the author suggested the need for practical statistics courses that focus on understanding statistical language and application, rather than solely on mathematical theory. Such courses aimed to equip medical researchers with the necessary skills to use statistical programs effectively.
Furthermore, the author emphasized the broader potential of microcomputers beyond statistics. They advocated for the integration of microcomputers as common tools in teaching departments, regardless of the subject being taught. Microcomputers were seen as beneficial in areas such as libraries, laboratories, departmental offices, and even intensive care units, aiding in note-keeping and clinical research.
The author predicted that as awareness of the potential uses of microcomputers increased, their usage would multiply exponentially across different specialties. This highlighted the anticipation of microcomputers becoming widely adopted in various fields due to their versatility and potential benefits.
1 / 1
A summary of our whole conversation
1 / 1
ChatGPT
ChatGPT
During our conversation, we covered various topics including microcomputers, programming languages, the evolution of computer science, and the role of computer scientists in programming. We discussed the potential of microcomputers in statistics and the need for skilled programmers with a solid understanding of statistics to fully utilize their capabilities. We also examined the challenges posed by existing statistical packages and the importance of practical statistics courses to enhance users' proficiency.
Additionally, we explored the history and development of programming languages, from Fortran and COBOL to Pascal, Ada, and LISP. We highlighted the significance of structured programming, data abstraction, and literate programming as methodologies that improve program readability, reliability, and comprehension. Parallelism and concurrency were introduced as important concepts in programming, with a focus on their potential to enhance computational speed and efficiency.
Throughout our conversation, we emphasized the interdisciplinary nature of computer science, combining elements of art, science, and engineering. We recognized the need for computer scientists to be involved in programming tasks, considering their expertise in designing languages, improving program quality, and advancing the field. The importance of nurturing the discipline of computer science and acknowledging its contributions was underscored, as well as the potential for microcomputers to be widely utilized in various fields beyond statistics.
Overall, our conversation provided insights into the historical context, challenges, and opportunities in computer programming and the role of microcomputers in advancing various disciplines.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT May 24 Version
ChatGPT



