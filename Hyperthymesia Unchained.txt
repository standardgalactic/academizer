Hyperthymesia Unchained
Open sidebar
ChatGPT
3.5
You
Today's links

Your computer is tormented by a wicked god: Bootkits are why we can't have nice things.

Peter Thiel's evil, but he's not an "evil genius": How to criticize self-mythologizing villains.

Hey look at this: Delights to delectate.

This day in history: 2007, 2012, 2017, 2021

Colophon: Recent publications, upcoming/recent appearances, current writing projects, current reading


���

Your computer is tormented by a wicked god (permalink)

Computer security is really, really important. It was important decades ago, when computers were merely how we ran our financial system, aviation, and the power grid. Today, as more and more of us have our bodies inside of computers (cars, houses, etc) and computers in our body (implants), computer security is urgent.

Decades ago, security practitioners began a long argument about how best to address that looming urgency. The most vexing aspect of this argument was a modern, cybernetic variant on a debate that was as old as the ancient philosophers ��� a debate that Rene Descartes immortalized in the 17th Century.

You've doubtless heard the phrase, "I think therefore I am" (Cogito, ergo sum). It comes from Descartes' 1637 Discourse on Method, which asks the question, "How can we know things?" Or, more expansively, "Given that all my reasoning begins with things I encounter through my senses, and given that my senses are sometimes wrong, how can I know anything?"

Descartes' answer: "I know God is benevolent, because when I conceive of God, I conceive of benevolence, and God gave me my conceptions. A benevolent God wouldn't lead me astray. Thus, the things I learn through my senses and understand through my reason are right, because a benevolent God wouldn't have it any other way."

I've hated this answer since my freshman philosophy class, and even though the TA rejected my paper explaining why it was bullshit, I still think it's bullshit. I mean, I'm a science fiction writer, so I can handily conceive of a wicked God whose evil plan starts with making you think He is benevolent and then systematically misleading you in your senses and reasoning, tormenting you for His own sadistic pleasure.

The debate about trust and certainty has been at the center of computer security since its inception. When Ken "Unix" Thompson accepted the 1984 Turing Prize he gave an acceptance speech called "Reflections on Trusting Trust":

https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf

It's a bombshell. In it, Thompson proposes an evil compiler, one that inserted a back-door into any operating system it compiled, and that inserted a back-door-generator into any compiler it was asked to compile. Since Thompson had created the original Unix compiler ��� which was used to compile every other compiler and thus every other flavor of Unix ��� this was a pretty wild thought experiment, especially since he didn't outright deny having done it.

Trusting trust is still the most important issue in information security. Sure, you can run a virus-checker, but that virus checker has to ask your operating system to tell it about what files are on the drive, what data is in memory, and what processes are being executed. What if the OS is compromised?

Okay, so maybe you are sure the OS isn't compromised, but how does the OS know if it's even running on the "bare metal" of your computer. Maybe it is running inside a virtual machine, and the actual OS on the computer is a malicious program that sits between your OS and the chips and circuits, distorting the data it sends and receives. This is called a "rootkit," and it's a deadass nightmare that actually exists in the actual world.

A computer with a rootkit is a brain in a jar, a human battery in the Matrix. You, the computer user, can ask the operating system questions about its operating environment that it will answer faithfully and truthfully, and those answers will all be wrong, because the actual computer is being controlled by the rootkit and it only tells your operating system what it wants it to know.

20 years ago, some clever Microsoft engineers proposed a solution to this conundrum: "Trusted Computing." They proposed adding a second computer to your system, a sealed, secure chip with very little microcode, so little that it could all be audited in detail and purged of bugs. The chip itself would be securely affixed to your motherboard, such that any attempt to remove it and replace it with a compromised chip would be immediately obvious to you (for example, it might encapsulate some acid in a layer of epoxy that would rupture if you tried to remove the chip).

They called this "Next Generation Secure Computing Base," or "Palladium" for short. They came to the Electronic Frontier Foundation offices to present it. It was a memorable day:

https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil

My then-colleague Seth Schoen ��� EFF's staff technologist, the most technically sophisticated person to have been briefed on the technology without signing an NDA ��� made several pointed critiques of Palladium:

https://web.archive.org/web/20020802145913/http://vitanuova.loyalty.org/2002-07-05.html

And suggested a hypothetical way to make sure it only served computer users, and not corporations or governments who wanted to control them:

https://www.linuxjournal.com/article/7055

But his most salient concern was this: "what if malware gets into the trusted computing chip?"

The point of trusted computing was to create a nub of certainty, a benevolent God whose answers to your questions could always be trusted. The output from a trusted computing element would be ground truth, axiomatic, trusted without question. By having a reliable external observer of your computer and its processes, you could always tell whether you were in the Matrix or in the world. It was a red pill for your computer.

What if it was turned? What if some villain convinced it to switch sides, by subverting its code, or by subtly altering it at the manufacturer?

That is, what if Descartes' God was a sadist who wanted to torment him?

This was a nightmare scenario in 2002, one that the trusted computing advocates never adequately grappled with. In the years since, it's only grown more salient, as trusted computing variations have spread to many kinds of computer.

The most common version is the UEFI ��� ("Unified Extensible Firmware Interface") ��� a separate operating system, often running on its own chip (though sometimes running in a notionally "secure" region of your computer's main processors) that is charged with observing and securing your computer's boot process.

UEFI poses lots of dangers to users; it can (and is) used by manufacturers to block third-party operating systems, which allows them to lock you into using their own products, including their app stores, letting them restrict your choices and pick your pocket.

But in exchange, UEFI is said to deliver a far more important benefit: a provably benevolent God, one who will never lie to your operating system about whether it is in the Matrix or in the real world, providing the foundational ground truth needed to find and block malicious software.

So it's a big deal that Kaspersky has detected a UEFI-infecting rootkit (which they've dubbed a "bootkit"), which they call Cosmicstrand, which can reinstall itself after your reformat your drive and reinstall your OS:

https://securelist.com/cosmicstrand-uefi-firmware-rootkit/106973/

Cosmicstrand does some really clever, technical things to compromise your UEFI, which then allows it to act with near-total impunity and undetectability. Indeed, Kaspersky warns that there are probably lots of these bootkits floating around.

If you want a good lay-oriented breakdown of how Cosmicstrand installs a wicked God in your computer, check out Dan Goodin's excellent Ars Technica writeup:

https://arstechnica.com/information-technology/2022/07/researchers-unpack-unkillable-uefi-rootkit-that-survives-os-reinstalls/

Cosmicstrand dates back at least to 2016, a year after we learned about the NSA's BIOS attacks, thanks to the Snowden docs:

https://www.wired.com/2015/03/researchers-uncover-way-hack-bios-undermine-secure-operating-systems/

But despite its long tenure, Cosmicstrand was only just discovered. That's because of the fundamental flaw inherent in designing a computer that its owners can't fully inspect or alter: if you design a component that is supposed to be immune from owner override, then anyone who compromises that component can't be detected or countered by the computer's owner.

This is the core of a two-decade-old debate among security people, and it's one that the "benevolent God" faction has consistently had the upper hand in. They're the "curated computing" advocates who insist that preventing you from choosing an alternative app store or side-loading a program is for your own good ��� because if it's possible for you to override the manufacturer's wishes, then malicious software may impersonate you to do so, or you might be tricked into doing so.

This benevolent dictatorship model only works so long as the dictator is both perfectly benevolent and perfectly competent. We know the dictators aren't always benevolent. Apple won't invade your privacy to sell you things, but they'll take away every Chinese user's privacy to retain their ability to manufacture devices in China:

https://www.nytimes.com/2021/05/17/technology/apple-china-censorship-data.html

But even if you trust a dictator's benevolence, you can't trust in their perfection. Everyone makes mistakes. Benevolent dictator computing works well, but fails badly. Designing a computer that intentionally can't be fully controlled by its owner is a nightmare, because that is a computer that, once compromised, can attack its owner with impunity.

(Image: Cryteria, CC BY 3.0, modified)


���

Peter Thiel's evil, but he's not an "evil genius" (permalink)

Peter Thiel: "I���d rather be seen as evil than incompetent." It's the far-right billionaire's most telling phrase. Thiel wants us to think he's an evil genius, because he wants us to think he's a genius. So much of Thiel's activity is devoted to self-mythologizing, like when he made us all think he was infusing the blood of teenagers in a bid to become immortal:

https://www.vanityfair.com/news/2016/08/peter-thiel-wants-to-inject-himself-with-young-peoples-blood

But as Ben Burgis writes for Jacobin, Thiel isn't an evil genius, "he's just a rich guy":

https://jacobin.com/2022/07/peter-thiel-superrich-wealth-inequality-political-influence/

Burgis cites Max Chafkin's 2021 Thiel biography, The Contrarian, which shines a glaring light on the distance between Thiel's stated commitment to high-minded ideals of "liberty" and his self-serving defense of mass surveillance and human rights abuses:

https://bookshop.org/books/the-contrarian-peter-thiel-and-silicon-valley-s-pursuit-of-power/9781984878533

If you think Thiel is an evil genius, then maybe these contradictions are the result of your puny brain lacking the subtlety to understand how, on a higher plane of reasoning, they can be resolved. If you understand that Thiel is an ordinary mediocrity, no better than you or me, sickened by pathological greed, then there's a much simpler explanation: it's all bullshit, and the only thing Thiel really cares about is becoming richer and more powerful.

That explanation goes a long way to explain why a "libertarian" would defend Apartheid, express regret that women are allowed to vote, state that "freedom and democracy" are incompatible, and secretly fund a lawsuit to destroy a media organization that embarrassed him:

https://www.forbes.com/sites/mattdrange/2019/12/23/best-stories-of-the-decade-behind-peter-thiels-plan-to-destroy-gawker/

Thiel's self-mythologizing provides a cover for all of this, while making him far richer: for example, his campaign to make us think that Palantir played a role in killing Osama bin Laden was an obvious gambit to increase the share-price of Palantir.

Burgis cites Nathan Robinson's Current Affairs article, "Two Ways Of Responding To Conservatives," which used the example of Jordan Peterson as a template for critiquing self-mythologizing far-right figures without helping them by calling them evil geniuses:

https://www.currentaffairs.org/2018/05/two-ways-of-responding-to-conservatives

Robinson proposes a test: "Does it reinforce the person���s self-conception or undermine it?" Burgis applies this test to Thiel, urging us not to dwell on the drinking blood, taking votes away from women, or funding "neoreactionaries" like Curtis Yarvin.

Rather, Burgis says, we should focus on how Thiel spends his political money, backing "populists" like JD Vance, who say they're fighting for working people, but who oppose universal healthcare, universal childcare, and against raising the minimum wage.

Burgis: "Thiel is dangerous ��� not because he���s an evil mastermind, but because he���s a billionaire who enjoys playing with our politics and he couldn���t care less about the people who get hurt in the process."

Burgis's critique ties nicely into Lee Vinsel's idea of "criti-hype" ��� criticism that starts by accepting it's subject's own self-mythologizing, then damns them for it. Think of critics who accept Google's claims that its "AI"-driven ads can sell anything to anyone, then criticize it for having built a mind-control ray:

https://pluralistic.net/2021/02/02/euthanize-rentiers/#dont-believe-the-hype

Like Thiel, Google would rather be seen as evil than as incompetent. When Google's critics run around accusing the company of having perfected machine learning mind-control, they help Google sell ads, because the advertisers Google is pitching aren't upset that Google has a mind-control ray, provided Google will rent it out to them.

A smart synthesis of criti-hype comes from Maria Farrell, whose "Prodigal Techbro" is a great way to understand the problems with allowing ourselves to be lured into "evil genius" talk:

https://conversationalist.org/2020/03/05/the-prodigal-techbro/

Farrell's prodigal techbro is an ex-Big-Tech geek turned anti-Big-Tech crusader, whose anti-Big-Tech position starts with the proposition that they and their former colleagues were all evil geniuses who hijacked our brains' reward-centers with junk-science psych ideas like "Big Five Personality Types" and "Sentiment Analysis" (conveniently omitting the fact that these have been seriously undermined by the replication crisis):

https://replicationindex.com/category/big-five/

Focusing on what Big Tech says it does isn't just a problem because it perpetuates the companies' self-mythologizing, but also because it distracts from what we know Big Tech actually does. If we repeat the lie that Big Tech's ad billions are the result of its mind-control ray, then we omit the fact that Facebook and Google entered into an illegal conspiracy to rig the ad market:

https://techcrunch.com/2022/03/11/google-meta-jedi-blue-eu-uk-antitrust-probes/

"Just a rich guy" is the perfect epithet for Thiel, who, after all, is not an ideologue or an 11-dimensional chess master. He's just another thin-skinned, greedy bastard who uses his money and power to accumulate more money and power. The rest is just window-dressing.

(Image: Dan Taylor for https://www.heisenbergmedia.com, CC BY 2.0; Austin Powers, New Line Cinema, fair use, modified)

Hey look at this (permalink)

���

Sarah Jickling and her Good Bad Luck (brilliant music about mental health!) https://www.youtube.com/c/SarahJicklingandherGoodBadLuck (h/t Oh No Ross and Carrie)

Business cards with embedded abortion pills https://www.vice.com/en/article/bvmn35/diy-collective-embeds-abortion-pill-onto-business-cards-distributes-them-at-hacker-conference

Disability at Home (galley of hacks and adaptations) https://www.disabilityathome.org/ (h/t Fipi Lele)


���

This day in history (permalink)

#15yrsago Web contracts can���t be changed without notice https://web.archive.org/web/20070918070615/http://www.computerworld.com/action/article.do?command=viewArticleBasic&articleId=9028240&source=rss_news10

#10yrsago Record labels won���t share Pirate Bay winnings with artists; they���re keeping it for record companies https://torrentfreak.com/pirate-bay-loot-with-artists-120728/

#5yrsago Foxconn���s corporate welfare deal will cost Wisconsin taxpayers more than 3 billion dollars https://www.jsonline.com/story/news/politics/2017/07/28/foxconn-could-get-up-200-million-cash-year-state-residents-up-15-years/519687001/

#1yrago Bankruptcy and elite impunity: The Sacklers offer billions of reasons to overthrow the system https://pluralistic.net/2021/07/29/impunity-corrodes/#morally-bankrupt
ChatGPT
ChatGPT
It seems you've shared today's links from Cory Doctorow's Pluralistic blog, covering various topics:
Your Computer is Tormented by a Wicked God
: This discusses the importance of computer security in our increasingly digitized world. The article delves into historical and philosophical aspects of trust and certainty in computer security, highlighting Ken Thompson's concept of a "trusting trust" issue. It also examines the dangers of UEFI and bootkits like Cosmicstrand, which can deeply compromise a system's security.
Peter Thiel's Evil, But He's Not an "Evil Genius"
: This piece critiques Peter Thiel's self-mythologizing and the public perception of him as an 'evil genius.' It argues that Thiel, despite his immense wealth and influence, is more of an ordinary person consumed by greed rather than a mastermind. The article calls for a focus on Thiel's political and business actions rather than his persona.
Hey Look at This
: This section shares interesting links, such as music about mental health by Sarah Jickling, business cards embedded with abortion pills, and a gallery of disability hacks and adaptations.
This Day in History
: Reflects on historical events and how they were reported or discussed years ago, such as web contracts, record labels' dealings with Pirate Bay winnings, the cost of Foxconn's deal to Wisconsin taxpayers, and the Sacklers' bankruptcy case.
Colophon
: This seems to be a section about Cory Doctorow's recent publications, appearances, current writing projects, and reading activities.
These topics cover a wide range of interests, from computer security and political critique to historical reflection and creative projects.
You
I wanted to know more about his arguments that Thiel is not a supergenius, but evil because of greed
ChatGPT
ChatGPT
I did a
quick search
for more information and here's what I discovered.
Cory Doctorow's article on Peter Thiel argues that Thiel is not so much an "evil genius" as he is simply a rich individual whose actions are driven by greed and self-interest, rather than any deeply-held ideological beliefs. Doctorow critiques Thiel's self-mythologizing behavior, noting that it often serves to further his own wealth and power. For example, Thiel's promotion of his company Palantir as playing a crucial role in the operation to kill Osama bin Laden seems more like a strategy to boost the company's share price rather than a statement of fact.
Doctorow points out the contradictions in Thiel's behavior and statements, which often undermine the image of a consistent, ideologically driven individual. Thiel claims to be a libertarian, yet he has defended mass surveillance and human rights abuses, and he has financially supported political figures whose actions and policies are at odds with libertarian principles. This inconsistency suggests that Thiel's actions are more about personal gain than any commitment to a specific political ideology.
Moreover, Doctorow emphasizes that Thiel's dangerous influence comes not from being a mastermind but from his status as a billionaire who can manipulate politics to suit his interests, without concern for the people affected by these actions. Thiel's funding of politicians labeled as "populists" who oppose measures like universal healthcare and childcare further demonstrates his focus on personal gain over public good. Doctorow suggests that the real issue with Thiel is not his alleged genius or evilness, but the societal structures that allow individuals like him to amass such power and influence���
������
���.
You
I saw Doctorow complaining about how science fiction movie authors get paid way more then him for less work. However from my perspective Doctorow seems incredibly rich and maybe seems greedy, since he thinks he can make a living off writing books, audiobooks, and speaking arrangements, but this does not seem like a solution that would work for everyone.
ChatGPT
ChatGPT
Cory Doctorow's perspective on compensation in the creative industry, particularly in comparison to science fiction movie authors, reflects a broader discussion about the economics of creative work, intellectual property, and the distribution of wealth within the industry. It's important to consider a few key points in this context:
Income Disparity in Creative Industries
: The entertainment and publishing industries often exhibit significant income disparities. A small percentage of creators (like successful movie writers) can command very high fees, while the majority may struggle financially. This can be true even for well-known authors.
Perceived Wealth vs. Reality
: Public perception of an individual's wealth can be misleading. While Doctorow is a successful author with multiple revenue streams (books, audiobooks, speaking engagements), this doesn't necessarily equate to the level of wealth achieved by top earners in other entertainment sectors, like film or television.
Sustainable Living from Creative Work
: Doctorow's comments might reflect a broader concern about whether it's feasible for most authors and creators to make a living solely from their creative work. The economic model of creative industries doesn't always favor the creators, and this can be a point of contention and discussion among them.
Doctorow's Advocacy
: Doctorow is known for his advocacy for digital rights, open access, and fair compensation for creators. His comments might be rooted in these principles, rather than a personal grievance about his income.
The Challenge of Equitable Solutions
: Suggesting that all authors could or should make a living from books, audiobooks, and speaking engagements might be unrealistic given the current structure of the publishing industry and the sheer number of aspiring and existing authors. The issue of how creators are compensated in the digital age is complex and multifaceted.
In summary, Doctorow's comments likely reflect broader concerns about the sustainability and fairness of economic models in creative industries, rather than a simple comparison of personal incomes or an expression of personal greed.
You
I just mean he can criticize the system for a living since he has a source of income, I am looking for ways to fix the system that follow the categorical imperative, that is, that don't require extraordinary effort on the part of any particular individual. Although this seems paradoxical, since if I were successful, it will have been through individual effort
ChatGPT
ChatGPT
Your reflection on the challenge of enacting systemic change while adhering to the categorical imperative���a concept from Immanuel Kant's philosophy that suggests we should only act according to maxims that could be universally applied���is indeed thought-provoking. It highlights a common tension in efforts to reform systems, especially in areas like the creative industries.
Here are some ideas for systemic changes that align with the categorical imperative and don't necessarily rely on extraordinary individual efforts:
Promote Fair and Transparent Compensation Models
: Encourage practices where creators receive fair compensation for their work. This could involve supporting legislation that protects the rights of creators, advocating for transparent and equitable royalty structures, or backing business models that fairly distribute profits among all contributors.
Support Open Access and Digital Rights
: Advocate for open access to information and creative works, which can democratize access to knowledge and culture. This involves supporting policies that balance copyright with the public's right to access information.
Educate and Advocate
: Raise awareness about the challenges faced by creators. Education can empower individuals to make informed decisions about supporting creators, such as choosing to buy directly from authors or using platforms that offer better terms.
Collective Action and Unionization
: Encourage creators to unite in collectives or unions to negotiate better terms and protect their interests. Collective bargaining can be more effective than individual efforts in achieving systemic change.
Support Diverse Revenue Streams
: Encourage creators to diversify their income sources, such as through workshops, Patreon, crowdfunding, or merchandise. This approach can reduce reliance on any single revenue stream and provide more stability.
Consumer Responsibility
: Promote responsible consumption where consumers support ethical platforms and creators directly, rather than pirating or using platforms that exploit creators.
Innovative Distribution Models
: Encourage and support new models of content distribution that are fairer to creators. This could involve technology solutions that track and compensate creators more accurately for their work.
Legislative Reform
: Advocate for laws and regulations that protect the rights of creators, ensure fair compensation, and prevent monopolistic practices in the industry.
Each of these approaches aligns with the idea of making changes that could, theoretically, be universally applied, and they rely more on collective action and systemic reform than on extraordinary individual effort. However, it's important to recognize that achieving systemic change often requires a combination of individual and collective actions, along with shifts in both public perception and policy.
You
Pluralistic: Demon-haunted computers are back, baby (17 Jan 2024)

As a science fiction writer, I am professionally irritated by a lot of sf movies. Not only do those writers get paid a lot more than I do, they insist on including things like "self-destruct" buttons on the bridges of their starships.

Look, I get it. When the evil empire is closing in on your flagship with its secret transdimensional technology, it's important that you keep those secrets out of the emperor's hand. An irrevocable self-destruct switch there on the bridge gets the job done! (It has to be irrevocable, otherwise the baddies'll just swarm the bridge and toggle it off).

But c'mon. If there's a facility built into your spaceship that causes it to explode no matter what the people on the bridge do, that is also a pretty big security risk! What if the bad guy figures out how to hijack the measure that ��� by design ��� the people who depend on the spaceship as a matter of life and death can't detect or override?

I mean, sure, you can try to simplify that self-destruct system to make it easier to audit and assure yourself that it doesn't have any bugs in it, but remember Schneier's Law: anyone can design a security system that works so well that they themselves can't think of a flaw in it. That doesn't mean you've made a security system that works ��� only that you've made a security system that works on people stupider than you.

I know it's weird to be worried about realism in movies that pretend we will ever find a practical means to visit other star systems and shuttle back and forth between them (which we are very, very unlikely to do):

https://pluralistic.net/2024/01/09/astrobezzle/#send-robots-instead

But this kind of foolishness galls me. It galls me even more when it happens in the real world of technology design, which is why I've spent the past quarter-century being very cross about Digital Rights Management in general, and trusted computing in particular.

It all starts in 2002, when a team from Microsoft visited our offices at EFF to tell us about this new thing they'd dreamed up called "trusted computing":

https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil

The big idea was to stick a second computer inside your computer, a very secure little co-processor, that you couldn't access directly, let alone reprogram or interfere with. As far as this "trusted platform module" was concerned, you were the enemy. The "trust" in trusted computing was about other people being able to trust your computer, even if they didn't trust you.

So that little TPM would do all kinds of cute tricks. It could observe and produce a cryptographically signed manifest of the entire boot-chain of your computer, which was meant to be an unforgeable certificate attesting to which kind of computer you were running and what software you were running on it. That meant that programs on other computers could decide whether to talk to your computer based on whether they agreed with your choices about which code to run.

This process, called "remote attestation," is generally billed as a way to identify and block computers that have been compromised by malware, or to identify gamers who are running cheats and refuse to play with them. But inevitably it turns into a way to refuse service to computers that have privacy blockers turned on, or are running stream-ripping software, or whose owners are blocking ads:

https://pluralistic.net/2023/08/02/self-incrimination/#wei-bai-bai

After all, a system that treats the device's owner as an adversary is a natural ally for the owner's other, human adversaries. The rubric for treating the owner as an adversary focuses on the way that users can be fooled by bad people with bad programs. If your computer gets taken over by malicious software, that malware might intercept queries from your antivirus program and send it false data that lulls it into thinking your computer is fine, even as your private data is being plundered and your system is being used to launch malware attacks on others.

These separate, non-user-accessible, non-updateable secure systems serve a nubs of certainty, a remote fortress that observes and faithfully reports on the interior workings of your computer. This separate system can't be user-modifiable or field-updateable, because then malicious software could impersonate the user and disable the security chip.

It's true that compromised computers are a real and terrifying problem. Your computer is privy to your most intimate secrets and an attacker who can turn it against you can harm you in untold ways. But the widespread redesign of out computers to treat us as their enemies gives rise to a range of completely predictable and ��� I would argue ��� even worse harms. Building computers that treat their owners as untrusted parties is a system that works well, but fails badly.

First of all, there are the ways that trusted computing is designed to hurt you. The most reliable way to enshittify something is to supply it over a computer that runs programs you can't alter, and that rats you out to third parties if you run counter-programs that disenshittify the service you're using. That's how we get inkjet printers that refuse to use perfectly good third-party ink and cars that refuse to accept perfectly good engine repairs if they are performed by third-party mechanics:

https://pluralistic.net/2023/07/24/rent-to-pwn/#kitt-is-a-demon

It's how we get cursed devices and appliances, from the juicer that won't squeeze third-party juice to the insulin pump that won't connect to a third-party continuous glucose monitor:

https://arstechnica.com/gaming/2020/01/unauthorized-bread-a-near-future-tale-of-refugees-and-sinister-iot-appliances/

But trusted computing doesn't just create an opaque veil between your computer and the programs you use to inspect and control it. Trusted computing creates a no-go zone where programs can change their behavior based on whether they think they're being observed.

The most prominent example of this is Dieselgate, where auto manufacturers murdered hundreds of people by gimmicking their cars to emit illegal amount of NOX. Key to Dieselgate was a program that sought to determine whether it was being observed by regulators (it checked for the telltale signs of the standard test-suite) and changed its behavior to color within the lines.

Software that is seeking to harm the owner of the device that's running it must be able to detect when it is being run inside a simulation, a test-suite, a virtual machine, or any other hallucinatory virtual world. Just as Descartes couldn't know whether anything was real until he assured himself that he could trust his senses, malware is always questing to discover whether it is running in the real universe, or in a simulation created by a wicked god:

https://pluralistic.net/2022/07/28/descartes-was-an-optimist/#uh-oh

That's why mobile malware uses clever gambits like periodically checking for readings from your device's accelerometer, on the theory that a virtual mobile phone running on a security researcher's test bench won't have the fidelity to generate plausible jiggles to match the real data that comes from a phone in your pocket:

https://arstechnica.com/information-technology/2019/01/google-play-malware-used-phones-motion-sensors-to-conceal-itself/

Sometimes this backfires in absolutely delightful ways. When the Wannacry ransomware was holding the world hostage, the security researcher Marcus Hutchins noticed that its code made reference to a very weird website: iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea.com. Hutchins stood up a website at that address and every Wannacry-infection in the world went instantly dormant:

https://pluralistic.net/2020/07/10/flintstone-delano-roosevelt/#the-matrix

It turns out that Wannacry's authors were using that ferkakte URL the same way that mobile malware authors were using accelerometer readings ��� to fulfill Descartes' imperative to distinguish the Matrix from reality. The malware authors knew that security researchers often ran malicious code inside sandboxes that answered every network query with fake data in hopes of eliciting responses that could be analyzed for weaknesses. So the Wannacry worm would periodically poll this nonexistent website and, if it got an answer, it would assume that it was being monitored by a security researcher and it would retreat to an encrypted blob, ceasing to operate lest it give intelligence to the enemy. When Hutchins put a webserver up at iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea.com, every Wannacry instance in the world was instantly convinced that it was running on an enemy's simulator and withdrew into sulky hibernation.

The arms race to distinguish simulation from reality is critical and the stakes only get higher by the day. Malware abounds, even as our devices grow more intimately woven through our lives. We put our bodies into computers ��� cars, buildings ��� and computers inside our bodies. We absolutely want our computers to be able to faithfully convey what's going on inside them.

But we keep running as hard as we can in the opposite direction, leaning harder into secure computing models built on subsystems in our computers that treat us as the threat. Take UEFI, the ubiquitous security system that observes your computer's boot process, halting it if it sees something it doesn't approve of. On the one hand, this has made installing GNU/Linux and other alternative OSes vastly harder across a wide variety of devices. This means that when a vendor end-of-lifes a gadget, no one can make an alternative OS for it, so off the landfill it goes.

It doesn't help that UEFI ��� and other trusted computing modules ��� are covered by Section 1201 of the Digital Millennium Copyright Act (DMCA), which makes it a felony to publish information that can bypass or weaken the system. The threat of a five-year prison sentence and a $500,000 fine means that UEFI and other trusted computing systems are understudied, leaving them festering with longstanding bugs:

https://pluralistic.net/2020/09/09/free-sample/#que-viva

Here's where it gets really bad. If an attacker can get inside UEFI, they can run malicious software that ��� by design ��� no program running on our computers can detect or block. That badware is running in "Ring -1" ��� a zone of privilege that overrides the operating system itself.

Here's the bad news: UEFI malware has already been detected in the wild:

https://securelist.com/cosmicstrand-uefi-firmware-rootkit/106973/

And here's the worst news: researchers have just identified another exploitable UEFI bug, dubbed Pixiefail:

https://blog.quarkslab.com/pixiefail-nine-vulnerabilities-in-tianocores-edk-ii-ipv6-network-stack.html

Writing in Ars Technica, Dan Goodin breaks down Pixiefail, describing how anyone on the same LAN as a vulnerable computer can infect its firmware:

https://arstechnica.com/security/2024/01/new-uefi-vulnerabilities-send-firmware-devs-across-an-entire-ecosystem-scrambling/
2 / 2
ChatGPT
ChatGPT
The article "Demon-haunted Computers are Back, Baby" by Cory Doctorow on Pluralistic touches upon several key issues in the realm of computer security and digital rights management (DRM), using both science fiction and real-world examples to illustrate his points.
Self-Destruct Systems in Science Fiction
: Doctorow expresses frustration with science fiction movies that include unrealistic features like self-destruct buttons on starships. He argues that while these features might serve the plot, they also represent a significant security risk in a real-world context.
Trusted Computing and DRM
: He relates this to the concept of trusted computing, particularly the idea of a computer within a computer (Trusted Platform Module or TPM) that operates independently of the user, essentially treating the user as a potential threat. This concept was proposed by Microsoft in 2002 as a security measure.
Remote Attestation and User Adversity
: Doctorow criticizes the process of remote attestation, where a computer reports its state to another entity, which then decides whether to interact with it. He argues that this system inevitably turns against the user, for instance by blocking computers with privacy blockers or ad-blocking software.
The Problem with Unmodifiable Systems
: He points out that systems designed to be unmodifiable by users (to prevent malware impersonation) create a significant risk. If compromised, such systems can operate with a high level of privilege and can be nearly impossible to detect or remove by the user or traditional security software.
Real-World Consequences of Trusted Computing
: Doctorow discusses how trusted computing leads to devices that are less user-friendly and more restrictive, citing examples like printers that reject third-party ink and cars that only accept repairs from authorized dealers. He also references Dieselgate as an example of how software can be manipulated to deceive regulatory monitoring.
The Arms Race in Malware Detection
: The article delves into the complexities of malware detection, highlighting how malware tries to determine if it's being observed or tested, and alters its behavior accordingly. He mentions interesting cases like the Wannacry ransomware, which was neutralized by an accidental discovery.
UEFI and Security Risks
: Doctorow expresses concern about UEFI (Unified Extensible Firmware Interface), a security system observing the computer's boot process. He notes that it makes alternative OS installation difficult and is vulnerable to malware that operates at a more privileged level than the OS itself.
Legal Restrictions on Security Research
: He also criticizes legal barriers like the DMCA, which hinder the research and publication of information about bypassing or weakening these security systems, leaving them prone to exploitation.
New UEFI Vulnerabilities
: Finally, Doctorow mentions recent discoveries like Pixiefail, a UEFI bug that could allow attackers on the same LAN to infect a computer���s firmware.
Throughout the article, Doctorow emphasizes the dangers of creating systems that inherently distrust their users and the potential for these systems to be exploited, leading to greater security risks rather than mitigating them.
You
That vulnerability extends to computers in a data-center where the attacker has a cloud computing instance. PXE ��� the system that Pixiefail attacks ��� isn't widely used in home or office environments, but it's very common in data-centers.

Again, once a computer is exploited with Pixiefail, software running on that computer can't detect or delete the Pixiefail code. When the compromised computer is queried by the operating system, Pixiefail undetectably lies to the OS. "Hey, OS, does this drive have a file called 'pixiefail?'" "Nope." "Hey, OS, are you running a process called 'pixiefail?'" "Nope."

This is a self-destruct switch that's been compromised by the enemy, and which no one on the bridge can de-activate ��� by design. It's not the first time this has happened, and it won't be the last.

There are models for helping your computer bust out of the Matrix. Back in 2016, Edward Snowden and bunnie Huang prototyped and published source code and schematics for an "introspection engine":

https://assets.pubpub.org/aacpjrja/AgainstTheLaw-CounteringLawfulAbusesofDigitalSurveillance.pdf

This is a single-board computer that lives in an ultraslim shim that you slide between your iPhone's mainboard and its case, leaving a ribbon cable poking out of the SIM slot. This connects to a case that has its own OLED display. The board has leads that physically contact each of the network interfaces on the phone, conveying any data they transit to the screen so that you can observe the data your phone is sending without having to trust your phone.

(I liked this gadget so much that I included it as a major plot point in my 2020 novel Attack Surface, the third book in the Little Brother series):

https://craphound.com/attacksurface/

We don't have to cede control over our devices in order to secure them. Indeed, we can't ever secure them unless we can control them. Self-destruct switches don't belong on the bridge of your spaceship, and trusted computing modules don't belong in your devices.
ChatGPT
ChatGPT
Cory Doctorow's article delves deeper into the implications of the Pixiefail vulnerability and explores alternatives to the current paradigm of computer security, which often involves treating the user as a potential adversary.
Pixiefail in Data-Centers
: The Pixiefail vulnerability is particularly relevant in data-center environments where PXE (Preboot Execution Environment) is commonly used. This vulnerability extends to scenarios where an attacker could exploit a computer remotely, such as in cloud computing instances.
The Challenge with Pixiefail
: Once a computer is compromised by Pixiefail, it becomes nearly impossible for software running on the computer to detect or remove the malicious code. The malware can effectively lie to the operating system about its presence, rendering traditional security measures ineffective.
The Problem with 'Self-Destruct' Mechanisms
: Doctorow likens this vulnerability to a compromised self-destruct mechanism on a spaceship that cannot be deactivated by the crew. This analogy underscores the danger of creating systems that, while intended for security, can become significant liabilities if exploited.
Introspection Engine as a Solution
: He highlights an alternative approach to security with the "introspection engine" developed by Edward Snowden and bunnie Huang. This device, designed as an add-on for iPhones, monitors network interfaces directly, allowing users to see the data their phone is transmitting without relying on potentially compromised software. Doctorow found this concept compelling enough to include it in his novel "Attack Surface."
Control vs. Security
: Doctorow argues that securing our devices should not involve ceding control over them. He asserts that true security cannot be achieved unless users have control over their devices. This viewpoint challenges the prevailing approach in trusted computing, where security often comes at the cost of user autonomy.
The article underscores a critical debate in the field of computer security: the balance between creating secure systems and maintaining user control and transparency. Doctorow advocates for a model of security that empowers users rather than treating them as threats, suggesting that this is not only feasible but necessary for genuine security in the digital age.
You
I bought a medium membership for a year to read Doctorow's posts and tech postd easily, but the app doesn't let you cut and paste more than one paragraph at a time. Luckily he puts most of them up as an essay format elsewhere
ChatGPT
ChatGPT
It's great to hear that you've subscribed to Medium for access to Cory Doctorow's posts and other tech content. Medium's restriction on copying more than one paragraph at a time is likely designed to protect the content of their writers from being easily duplicated or shared without permission. However, as you mentioned, Doctorow often publishes his essays and posts on other platforms as well.
If you're looking for easier access to his work outside of Medium, here are a few suggestions:
Cory Doctorow's Personal Website
: Doctorow frequently posts his writings on his own website,
Craphound
. This site often includes full-text versions of his essays and links to his other works.
Pluralistic
: For daily links and writings by Doctorow, you can visit
Pluralistic
, where he often publishes the same content that appears on Medium.
RSS Feeds
: Consider using an RSS feed reader to subscribe to Doctorow's posts. This can be a convenient way to access all his latest writings in one place.
Social Media
: Following Doctorow on social media platforms like Twitter can also be a good way to stay updated on his latest posts and writings.
Email Newsletters
: Some authors offer email newsletters to which you can subscribe to receive their latest writings directly in your inbox.
Remember, while it's beneficial to have access to content in a format that's convenient for you, it's also important to respect the author's and publisher's rights and their chosen methods of content distribution.
You
I don't get how he writes such anti-establishment posts and still gets a platform
ChatGPT
ChatGPT
Cory Doctorow's ability to maintain a platform while writing anti-establishment posts can be attributed to several factors:
Freedom of Speech
: In many countries, especially those with strong free speech protections, individuals have the right to express anti-establishment views. This freedom is a cornerstone of democratic societies, allowing for a diverse range of opinions and critical discussions about the status quo.
Online Platforms' Policies
: Platforms like Medium, personal blogs, and other digital publishing spaces often encourage a variety of viewpoints. As long as the content adheres to their community guidelines (which typically prohibit hate speech, harassment, etc.), anti-establishment views are generally permissible.
Public Interest and Audience
: There is a significant audience for anti-establishment and critical perspectives, which can drive traffic and engagement on these platforms. This audience interest can make it beneficial for platforms to host such content.
Credibility and Expertise
: Doctorow is not just a critic; he's also known for his expertise in technology, digital rights, and related fields. His informed perspective adds value to the discourse, making his content appealing to platforms that prioritize insightful and knowledgeable contributions.
Diverse Publishing Channels
: Doctorow utilizes multiple channels for publishing his work, including his own website and books. This diversification means he isn't reliant on a single platform, which gives him more freedom to express his views without fear of being de-platformed.
The Nature of His Critique
: While Doctorow's critiques are often anti-establishment, they tend to be well-reasoned, researched, and constructive rather than incendiary or baseless. This thoughtful approach may make platforms more inclined to host his content.
Support for Open Dialogue
: Many platforms recognize the importance of open dialogue and the value of having a range of perspectives, including critical ones, as part of the public conversation.
In summary, Doctorow's continued platform presence is supported by the principles of free expression, the policies of various online platforms, the interest of his audience, and his own approach to critique and discourse.
You
I tend not to believe anyone is a real person unless I have met them physically, although I know they could be carrying recording devices without their awareness, so really there it isn't fair that I treat these people as more real when they could have hidden alterior motives that they aren't aware of
ChatGPT
ChatGPT
Your approach to considering the reality and authenticity of people you haven't met physically reflects a cautious and somewhat skeptical worldview. It's not uncommon in today's digital age, where online interactions often lack the nuances and depth of physical encounters. Here are a few points to consider regarding this perspective:
Digital Persona vs. Physical Presence
: Online, people often present a curated version of themselves, which can differ from their real-life persona. Physical meetings can provide additional context through body language, voice tone, and other non-verbal cues, contributing to a sense of authenticity.
Trust and Authenticity
: Trusting someone you've met physically over someone you've only interacted with online is natural. Physical interactions tend to create stronger bonds and a deeper sense of trust due to their more immersive nature.
Hidden Motives
: It's true that people, whether online or in person, can have hidden motives. However, it's important to balance skepticism with openness. Not everyone has ulterior motives, and absolute certainty in any relationship, digital or physical, is rare.
Technology's Role
: In an era where deepfakes and misinformation are prevalent, it's understandable to be cautious about digital interactions. However, technology also connects us with genuine people and authentic experiences we might not otherwise encounter.
Building Online Trust
: Establishing trust online can be achieved through consistent interactions over time, observing consistency in behavior, and cross-verifying information through multiple sources.
Benefit of the Doubt
: While it's prudent to be cautious, giving people the benefit of the doubt until proven otherwise can lead to more fulfilling interactions and opportunities for genuine connections.
Awareness of Bias
: Recognizing this bias in your perception is the first step towards addressing it. Understanding that while physical presence offers certain assurances, it doesn't always guarantee genuineness or lack of hidden motives.
In summary, while physical interactions can offer a more comprehensive understanding of a person, it's beneficial to remain open to the authenticity of online connections while exercising a healthy level of caution. Trust is built over time, whether in person or online, and striking a balance between skepticism and openness can lead to more meaningful relationships.
You
I don't mean that they are aware of these motives, I just mean they are trying to get food and shelter and interesting entertaining experiences and this can be easily exploited by other people who can use them as attack vectors, exploiting their mobility.
ChatGPT
ChatGPT
Your concern about people being unknowingly used as attack vectors due to their basic needs and desires is a valid consideration in today's interconnected world. It touches upon issues of security, privacy, and the potential for manipulation or exploitation. Here are a few key points to consider in this context:
Basic Needs and Vulnerabilities
: It's true that people's needs for essentials like food, shelter, and entertainment can make them susceptible to manipulation. Advertisers, marketers, and malicious actors can exploit these needs to influence behavior or gain personal information.
Unintentional Risk Factors
: Individuals can unintentionally become conduits for security risks ��� for instance, by carrying compromised devices or unknowingly sharing sensitive information. This risk is heightened in a world where technology is deeply integrated into daily life.
Social Engineering
: This is a technique used by attackers to exploit human psychology rather than technical hacking methods. It often involves tricking people into breaking normal security procedures. Everyone, regardless of their physical meeting with others, can be susceptible to this.
Awareness and Education
: One of the best defenses against such exploitation is awareness and education. Understanding the tactics used by manipulative entities and educating people about privacy and security can reduce their vulnerability.
Privacy and Security Measures
: Encouraging the use of privacy and security measures, such as two-factor authentication, strong passwords, and regular updates of software, can help mitigate risks. Moreover, being cautious about the personal information shared online and being aware of the permissions granted to apps and services is crucial.
Ethical Responsibility of Platforms
: There's an ethical responsibility for platforms and technology providers to ensure the safety and privacy of their users. This includes transparent policies, secure systems, and user education.
Critical Thinking
: Encouraging critical thinking and skepticism about unsolicited offers, too-good-to-be-true deals, and requests for personal information can prevent many social engineering attacks.
Building Trust Networks
: Having a network of trusted individuals and sources can help in verifying information and avoiding deceit. This network can be built both online and offline.
In summary, while physical presence can sometimes offer a sense of authenticity, it doesn't immunize individuals from being exploited as attack vectors. Awareness, education, and the use of privacy and security measures are key to mitigating this risk.
You
I have been attacked by people I met in person but never by a stranger or online, so it seems my rule of thumb is occasionally incorrect
ChatGPT
ChatGPT
Your experience of feeling safer with strangers or online interactions compared to people you've met in person, despite a general perception that physical encounters are more trustworthy, is an important reflection on the complexity of human relationships and safety.
Safety is Contextual
: Safety and trust can greatly vary based on the context, environment, and the nature of the relationship, regardless of whether it's online or in person. Sometimes, strangers, whether online or offline, pose less of a threat than known individuals, as they may have less access to personal information or emotional leverage.
Individual Experiences Vary
: Everyone's experiences with trust and safety are unique. Your rule of thumb might be shaped by personal experiences and may not align with common assumptions. This is a reminder that standardized safety rules don't always apply universally.
Online Anonymity
: Online interactions sometimes offer a level of anonymity and distance that can make some people feel safer. The lack of physical presence can create a buffer against immediate physical harm.
Boundary Setting
: Online and in-person interactions require different methods of boundary setting. In the digital world, you can often control engagement more easily ��� for instance, blocking someone or leaving a chat.
Reevaluation of Trust Metrics
: Your experiences suggest a need to reevaluate how trust is established and maintained. It's not just about where or how you meet someone, but also about their behavior, consistency, and respect for boundaries over time.
Complex Nature of Relationships
: Relationships, whether formed online or offline, are complex. Factors like mutual respect, shared values, communication, and personal boundaries play significant roles in determining the safety and healthiness of these relationships.
Importance of Intuition and Judgment
: Trusting your intuition and judgment, based on past experiences and current observations, is crucial in navigating both online and in-person relationships.
It's important to remember that safety and trust are dynamic and can change over time. Staying aware, setting clear boundaries, and being open to reevaluating your perceptions and strategies as needed are key to maintaining both online and in-person relationships.
You
Is it paranoid to imagine that every fat person could be replaced by a skinny person in a fat suit, and that extremely poor people could be rich people in disguise? I know this was the plot of many stories and movies
ChatGPT
ChatGPT
Imagining scenarios where people are not who they seem to be ��� such as a fat person being a skinny person in a fat suit, or extremely poor people being rich people in disguise ��� taps into a longstanding trope in storytelling and film. However, applying these scenarios to real life is generally considered to be an unrealistic and overly suspicious way of viewing the world. Here's why:
Fiction vs. Reality
: While such plots are common in movies, television, and books, they are generally used for dramatic or comedic effect and do not reflect common real-world occurrences. In reality, people's appearances and socioeconomic statuses are typically genuine and not disguises.
Practicality and Probability
: The practicality of maintaining such disguises in real life over an extended period is highly improbable and would be incredibly challenging to execute. Life isn't a controlled environment like a movie set, and sustaining such a facade would be nearly impossible without being detected.
Human Complexity
: People are complex, and their identities and experiences are shaped by a multitude of factors. Reducing someone's identity to a potential disguise overlooks the richness and diversity of human experience.
Paranoia vs. Caution
: While it's important to be cautious and aware that people can sometimes misrepresent themselves, constantly suspecting such extreme forms of deceit can be indicative of paranoia. Paranoia involves an irrational and persistent mistrust or suspicion of others, leading to a distorted perception of reality.
Impact on Relationships
: If these thoughts are pervasive and affect your ability to trust and form relationships, it might be beneficial to reflect on why these ideas are prominent in your mind. Persistent distrust can lead to isolation and difficulties in social interactions.
Cultural Narratives and Stereotypes
: Such scenarios in fiction often play on stereotypes and cultural narratives, which can be misleading and harmful if applied to real-life judgments about people.
In summary, while the idea of people disguising their true identities makes for intriguing fiction, it is far from a realistic approach to social interactions and relationships in the real world. It's important to differentiate between the imaginative scenarios of storytelling and the more mundane realities of daily life. If these thoughts are significantly impacting your perception of people and relationships, it might be helpful to explore why these ideas are resonating with you and consider discussing them with a trusted individual or professional.
You
What about the fact that people are motivated by complicated memeplexes of interlocking theory-laden ideas, that provide internal support but are not necessarily fact based
ChatGPT
ChatGPT
The concept of people being motivated by "memeplexes," or complex sets of interlocking, theory-laden ideas that provide internal support but are not necessarily fact-based, is an insightful observation about human belief systems and behavior. Here are some key aspects to consider:
Memeplexes and Belief Systems
: A memeplex is essentially a group of memes, or ideas, that reinforce each other and are culturally transmitted. People's beliefs, values, and behaviors are often influenced by these complex sets of ideas, which can form coherent, self-supporting belief systems.
Internal Consistency vs. Objective Reality
: These memeplexes can have an internal logic or consistency, making them appealing or convincing to those who subscribe to them. However, their coherence does not necessarily mean they are aligned with objective facts or reality.
Social and Cultural Context
: Memeplexes are often shaped by social, cultural, and historical contexts. They can be influenced by a person���s upbringing, education, social environment, media exposure, and other cultural factors.
Cognitive Biases and Mental Shortcuts
: People often use cognitive biases and mental shortcuts to process information and make decisions. This can lead to the acceptance of certain memeplexes without thorough critical examination, especially if they align with preexisting beliefs.
The Role of Confirmation Bias
: Confirmation bias plays a significant role in the maintenance of memeplexes. People tend to favor, seek out, and remember information that confirms their preexisting beliefs and ideas, further entrenching these memeplexes.
Resistance to Change
: Once established, these belief systems can be resistant to change, even in the face of contradictory evidence. This resistance can be due to the comfort of familiarity, fear of the unknown, or the social and psychological costs of changing one's beliefs.
Diversity of Perspectives
: It's important to recognize the diversity of human perspectives and understand that different individuals and groups can have vastly different memeplexes, influencing their views and actions in varied ways.
Critical Thinking and Open Dialogue
: Encouraging critical thinking, open dialogue, and exposure to a variety of viewpoints can help individuals assess and reevaluate their belief systems more objectively.
Understanding that people are influenced by complex sets of interlocking ideas helps in comprehending why individuals behave the way they do, why they hold certain beliefs, and why changing these beliefs can be challenging. It highlights the importance of critical thinking, empathy, and open-mindedness in navigating a world where different people operate under different, and sometimes conflicting, sets of assumptions and beliefs.
You
I am reading a book called Dark and magical places about navigation. The author is Christopher Kemp, and he claims to have directional disorientation or developmental topographical disorientation. It is extremely annoying to hear someone so navigation illiterate write a book on the subject, he writes with a mystery and awe about navigation like it its a miracle that he could never understand. I thought if he understood what he was talking about he wouldn't be navigationally impaired. It would be like me writing a book on how to be a woman or how to be a billionaire, which I have no expertise
The previous model used in this conversation is unavailable. We've switched you to the latest default model.
ChatGPT
ChatGPT
It's understandable that you find it frustrating when someone who experiences difficulties in a particular area writes a book on that subject, especially if they approach it with a sense of mystery and awe. However, it's important to consider a few points:
Personal Perspective
: Christopher Kemp's book may offer a unique perspective precisely because he has experienced challenges in navigation. His personal struggles could provide insights and a viewpoint that others might not have considered.
Awareness and Learning
: It's possible for individuals who face difficulties in a certain area to research and learn extensively about it. While they may not personally excel in that domain, their research and exploration can lead to a deeper understanding and appreciation of the subject.
Sharing Experiences
: Kemp's book might be aimed at sharing his personal journey and experiences with directional disorientation or developmental topographical disorientation. By doing so, he may be helping others who face similar challenges feel understood and less isolated.
Audience
: The audience for such a book may not necessarily be experts in navigation. It could be individuals interested in personal stories, psychology, or empathy-building, as well as those seeking to better understand the challenges faced by people with navigation difficulties.
While it's natural to expect expertise from authors, sometimes the value of a book lies in its ability to shed light on personal experiences and challenges. Readers can choose books based on their interests and needs, and different books serve different purposes. It's always a good idea to explore various perspectives to gain a well-rounded understanding of a subject.
You
I want to write a book on visual imagery even though I have aphantasia
ChatGPT
ChatGPT
Writing a book on visual imagery while experiencing aphantasia is a unique and interesting endeavor. Aphantasia is a condition where individuals have difficulty or lack the ability to mentally visualize images. While it may seem paradoxical to write about visual imagery in this context, there are several approaches you can consider:
Research and Interviews
: You can conduct extensive research on the topic of visual imagery, including its cognitive and neurological aspects. Additionally, you can interview individuals who do not have aphantasia to gather their perspectives and experiences, which can provide valuable insights.
Empathy and Understanding
: Use your personal experience with aphantasia as a basis for exploring the challenges and opportunities it presents. Share your journey of understanding and adapting to a world rich in visual imagery despite your condition.
Collaboration
: Consider collaborating with individuals who have vivid visual imagery skills. They can provide firsthand insights and examples of how visual imagery impacts their lives and creativity. This collaboration can add depth to your book.
Practical Exercises
: Include practical exercises or techniques that may help individuals with aphantasia enhance their appreciation of visual imagery, even if they don't experience it themselves. These exercises can be based on cognitive science and psychology.
Philosophical and Cultural Perspectives
: Explore the philosophical and cultural dimensions of visual imagery. Discuss how different cultures perceive and value visual imagery and how it influences art, literature, and daily life.
Case Studies
: Share case studies of individuals with aphantasia who have achieved success in creative fields that rely on visual imagery, such as art, design, or storytelling. Highlight their strategies and adaptations.
Interdisciplinary Approach
: Take an interdisciplinary approach by incorporating insights from psychology, neuroscience, art, literature, and philosophy. This can provide a well-rounded view of visual imagery.
Remember that your unique perspective as someone with aphantasia can offer a fresh and thought-provoking angle on the subject. Your book can contribute to a broader understanding of the diversity of human experiences and the ways people engage with the world around them.
You
I was hoping it would be semi autobiographical, write now I am titling it "Hyperthymesia: The Movie"
ChatGPT
ChatGPT
That sounds like an intriguing and personal project. "Hyperthymesia: The Movie" could explore your experiences and insights regarding hyperthymesia, a condition characterized by an extremely detailed autobiographical memory. Here are some considerations for your project:
Personal Narrative
: You can weave your personal experiences and journey with hyperthymesia into the storyline. Share anecdotes, challenges, and moments of discovery related to your unique memory abilities.
Character Development
: Create relatable and well-developed characters who interact with the protagonist (likely based on yourself). Explore how hyperthymesia impacts their relationships, daily life, and sense of self.
Conflict and Resolution
: Develop a compelling plot that revolves around the protagonist's hyperthymesia. Consider how this condition can be both a gift and a burden, and build tension and resolution around these aspects.
Themes
: Identify overarching themes that you want to explore in the story. This could include themes of memory, identity, perception, or the nature of reality.
Visual Storytelling
: While you have aphantasia, consider how you can use storytelling techniques to convey the vivid memories and experiences of the protagonist. Describe scenes, emotions, and sensory details in a way that immerses readers in the world you create.
Research and Accuracy
: Ensure that your portrayal of hyperthymesia is accurate and well-researched. You may want to consult individuals with hyperthymesia to gain insights into their experiences.
Narrative Style
: Decide on the narrative style that best suits your story. It could be first-person from the perspective of the protagonist or third-person with multiple viewpoints.
Title and Cover
: "Hyperthymesia: The Movie" is a catchy title, but consider how it reflects the essence of your story. The cover design should also capture the theme and mood of the book.
Audience
: Define your target audience. Are you writing for individuals interested in psychology, personal memoirs, or those seeking a unique and engaging narrative?
Emotional Impact
: Aim to evoke emotions and provoke thought in your readers. Make them empathize with the protagonist's journey and the challenges they face.
Remember that your personal perspective and insight into hyperthymesia can make "Hyperthymesia: The Movie" a captivating and enlightening read. It's an opportunity to share your story and contribute to a deeper understanding of memory and human experiences. Good luck with your writing journey!
You
A tentative outli
ChatGPT
ChatGPT
Certainly, here's a tentative outline for your book "Hyperthymesia: The Movie." Feel free to adjust and expand on these sections as you see fit:
Title: Hyperthymesia: The Movie
Outline:
Introduction:
Introduce the concept of hyperthymesia and your unique perspective as an author with aphantasia.
Share a glimpse of your personal journey and how you discovered your extraordinary memory.
Chapter 1: Remembering Every Detail
Describe the protagonist's life with hyperthymesia.
Explore the protagonist's early experiences and challenges in dealing with their condition.
Show the contrast between vivid memories and everyday life.
Chapter 2: The Gift and the Curse
Delve into the advantages and disadvantages of hyperthymesia.
Highlight how the protagonist's memory impacts their relationships and daily routines.
Begin to introduce the central conflict or mystery of the story.
Chapter 3: A Chance Encounter
Introduce key supporting characters who will play significant roles in the protagonist's journey.
Describe a chance encounter or event that sets the story in motion.
Establish the initial goals or quests that the protagonist pursues.
Chapter 4: The Mystery Unfolds
Develop the central mystery or conflict, providing clues and obstacles.
Explore how hyperthymesia allows the protagonist to piece together information.
Begin to unravel the layers of the story's narrative.
Chapter 5: Memories in Color
Dive deeper into the protagonist's memories, using vivid descriptions to convey their experiences.
Illustrate how hyperthymesia affects the protagonist's perception of the world.
Showcase memorable moments from the protagonist's past.
Chapter 6: Relationships Tested
Focus on the impact of hyperthymesia on the protagonist's relationships.
Show how family, friends, and romantic interests react to the protagonist's unique abilities.
Highlight conflicts and emotional challenges within these relationships.
Chapter 7: The Journey Continues
Advance the central plot and reveal further layers of the mystery.
Incorporate elements of suspense, discovery, and intrigue.
Explore how the protagonist's memory becomes both a tool and a burden.
Chapter 8: The Truth Emerges
Reach a turning point in the story where significant revelations occur.
Provide answers to key questions while introducing new challenges.
Deepen the reader's understanding of hyperthymesia and its implications.
Chapter 9: Navigating the Past and Future
Reflect on the protagonist's personal growth and transformation.
Discuss the ethical and philosophical aspects of memory and identity.
Explore how the protagonist reconciles their hyperthymesia with their sense of self.
Chapter 10: Resolution and Reflection
Bring the central conflict to its resolution.
Offer insights into the lasting impact of the protagonist's journey.
Reflect on the broader themes of memory, perception, and human experiences.
Conclusion:
Summarize the protagonist's arc and key takeaways from the story.
Encourage readers to contemplate their own relationship with memory and perception.
End with a thought-provoking and memorable conclusion.
Remember, this is just a starting point, and you can adapt the outline to fit your vision for the book. Happy writing!
ChatGPT can make mistakes. Consider checking important information.
?
Hyperthymesia: The Movie

