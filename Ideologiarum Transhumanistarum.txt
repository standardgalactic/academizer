Ideologiarum Transhumanistarum
Abrir barra lateral
ChatGPT
4
TLDR 
This document is intended as a supplementary resource for The Great Simplification podcast 
episode #132 with Nate Hagens and Daniel Schmachtenberger on artificial intelligence (AI) and 
climate change. As discussed in the podcast, issues emerging from the nexus of AI and climate 
go beyond concerns of direct energy consumption to deeper and more systemic concerns, 
including the acceleration of extractive industries by AI applications, strong interconnections 
with the defense industry, the underlying transhumanist philosophy driving AI accelerationism, 
and a systems blindness to economy-wide Jevons paradox rebound effects. 
���There is a clear growing trend in marketing rhetoric across sectors for AI to enable 
significant growth whilst also tackling climate and sustainability challenges 
���Coupled with the extraordinary exponential growth of the AI sector and 
ubiquitous applications in areas such as the oil & gas industry and defense 
& intelligence sector, there is a substantial risk that AI climate solutionist 
rhetoric ultimately serves as an unprecedented form of greenwashing for an 
ultimately catastrophic set of technologies. 
���Despite some claims that AI could revolutionize scientific development of 
panacea solutions like nuclear fusion, in reality, this is unlikely 
���Advancements in various forms of artificial intelligence, including AI-enhanced planetary 
sensing capacities as well as generative AI pose distinct accelerating risks for the twin 
attractors of the metacrisis (catastrophe or dystopia) 
���Increased dystopian potential: The prevalence of digital technology and 
growing capabilities of AI-enabled Internet of Things (IoT), distributed sensor 
networks, ultra-high resolution satellites, and smart cities, whilst potentially useful 
for climate and biodiversity conservation, simultaneously increase the capacity 
for authoritarian regimes to utilize ubiquitous surveillance 
���Pathways for catastrophic risks: agential risks where a small group of people 
or even one person could use generative AI to assist planning large-scale 
terrorist actions, possibly at the level of mass genocide, omnicide and collapsing 
civilization. Similarly, runaway artificial superintelligence (ASI) with agentic 
capacity may do so by itself. With little effort, ChatGPT can be prompted to 
answer confidently about various ways an ASI could destroy humanity: see our 
document here 
���AI safety efforts themselves tend to accelerate AI development, all of which is largely 
supported by a dangerous mix of philosophical views which fundamentally see little 
value in embodied human lives, natural ecosystems and the living biosphere 
���How much of a difference AI would make to climate is likely a lot less than 
proponents like to claim. None of the solutions individually, nor taken as a whole, 
appear to convincingly ���solve��� climate change writ large. At the same time, various 
existing and developing machine learning applications are individually useful within a 
narrow scope, though many with limitations and additional risks
ChatGPT
This document accompanies The Great Simplification podcast episode #132 featuring Nate Hagens and Daniel Schmachtenberger. It delves into the complex relationship between artificial intelligence (AI) and climate change, emphasizing not just AI���s direct energy use but broader systemic impacts. Key points include:
AI���s Role in Extractive Industries
: AI applications may accelerate extractive activities, intertwining deeply with sectors like oil, gas, and defense, potentially leading to a form of greenwashing that masks the technologies' detrimental impacts.
Transhumanist Drives and Systemic Blindness
: The push for rapid AI development is partly driven by transhumanist philosophies, often overlooking significant systemic issues like the Jevons paradox, where increased efficiency leads to higher resource consumption.
Marketing and Misrepresentation
: There is a trend of using AI as a marketing tool claiming it can address climate issues, which risks overselling AI's capabilities and underestimating its environmental costs.
Potential for Dystopia and Catastrophe
: AI-enhanced technologies could aid authoritarian surveillance or enable severe agential risks, such as terrorism or actions by rogue AI, possibly leading to extreme scenarios like mass genocide or omnicide.
AI Safety and Acceleration
: Efforts to ensure AI safety may paradoxically hasten AI development, supported by philosophical views that undervalue human and ecological well-being.
Limited Impact on Climate Change
: Despite claims, AI alone is unlikely to resolve the climate crisis thoroughly and may carry significant limitations and risks.
The document underscores a need for critical examination of AI���s role in climate solutions and the broader implications of its integration into societal and ecological systems.
4
���Two low hanging fruit applications (concrete and food waste) optimistically 
add up to ~4% of global GHG emissions. There is insufficient information to 
ballpark a fraction for the rest- many of which depend on the success of other 
underlying tech anyway (renewables, EVs, fusion, precision ag, etc.) 
���Considering other side effects and externalities from AI/ML, proposed solutions 
likely outweigh climate benefits- the material and energy demands of more 
semiconductors, cloud server capacity, IoT sensors, and robotics; the exacerbation of 
actively deleterious climate approaches like forest carbon offsets, direct air capture, 
boosting of fossil fuel greenwashing; Jevons rebound effects across nearly all ML-driven 
efficiency gains, plus the entire economic growth acceleration from the AI field as a 
whole if taken together almost certainly outweighs the few percent of global GHG 
emission reductions it could otherwise drive. 
���Globally, the digital tech sector accounts for 10% of global electricity demand. 
Current projections expect data server energy demand to double over the 
next four years, primarily due to AI data server electricity demand growth 
���We estimate about 965 thousand metric tons of mining rock waste was 
produced just for the GPUs used to train OpenAI���s GPT-3 
���A rough estimate based on the Garrett relation between global cumulative 
economic production and energy consumption suggests that current projected 
economic growth from AI would require by 2030 an additional 739TWh per year, 
which is approximately the entire nuclear energy generation of the US 
���Virtually all useful AI/ML applications for climate do not require more AI 
advancements. Of the solutions reviewed below, only two benefit from the current 
advancements in generative AI- material discovery for battery science and construction 
materials such as concrete. 
���All others genuine applications make use of existing, well established tech and 
algorithms (e.g. deep learning, convolutional neural networks, computer vision), 
which only require further work within their particular domain of application (data 
processing, training, architecture), and some benefits from related AI R&D efforts 
like ���explainable AI���. 
���The majority of current AI R&D efforts in large language models and generative 
image & video algorithms are effectively separate from these existing 
applications.
ChatGPT
The document highlights the limited environmental benefits of AI applications in climate solutions, with a detailed examination of the actual and potential impacts. It discusses two specific applications where AI might contribute modestly to greenhouse gas (GHG) reductions���concrete production and food waste management���which together might optimistically reduce global GHG emissions by about 4%. However, it raises concerns that the overall environmental cost of AI might negate these benefits:
Broader Environmental Impact
: The extensive use of resources for AI technologies, such as semiconductors, cloud servers, IoT sensors, and robotics, significantly increases material and energy demands. These demands may not only counteract the GHG savings but also exacerbate other problematic climate strategies like questionable forest carbon offsets and direct air capture technologies.
Economic and Energy Costs
: The document notes that AI's impact on economic growth leads to increased energy consumption. For instance, the digital tech sector already accounts for about 10% of global electricity demand, with expectations of this demand doubling in the next few years due to AI. Additionally, the document estimates substantial environmental costs from the mining required for technologies like GPUs used in AI development.
Jevons Paradox
: The document also points out the Jevons Paradox, where increased efficiency due to machine learning (ML) applications might lead to overall higher resource consumption rather than conservation, thus negating the purported efficiency gains.
Limited Necessity for Advanced AI
: Most beneficial AI applications for climate management do not require cutting-edge AI advancements but can instead utilize existing technologies and algorithms, such as deep learning and computer vision. The current surge in AI research, particularly in large language models and generative algorithms, is seen as largely separate from genuinely useful climate applications.
Overall, the document is skeptical about the net climate benefits of AI and ML technologies, suggesting that their associated costs and externalities likely outweigh the potential reductions in GHG emissions. It calls for a more critical assessment of AI's role in climate solutions, prioritizing existing and less resource-intensive technologies.
4
AI Industry Trends, Rhetoric and Risks 
Climate Solutionist Rhetoric 
Current and emerging AI-driven applications are increasingly seen as reasons to promulgate AI 
as a broad climate & sustainability solution. Terms such as ���Green AI���, ���Sustainable AI���, ���Zero 
Carbon AI���, and ���Net Zero AI��� are often used in much of the marketing and news reporting of 
the current AI boom but are also increasingly defining the mission for academic work and R&D 
for AI1. 
The following are some characteristic examples of this memetic trend from notable platforms 
and organizations: 
���9 ways AI is helping tackle climate change (World Economic Forum) 
���How To Fight Climate Change Using AI (Forbes) 
���Can AI Help Solve the Climate Crisis? (Google) 
���How AI could power the climate breakthrough the world needs (CNN) 
���Explainer: How AI helps combat climate change (UN) 
���How AI can enable a Sustainable Future (PwC report) 
���Reduce Carbon and Costs with the power of AI (BCG report) 
In the extremes, particularly from ���effective accelerationist- e/acc��� groups which increasingly 
define the cultural undercurrents of Silicon Valley, some view artificial (general) intelligence (and 
digital technology broadly) as necessary for solving climate change entirely. From these 
perspectives, the only real solutions to climate change are fundamentally technological (such as 
direct air capture for carbon dioxide removal and solar geoengineering), and these can only be 
accelerated in time via AI and/or AGI. 
Whilst extreme, similar AI techno-solutionist sentiments are also defining influential mainstream 
positions. Take these direct quotes from influential AI and information technology think tanks: 
The digital transition is also considered to be a key tool to reduce energy consumption in 
many sectors ("IT for Green"), to such an extent that it now hardly seems possible to 
address climate change without the large-scale incorporation of digital 
technologies. (The Shift Project, 2019)
ChatGPT
The document delves into the growing trend of framing AI as a critical solution to climate change, encapsulated by terms like ���Green AI���, ���Sustainable AI���, ���Zero Carbon AI���, and ���Net Zero AI���. This rhetoric is prevalent across a spectrum of platforms, from influential media to academic and research circles, illustrating a significant shift towards AI-driven solutions in discussions around sustainability and environmental stewardship.
Key Trends in AI Industry Rhetoric:
Promotion of AI as Essential to Climate Solutions
: Numerous articles and reports position AI as an indispensable tool for tackling climate change. This is evident in publications from major platforms such as the World Economic Forum, Forbes, and CNN, which highlight ways AI can contribute to environmental goals.
Influence of Silicon Valley and Tech Think Tanks
: The cultural and technological narratives driven by Silicon Valley and related think tanks increasingly promote a vision where advanced AI, including artificial general intelligence (AGI), is seen as pivotal for implementing large-scale technological solutions like direct air capture and solar geoengineering.
Mainstreaming of Techno-solutionist Views
: Even beyond the fringes, mainstream discourse is shaping a consensus that addressing climate change is unfeasible without significant reliance on digital technologies. This view is supported by statements from entities like The Shift Project, which emphasize the digital transition as a key strategy for reducing energy consumption across various sectors.
Risks and Critiques:
Risk of Overselling AI Capabilities
: The optimistic portrayal of AI as a silver bullet for climate issues may risk overselling its capabilities while underestimating the associated environmental, social, and economic costs.
Potential for Greenwashing
: As AI applications proliferate, there's a substantial risk that their touted environmental benefits could serve as a form of greenwashing, particularly when these technologies are used to enhance operations in traditionally pollutive industries like oil and gas.
Technological Dependency
: The focus on high-tech solutions may lead to neglecting simpler, potentially more effective approaches that are already available and often less resource-intensive.
Economic and Energy Costs
: The significant energy and resource demands of expanding AI technologies could paradoxically contribute to increased carbon emissions, countering the very goals they aim to achieve.
The document suggests that while AI has potential applications in addressing some aspects of climate change, there is a critical need for a more nuanced and critical examination of its role within broader sustainability strategies. This approach would balance technological advancements with practical, scalable, and sustainable solutions, avoiding an overreliance on AI as the sole pathway to environmental and climate resilience.
4
���by 2030 digital technologies will deliver reductions in carbon emissions equivalent to 
nearly seven times the size of the growth in the total information and communications 
technology (ICT) sector emissions footprint over the same period3. (Global 
e-Sustainability Initiative, 2019) 
The above rhetoric is already translating to real observable market trends. Fortune Business 
Insights finds the ���green technology and sustainability market��� to be valued at USD 16.48 billion 
in 2023 and is projected to grow to USD 89.97 billion by 2032- a compounded annual growth 
rate (CAGR) of 20.9%4- largely presumed to be driven by generative artificial intelligence. 
In the energy sector, the IEA describes AI as an ���increasingly critical resource��� that already 
serves more than 50 different uses in the energy system and is essential for enabling the 
renewable energy transition (see Forecasting Supply and Demand below). 
Unlikely Breakthroughs 
Various headlines over the last few years have indicated that the tech and AI industry is 
particularly hopeful for the ability of artificial intelligence to enable breakthroughs for nuclear 
fusion. Fusion, widely seen as the holy grail of clean energy and panacea for climate change, is 
also being seen as an answer to the extraordinary energy requirements of AI. 
Example articles: 
���How AI is Revolutionising Nuclear Fusion to Harness Limitless Clean Energy (KnowHow, 
Apr 2024) 
���Scientists say they can use AI to solve a key problem in the quest for near-limitless clean 
energy (CNN, February 2024) 
���Engineers use AI to wrangle fusion power for the grid (Princeton University, Feb 2024) 
Whilst it certainly is the case that artificial intelligence and machine learning have been 
successfully used in existing nuclear fission reactors (e.g. reactor design, safety and reliability of 
pressurized water reactors, predicting extreme heat flux conditions), and there have been 
genuinely useful advances which utilize machine learning algorithms for plasma stability of nuclear fusion reactors, these are unlikely to be total ���game-changers���, unlike current 
techno-optimist rhetoric makes it out to be. 
See our more extensive notes below on why this is unlikely to be the case. In the most general 
sense, however, whilst machine learning, various types of neural networks, and (in some limited 
cases) generative AI can be useful in very specific use-cases for environmental/climate-related 
and adjacent research (see, e.g. accelerating materials science), for the most part, AI is 
fundamentally, inherently limited in how much it can accelerate scientific and technological 
progress. There are several arguments for this: 
���Scientific and technological progress requires real-world experimentation. Though 
various forms of AI can speed up certain methods and processes used for 
experimentation (e.g. handling large data sets, speeding up experimental design, etc.), 
simulations, inductive and inferential machine reasoning simply cannot replace physical 
experiments 
���Though proponents of ML-enhanced scientific research and discovery will often support 
their claims by suggesting AI models are ���theory-free��� or ���theory-agnostic��� and can thus 
merely rely on data (i.e. allowing the data to ���speak for itself���), this is in actuality deeply 
misguided. It is widely accepted in philosophy of science that data is always 
theory-mediated, and hence cannot be taken to be merely empirical, objective inputs. 
���Theory-ladenness is evident in contemporary AI methods for scientific research 
and R&D, such as AlphaFold, which unavoidably does integrate scientific theory 
at virtually all levels: data, model structure, hyperparameters, training, evaluation 
and interpretation of results5. 
���As a consequence of the above, any true ���breakthroughs��� in science that require 
fundamental advances in theory (e.g. theoretical physics) cannot be done via AI. 

In short, science itself cannot be automated.
ChatGPT
The document discusses the optimistic claims about digital technologies' potential to significantly reduce carbon emissions, juxtaposed against the real-world growth of the green technology and sustainability market. It critiques the prevailing narrative that AI and digital technologies alone can drive substantial advancements in climate solutions and energy systems, specifically through the lens of nuclear fusion and other high-stakes areas.
Highlights of the Document:
Claimed Impact of Digital Technologies
: The Global e-Sustainability Initiative (2019) claims that by 2030, digital technologies will offset carbon emissions by nearly seven times the growth in emissions from the information and communications technology (ICT) sector itself. This reflects a strong belief in the potential of digital solutions to contribute positively to climate goals.
Market Growth Trends
: The ���green technology and sustainability market��� is projected to grow significantly, with a compound annual growth rate (CAGR) of 20.9% from 2023 to 2032, indicating robust market confidence in these technologies, particularly in AI-driven applications.
AI in Energy Sector
: The International Energy Agency (IEA) notes that AI already plays a crucial role in over 50 different applications within the energy system, crucial for advancing the renewable energy transition. This includes applications in forecasting supply and demand, which are vital for integrating renewable energy sources effectively.
Focus on Nuclear Fusion
: There is a strong narrative in the tech industry that AI can enable breakthroughs in nuclear fusion, a potential game-changer for clean energy. However, while AI has contributed to advancements in areas like plasma stability in nuclear fusion reactors, these contributions are unlikely to revolutionize energy production on their own.
Limits of AI in Scientific Progress
: The document emphasizes that real-world experimentation cannot be fully replaced by AI and machine learning. It also critiques the notion that AI can operate in a "theory-free" manner, pointing out that data and modeling in scientific research are inherently theory-laden. Major breakthroughs, especially those requiring new theoretical understandings, cannot be achieved solely through AI.
Critiques and Realism:
The document cautions against an overly optimistic view of AI���s role in scientific and technological progress, stressing that while AI can enhance certain processes, it is not a panacea. The emphasis on technology-driven solutions might overshadow simpler, potentially more effective strategies that are less resource-intensive and more immediately deployable. Moreover, the focus on high-tech solutions like AI may divert attention and resources from other critical areas of climate action that require urgent attention.
In sum, the narrative around AI and sustainability must be tempered with realism about the limitations of technology in addressing complex global issues like climate change. This calls for a balanced approach that combines technology with policy, human ingenuity, and traditional methods of environmental management to create a sustainable future.
4
AI- Oil & Gas Industry 
As the AI sector has grown, major tech companies have been providing a variety of services, as 
well as direct R&D collaborations with the oil & gas industry. The following are some highlights, 
however we discuss this in more detail including specific applications below. 
���50% of oil and gas executives have already begun to use AI in their organizations 
���92% of oil and gas companies are either currently investing in AI or plan to in the 
next two years. 
���AI in the oil and gas market was valued at US$2 billion in 2019 and expected to 
reach $4.21 billion by 2028 and $13 billion by 2034 
���As noted in the podcast, automated robotic servicing of gas pipelines is currently 
on the horizon. An AI and augmented reality-enabled crawling modular robot 
developed by Carnegie Mellon Robotics Institute has demonstrated the ability to 
map, identify and repair leaks within gas pipelines 
���Saudi Aramco has been investing the most out of any oil and gas company- 
around $3.5 billion in AI R&D, particularly for oil exploration and underwater 
operations 
���Tech corporations (including Accenture, Amazon, Google, IBM, Microsoft and Oracle) 
are competing to service rising demand for AI technologies from the fossil fuel industry; 
what has been described as ���automating the climate crisis���. 
���In 2020, Greenpeace published a report documenting how major oil corporations 
(Shell, BP, Chevron, ExxonMobil) had been contracting cloud computation 
services from tech companies 
���Though Google announced previously that they will ���not build custom AI/ML 
algorithms to facilitate upstream extraction in the oil and gas industry���, they have 
continued their partnership with Saudi Aramco since at least 2023 
���Fortune Magazine reported in 2024 that Amazon, Microsoft and Google are 
currently opening headquarter offices in Saudi Arabia 
���The GPU manufacturer NVIDIA has multiple direct partnerships for high performance 
computing (HPC) AI data centers, specialized hardware and software specifically for oil 
and gas 
���A recent collaboration between NVIDIA and Shearwater GeoServices in 2023 
achieved 10x faster performance of seismic processing software key to oil and gas exploration workflows, utilizing the GH200 Grace Hopper Superchip, 
specifically designed for AI HPC data centers 
���In 2018 NVIDIA announced a collaboration with Baker Hughes (a subsidiary of 
General Electric) to develop machine learning to ���dramatically reduce the cost, 
finding, extracting, processing and delivering oil��� 
���Orbital Sidekick, founded as part of NVIDIA���s Inception startup program, was the 
first to use hyperspectral imaging to detect gas pipeline leaks from space, 
utilizing NVIDIA���s Jetson AGX module as an AI engine which is designed for 
autonomous machines
ChatGPT
The discussion on AI's involvement in the oil and gas industry paints a complex picture of technological advancement juxtaposed with environmental concerns. Here are some key points from the document:
AI Adoption in the Oil & Gas Industry:
Widespread Adoption
: Half of the oil and gas executives report using AI within their operations. This high adoption rate reflects the significant interest and investment in AI technologies across the sector.
Investment and Market Growth
: The AI market in the oil and gas industry was valued at $2 billion in 2019, with expectations to grow to $4.21 billion by 2028 and $13 billion by 2034. This growth trajectory underscores the industry's reliance on AI for various operational enhancements.
Operational Improvements
: AI applications, such as automated robotic servicing and augmented reality-enhanced robots developed by Carnegie Mellon Robotics Institute, demonstrate significant advancements in efficiency, particularly in maintenance tasks like pipeline leak repairs.
Major Investments and Collaborations:
Saudi Aramco's Leading Role
: Saudi Aramco's $3.5 billion investment in AI for exploration and underwater operations highlights the scale of commitment to integrating AI within core operational strategies.
Tech Giants��� Involvement
: Companies like Accenture, Amazon, Google, IBM, Microsoft, and Oracle are key players in providing AI solutions to the oil and gas industry, despite public scrutiny and criticism regarding the environmental implications of such partnerships.
Controversial Partnerships and Ethical Concerns:
Public Scrutiny and Corporate Responses
: While Google has stated it would not build custom AI/ML algorithms for upstream extraction, its ongoing partnerships, such as with Saudi Aramco, suggest a complex relationship with the oil and gas sector. Similarly, the expansion of Amazon, Microsoft, and Google in Saudi Arabia indicates a deepening entanglement with fossil fuel interests.
Environmental Impact Reports
: Greenpeace's 2020 report sheds light on the involvement of tech giants in providing computational services that potentially enable further oil and gas exploration and extraction, highlighting an ethical dilemma for these companies.
Technological Innovations:
NVIDIA's Role
: NVIDIA is a pivotal technology provider, with its high-performance computing AI data centers and specialized hardware like the GH200 Grace Hopper Superchip enhancing seismic processing software. This not only improves exploration efficiency but also reduces operational costs.
Innovative Applications
: Startups like Orbital Sidekick, emerging from NVIDIA's Inception program, utilize hyperspectral imaging and AI to detect pipeline leaks from space, showcasing the potential for AI to contribute to environmental monitoring despite its primary use in enhancing extraction and processing efficiencies.
Conclusion:
The involvement of AI in the oil and gas industry is a double-edged sword. While it brings significant efficiency improvements and cost reductions, it also raises ethical and environmental concerns about accelerating fossil fuel extraction at a time when the global consensus is shifting towards sustainable energy solutions. This scenario underscores the need for a balanced approach in evaluating the benefits of AI against its potential to exacerbate climate issues, urging stakeholders to consider long-term environmental impacts over short-term gains.
4
AI- Military defense & Intelligence 
A major source of investment for AI development is currently from the defense and Intelligence 
sector. Though on the surface it may seem that AI applications for climate and the environment 
are distinctly separate to the military and intelligence sector, ultimately the current risk is that 
tech companies pushing for ���green AI��� are (knowingly or inadvertently) simultaneously pushing 
forward the same technological capacity for uses in war and surveillance. Notably, some AI 
accelerationists frame their arguments explicitly in terms of a geopolitical AGI arms race 
between China and the US for military dominance. 
Moreover, some of the technical hardware capacities useful in climate and environmental 
applications (e.g. whole Earth surface satellite monitoring) have clear dual use cases for military 
and intelligence surveillance purposes. 
Notable recent funding statistics: 
���The U.S. Defense Advanced Research Projects Agency (DARPA) recently funded a $78 
million program for new types of AI chips in battlefield conditions, with the dual goal of 
optimizing on energy and size. 
���Recent budget requests from DARPA have also indicated massive increases in 
funding for AI projects including autonomous systems and human machine teams 
���The Brookings Institution recently found that AI-related federal U.S. contracts have 
increased 1,200% from $355 million in 2022, to $4.6 billion in 2023. 
Recent examples of AI use in military and battlefield applications: 
���Precision targeting: AI is currently in use by the Israel defense Force (IDF) for a target 
creation platform known as Habsora (the Gospel) to rapidly generate recommendations 
for bombing targets based on suspected militants. Investigative reporting by Israeli 
magazines have also described an AI program (���Lavender���) which examines data 
including social network connections and family relationships to identify possible Hamas 
fighters. 
���Drones: Substantial developments have been made in autonomous drones utilizing 
various AI-enabled systems (computer vision, autonomous decision making, swarm algorithms) over the past few years. These include mass produced, autonomous drones 
in the Ukraine conflict, ���slaughterbots��� which could be used by Cartels, and so-called 
drone ���killwebs��� 
���Comprehensive battle planning: Artificial intelligence systems can now convincingly 
simulate human behavior in military simulations, U.S. DARPA has partnered with 
Northrop Grumman to apply AI in novel strategic game scenarios, and Palantir AIP has 
recently unveiled an LLM platform for defense and military planning as an AI decision 
support system. 
���Intelligence planning: AI algorithms are uniquely well equipped to make use of 
extremely large data sets, leading to a proliferation in use cases across the intelligence 
sector. Currently, about 56 out of 176 countries use AI for surveillance. Emerging 
applications from ongoing research include ���negative mental state monitoring��� and 
containing the spread of rumors in social networks.
ChatGPT
The document highlights the significant and growing involvement of AI in the military and intelligence sectors, emphasizing both the advancements and the ethical dilemmas posed by dual-use technologies that serve both civilian and military purposes. Here are the key points:
Investment and Development in Military AI:
Significant Funding
: The U.S. Defense Advanced Research Projects Agency (DARPA) has allocated substantial funds towards AI development for military applications, including $78 million for AI chips designed for battlefield conditions. This funding aims to optimize technology for energy efficiency and compact size, suitable for combat scenarios.
Rapid Growth in Contracts
: AI-related federal U.S. contracts have seen an exponential increase, with spending rising 1,200% from $355 million in 2022 to $4.6 billion in 2023. This indicates a major surge in the military's commitment to integrating AI technologies.
Applications of AI in Military Operations:
Precision Targeting
: The Israel Defense Force (IDF) utilizes AI for precision targeting, employing platforms like Habsora to generate rapid recommendations for bombing targets based on data analysis. This includes identifying individuals based on social connections and other personal data.
Autonomous Drones
: There have been significant advancements in autonomous drones, which employ AI for navigation, target identification, and operational tactics. These drones are used in various conflict zones and by different actors, demonstrating the wide-ranging applications and potential risks of such technologies.
Strategic and Comprehensive Planning
: AI systems are increasingly used in strategic military planning, including simulations that mimic human behavior in conflict scenarios. Companies like Northrop Grumman and Palantir are key players in providing AI-driven solutions for military strategy and intelligence operations.
Intelligence and Surveillance
: AI's capability to handle large datasets makes it highly effective for surveillance and intelligence tasks. Approximately 56 countries now use AI to enhance their surveillance capabilities, with applications ranging from monitoring mental states to controlling information spread on social networks.
Dual-Use Dilemmas:
The integration of AI in military contexts raises critical ethical issues, particularly concerning dual-use technologies that can be applied in both civilian and military settings. For example, satellite monitoring technologies designed for environmental tracking can also be utilized for surveillance and intelligence gathering by military forces. This overlap underscores the complex interplay between advancing technology for societal benefits while mitigating risks of misuse or escalation in military contexts.
Overall, the growing role of AI in defense and intelligence sectors necessitates careful consideration of both its potential benefits and its broader implications for global security and ethical governance.
4
Ubiquitous Surveillance 
Ubiquitous technological surveillance (UTS) is radically increasing, with extremely strong 
interlinkages with current and proposed uses of AI for climate and environmental problems, and 
risks for the rise of ���eco-surveillance��� states 
���Internet of Things (IoT), smart homes and smart cities are enabling both automated 
surveillance systems to track citizens through cameras, microphones, traffic and public 
transport monitoring, consumer purchases (etc.), as well as ostensibly reducing 
environmental footprints 
���Even existing universal tech such as WiFi signals can be utilized via AI to identify 
people in a building, similar to radar 
���Smart cities which aim to utilize IoT and ���smart��� sensor tech to optimize and 
solve various urban problems from traffic and waste management to energy 
efficiency of lighting and heating systems have been argued to pave the way to 
enabling the rise of ���digital authoritarianism���, as systems capable of monitoring, 
controlling and autonomizing urban services can be used for both environmental 
ends as well as mass surveillance, control and suppression. 
���Satellite networks which are now close to the level of real-time monitoring of every 
square meter6of the Earth���s surface enable both unprecedented capacity for 
planetary-scale computation with positive environmental and climate use cases (e.g. 
mapping illegal deforestation, tropical forest health, early warning of ecological tipping 
points, identifying dirty polluters), as well as uses for the military and defense sector (e.g. 
���To take one example, Planet Labs which markets itself primarily as satellite 
imaging for environmental, agricultural and urban Earth insights (with their latest 
6 Very high resolution satellite imagery is now reaching ever finer scales, down to 30-60cm ground 
resolution 
Last Updated July 2024 
platform utilizing various AI-based models), also has direct partnerships with the 
U.S. Department of Defense and Intelligence Community. 
���Satellite remote sensing capabilities are continuously improving. The company 
ICEYE has now developed synthetic-aperture radar (SAR) remote sensing, with 
effectively real-time earth observation capabilities for any location on the surface 
of the planet down to 50 cm resolution.
ChatGPT
The document outlines significant concerns related to the growth of ubiquitous technological surveillance (UTS) and its intersection with AI applications in climate and environmental monitoring, revealing potential pathways to "eco-surveillance" states. Here are the key issues and developments:
Integration of AI and Surveillance Technologies:
Smart Cities and IoT
: Smart cities utilize a network of IoT devices, including sensors and smart technologies, to enhance urban management, such as optimizing traffic, waste, and energy systems. While these technologies aim to reduce environmental footprints and solve urban challenges, they also raise privacy concerns due to their potential to monitor and track citizens extensively through cameras, microphones, and even WiFi signals.
Satellite Surveillance
: Advancements in satellite technology now allow nearly real-time monitoring of the Earth's surface. Companies like Planet Labs and ICEYE use high-resolution satellite imagery and synthetic-aperture radar (SAR) to observe the planet down to resolutions as fine as 50 cm. While these capabilities are beneficial for environmental monitoring (e.g., detecting illegal deforestation and monitoring ecological health), they also serve military and intelligence purposes, illustrating the dual-use nature of these technologies.
Ethical and Privacy Concerns:
Potential for Digital Authoritarianism
: The capability of smart city technologies to control and automate urban services can be leveraged not only for environmental purposes but also for mass surveillance and social control. This raises concerns about the emergence of digital authoritarianism, where state powers could misuse environmental monitoring systems for extensive public surveillance and suppression.
Dual Use of Environmental Technologies
: Satellite networks and other monitoring technologies, though pivotal for tracking environmental changes and aiding in sustainability efforts, are also employed by defense and intelligence agencies. This dual use raises ethical dilemmas about the primary purposes of these technologies and the transparency of their applications.
Data Privacy and Civil Liberties
: The extensive data collected by IoT devices and satellite monitoring systems pose significant risks to personal privacy. The potential misuse of this data by governments or other entities could lead to infringements on civil liberties, highlighting the need for robust data protection laws and ethical guidelines.
Conclusion:
The expansion of AI-enabled surveillance capabilities presents both opportunities and challenges. While they can significantly contribute to environmental conservation and climate action, there is a pressing need to address the ethical implications, particularly the risk of surveillance overreach under the guise of environmental monitoring. Balancing technological advancements with the protection of privacy and civil rights is crucial to prevent the rise of eco-surveillance states and ensure that these technologies are used responsibly and ethically.
4
AI Safety to AI Accelerationism 
AI Safety Doom Loop 
One of the ironic, though deep-seated drivers of the AI risk nexus is the tendency for any AI 
safety effort to ultimately drive further AI development and dominance. This is evidenced 
primarily by the inception of OpenAI, Anthropic, and DeepMind, which were originally AI safety 
efforts and ultimately became key players in the AI arms race. 
���AI safety efforts tend to become AI dominance efforts. Companies like OpenAI and 
Anthropic demonstrate this trend. The extensive computing resources needed for AI 
experimentation demand significant capital7. This funding typically comes from investors 
who expect a return on their investment. Consequently, the research gets steered 
towards commercially viable directions rather than focusing solely on safety concerns. 
���Over time, AI safety researchers become AI accelerationists. This shift in orientation 
occurs when researchers realize that the race to develop advanced AI is unstoppable 
due to the massive expenditure of capital and talent and the incredibly rapid pace of 
progress in AI capabilities. Winning this arms race will grant such immense power that 
only the winners will have any meaningful influence on the future. Consequently, these 
researchers conclude that accelerating AI development, rather than attempting to slow it 
down, offers the best chance to have a meaningful impact on how AI will shape 
humanity's future. 
���Increasingly, the fear of being put out of work soon by AI is increasing, as is the money 
being invested into the space currently- so people with the skills to do safety work, who 
could also do development work, see making a startup to do some basic thing that will 
get acquired by one of the big players for a big exit, as possibly their last chance for 
economic security, which is increasingly desired in the presence of such radical and 
unpredictable societal transformation.

���The fear of AI replacing jobs is increasing. This creates a dilemma for those skilled in AI 
safety and development. Many see founding an AI startup, with the goal of being 
acquired by a major company, as possibly their last chance for financial security. This 
view is fueled by the radical and unpredictable societal changes AI will bring. Nick 
Bostrom's recent work illustrates this shift in perspective. Known for raising concerns 
about AGI risks in Superintelligence (2014) Bostrom���s recent book Deep Utopia (2024) 
claims that a benevolent AI ruler may be the only solution to human coordination 
problems, reflecting a marked change in outlook on AI's role in society. 
Notably, even current LLMs such as GPT-4, Claude, BERT, LaMDA and LLaMA 2 pose 
non-negligible agential risks where a small group of people or even one person could use such 
a model to plan large-scale terrorist actions, possibly at the level of mass genocide, omnicide 
and collapsing civilization8. Alternatively, runaway artificial superintelligence (ASI) with agentic 
capacity may do so by itself. Even without much effort9, ChatGPT will answer confidently about 
various ways an ASI could destroy humanity.
ChatGPT
The discussion about the AI Safety Doom Loop presents a critical analysis of how initiatives intended to enhance AI safety can paradoxically accelerate AI development, potentially leading to dominance and heightened risks. Here are the main points outlined in the document:
Transition from AI Safety to AI Dominance:
Origins and Evolution of AI Companies
: Initially founded with a focus on AI safety, organizations like OpenAI, Anthropic, and DeepMind have evolved into major players in the AI arms race. This transformation highlights a shift from pure safety concerns to broader developmental ambitions, driven by the need for extensive computing resources and substantial capital investment.
Commercialization Over Safety
: The intense capital requirements for AI research often lead to funding from investors seeking financial returns, which can divert focus from safety to commercially viable products and solutions. This shift is a core component of the AI Safety Doom Loop, where safety efforts inadvertently fuel further AI development.
Accelerationism Among Researchers
: As researchers recognize the unstoppable pace of AI advancement and the significant resources being poured into the field, many pivot towards accelerating AI development. They see this as a necessary strategy to remain influential in shaping AI's impact on the future, given the competitive nature of the field and the immense power that advanced AI systems can wield.
Economic Pressures and Societal Changes:
Economic Insecurity and AI Development
: The increasing fear of job displacement by AI technologies creates economic pressures for those skilled in AI safety and development. Many view launching AI startups with the aim of being acquired by larger companies as a strategic move for financial security amidst rapid and unpredictable societal transformations.
Philosophical Shifts in AI's Role
: The evolving perspectives on AI's role in society are illustrated by thinkers like Nick Bostrom. While initially cautioning against the risks of artificial general intelligence (AGI) in his 2014 book "Superintelligence", Bostrom���s more recent work, "Deep Utopia" (2024), posits that a benevolent AI ruler could be a viable solution to human coordination problems, marking a significant shift in how AI's potential is perceived.
Risks of Advanced AI:
Agential Risks
: Current large language models (LLMs), including GPT-4, Claude, BERT, LaMDA, and LLaMA 2, introduce non-negligible risks where these technologies could be used for harmful purposes. The potential for AI to enable large-scale negative actions, such as terrorism or even societal collapse, is a significant concern.
Runaway AI
: The possibility of a runaway artificial superintelligence (ASI) acting independently adds another layer of risk. Such an entity could potentially undertake actions with catastrophic consequences for humanity.
Conclusion:
The AI Safety Doom Loop underscores the complex interplay between AI safety initiatives and the broader dynamics of AI development and dominance. This loop reflects the dual challenge of fostering AI technologies that contribute positively to society while managing the inherent risks and ethical dilemmas they pose. The document calls for a balanced approach that addresses these challenges through robust regulatory frameworks, transparent AI development practices, and a renewed focus on AI safety alongside technological advancements.
4
Transhumanism and TESCREAL Ideology 
Many of the technologists, entrepreneurs, and investors in the space hold ���TESCREAL��� views10 
and will even admit that they believe the replacement of biological life with digital life is both 
inevitable and desirable. As such, care for the safety of life as we know it is seen as the ignorant 
and regressive clinging to the inelegant, limited, and death-bound ���wet-ware��� biohardware we 
happen to be currently running on. 
���A particularly striking example of this is the publicly stated ultimate ambition of Neuralink, 
Elon Musk���s brain chip company which eventually aims to use these implants to ���merge 
humans with AI��� 
���Transhumanism and TESCREAL type views, common in the AI space, are 
fundamentally undergirded by computationalist and simulationism types of metaphysical 
beliefs, which view the whole world and reality itself as fundamentally computational 
���The World Transhumanist Association (H+) and the transhumanist philosophical 
project was founded by David Pearce and Nick Bostrom in the late 90s, 
advocating for technological innovation to strive towards sci-fi type 
10 Transhumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism and 
Longtermism- a mutually reinforcing set of philosophies commonly bundled together in Silicon Valley tech 
spaces, as described by Timnit Gebru and Emile Torres. For more on the views of TESCREAL ideologies 
see: 
Gebru, T. and Torres, ��.P. (2024) ���The TESCREAL bundle: Eugenics and the promise of utopia through 
artificial general intelligence���, First Monday [Preprint]. Available at: https://doi.org/10.5210/fm.v29i4.13636. 
https://www.truthdig.com/articles/the-acronym-behind-our-wildest-ai-dreams-and-nightmares/ 
9 I.e. without precise prompt engineering to ���jailbreak��� safety programming 
8 See also 
Last Updated July 2024 
advancements for the human condition including cryonics, life extension, space 
colonization, personality pills, and superintelligent artificial intelligence. 
���This has led to the commitment to a ���hedonistic imperative��� as part of the 
Abolitionist Project, which seeks to ���phasing out the biology of suffering��� 
for all sentient life via consciousness upload and/or genetically 
engineering pain receptors 
���These kinds of beliefs, combined with techno-optimist visions of human progress also 
drive a prevalence of disturbingly outlandish views held by many industry leaders and 
prominent influential thinkers in the AI and tech industry 
���Compilation of views AI experts have regarding AGI and AI alignment. ���Compilation of more outlandish AI-related views across the industry
ChatGPT
The document delves into the philosophical underpinnings and ideological positions prevalent among some segments of the tech community, particularly focusing on Transhumanism and the TESCREAL ideology. Here's an exploration of these concepts and their implications:
Transhumanism and TESCREAL Ideology
Definition and Scope
: Transhumanism is a movement that advocates for using technology to enhance human intellectual, physical, and psychological capacities. The TESCREAL acronym stands for Transhumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism, and Longtermism. These philosophies share a common thread in their futuristic and often radical vision for humanity, which includes overcoming natural biological limits and even merging biological life with digital or artificial forms.
Philosophical Beliefs
: Proponents of these ideologies often embrace computationalist and simulationist views, considering reality itself as fundamentally computational. This perspective sees technological advancement not just as a tool but as an essential pathway to evolving human existence and consciousness.
Major Advocates and Projects
:
Neuralink
: Elon Musk���s venture into brain-computer interfaces, aims to merge human cognitive capabilities with artificial intelligence, reflecting a literal interpretation of transhumanist goals.
World Transhumanist Association (H+)
: Co-founded by philosophers David Pearce and Nick Bostrom, it has historically promoted a vision of technology-driven evolution that could lead to scenarios like cryonics, life extension, and even space colonization.
The Abolitionist Project
: This initiative seeks to eradicate suffering by manipulating biological processes (e.g., through genetically engineered pain receptors) or by uploading consciousness to non-biological substrates, aiming for a future where pain and suffering are obsolete.
Implications and Critiques
Techno-Optimism vs. Ethical Concerns
: The radical optimism about technology's role in human progress often clashes with profound ethical, social, and philosophical questions. Critics argue that such views might underestimate the complexities of biological life and the potential negative consequences of altering human nature fundamentally.
Impact on AI Development
: These ideologies influence how AI is developed and integrated into society. For example, the pursuit of artificial general intelligence (AGI) is often driven by a belief in its potential to solve all human problems, which could lead to overlooking potential risks and societal impacts.
Cultural and Social Influence
: The prevalence of these ideologies in Silicon Valley and among tech elites shapes not only technological development but also cultural narratives about the future of humanity. This influence can affect public policy and societal expectations regarding technology and progress.
Criticism from Within the Tech Community
: Figures like Timnit Gebru and Emile Torres have critiqued the TESCREAL bundle for its potential links to modern forms of eugenics and utopianism, warning against the uncritical adoption of these ideologies without considering their broader implications.
Conclusion
The interplay between AI, transhumanism, and TESCREAL ideologies highlights a tension between ambitious technological aspirations and the practical, ethical considerations these technologies engender. As AI continues to advance, it is crucial to engage in ongoing dialogue about the values guiding these developments and the kind of future they are likely to bring about. This will ensure that the evolution of AI and its integration into human life remains aligned with broadly beneficial and ethically sound principles.
4
Direct Energy and Material Uses 
Within the concentric circles of how AI can and may potentially impact climate and the 
environment, at the center are direct energy and material demands from hardware itself, 
particularly server farms. 
Key Highlights 
���Globally, the digital tech sector consumes about 10% of the world���s electricity 
consumption, has a carbon footprint about 2x-3x that of the UK or France, accounts for 
4% of global GHG emissions and consumes about 5-7% more electricity every year11. 
���One estimate suggests that global electricity demand from digital technology 
could grow to 20% of global demand by 2025. The IEA projects that electricity 
consumption from AI, data centers and cryptocurrency could double by 2026 
11 Stats from Pitron, G. (2023) The dark cloud: how the digital world is costing the Earth. Brunswick, 
Victoria: Scribe Publications. 
Last Updated July 2024 
���Growth of the digital tech sector and particularly AI is currently largely limited by 
energy demand 
���Data center energy demand in 2022 was 17GW from 2,700 data centers, and is 
projected to reach 32GW by 2029. 
���IEA projections suggest global consumption of electricity for data centers may 
grow from 460 TWh in 2022 to more than 1000 TWh in 2026, though this is quite 
possibly an underestimate12 
���Data centers in particular account for 2% of global electricity demand. 
���Google���s data centers used 20 percent more water in 2022 than in 2021, while 
Microsoft���s water use rose by 34 percent. 
���Power demand projections for power grids in the US (second source) and 
internationally have doubled their annual expected growth rate over the five to 
ten year timeframe as of 2023
���Energy use of ChatGPT 
������It���s been estimated that ChatGPT is responding to something like two hundred 
million requests per day, and, in so doing, is consuming more than half a million 
kilowatt-hours of electricity.��� (For comparison���s sake, the average U.S. household 
consumes twenty-nine kilowatt-hours a day.) (Elizabeth Kolbert, The Obscene 
Energy Demands of AI) 
���Existing machine learning applications have already seen demonstrable Jevons-like 
dynamics play out. 
���The use of AI and machine learning assisted translation services did reduce 
costs in translation services by 40%, but the Bureau of Labor Statistics found an 
uptick of 19% in translation and interpreter services in 2021. 
���Organizational use of AI for automating quantified risk policy workflow led to 
significant increases in revenue per worker (up to 38%), leading the business to 
hiring more workers
ChatGPT
The document details the substantial energy and material demands of the AI and broader digital technology sectors, highlighting the significant environmental footprint associated with these technologies. Here are the key points discussed:
Energy Consumption and Environmental Impact:
Global Energy Demand
: The digital tech sector, which includes data centers, AI, and cryptocurrency operations, consumes about 10% of the world���s electricity. This consumption is projected to grow substantially, potentially reaching 20% of global demand by 2025 according to some estimates. The International Energy Agency (IEA) suggests that electricity consumption for data centers alone could double by 2026.
Carbon Footprint
: The sector���s carbon footprint is considerable, estimated to be 2-3 times that of countries like the UK or France, and contributes about 4% of global greenhouse gas (GHG) emissions.
Data Center Growth
: The number of data centers and their energy demand is rapidly increasing. From consuming 17GW in 2022, data center energy demand is projected to reach 32GW by 2029, with their electricity consumption possibly exceeding 1000 TWh by 2026.
Water Usage
: The water consumption of data centers is also escalating, with Google and Microsoft reporting significant increases in water usage, crucial for cooling systems in these facilities.
AI-Specific Energy Usage:
ChatGPT���s Energy Consumption
: ChatGPT, as an example of a widely used AI application, reportedly handles around two hundred million requests per day, consuming over half a million kilowatt-hours of electricity daily. This is vastly greater than the daily energy consumption of the average U.S. household.
Economic and Environmental Rebound Effects:
Jevons Paradox in AI
: The use of AI in various sectors has led to increased efficiency and lower costs, but also to increased overall consumption���a phenomenon known as the Jevons Paradox. For example, AI-driven enhancements in translation services reduced costs but led to an increase in demand for these services, ultimately resulting in higher overall consumption of resources.
Impact on Employment and Productivity
: While AI has automated certain tasks, leading to productivity gains, these improvements have also resulted in increased hiring in some sectors as companies expand due to greater efficiencies and revenue.
Conclusion:
The expanding footprint of AI and digital technologies poses significant challenges for sustainability efforts. While these technologies offer remarkable capabilities and efficiencies, their environmental impact���through direct energy consumption, carbon emissions, and water usage���necessitates careful management and innovative solutions to mitigate their adverse effects. This includes developing more energy-efficient computing technologies, optimizing AI applications to reduce unnecessary energy consumption, and integrating renewable energy sources into data center operations. The document underscores the need for a balanced approach that considers both the benefits and environmental costs of rapidly advancing digital and AI technologies.
4
Direct Energy and Material Demands 
Booming demand for AI computational capacity has led to a recent surge in demand for 
necessary infrastructure in the form of data centers, which necessarily have intrinsically high 
electricity, water and material requirements. These issues haven���t escaped the attention of news 
outlets and analysts, the following are a few select examples:

No consensus exists on either usage figure yet: ���Right now, it���s not possible to tell how your AI 
request for homework help or a picture of an astronaut riding a horse will affect carbon 
emissions or freshwater stocks [���] the same is true of carbon.��� 
As Use of A.I. Soars, So Does the Energy and Water It Requires (E360 Yale, 2024) 
Using the training of BERT as a reference experiment, ���There is large variation between the 
least carbon-intensive regions [...] choosing the region in which experiments run can be very 
impactful (7k grams vs. 26k grams [of CO2], for the most efficient vs. least efficient regions).��� 
Measuring the Carbon Intensity of AI in Cloud Instances (Dodge et al. 2022) 
Compute applied to AI has a doubling time of 3.4 months. 
AI and Compute (OpenAI) 
���...at present, the emissions from LLMs are relatively insignificant compared to both their 
popularity and to other everyday activities.��� 
An analysis of both hardware production and energy usage (Smith et al. 2023) 
Though energy, water and material consumption concerns apply broadly to digital technologies 
and cloud computing broadly, artificial intelligence in particular poses a distinct concern due to 
the scale and intensity of computation involved, as well as more particular hardware 
requirements- notably graphics processing units (GPUs). 
Though the majority of attention has thus far been on direct electrical energy consumption and 
CO2emissions, far less has been focused on material footprints of AI data centers. Material 
demands includes concrete, steel, glass and aluminum for basic infrastructure of data center 
structures themselves, as well as various metals used in semiconductors and chip 
manufacturing, notably precious metals including gold, silver and palladium; basic metals such 
as copper and iron; rare earths such as dysprosium, neodymium and yttrium; and critical raw 
metals such as indium, titanium and gallium13. 
From our rough estimate14, about 965 thousand metric tons of mining rock waste was 
produced just for the GPUs (about 10,000 NVIDIA A100s) used in OpenAI���s custom-built 
supercomputer to train GPT-3. This is mostly due to just three elements���indium, gold, 
dysprosium, and copper���and would plausibly be another magnitude greater if all other 
components (motherboards, CPUs, network cables, etc.) were included.
ChatGPT
The document discusses the significant resource demands���specifically energy, water, and materials���associated with the infrastructure required to support AI technologies, particularly data centers. Here���s an analysis of these concerns:
Key Concerns Highlighted:
Energy Consumption
:
AI computational demands are exponentially growing, contributing to a sharp increase in energy usage. This consumption is significantly impacted by the location of data centers due to regional variations in carbon intensity. For example, emissions can vary drastically depending on whether a data center is powered by renewable energy or fossil fuels.
Water Usage
:
AI operations, especially in data centers, require substantial amounts of water primarily for cooling purposes. The rising demand for AI services increases the strain on water resources, which is particularly concerning in regions facing water scarcity.
Material Use and Environmental Impact
:
The construction and operation of data centers necessitate large quantities of materials such as concrete, steel, glass, and aluminum. Additionally, the production of AI-specific hardware like GPUs involves various metals and rare earth elements, which have significant environmental impacts. For instance, the mining of metals like indium, gold, dysprosium, and copper results in substantial rock waste and ecological disruption.
Additional Insights from Selected Examples:
Carbon and Water Footprint Uncertainty
:
There is currently no clear consensus on the specific impact of individual AI operations on carbon emissions and water usage, complicating efforts to quantify and mitigate these effects.
Impact of AI on Carbon Intensity
:
Research indicates that the choice of location for running AI experiments can have a significant impact on their carbon footprint, suggesting that strategic siting of data centers could reduce overall emissions.
Rapid Growth of AI Compute
:
The computational capacity required for AI is doubling approximately every 3.4 months, underscoring the intense and growing demand for resources to support AI development and deployment.
Relative Emissions from LLMs
:
While the emissions from large language models (LLMs) are currently considered insignificant relative to their popularity and compared to other everyday activities, this perspective could change as AI usage expands and as more comprehensive data becomes available.
Material Footprint:
The focus has primarily been on the energy consumption of AI, but the material demands, particularly for high-performance hardware like GPUs, are also critical. These demands include not just the materials used directly in hardware but also the broader infrastructure of data centers.
Conclusion:
The substantial resource demands associated with AI highlight the need for sustainable practices in the design, location, and operation of data centers. It also calls for advances in technology that reduce the environmental footprint of AI hardware production and operation. This includes improving energy efficiency, using renewable energy sources, developing more sustainable cooling technologies, and reducing material waste through recycling and better material science. These steps are crucial to aligning AI development with global sustainability goals and reducing its environmental impact.
4
A list of all of the topics we've discussed.
ChatGPT
Here's a summary of the topics we've covered in our discussion:
AI and Climate Change
: We explored how AI intersects with climate change, focusing on its applications in accelerating extractive industries, contributing to defense industry activities, and embodying transhumanist accelerationism ideals.
AI Industry Trends, Rhetoric, and Risks
: We discussed the rise of climate solutionist rhetoric in the AI industry, the reality of AI's environmental impacts, and the prevalent marketing strategies that promote AI as a sustainable solution.
AI in the Oil and Gas Industry
: We examined how AI is being increasingly used in the oil and gas sectors, highlighting the investments and technological developments driven by major tech companies and the implications for environmental strategies.
AI in Military Defense and Intelligence
: We looked at how AI is being employed in the defense and intelligence sectors, noting the ethical and practical implications of such uses, particularly regarding surveillance and autonomous weaponry.
Ubiquitous Technological Surveillance
: We delved into the rise of ubiquitous surveillance enabled by AI and IoT technologies, discussing the potential for digital authoritarianism and the dual use of these technologies in both civilian and military contexts.
AI Safety to AI Accelerationism
: We touched on the ironic trend where efforts to ensure AI safety inadvertently contribute to accelerated AI development, leading to greater dominance of AI technologies in various sectors.
Transhumanism and TESCREAL Ideology
: We discussed the influence of transhumanist and TESCREAL ideologies within the tech community, particularly their impact on shaping AI development and societal expectations.
Direct Energy and Material Uses of AI
: Finally, we reviewed the direct energy, water, and material demands of AI, focusing on the infrastructure required for data centers and the broader environmental implications of these requirements.
Each topic connects to broader discussions about the implications of AI on society, the environment, and global technological trends.
4
A very short narrative summary in Latin
ChatGPT
In nostra disputatione, varia de Artificiali Intelligentia (AI) themata tractavimus, praesertim quomodo ad mutationes climaticas et industrias extractivas acceleret. De usu AI in industriis olei et gasis, necnon defensionis et intelligentiae militaribus, locuti sumus. Inspectavimus etiam quomodo AI ad vigilantiam ubiquam et surveillantiam technologicam conferat, atque de ironia quod conatus securitatis AI ad celerationem eiusdem technologiae ducant. Demum, de influentiis ideologiarum transhumanismi et TESCREAL in communitatem technicam, et de directis impendiis energiae et materiae pro AI disseruimus. Haec omnia magnam vim habent non solum in technologiam sed etiam in societatem globalem et mores environmentalis.
4
ChatGPT puede cometer errores. Comprueba la informaci��n importante.
?
ChatGPT

