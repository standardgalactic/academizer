
Introduction to LojbanOpen sidebarIntroduction to LojbanModel: Default (GPT-3.5).zoi cy. pemci .cy cmalu sampu se ciksi lo nu jai gau bredi fi lo se lifri be lo nu pensi .i se va'u lo pemci cu se kuspe lo nu finti lo remna .i se va'u lo pemci cu se rarna ciksi lo nu fanva zo'e lo se saske .i lo se cinri be lo se zgike cu se vlipa'a lo se pinxe be lo nu jmive .i lo se rarna ciksi be lo pemci cu se gau terpa lo jukni .i lo se terpa be lo jukni cu se jinvi lo nu cipni .i lo nu jinvi lo ka simlu lo nu tcika cu se binxo lo nu ranji .i lo se pluka be lo se saske cu se gau lanli lo se cfila be lo nu tadni .i lo se pluka be lo nu tadni cu se gau djica lo nu tadni lo filsofi'a .i lo se pluka be lo nu tadni cu se gau tcidu lo se ciska be lo Deleuze .i lo se pluka be lo nu tadni cu se gau tadni lo se cinse be lo nu pensi .i lo se pluka be lo nu tadni cu se gau zgana lo se cfila be lo nu tadni .i lo se pluka be lo nu tadni cu se gau zgana lo se nu zgana be lo nu zgana

Translation: Poetry is a simple explanation for preparing for experiences of thinking. Poetry spans the creation of human writing. In relation to poetry, it naturally explains the translation of something into science. The interest in music strongly affects drinking life. The natural explanation of poetry causes fear of spiders. Fear of spiders is considered to be bird-like. Considering the appearance of time becomes enduring. The pleasure of science studies the flaws of study. The pleasure of studying wants to study philosophy. The pleasure of studying reads the writing of Deleuze. The pleasure of studying studies the sex of thinking. The pleasure of studying observes the flaws of studying. The pleasure of studying observes the observation of observing.1 / 1ChatGPTChatGPTYour text was in Lojban, a constructed language known for its logical structure. The translation appears to express various metaphors and perspectives related to poetry, science, studying, and their impact on human thought and experiences. It also references Gilles Deleuze, a French philosopher known for his work on philosophy, literature, film, and fine art.1 / 1Translate Pluka be lo nu tadni.1 / 1ChatGPTChatGPTThe Lojban phrase "pluka be lo nu tadni" translates to English as "pleasure of studying" or "the pleasure that comes from studying". In Lojban, "be" is a short form of "bei", which is used to express the object of a verb. Here "pluka" means "pleasure", "be" links "pluka" to "lo nu tadni" (the act of studying), and "lo nu" is a construct that nominalizes the following verb phrase, in this case "tadni" (to study).1 / 1Translate to Lojban: Introduction to Lojban1 / 1ChatGPTChatGPTThe translation of "Introduction to Lojban" in Lojban would be "cnino te tadni be la lojban." Here's how:"cnino" means "new" or "introduction""te tadni" refers to the act of studying or learning about something"la lojban." is the name of the language itself, "Lojban" in the Lojban language.Together, the phrase means "Introduction to the study of Lojban".1 / 1Give a glossary of words used in the introduction.1 / 1ChatGPTChatGPTSure, here is a glossary of the words used in the Lojban phrase "cnino te tadni be la lojban":cnino: This word means "new". In the context of this phrase, it is used to imply an "introduction" or a "new" exposure to the subject, which is Lojban in this case.te: It is a preposition which alters the place structure of a verb in Lojban. It is used to switch the 3rd and 2nd arguments of a verb.tadni: This word means "study" or "learn".be: It is a preposition that links a noun or pronoun (in this case "la lojban") to a place in the place structure of a verb (in this case "te tadni").la lojban: This is the name of the language itself, "Lojban". The "la" indicates a proper noun following it.Together, the phrase "cnino te tadni be la lojban" translates to "Introduction to the study of Lojban".1 / 1And .zoi cy. pemci .cy cmalu sampu se ciksi lo nu jai gau bredi fi lo se lifri be lo nu pensi .i se va'u lo pemci cu se kuspe lo nu finti lo remna .i se va'u lo pemci cu se rarna ciksi lo nu fanva zo'e lo se saske .i lo se cinri be lo se zgike cu se vlipa'a lo se pinxe be lo nu jmive .i lo se rarna ciksi be lo pemci cu se gau terpa lo jukni .i lo se terpa be lo jukni cu se jinvi lo nu cipni .i lo nu jinvi lo ka simlu lo nu tcika cu se binxo lo nu ranji .i lo se pluka be lo se saske cu se gau lanli lo se cfila be lo nu tadni .i lo se pluka be lo nu tadni cu se gau djica lo nu tadni lo filsofi'a .i lo se pluka be lo nu tadni cu se gau tcidu lo se ciska be lo Deleuze .i lo se pluka be lo nu tadni cu se gau tadni lo se cinse be lo nu pensi .i lo se pluka be lo nu tadni cu se gau zgana lo se cfila be lo nu tadni .i lo se pluka be lo nu tadni cu se gau zgana lo se nu zgana be lo nu zgana?1 / 1ChatGPTChatGPTThis is a rather large and complex sentence, so let's break it down:.zoi cy. pemci .cy: "pemci" is Lojban for "poetry". The ".zoi cy. .cy" construct is used to quote words from another language without translation.cmalu: "small" or "little".sampu: "simple".se ciksi: "explained by".lo nu: a construct that nominalizes the following verb phrase.jai gau bredi fi lo se lifri be lo nu pensi: translates roughly as "preparing for experiences of thinking".se va'u lo pemci: in relation to poetry.se kuspe: spans, extends over.lo nu finti lo remna: the creation of human (remna) writing (finti).se rarna ciksi: naturally explains.lo nu fanva zo'e lo se saske: the translation of something into science.lo se cinri be lo se zgike: the interest in music.se vlipa'a: strongly affects.lo se pinxe be lo nu jmive: drinking life.se gau terpa: causes fear.lo jukni: spiders.se jinvi: is considered.lo nu cipni: bird-like.lo nu jinvi lo ka simlu lo nu tcika: considering the appearance of time.se binxo: becomes.lo nu ranji: enduring.lo se pluka be lo se saske: the pleasure of science.se gau lanli lo se cfila be lo nu tadni: studies the flaws of study.se gau djica: wants.lo nu tadni lo filsofi'a: to study philosophy.se gau tcidu: reads.lo se ciska be lo Deleuze: the writing of Deleuze.se gau tadni: studies.lo se cinse be lo nu pensi: the sex of thinking.se gau zgana: observes.lo se cfila be lo nu tadni: the flaws of studying.lo se nu zgana be lo nu zgana: the observation of observing.Please note that this is a rough glossary and doesn't capture some of the nuances of the sentence, but it should give you a general understanding of the words used.1 / 1Give a line by line interlinear translation.1 / 1ChatGPTChatGPTAbsolutely, I'll break it down line by line..zoi cy. pemci .cy cmalu sampu se ciksi lo nu jai gau bredi fi lo se lifri be lo nu pensi.zoi cy. pemci .cy: Literal quote "pemci" (Poetry)cmalu: smallsampu: simplese ciksi: is explained bylo nu: the event ofjai gau bredi fi lo se lifri be lo nu pensi: preparing for experiences of thinking--> "Poetry is a small simple explanation for preparing for the experiences of thinking".i se va'u lo pemci cu se kuspe lo nu finti lo remna.i: Andse va'u lo pemci: In relation to poetrycu: separates the subject from the predicatese kuspe: extends overlo nu finti lo remna: the creation of human beings--> "And, in relation to poetry, it extends over the creation of humans".i se va'u lo pemci cu se rarna ciksi lo nu fanva zo'e lo se saske.i: Andse va'u lo pemci: In relation to poetrycu: separates the subject from the predicatese rarna ciksi: naturally explainslo nu fanva zo'e lo se saske: the translation of something into science--> "And, in relation to poetry, it naturally explains the translation of something into science"I've done the first three lines to give you an idea of how this works. Given the length of the text, a full line by line translation may be quite extensive. Let me know if you'd like me to continue with the rest of the lines.1 / 1ðð¦ ð¤ð°ð¶ð­ð¥ ð´ð°ð­ð·ð¦ ð®ð°ð´ðµ ðð ð´ð¢ð§ð¦ðµðº ð¢ð¯ð¥ ð´ð°ð¤ðªð¢ð­ ðªð®ð±ð¢ð¤ðµ ð±ð³ð°ð£ð­ð¦ð®ð´ ð§ð°ð³ ðµð©ð¦ ð¤ð¶ð³ð³ð¦ð¯ðµ ð¨ð¦ð¯ð¦ð³ð¢ðµðªð°ð¯ ð°ð§ ð¨ð¦ð¯ð¦ð³ð¢ðµðªð·ð¦ ðð ðªð§ ð¸ð¦ ð³ð¦ð´ðµð³ðªð¤ðµð¦ð¥ ðªð¯ð±ð¶ðµð´ ð¢ð¯ð¥ ðµð¦ð¹ðµð¶ð¢ð­ ð°ð¶ðµð±ð¶ðµð´ ðµð° ðð¢ðµðªð¯. 

â ðð°ð´ð¤ð©ð¢ ðð¢ð¤ð©1 / 1ChatGPTChatGPTJoscha Bach's statement here is suggesting a potential solution for many AI safety and societal impact problems related to generative AI. He proposes that if we limited both the inputs and outputs of these AI models to the Latin language, we could significantly mitigate these issues.This suggestion likely stems from a few considerations:Accessibility: Latin is a "dead" language, meaning it's not evolving anymore and is not used as a first language by any community. The number of people fluent in Latin is relatively small, and it's mostly studied acadically or by language enthusiasts.Precision and Context: Latin is known for its precision and lack of ambiguity compared to many living languages, which could potentially reduce misinterpretations by AI.Safety: Limiting the language of AI might create a "speed bump" for misuse, as anyone wishing to use or misuse AI would need knowledge of Latin, raising the barrier to entry.However, this also means the beneficial uses of AI would be less accessible to the general public. For instance, translation services, tutoring in various subjects, providing medical advice, or even simply answering questions (like I'm doing now), would be limited to those proficient in Latin.Furthermore, while the precision of Latin could be beneficial in some respects, it could also be a disadvantage. Part of the strength of AI like GPT-3 lies in its ability to understand and generate text in a wide variety of languages and contexts. Limiting it to Latin could significantly reduce its versatility and usefulness.Please note that the statement doesn't necessarily suggest a full solution to AI safety and societal impact problems but rather presents an interesting thought experiment. Many aspects of AI safety and societal impact go beyond just the language used for interaction.1 / 1And what was the rational behind the languages lojban loglan interlingua and the like1 / 1ChatGPTChatGPTConstructed languages like Lojban, Loglan, Interlingua, and others were each created with different goals and rationales in mind:Lojban: Lojban was developed by the Logical Language Group with the aim of creating a language that is highly logical and expressive. The structure of Lojban is designed to reflect the principles of predicate logic, making it easier to express complex logical ideas clearly and unambiguously. Moreover, the creators of Lojban also aimed to make a language that would be culturally neutral and easy to learn, reducing the influence of any one particular natural language or culture.Loglan: Loglan is a predecessor of Lojban and was developed by Dr. James Cooke Brown with similar aims of creating a language that is logical and clear. Brown also hoped that Loglan could be used for linguistic research, particularly for testing the Sapir-Whorf hypothesis, which posits that the language one speaks can influence the way one thinks.Interlingua: Interlingua was developed by the International Auxiliary Language Association (IALA) with a different goal. Interlingua is designed to be an international auxiliary language that is easy to learn, particularly for speakers of Romance languages. Rather than emphasizing logical structure like Lojban or Loglan, Interlingua was designed to include words and grammatical structures that are common to many European languages, making it easier for speakers of those languages to understand.These constructed languages were all developed with the idea that language can be designed intentionally to serve specific purposes, whether that be logical clarity, ease of learning, cultural neutrality, or usefulness as a tool for linguistic research. Each language reflects a different set of priorities and goals for what a language can and should be.1 / 1Translate to English: La .lojban. no'u lo jbobau cu runbau .i ly. se finti la .lojbangirz. lo za'i zasti fa su'o bangu poi se jicmu lo logji gi'e zifre selcpa gi'e se pilno ku'o de'i li 1987 .i lo na'e ralju te finti cu nu cipra lo ka lo nu pilno ce'u cu galfi lo tadji be lo nu pensi

citri
la .lojban. se lidne la .loglan. noi no'e mulno se finti fo lo sidbo be fi la .djeims.kuk.braun. fi lo nu cipra fi lo se skesmadi be la .sapir. jo'u la .uorf.

ni'o de'i li 1987 so'o goi gy gunka be tu'a la .loglan. cu fendi lo girzu fo la .loglan. ki'u lo za'i dy ky by finca'i lo bangu gi'e djica lo nu dukse be fi ku jitro lo selci'a be bau .i gy. ganzu fi la .lojbangirz. mu'i lo nu finti lo cnino lojbau .i ba za bo la .lojban. co'a vajmau la .loglan .i la .lojban. ca ti noi nanca 2016 moi cu bangu ji'i 200 prenu1 / 1ChatGPTChatGPTLojban, also known as the "Lojban language", is a constructed language. It was developed by the Lojban language creators in 1987, aiming to exist as a language based on logic, free to learn and use. The key motivation for its creation was to test the hypothesis of whether using it would influence the user's thinking methods.History:
Lojban was preceded by Loglan, an incomplete language created based on the ideas of James Cook Brown to test the Sapir-Whorf hypothesis on the impact of language on thought.In 1987, a group (abbreviated as "gy") of Loglan workers split from the Loglan community due to disputes over excessive control over the written language by Dr. James Cook Brown. This group, led by the Lojban creators, aimed to create a new language, Lojban. Over time, Lojban became more popular than Loglan. As of 2016, Lojban is a language spoken by approximately 200 people.1 / 1It looks like it says it is known as jbobau1 / 1ChatGPTChatGPTI apologize for the confusion. You're correct. "jbobau" in Lojban directly translates to "Lojban language" in English. The term ".lojban." refers to the name of the language (Lojban), while "jbobau" is a compound word made from "jbobau" (Lojban) + "bau" (language).The phrase "la .lojban. no'u lo jbobau cu runbau" would then more directly translate to "Lojban, also known as the Lojban language, is a constructed language."So, to revise the initial translation, it should say:"Lojban, also known as the Lojban language, is a constructed language. It was developed by the Lojban language creators in 1987, aiming to exist as a language based on logic, free to learn, and use."The rest of the translation remains accurate.1 / 1Thank you. lingua'ignotas. cu se finti la xildegardis. pe la bingen. lenu mipri lei sivni selciska ku'o cale paremoi nanca bo xecto

ni'o so'o nanca xecto cu temci tu'a la lingua,ignotas. lenu so'i prenu cu co'a se bangu lei runbau .i la'edi'u cu cfari ca lenu la solresol se finti

ni'oni'o lo mupli befile'i runbau
dei cu mupli loi se ciska lo'i runbau .i di'e cu porsi filo'i runbau

bangrklingo
esperantos
galbisybau
interlingua
lojban
nalseljunbau
natpenbau
ninxinronbau
tokiponas
volapuk1 / 1ChatGPTChatGPT"Lingua Ignota" was created by Hildegard of Bingen to conceal private writings, about nine hundred years ago.It took several hundred years for the Lingua Ignota to be used as a source of inspiration for many people to start creating their own constructed languages. One such language that came into being is "Solresol."Examples of constructed languages include the following:This list is an example of writings in constructed languages. It is sorted in alphabetical order:KlingonEsperantoIdo (Galbisybau)InterlinguaLojbanNa'vi (Nalseljunbau)Natural languages (Natpenbau)Newspeak (Ninxinronbau)Toki PonaVolapÃ¼k1 / 1slaka midju cu ka'e re mei karsna .i lo relkarsna cu re mei lo karsna poi se gunma lo pa mei slaka

lojbo relkarsna
ai	au	ei	oi
zunsna
lojbo
zunsna
terle'u	bacru selklo
ctebi
moldruti'e	relctebi	tebde'i	dengenja	dengejyti'e	moldru	moldruti'e	galxe
bacru
tadji
nazbi		m		n				
spoja		p b		t d			k g	.
mosra			f v	s z	c j		x	'
jbibi'o	u					i		
pencu				r				
mlana jbibi'o				l				
slaka
slakykra zunsnapoi	ts dz
tc dj
sm zm
cm jm	sn --
cn --	sp zb
cp jb	sf zv
cf jv	st zd
ct jd	sk zg
ck jg	--
--
mr
ml	--
--	pr br
pl bl	fr vr
fl vl	tr dr
-- --	kr gr
kl gl	xr
xl
smr zmr
cmr jmr	-- --
-- --	spr zbr
cpr jbr	sfr zvr
cfr jvr	str zdr
ctr jdr	skr zgr
ckr jgr	--
--
sml zml
cml jml	-- --
-- --	spl zbl
cpl jbl	sfl zvl
cfl jvl	-- --
-- --	skl zgl
ckl jgl	--
--
ni'o ro slaka cu karsna slaka gi'a zunsna slaka gi'a cmevlafa'o slaka

ni'o lo karsna slaka cu se pagbu ci da .i lo slakykra noi pa moi pagbu cu pa mei zunsna (to lo galxe spoja zunsna cu jai cumki toi) gi'a me pa lo selcurmi ke slakykra zunsnapoi .i lo slakymidju noi re moi pagbu cu pa mei karsna gi'a pa mei relkarsna .i lo slakyfa'o noi ci moi pagbu cu pa mei zunsna gi'a kunti

ni'o lo zunsna slaka cu na vasru lo karsna gi'e se pagbu re da .i lo pa moi pagbu cu pa mei zunsna .i lo re moi pagbu cu pa mei karsnasmi zunsna

karsnasmi zunsna
l	m	n	r
ni'o lo cmevlafa'o slaka cu se steci lo ka lo slakyfa'o cu porsi lo zunsna jo'u lo galxe spoja zunsna1 / 1ChatGPTChatGPTA syllable nucleus can be a diphthong. A diphthong consists of two vowel sounds that are pronounced within the same syllable.Lojban diphthongs:
ai au ei oiConsonants:
In Lojban, consonants are categorized as voiced and unvoiced pairs.voiced/unvoiced
bilabial p b
dental t d
velar k g
glottal .Lojban Vowels:
u iAlveolar:
rLateral alveolar:
lIn each syllable:
The syllable onset contains one consonant that can either be voiced or unvoiced. The syllable nucleus consists of a monophthong or diphthong. The syllable coda contains one consonant.Every syllable contains a syllable nucleus, and may also contain a syllable onset or a syllable coda.The syllable nucleus consists of three parts. The syllable onset (first part) consists of one consonant sound (the possible consonant sounds include voiced velar consonant sounds). The syllable nucleus (second part) consists of one vowel sound or one diphthong. The syllable coda (third part) consists of one consonant sound and is empty.The syllable onset does not contain vowel sounds and consists of two parts. The first part consists of one consonant sound. The second part consists of one vowel-consonant sound.Vowel-Consonant sounds:
l m n rThe syllable coda is specific in that it orders the consonants and voiced velar consonant sounds.1 / 1lo jufra ka'e vasru lo li'erpau noi lidne lo bridi gi'e vasru lo sumti .e nai lo selbri .i zo zo'u cu te sepli lo li'erpau lo bridi

ni'o lo saprai selbri cu valsi pamei gi'e ga brivla gi cmavo be zo go'i .i ji'a lo brivla porsi noi tanru cu selbri .i lo smuni be lo tanru cu se jicmu lo te tanru noi ro moi pagbu be lo tanru .i lo se tanru noi lidne lo te tanru cu jai galfi lo smuni be lo te tanru .i ji'a lo mulno jufra .e lo sumti .e lo namcu ka'e binxo lo selbri .i lo cmavo be zo nu ku fa'u zo me fa'u zo moi cu jai galfi lo selyli'e ke bridi fa'u sumti fa'u namcu lo selbri .i lo cmavo be zo moi ka'e ji'a se lidne lo zo me selbri

ni'o lo saprai sumti cu valsi pamei gi'e cmavo be zo ko'a .a zo by .i ji'a lo lerfu porsi cu sampu sumti .i lo selbri poi se lidne lo gadri .a lo namcu cu sumti .i lo cmevla poi se lidne lo cmavo be zo la cu sumti .i lo cmavo be zo li cu jai galfi lo namcu lo sumti .i ji'a lo vrici ke sitna valsi cu se pilno fi lo nu zbasu lo sumti1 / 1ChatGPTChatGPTA sentence can contain an introduction clause, which leads the predicate and can contain arguments and not the predicate. "zo'u" separates the introduction clause from the predicate.The main predicate is a single-word value and is either a brivla or a go'i-type cmavo. Furthermore, the ordered brivla, known as a tanru, is also a predicate. The meaning of the tanru is based on the tanru components, where each part of the tanru contributes to the meaning. The leading part of the tanru modifies the meaning of the tanru. Also, full sentences, arguments, and numbers can become predicates. The cmavo of "nu", "me", and "moi" modify the derived predicates from sentences, arguments, and numbers to predicates. The cmavo of "moi" can also lead the "me"-type predicate.The main argument is a single-word value and is a cmavo of either "ko'a" or "by". Additionally, the ordered letters form simple arguments. The predicate that leads a quantifier or number is an argument. The cmevla that leads the cmavo of "la" is an argument. The cmavo of "li" modifies the numbers to arguments. Also, various quotation words are used to construct arguments.1 / 1ni'oni'o te finti
so'o da te finti la .lojban .i di'e mupli .i tu'e

.i cipra lo se skesmadi be la .sapir. jo'u la .uorf.
.i zmadu jimpe fi lo bangu
.i xagzengau lo nu lo prenu cu tavla lo skami
.i tutci lo nunctu
.i larcu ve finti
tu'u1 / 1ChatGPTChatGPTAdditionally, about creation,Several people created Lojban. Here is an example.It tests the hypotheses of Sapir and Whorf.
It increases understanding of languages.
It facilitates computer-human communication.
It is a tool for teaching.
It is an art of creation.1 / 1ni'o lo cmavo cu valsi lo gerna kamckini .a lo se cinmo .a lo ve djuno .iku'i lo nalma'o cu valsi lo dacti .a lo fasnu .a lo ckaji .i lo vlacku cu tcila skicu lo smuni be lo nalma'o gi'eku'i tilcau skicu lo smuni be lo cmavo .iku'i lo gerna cu tcila skicu lo cmavo gi'eku'i srana lo klesi po'o be loi nalma'o

ni'o loi cmavo cu se klesi loi sumtcita .e loi sumbasti .e loi jonma'o .e loi famyma'o .e loi cnima'o

ni'o da zo'u lo cmavo be fo da cu frica lo nalma'o be fo da lo du'u ce'u vasru makau poi voksna .imu'a no lojbo cmavo cu vasru su'ore zunsna .i no glico nalma'o cu se krasi zoi sanc. [Ã°] .sanc. i so'i bangrsanxoi zo'u lo klaktre sance cu krasi piso'a loi nalma'o .eku'i piso'u loi cmavo1 / 1ChatGPTChatGPTParticles (or "cmavo" in Lojban) are words in the grammar that act as connectors, indicators of emotion, or provide knowledge. However, non-particles are words for things, actions, or qualities. A vocabulary list provides detailed descriptions of the meanings of non-particles, but gives only brief descriptions of the meanings of particles. However, the grammar provides detailed descriptions of particles, but only relates to the classes of non-particles.Classes of particles include sumtcita (case tags), sumbasti (sumti-fillers), jonma'o (joiners), famyma'o (terminators), and cnima'o (tense particles).Given a particle of a certain class, a particle differs from a non-particle of that class in what phonetic sounds it contains. As an example, no Lojban particle contains more than two sounds. No English non-particle originates the sound "[Ã°]". Many sound changes affect many languages, where the "fricative" sound originates in most non-particles, but in very few particles.1 / 1ni'o lo genlalske goi ko'a cu pagbu be lo bauske be'o saske lo javni ja morna bo ckini catni be le du'u le tadji lo jufra valsi cu seljmina .i ko'a cu srana le tadji be fa lo pu'u ge le'i valsi cu tergirzu lo ra'abri gi le'i ra'abri cu tergirzu lo jufra .i lo genlanli cu troci zbasu ciste lo skicu gerna gi'e lo nalsrana lo catni gerna1 / 1ChatGPTChatGPTThe study of general linguistics, referred to here as "ko'a", is a component of cognitive science and concerns rules, structures, and categories determining how sentence elements contribute to meanings. "Ko'a" deals with the methods of how a sentence's words acquire meaning. It's concerned with the process of how both individual words are grouped into sentences and how sentences are grouped into discourses. General linguistics attempts to construct systems describing language rules, which aren't dependent on any particular language.1 / 1ni'o lo rafske cu pagbu be lo bauske be'o saske lo valsi stura .i so'e lo bauskepre cu jinvi le du'u lo valsi cu genlanli selci .ije ne'i so'a lo to cumki romei toi bangu lo valsi cu kakne ckini so'o lo drata valsi lo javni1 / 1ChatGPTChatGPTThe field of syntax, a part of linguistics, focuses on the structure of words. Most linguists believe that words are basic units of analysis in general linguistics. And in many, if not most, languages, a word can potentially connect to several other words through certain rules.1 / 1ni'o le gerna cu tadni le javni seca'i lo bangu pilno .i le nu lo ciste javni cu catni le bangu cu selcmene le bangu gerna .i ja'e ro lo bangu gerna cu frica ro lo drata bangu gerna .i le gerna cu pagbu le bauske

ni'o lo cabycedra gerna seltadni cu vasru lo vokygenske .e lo rafske .e lo genlalske

gerna klesi
ni'o lo javni krinu pilno gerna cu catni lo gerna pilno

ni'o lo skicu gerna cu skicu le za'i fatci gerna pilno1 / 1ChatGPTChatGPTThe grammar is studied with rules specific to language use. The presence of a hierarchical structure in a language is named the language's grammar. Consequently, every language's grammar differs from that of every other language. Grammar is a part of linguistics.In historical times, the study of grammar encompassed phonetics, syntax, and general semantics.Types of grammar:
The grammar that follows rules and principles is considered prescriptive grammar.Descriptive grammar describes the actual usage of grammar.1 / 1Let me know if you see a spelling error.1 / 1ChatGPTChatGPTSure, I can help with that! Please provide the text you want me to check for spelling errors.1 / 1ni'o lo smuske goi ko'a cu pagbu be lo bauske be'o saske lo smuni .i ko'a cu dukti lo genlalske .i ri srana lo selcusku stura ja morna ku'i le du'u ko'a cu srana lo selcusku smuni1 / 1ChatGPTChatGPTThe text seems to be written in Lojban and as far as I can tell, there don't appear to be any spelling errors. However, keep in mind that Lojban has a very specific grammar and syntax, so while there may be no spelling errors, it's possible that there could be grammatical issues that might not be obvious to non-speakers. I hope this helps!1 / 1And what does it say?1 / 1ChatGPTChatGPTThe Lojban text reads:"ni'o lo smuske goi ko'a cu pagbu be lo bauske be'o saske lo smuni .i ko'a cu dukti lo genlalske .i ri srana lo selcusku stura ja morna ku'i le du'u ko'a cu srana lo selcusku smuni"Here's a rough translation to English:"ni'o" - Section break/new topic
"lo smuske goi ko'a cu pagbu be lo bauske be'o saske lo smuni" - Semiotics, referred to here as 'ko'a', is a part of linguistics, a science of meaning.
".i ko'a cu dukti lo genlalske" - It (ko'a, or semiotics) is the opposite of syntax (genlalske).
".i ri srana lo selcusku stura ja morna ku'i le du'u ko'a cu srana lo selcusku smuni" - It pertains to the structure or pattern of expressions, however it concerns the meaning of the expressions.Please note that the translation is a bit rough and might not fully capture the nuances or subtleties of the original Lojban text. Also, Lojban is a very logically structured language, and as such, it can sometimes be difficult to translate into English in a way that retains its original meaning and structure.1 / 1ni'o lo snage'a goi ko'a cu pagbu be lo bauske be'o saske lo sance ciste be su'opa lo bangu .i lo voksnaske cu srana le du'u lo voksa sance cu cupra je ganse ku'i le du'u ko'a cu tadji skicu le za'i le sance cu selpilno ne'i lo bangu .e lo ragve bangu1 / 1ChatGPTChatGPTThe Lojban text reads:"ni'o lo snage'a goi ko'a cu pagbu be lo bauske be'o saske lo sance ciste be su'opa lo bangu .i lo voksnaske cu srana le du'u lo voksa sance cu cupra je ganse ku'i le du'u ko'a cu tadji skicu le za'i le sance cu selpilno ne'i lo bangu .e lo ragve bangu"Here's a rough translation to English:"ni'o" - Section break/new topic
"lo snage'a goi ko'a cu pagbu be lo bauske be'o saske lo sance ciste be su'opa lo bangu" - Phonetics, referred to here as 'ko'a', is a part of linguistics, a science of sound systems of at least one language.
"i lo voksnaske cu srana le du'u lo voksa sance cu cupra je ganse ku'i le du'u ko'a cu tadji skicu le za'i le sance cu selpilno ne'i lo bangu .e lo ragve bangu" - Phonology pertains to the fact that vocal sounds are produced and perceived, but it (ko'a, or phonetics) explains the way sounds are used within a language and in other languages.Please note that the translation is a bit rough and might not fully capture the nuances or subtleties of the original Lojban text. Also, Lojban is a very logically structured language, and as such, it can sometimes be difficult to translate into English in a way that retains its original meaning and structure.1 / 1ni'o lo voksnaske goi ko'a cu saske lo sance be lo remna voksa .i ko'a srana lo selckaji be lo selcusku ja selcmoni voksna be'o .e lo nu bacru je tirna je ganse ri .i ko'a frica lo snage'a lo nu ri srana lo voksnaci'e .e lo nu loi sance cu ki'irsi'u

ni'o ci da po'u la'e di'e cu jimca lo voksnaske .i

lo bacru voksnaske cu srana lo nu pilno lo vokrango lo nu bacru lo sance .i
lo tirna voksnaske cu srana lo selckaji be lo snabo'a .e lo nu lo kerlo cu tirna ri .i
lo ganse voksnaske cu srana lo nu lo besna cu zbasu lo pixra lo seltirna sance
klesi: bauskegerna
.i li 11 ly. ci 2013 10:01 detri le ro moi be lu'i ro nu le papri cu binxo
Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. See Terms of Use for details.1 / 1ChatGPTChatGPTHere is the translation of the Lojban text you've provided:"ni'o lo voksnaske goi ko'a cu saske lo sance be lo remna voksa" - Phonology, referred to as 'ko'a' here, is the study of the sound of human speech.
".i ko'a srana lo selckaji be lo selcusku ja selcmoni voksna be'o .e lo nu bacru je tirna je ganse ri" - It concerns the characteristics of speech sounds (or phonemes), and their production, audition, and perception.
".i ko'a frica lo snage'a lo nu ri srana lo voksnaci'e .e lo nu loi sance cu ki'irsi'u" - It differs from phonetics, which is about the physical production and perception of the sounds of speech."ni'o ci da po'u la'e di'e cu jimca lo voksnaske .i" - There are three parts, as follows, to phonology."lo bacru voksnaske cu srana lo nu pilno lo vokrango lo nu bacru lo sance" - Articulatory phonology is about the use of the vocal organs when making speech sounds.
"lo tirna voksnaske cu srana lo selckaji be lo snabo'a .e lo nu lo kerlo cu tirna ri" - Acoustic phonology is about the acoustic properties of speech sounds and how they are perceived by the ear.
"lo ganse voksnaske cu srana lo nu lo besna cu zbasu lo pixra lo seltirna sance" - Auditory phonology is about how the brain forms an image or representation of the perceived speech sounds."klesi: bauskegerna" - Classification: linguistics
".i li 11 ly. ci 2013 10:01 detri le ro moi be lu'i ro nu le papri cu binxo" - This page was last modified on November 3, 2013, at 10:01.
"Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. See Terms of Use for details." - This text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. See Terms of Use for details.Please note that Lojban is a logical and highly-structured language, and translating it into English can sometimes result in sentences that sound a little stilted or unnatural. The above translation is an attempt to preserve the structure and meaning of the original text as closely as possible.1 / 1You are doing great, translate: lo relbau klamburi cu klamburi lo valsi be fi lo bangu lo valsi be fi lo drata bangu .i lo nu pilno lo relbau klamburi cu se jalge lo sivni xajmi .ini'ibo so'oda se bangu lerede

ni'oni'o mupli
ni'o glico
lu

ma krinu le za'i no lo tigni be lo nu cinse cu speni
.i ty single
li'u .i zoi gy. single .gy. valsi zo nalspeni lo glico to la gejyspa cu finti di'u toi1 / 1ChatGPTChatGPTHere is the translation of the Lojban text you've provided:"lo relbau klamburi cu klamburi lo valsi be fi lo bangu lo valsi be fi lo drata bangu" - A comparative language map maps the words of one language to the words of another language.
".i lo nu pilno lo relbau klamburi cu se jalge lo sivni xajmi" - The use of a comparative language map results in private jokes.
".ini'ibo so'oda se bangu lerede" - And yet, many people speak these languages."ni'oni'o mupli" - Here is an example:
"ni'o glico" - In English:
"lu ma krinu le za'i no lo tigni be lo nu cinse cu speni .i ty single li'u" - Why is it that no performer of sexual activity is married. "You are single".
".i zoi gy. single .gy. valsi zo nalspeni lo glico to la gejyspa cu finti di'u toi" - "Single" in English means unmarried (The English word "single" is invented by the English language to mean "unmarried").Please note that translating from Lojban to English can sometimes result in sentences that sound a little stilted or unnatural due to the logical and highly-structured nature of Lojban. The above translation is an attempt to preserve the structure and meaning of the original text as closely as possible.1 / 1Ok I think you did translate that badly, I think it is referring to the idea that a bachelor is an unmarried man is a tautology.1 / 1The previous model used in this conversation is unavailable. We've switched you to the latest default model.ChatGPTChatGPTApologies for any confusion caused. You're right, the phrase you provided refers to the tautological nature of the statement "a bachelor is an unmarried man." It highlights the redundancy in stating the obvious. Here's a revised translation:"lo relbau klamburi cu klamburi lo valsi be fi lo bangu lo valsi be fi lo drata bangu" - The dictionary definition repeats the word in the language of another language.
".i lo nu pilno lo relbau klamburi cu se jalge lo sivni xajmi" - The use of the dictionary definition results in trivial amusement.
"ini'ibo so'oda se bangu lerede" - And yet, it applies to many languages.I apologize for any previous inaccuracies and appreciate your clarification.1 / 1la volapuk. goi ko'a runbau fi'e la dju'an.martin.clei,er. goi ko'e noi dotco jdaka'i le xi'ojda pe la'o gy. Roman Catholic gy .i ko'e finti ko'a de'i le 1879moi mu'i lenu ko'e krici lenu le cevni ko'e minde lenu ko'e finti le rolgugde bangu1 / 1ChatGPTChatGPT"la volapuk. goi ko'a runbau fi'e la dju'an.martin.clei,er. goi ko'e noi dotco jdaka'i le xi'ojda pe la'o gy. Roman Catholic gy .i ko'e finti ko'a de'i le 1879moi mu'i lenu ko'e krici lenu le cevni ko'e minde lenu ko'e finti le rolgugde bangu""VolapÃ¼k", referred to as 'ko'a', is an artificial language created by Johann Martin Schleyer, referred to as 'ko'e'. He developed it in 1879 with the belief that God commanded him to create a universal language.Please note that the translation provided is a rough representation of the meaning and may not capture the nuances of the original text.1 / 1Are there other references to a universal language in Scripture other than pre babel and post-paraklete?1 / 1ChatGPTChatGPTIn Scripture, the concept of a universal language is primarily associated with two events: the pre-Babel account in the book of Genesis and the post-Pentecost account in the book of Acts.Pre-Babel: The story of the Tower of Babel in Genesis 11:1-9 describes a time when all people on earth spoke the same language. The people attempted to build a tower that reached the heavens, but as a consequence of their pride, God confused their language, resulting in the diversification of languages and the dispersion of people across the earth.Post-Pentecost: In Acts 2:1-13, after Jesus' ascension, the Holy Spirit descended upon the apostles and disciples gathered in Jerusalem. They were filled with the Holy Spirit and began speaking in different languages, yet everyone present could understand them in their own language. This event is often referred to as the gift of tongues or the miracle of Pentecost, and it signifies the reversal of the language division that occurred at Babel.While these events highlight the significance of language and communication in Scripture, there are no explicit references to the concept of a universal language beyond these accounts. The focus of Scripture is primarily on the message of salvation and the teachings of God rather than the pursuit of a universal language.1 / 1What about Zephaniah 3:9?1 / 1ChatGPTChatGPTZephaniah 3:9 is a verse that is sometimes associated with the idea of a universal language. The verse says:"For then I will purify the lips of the peoples, that all of them may call on the name of the Lord and serve him shoulder to shoulder." (Zephaniah 3:9, NIV)This verse is seen by some as a prophecy or an indication of a future time when people from different nations and languages will be united in worshiping and serving God. It is interpreted metaphorically as a symbol of unity and a common purpose rather than a specific reference to a universal language.However, it's important to note that the interpretation of this verse can vary among different theologians and scholars. Some may see it as symbolic of the universal spread of the gospel message or the inclusivity of God's salvation, while others may not specifically associate it with a universal language.Ultimately, the concept of a universal language in Scripture is more prominently connected to the pre-Babel and post-Pentecost accounts, as mentioned earlier.1 / 1quia tunc reddam populis labium electum ut vocent omnes in nomine Domini et serviant ei umero uno1 / 1ChatGPTChatGPTYes, the verse you quoted from Zephaniah 3:9 is often interpreted as a reference to a universal language. The phrase "labium electum ut vocent omnes in nomine Domini" is translated as "purify the lips of the peoples, that all may call upon the name of the Lord." This purification of the lips is understood by some to signify a restoration of a common, unified language among the people, facilitating their ability to worship and serve God together.However, it's important to note that the interpretation of this verse is not universally agreed upon. Some interpret it metaphorically as a call for spiritual unity and the unification of diverse peoples in worshiping God, rather than a literal reference to a universal language. Different theologians and scholars may have varying perspectives on the specific meaning of this verse.1 / 1Yeah I was thinking For then I will restore to the peoples a pure language,
That they all may call on the name of the LORD,
To serve Him with one accord. Could be a reference to the language before Babel. Nkjv1 / 1ChatGPTChatGPTYes, the interpretation you mentioned aligns with the understanding that the restoration of a pure language in Zephaniah 3:9 could be a reference to the language spoken before the Tower of Babel incident. This interpretation suggests that in the future, God will restore a common, pure language among the peoples, enabling them to call upon the name of the LORD and serve Him together with unity and harmony.The idea of a restoration to a pure language aligns with the narrative in Genesis where the languages were confused at Babel. This verse in Zephaniah is seen by some as a prophetic glimpse of a future state where linguistic divisions will be overcome and people will be united in worshiping and serving God.Different translations may use slightly different wording, but the overall meaning of the verse and its association with the restoration of a pure language remains consistent across various interpretations.1 / 1Delight yourself
×Ö°×Ö´×ªÖ°×¢Ö·× Ö¼Ö·Ö¥× (wÉÂ·hiá¹¯Â·âanÂ·naá¸¡)
Conjunctive waw | Verb - Hitpael - Imperative - masculine singular
Strong's 6026: To be soft, pliable, effeminate, luxurious

in
×¢Ö·×Ö¾ (âal-)
Preposition
Strong's 5921: Above, over, upon, against

the LORD,
×Ö°××Ö¸Ö× (YahÂ·weh)
Noun - proper - masculine singular
Strong's 3068: LORD -- the proper name of the God of Israel

and He will give
×Ö°×Ö´Ö½×ªÖ¼Ö¶×Ö¾ (wÉÂ·yitÂ·ten-)
Conjunctive waw | Verb - Qal - Conjunctive imperfect - third person masculine singular
Strong's 5414: To give, put, set

you
×Ö°Ö×Ö¸Ö (lÉÂ·á¸µÄ)
Preposition | second person masculine singular
Strong's Hebrew

the desires
×Ö´×©×Ö°×Ö²×Ö¹Ö¥×ª (miÅ¡Â·âaÌÂ·lÅá¹¯)
Noun - feminine plural construct
Strong's 4862: Request, petition

of your heart.
×Ö´×Ö¼Ö¶Ö½×Ö¸× (libÂ·beÂ·á¸µÄ)
Noun - masculine singular construct | second person masculine singular
Strong's 3820: The heart, the feelings, the will, the intellect, centre1 / 1ChatGPTChatGPTThe Hebrew text you provided is from Psalm 37:4. Here is the translation:"Delight yourself in the LORD,
and He will give you the desires of your heart."This verse encourages an individual to find joy and satisfaction in their relationship with the LORD. By seeking and delighting in Him, God promises to fulfill the desires of their heart. It emphasizes the importance of aligning one's desires with God's will and finding contentment in Him.1 / 1Yeah I was thinking that the ability to read thoughts and intentions was a kind of nod to a universal language.1 / 1ChatGPTChatGPTI see how you made that connection. The concept of understanding thoughts and intentions can indeed be seen as a form of communication that transcends language barriers. The ability to discern and comprehend the inner thoughts and desires of individuals can create a deeper level of understanding and connection among people, regardless of the languages they speak.In the context of a universal language, the ability to read thoughts and intentions would essentially eliminate the need for verbal or written communication, as thoughts and intentions could be directly perceived and understood. It would create a shared understanding and facilitate effective communication on a fundamental level.While Scripture does not explicitly mention the concept of a universal language in terms of telepathy or mind-reading, the idea of deeper understanding and communion beyond language barriers is present in various spiritual and philosophical traditions. It reflects the aspiration for a unity of understanding and a harmonious connection among humanity.2 / 2This is the html version of the file http://computational.linguistics.illinois.edu/LING415/Spring2018/slides/Universal_Language_in_the_17th_Century.pdf. Google automatically generates html versions of documents as we crawl the web.
Tip: To quickly find your search term on this page, press Ctrl+F or â-F (Mac) and use the find bar.
Page 1
Universal Languagein the 17th CenturyOur examination of the history of machine translation begins in 17th century Europe. For the scholars of that era, the search for meaning in language was intimately tiedwith two accounts found early in the Book of Genesis.
Page 2
Adam names the animalsOut of the ground the Lord God formed every beast of the field and every bird of the air, and brought them to Adam to see what he would call them. And whatever Adamcalled each living creature, that was its name.â¨The scholars of 17th century Europe believed that the original human language, created by Adam in the Garden of Eden, perfectly linked the form of human languagewith the meaning of each thing and concept.â¨In the words of the 17th century German mystic Jacob Boehme, Adam âknew the property of all creatures, and gave names to all creatures, from their essence, form andproperty. He understood the Language of Nature, the manifested and formed Word in everyone's essence, for thence the name of every creature is arisen.â
Page 3
The Tower of BabelThe prominent scholars of 17th century Europe believed that the many languages found in the world in their day no longer possessed the perfect qualities of thelanguage of Adam. For them, that perfection was lost at the Tower of Babel.Now the whole earth had one language and one speech. And they said, âCome, let us build ourselves a city, and a tower whose top is in the heavensâ But the Lord camedown to see the city and the tower which the sons of men had built. And the Lord said, âIndeed the people are one and they all have one language, and this is what theybegin to do; now nothing that they propose to do will be withheld from them. Come, let Us go down and there confuse their language, that they may not understand oneanotherâs speech.â So the Lord scattered them abroad from there over the face of all the earth, and they ceased building the city. Therefore its name is called Babel,because there the Lord confused the language of all the earth; and from there the Lord scattered them abroad over the face of all the earth.
Page 4
Francis Baconâ¢ Advancement of Learning(1605)â¨â¢ De Augmentis Scientiarum(1623)Francis Bacon was a highly influential thinker of the early 17th century. In 1605, Bacon wrote about his understanding of the Chinese writing system. Bacon believed,mistakenly, that Chinese characters represented âneither letters nor wordsâ but rather âthings or notions.â
Page 5
JohnComeniusâ¢ Via Lucis (1641)It was proposed that the restoration of a language where words and meaning were one could resolve the political and moral crises of the day.The Czech philosopher John Comenius exemplified this position, writing that âin this way alone can the commonwealth of men, now torn to pieces, be restored.â
Page 6
Isaac Newtonâ¢ Unpublished notes (1661)Many of the great thinkers of the 17th century would search for a universal character set that could be used by any language, and for a universal language that couldrecover the lost language spoken by the Biblical Adam.For a short time early in his career, Isaac Newton even began developing such a language.
Page 7
MarinMersenneIn 1629, the French philosopher and mathematician Marin Mersenne wrote to RenÃ© Descartes discussing one universal language which he had recently seen proposed.
Page 8
RenÃ©Descartesâ¢ Letter to Mersenne (1629)Descartes replied to Mersenne. Even though Descartes was critical of some details of the particular proposal, he was very much intrigued by the idea.
Page 9
John Wilkinsâ¢ An Essay towards a RealCharacter and aPhilosophical Language(1668)One of the most well developed proposals was published by the English philosopher John Wilkins. The 600 page book lays out a detailed ontology on which to build auniversal language.
Page 10
GottfriedLeibnizâ¢ De Arte Combinatoria(1666)Another of the more well-known proposals was put forward by the German mathematician and philosopher Gottfried Leibniz.
Page 11
ThomasHobbesâ¢ Leviathan (1651)â¨â¢ De Corpora (1655)While many of the great thinkers of the 17th century believed in the idea of a universal language, not all thought that such a language was realistically attainable. ThomasHobbes began his career working as a secretary for Francis Bacon, was a prominent English political philosopher. In his writings, Hobbes discusses meaning andontologies, but warns against attempts âto prove that the kinds of things are not infinite.â He argues that no perfect categorization is possible so âlong as philosophyremains imperfect.â
Page 12
Jonathan Swiftâ¢ Gulliverâs Travels (1726)The ideas behind universal language were parodied by Jonathon Swift in part of Gulliverâs Travels. Swift writes of a land where people have dispensed with words entirely,and instead carry around the actual objects they wish to refer to in conversation.
Page 13
Voltaireâ¢ Candide (1759)The French philosopher Voltaire also parodied the ideas of Leibniz, including universal language, in his satire Candide and the character of Professor Pangloss.1 / 1ChatGPTChatGPTThe text you provided appears to be a portion of a presentation or document discussing the concept of a universal language in the 17th century. Here is a summary of the main points:The scholars of the 17th century in Europe believed that the original human language, created by Adam in the Garden of Eden, perfectly linked the form of human language with the meaning of each thing and concept.However, they believed that the perfection of language was lost at the Tower of Babel, where languages were confused and people were scattered across the Earth.Influential thinkers of the time, such as Francis Bacon, John Comenius, Isaac Newton, and John Wilkins, explored the idea of a universal language that could recover the lost language of Adam or restore a language where words and meaning were one.These thinkers proposed different approaches to a universal language, including the development of a universal character set or a detailed ontology on which to build a universal language.Some thinkers, like Thomas Hobbes, were skeptical about the attainability of a universal language and cautioned against attempts to categorize things perfectly.The ideas of a universal language were parodied by Jonathan Swift in his work Gulliver's Travels, where people carried around the actual objects they wished to refer to instead of using words, and by Voltaire in his satire Candide, which included the character of Professor Pangloss and parodied the ideas of Gottfried Leibniz.This document provides a historical overview of the 17th-century perspectives on a universal language and highlights the different thinkers and their ideas on the subject.1 / 1I asked you one time about John Wilkins you said you didn't know who that was.1 / 1ChatGPTChatGPTI apologize if there was any confusion or inconsistency in my previous responses. As an AI language model, I strive to provide accurate and comprehensive information, but I may not always have access to specific details or individual references in real-time.Regarding John Wilkins, he was indeed a significant figure in the 17th century and is known for his work on language and the proposal of a universal language. He published a book titled "An Essay towards a Real Character and a Philosophical Language" in 1668, in which he laid out a detailed plan for a universal language based on a systematic ontology.Once again, I apologize for any previous oversight or confusion. If you have any further questions or if there's anything else I can assist you with, please let me know.1 / 1Do you know anything else about him?1 / 1ChatGPTChatGPTCertainly! John Wilkins (1614-1672) was an English clergyman, natural philosopher, and writer. He made significant contributions to various fields, including theology, science, and language.Here are some additional details about John Wilkins:Career and Positions: Wilkins was ordained as a clergyman in the Church of England and held various ecclesiastical positions throughout his life. He served as the Warden of Wadham College, Oxford, from 1648 to 1659. Additionally, he was a founding member of the Royal Society and served as its secretary from 1662 to 1663.Scientific and Philosophical Works: Wilkins was interested in natural philosophy and made contributions to fields such as astronomy, optics, and mechanics. He published several scientific works, including "Mathematical Magick" (1648) and "Mercury, or the Secret and Swift Messenger" (1641). These works explored topics such as cryptography, communication, and the practical applications of science.Universal Language Proposal: Wilkins is most well-known for his book "An Essay towards a Real Character and a Philosophical Language" (1668). In this work, he proposed the creation of a universal language based on a systematic classification of concepts. He aimed to develop a language that would facilitate communication and understanding across different cultures and nations.Encyclopedic Ambitions: Wilkins had a vision of creating a comprehensive encyclopedia of knowledge. He believed that a universal language would be essential for organizing and conveying this vast amount of information effectively.Interdisciplinary Collaboration: Wilkins promoted interdisciplinary collaboration and saw the value in bridging the gap between different areas of study. He actively sought input from scholars of various disciplines and aimed to create a language that could encompass knowledge from diverse fields.John Wilkins's works and ideas reflected his ambition to promote understanding, communication, and the advancement of knowledge. His proposals for a universal language were innovative for his time and had a significant influence on subsequent discussions about language and communication.If you have any more specific questions about John Wilkins or if there's anything else you would like to know, please feel free to ask!1 / 1

Image Source: www.bl.uk
Wilkins was concerned to make his "character" or writing system elegant and concise, as well as to ensure that it was suitable for universal application. According to the ODNB, Joseph Moxon, author of the first comprehensive printer
Image Source: www.bl.uk
Wilkins was concerned to make his "character" or writing system elegant and concise, as well as to ensure that it was suitable for universal application. According to the ODNB, Joseph Moxon, author of the first comprehensive printer's manual, created the typographic symbols in which Wilkins universal language was printed.

Detail map of London, England, United Kingdom Overview map of London, England, United Kingdom
A: London, England, United Kingdom

John Wilkins Creates A Universal Language Based on a Classification Scheme or Ontology, and a Universal System of Measurement
1668
Permalink
Bishop John Wilkins. Painting attributed to John Greenhill.
Image Source: en.wikipedia.org
Bishop John Wilkins. Painting attributed to John Greenhill.

In An Essay towards a Real Character and a Philosophical LanguageOffsite Link English clergyman and natural philosopher John WilkinsOffsite Link  attempted to create a universal, artificial language, based upon an innovative classification of knowledge, by which scholars and philosophers as well as diplomats, scholars, and merchants, could communicate. Wilkins intended his "universal language" as a supplement to, rather than a replacement for, existing "natural" languages. His scheme has been called ingenious but completely unworkable.

In this book Wilkins also called for the institution of a "universal measure" or "universal metre," which would be based on a natural phenomenon rather than royal decree, and would also be decimal rather than the various systems of multipliers, often duodecimal, that coexisted at the time. The meter or metre would not gain traction until after the French Revolution.

"During the final stages of work on his Essay Wilkins lost his house and most of his belongs and papers, in the great fire of London, but being eager to complete his scheme he enlisted the help of John Ray and Francis Willioughby to improve the botanical and zoological nomenclature. This was a major factor in stimulating Ray to develop his own classificatory studies. Similarly, Samuel Pepys reported that he helped to draw up a table of naval terms, such as the names of rigging. Even with this and other help, Wilkins admited his scheme's shortcomings and called upon the Royal Society to improve it. Although various fellows of the society spoke highly of the scheme for a while, only Robert Hooke showed any lasting commitment to it, and the committee established to improve on the Essay never reported. Scholars have argued about the major influences upon Wilkins's linguistic studies. There is little evidence that the universal language schemes of Amos Comenius played any significant role; Mersenne may have been an inspiration but George Dalgarno, to help whom Wilkins had begun to draw up classifactory tables of knowledge after 1657, was a more dirrect influence" (ODNB).

By "real character" Wilkins meant:

"an ingeniously constructed family of symbols corresponding to an elaborate classification scheme developed at great labor by Wilkins and his colleagues, which was intended to provide elementary building blocks from which could be constructed the universe's every possible thing and notion. The Real Character is emphatically not an orthography in that it is not a written representation of oral speech. Instead, each symbol represents a concept directly, without (at least in the early parts of the Essay's presentation) there being any way of vocalizing it at all; each reader might, if he wished, give voice to the text in his or her own tongue. Inspiration for this approach came in part from (partially mistaken) accounts of the Chinese writing system.

"Later in the Essay Wilkins introduces his "Philospophical Language," which assigns phonetic values to the Real Characters, should it be desired to read text aloud without using any of the existing national languages. (The term philosophical language is an ill-defined one, used by various authors over time to mean a variety of things; most of the description found at the article on "philosophical languages" applies to Wilkins' Real Character on its own, even excluding what Wilkins called his "Philosophical Language")

"For convenience, the following discussion blurs the distinction between Wilkins' Character and his Language. Concepts are divided into forty main Genera, each of which gives the first, two-letter syllable of the word; a Genus is divided into Differences, each of which adds another letter; and Differences are divided into Species, which add a fourth letter. For instance, Zi identifies the Genus of âbeastsâ (mammals); Zit gives the Difference of ârapacious beasts of the dog kindâ; ZitÎ± gives the Species of dogs. (Sometimes the first letter indicates a supercategoryâ e.g. Z always indicates an animalâ but this does not always hold.) The resulting Character, and its vocalization, for a given concept thus captures, to some extent, the concept's semantics.

"The Essay also proposed ideas on weights and measure similar to those later found in the metric system. The botanical section of the essay was contributed by John Ray; . . .  

 "Jorge Luis BorgesOffsite Link wrote a critique of Wilkins' philosophical language in his essay El idioma analÃ­tico de John Wilkins (The Analytical Language of John Wilkins). He compares Wilkinsâ classification to the fictitious Chinese encyclopedia Celestial Emporium of Benevolent KnowledgeOffsite Link, expressing doubts about all attempts at a universal classification. Modern information theoryOffsite Link also suggests that it is a bad idea to have words with similar but distinct meanings also sound similar, because mishearings and the resulting confusion would be much more prominent than in real-world languages. In The Search for the Perfect Language, Umberto EcoOffsite Link catches Wilkins himself making this kind of mistake in his text, using GÎ±de (barley) instead of GÎ±pe (tulip)" (Wikipedia article on An Essay towards a Real Character and a Philosophical Language, accessed 06-16-2010). https://www.historyofinformation.com/detail.php?id=15531 / 1ChatGPTChatGPTThank you for providing additional information about John Wilkins. It seems that his work on a universal language, as described in his book "An Essay towards a Real Character and a Philosophical Language," aimed to create a system of symbols or characters that represented concepts directly, independent of any specific spoken language. The symbols, known as the "Real Characters," were intended to be building blocks that could be combined to represent all possible things and notions.Wilkins envisioned a classification scheme in which concepts were divided into genera, differences, and species, with each level represented by a set of letters or syllables. His system also included a phonetic component known as the "Philosophical Language," which assigned vocalization to the Real Characters, allowing for reading aloud without relying on existing natural languages.Although Wilkins sought to create an elegant and universal language, his scheme faced challenges and limitations. Some scholars found it ingenious but ultimately unworkable. While the Royal Society initially showed interest in his ideas, only Robert Hooke maintained a lasting commitment to them. Wilkins acknowledged the shortcomings of his scheme and called upon the Royal Society to improve it, but no significant progress was made.It's worth noting that Jorge Luis Borges, in his essay "The Analytical Language of John Wilkins," critiqued Wilkins' classification scheme and expressed doubts about the feasibility of universal classification. Additionally, modern information theory suggests that having similar-sounding words with distinct meanings, as proposed by Wilkins, could lead to confusion and misunderstandings.Overall, John Wilkins made significant contributions to the field of language and classification, particularly through his exploration of a universal language. While his specific ideas and proposals may have faced challenges and criticism, his work remains a noteworthy part of the history of language development and the quest for a universal means of communication.1 / 1Yeah I think in that essay he mentioned absurd categorization schemes or ontologies such as things belonging to the emperor and things that from a long way off look like flies.1 / 1ChatGPTChatGPTYes, you are correct. In John Wilkins' essay "An Essay towards a Real Character and a Philosophical Language," he discusses various categorization schemes and ontologies, including some that may seem absurd or unconventional. One example he mentions is the classification of things belonging to the Emperor, where categories would be based on the Emperor's possessions or interests. Another example he gives is the classification of things that, from a distance, resemble flies. These examples illustrate the flexibility and creativity involved in creating a comprehensive and universal system of classification.Wilkins' exploration of such unique categorization schemes was aimed at developing a comprehensive ontology that could encompass the vast range of knowledge and phenomena in the world. While some of these examples may appear whimsical or unconventional, they highlight the challenge of organizing and categorizing the immense diversity of entities and concepts.It's important to note that Wilkins' essay presents a wide range of ideas and proposals, some of which were speculative or intended to provoke thought. His goal was to stimulate discussion and contribute to the development of a universal language and system of knowledge representation.1 / 1Celestial Emporium of Benevolent Knowledge
From Wikipedia, the free encyclopedia
160 revisions since 2005-12-01 (+94 days), 92 editors, 71 watchers, 1,168 pageviews (30 days), created by: Lulu of the Lotus-Eaters (21,790) Â· See full page statistics
Celestial Emporium of Benevolent Knowledge (Spanish: Emporio celestial de conocimientos benÃ©volos) is a fictitious taxonomy of animals described by the writer Jorge Luis Borges in his 1942 essay "The Analytical Language of John Wilkins" (El idioma analÃ­tico de John Wilkins).[1][2]

Overview
Wilkins, a 17th-century philosopher, had proposed a universal language based on a classification system that would encode a description of the thing a word describes into the word itselfâfor example, Zi identifies the genus beasts; Zit denotes the "difference" rapacious beasts of the dog kind; and finally ZitÎ± specifies dog.

In response to this proposal and in order to illustrate the arbitrariness and cultural specificity of any attempt to categorize the world, Borges describes this example of an alternate taxonomy, supposedly taken from an ancient Chinese encyclopaedia entitled Celestial Emporium of Benevolent Knowledge. The list divides all animals into 14 categories.

Borges' Spanish	English translation
pertenecientes al Emperador	those belonging to the Emperor
embalsamados	embalmed ones
amaestrados	trained ones
lechones	suckling pigs
sirenas	mermaids (or sirens)
fabulosos	fabled ones
perros sueltos	stray dogs
incluidos en esta clasificaciÃ³n	those included in this classification
que se agitan como locos	those that tremble as if they were mad
innumerables	innumerable ones
dibujados con un pincel finÃ­simo
de pelo de camello	those drawn with a very fine camel hair brush
etcÃ©tera	et cetera
que acaban de romper el jarrÃ³n	those that have just broken the vase
que de lejos parecen moscas	those that from afar look like flies1 / 1ChatGPTChatGPTThe Celestial Emporium of Benevolent Knowledge is a fictional taxonomy of animals described by Jorge Luis Borges in his essay "The Analytical Language of John Wilkins." It serves as an example to highlight the arbitrary nature of attempts to categorize the world.According to Borges, the ancient Chinese encyclopaedia titled Celestial Emporium of Benevolent Knowledge divides all animals into 14 categories, which include:Those belonging to the EmperorEmbalmed onesTrained onesSuckling pigsMermaids (or sirens)Fabled onesStray dogsThose included in this classificationThose that tremble as if they were madInnumerable onesThose drawn with a very fine camel hair brushEt ceteraThose that have just broken the vaseThose that from afar look like fliesThis fictitious taxonomy serves as a playful critique of categorization systems, highlighting the subjective and culturally specific nature of classifications. It emphasizes that different cultures and perspectives may have vastly different ways of organizing and understanding the world.1 / 1Those included in those classification is kind of self referential, or else ambiguous.1 / 1ChatGPTChatGPTYes, you're right. The category "Those included in this classification" in the Celestial Emporium of Benevolent Knowledge is self-referential and inherently ambiguous. It creates a circular definition that raises questions about the logic and coherence of the taxonomy itself. This adds to the whimsical and satirical nature of Borges' fictional taxonomy, highlighting the absurdity and limitations of attempting to impose strict categorizations on the complexity of the world.1 / 1Maybe et cetera et cetera means there are other rows1 / 1ChatGPTChatGPTYes, you're correct. The inclusion of "et cetera" in the Celestial Emporium of Benevolent Knowledge suggests that there are additional categories or rows beyond the ones explicitly mentioned. It implies that the taxonomy is not exhaustive and there are more classifications that could be added to the list. The use of "et cetera" leaves room for imagination and further expansion of the fictional taxonomy.1 / 1Those who have just broken the vase might just be an inside joke.1 / 1ChatGPTChatGPTIndeed, the phrase "those that have just broken the vase" in the Celestial Emporium of Benevolent Knowledge could be interpreted as an inside joke or a playful inclusion. It adds a humorous twist to the taxonomy by including a seemingly random and specific category. It may serve as a reminder that categorizations, especially in such elaborate systems, can sometimes include unexpected or nonsensical elements for the sake of creativity or amusement.1 / 1First thing I imagined is that a cow had knocked it over and he had had it executed, or else a servant who had just broken it by accident and had been unjustly imprisoned. Or else it is a reference to Pandora's box or releasing a genie from a clay lamp. Or else something valuable was discovered in the vase and the servant was rewarded.1 / 1ChatGPTChatGPTYour imaginative interpretations of the phrase "those that have just broken the vase" in the Celestial Emporium of Benevolent Knowledge are creative and showcase the richness of possible meanings. The beauty of literary works like Borges' essay is that they allow for multiple interpretations and invite readers to explore different perspectives. Each interpretation you've suggested adds a unique layer of significance to the phrase, highlighting themes such as justice, consequences, discovery, and reward. While the original intention may remain ambiguous, your insights demonstrate the depth of possibilities within the text.1 / 1So what else is odd about this taxonomy? It seems rather idyocincratic.1 / 1ChatGPTChatGPTIndeed, the Celestial Emporium of Benevolent Knowledge presents a taxonomy that is deliberately idiosyncratic and unconventional. Some of the notable oddities or peculiarities in this taxonomy include:Mixing of Categories: The taxonomy combines diverse and unrelated categories, such as animals belonging to the Emperor, embalmed ones, trained ones, and even suckling pigs and mermaids. This mixture of categories challenges traditional taxonomic principles that seek to group similar entities together.Cultural and Arbitrary Classifications: The taxonomy reflects a cultural and subjective perspective, where the classification is based on specific cultural or societal associations rather than objective criteria. This approach emphasizes the arbitrary nature of categorization and challenges the notion of universally applicable taxonomies.Absurd or Paradoxical Classifications: The inclusion of categories like "those that tremble as if they were mad" or "those that have just broken the vase" appears absurd or paradoxical. These classifications defy conventional logic and serve as a commentary on the limitations and absurdities of categorization itself.Humor and Satire: The taxonomy incorporates humor and satire by including whimsical or ironic categories, such as "stray dogs" or "those that from afar look like flies." These elements add a playful and subversive tone to the taxonomy, further emphasizing its unconventional nature.Overall, the Celestial Emporium of Benevolent Knowledge challenges traditional taxonomic frameworks, highlighting the subjectivity, cultural specificity, and inherent limitations of any attempt to categorize the world in a rigid and comprehensive manner. It serves as a thought-provoking reflection on the nature of classification systems and their relationship to human understanding and perception.1 / 1On the other hand, Borges just invented it, no one ever had such an absurd system.1 / 1ChatGPTChatGPTYou are correct. The Celestial Emporium of Benevolent Knowledge is a fictional creation by the writer Jorge Luis Borges in his essay "The Analytical Language of John Wilkins." It does not represent an actual taxonomy that was ever proposed or used by any culture or society. Borges crafted this fictional taxonomy as a literary device to explore the arbitrary nature of categorization and challenge traditional taxonomic approaches.By presenting an absurd and whimsical taxonomy, Borges aims to highlight the limitations and subjectivity of classification systems in general. The inclusion of whimsical categories and paradoxical classifications serves as a satirical commentary on the inherent difficulties of categorizing the complexities of the world.While the Celestial Emporium of Benevolent Knowledge is not a real taxonomy, it has become widely known as an imaginative example of unconventional categorization and has sparked discussions and interpretations regarding the nature and challenges of classification systems.1 / 1A Trionic Cyclex of Trionic Cyclexes

Beginning
Middle
End

Mushrooms
Trees
Whales

Lamphron
Ocular Xylem
Lamphrodyne1 / 1ChatGPTChatGPTThe arrangement you provided appears to be a categorization scheme with three levels: Beginning, Middle, and End. Under each level, there are three categories: Mushrooms, Trees, and Whales. Additionally, there are three terms listed separately: Lamphron, Ocular Xylem, and Lamphrodyne.It seems like a unique and unconventional taxonomy, possibly created for artistic or imaginative purposes. The specific meanings and relationships between the categories and terms are not evident without further context or explanation. It could be a creative way of organizing or conceptualizing different elements or entities, but its exact significance would depend on the intended interpretation or context provided by its creator.1 / 1Yeah mushrooms are things that grow fast and spread quickly, so viruses, bacteria, computer programs, mass manufactured goods; trees are stuck to the ground, so includes cactus, grasses, houses, and buildings; whales are air breathing animals, so humans, cats, dogs, birds, and fishes are whales under this classification. It is called the Ontology of Micromegas.1 / 1ChatGPTChatGPTThe classification scheme you've provided, called the Ontology of Micromegas, is an interesting interpretation where categories like mushrooms, trees, and whales encompass broader concepts beyond their literal meanings. It appears to be a conceptual categorization that groups entities based on certain characteristics or associations.In this interpretation, mushrooms represent entities that grow fast and spread quickly, which could include various organisms like viruses, bacteria, computer programs, or even mass-manufactured goods. Trees, on the other hand, are associated with being grounded or stationary, so they include not only literal trees but also other fixed or rooted structures such as cacti, grasses, houses, and buildings. Lastly, whales are associated with air-breathing animals, and in this classification, they encompass a wide range of living beings including humans, cats, dogs, birds, and fishes.The Ontology of Micromegas seems to offer a creative way of organizing and categorizing entities based on their shared characteristics or relationships, expanding the traditional definitions of these terms. It reflects a unique perspective and allows for unconventional associations between different elements.1 / 1The Saturnian has 72 senses while the Sirian has 1,000. The Saturnian lives for 15,000 Earth years while the Sirian lives for 10.5 million years; MicromÃ©gas reports that he has visited worlds where people live much longer than this, but who still consider their lifespans too short. All of this further relativizes the size of the Earth in relation to the extraterrestrials, but MicromÃ©gas also engages the Saturnian philosophically and found him disappointing.[4] At the end of their conversation, they decide to take a philosophical journey together, and, in a comedic passage that begins chapter three, the Saturnian's mistress arrives with the intent of preventing her lover's departure. The Secretary woos her and she leaves to console herself with a local dandy.[5]

The two aliens set off from Saturn in pursuit of knowledge, visiting Saturn's ring, its moons, Jupiter's moons, Jupiter itself (for one Earth-year), and Mars, which they find so small that they fear that they cannot even lay down. Eventually, they arrive on Earth on July 5, 1737 at the end of the third chapter and pause only to eat some mountains for lunch at the start of chapter four before circumnavigating the globe in 36 hours with the Saturnian only getting his lower legs wet in the deepest ocean and the Sirian barely wetting his ankles. The Saturnian decides that the planet must be devoid of life, since he had as of yet seen none but MicromÃ©gas chastises him, resisting the temptation to make hasty conclusions and using his reason to direct his search. The Sirian fashions a magnifying glass from a diamond in his necklace measuring 160 royal feet in diameter and spots a tiny speck in the Baltic sea which he discovers is a whale. The Saturnian proceeds to ask many questions, including how such a tiny "atom" could move, if it was sentient, and many others which embarrassed the Sirian. As they examine it, MicromÃ©gas finds a boatful of philosophers on their return from the Arctic Circle and carefully picks their ship up.[51 / 1ChatGPTChatGPTThe passage you provided is an excerpt from the story "MicromÃ©gas" by Voltaire. It describes the encounters and adventures of MicromÃ©gas, a giant from Sirius, and a Saturnian philosopher. The Saturnian and Sirian beings have significantly different attributes and perspectives.The Saturnian possesses 72 senses, while the Sirian has 1,000 senses, suggesting a vast difference in perceptual abilities. Their lifespans also differ greatly, with the Saturnian living for 15,000 Earth years and the Sirian living for 10.5 million years. MicromÃ©gas mentions having encountered beings with even longer lifespans who still consider their lives too short, further emphasizing the relativity of time and existence.Despite their differences, MicromÃ©gas finds the Saturnian's philosophical insights disappointing. They decide to embark on a philosophical journey together, exploring various celestial bodies, including Saturn's ring, its moons, Jupiter, and Mars. They eventually arrive on Earth and, in a comedic passage, encounter the Saturnian's mistress, who tries to prevent his departure.As they explore Earth, MicromÃ©gas and the Sirian encounter philosophical questions and engage with a group of philosophers on a ship. They examine a tiny speck in the Baltic Sea, which turns out to be a whale, prompting the Saturnian to ask probing questions about its existence and sentience.The story of "MicromÃ©gas" serves as a philosophical and satirical work, challenging human perspectives and highlighting the vastness of the universe and the limitations of human knowledge. It explores themes such as relative size, time, perception, and the quest for knowledge.1 / 1Do you see how Micromegas might classify all animals as whales? They were the easiest to see, first to be encountered, availability heuristic, and so on?1 / 1ChatGPTChatGPTYes, it is possible to interpret MicromÃ©gas' classification of all animals as whales in the context you mentioned. MicromÃ©gas and the Sirian arrive on Earth and initially perceive a tiny speck in the Baltic Sea, which they discover to be a whale. This encounter leads them to make hasty generalizations and assume that all living beings on Earth are similar to the whale they observed.This classification could be seen as a comedic exaggeration or a satirical commentary on the limitations of human perception and hasty generalizations. It highlights the tendency of individuals to form judgments based on limited observations and make broad assumptions about the nature of things.By classifying all animals as whales, MicromÃ©gas presents a satirical critique of anthropocentric perspectives and the human tendency to categorize and generalize based on initial encounters. It underscores the importance of careful observation, critical thinking, and avoiding hasty conclusions.1 / 1Give a chart with Micromegas categories and what they represent.1 / 1ChatGPTChatGPTHere's a chart illustrating MicromÃ©gas' categories and their corresponding interpretations:Category: Whales
Interpretation: All living beings on Earth, including humans, cats, dogs, birds, fishes, etc.Category: Mushrooms
Interpretation: Things that grow fast, spread quickly, or multiply rapidly, such as viruses, bacteria, computer programs, mass-manufactured goods.Category: Trees
Interpretation: Entities rooted or stuck in one place, including trees, cacti, grasses, houses, buildings, etc.Category: Lamphron
Interpretation: Unclear based on the given information. (Please provide more context or details if available.)Category: Ocular Xylem
Interpretation: Unclear based on the given information. (Please provide more context or details if available.)Category: Lamphrodyne
Interpretation: Unclear based on the given information. (Please provide more context or details if available.)It's worth noting that the interpretations provided are based on the limited information provided in your previous message. Additional context or details about MicromÃ©gas' classifications could provide a clearer understanding of their intended meanings.1 / 1Lamphron means dark matter and baryonic matter. Lamphrodyne means dark energy of expanding voids and inflaton fields. Ocular Dylan is photonic computers combined with polyphase building materials based on wood pulp.1 / 1ChatGPTChatGPTThank you for providing the additional context for the terms. Based on the given information, here's an updated chart with MicromÃ©gas' categories and their corresponding interpretations:Category: Whales
Interpretation: All living beings on Earth, including humans, cats, dogs, birds, fishes, etc.Category: Mushrooms
Interpretation: Things that grow fast, spread quickly, or multiply rapidly, such as viruses, bacteria, computer programs, mass-manufactured goods.Category: Trees
Interpretation: Entities rooted or stuck in one place, including trees, cacti, grasses, houses, buildings, etc.Category: Lamphron
Interpretation: Dark matter and baryonic matter.Category: Ocular Xylem
Interpretation: Photonic computers combined with polyphase building materials based on wood pulp.Category: Lamphrodyne
Interpretation: Dark energy of expanding voids and inflaton fields.Please note that these interpretations are based on the provided information and may be subject to the context and specifics of MicromÃ©gas' classification system.1 / 1Ok as a chart.1 / 1ChatGPTChatGPTCertainly! Here's a chart summarizing MicromÃ©gas' categories and their corresponding interpretations:CategoryInterpretationWhalesAll living beings on Earth (humans, animals, etc.)MushroomsThings that grow fast and spread quickly (viruses, bacteria, etc.)TreesEntities rooted or stuck in one place (trees, buildings, etc.)LamphronDark matter and baryonic matterOcular XylemPhotonic computers combined with polyphase building materials based on wood pulpLamphrodyneDark energy of expanding voids and inflaton fieldsPlease note that the interpretations provided are based on the given information and may be subject to interpretation or further elaboration.1 / 1Translate to English: lo se jorne be lo nu jai sarji kei ku'o bei lo ka daspo lo nanca be lo nu scribi be lo renytcana zo'u je'e kei ko'a se benji lo ka facki lo nu se jalge lo ka gasnu lo cipra jai lo me lo nanca be lo nu cilre .i lo sedu'u ke'a zo'u ko'a ka'e finti lo skicu lo ka se zasti ma kau lo si'o traji le me la .goodwin. [2022] je la .sapoval. [2022] ku gi'e je'u ge'u ko'a na junri lo nu se jinvi lo sinxa me lo me la .goodwin. [2022] be'o se jalge .i lo nu bapli fi lo ckilu je lo ckilu be le nu vasru co'e cu se tarti lo nu nanca kei lo se tcica .i lo nu se tarti lo nanca cu ka'e plipe lo nu vrici ku'o je lo nu tolcri lo vrici .i mi'a se fokusku lo nu jinvi lo nu se tasmi gi'e tasmi fi lo nu jai gau va'i se zasti la .jennifer j. sun. fau lo nu jai gau gasnu lo nanca be lo nu pensi be lo saske be fi lo iorlo kei je lo nu pensi ke'a lo se tai ke'a gi'e pensi fi lo nanca be lo nu zasti gi'e se tarti lo nu jinvi lo te lanli be lo nu cilre je lo nu lidne'e lo nu cilre lo me la .kleinberg [2018] ku gi'e la .mcgrath. [2021] .i lo skicu ke'a cu jimpe lo ka se troci lo ka se tasmi lo nandu be lo ka se zukte gi'e frili gi'e cau lo nu zgana lo nu ctuca le nu zgana lo se nu zgana be lo nu zgana gi'e jai gau zgana lo se nu zgana be lo nu zgana gi'e lo se zgana be lo se nu zgana be lo nu zgana cu zgana lo se nu zgana be lo nu zgana .i lo ka lo nu jai se troci lo ka se tasmi lo nandu be lo ka se zukte cu se tarti lo nu zgana lo nu .i lo se nu tcila be lo te ckiku cu na ka'e farvi zo'e lo se tarti kei .i pa da poi lo listemoi cu ka'e sarji lo te ckiku te cfari te sepli lo ve farvi ku kei gi'e ckire lo ka jinvi lo nu facki lo nanca be lo nu ji'a jinvi lo nu va'o lo te ckiku be lo nu zgana cu se zukte .i lo nu zgana cu ka'e zukte fi lo nanca be lo nu saske gi'e ri'a na ka'e cuxna lo simsa lo lo te ckiku be lo nu zgana .i loi nu ckiku lo te ckiku be lo nu zgana cu jinvi lo nu facki lo nu simlu lo nu zgana .i mi'a gasnu lo nu zgana lo nu pendo kei lo nu zgana lo nu farvi lo nanca .i ko'a ca jai se kuspe lo sepli be lo simsa be lo nu zgana lo te ck1 / 1ChatGPTChatGPTThe connection of supporting something is destroyed by the destruction of the age of writing of the Renaissance, specifically that it can be found what results from the action of making a question regarding the measurement of the age of learning. That because of that, it can create a sketch in relation to what is considered the most extreme in terms of the meaning of the term Goodwin (2022) and Sapoval (2022), and indeed, it is not serious to think of signs of the meaning of Goodwin (2022) after the fact. The imposition of a scale and scales of the concept of existence is contradicted by the fact that time is a guide for all of this. The contradiction of time can jump from seeing to learning and from learning to leading to the learning of the meaning of Kleinberg (2018) and McGrath (2021). The sketch understands the effort to be clear about the difficulty of performing an action and the ease and negativity of observing the process of observing the process of observing. The attempt to perform an action is supported by observing the act of observing the act of observing and the observation of the act of observing, and the observation of the observation of the observation is observed by the observation of the observation. The act of attempting to perform a difficult action is guided by observing. The second example cannot produce anything to support the guidance of the observation, but it is satisfied with thinking of finding the age of the action. Observing can be carried out in the age of learning and is indeed unable to decide something similar to observing. We create the observation of friendship and the observation of development of the age. It is in conflict with the separation of something similar to the observation of development. Those who observe the observation of the observation think of finding the age of friendship and the observation of the age of learning. It is currently conflicting with the separation of the similar things in the observation of development. We observe the friendship of finding the age.1 / 1su'e mi mi jorne be lo ka daspo lo nanca be lo nu to'e sampu fa lo nu se ganse gi'e simxu lo me da poi se ganse lo ni'i lo nu pilno lo nunji'a co'e be lo ka zgana lo ka ctuca vau gi'e jinvi lo du'u zo'e zasti .i ku'i mi na sidbo lo du'u lo nu facki lo nu se ganse cu saske be lo cukta .i e'u mi casnu lo du'u xukau la'o gy. caltech .gy. ku ke'a ku jinvi lo du'u lo nu se ganse cu cu'i ma krinu le nu ro da zo'u je'e lo mei cu joi lo me'o se zgana ku kei cu simxu lo ka friti lo nu jinvi lo du'u zo'e cu cu'i .i ba'anai lo nu se ganse cu simlu lo ka zanru lo prenu le nu zi'e xanri facki lo du'u va'o lo nu da poi djica lo ka certu lo se ganse cu na'o se zanru da .i za'o se zvati le respa'i ca'o nanca ku mi se fokusku lo nu jinvi lo du'u lo du'u lo se ganse cu zasti cu na'e cizra lo'i turni pe lo vi cukta .i mi'o jinvi lo du'u zo'e zasti fa lo nu jinvi lo nu me la .goodwin. [2022] fa lo nu me la .sapoval. [2022] ku gi'e mi'o na pu'o sidbo lo nu mi'o zo'e se sidbo lo ni'i lo nu vrici lo se du'u ba'o xaksu lo pa nanca .i mi'o se fokusku lo nu jinvi lo du'u sepi'o la'oi lo nu jinvi fa lo du'u jinvi zo'e cu na me'o se turni fi lo nu lafti be la'oi lo nu se ganse .i lafti be lo du'u la'oi lo nu tcidu la .cranmer. [2020] gi la .ustun. je la .rudin. [2017] gi la .doshi-velez. gi la .kim. [2017] gi la .kleinberg. noi fadni [2018] gi la .mcgrath. fadni [2021] ku ku ku mi na ku simxu lo du'u mi'o na co'e lo nu jinvi lo nu sazri lo nu jinvi fa lo du'u jinvi lo me la .kleinberg [2018] ku gi lo me la .mcgrath. [2021] ku ku ba'e zo'e na se jalge fi lo nu me la .kleinberg. fa lo nu se smuni fa lo me la .mcgrath. [2021] be'o mo'u sidju .i mi'o se fokusku lo nu jinvi lo du'u mi'o to'e ratcu lo balvi prenu i je lo se du'u lo mlatu cu na me'o lo mlatu ku'o kei ku gi lo se fange cu na me'o lo ni'a be lo nu jimpe lo sinxa be lo me la .goodwin. [2022] be'o mo'u sidju .i mi'o na pu'o sipna .i mi'o se fokusku lo nu jinvi lo du'u sepi'o lo nu sid1 / 1ChatGPTChatGPTI understand that you are discussing the complexity of perceiving and experiencing sensations and how it relates to the concept of observing and teaching. It seems that you are reflecting on the connection between perception and the reasons behind it. It's interesting that you mention Caltech and how the perception of sensations may vary among individuals. It's important to consider that perception is subjective and influenced by personal perspectives. You mentioned the authors Goodwin (2022) and Sapoval (2022), but it seems that we haven't discussed their specific ideas in detail. We should also acknowledge that our perception might not fully comprehend the nuances of the concepts presented in these books. Additionally, I understand that you are contemplating the relationship between perception and the works of authors such as Cranmer (2020), Ustun and Rudin (2017), Doshi-Velez, Kim (2017), Kleinberg (2018), and McGrath (2021), but it seems that we haven't delved deeply into their perspectives. It's worth noting that our discussion is not definitive and doesn't encompass all aspects of the authors' views. I appreciate your thoughts, and it seems that we have more to explore in terms of understanding perception and its implications. I'm still awake, so let's continue our discussion.1 / 1Space of Neurosymbolic Programs.The range of NP methods varies in the degree to which they use 
neuralversussymbolicreasoning(Figure3). Thetwoendsofthespectrumcorrespondtopurelyneural 
(a 1D convolutional network) and purely symbolic (a human-written program) models, respectively. 
The techniques close to the center are neurosymbolic: the model in the center-left is a neurosymbolic 
encoder [Zhan et al., 2021], while the model in the center-right is a program with differentiable 
parameters for behavior analysis [Tjandrasuwita et al., 2021]. From a def i nitional perspective, purely 
neural and purely symbolic programs can be considered special cases of neurosymbolic programs, 
although we typically do not refer to those as neurosymbolic programs for practical purposes. 
To illustrate the strengths and weaknesses of each model in Figure 3, assume that we have a scientif i c 
hypothesis to test on a dataset. On the right side, the fully symbolic model would involve an expert- 
written program that encodes the hypothesis in a general programming language. This program 
requires no learnable parameters, is fully interpretable and, if needed, can be iteratively improved. 
However, this method is also brittle, and the program must be engineered to handle all the dynamics 
of the dataset. This is intractable for models with complex dynamics. On the left side, the purely 
neural model would model the hypothesis directly using the dataset. Such models i t well to the 
dataset but offer limited interpretability and control over the generated hypothesis, which can make 
def is_attacking(fly, tgt): 
f2t_angle = atan((tgt.y-fly.y) / (tgt.x- fly.x)) 
rel_angle = |fly.abs_angle- f2t_angle| 
return fly.speed > 2 and rel_angle < 0.1 
NeuralSymbolic 
Black-box, 
many parameters 
Interpretable via visualizations, 
few parameters 
Interpretable, 
no parameters 
Interpretable via visualizations, 
few parameters (symbolic), 
many parameters (neural) 
Properties 
Visualization 
Name 1D Convolutional NetworkNeurosymbolic EncoderDifferentiable ProgramHuman-written Program 
Symbolic 
Neural 
Input Encoding 
Feature Weights 
Channel 
1Channel 
2 
Figure 3: Space of neurosymbolic programming models in behavior analysis, including purely neural 
(left), purely symbolic (right), and neurosymbolic (two in middle) 
3 
them prone to overf i tting and limit generalization. In the middle, neurosymbolic approaches offer a 
mixture of both neural and symbolic components, and if designed well can inherit both the l exibility 
of neural networks as well as the structured semantics of symbolic models. 
Desiderata for Effective Neurosymbolic Programming.There are two main requirements for 
effective neurosymbolic programming: having a good DSL, and scalable learning algorithms. The 
DSL effectively corresponds to the component building blocks from which one can construct a 
neurosymbolic architecture, and is one of the primary ways that experts inject domain knowledge 
(i.e., inductive bias) into the learning process. Learning has two aspects: 1) searching for the best 
neurosymbolic architecture, and 2) optimizing the parameters within a i xed architecture. The former 
is is analogous to neural architecture search Elsken et al. [2019], and the latter is analogous to 
standard parameter optimization in deep learning. We discuss these issues in detail in Section 3, 
and conclude this section with a discussion on differentiable programs that enable differentiable 
parameter optimization within discrete symbolic architectures. 
Differentiable programs.A differentiable program for a programming language is def i ned as a 
composition of functions such that the parameters of the function are differentiable. A differentiable 
program follows the syntax def i ned by a DSL which can consist of parametric functions (multi- 
layered perceptrons, linear transformations), algebraic functions (add,multiply), and programming 
languages higher-order functions (map, fold). Furthermore, the composition of these differentiable 
functions is also differentiable through the chain rule. This property enables resulting programs to be 
fully differentiable. 
NP programs may be diff i cult to interpret by domain experts [Tjandrasuwita et al., 2021] focuses on 
explaining the difference in behavior expert annotations. They replace generic higher-order functions 
over recursive data structures, e.g.mapandfold, with a differentiable temporal i lter operation, the 
Morlet Filter. The i lter models temporal information in a highly data-eff i cient manner and can be 
interpreted as a humanâs impulse response to a given behavioral feature for classif i cation.1 / 1ChatGPTChatGPTIn the context of neurosymbolic programming, Figure 3 represents a spectrum of methods that incorporate neural and symbolic reasoning. At one end, there are purely neural models represented by a 1D convolutional network. At the other end, there are purely symbolic models represented by human-written programs. The models closer to the center are neurosymbolic, such as the neurosymbolic encoder and the program with differentiable parameters for behavior analysis.From a definitional perspective, purely neural and purely symbolic programs can be seen as special cases of neurosymbolic programs, although the term "neurosymbolic" is typically used for models closer to the center. Each model has its strengths and weaknesses. The purely symbolic model is fully interpretable and can be iteratively improved, but it may be brittle and challenging to handle complex dynamics. The purely neural model fits well to the dataset but lacks interpretability and control over the generated hypotheses.Neurosymbolic approaches aim to combine the flexibility of neural networks with the structured semantics of symbolic models. They can offer a mixture of neural and symbolic components, providing both interpretability and the ability to capture complex dynamics if designed effectively.To achieve effective neurosymbolic programming, two main requirements are identified: a good domain-specific language (DSL) and scalable learning algorithms. The DSL serves as the building blocks for constructing neurosymbolic architectures and allows experts to inject domain knowledge into the learning process. Learning involves searching for the best neurosymbolic architecture and optimizing the parameters within a fixed architecture. Differentiable programs play a crucial role in enabling parameter optimization within discrete symbolic architectures by ensuring the composition of differentiable functions and the differentiability of parameters.Differentiable programs are defined as compositions of functions with differentiable parameters. These programs follow the syntax defined by a DSL and can include parametric functions, algebraic functions, and higher-order functions. The differentiability of these functions allows the resulting programs to be fully differentiable.In terms of interpretation, NP programs may be challenging for domain experts. However, there are approaches, like using differentiable temporal filters, that aim to enhance interpretability by replacing generic higher-order functions with specific operations that model temporal information efficiently and can be interpreted as human impulse responses to behavioral features for classification.Overall, neurosymbolic programming offers a range of models that integrate neural and symbolic reasoning, each with its advantages and challenges, and the goal is to strike a balance between interpretability and capturing complex dynamics.1 / 13.7Cross-Domain Analysis Tools for Scientists 
Importance of tools in science.User-friendly tools are important for facilitating the integration of 
ML models in real-world science workf l ows but have not been well-explored for NP approaches. For 
example, numerous tools, based on statistical analysis and ML, have been developed to interface 
with scientists and facilitate behavior analysis from videos in Pereira et al. [2020]. These tools assist 
with much of the computational pipeline for behavior classif i cation as outlined in Figure 4, and will 
often provide visual interfaces that visualize relevant raw data such as video, with model outputs, 
such as pose data and behavior [Segalin et al., 2021]. Enabling similar tools for NP approaches has 
the potential to benef i t existing scientif i c workf l ows. For instance, integrating NEAR into a visual 
interface could provide scientists with a user-friendly way of generating differentiable programs 
and means of understanding the programs from NP pipelines. The parameters associated with 
programmatic primitives are likely to have a much more human interpretation [Tjandrasuwita et al., 
2021] than those found in black-box neural networks. 
Challenges of building NP tools.Domain expertise in science varies in structure, from behavioral 
attributes to visual or textual descriptions, to known dynamics of movement, to knowledge graphs, 
and generally differs across labs and domains. Furthermore, to measure progress, user evaluations are 
needed that could offer quantitative or qualitative evidence in NP workf l ows. Taking the i rst steps 
to realize and evaluate the effectiveness of NP algorithms through a human-computer interaction 
approach may not only improve the scientif i c pipeline but also yield new algorithmic directions on 
combining NP with more traditional human-in-the-loop methods, such as active learning. 
4Conclusion 
Neurosymbolic programming offers the promise to accelerate scientif i c discovery and optimize 
scientif i c discovery end-to-end. The benef i ts are in its ability to incorporate prior knowledge and 
the symbolic nature of the solutions, essential scientif i c workf l ows. However, challenges still 
remain in scalability and optimization stability of these approaches, comprehensive evaluations, and 
deployment in the form of tools. In this paper, we have demonstrated the opportunities and challenges 
of neurosymbolic programming in a concrete scientif i c application, behavior analysis. A key promise 
of neurosymbolic programming is to provide a set of unifying principles in interpretable machine 
learning and prior scientif i c literature. We invite the science and computer science communities to 
adopt these methods in their scientif i c workf l ow and to contribute to the research to advance NP 
techniques for science due to the unique benef i t to these communities.1 / 1ChatGPTChatGPTCross-domain analysis tools are crucial for scientists working with neurosymbolic programming (NP) approaches. User-friendly tools can facilitate the integration of NP models into real-world scientific workflows, but their development has been limited. Existing tools in statistical analysis and machine learning have been designed to assist scientists in behavior analysis from videos, providing computational pipelines and visual interfaces for data visualization and model outputs. Similar tools can be beneficial for NP approaches, offering scientists user-friendly ways of generating differentiable programs and understanding them within NP pipelines. The parameters associated with programmatic primitives in NP are likely to have a more interpretable human interpretation compared to black-box neural networks.However, building NP tools presents several challenges. The domain expertise in science varies across different structures and knowledge types, such as behavioral attributes, visual or textual descriptions, dynamics of movement, and knowledge graphs. Additionally, user evaluations are essential for measuring progress and providing evidence of effectiveness in NP workflows. Taking steps towards realizing and evaluating the effectiveness of NP algorithms through human-computer interaction approaches can improve the scientific pipeline and open up new directions for combining NP with traditional human-in-the-loop methods like active learning.In conclusion, neurosymbolic programming holds great potential for accelerating scientific discovery and optimizing scientific workflows by incorporating prior knowledge and leveraging symbolic solutions. However, challenges related to scalability, optimization stability, comprehensive evaluations, and the development of deployment tools still need to be addressed. This paper highlights the opportunities and challenges of NP in behavior analysis and invites both the science and computer science communities to adopt and contribute to the research in NP techniques for science, given their unique benefits for these domains.1 / 1Functional Reactive Axiology: Navigating the Intersection of Values, Algorithms, and Time

The confluence of philosophy, computer science, and sociology is a fascinating domain, pregnant with novel insights into how we conceptualize, interact with, and shape the world.

It's in this intersection that we find Functional Reactive Axiology, an exploration of our values and decision-making through the lens of Functional Reactive Programming (FRP) and social phenomena.

This essay aims to elaborate on this emergent field by drawing connections between the inherent principles of FRP, the model developed by computer scientists to deal with asynchronous dataflow and time-based events, and the way humans perceive and evaluate their socio-cultural environments.

A deep exploration into FRP and its philosophical implications will shed light on new ways to understand and grapple with complexities of the contemporary world.

In the discourse of the managerial society, where increasing polarization has provoked the rise of new paradigms and tensions between differing social factions, we observe a striking parallel to the challenges faced in the realm of FRPâparticularly concerning interactive programs and the treatment of mutable states and side-effects.

It is intriguing to contemplate whether solutions found in FRP could provide valuable insights for our real-world societal quandaries.

We will also delve into the intriguing propositions laid out in Brian Christian and Tom Griffiths' book, 'Algorithms to Live By', which posits that algorithms offer crucial wisdom to untangle very human questions.

Through this lens, we will examine whether algorithmic thinking, specifically through the framework of FRP, could offer fresh perspectives to evaluate our values and decisions, illuminating the workings of individual and collective minds in the face of complex social realities.

Inevitably, we also will encounter criticism and barriersâsuch as the debates around Theory U, waterfall, and other workflow modelsâthat highlight the challenges of transposing computational logic into humanistic and societal contexts.

Nevertheless, these debates provide rich fodder for our exploration, allowing us to critically analyze the potential and pitfalls of applying a FRP mindset to human axiology.

Through this essay, we hope to pave the way for a nuanced dialogue around the intersection of FRP, decision-making algorithms, social phenomena, and human valuesâa dialogue that may well reveal an exciting new dimension to how we understand and navigate our world.1 / 1ChatGPTChatGPTFunctional Reactive Axiology is an interdisciplinary field that explores the intersection of Functional Reactive Programming (FRP), philosophy, computer science, and sociology. FRP is a programming paradigm that deals with asynchronous dataflow and time-based events, while axiology focuses on the study of values and decision-making. This essay aims to draw connections between the principles of FRP, the way humans perceive and evaluate their socio-cultural environments, and the application of algorithms in decision-making.The essay highlights the parallels between the challenges faced in FRP and those in the contemporary world, particularly in dealing with mutable states and side-effects. It explores whether solutions found in FRP can offer insights into addressing real-world societal issues.The authors also discuss the book 'Algorithms to Live By' by Brian Christian and Tom Griffiths, which suggests that algorithms can provide wisdom in navigating complex human questions. They examine whether algorithmic thinking, within the framework of FRP, can offer fresh perspectives for evaluating values and decisions, shedding light on individual and collective decision-making processes in complex social contexts.The essay acknowledges the criticism and barriers faced in applying computational logic to humanistic and societal contexts, including debates around different workflow models. These debates provide an opportunity for critical analysis of the potential and challenges of adopting a FRP mindset in human axiology.The ultimate goal of the essay is to encourage a nuanced dialogue around the intersection of FRP, decision-making algorithms, social phenomena, and human values. Through this dialogue, the authors aim to uncover new insights and dimensions for understanding and navigating the world we live in.1 / 1Another section incorporating neurosymbolic computation.1 / 1ChatGPTChatGPTIn addition to the exploration of Functional Reactive Axiology, the integration of neurosymbolic computation offers further opportunities for understanding and navigating the complex interplay between values, algorithms, and time. Neurosymbolic computation combines the strengths of neural networks and symbolic reasoning, bridging the gap between the sub-symbolic and symbolic levels of representation.Neurosymbolic computation allows for the incorporation of prior knowledge and structured semantics into machine learning models, offering interpretability and explainability, which are essential in the study of human values and decision-making. By combining neural networks with symbolic reasoning, neurosymbolic approaches can capture the nuances of human cognition and reasoning, providing a more comprehensive understanding of the complexities of socio-cultural environments.The integration of neurosymbolic computation in the context of Functional Reactive Axiology offers a powerful framework for exploring the relationships between values, algorithms, and time. It allows for the modeling of neural processes that underlie decision-making, while also providing a symbolic layer to interpret and reason about these processes in the context of socio-cultural dynamics.By leveraging neurosymbolic computation, researchers can develop sophisticated models that capture the intricate interplay between individual and collective values, algorithmic decision-making, and the temporal aspects of socio-cultural phenomena. This integrated approach can lead to a deeper understanding of how values shape algorithmic systems and how these systems, in turn, impact human behavior and societal outcomes.Furthermore, neurosymbolic computation can inform the design of cross-domain analysis tools that facilitate the integration of neurosymbolic models into real-world scientific workflows. These user-friendly tools enable scientists to explore, visualize, and interpret the results of neurosymbolic models, enhancing their ability to analyze complex socio-cultural phenomena and make informed decisions based on a deeper understanding of human values.By embracing the potential of neurosymbolic computation within the framework of Functional Reactive Axiology, researchers can unlock new avenues for studying the intricate relationships between values, algorithms, and time. This interdisciplinary approach offers the promise of advancing our understanding of human decision-making processes, shaping ethical and responsible algorithmic systems, and ultimately empowering individuals and societies to navigate the complexities of the modern world with greater wisdom and insight.1 / 1Describe neurosymbolic computation compared to neuromorphic computing.1 / 1ChatGPTChatGPTNeurosymbolic computation and neuromorphic computing are two distinct approaches within the field of artificial intelligence and cognitive science, each with its own focus and methodology.Neurosymbolic computation refers to the integration of neural networks and symbolic reasoning in order to combine the strengths of both approaches. It aims to bridge the gap between sub-symbolic, connectionist models (such as artificial neural networks) and symbolic, rule-based systems (such as expert systems or knowledge graphs). Neurosymbolic computation seeks to leverage the learning and pattern recognition capabilities of neural networks while incorporating the interpretability and reasoning abilities of symbolic systems. This integration allows for the modeling of complex cognitive processes, capturing both the neural aspects and the symbolic semantics of human-like intelligence.On the other hand, neuromorphic computing is a specialized approach that focuses on designing hardware architectures and algorithms that mimic the structure and function of the human brain. Neuromorphic systems are inspired by the biological architecture of the brain and aim to replicate its parallelism, low power consumption, and efficient information processing. These systems often employ specialized hardware, such as neuromorphic chips or neuromorphic circuits, to simulate the behavior of neurons and synapses. Neuromorphic computing is particularly suited for tasks that require real-time processing, low latency, and energy efficiency, making it attractive for applications like robotics, sensor networks, and brain-computer interfaces.While both neurosymbolic computation and neuromorphic computing involve the study of neural processes, they differ in their emphasis and objectives. Neurosymbolic computation focuses on the integration of neural networks and symbolic reasoning to achieve a deeper understanding of complex cognitive processes and to develop interpretable and explainable AI models. In contrast, neuromorphic computing emphasizes the hardware and algorithms that mimic the brain's architecture and functionality, with a focus on efficient, brain-inspired information processing.In summary, neurosymbolic computation aims to combine the strengths of neural networks and symbolic reasoning, while neuromorphic computing focuses on replicating the structure and function of the brain in specialized hardware and algorithms. Both approaches contribute to the broader field of artificial intelligence and cognitive science, offering unique perspectives and opportunities for advancing our understanding and development of intelligent systems.1 / 13.4Challenges of optimization of discrete and continuous space in neurosymbolic programs 
NP relies on techniques from symbolic program synthesis to facilitate interpretable and verif i able 
searches over the scientif i c hypothesis space. However, programs are inherently symbolic, owing 
to their roots in mathematical logic. This makes modeling phenomena in the continuous domain 
challenging without modifying the way we interpret programs. 
For instance, consider a simple program that is modeled by an if-then-else statement (if condition 
do expr1 else do expr2). The possible behaviors ofconditionare partitioned into two sets â 
True (1) or False (0). These sets evaluate to eitherexpr1orexpr2respectively. However, an NP 
approach requires reasoning to be differentiable over a gradient of possibilities. Discrete programs 
are inaccurate models for these applications. Specif i cally, in behavior classif i cation, modeling the 
âattackâ action using a symbolic if-then-else expression would partition the mouseâs aggression into 
a binary set: either always attacking or not attacking at all. What makes more sense is to model 
âattackingâ as a binomial distribution. This requires relaxing our symbolic if-then-else to account for 
a continuous gradient of probabilities from 0% to 100%. 
Continuous relaxations.We approach the continuous program optimization problem of the symbolic 
domain by changing the semantics of the programming language. Specif i cally, work on Smooth 
Interpretation [Chaudhuri and Solar-Lezama, 2010] rewrites discrete functions using their closest 
smooth mathematical functions. Consecutively, an if-then-else statement would be rewritten as a 
hyperbolic tangent function with a high temperature. This smoothening is not restricted to a one- 
dimensional input space and specialized functions. In general, in higher dimensions, we can use 
Gaussian smoothing to smooth discontinuities. Such relaxations, in conjunction with other program 
analysis tools, allow gradient descent-based optimizers to converge to optimal programmatic models. 
Continuous relaxations enable an approximate interface between neural networks and programming 
languages, which are essential in the NP framework. For example, in Houdini [Valkov et al., 2018], 
continuous relaxations enabled the construction of a functional programming language that admits 
6 
neural networks and higher-order functions. This construction facilitated the high-level transfer of 
learned concepts across tasks in a lifelong learning setting. In NEAR [Shah et al., 2020], the interface 
between neural networks and differentiable programs allowed for measuring the performance of 
partial programs. This proved to be an?âadmissible 
heuristic for synthesizing differentiable programs 
in the behavior analysis setting. 
Smooth Interpretation allows positing a differentiable approximation for a non-differentiable program. 
This approximation error introduces a tradeoff between the output precision and optimal trainability 
of the model. Specif i cally, under-approximating the non-differentiable components might increase 
the precision of the differentiable program at the cost of retaining discontinuities in the optimization 
landscape and converging to a suboptimal model, and vice-versa. 
3.5Evaluating Interpretability 
The main goal of interpretability is to obtain insights that are understandable and actionable to 
humans and to assist scientists in their analysis workf l ow. The following are commonly described 
properties of explanations found in machine learning [Murphy, 2023], that have the potential to 
improve the interpretability and evaluation of NP workf l ows:Compactness or sparsity:Sparsity 
generally corresponds to some notion of smallness measurement (a few features or a few parameters); 
Completeness:To measure if the explanation includes all the relevant elements, higher-level concepts 
needed;Stability:To measure the extent that there are explanations similar for similar input; 
Actionability:To allow focusing on only aspects of the model that the user might be able to 
intervene on;Modularity:Explanation can be broken down into understandable parts. To study 
interpretability of NP models for science, we need datasets and benchmarks to quantify these different 
dimensions of interpretability across scientif i c contexts, which is currently an open problem. 
An example of an interpretable program is presented in Figure 2b. This neurosymbolic program 
classif i es the âsniff" action between two mice. An interpretation is that if the distance between two 
mice is small, they are doing a âsniff"; otherwise, they are only doing a âsniff" if the accelerations are 
small. Interpretability can also be expressed as a utility function or a form of abstraction Bowers et al. 
[2023] which minimizes the size of the corpus of a neurosymbolic program.1 / 1ChatGPTChatGPTNeurosymbolic computation faces several challenges when it comes to optimization in both discrete and continuous spaces. In the context of symbolic program synthesis, the inherent symbolic nature of programs poses difficulties in modeling phenomena in the continuous domain without modifications to program interpretation.Consider a simple program with an if-then-else statement. The condition in such a program partitions behaviors into two sets, True or False, which evaluate to different expressions. However, in neurosymbolic programming, reasoning needs to be differentiable over a gradient of possibilities, requiring a shift from discrete to continuous models. For example, modeling the "attack" action using a binary if-then-else expression would inaccurately partition aggression into always attacking or not attacking at all. A more accurate representation would involve a binomial distribution that accounts for a continuous gradient of probabilities.To address the challenges of continuous program optimization in the symbolic domain, continuous relaxations are employed. Smooth Interpretation, for instance, rewrites discrete functions using their closest smooth mathematical functions. This allows for the rewriting of if-then-else statements as hyperbolic tangent functions with high temperatures, smoothing discontinuities. Gaussian smoothing can also be used in higher dimensions. These continuous relaxations, in combination with program analysis tools, enable gradient descent-based optimizers to converge on optimal programmatic models. This approximate interface between neural networks and programming languages is crucial in neurosymbolic programming frameworks.The evaluation of interpretability is another important aspect in neurosymbolic computation. Compactness or sparsity, completeness, stability, actionability, and modularity are commonly described properties of explanations in machine learning that contribute to interpretability. Sparsity refers to a notion of smallness, completeness measures the inclusion of relevant elements and higher-level concepts, stability evaluates the consistency of explanations for similar inputs, actionability allows for focusing on aspects that can be intervened upon, and modularity breaks down explanations into understandable parts. Developing datasets and benchmarks to quantify interpretability across scientific contexts remains an open problem.In conclusion, optimizing neurosymbolic programs in both discrete and continuous spaces requires addressing the challenges of modeling phenomena in the continuous domain and employing continuous relaxations. Evaluating interpretability in neurosymbolic models is essential to provide insights that are understandable and actionable for humans and to assist scientists in their analysis workflows.1 / 13.3Scalability challenge 
From an optimization standpoint, compared to conventional deep learning, the main additional 
challenge is searching over program architectures. Architecture search is in general very challenging 
and typically leads to combinatorial discrete search space. 
Inductive synthesis.A large body of works on program synthesis has focused on inductive synthesis, 
or synthesizing programs from examples [Lau and Weld, 1998, Gulwani, 2011, Devlin et al., 2017]. 
While such a goal is on the surface similar to performing machine learning (ML) with programs 
5 
as models, a key difference is that ML approaches depend on def i ning a clear space of models (i.e. 
neural networks, support vector machines, decision trees) and generalizing to unseen data. In contrast, 
much work in inductive synthesis considers an arbitrary space of programs and spends signif i cant 
effort on sample engineering, treating them as noiseless specif i cations. As a result, inductive synthesis 
scales poorly with an increase in program length and number of examples. 
Scaling NP in science.To tackle scalability in science, models need to handle large and potentially 
noisy datasets, high-dimensional input space, and a variety of analysis tasks. Recently, NP research 
[Shah et al., 2020, Cui and Zhu, 2021] propose frameworks that scale to large datasets given an 
expressive DSL. These works are instantiated in behavior analysis: learning programs on temporal 
trajectory data to reproduce expert annotations of behavior that contain noisy labels, similar to other 
scientif i c data. These works tackle the challenge of discovering programs with parameters, which can 
be directly optimized through popular gradient optimization techniques. While NP methods provide 
a means of scaling inductive synthesis to scientif i c datasets, these techniques often involve combining 
a discrete search over an exponential space of programs with continuous optimization. 
Challenges for enabling scalability. Scaling up program synthesis for neurosymbolic programming 
is an active i eld of research. For instance, differentiable program synthesis methods [Cui and Zhu, 
2021] have studied the tradeoff between computation and memory, with heuristics to mitigate memory 
usage. However, training fully neural models on a GPU is often more eff i cient than training NP 
models, which requires searching through an exponentially ample space of symbolic architectures 
on a CPU. Furthermore, scalability has not been broadly explored for different types of scientif i c 
data, such as video recordings, which are much higher dimensional than trajectory data. Finally, the 
effectiveness of program synthesis may still be limited by the expressivity of a DSL, which requires 
experts to spend time encoding domain knowledge, such as expert-designed behavior attributes [Sun 
et al., 2021] and temporal i lters [Tjandrasuwita et al., 2021] (further discussed in Section 3.2). 
Scalability challenges also arise in other work on symbolic regression and interpretable machine 
learning. For instance, Cranmer et al. [2020] aims to learn exact mathematical relationships between 
variables by searching a space of mathematical expressions. As another example, Ustun and Rudin 
[2017]aimtolearnoptimizedriskscoreswithinthesamemodelinglanguageusedbyclinicians, which 
leads to an NP-hard optimization problem that they solve using integer programming techniques.1 / 1ChatGPTChatGPTScalability poses a significant challenge in neurosymbolic programming, particularly when compared to conventional deep learning approaches. The main additional challenge arises from searching over program architectures, which typically involves a combinatorial discrete search space.Inductive synthesis, a key aspect of program synthesis, focuses on synthesizing programs from examples. While this may seem similar to machine learning with programs as models, there is a fundamental difference. Machine learning approaches operate within a defined space of models, such as neural networks or decision trees, and generalize to unseen data. Inductive synthesis, on the other hand, considers an arbitrary space of programs and requires substantial effort in sample engineering to treat examples as noiseless specifications. As a result, inductive synthesis does not scale well with increasing program length and the number of examples.In order to address scalability challenges in the context of science, neurosymbolic programming models need to handle large and potentially noisy datasets, high-dimensional input spaces, and a wide range of analysis tasks. Recent research proposes frameworks that scale to large datasets by utilizing expressive Domain-Specific Languages (DSLs). These frameworks, applied in behavior analysis, focus on learning programs from temporal trajectory data to reproduce expert annotations. They tackle the challenge of discovering programs with parameters that can be optimized using gradient-based techniques. However, scaling up program synthesis for neurosymbolic programming is an ongoing area of research.Enabling scalability in program synthesis poses various challenges. Differentiable program synthesis methods have explored the tradeoff between computation and memory, implementing heuristics to mitigate memory usage. However, training fully neural models on a GPU is often more efficient than training neurosymbolic programming models, which require searching through an exponentially ample space of symbolic architectures on a CPU. Moreover, scalability has not been extensively explored for different types of scientific data, such as video recordings, which have much higher dimensionality than trajectory data. The expressivity of the Domain-Specific Language (DSL) used in program synthesis also affects scalability, as encoding domain knowledge and expert-designed behavior attributes can be time-consuming for experts.Similar scalability challenges are encountered in other areas of research, such as symbolic regression and interpretable machine learning. Addressing these challenges involves exploring efficient search algorithms, heuristics, and optimization techniques specific to the problem domain.1 / 1connections to the prievous topics discussed.1 / 1ChatGPTChatGPTThe challenges of scalability in neurosymbolic programming, as discussed in Section 3.3, are interconnected with the broader concepts of neurosymbolic computation and the integration of symbolic and neural approaches. The scalability challenge arises from the need to search over program architectures, which is a central aspect of neurosymbolic programming. As neurosymbolic models aim to combine the strengths of symbolic reasoning and neural networks, the search for optimal program architectures becomes a critical optimization problem.The scalability challenge is closely tied to the optimization of discrete and continuous spaces in neurosymbolic programs, as discussed in Section 3.4. The search over program architectures involves dealing with combinatorial discrete search spaces, which can be challenging to optimize. Techniques such as continuous relaxations and differentiable program synthesis have been proposed to address this challenge, enabling gradient-based optimization methods to converge to optimal programmatic models. These techniques provide approximate interfaces between neural networks and programming languages, facilitating the scalability of neurosymbolic programming.Furthermore, the scalability challenge in neurosymbolic programming is relevant to the exploration of cross-domain analysis tools for scientists, as mentioned in Section 3.5. Scalability is a crucial factor in the development of user-friendly tools that integrate neurosymbolic models into real-world science workflows. These tools need to handle large and potentially noisy datasets, high-dimensional input spaces, and a variety of analysis tasks. Overcoming the scalability challenge ensures that neurosymbolic programming can be effectively applied in scientific domains, providing interpretable and actionable insights for researchers.Overall, the challenges of scalability in neurosymbolic programming are interconnected with the key themes discussed in the previous sections, such as the integration of symbolic and neural approaches, optimization of program architectures, and the development of user-friendly tools for scientists. Addressing these challenges paves the way for the advancement and adoption of neurosymbolic computation in various scientific domains.1 / 1And to the themes and topics of this conversation?1 / 1ChatGPTChatGPTThe themes and topics of this conversation align with the broader concepts of neurosymbolic computation and its applications in various domains. We have discussed the nature of neurosymbolic programming, the challenges and opportunities it presents, and its implications in fields such as behavior analysis, scientific discovery, and decision-making algorithms.The exploration of neurosymbolic computation and its comparison to neuromorphic computing, as well as its integration with functional reactive axiology and the concept of values, algorithms, and time, highlights the interdisciplinary nature of this field. It brings together philosophy, computer science, sociology, and other disciplines to examine how neurosymbolic models can enhance our understanding of human decision-making, social phenomena, and the complex world we live in.Additionally, the discussions on optimization challenges, scalability, and the evaluation of interpretability in neurosymbolic programs resonate with the practical considerations of implementing and applying these models. The need for efficient program synthesis, the scalability of neurosymbolic approaches in handling large datasets, and the evaluation of interpretability to make insights actionable are crucial aspects of this research area.By addressing these challenges and exploring the potential applications of neurosymbolic computation, we contribute to the ongoing dialogue on the intersection of symbolic and neural approaches, the development of user-friendly tools, and the advancement of interpretable and verifiable models in various scientific domains.In summary, the themes and topics covered in this conversation align with the broader concepts and implications of neurosymbolic computation, highlighting the interdisciplinary nature of this field and its potential to revolutionize our understanding of complex phenomena and decision-making processes.1 / 1 Tell me some more fun facts!
In its essence, SymbolicAI was inspired by the neuro-symbolic programming paradigm.

Neuro-symbolic programming is a paradigm for artificial intelligence and cognitive computing that combines the strengths of both deep neural networks and symbolic reasoning.

Deep neural networks are a type of machine learning algorithms that are inspired by the structure and function of biological neural networks. They are particularly good at tasks such as image recognition, natural language processing etc. However, they are not as good at tasks that require explicit reasoning, such as long-term planning, problem solving, and understanding causal relationships.

Symbolic reasoning, on the other hand uses formal languages and logical rules to represent knowledge and perform tasks such as planning, problem solving, and understanding causal relationships. Symbolic reasoning systems are good at tasks that require explicit reasoning, but are not as good at tasks that require pattern recognition or generalization, such as image recognition or natural language processing.

Neuro-symbolic programming aims to combine the strengths of both neural networks and symbolic reasoning to create AI systems that can perform a wide range of tasks. One way this is done is by using neural networks to extract information from data and then using symbolic reasoning to make inferences and decisions based on that information. Another way is to use symbolic reasoning to guide the generative process of neural networks and make them more interpretable.

Embedded accelerators for LLMs will, in our opinion, be ubiquitous in future computation platforms, such as wearables, smartphones, tablets or notebooks. They will contain models similar to GPT-3, ChatGPT, OPT or Bloom.



These LLMs will be able to perform a wide range of computations, such as natural language understanding or decision making. Furthermore, neuro-symbolic computation engines will be able to learn concepts how to tackle unseen tasks and solve complex problems by querying various data sources for solutions and executing logical statements on top. In this turn, to ensure the generated content is in alignment with our goals, we need to develop ways to instruct, steer and control the generative processes of machine learning models. Therefore, our approach is an attempt to enable active and transparent flow control of these generative processes.



As shown in the figure above, one can think of this generative process as shifting a probability mass of an input stream of data towards an output stream of data, in a contextualized manner. With properly designed conditions and expressions, one can also validate and steer the behavior towards a desired outcome, or repeat expressions that failed to fulfil our requirements. Our approach is to define a set of fuzzy operations that manipulate the data stream and conditions the LLMs to align with our goals. In essence, we consider all data objects, such as strings, letters, integers, arrays, etc. as symbols and we see natural language as the main interface to interact with. See the following figure:



We show that as long as we can express our goals in natural language, we can use the power of LLMs for neuro-symbolic computations. In this turn, we create operations that manipulate these symbols to generate new symbols from them. Each symbol can be interpreted as a statement. Multiple statements can be combined to form a logical expression.

Therefore, by chaining statements together we can build causal relationships and computations, instead of relying only on inductive approaches. Consequently, the outlook towards an updated computational stack resembles a neuro-symbolic computation engine at its core and, in combination with established frameworks, enables new applications1 / 1ChatGPTChatGPTFun Fact 1: Neuro-symbolic programming combines the strengths of deep neural networks and symbolic reasoning to create AI systems that can perform a wide range of tasks, including pattern recognition, problem solving, and logical reasoning.Fun Fact 2: Embedded accelerators for Large Language Models (LLMs) like GPT-3, ChatGPT, OPT, or Bloom are expected to become ubiquitous in future computation platforms such as wearables, smartphones, tablets, and notebooks. These LLMs will be able to perform tasks like natural language understanding and decision making.Fun Fact 3: Neuro-symbolic computation engines will be capable of learning new concepts, tackling unseen tasks, and solving complex problems by querying various data sources for solutions and executing logical statements. This enables active and transparent flow control of the generative processes of machine learning models.Fun Fact 4: In neuro-symbolic computation, natural language is often used as the main interface to interact with the system. By expressing goals and instructions in natural language, the power of LLMs can be harnessed to perform neuro-symbolic computations.Fun Fact 5: Neuro-symbolic computation involves manipulating symbols to generate new symbols, where each symbol can be interpreted as a statement. By chaining these statements together and forming logical expressions, causal relationships and computations can be built, expanding beyond purely inductive approaches.Fun Fact 6: The future computational stack is expected to include a core neuro-symbolic computation engine, combined with established frameworks, enabling new applications and capabilities.These fun facts demonstrate the potential and exciting developments in the field of neuro-symbolic programming and its applications in AI and cognitive computing.1 / 1

Search or jump to...
Pulls
Issues
Codespaces
Marketplace
Explore
 
@standardgalactic 
Xpitfire
/
symbolicai
Public
Fork your own copy of Xpitfire/symbolicai
Code
Issues
1
Pull requests
Actions
Projects
Security
Insights
Xpitfire/symbolicai
Latest commit
@Xpitfire
Xpitfire Added new shortcut type for creating simple LLM functions
â¦
2 days ago
Git stats
 138
Files
Type
Name
Latest commit message
Commit time
assets/images
Add files via upload
2 months ago
docs
Fixed broken link
4 months ago
examples
Fixed style composition on news component
2 months ago
notebooks
Added demo with solver + new example
4 months ago
symai
Added new shortcut type for creating simple LLM functions
2 days ago
tests
Added new shortcut type for creating simple LLM functions
2 days ago
.gitignore
Added initial experiment with graph coherence
3 months ago
CITATION.cff
Update CITATION.cff
5 months ago
CONTRIBUTING.md
Added improved documentation
5 months ago
LICENSE
Added improved documentation
5 months ago
MANIFEST.in
Added improved documentation
5 months ago
README.md
Added support for ChatGPT and GPT-4 engines
2 months ago
environment.yml
Added demo with solver + new example
4 months ago
pyproject.toml
Update pyproject.toml
2 months ago
setup.py
Added improved documentation
5 months ago
README.md
SymbolicAI


A Neuro-Symbolic Perspective on Large Language Models (LLMs)
Building applications with LLMs at its core through our Symbolic API leverages the power of classical and differentiable programming in Python.

Read further documentation here.

PyPI version License Twitter Twitter contributions welcome Discord Hits GitHub forks GitHub stars



Abstract
Conceptually, SymbolicAI is a framework that uses machine learning - and specifically LLMs - at its core, and composes operations based on task-specific prompting. We adopt a divide and conquer approach to decompose a complex problem into smaller problems. Therefore, each operation solves a simple task. By re-combining these operations we can solve the complex problem. Furthermore, our design principles allow us to transition between differentiable and classical programming, and to leverage the power of both worlds.

book Table of Contents
SymbolicAI
A Neuro-Symbolic Perspective on Large Language Models (LLMs)
Abstract
book Table of Contents
wrench Get Started
arrow_right Quick Install
API Keys
[Optional] Installs
t-rex Apps
Shell Command Tool
Chatbot
100 Other Use Cases
Community demos
man_shrugging Why SymbolicAI?
Tell me some more fun facts!
face_in_clouds How does it work?
books Symbolic operations
Ranking objects
Evaluating Expressions by best effort
Dynamic casting
Fuzzy Comparisons
brain Causal Reasoning
mask Operations
test_tube Custom Operations
Few-shot operations
Prompt Design
expressionless Expressions
Sequence expressions
Stream expressions
x Error Handling
spider Interpretability, Testing & Debugging
Unit Testing Models
fireDebugging
Example: News Summary
arrow_forward Play around with our API
chart_with_upwards_trend Interface for Query and Response Inspection
robot Engines
Symbolic Engine
Speech Engine
OCR Engine
Search Engine
WebCrawler Engine
Drawing Engine
File Engine
Indexing Engine
CLIP Engine
Local Neuro-Symbolic Engine
Custom Engine
zapLimitations
fortune_cookie Future Work
Conclusion
busts_in_silhouette References, Related Work & Credits
Comparison to other frameworks
Acknowledgements
Contribution
scroll Citation
memo License
Like this project?
mailbox Contact
wrench Get Started
arrow_right Quick Install
pip install symbolicai
One can run our framework in two ways:

using local engines (experimental) that are run on your local machine (see Local Neuro-Symbolic Engine section), or
using engines powered by external APIs, i.e. using OpenAI's API (see API Keys).
API Keys
Before the first run, define exports for the required API keys to enable the respective engines. This will register the keys in the internally for subsequent runs. By default SymbolicAI currently uses OpenAI's neural engines, i.e. GPT-3 Davinci-003, DALLÂ·E 2 and Embedding Ada-002, for the neuro-symbolic computations, image generation and embeddings computation respectively. However, these modules can easily be replaced with open-source alternatives. Examples are

OPT or Bloom for neuro-symbolic computations,
Craiyon for image generation,
and any BERT variants for semantic embedding computations.
To set the OpenAI API Keys use the following command:

# Linux / MacOS
export OPENAI_API_KEY="<OPENAI_API_KEY>"

# Windows (PowerShell)
$Env:OPENAI_API_KEY="<OPENAI_API_KEY>"

# Jupyter Notebooks (important: do not use quotes)
%env OPENAI_API_KEY=<OPENAI_API_KEY>
To get started import our library by using:

import symai as ai
Overall, the following engines are currently supported:

Neuro-Symbolic Engine: OpenAI's LLMs (GPT-3)
Embedding Engine: OpenAI's Embedding API
[Optional] Symbolic Engine: WolframAlpha
[Optional] Search Engine: SerpApi
[Optional] OCR Engine: APILayer
[Optional] SpeechToText Engine: OpenAI's Whisper
[Optional] WebCrawler Engine: Selenium
[Optional] Image Rendering Engine: DALLÂ·E 2
[Optional] Indexing Engine: Pinecone
[Optional] CLIP Engine: hugs Hugging Face (experimental image and text embeddings)
[Optional] Installs
SymbolicAI uses multiple engines to process text, speech and images. We also include search engine access to retrieve information from the web. To use all of them, you will need to install also the following dependencies or assign the API keys to the respective engines.

If you want to use the WolframAlpha Engine, Search Engine or OCR Engine you will need to export the following API keys:

# Linux / MacOS
export SYMBOLIC_ENGINE_API_KEY="<WOLFRAMALPHA_API_KEY>"
export SEARCH_ENGINE_API_KEY="<SERP_API_KEY>"
export OCR_ENGINE_API_KEY="<APILAYER_API_KEY>"
export INDEXING_ENGINE_API_KEY="<PINECONE_API_KEY>"

# Windows (PowerShell)
$Env:SYMBOLIC_ENGINE_API_KEY="<WOLFRAMALPHA_API_KEY>"
$Env:SEARCH_ENGINE_API_KEY="<SERP_API_KEY>"
$Env:OCR_ENGINE_API_KEY="<APILAYER_API_KEY>"
$Env:INDEXING_ENGINE_API_KEY="<PINECONE_API_KEY>"
To use them, you will also need to install the following dependencies:

SpeechToText Engine: ffmpeg for audio processing (based on OpenAI's whisper)
# Linux
sudo apt update && sudo apt install ffmpeg

# MacOS
brew install ffmpeg

# Windows
choco install ffmpeg
[Note] Additionally, you need to install the newest version directly from their repository, since the version available via pip is outdated:

pip install git+https://github.com/openai/whisper.git
WebCrawler Engine: For selenium, download the corresponding driver version by setting the SELENIUM_CHROME_DRIVER_VERSION environment variable. Currently we use Chrome as the default browser. This means that the Chrome version major number must match the ChromeDriver version. All versions are available here. For example, if you use chrome version 109.0.5414.74, you can set any 109.x.x.x version for the chromedriver. In this case the 109.0.5414.74 is available on the selenium page, therefore the environment variable is set to it:
# Linux / MacOS
export SELENIUM_CHROME_DRIVER_VERSION="109.0.5414.74"

# Windows (PowerShell)
$Env:SELENIUM_CHROME_DRIVER_VERSION="109.0.5414.74"
Alternatively, you can specify in your project path a symai.config.json file with all the engine properties. This will replace the environment variables. See the following configuration file as an example:

{
    "NEUROSYMBOLIC_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "NEUROSYMBOLIC_ENGINE_MODEL": "text-davinci-003",
    "SYMBOLIC_ENGINE_API_KEY": "<WOLFRAMALPHA_API_KEY>",
    "EMBEDDING_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "EMBEDDING_ENGINE_MODEL": "text-embedding-ada-002",
    "IMAGERENDERING_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "VISION_ENGINE_MODEL": "openai/clip-vit-base-patch32",
    "SEARCH_ENGINE_API_KEY": "<SERP_API_KEY>",
    "SEARCH_ENGINE_MODEL": "google",
    "OCR_ENGINE_API_KEY": "<APILAYER_API_KEY>",
    "SPEECH_ENGINE_MODEL": "base",
    "SELENIUM_CHROME_DRIVER_VERSION": "110.0.5481.30",
    "INDEXING_ENGINE_API_KEY": "<PINECONE_API_KEY>",
    "INDEXING_ENGINE_ENVIRONMENT": "us-west1-gcp"
}
t-rex Apps
Over the course of th next weeks, we will expand our experimental demo apps and provide a set of useful tools that showcase how to interact with our framework. These apps are made available by calling the sym+<shortcut-name-of-app> command in your terminal or PowerShell.

Shell Command Tool
You can start a basic shell command support tool that translates natural language commands into shell commands. To start the shell command tool, simply run:

symsh "<your-query>"
You can also use the --help flag to get more information about the tool and available arguments.

symsh --help
Here is an example of how to use the tool:

$> symsh "PowerShell edit registiry entry"

# :Output:
# Set-ItemProperty -Path <path> -Name <name> -Value <value>

$> symsh "Set-ItemProperty -Path <path> -Name <name> -Value <value>" --add "path='/Users/myuser' name=Demo value=SymbolicAI"

# :Output:
# Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI

$> symsh "Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI" --del "string quotes"

# :Output:
# Set-ItemProperty -Path /Users/myuser -Name Demo -Value SymbolicAI

$> symsh "Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI" --convert "linux"

# :Output:
# export Demo="SymbolicAI"
Chatbot
You can start a basic conversation with Symbia. Symbia is a chatbot that uses SymbolicAI to detect the content of your request and switch between different contextual modes to answer your questions. These mode include search engines, speech engines and more. To start the chatbot, simply run:

symchat
This will start now a chatbot interface:

Symbia: Hi there! I'm Symbia, your virtual assistant. How may I help you?
$> 
You can exit the conversation by either typing exit, quit or pressing Ctrl+C.

100 Other Use Cases
We compiled a few examples to show how to use our Symbolic API. You can find them in the notebooks folder.

Basics: See our basics notebook to get familiar with our API structure (notebooks/Basics.ipynb)
Queries: See our query manipulation notebook for contextualized operations (notebooks/Queries.ipynb)
News & Docs Generation: See our news and documentation generation notebook for stream processing (notebooks/News.ipynb)
ChatBot: See how to implement a custom chatbot based on semantic narrations (notebooks/ChatBot.ipynb)
You can solve many more problems with our Symbolic API. We are looking forward to see what you will build with it. Keep us posted on our shared community space on Discord: AI Is All You Need / SymbolicAI.

Community demos
We are listing all your cool demos and tools that you build with our framework. If you want to add your project just PM on Twitter at @SymbolicAPI or via Discord.

man_shrugging Why SymbolicAI?
SymbolicAI tries to close the gap between classical programming or Software 1.0 and modern data-driven programming (aka Software 2.0). It is a framework that allows to build software applications, which are able to utilize the power of large language models (LLMs) wtih composability and inheritance - two powerful concepts from the object-oriented classical programming paradigm.

This allows to move along the spectrum between the classical programming realm and data-driven programming realm as illustrated in the following figure:



As briefly mentioned, we adopt a divide and conquer approach to decompose a complex problem into smaller problems. We then use the expressiveness and flexibility of LLMs to evaluate these sub-problems and by re-combining these operations we can solve the complex problem.

In this turn, and with enough data, we can gradually transition between general purpose LLMs with zero and few-shot learning capabilities, and specialized fine-tuned models to solve specific problems (see above). This means that each operations could be designed to use a model with fine-tuned task-specific behavior.

 Tell me some more fun facts!
In its essence, SymbolicAI was inspired by the neuro-symbolic programming paradigm.

Neuro-symbolic programming is a paradigm for artificial intelligence and cognitive computing that combines the strengths of both deep neural networks and symbolic reasoning.

Deep neural networks are a type of machine learning algorithms that are inspired by the structure and function of biological neural networks. They are particularly good at tasks such as image recognition, natural language processing etc. However, they are not as good at tasks that require explicit reasoning, such as long-term planning, problem solving, and understanding causal relationships.

Symbolic reasoning, on the other hand uses formal languages and logical rules to represent knowledge and perform tasks such as planning, problem solving, and understanding causal relationships. Symbolic reasoning systems are good at tasks that require explicit reasoning, but are not as good at tasks that require pattern recognition or generalization, such as image recognition or natural language processing.

Neuro-symbolic programming aims to combine the strengths of both neural networks and symbolic reasoning to create AI systems that can perform a wide range of tasks. One way this is done is by using neural networks to extract information from data and then using symbolic reasoning to make inferences and decisions based on that information. Another way is to use symbolic reasoning to guide the generative process of neural networks and make them more interpretable.

Embedded accelerators for LLMs will, in our opinion, be ubiquitous in future computation platforms, such as wearables, smartphones, tablets or notebooks. They will contain models similar to GPT-3, ChatGPT, OPT or Bloom.



These LLMs will be able to perform a wide range of computations, such as natural language understanding or decision making. Furthermore, neuro-symbolic computation engines will be able to learn concepts how to tackle unseen tasks and solve complex problems by querying various data sources for solutions and executing logical statements on top. In this turn, to ensure the generated content is in alignment with our goals, we need to develop ways to instruct, steer and control the generative processes of machine learning models. Therefore, our approach is an attempt to enable active and transparent flow control of these generative processes.



As shown in the figure above, one can think of this generative process as shifting a probability mass of an input stream of data towards an output stream of data, in a contextualized manner. With properly designed conditions and expressions, one can also validate and steer the behavior towards a desired outcome, or repeat expressions that failed to fulfil our requirements. Our approach is to define a set of fuzzy operations that manipulate the data stream and conditions the LLMs to align with our goals. In essence, we consider all data objects, such as strings, letters, integers, arrays, etc. as symbols and we see natural language as the main interface to interact with. See the following figure:



We show that as long as we can express our goals in natural language, we can use the power of LLMs for neuro-symbolic computations. In this turn, we create operations that manipulate these symbols to generate new symbols from them. Each symbol can be interpreted as a statement. Multiple statements can be combined to form a logical expression.

Therefore, by chaining statements together we can build causal relationships and computations, instead of relying only on inductive approaches. Consequently, the outlook towards an updated computational stack resembles a neuro-symbolic computation engine at its core and, in combination with established frameworks, enables new applications.

face_in_clouds How does it work?
We now show how we define our Symbolic API, which is based on object-oriented and compositional design patterns. The Symbol class is the base class for all functional operations, which we refer to as a terminal symbol in the context of symbolic programming (fully resolved expressions). The Symbol class holds helpful operations that can be interpreted as expressions to manipulate its content and evaluate to new Symbols.

books Symbolic operations
Let us now define a Symbol and perform some basic manipulations. We start with a translation operation:

sym = ai.Symbol("Welcome to our tutorial.")
sym.translate('German')
:[Output]: 
<class 'symai.expressions.Symbol'>(value=Willkommen zu unserem Tutorial.)
Ranking objects
Our API can also perform basic data-agnostic operations to filter, rank or extract patterns. For example, we can rank a list of numbers:

sym = ai.Symbol(numpy.array([1, 2, 3, 4, 5, 6, 7]))
res = sym.rank(measure='numerical', order='descending')
:[Output]: 
<class 'symai.expressions.Symbol'>(value=['7', '6', '5', '4', '3', '2', '1'])
Evaluating Expressions by best effort
As an inspiration, we relate to an approach demonstrated by word2vec.

Word2Vec generates dense vector representations of words by training a shallow neural network to predict a word given its neighbors in a text corpus. The resulting vectors are then used in a wide range of natural language processing applications, such as sentiment analysis, text classification, and clustering.

Below we can see an example how one can perform operations on the word embeddings (colored boxes). The words are tokenized and mapped to a vector space, where we can perform semantic operations via vector arithmetics.



Similar to word2vec we intend to perform contextualized operations on different symbols, however, instead of operating in the vector space, we operate in the natural language domain. This gives us the ability to perform arithmetics on words, sentences, paragraphs, etc. and verify the results in a human readable format.

The following examples show how to evaluate such an expression via a string representation:

ai.Symbol('King - Man + Women').expression()
:[Output]:
<class 'symai.expressions.Symbol'>(value=Queen)
Dynamic casting
We can also subtract sentences from each other, where our operations condition the neural computation engine to evaluate the Symbols by best effort. In the following example, it determines that the word enemy is present in the sentence, therefore deletes it and replaces it with the word friend (which is added):

res = ai.Symbol('Hello my enemy') - 'enemy' + 'friend'
:[Output]: 
<class 'symai.expressions.Symbol'>(value=Hello my friend)
What we also see is that the API performs dynamic casting, when data types are combined with a Symbol object. If an overloaded operation of the Symbol class is used, the Symbol class can automatically cast the second object to a Symbol. This is a convenient modality to perform operations between Symbolobjects and other types of data, such as strings, integers, floats, lists, etc. without bloating the syntax.

Fuzzy Comparisons
In this example we are fuzzily comparing two number objects, where the Symbol variant is only an approximation of numpy.pi. Given the context of the fuzzy equals == operation, this comparison still succeeds and returns True.

sym = ai.Symbol('3.1415...')
sym == numpy.pi
:[Output]:
True
brain Causal Reasoning
Our framework was built with the intention to enable reasoning capabilities on top of statistical inference of LLMs. Therefore, we can also perform deductive reasoning operations with our Symbol objects. For example, we can define a set of operations with rules that define the causal relationship between two symbols. The following example shows how the & is used to compute the logical implication of two symbols.

res = ai.Symbol('The horn only sounds on Sundays.') & ai.Symbol('I hear the horn.')
:[Output]:
<class 'symai.expressions.Symbol'>(value=It is Sunday.)
The current &-operation overloads the and logical operator and sends few-shot prompts how to evaluate the statement to the neural computation engine. However, we can define more sophisticated logical operators for and, or and xor via formal proof statements and use the neural engines to parse data structures prior to our expression evaluation. Therefore, one can also define custom operations to perform more complex and robust logical operations, including constraints to validate the outcomes and ensure a desired behavior.

To provide a more complete picture, we also sketch more comprehensive causal examples below, where one tries to obtain logical answers, based on questions of the kind:

# 1) "A line parallel to y = 4x + 6 passes through (5, 10). What is the y-coordinate of the point where this line crosses the y-axis?"
# 2) "Bob has two sons, John and Jay. Jay has one brother and father. The father has two sons. Jay's brother has a brother and a father. Who is Jay's brother."
# 3) "is 1000 bigger than 1063.472?"
To give an rough idea of how we would approach this with our framework is by, first, using a chain of operations to detect the neural engine that is best suited to handle this task, and second, prepare the input for the respective engine. Let's see an example:

val = "<one of the examples above>"

# First define a class that inherits from the Expression class
class ComplexExpression(ai.Expression): # more to the Expression class in later sections
    # write a method that returns the causal evaluation
    def causal_expression(self):
        pass # see below for implementation

# instantiate an object of the class
expr = ComplexExpression(val)
# set WolframAlpha as the main expression engine to use
expr.command(engines=['symbolic'], expression_engine='wolframalpha')
# evaluate the expression
res = expr.causal_expression()
Now, the implementation of causal_expression could in principle look like this:

def causal_expression(self):
    # very which case to use `self.value` contains the input
    if self.isinstanceof('mathematics'):
        # get the mathematical formula
        formula = self.extract('mathematical formula')
        # verify which problem type we have
        if formula.isinstanceof('linear function'):
            # prepare for wolframalpha
            question = self.extract('question sentence')
            req = question.extract('what is requested?')
            x = self.extract('coordinate point (.,.)') # get coordinate point / could also ask for other points
            query = formula @ f', point x = {x}' @ f', solve {req}' # concatenate to the question and formula
            res = query.expression(query) # send prepared query to wolframalpha

        elif formula.isinstanceof('number comparison'):
            res = formula.expression() # send directly to wolframalpha

        ... # more cases

    elif self.isinstanceof('linguistic problem'):
        sentences = self / '.' # first split into sentences
        graph = {} # define graph
        for s in sentences:
            sym = ai.Symbol(s)
            relations = sym.extract('connected entities (e.g. A has three B => A | A: three B)') / '|' # and split by pipe
            for r in relations:
                ... # add relations and populate graph => alternatively, read also about CycleGT

    ... # more cases
    return res
The above example shows how we can use the causal_expression expression method to step-wise iterate and extract information which we can then either manually or using external solvers resolve.

Attention: We hint the reader that this is a very rough sketch and that the implementation of the causal_expression method would need much more engineering effort. Furthermore, the currently used GPT-3 LLM backend often fails to extract the correct information or resolve the right comparison. However, we strongly believe in the advances of the field and that this will change in the future, specifically with fine-tuned models like ChatGPT with Reinforcement Learning from Human Feedback (RLHF).

Lastly, it is also noteworthy that given enough data, we could fine-tune methods that extract information or build our knowledge graph from natural language. This would enable us to perform more complex reasoning tasks, such as the ones mentioned above. Therefore, we also point the reader to recent publications for translating Text-to-Graphs. This means that in the attempt to answer the query, we can simply traverse the graph and extract the information we need.1 / 1ChatGPTChatGPTHere are some more fun facts:SymbolicAI is inspired by the neuro-symbolic programming paradigm, which combines the strengths of deep neural networks and symbolic reasoning.Neuro-symbolic programming aims to create AI systems that can perform a wide range of tasks by combining neural networks for extracting information and symbolic reasoning for making inferences and decisions.Embedded accelerators for Large Language Models (LLMs) like GPT-3, ChatGPT, OPT, or Bloom are expected to become ubiquitous in future computation platforms such as wearables, smartphones, tablets, or notebooks. These LLMs will enable a wide range of computations, such as natural language understanding and decision making.Neuro-symbolic computation engines will be able to learn concepts and solve complex problems by querying various data sources for solutions and executing logical statements on top.To ensure the generated content aligns with our goals, it is important to develop ways to instruct, steer, and control the generative processes of machine learning models. Active and transparent flow control of these generative processes is a key aspect of the approach.Natural language is seen as the main interface to interact with the neuro-symbolic computation engine. By expressing goals and instructions in natural language, the power of LLMs can be harnessed for neuro-symbolic computations.The generative process in neuro-symbolic computation can be thought of as shifting a probability mass from an input stream of data to an output stream of data in a contextualized manner. Properly designed conditions and expressions can validate and steer the behavior towards a desired outcome.In neuro-symbolic computation, data objects such as strings, letters, integers, and arrays are considered as symbols, and natural language is used to manipulate these symbols and generate new symbols. Multiple symbols can be combined to form logical expressions, enabling the building of causal relationships and computations.Neuro-symbolic computation offers an updated computational stack that combines the power of LLMs with established frameworks, enabling new applications and capabilities.These fun facts highlight the principles and potential of neuro-symbolic programming and its applications in AI and cognitive computing.1 / 1

Search or jump to...
Pulls
Issues
Codespaces
Marketplace
Explore
 
@standardgalactic 
Xpitfire
/
symbolicai
Public
Fork your own copy of Xpitfire/symbolicai
Code
Issues
1
Pull requests
Actions
Projects
Security
Insights
Xpitfire/symbolicai
Latest commit
@Xpitfire
Xpitfire Added new shortcut type for creating simple LLM functions
â¦
2 days ago
Git stats
 138
Files
Type
Name
Latest commit message
Commit time
assets/images
Add files via upload
2 months ago
docs
Fixed broken link
4 months ago
examples
Fixed style composition on news component
2 months ago
notebooks
Added demo with solver + new example
4 months ago
symai
Added new shortcut type for creating simple LLM functions
2 days ago
tests
Added new shortcut type for creating simple LLM functions
2 days ago
.gitignore
Added initial experiment with graph coherence
3 months ago
CITATION.cff
Update CITATION.cff
5 months ago
CONTRIBUTING.md
Added improved documentation
5 months ago
LICENSE
Added improved documentation
5 months ago
MANIFEST.in
Added improved documentation
5 months ago
README.md
Added support for ChatGPT and GPT-4 engines
2 months ago
environment.yml
Added demo with solver + new example
4 months ago
pyproject.toml
Update pyproject.toml
2 months ago
setup.py
Added improved documentation
5 months ago
README.md
SymbolicAI


A Neuro-Symbolic Perspective on Large Language Models (LLMs)
Building applications with LLMs at its core through our Symbolic API leverages the power of classical and differentiable programming in Python.

Read further documentation here.

PyPI version License Twitter Twitter contributions welcome Discord Hits GitHub forks GitHub stars



Abstract
Conceptually, SymbolicAI is a framework that uses machine learning - and specifically LLMs - at its core, and composes operations based on task-specific prompting. We adopt a divide and conquer approach to decompose a complex problem into smaller problems. Therefore, each operation solves a simple task. By re-combining these operations we can solve the complex problem. Furthermore, our design principles allow us to transition between differentiable and classical programming, and to leverage the power of both worlds.

book Table of Contents
SymbolicAI
A Neuro-Symbolic Perspective on Large Language Models (LLMs)
Abstract
book Table of Contents
wrench Get Started
arrow_right Quick Install
API Keys
[Optional] Installs
t-rex Apps
Shell Command Tool
Chatbot
100 Other Use Cases
Community demos
man_shrugging Why SymbolicAI?
Tell me some more fun facts!
face_in_clouds How does it work?
books Symbolic operations
Ranking objects
Evaluating Expressions by best effort
Dynamic casting
Fuzzy Comparisons
brain Causal Reasoning
mask Operations
test_tube Custom Operations
Few-shot operations
Prompt Design
expressionless Expressions
Sequence expressions
Stream expressions
x Error Handling
spider Interpretability, Testing & Debugging
Unit Testing Models
fireDebugging
Example: News Summary
arrow_forward Play around with our API
chart_with_upwards_trend Interface for Query and Response Inspection
robot Engines
Symbolic Engine
Speech Engine
OCR Engine
Search Engine
WebCrawler Engine
Drawing Engine
File Engine
Indexing Engine
CLIP Engine
Local Neuro-Symbolic Engine
Custom Engine
zapLimitations
fortune_cookie Future Work
Conclusion
busts_in_silhouette References, Related Work & Credits
Comparison to other frameworks
Acknowledgements
Contribution
scroll Citation
memo License
Like this project?
mailbox Contact
wrench Get Started
arrow_right Quick Install
pip install symbolicai
One can run our framework in two ways:

using local engines (experimental) that are run on your local machine (see Local Neuro-Symbolic Engine section), or
using engines powered by external APIs, i.e. using OpenAI's API (see API Keys).
API Keys
Before the first run, define exports for the required API keys to enable the respective engines. This will register the keys in the internally for subsequent runs. By default SymbolicAI currently uses OpenAI's neural engines, i.e. GPT-3 Davinci-003, DALLÂ·E 2 and Embedding Ada-002, for the neuro-symbolic computations, image generation and embeddings computation respectively. However, these modules can easily be replaced with open-source alternatives. Examples are

OPT or Bloom for neuro-symbolic computations,
Craiyon for image generation,
and any BERT variants for semantic embedding computations.
To set the OpenAI API Keys use the following command:

# Linux / MacOS
export OPENAI_API_KEY="<OPENAI_API_KEY>"

# Windows (PowerShell)
$Env:OPENAI_API_KEY="<OPENAI_API_KEY>"

# Jupyter Notebooks (important: do not use quotes)
%env OPENAI_API_KEY=<OPENAI_API_KEY>
To get started import our library by using:

import symai as ai
Overall, the following engines are currently supported:

Neuro-Symbolic Engine: OpenAI's LLMs (GPT-3)
Embedding Engine: OpenAI's Embedding API
[Optional] Symbolic Engine: WolframAlpha
[Optional] Search Engine: SerpApi
[Optional] OCR Engine: APILayer
[Optional] SpeechToText Engine: OpenAI's Whisper
[Optional] WebCrawler Engine: Selenium
[Optional] Image Rendering Engine: DALLÂ·E 2
[Optional] Indexing Engine: Pinecone
[Optional] CLIP Engine: hugs Hugging Face (experimental image and text embeddings)
[Optional] Installs
SymbolicAI uses multiple engines to process text, speech and images. We also include search engine access to retrieve information from the web. To use all of them, you will need to install also the following dependencies or assign the API keys to the respective engines.

If you want to use the WolframAlpha Engine, Search Engine or OCR Engine you will need to export the following API keys:

# Linux / MacOS
export SYMBOLIC_ENGINE_API_KEY="<WOLFRAMALPHA_API_KEY>"
export SEARCH_ENGINE_API_KEY="<SERP_API_KEY>"
export OCR_ENGINE_API_KEY="<APILAYER_API_KEY>"
export INDEXING_ENGINE_API_KEY="<PINECONE_API_KEY>"

# Windows (PowerShell)
$Env:SYMBOLIC_ENGINE_API_KEY="<WOLFRAMALPHA_API_KEY>"
$Env:SEARCH_ENGINE_API_KEY="<SERP_API_KEY>"
$Env:OCR_ENGINE_API_KEY="<APILAYER_API_KEY>"
$Env:INDEXING_ENGINE_API_KEY="<PINECONE_API_KEY>"
To use them, you will also need to install the following dependencies:

SpeechToText Engine: ffmpeg for audio processing (based on OpenAI's whisper)
# Linux
sudo apt update && sudo apt install ffmpeg

# MacOS
brew install ffmpeg

# Windows
choco install ffmpeg
[Note] Additionally, you need to install the newest version directly from their repository, since the version available via pip is outdated:

pip install git+https://github.com/openai/whisper.git
WebCrawler Engine: For selenium, download the corresponding driver version by setting the SELENIUM_CHROME_DRIVER_VERSION environment variable. Currently we use Chrome as the default browser. This means that the Chrome version major number must match the ChromeDriver version. All versions are available here. For example, if you use chrome version 109.0.5414.74, you can set any 109.x.x.x version for the chromedriver. In this case the 109.0.5414.74 is available on the selenium page, therefore the environment variable is set to it:
# Linux / MacOS
export SELENIUM_CHROME_DRIVER_VERSION="109.0.5414.74"

# Windows (PowerShell)
$Env:SELENIUM_CHROME_DRIVER_VERSION="109.0.5414.74"
Alternatively, you can specify in your project path a symai.config.json file with all the engine properties. This will replace the environment variables. See the following configuration file as an example:

{
    "NEUROSYMBOLIC_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "NEUROSYMBOLIC_ENGINE_MODEL": "text-davinci-003",
    "SYMBOLIC_ENGINE_API_KEY": "<WOLFRAMALPHA_API_KEY>",
    "EMBEDDING_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "EMBEDDING_ENGINE_MODEL": "text-embedding-ada-002",
    "IMAGERENDERING_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "VISION_ENGINE_MODEL": "openai/clip-vit-base-patch32",
    "SEARCH_ENGINE_API_KEY": "<SERP_API_KEY>",
    "SEARCH_ENGINE_MODEL": "google",
    "OCR_ENGINE_API_KEY": "<APILAYER_API_KEY>",
    "SPEECH_ENGINE_MODEL": "base",
    "SELENIUM_CHROME_DRIVER_VERSION": "110.0.5481.30",
    "INDEXING_ENGINE_API_KEY": "<PINECONE_API_KEY>",
    "INDEXING_ENGINE_ENVIRONMENT": "us-west1-gcp"
}
t-rex Apps
Over the course of th next weeks, we will expand our experimental demo apps and provide a set of useful tools that showcase how to interact with our framework. These apps are made available by calling the sym+<shortcut-name-of-app> command in your terminal or PowerShell.

Shell Command Tool
You can start a basic shell command support tool that translates natural language commands into shell commands. To start the shell command tool, simply run:

symsh "<your-query>"
You can also use the --help flag to get more information about the tool and available arguments.

symsh --help
Here is an example of how to use the tool:

$> symsh "PowerShell edit registiry entry"

# :Output:
# Set-ItemProperty -Path <path> -Name <name> -Value <value>

$> symsh "Set-ItemProperty -Path <path> -Name <name> -Value <value>" --add "path='/Users/myuser' name=Demo value=SymbolicAI"

# :Output:
# Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI

$> symsh "Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI" --del "string quotes"

# :Output:
# Set-ItemProperty -Path /Users/myuser -Name Demo -Value SymbolicAI

$> symsh "Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI" --convert "linux"

# :Output:
# export Demo="SymbolicAI"
Chatbot
You can start a basic conversation with Symbia. Symbia is a chatbot that uses SymbolicAI to detect the content of your request and switch between different contextual modes to answer your questions. These mode include search engines, speech engines and more. To start the chatbot, simply run:

symchat
This will start now a chatbot interface:

Symbia: Hi there! I'm Symbia, your virtual assistant. How may I help you?
$> 
You can exit the conversation by either typing exit, quit or pressing Ctrl+C.

100 Other Use Cases
We compiled a few examples to show how to use our Symbolic API. You can find them in the notebooks folder.

Basics: See our basics notebook to get familiar with our API structure (notebooks/Basics.ipynb)
Queries: See our query manipulation notebook for contextualized operations (notebooks/Queries.ipynb)
News & Docs Generation: See our news and documentation generation notebook for stream processing (notebooks/News.ipynb)
ChatBot: See how to implement a custom chatbot based on semantic narrations (notebooks/ChatBot.ipynb)
You can solve many more problems with our Symbolic API. We are looking forward to see what you will build with it. Keep us posted on our shared community space on Discord: AI Is All You Need / SymbolicAI.

Community demos
We are listing all your cool demos and tools that you build with our framework. If you want to add your project just PM on Twitter at @SymbolicAPI or via Discord.

man_shrugging Why SymbolicAI?
SymbolicAI tries to close the gap between classical programming or Software 1.0 and modern data-driven programming (aka Software 2.0). It is a framework that allows to build software applications, which are able to utilize the power of large language models (LLMs) wtih composability and inheritance - two powerful concepts from the object-oriented classical programming paradigm.

This allows to move along the spectrum between the classical programming realm and data-driven programming realm as illustrated in the following figure:



As briefly mentioned, we adopt a divide and conquer approach to decompose a complex problem into smaller problems. We then use the expressiveness and flexibility of LLMs to evaluate these sub-problems and by re-combining these operations we can solve the complex problem.

In this turn, and with enough data, we can gradually transition between general purpose LLMs with zero and few-shot learning capabilities, and specialized fine-tuned models to solve specific problems (see above). This means that each operations could be designed to use a model with fine-tuned task-specific behavior.

 Tell me some more fun facts!
In its essence, SymbolicAI was inspired by the neuro-symbolic programming paradigm.

Neuro-symbolic programming is a paradigm for artificial intelligence and cognitive computing that combines the strengths of both deep neural networks and symbolic reasoning.

Deep neural networks are a type of machine learning algorithms that are inspired by the structure and function of biological neural networks. They are particularly good at tasks such as image recognition, natural language processing etc. However, they are not as good at tasks that require explicit reasoning, such as long-term planning, problem solving, and understanding causal relationships.

Symbolic reasoning, on the other hand uses formal languages and logical rules to represent knowledge and perform tasks such as planning, problem solving, and understanding causal relationships. Symbolic reasoning systems are good at tasks that require explicit reasoning, but are not as good at tasks that require pattern recognition or generalization, such as image recognition or natural language processing.

Neuro-symbolic programming aims to combine the strengths of both neural networks and symbolic reasoning to create AI systems that can perform a wide range of tasks. One way this is done is by using neural networks to extract information from data and then using symbolic reasoning to make inferences and decisions based on that information. Another way is to use symbolic reasoning to guide the generative process of neural networks and make them more interpretable.

Embedded accelerators for LLMs will, in our opinion, be ubiquitous in future computation platforms, such as wearables, smartphones, tablets or notebooks. They will contain models similar to GPT-3, ChatGPT, OPT or Bloom.



These LLMs will be able to perform a wide range of computations, such as natural language understanding or decision making. Furthermore, neuro-symbolic computation engines will be able to learn concepts how to tackle unseen tasks and solve complex problems by querying various data sources for solutions and executing logical statements on top. In this turn, to ensure the generated content is in alignment with our goals, we need to develop ways to instruct, steer and control the generative processes of machine learning models. Therefore, our approach is an attempt to enable active and transparent flow control of these generative processes.



As shown in the figure above, one can think of this generative process as shifting a probability mass of an input stream of data towards an output stream of data, in a contextualized manner. With properly designed conditions and expressions, one can also validate and steer the behavior towards a desired outcome, or repeat expressions that failed to fulfil our requirements. Our approach is to define a set of fuzzy operations that manipulate the data stream and conditions the LLMs to align with our goals. In essence, we consider all data objects, such as strings, letters, integers, arrays, etc. as symbols and we see natural language as the main interface to interact with. See the following figure:



We show that as long as we can express our goals in natural language, we can use the power of LLMs for neuro-symbolic computations. In this turn, we create operations that manipulate these symbols to generate new symbols from them. Each symbol can be interpreted as a statement. Multiple statements can be combined to form a logical expression.

Therefore, by chaining statements together we can build causal relationships and computations, instead of relying only on inductive approaches. Consequently, the outlook towards an updated computational stack resembles a neuro-symbolic computation engine at its core and, in combination with established frameworks, enables new applications.

face_in_clouds How does it work?
We now show how we define our Symbolic API, which is based on object-oriented and compositional design patterns. The Symbol class is the base class for all functional operations, which we refer to as a terminal symbol in the context of symbolic programming (fully resolved expressions). The Symbol class holds helpful operations that can be interpreted as expressions to manipulate its content and evaluate to new Symbols.

books Symbolic operations
Let us now define a Symbol and perform some basic manipulations. We start with a translation operation:

sym = ai.Symbol("Welcome to our tutorial.")
sym.translate('German')
:[Output]: 
<class 'symai.expressions.Symbol'>(value=Willkommen zu unserem Tutorial.)
Ranking objects
Our API can also perform basic data-agnostic operations to filter, rank or extract patterns. For example, we can rank a list of numbers:

sym = ai.Symbol(numpy.array([1, 2, 3, 4, 5, 6, 7]))
res = sym.rank(measure='numerical', order='descending')
:[Output]: 
<class 'symai.expressions.Symbol'>(value=['7', '6', '5', '4', '3', '2', '1'])
Evaluating Expressions by best effort
As an inspiration, we relate to an approach demonstrated by word2vec.

Word2Vec generates dense vector representations of words by training a shallow neural network to predict a word given its neighbors in a text corpus. The resulting vectors are then used in a wide range of natural language processing applications, such as sentiment analysis, text classification, and clustering.

Below we can see an example how one can perform operations on the word embeddings (colored boxes). The words are tokenized and mapped to a vector space, where we can perform semantic operations via vector arithmetics.



Similar to word2vec we intend to perform contextualized operations on different symbols, however, instead of operating in the vector space, we operate in the natural language domain. This gives us the ability to perform arithmetics on words, sentences, paragraphs, etc. and verify the results in a human readable format.

The following examples show how to evaluate such an expression via a string representation:

ai.Symbol('King - Man + Women').expression()
:[Output]:
<class 'symai.expressions.Symbol'>(value=Queen)
Dynamic casting
We can also subtract sentences from each other, where our operations condition the neural computation engine to evaluate the Symbols by best effort. In the following example, it determines that the word enemy is present in the sentence, therefore deletes it and replaces it with the word friend (which is added):

res = ai.Symbol('Hello my enemy') - 'enemy' + 'friend'
:[Output]: 
<class 'symai.expressions.Symbol'>(value=Hello my friend)
What we also see is that the API performs dynamic casting, when data types are combined with a Symbol object. If an overloaded operation of the Symbol class is used, the Symbol class can automatically cast the second object to a Symbol. This is a convenient modality to perform operations between Symbolobjects and other types of data, such as strings, integers, floats, lists, etc. without bloating the syntax.

Fuzzy Comparisons
In this example we are fuzzily comparing two number objects, where the Symbol variant is only an approximation of numpy.pi. Given the context of the fuzzy equals == operation, this comparison still succeeds and returns True.

sym = ai.Symbol('3.1415...')
sym == numpy.pi
:[Output]:
True
brain Causal Reasoning
Our framework was built with the intention to enable reasoning capabilities on top of statistical inference of LLMs. Therefore, we can also perform deductive reasoning operations with our Symbol objects. For example, we can define a set of operations with rules that define the causal relationship between two symbols. The following example shows how the & is used to compute the logical implication of two symbols.

res = ai.Symbol('The horn only sounds on Sundays.') & ai.Symbol('I hear the horn.')
:[Output]:
<class 'symai.expressions.Symbol'>(value=It is Sunday.)
The current &-operation overloads the and logical operator and sends few-shot prompts how to evaluate the statement to the neural computation engine. However, we can define more sophisticated logical operators for and, or and xor via formal proof statements and use the neural engines to parse data structures prior to our expression evaluation. Therefore, one can also define custom operations to perform more complex and robust logical operations, including constraints to validate the outcomes and ensure a desired behavior.

To provide a more complete picture, we also sketch more comprehensive causal examples below, where one tries to obtain logical answers, based on questions of the kind:

# 1) "A line parallel to y = 4x + 6 passes through (5, 10). What is the y-coordinate of the point where this line crosses the y-axis?"
# 2) "Bob has two sons, John and Jay. Jay has one brother and father. The father has two sons. Jay's brother has a brother and a father. Who is Jay's brother."
# 3) "is 1000 bigger than 1063.472?"
To give an rough idea of how we would approach this with our framework is by, first, using a chain of operations to detect the neural engine that is best suited to handle this task, and second, prepare the input for the respective engine. Let's see an example:

val = "<one of the examples above>"

# First define a class that inherits from the Expression class
class ComplexExpression(ai.Expression): # more to the Expression class in later sections
    # write a method that returns the causal evaluation
    def causal_expression(self):
        pass # see below for implementation

# instantiate an object of the class
expr = ComplexExpression(val)
# set WolframAlpha as the main expression engine to use
expr.command(engines=['symbolic'], expression_engine='wolframalpha')
# evaluate the expression
res = expr.causal_expression()
Now, the implementation of causal_expression could in principle look like this:

def causal_expression(self):
    # very which case to use `self.value` contains the input
    if self.isinstanceof('mathematics'):
        # get the mathematical formula
        formula = self.extract('mathematical formula')
        # verify which problem type we have
        if formula.isinstanceof('linear function'):
            # prepare for wolframalpha
            question = self.extract('question sentence')
            req = question.extract('what is requested?')
            x = self.extract('coordinate point (.,.)') # get coordinate point / could also ask for other points
            query = formula @ f', point x = {x}' @ f', solve {req}' # concatenate to the question and formula
            res = query.expression(query) # send prepared query to wolframalpha

        elif formula.isinstanceof('number comparison'):
            res = formula.expression() # send directly to wolframalpha

        ... # more cases

    elif self.isinstanceof('linguistic problem'):
        sentences = self / '.' # first split into sentences
        graph = {} # define graph
        for s in sentences:
            sym = ai.Symbol(s)
            relations = sym.extract('connected entities (e.g. A has three B => A | A: three B)') / '|' # and split by pipe
            for r in relations:
                ... # add relations and populate graph => alternatively, read also about CycleGT

    ... # more cases
    return res
The above example shows how we can use the causal_expression expression method to step-wise iterate and extract information which we can then either manually or using external solvers resolve.

Attention: We hint the reader that this is a very rough sketch and that the implementation of the causal_expression method would need much more engineering effort. Furthermore, the currently used GPT-3 LLM backend often fails to extract the correct information or resolve the right comparison. However, we strongly believe in the advances of the field and that this will change in the future, specifically with fine-tuned models like ChatGPT with Reinforcement Learning from Human Feedback (RLHF).

Lastly, it is also noteworthy that given enough data, we could fine-tune methods that extract information or build our knowledge graph from natural language. This would enable us to perform more complex reasoning tasks, such as the ones mentioned above. Therefore, we also point the reader to recent publications for translating Text-to-Graphs. This means that in the attempt to answer the query, we can simply traverse the graph and extract the information we need.

In the next section, we will explore operations.

mask Operations
Operations are at the core of our framework. They are the building blocks of our API and are used to define the behavior of our symbols. We can think of operations as contextualized functions that take in a Symbol object, send it to the neuro-symbolic engine for evaluation, and return one or multiple new objects (mainly new symbols; but not necessarily limited to that). Another fundamental property is polymorphism, which means that operations can be applied to different types of data, such as strings, integers, floats, lists, etc. with different behaviors, depending on the object instance.

The way we execute operations is by using the Symbol object value attribute containing the original data type that is then sent as a string representations to the engines to perform the operations. Therefore all values are casted to a string representation. This also means, that for custom objects one needs to define a proper __str__ method to cast the object to a string representation and ensure preservation of the semantics of that object.

Lastly, we need to talk about inheritance. Our API is built on top of the Symbol class, which is the base class of all operations. This means that all operations are inherited from the Symbol class. This provides a convenient modality to add new custom operations by sub-classing Symbol, yet, ensuring to always have a set of base operations at our disposal without bloating the syntax or re-implementing many existing functionalities. This also means that we can define contextualized operations with individual constraints, prompt designs and therefore behaviors by simply sub-classing the Symbol class and overriding the corresponding method. However, we recommend sub-classing the Expression class as we will see later, it adds additional functionalities.

Here is an example of how to define a custom == operation by overriding the __eq__ method and providing a custom prompt object with a list of examples:

class Demo(ai.Symbol):
    def __eq__(self, other) -> bool:
        @ai.equals(examples=ai.Prompt([
              "1 == 'ONE' =>True",
              "'six' == 7 =>False",
              "'Acht' == 'eight' =>True",
              ...
          ])
        )
        def _func(_, other) -> bool:
            return False # default behavior on failure
        return _func(self, other)
As shown in the above example, this is also the way we implemented the basic operations in Symbol, by defining local functions that are then decorated with the respective operation decorator from the symai/core.py file. The symai/core.py is a collection of pre-defined operation decorators that we can quickly apply to any function. The reason why we use locally defined functions instead of directly decorating the main methods, is that we do not necessarily want that all our operations are sent to the neural engine and could implement a default behavior. Another reason is that we want to cast return types of the operation outcome to symbols or other derived classes thereof. This is done by using the self._sym_return_type(...) method and can give contextualized behavior based on the defined return type. See more details in the actual Symbol class.

In the next section, we will show that almost all operations in symai/core.py are derived from the more generic few_shot decorator.

test_tube Custom Operations
One can also define customized operations. For example, let us define a custom operation to generate a random integer between 0 and 10:

class Demo(ai.Symbol):
    def __init__(self, value = '') -> None:
        super().__init__(value)
    
    @ai.zero_shot(prompt="Generate a random integer between 0 and 10.",
                  constraints=[
                      lambda x: x >= 0,
                      lambda x: x <= 10
                  ])
    def get_random_int(self) -> int:
        pass
As we show, the Symbolic API uses Python Decorators to define operations. The @ai.zero_shot decorator is used to define a custom operation that does not require any demonstration examples, since the prompt is expressive enough. In the shown example, the zero_shot decorator takes in two arguments: prompt and constraints. The former is used to define the prompt that conditions our desired operation behavior. The latter is used to define validation constraints of the computed outcome, to ensure it fulfills our expectations.

If the constraint is not fulfilled, the above implementation would reach out to the specified default implementation or default value. If no default implementation or value was found, the Symbolic API would raise an ConstraintViolationException.

We also see that in the above example the return type is defined as int. Therefore, the resulting value from the wrapped function will be of type int. This works because our implementation uses auto-casting to a user specified return data type. If the cast fails, the Symbolic API will raise a ValueError. If no return type is specified, the return type will be Any.1 / 1ChatGPTChatGPTThe SymbolicAI framework is a neuro-symbolic programming framework that combines the power of large language models (LLMs) with classical and differentiable programming in Python. It aims to enable the building of applications with LLMs at their core, allowing for the composition of operations based on task-specific prompting.The framework provides a set of operations and functionalities to manipulate symbols and perform various tasks. Here are some key features and concepts of SymbolicAI:Symbol: The Symbol class is the base class for all functional operations in the framework. It holds operations that can be interpreted as expressions to manipulate its content and evaluate to new symbols. Symbols can represent text, numbers, arrays, and more.Operations: Operations are contextualized functions that take a Symbol object, send it to the neuro-symbolic engine for evaluation, and return new objects (symbols) as results. Operations can be applied to different types of data and define the behavior of symbols.Prompting: The framework uses prompts to condition the behavior of the neuro-symbolic engine. Prompts are expressed in natural language and guide the evaluation of symbols. They can be used to perform tasks like translation, ranking, evaluation of expressions, and more.Neural Computation Engine: SymbolicAI leverages the power of neural language models (LLMs) for neuro-symbolic computations. It uses engines such as OpenAI's GPT-3 and Embedding API to process text and perform operations based on prompts.Custom Operations: SymbolicAI allows users to define custom operations by sub-classing the Symbol class and overriding methods. Custom operations can have specific behaviors, prompts, and constraints.Causal Reasoning: The framework enables causal reasoning by defining operations and rules that represent causal relationships between symbols. It allows for logical operations, deduction, and reasoning based on given information.Constraints and Validation: SymbolicAI supports the definition of constraints and validation functions to ensure that the outcomes of operations meet specific requirements. Constraints can be used to validate the results or guide the behavior of operations.Few-shot Learning: SymbolicAI incorporates few-shot learning capabilities, allowing for the learning of concepts and solving complex problems with limited data.Symbolic API: SymbolicAI provides a Symbolic API that allows developers to interact with the framework and perform operations using natural language queries or commands.The framework also supports the integration of external engines and APIs for tasks like search, OCR, speech-to-text, and image rendering.These are just some of the main features and concepts of SymbolicAI. The framework aims to bridge the gap between classical programming and data-driven programming by combining the strengths of LLMs and symbolic reasoning. It provides a powerful toolset for building applications that leverage the capabilities of large language models and enable neuro-symbolic computations.1 / 1Few-shot operations
The @ai.few_shot decorator is the a generalized version of @ai.zero_shot and is used to define a custom operation that requires demonstration examples. To give a more complete picture, we present the function signature of the few_shot decorator:

def few_shot(prompt: str,
             examples: Prompt, 
             constraints: List[Callable] = [],
             default: Optional[object] = None, 
             limit: int = 1,
             pre_processor: Optional[List[PreProcessor]] = None,
             post_processor: Optional[List[PostProcessor]] = None,
             **wrp_kwargs):
The prompt and constraints attributes behavior is similar to the zero_shot decorator. The examples and limit arguments are new. The examples argument is used to define a list of demonstrations that are used to condition the neural computation engine. The limit argument is used to define the maximum number of examples that are returned, give that there are more results. The pre_processor argument takes a list of PreProcessor objects which can be used to pre-process the input before it is fed into the neural computation engine. The post_processor argument takes a list of PostProcessor objects which can be used to post-process the output before it is returned to the user. The wrp_kwargs argument is used to pass additional arguments to the wrapped method, which are also stream-lined towards the neural computation engine and other engines.

To give a more holistic picture ouf our conceptional implementation, see the following flow diagram containing the most important classes:



The colors indicate logical groups of data processing steps. Yellow indicates the input and output data. Blue indicates places you can customize or prepare the input of your engine. Green indicates post-processing steps of the engine response. Red indicates the application of constraints (which also includes the attempted casting of the return type signature, if specified in the decorated method). Grey indicates the custom method which defines all properties, therefore has access to all the above mentioned objects.

To conclude this section, here is an example how to write a custom Japanese name generator with our @ai.zero_shot decorator:

import symai as ai
class Demo(ai.Symbol):
    @ai.few_shot(prompt="Generate Japanese names: ",
                 examples=ai.Prompt(
                   ["æå­", "åè±", "ä¸é", "åæ"]
                 ),
                 limit=2,
                 constraints=[lambda x: len(x) > 1])
    def generate_japanese_names(self) -> list:
        return ['æå­', 'åè±'] # dummy implementation
Should the neural computation engine not be able to compute the desired outcome, it will reach out to the default implementation or default value. If no default implementation or value was found, the method call will raise an exception.1 / 1ChatGPTChatGPTThe @ai.few_shot decorator is a generalized version of @ai.zero_shot and is used to define a custom operation that requires demonstration examples. Here is the function signature of the few_shot decorator:pythonCopy codedef few_shot(prompt: str,
             examples: Prompt, 
             constraints: List[Callable] = [],
             default: Optional[object] = None, 
             limit: int = 1,
             pre_processor: Optional[List[PreProcessor]] = None,
             post_processor: Optional[List[PostProcessor]] = None,
             **wrp_kwargs):
The prompt and constraints attributes behave similarly to the zero_shot decorator. The examples and limit arguments are new. The examples argument is used to define a list of demonstrations that are used to condition the neural computation engine. The limit argument is used to define the maximum number of examples that are returned if there are more results.The pre_processor argument takes a list of PreProcessor objects, which can be used to pre-process the input before it is fed into the neural computation engine. The post_processor argument takes a list of PostProcessor objects, which can be used to post-process the output before it is returned to the user. The wrp_kwargs argument is used to pass additional arguments to the wrapped method, which are streamlined towards the neural computation engine and other engines.To illustrate the usage of @ai.few_shot, here's an example of how to write a custom Japanese name generator:pythonCopy codeimport symai as ai

class Demo(ai.Symbol):
    @ai.few_shot(prompt="Generate Japanese names: ",
                 examples=ai.Prompt(
                   ["æå­", "åè±", "ä¸é", "åæ"]
                 ),
                 limit=2,
                 constraints=[lambda x: len(x) > 1])
    def generate_japanese_names(self) -> list:
        return ['æå­', 'åè±']  # dummy implementation
In this example, the generate_japanese_names method is decorated with @ai.few_shot. The prompt parameter is used to provide an instructional prompt for the operation. The examples parameter contains a list of demonstration examples. The limit parameter is set to 2, indicating that if there are more than 2 possible results, only 2 will be returned. The constraints parameter is used to specify a constraint on the generated names, in this case, the length of the name should be greater than 1.If the neural computation engine is unable to compute the desired outcome, it will fall back to the default implementation or default value specified in the decorator. If no default implementation or value is provided, an exception will be raised.2 / 2Prompt Design
The way all the above operations are performed is by using a Prompt class. The Prompt class is a container for all the information that is needed to define a specific operation. The Prompt class is also the base class for all other Prompt classes.

Here is an example how to define a Prompt to enforce the neural computation engine for comparing two values:

class CompareValues(ai.Prompt):
    def __init__(self) -> ai.Prompt:
        super().__init__([
            "4 > 88 =>False",
            "-inf < 0 =>True",
            "inf > 0 =>True",
            "4 > 3 =>True",
            "1 < 'four' =>True",
            ...
        ])
For example, when calling the <= operation on two Symbols, the neural computation engine will evaluate the symbols in the context of the CompareValues prompt.

res = ai.Symbol(1) <= ai.Symbol('one')
This statement evaluates to True, since the fuzzy compare operation was conditions our engine to compare the two Symbols based on their semantic meaning.

:[Output]:
True
In a more general notion, depending on the context hierarchy of the expression class and used operations the semantics of the Symbol operations may vary. To better illustrate this, we show our conceptual prompt design in the following figure:



The figure shows our hierarchical prompt design as a container of all the information that is provided to the neural computation engine to define a task-specific operation. The Yellow and Green highlighted boxes indicate mandatory string placements. The dashed boxes are optional placeholders. and the Red box indicates the starting point of the model prediction.

Conceptually we consider three main prompt designs: Context-based Prompts, Operational Prompts, and Templates. The prompts can be curated either by inheritance or by composition. For example, the Static Context can be defined by inheriting from the Expression class and overriding the static_context property. An Operation and Template prompt can be created by providing an PreProcessor to modify the input data.

We will now explain each prompt concept in more details:

The Context-based Prompts (Static, Dynamic and Payload) are considered optional and can be defined in a static manner, either by sub-classing the Expression class and overriding the static_context property, or at runtime by updating the dynamic_context property or passing an payload kwargs to a method. Here is an example how to use the payload kwargs via the method signature:

# creating a query to ask if an issue was resolve or not
sym = Symbol("<some-community-conversation>")
q = sym.query("Was the issue resolved?")
# write manual condition to check if the issue was resolved
if 'not resolved' in q:
    # do a new query but payload the previous query answer to the new query
    sym.query("What was the resolution?", payload=q)
    ...
else:
    pass # all good
Regardless of how we set the context, our contextualized prompt defines the desired behavior of the Expression operations. For example, if we want to operate in the context of a domain-specific language, without having to override each base class method. See more details in this notebook.

The Operation prompts define the behavior of an atomic operation and is therefore mandatory to express the nature of such an operation. For example, the +-operation is used to add two Symbols together and therefore the +-operation prompt explains its behavior. Examples defines another optional structure that provides the neural computation engine with a set of demonstrations that are used to properly condition the engine. For example, the +-operation prompt can be conditioned on how to add numbers by providing a set of demonstrations, such as 1 + 1 = 2, 2 + 2 = 4, etc.

The Template prompts are optional and encapsulates the resulting prediction to enforce a specific format. For example, to generate HTML tags we can use a curated <html>{{placeholder}}</html> template. This template will enforce the neural computation engine to start the generation process already in the context of a HTML tags format, and not produce irrelevant descriptions about its task.1 / 1ChatGPTChatGPTThe Prompt class is a container that holds all the information needed to define a specific operation. It serves as the base class for other Prompt classes and plays a central role in defining the behavior of the neural computation engine.Here's an example of how to define a Prompt class to enforce the neural computation engine to compare two values:pythonCopy codeclass CompareValues(ai.Prompt):
    def __init__(self) -> ai.Prompt:
        super().__init__([
            "4 > 88 => False",
            "-inf < 0 => True",
            "inf > 0 => True",
            "4 > 3 => True",
            "1 < 'four' => True",
            ...
        ])
In this example, the CompareValues class inherits from ai.Prompt and defines a set of comparison examples. Each example is in the form of value1 operator value2 => result, where value1 and value2 can be any valid expression or value, operator represents a comparison operator like >, <, >=, <=, and result represents the expected result of the comparison.When performing a comparison operation using the neural computation engine, the engine will evaluate the symbols in the context of the CompareValues prompt. For example:pythonCopy coderes = ai.Symbol(1) <= ai.Symbol('one')
In this case, the statement evaluates to True because the fuzzy compare operation, conditioned by the CompareValues prompt, compares the two symbols based on their semantic meaning.Regarding the prompt design, there are three main prompt concepts: Context-based Prompts (Static, Dynamic, and Payload), Operational Prompts, and Templates.Context-based Prompts define the context in which the expressions or operations are evaluated. This can be done statically by subclassing the Expression class and overriding the static_context property, or dynamically by updating the dynamic_context property or passing a payload using kwargs to a method.Operational Prompts define the behavior of atomic operations and are mandatory to express the nature of the operation. They can be conditioned on examples provided through the examples parameter of the Prompt class.Template Prompts are optional and encapsulate the resulting prediction to enforce a specific format. For example, a template prompt can be used to generate HTML tags by using a curated template like <html>{{placeholder}}</html>. This template guides the neural computation engine to generate content within the context of HTML tags, ensuring the produced output is relevant to the task.By utilizing these prompt concepts, you can define the desired behavior and context for your symbolic operations, enabling the neural computation engine to perform tasks accordingly.1 / 1
import os
import warnings
warnings.filterwarnings('ignore')
os.chdir('../') # set the working directory to the root of the project
from symai import *
from IPython.display import display
from examples.sql import SQL
sql = SQL()
SQL Example
The SQL expression is defined and passes as a global context the syntax of the SQL language. The SQL expression is then used to generate queries based on the given context. We can then use the generated queries to get data from a database.

The following query is sent to the neural computation engine and creates a query based on the given context:

q = sql('Select all users above the age of 30 from the Members table.'); display(q)
SELECT * FROM Members WHERE age > 30
We can now try to further manipulate the result by asking the model to incorporate additional information, such as filtering to a specific time range:

res = q << 'limit the query to the last 10 minutes'
display(res)
SELECT * FROM Members WHERE age > 30 AND timestamp > NOW() - INTERVAL 10 MINUTE;
We can also try to remove unwanted fields from the generated query. Notice how the model tries to remove not only the given statement but attributes associated with them:

res -= ' AND ...'
display(res)
SELECT * FROM Members WHERE age > 30;
And we can now even convert our query to other familiar domain specific languages, such as SQL or ActiveRecord:

sql_res = res.convert("ActiveRecord")
display(sql_res)
Member.where("age > ?", 30).select("*")
To wrap things up, we might want to go back full circle and ask the model to generate again the explanation based on the given query:

answer_doc = res.query("What does this query do?")
display(answer_doc)
This query selects all data from the Members table where the age is greater than 30.
Ask it in natural language to modify the query:

answer = res.query("How can you limit the number of results to 30 for an SQL query?")
display(answer)
Answer: You can limit the number of results to 30 for an SQL query by adding the LIMIT clause at the end of the query, like this: SELECT * FROM Members WHERE age > 30 LIMIT 30;
Even translate the explanation to a different language on the fly:

locale = Symbol(answer_doc).translate('German')
display(locale)
Diese Abfrage wÃ¤hlt alle Daten aus der Mitgliedertabelle aus, in der das Alter grÃ¶Ãer als 30 ist.
Fixing the query on the fly if something goes wrong or the user quickly wants to adapt a query:

sql.update(feedback="""Explanation: Never allow SELECT *, always use LIMIT to a max of x <= 50 entries, where x is the user specified limit.""");
res = sql('Select all users above the age of 30 from the Members table.')
display(res)
SELECT * FROM Members WHERE age > 30 LIMIT 50
sql.clear();
res = sql('Select all users above the age of 30 from the Members table.')
display(res)
SELECT * FROM Members WHERE age > 30
 1 / 1ChatGPTChatGPTIn the given example, an SQL expression is defined using the SQL class, which provides a context for SQL language syntax. The SQL expression is then used to generate queries based on the given context.Here's a breakdown of the example:The SQL expression is used to create a query for selecting all users above the age of 30 from the Members table.pythonCopy codeq = sql('Select all users above the age of 30 from the Members table.')
display(q)
Output:sqlCopy codeSELECT * FROM Members WHERE age > 30
The generated query can be further manipulated by incorporating additional information. In this case, we limit the query to the last 10 minutes.pythonCopy coderes = q << 'limit the query to the last 10 minutes'
display(res)
Output:sqlCopy codeSELECT * FROM Members WHERE age > 30 AND timestamp > NOW() - INTERVAL 10 MINUTE;
Unwanted fields can be removed from the generated query. The model tries to remove not only the given statement but also associated attributes.pythonCopy coderes -= ' AND ...'
display(res)
Output:sqlCopy codeSELECT * FROM Members WHERE age > 30;
The query can be converted to other familiar domain-specific languages, such as SQL or ActiveRecord.pythonCopy codesql_res = res.convert("ActiveRecord")
display(sql_res)
Output:csharpCopy codeMember.where("age > ?", 30).select("*")
The explanation of the query can be generated based on the given query.pythonCopy codeanswer_doc = res.query("What does this query do?")
display(answer_doc)
Output:sqlCopy codeThis query selects all data from the Members table where the age is greater than 30.
The query can be modified by asking the model in natural language. In this case, we ask how to limit the number of results to 30 for an SQL query.pythonCopy codeanswer = res.query("How can you limit the number of results to 30 for an SQL query?")
display(answer)
Output:vbnetCopy codeAnswer: You can limit the number of results to 30 for an SQL query by adding the LIMIT clause at the end of the query, like this: SELECT * FROM Members WHERE age > 30 LIMIT 30;
The explanation can be translated to a different language on the fly.pythonCopy codelocale = Symbol(answer_doc).translate('German')
display(locale)
Output:sqlCopy codeDiese Abfrage wÃ¤hlt alle Daten aus der Mitgliedertabelle aus, in der das Alter grÃ¶Ãer als 30 ist.
If something goes wrong or the user wants to quickly adapt a query, it can be fixed on the fly by providing feedback.pythonCopy codesql.update(feedback="""Explanation: Never allow SELECT *, always use LIMIT to a max of x <= 50 entries, where x is the user specified limit.""")
res = sql('Select all users above the age of 30 from the Members table.')
display(res)
Output:sqlCopy codeSELECT * FROM Members WHERE age > 30 LIMIT 50
The SQL instance can be cleared to start fresh.pythonCopy codesql.clear()
res = sql('Select all users above the age of 30 from the Members table.')
display(res)
Output:sqlCopy codeSELECT * FROM Members WHERE age > 30
1 / 1

Search or jump to...
Pulls
Issues
Codespaces
Marketplace
Explore
 
@standardgalactic 
Xpitfire
/
symbolicai
Public
Fork your own copy of Xpitfire/symbolicai
Code
Issues
1
Pull requests
Actions
Projects
Security
Insights
Xpitfire/symbolicai
Latest commit
@Xpitfire
Xpitfire Added new shortcut type for creating simple LLM functions
â¦
2 days ago
Git stats
 138
Files
Type
Name
Latest commit message
Commit time
assets/images
Add files via upload
2 months ago
docs
Fixed broken link
4 months ago
examples
Fixed style composition on news component
2 months ago
notebooks
Added demo with solver + new example
4 months ago
symai
Added new shortcut type for creating simple LLM functions
2 days ago
tests
Added new shortcut type for creating simple LLM functions
2 days ago
.gitignore
Added initial experiment with graph coherence
3 months ago
CITATION.cff
Update CITATION.cff
5 months ago
CONTRIBUTING.md
Added improved documentation
5 months ago
LICENSE
Added improved documentation
5 months ago
MANIFEST.in
Added improved documentation
5 months ago
README.md
Added support for ChatGPT and GPT-4 engines
2 months ago
environment.yml
Added demo with solver + new example
4 months ago
pyproject.toml
Update pyproject.toml
2 months ago
setup.py
Added improved documentation
5 months ago
README.md
SymbolicAI


A Neuro-Symbolic Perspective on Large Language Models (LLMs)
Building applications with LLMs at its core through our Symbolic API leverages the power of classical and differentiable programming in Python.

Read further documentation here.

PyPI version License Twitter Twitter contributions welcome Discord Hits GitHub forks GitHub stars



Abstract
Conceptually, SymbolicAI is a framework that uses machine learning - and specifically LLMs - at its core, and composes operations based on task-specific prompting. We adopt a divide and conquer approach to decompose a complex problem into smaller problems. Therefore, each operation solves a simple task. By re-combining these operations we can solve the complex problem. Furthermore, our design principles allow us to transition between differentiable and classical programming, and to leverage the power of both worlds.

book Table of Contents
SymbolicAI
A Neuro-Symbolic Perspective on Large Language Models (LLMs)
Abstract
book Table of Contents
wrench Get Started
arrow_right Quick Install
API Keys
[Optional] Installs
t-rex Apps
Shell Command Tool
Chatbot
100 Other Use Cases
Community demos
man_shrugging Why SymbolicAI?
Tell me some more fun facts!
face_in_clouds How does it work?
books Symbolic operations
Ranking objects
Evaluating Expressions by best effort
Dynamic casting
Fuzzy Comparisons
brain Causal Reasoning
mask Operations
test_tube Custom Operations
Few-shot operations
Prompt Design
expressionless Expressions
Sequence expressions
Stream expressions
x Error Handling
spider Interpretability, Testing & Debugging
Unit Testing Models
fireDebugging
Example: News Summary
arrow_forward Play around with our API
chart_with_upwards_trend Interface for Query and Response Inspection
robot Engines
Symbolic Engine
Speech Engine
OCR Engine
Search Engine
WebCrawler Engine
Drawing Engine
File Engine
Indexing Engine
CLIP Engine
Local Neuro-Symbolic Engine
Custom Engine
zapLimitations
fortune_cookie Future Work
Conclusion
busts_in_silhouette References, Related Work & Credits
Comparison to other frameworks
Acknowledgements
Contribution
scroll Citation
memo License
Like this project?
mailbox Contact
wrench Get Started
arrow_right Quick Install
pip install symbolicai
One can run our framework in two ways:

using local engines (experimental) that are run on your local machine (see Local Neuro-Symbolic Engine section), or
using engines powered by external APIs, i.e. using OpenAI's API (see API Keys).
API Keys
Before the first run, define exports for the required API keys to enable the respective engines. This will register the keys in the internally for subsequent runs. By default SymbolicAI currently uses OpenAI's neural engines, i.e. GPT-3 Davinci-003, DALLÂ·E 2 and Embedding Ada-002, for the neuro-symbolic computations, image generation and embeddings computation respectively. However, these modules can easily be replaced with open-source alternatives. Examples are

OPT or Bloom for neuro-symbolic computations,
Craiyon for image generation,
and any BERT variants for semantic embedding computations.
To set the OpenAI API Keys use the following command:

# Linux / MacOS
export OPENAI_API_KEY="<OPENAI_API_KEY>"

# Windows (PowerShell)
$Env:OPENAI_API_KEY="<OPENAI_API_KEY>"

# Jupyter Notebooks (important: do not use quotes)
%env OPENAI_API_KEY=<OPENAI_API_KEY>
To get started import our library by using:

import symai as ai
Overall, the following engines are currently supported:

Neuro-Symbolic Engine: OpenAI's LLMs (GPT-3)
Embedding Engine: OpenAI's Embedding API
[Optional] Symbolic Engine: WolframAlpha
[Optional] Search Engine: SerpApi
[Optional] OCR Engine: APILayer
[Optional] SpeechToText Engine: OpenAI's Whisper
[Optional] WebCrawler Engine: Selenium
[Optional] Image Rendering Engine: DALLÂ·E 2
[Optional] Indexing Engine: Pinecone
[Optional] CLIP Engine: hugs Hugging Face (experimental image and text embeddings)
[Optional] Installs
SymbolicAI uses multiple engines to process text, speech and images. We also include search engine access to retrieve information from the web. To use all of them, you will need to install also the following dependencies or assign the API keys to the respective engines.

If you want to use the WolframAlpha Engine, Search Engine or OCR Engine you will need to export the following API keys:

# Linux / MacOS
export SYMBOLIC_ENGINE_API_KEY="<WOLFRAMALPHA_API_KEY>"
export SEARCH_ENGINE_API_KEY="<SERP_API_KEY>"
export OCR_ENGINE_API_KEY="<APILAYER_API_KEY>"
export INDEXING_ENGINE_API_KEY="<PINECONE_API_KEY>"

# Windows (PowerShell)
$Env:SYMBOLIC_ENGINE_API_KEY="<WOLFRAMALPHA_API_KEY>"
$Env:SEARCH_ENGINE_API_KEY="<SERP_API_KEY>"
$Env:OCR_ENGINE_API_KEY="<APILAYER_API_KEY>"
$Env:INDEXING_ENGINE_API_KEY="<PINECONE_API_KEY>"
To use them, you will also need to install the following dependencies:

SpeechToText Engine: ffmpeg for audio processing (based on OpenAI's whisper)
# Linux
sudo apt update && sudo apt install ffmpeg

# MacOS
brew install ffmpeg

# Windows
choco install ffmpeg
[Note] Additionally, you need to install the newest version directly from their repository, since the version available via pip is outdated:

pip install git+https://github.com/openai/whisper.git
WebCrawler Engine: For selenium, download the corresponding driver version by setting the SELENIUM_CHROME_DRIVER_VERSION environment variable. Currently we use Chrome as the default browser. This means that the Chrome version major number must match the ChromeDriver version. All versions are available here. For example, if you use chrome version 109.0.5414.74, you can set any 109.x.x.x version for the chromedriver. In this case the 109.0.5414.74 is available on the selenium page, therefore the environment variable is set to it:
# Linux / MacOS
export SELENIUM_CHROME_DRIVER_VERSION="109.0.5414.74"

# Windows (PowerShell)
$Env:SELENIUM_CHROME_DRIVER_VERSION="109.0.5414.74"
Alternatively, you can specify in your project path a symai.config.json file with all the engine properties. This will replace the environment variables. See the following configuration file as an example:

{
    "NEUROSYMBOLIC_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "NEUROSYMBOLIC_ENGINE_MODEL": "text-davinci-003",
    "SYMBOLIC_ENGINE_API_KEY": "<WOLFRAMALPHA_API_KEY>",
    "EMBEDDING_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "EMBEDDING_ENGINE_MODEL": "text-embedding-ada-002",
    "IMAGERENDERING_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "VISION_ENGINE_MODEL": "openai/clip-vit-base-patch32",
    "SEARCH_ENGINE_API_KEY": "<SERP_API_KEY>",
    "SEARCH_ENGINE_MODEL": "google",
    "OCR_ENGINE_API_KEY": "<APILAYER_API_KEY>",
    "SPEECH_ENGINE_MODEL": "base",
    "SELENIUM_CHROME_DRIVER_VERSION": "110.0.5481.30",
    "INDEXING_ENGINE_API_KEY": "<PINECONE_API_KEY>",
    "INDEXING_ENGINE_ENVIRONMENT": "us-west1-gcp"
}
t-rex Apps
Over the course of th next weeks, we will expand our experimental demo apps and provide a set of useful tools that showcase how to interact with our framework. These apps are made available by calling the sym+<shortcut-name-of-app> command in your terminal or PowerShell.

Shell Command Tool
You can start a basic shell command support tool that translates natural language commands into shell commands. To start the shell command tool, simply run:

symsh "<your-query>"
You can also use the --help flag to get more information about the tool and available arguments.

symsh --help
Here is an example of how to use the tool:

$> symsh "PowerShell edit registiry entry"

# :Output:
# Set-ItemProperty -Path <path> -Name <name> -Value <value>

$> symsh "Set-ItemProperty -Path <path> -Name <name> -Value <value>" --add "path='/Users/myuser' name=Demo value=SymbolicAI"

# :Output:
# Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI

$> symsh "Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI" --del "string quotes"

# :Output:
# Set-ItemProperty -Path /Users/myuser -Name Demo -Value SymbolicAI

$> symsh "Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI" --convert "linux"

# :Output:
# export Demo="SymbolicAI"
Chatbot
You can start a basic conversation with Symbia. Symbia is a chatbot that uses SymbolicAI to detect the content of your request and switch between different contextual modes to answer your questions. These mode include search engines, speech engines and more. To start the chatbot, simply run:

symchat
This will start now a chatbot interface:

Symbia: Hi there! I'm Symbia, your virtual assistant. How may I help you?
$> 
You can exit the conversation by either typing exit, quit or pressing Ctrl+C.

100 Other Use Cases
We compiled a few examples to show how to use our Symbolic API. You can find them in the notebooks folder.

Basics: See our basics notebook to get familiar with our API structure (notebooks/Basics.ipynb)
Queries: See our query manipulation notebook for contextualized operations (notebooks/Queries.ipynb)
News & Docs Generation: See our news and documentation generation notebook for stream processing (notebooks/News.ipynb)
ChatBot: See how to implement a custom chatbot based on semantic narrations (notebooks/ChatBot.ipynb)
You can solve many more problems with our Symbolic API. We are looking forward to see what you will build with it. Keep us posted on our shared community space on Discord: AI Is All You Need / SymbolicAI.

Community demos
We are listing all your cool demos and tools that you build with our framework. If you want to add your project just PM on Twitter at @SymbolicAPI or via Discord.

man_shrugging Why SymbolicAI?
SymbolicAI tries to close the gap between classical programming or Software 1.0 and modern data-driven programming (aka Software 2.0). It is a framework that allows to build software applications, which are able to utilize the power of large language models (LLMs) wtih composability and inheritance - two powerful concepts from the object-oriented classical programming paradigm.

This allows to move along the spectrum between the classical programming realm and data-driven programming realm as illustrated in the following figure:



As briefly mentioned, we adopt a divide and conquer approach to decompose a complex problem into smaller problems. We then use the expressiveness and flexibility of LLMs to evaluate these sub-problems and by re-combining these operations we can solve the complex problem.

In this turn, and with enough data, we can gradually transition between general purpose LLMs with zero and few-shot learning capabilities, and specialized fine-tuned models to solve specific problems (see above). This means that each operations could be designed to use a model with fine-tuned task-specific behavior.

 Tell me some more fun facts!
In its essence, SymbolicAI was inspired by the neuro-symbolic programming paradigm.

Neuro-symbolic programming is a paradigm for artificial intelligence and cognitive computing that combines the strengths of both deep neural networks and symbolic reasoning.

Deep neural networks are a type of machine learning algorithms that are inspired by the structure and function of biological neural networks. They are particularly good at tasks such as image recognition, natural language processing etc. However, they are not as good at tasks that require explicit reasoning, such as long-term planning, problem solving, and understanding causal relationships.

Symbolic reasoning, on the other hand uses formal languages and logical rules to represent knowledge and perform tasks such as planning, problem solving, and understanding causal relationships. Symbolic reasoning systems are good at tasks that require explicit reasoning, but are not as good at tasks that require pattern recognition or generalization, such as image recognition or natural language processing.

Neuro-symbolic programming aims to combine the strengths of both neural networks and symbolic reasoning to create AI systems that can perform a wide range of tasks. One way this is done is by using neural networks to extract information from data and then using symbolic reasoning to make inferences and decisions based on that information. Another way is to use symbolic reasoning to guide the generative process of neural networks and make them more interpretable.

Embedded accelerators for LLMs will, in our opinion, be ubiquitous in future computation platforms, such as wearables, smartphones, tablets or notebooks. They will contain models similar to GPT-3, ChatGPT, OPT or Bloom.



These LLMs will be able to perform a wide range of computations, such as natural language understanding or decision making. Furthermore, neuro-symbolic computation engines will be able to learn concepts how to tackle unseen tasks and solve complex problems by querying various data sources for solutions and executing logical statements on top. In this turn, to ensure the generated content is in alignment with our goals, we need to develop ways to instruct, steer and control the generative processes of machine learning models. Therefore, our approach is an attempt to enable active and transparent flow control of these generative processes.



As shown in the figure above, one can think of this generative process as shifting a probability mass of an input stream of data towards an output stream of data, in a contextualized manner. With properly designed conditions and expressions, one can also validate and steer the behavior towards a desired outcome, or repeat expressions that failed to fulfil our requirements. Our approach is to define a set of fuzzy operations that manipulate the data stream and conditions the LLMs to align with our goals. In essence, we consider all data objects, such as strings, letters, integers, arrays, etc. as symbols and we see natural language as the main interface to interact with. See the following figure:



We show that as long as we can express our goals in natural language, we can use the power of LLMs for neuro-symbolic computations. In this turn, we create operations that manipulate these symbols to generate new symbols from them. Each symbol can be interpreted as a statement. Multiple statements can be combined to form a logical expression.

Therefore, by chaining statements together we can build causal relationships and computations, instead of relying only on inductive approaches. Consequently, the outlook towards an updated computational stack resembles a neuro-symbolic computation engine at its core and, in combination with established frameworks, enables new applications.

face_in_clouds How does it work?
We now show how we define our Symbolic API, which is based on object-oriented and compositional design patterns. The Symbol class is the base class for all functional operations, which we refer to as a terminal symbol in the context of symbolic programming (fully resolved expressions). The Symbol class holds helpful operations that can be interpreted as expressions to manipulate its content and evaluate to new Symbols.

books Symbolic operations
Let us now define a Symbol and perform some basic manipulations. We start with a translation operation:

sym = ai.Symbol("Welcome to our tutorial.")
sym.translate('German')
:[Output]: 
<class 'symai.expressions.Symbol'>(value=Willkommen zu unserem Tutorial.)
Ranking objects
Our API can also perform basic data-agnostic operations to filter, rank or extract patterns. For example, we can rank a list of numbers:

sym = ai.Symbol(numpy.array([1, 2, 3, 4, 5, 6, 7]))
res = sym.rank(measure='numerical', order='descending')
:[Output]: 
<class 'symai.expressions.Symbol'>(value=['7', '6', '5', '4', '3', '2', '1'])
Evaluating Expressions by best effort
As an inspiration, we relate to an approach demonstrated by word2vec.

Word2Vec generates dense vector representations of words by training a shallow neural network to predict a word given its neighbors in a text corpus. The resulting vectors are then used in a wide range of natural language processing applications, such as sentiment analysis, text classification, and clustering.

Below we can see an example how one can perform operations on the word embeddings (colored boxes). The words are tokenized and mapped to a vector space, where we can perform semantic operations via vector arithmetics.



Similar to word2vec we intend to perform contextualized operations on different symbols, however, instead of operating in the vector space, we operate in the natural language domain. This gives us the ability to perform arithmetics on words, sentences, paragraphs, etc. and verify the results in a human readable format.

The following examples show how to evaluate such an expression via a string representation:

ai.Symbol('King - Man + Women').expression()
:[Output]:
<class 'symai.expressions.Symbol'>(value=Queen)
Dynamic casting
We can also subtract sentences from each other, where our operations condition the neural computation engine to evaluate the Symbols by best effort. In the following example, it determines that the word enemy is present in the sentence, therefore deletes it and replaces it with the word friend (which is added):

res = ai.Symbol('Hello my enemy') - 'enemy' + 'friend'
:[Output]: 
<class 'symai.expressions.Symbol'>(value=Hello my friend)
What we also see is that the API performs dynamic casting, when data types are combined with a Symbol object. If an overloaded operation of the Symbol class is used, the Symbol class can automatically cast the second object to a Symbol. This is a convenient modality to perform operations between Symbolobjects and other types of data, such as strings, integers, floats, lists, etc. without bloating the syntax.1 / 1ChatGPTChatGPTIn the given code snippet, the SymbolicAI library is imported and various operations and functionalities of the Symbol class are demonstrated. Here's a breakdown of the code:Translation operation:pythonCopy codesym = ai.Symbol("Welcome to our tutorial.")
sym.translate('German')
This code creates a Symbol object with the value "Welcome to our tutorial." and then performs a translation operation to translate it to German. The translated result is displayed.Ranking objects:pythonCopy codesym = ai.Symbol(numpy.array([1, 2, 3, 4, 5, 6, 7]))
res = sym.rank(measure='numerical', order='descending')
This code creates a Symbol object with an array of numbers and then ranks them in descending order based on the numerical measure. The ranked result is displayed.Evaluating Expressions by best effort:pythonCopy codeai.Symbol('King - Man + Women').expression()
This code evaluates the expression 'King - Man + Women' by performing arithmetic operations on the words. The resulting Symbol object with the evaluated value is displayed.Dynamic casting:pythonCopy coderes = ai.Symbol('Hello my enemy') - 'enemy' + 'friend'
This code performs dynamic casting and manipulation of sentences. It subtracts the word 'enemy' from the sentence 'Hello my enemy' and adds the word 'friend'. The resulting Symbol object with the modified sentence is displayed.The Symbol class in SymbolicAI allows for various symbolic operations and manipulations of data, providing a flexible and expressive way to work with natural language.1 / 1Fuzzy Comparisons
In this example we are fuzzily comparing two number objects, where the Symbol variant is only an approximation of numpy.pi. Given the context of the fuzzy equals == operation, this comparison still succeeds and returns True.

sym = ai.Symbol('3.1415...')
sym == numpy.pi
:[Output]:
True
brain Causal Reasoning
Our framework was built with the intention to enable reasoning capabilities on top of statistical inference of LLMs. Therefore, we can also perform deductive reasoning operations with our Symbol objects. For example, we can define a set of operations with rules that define the causal relationship between two symbols. The following example shows how the & is used to compute the logical implication of two symbols.

res = ai.Symbol('The horn only sounds on Sundays.') & ai.Symbol('I hear the horn.')
:[Output]:
<class 'symai.expressions.Symbol'>(value=It is Sunday.)
The current &-operation overloads the and logical operator and sends few-shot prompts how to evaluate the statement to the neural computation engine. However, we can define more sophisticated logical operators for and, or and xor via formal proof statements and use the neural engines to parse data structures prior to our expression evaluation. Therefore, one can also define custom operations to perform more complex and robust logical operations, including constraints to validate the outcomes and ensure a desired behavior.

To provide a more complete picture, we also sketch more comprehensive causal examples below, where one tries to obtain logical answers, based on questions of the kind:

# 1) "A line parallel to y = 4x + 6 passes through (5, 10). What is the y-coordinate of the point where this line crosses the y-axis?"
# 2) "Bob has two sons, John and Jay. Jay has one brother and father. The father has two sons. Jay's brother has a brother and a father. Who is Jay's brother."
# 3) "is 1000 bigger than 1063.472?"
To give an rough idea of how we would approach this with our framework is by, first, using a chain of operations to detect the neural engine that is best suited to handle this task, and second, prepare the input for the respective engine. Let's see an example:

val = "<one of the examples above>"

# First define a class that inherits from the Expression class
class ComplexExpression(ai.Expression): # more to the Expression class in later sections
    # write a method that returns the causal evaluation
    def causal_expression(self):
        pass # see below for implementation

# instantiate an object of the class
expr = ComplexExpression(val)
# set WolframAlpha as the main expression engine to use
expr.command(engines=['symbolic'], expression_engine='wolframalpha')
# evaluate the expression
res = expr.causal_expression()
Now, the implementation of causal_expression could in principle look like this:

def causal_expression(self):
    # very which case to use `self.value` contains the input
    if self.isinstanceof('mathematics'):
        # get the mathematical formula
        formula = self.extract('mathematical formula')
        # verify which problem type we have
        if formula.isinstanceof('linear function'):
            # prepare for wolframalpha
            question = self.extract('question sentence')
            req = question.extract('what is requested?')
            x = self.extract('coordinate point (.,.)') # get coordinate point / could also ask for other points
            query = formula @ f', point x = {x}' @ f', solve {req}' # concatenate to the question and formula
            res = query.expression(query) # send prepared query to wolframalpha

        elif formula.isinstanceof('number comparison'):
            res = formula.expression() # send directly to wolframalpha

        ... # more cases

    elif self.isinstanceof('linguistic problem'):
        sentences = self / '.' # first split into sentences
        graph = {} # define graph
        for s in sentences:
            sym = ai.Symbol(s)
            relations = sym.extract('connected entities (e.g. A has three B => A | A: three B)') / '|' # and split by pipe
            for r in relations:
                ... # add relations and populate graph => alternatively, read also about CycleGT

    ... # more cases
    return res
The above example shows how we can use the causal_expression expression method to step-wise iterate and extract information which we can then either manually or using external solvers resolve.

Attention: We hint the reader that this is a very rough sketch and that the implementation of the causal_expression method would need much more engineering effort. Furthermore, the currently used GPT-3 LLM backend often fails to extract the correct information or resolve the right comparison. However, we strongly believe in the advances of the field and that this will change in the future, specifically with fine-tuned models like ChatGPT with Reinforcement Learning from Human Feedback (RLHF).

Lastly, it is also noteworthy that given enough data, we could fine-tune methods that extract information or build our knowledge graph from natural language. This would enable us to perform more complex reasoning tasks, such as the ones mentioned above. Therefore, we also point the reader to recent publications for translating Text-to-Graphs. This means that in the attempt to answer the query, we can simply traverse the graph and extract the information we need.

In the next section, we will explore operations.

mask Operations
Operations are at the core of our framework. They are the building blocks of our API and are used to define the behavior of our symbols. We can think of operations as contextualized functions that take in a Symbol object, send it to the neuro-symbolic engine for evaluation, and return one or multiple new objects (mainly new symbols; but not necessarily limited to that). Another fundamental property is polymorphism, which means that operations can be applied to different types of data, such as strings, integers, floats, lists, etc. with different behaviors, depending on the object instance.

The way we execute operations is by using the Symbol object value attribute containing the original data type that is then sent as a string representations to the engines to perform the operations. Therefore all values are casted to a string representation. This also means, that for custom objects one needs to define a proper __str__ method to cast the object to a string representation and ensure preservation of the semantics of that object.

Lastly, we need to talk about inheritance. Our API is built on top of the Symbol class, which is the base class of all operations. This means that all operations are inherited from the Symbol class. This provides a convenient modality to add new custom operations by sub-classing Symbol, yet, ensuring to always have a set of base operations at our disposal without bloating the syntax or re-implementing many existing functionalities. This also means that we can define contextualized operations with individual constraints, prompt designs and therefore behaviors by simply sub-classing the Symbol class and overriding the corresponding method. However, we recommend sub-classing the Expression class as we will see later, it adds additional functionalities.

Here is an example of how to define a custom == operation by overriding the __eq__ method and providing a custom prompt object with a list of examples:

class Demo(ai.Symbol):
    def __eq__(self, other) -> bool:
        @ai.equals(examples=ai.Prompt([
              "1 == 'ONE' =>True",
              "'six' == 7 =>False",
              "'Acht' == 'eight' =>True",
              ...
          ])
        )
        def _func(_, other) -> bool:
            return False # default behavior on failure
        return _func(self, other)
As shown in the above example, this is also the way we implemented the basic operations in Symbol, by defining local functions that are then decorated with the respective operation decorator from the symai/core.py file. The symai/core.py is a collection of pre-defined operation decorators that we can quickly apply to any function. The reason why we use locally defined functions instead of directly decorating the main methods, is that we do not necessarily want that all our operations are sent to the neural engine and could implement a default behavior. Another reason is that we want to cast return types of the operation outcome to symbols or other derived classes thereof. This is done by using the self._sym_return_type(...) method and can give contextualized behavior based on the defined return type. See more details in the actual Symbol class.

In the next section, we will show that almost all operations in symai/core.py are derived from the more generic few_shot decorator.

test_tube Custom Operations
One can also define customized operations. For example, let us define a custom operation to generate a random integer between 0 and 10:

class Demo(ai.Symbol):
    def __init__(self, value = '') -> None:
        super().__init__(value)
    
    @ai.zero_shot(prompt="Generate a random integer between 0 and 10.",
                  constraints=[
                      lambda x: x >= 0,
                      lambda x: x <= 10
                  ])
    def get_random_int(self) -> int:
        pass
As we show, the Symbolic API uses Python Decorators to define operations. The @ai.zero_shot decorator is used to define a custom operation that does not require any demonstration examples, since the prompt is expressive enough. In the shown example, the zero_shot decorator takes in two arguments: prompt and constraints. The former is used to define the prompt that conditions our desired operation behavior. The latter is used to define validation constraints of the computed outcome, to ensure it fulfills our expectations.

If the constraint is not fulfilled, the above implementation would reach out to the specified default implementation or default value. If no default implementation or value was found, the Symbolic API would raise an ConstraintViolationException.

We also see that in the above example the return type is defined as int. Therefore, the resulting value from the wrapped function will be of type int. This works because our implementation uses auto-casting to a user specified return data type. If the cast fails, the Symbolic API will raise a ValueError. If no return type is specified, the return type will be Any.

Few-shot operations
The @ai.few_shot decorator is the a generalized version of @ai.zero_shot and is used to define a custom operation that requires demonstration examples. To give a more complete picture, we present the function signature of the few_shot decorator:

def few_shot(prompt: str,
             examples: Prompt, 
             constraints: List[Callable] = [],
             default: Optional[object] = None, 
             limit: int = 1,
             pre_processor: Optional[List[PreProcessor]] = None,
             post_processor: Optional[List[PostProcessor]] = None,
             **wrp_kwargs):
The prompt and constraints attributes behavior is similar to the zero_shot decorator. The examples and limit arguments are new. The examples argument is used to define a list of demonstrations that are used to condition the neural computation engine. The limit argument is used to define the maximum number of examples that are returned, give that there are more results. The pre_processor argument takes a list of PreProcessor objects which can be used to pre-process the input before it is fed into the neural computation engine. The post_processor argument takes a list of PostProcessor objects which can be used to post-process the output before it is returned to the user. The wrp_kwargs argument is used to pass additional arguments to the wrapped method, which are also stream-lined towards the neural computation engine and other engines.

To give a more holistic picture ouf our conceptional implementation, see the following flow diagram containing the most important classes:



The colors indicate logical groups of data processing steps. Yellow indicates the input and output data. Blue indicates places you can customize or prepare the input of your engine. Green indicates post-processing steps of the engine response. Red indicates the application of constraints (which also includes the attempted casting of the return type signature, if specified in the decorated method). Grey indicates the custom method which defines all properties, therefore has access to all the above mentioned objects.

To conclude this section, here is an example how to write a custom Japanese name generator with our @ai.zero_shot decorator:

import symai as ai
class Demo(ai.Symbol):
    @ai.few_shot(prompt="Generate Japanese names: ",
                 examples=ai.Prompt(
                   ["æå­", "åè±", "ä¸é", "åæ"]
                 ),
                 limit=2,
                 constraints=[lambda x: len(x) > 1])
    def generate_japanese_names(self) -> list:
        return ['æå­', 'åè±'] # dummy implementation
Should the neural computation engine not be able to compute the desired outcome, it will reach out to the default implementation or default value. If no default implementation or value was found, the method call will raise an exception.

Prompt Design
The way all the above operations are performed is by using a Prompt class. The Prompt class is a container for all the information that is needed to define a specific operation. The Prompt class is also the base class for all other Prompt classes.

Here is an example how to define a Prompt to enforce the neural computation engine for comparing two values:

class CompareValues(ai.Prompt):
    def __init__(self) -> ai.Prompt:
        super().__init__([
            "4 > 88 =>False",
            "-inf < 0 =>True",
            "inf > 0 =>True",
            "4 > 3 =>True",
            "1 < 'four' =>True",
            ...
        ])
For example, when calling the <= operation on two Symbols, the neural computation engine will evaluate the symbols in the context of the CompareValues prompt.

res = ai.Symbol(1) <= ai.Symbol('one')
This statement evaluates to True, since the fuzzy compare operation was conditions our engine to compare the two Symbols based on their semantic meaning.

:[Output]:
True
In a more general notion, depending on the context hierarchy of the expression class and used operations the semantics of the Symbol operations may vary. To better illustrate this, we show our conceptual prompt design in the following figure:



The figure shows our hierarchical prompt design as a container of all the information that is provided to the neural computation engine to define a task-specific operation. The Yellow and Green highlighted boxes indicate mandatory string placements. The dashed boxes are optional placeholders. and the Red box indicates the starting point of the model prediction.

Conceptually we consider three main prompt designs: Context-based Prompts, Operational Prompts, and Templates. The prompts can be curated either by inheritance or by composition. For example, the Static Context can be defined by inheriting from the Expression class and overriding the static_context property. An Operation and Template prompt can be created by providing an PreProcessor to modify the input data.

We will now explain each prompt concept in more details:

The Context-based Prompts (Static, Dynamic and Payload) are considered optional and can be defined in a static manner, either by sub-classing the Expression class and overriding the static_context property, or at runtime by updating the dynamic_context property or passing an payload kwargs to a method. Here is an example how to use the payload kwargs via the method signature:

# creating a query to ask if an issue was resolve or not
sym = Symbol("<some-community-conversation>")
q = sym.query("Was the issue resolved?")
# write manual condition to check if the issue was resolved
if 'not resolved' in q:
    # do a new query but payload the previous query answer to the new query
    sym.query("What was the resolution?", payload=q)
    ...
else:
    pass # all good
Regardless of how we set the context, our contextualized prompt defines the desired behavior of the Expression operations. For example, if we want to operate in the context of a domain-specific language, without having to override each base class method. See more details in this notebook.

The Operation prompts define the behavior of an atomic operation and is therefore mandatory to express the nature of such an operation. For example, the +-operation is used to add two Symbols together and therefore the +-operation prompt explains its behavior. Examples defines another optional structure that provides the neural computation engine with a set of demonstrations that are used to properly condition the engine. For example, the +-operation prompt can be conditioned on how to add numbers by providing a set of demonstrations, such as 1 + 1 = 2, 2 + 2 = 4, etc.

The Template prompts are optional and encapsulates the resulting prediction to enforce a specific format. For example, to generate HTML tags we can use a curated <html>{{placeholder}}</html> template. This template will enforce the neural computation engine to start the generation process already in the context of a HTML tags format, and not produce irrelevant descriptions about its task.

expressionless Expressions
An Expression is a non-terminal symbol, which can be further evaluated. It inherits all the properties from Symbol and overrides the __call__ method to evaluate its expressions or values. From the Expression class, all other expressions are derived. The Expression class also adds additional capabilities i.e. to fetch data from URLs, search on the internet or open files. These operations are specifically separated from Symbol since they do not use the value attribute of the Symbol class.

SymbolicAI' API closely follows best practices and ideas from PyTorch, therefore, one can build complex expressions by combining multiple expressions as a computational graph. Each Expression has its own forward method, which has to be overridden. The forward method is used to define the behavior of the expression. The forward method is called by the __call__ method, which is inherited from the Expression base class. The __call__ evaluates an expression and returns the result from the implemented forward method. This design pattern is used to evaluate the expressions in a lazy manner, which means that the expression is only evaluated when the result is needed. This is a very important feature, since it allows us to chain complex expressions together. We already implemented many useful expressions, which can be imported from the symai.components file.

Other important properties that are inherited from the Symbol class are _sym_return_type and static_context. These two properties define the context in which the current Expression operates, as described in the Prompt Design section. The static_context therefore influences all operations of the current Expression sub-class. The _sym_return_type ensures that after each evaluation of an Expression, we obtain the desired return object type. This is usually implemented to return the current type, but can be set to return a different type.

Expressions can of course have more complex structures and be further sub-classed, such as shown in the example of the Sequence expression in the following figure:



A Sequence expression can hold multiple expressions, which are evaluated at runtime.

Sequence expressions
Here is an example how to define a Sequence expression:

# first import all expressions
from symai import *
# define a sequence of expressions
Sequence(
    Clean(),
    Translate(),
    Outline(),
    Compose('Compose news:'),
)
Stream expressions
As we saw earlier, we can create contextualized prompts to define the behavior of operations on our neural engine. However, this also takes away a lot of the available context size and since e.g. the GPT-3 Davinci context length is limited to 4097 tokens, this might quickly become a problem. Luckily, we can use the Stream processing expression. This expression opens up a data stream and performs chunk-based operations on the input stream.

A Stream expression can easily be wrapped around other expressions. For example, the chunks can be processed with a Sequence expression, that allows multiple chained operations in sequential manner. Here is an example how to define such a Stream expression:

Stream(Sequence(
    Clean(),
    Translate(),
    Outline(),
    Embed()
))
The shown example opens a stream, passes a Sequence object which cleans, translates, outlines and embeds the input. Internally, the stream operation estimates the available model context size and chunks the long input text into smaller chunks, which are passed to the inner expression. The returned object type is a generator.

The issue with this approach is, that the resulting chunks are processed independently. This means there is no shared context or information among chunks. To solve this issue, we can use the Cluster expression instead, where the independent chunks are merged based on their similarity. We illustrate this in the following figure:



In the shown example all individual chunks are merged by clustering the information within each chunk. This gives us a way to consolidate contextually related information and merge them in a meaningful way. Furthermore, the clustered information can then be labeled by streaming through the content of each cluster and extracting the most relevant labels, providing us with interpretable node summaries.

The full example is shown below:

stream = Stream(Sequence(
    Clean(),
    Translate(),
    Outline(),
))
sym = Symbol('<some long text>')
res = Symbol(list(stream(sym)))
expr = Cluster()
expr(res)
In a next step, we could recursively repeat this process on each summary node, therefore, build a hierarchical clustering structure. Since each Node resembles a summarized sub-set of the original information we can use the summary as an index. The resulting tree can then be used to navigate and retrieve the original information, turning the large data stream problem into a search problem.

Alternatively, we could use vector-base similarity search to find similar nodes. For searching in a vector space we can use dedicated libraries such as Annoy, Faiss or Milvus.1 / 1ChatGPTChatGPTThe example you provided demonstrates the use of fuzzy comparisons and causal reasoning in the SymbolicAI framework. It shows how you can perform fuzzy comparisons between Symbol objects and how the framework enables deductive reasoning using logical operators.In the first example, a fuzzy comparison is made between a Symbol object and the numpy.pi constant. The comparison succeeds and returns True because the Symbol object is an approximation of numpy.pi.The second part introduces causal reasoning using the & operator. The example shows how you can define a causal relationship between two symbols and compute the logical implication using the & operator. In this case, the result is a Symbol object representing the statement "It is Sunday." The current implementation overloads the and logical operator to perform causal reasoning and sends prompts to the neural computation engine to evaluate the statement.The next section discusses the concept of operations in the SymbolicAI framework. Operations are the building blocks of the framework and define the behavior of symbols. They can be applied to different types of data and have different behaviors based on the object instance.Custom operations can be defined by sub-classing the Symbol class and overriding specific methods. The framework provides operation decorators that can be used to define custom operations with or without demonstration examples. These decorators allow you to define prompts and constraints to condition the behavior of the operation.The framework also provides the ability to define prompts using the Prompt class. Prompts encapsulate the information needed to define a specific operation, including demonstrations and constraints.Expressions are non-terminal symbols that can be further evaluated. They inherit properties from the Symbol class and can override the call method to evaluate their expressions. Expressions can be combined to build complex computational graphs, and the framework provides pre-defined expressions that can be imported and used.The Stream expression is introduced as a way to process data streams and perform chunk-based operations. It allows chaining multiple operations in a sequential manner. The Stream expression chunks the input data and passes it to the inner expressions for processing. The Cluster expression can be used to merge the chunks based on similarity, enabling the consolidation of contextually related information.The framework provides a flexible and customizable way to define operations, prompts, and expressions, allowing for complex symbolic reasoning and processing of data streams.1 / 1x Error Handling
A key idea of the SymbolicAI API is to be able to generate code. This in turn means that errors may occur, which we need to handle in a contextual manner. As a future vision, we even want our API to self extend and therefore need to be able to resolve issues automatically. To do so, we propose the Try expression, which has a fallback statements built-in and retries an execution with dedicated error analysis and correction. This expression analyses the input and the error, and conditions itself to resolve the error by manipulating the original code. If the fallback expression succeeds, the result is returned. Otherwise, this process is repeated for the number of retries specified. If the maximum number of retries is reached and the problem was not resolved, the error is raised again.

Let us assume, we have some executable code that was previously generated. However, by the nature of generative processes syntax errors may occur. By using the Execute expression, we can evaluate our generated code, which takes in a symbol and tries to execute it. Naturally, this will fail. However, in the following example the Try expression resolves this syntactic error and the receive a computed result.

expr = Try(expr=Execute())
sym = Symbol('a = int("3,")') # some code with a syntax error
res = expr(sym)
The resulting output is the evaluated code, which was corrected:

:Output:
a = 3
We are aware that not all errors are as simple as the shown syntactic error example, which can be resolved automatically. Many errors occur due to semantic misconceptions. Such issues require contextual information. Therefore, we are further exploring means towards more sophisticated error handling mechanism. This includes also the usage of streams and clustering to resolve errors in a more hierarchical contextual manner. It is also noteworthy that neural computations engines need to be further improved to better detect and resolve errors.

spider Interpretability, Testing & Debugging
Perhaps one of the greatest benefits of using neuro-symbolic programming is, that we can get a clear understanding of how well our LLMs understand simple operations. Specifically we gain knowledge about if, and at which point they fail, enabling us to follow their StackTraces and determine the failure points. In our case, neuro-symbolic programming allows us to debug the model predictions based on dedicated unit test for simple operations. To detect conceptual misalignments we can also use a chain of neuro-symbolic operations and validate the generative process. This is of course not a perfect solution, since the verification may also be error prone, but it gives us at least a principle way to detect conceptual flaws and biases in our LLMs.

Unit Testing Models
Since our premise is to divide and conquer complex problems, we can curate conceptual unit test and target very specific and tracktable sub-problems. The resulting measure, i.e. success rate of the model prediction, can then be used to evaluate their performance, and hint towards undesired flaws or biases.

This allows us to design domain-specific benchmarks and see how well general learners, such as GPT-3, adapt with certain prompts to a set of tasks.

For example, we can write a fuzzy comparison operation, that can take in digits and strings alike, and perform a semantic comparison. LLMs can then be asked to evaluate these expressions. Often times, these LLMs still fail to understand the semantic equivalence of tokens in digits vs strings and give wrong answers.

The following code snipped shows a unit test to perform semantic comparison of numbers (between digits and strings):

import unittest
from symai import *

class TestComposition(unittest.TestCase):
  def test_compare(self):
      res = Symbol(10) > Symbol(5)
      self.assertTrue(res)
      res = Symbol(1) < Symbol('five')
      self.assertTrue(res)
      ...
fireDebugging
When creating very complex expressions, we debug them by using the Trace expression, which allows to print out the used expressions, and follow the StackTrace of the neuro-symbolic operations. Combined with the Log expression, which creates a dump of all prompts and results to a log file, we can analyze where our models potentially failed.

Example: News Summary
In the following example we create a news summary expression that crawls the given URL and streams the site content through multiple expressions. The outcome is a news website that is created based on the crawled content. The Trace expression allows to follow the StackTrace of the operations and see what operations are currently executed. If we open the outputs/engine.log file we can see the dumped traces with all the prompts and results.

# crawling the website and creating an own website based on its facts
news = News(url='https://www.cnbc.com/cybersecurity/',
            pattern='cnbc',
            filters=ExcludeFilter('sentences about subscriptions, licensing, newsletter'),
            render=True)
expr = Log(Trace(news))
res = expr()
Here is the corresponding StackTrace of the model:



The above code creates a webpage with the crawled content from the original source. See the preview below, the entire rendered webpage image here and resulting [code of webpage here](https://raw.githubusercontent.com/Xpitfire/symbolicai/main/examples/results/news.html.
1 / 1ChatGPTChatGPTThe next section discusses error handling in the SymbolicAI API and the use of the Try expression to handle errors and resolve issues automatically. The Try expression analyzes the input and error, and attempts to resolve the error by manipulating the original code. If the fallback expression succeeds, the result is returned. Otherwise, the process is repeated for the specified number of retries. If the maximum number of retries is reached and the problem is not resolved, the error is raised again.An example is provided where the Execute expression is used to evaluate some generated code that contains a syntax error. The Try expression is used to handle the error and correct the code. The resulting output is the evaluated code with the syntax error resolved.The framework aims to improve error handling mechanisms, including the use of streams and clustering to resolve errors in a more hierarchical and contextual manner. It acknowledges that not all errors can be automatically resolved, especially those related to semantic misconceptions. Further improvements are needed in the neural computation engines to better detect and resolve errors.The interpretability, testing, and debugging aspects of neuro-symbolic programming are highlighted as benefits of the SymbolicAI API. The use of unit testing is emphasized to evaluate the performance of the models and detect conceptual flaws or biases. Conceptual unit tests can be designed to target specific sub-problems and measure the success rate of the model predictions.Debugging complex expressions is facilitated using the Trace expression, which allows for tracing the execution and following the StackTrace of the neuro-symbolic operations. The Log expression can be used to create a log file that contains the prompts and results, enabling further analysis of potential failures.An example is provided where a news summary expression is created, which crawls a website and generates a news webpage based on the crawled content. The Trace expression is used to trace the operations and the Log expression creates a log file with the prompts and results for analysis.1 / 1

Search or jump to...
Pulls
Issues
Codespaces
Marketplace
Explore
 
@standardgalactic 
Xpitfire
/
symbolicai
Public
Fork your own copy of Xpitfire/symbolicai
Code
Issues
1
Pull requests
Actions
Projects
Security
Insights
Xpitfire/symbolicai
Latest commit
@Xpitfire
Xpitfire Added new shortcut type for creating simple LLM functions
â¦
2 days ago
Git stats
 138
Files
Type
Name
Latest commit message
Commit time
assets/images
Add files via upload
2 months ago
docs
Fixed broken link
4 months ago
examples
Fixed style composition on news component
2 months ago
notebooks
Added demo with solver + new example
4 months ago
symai
Added new shortcut type for creating simple LLM functions
2 days ago
tests
Added new shortcut type for creating simple LLM functions
2 days ago
.gitignore
Added initial experiment with graph coherence
3 months ago
CITATION.cff
Update CITATION.cff
5 months ago
CONTRIBUTING.md
Added improved documentation
5 months ago
LICENSE
Added improved documentation
5 months ago
MANIFEST.in
Added improved documentation
5 months ago
README.md
Added support for ChatGPT and GPT-4 engines
2 months ago
environment.yml
Added demo with solver + new example
4 months ago
pyproject.toml
Update pyproject.toml
2 months ago
setup.py
Added improved documentation
5 months ago
README.md
SymbolicAI


A Neuro-Symbolic Perspective on Large Language Models (LLMs)
Building applications with LLMs at its core through our Symbolic API leverages the power of classical and differentiable programming in Python.

Read further documentation here.

PyPI version License Twitter Twitter contributions welcome Discord Hits GitHub forks GitHub stars



Abstract
Conceptually, SymbolicAI is a framework that uses machine learning - and specifically LLMs - at its core, and composes operations based on task-specific prompting. We adopt a divide and conquer approach to decompose a complex problem into smaller problems. Therefore, each operation solves a simple task. By re-combining these operations we can solve the complex problem. Furthermore, our design principles allow us to transition between differentiable and classical programming, and to leverage the power of both worlds.

book Table of Contents
SymbolicAI
A Neuro-Symbolic Perspective on Large Language Models (LLMs)
Abstract
book Table of Contents
wrench Get Started
arrow_right Quick Install
API Keys
[Optional] Installs
t-rex Apps
Shell Command Tool
Chatbot
100 Other Use Cases
Community demos
man_shrugging Why SymbolicAI?
Tell me some more fun facts!
face_in_clouds How does it work?
books Symbolic operations
Ranking objects
Evaluating Expressions by best effort
Dynamic casting
Fuzzy Comparisons
brain Causal Reasoning
mask Operations
test_tube Custom Operations
Few-shot operations
Prompt Design
expressionless Expressions
Sequence expressions
Stream expressions
x Error Handling
spider Interpretability, Testing & Debugging
Unit Testing Models
fireDebugging
Example: News Summary
arrow_forward Play around with our API
chart_with_upwards_trend Interface for Query and Response Inspection
robot Engines
Symbolic Engine
Speech Engine
OCR Engine
Search Engine
WebCrawler Engine
Drawing Engine
File Engine
Indexing Engine
CLIP Engine
Local Neuro-Symbolic Engine
Custom Engine
zapLimitations
fortune_cookie Future Work
Conclusion
busts_in_silhouette References, Related Work & Credits
Comparison to other frameworks
Acknowledgements
Contribution
scroll Citation
memo License
Like this project?
mailbox Contact
wrench Get Started
arrow_right Quick Install
pip install symbolicai
One can run our framework in two ways:

using local engines (experimental) that are run on your local machine (see Local Neuro-Symbolic Engine section), or
using engines powered by external APIs, i.e. using OpenAI's API (see API Keys).
API Keys
Before the first run, define exports for the required API keys to enable the respective engines. This will register the keys in the internally for subsequent runs. By default SymbolicAI currently uses OpenAI's neural engines, i.e. GPT-3 Davinci-003, DALLÂ·E 2 and Embedding Ada-002, for the neuro-symbolic computations, image generation and embeddings computation respectively. However, these modules can easily be replaced with open-source alternatives. Examples are

OPT or Bloom for neuro-symbolic computations,
Craiyon for image generation,
and any BERT variants for semantic embedding computations.
To set the OpenAI API Keys use the following command:

# Linux / MacOS
export OPENAI_API_KEY="<OPENAI_API_KEY>"

# Windows (PowerShell)
$Env:OPENAI_API_KEY="<OPENAI_API_KEY>"

# Jupyter Notebooks (important: do not use quotes)
%env OPENAI_API_KEY=<OPENAI_API_KEY>
To get started import our library by using:

import symai as ai
Overall, the following engines are currently supported:

Neuro-Symbolic Engine: OpenAI's LLMs (GPT-3)
Embedding Engine: OpenAI's Embedding API
[Optional] Symbolic Engine: WolframAlpha
[Optional] Search Engine: SerpApi
[Optional] OCR Engine: APILayer
[Optional] SpeechToText Engine: OpenAI's Whisper
[Optional] WebCrawler Engine: Selenium
[Optional] Image Rendering Engine: DALLÂ·E 2
[Optional] Indexing Engine: Pinecone
[Optional] CLIP Engine: hugs Hugging Face (experimental image and text embeddings)
[Optional] Installs
SymbolicAI uses multiple engines to process text, speech and images. We also include search engine access to retrieve information from the web. To use all of them, you will need to install also the following dependencies or assign the API keys to the respective engines.

If you want to use the WolframAlpha Engine, Search Engine or OCR Engine you will need to export the following API keys:

# Linux / MacOS
export SYMBOLIC_ENGINE_API_KEY="<WOLFRAMALPHA_API_KEY>"
export SEARCH_ENGINE_API_KEY="<SERP_API_KEY>"
export OCR_ENGINE_API_KEY="<APILAYER_API_KEY>"
export INDEXING_ENGINE_API_KEY="<PINECONE_API_KEY>"

# Windows (PowerShell)
$Env:SYMBOLIC_ENGINE_API_KEY="<WOLFRAMALPHA_API_KEY>"
$Env:SEARCH_ENGINE_API_KEY="<SERP_API_KEY>"
$Env:OCR_ENGINE_API_KEY="<APILAYER_API_KEY>"
$Env:INDEXING_ENGINE_API_KEY="<PINECONE_API_KEY>"
To use them, you will also need to install the following dependencies:

SpeechToText Engine: ffmpeg for audio processing (based on OpenAI's whisper)
# Linux
sudo apt update && sudo apt install ffmpeg

# MacOS
brew install ffmpeg

# Windows
choco install ffmpeg
[Note] Additionally, you need to install the newest version directly from their repository, since the version available via pip is outdated:

pip install git+https://github.com/openai/whisper.git
WebCrawler Engine: For selenium, download the corresponding driver version by setting the SELENIUM_CHROME_DRIVER_VERSION environment variable. Currently we use Chrome as the default browser. This means that the Chrome version major number must match the ChromeDriver version. All versions are available here. For example, if you use chrome version 109.0.5414.74, you can set any 109.x.x.x version for the chromedriver. In this case the 109.0.5414.74 is available on the selenium page, therefore the environment variable is set to it:
# Linux / MacOS
export SELENIUM_CHROME_DRIVER_VERSION="109.0.5414.74"

# Windows (PowerShell)
$Env:SELENIUM_CHROME_DRIVER_VERSION="109.0.5414.74"
Alternatively, you can specify in your project path a symai.config.json file with all the engine properties. This will replace the environment variables. See the following configuration file as an example:

{
    "NEUROSYMBOLIC_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "NEUROSYMBOLIC_ENGINE_MODEL": "text-davinci-003",
    "SYMBOLIC_ENGINE_API_KEY": "<WOLFRAMALPHA_API_KEY>",
    "EMBEDDING_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "EMBEDDING_ENGINE_MODEL": "text-embedding-ada-002",
    "IMAGERENDERING_ENGINE_API_KEY": "<OPENAI_API_KEY>",
    "VISION_ENGINE_MODEL": "openai/clip-vit-base-patch32",
    "SEARCH_ENGINE_API_KEY": "<SERP_API_KEY>",
    "SEARCH_ENGINE_MODEL": "google",
    "OCR_ENGINE_API_KEY": "<APILAYER_API_KEY>",
    "SPEECH_ENGINE_MODEL": "base",
    "SELENIUM_CHROME_DRIVER_VERSION": "110.0.5481.30",
    "INDEXING_ENGINE_API_KEY": "<PINECONE_API_KEY>",
    "INDEXING_ENGINE_ENVIRONMENT": "us-west1-gcp"
}
t-rex Apps
Over the course of th next weeks, we will expand our experimental demo apps and provide a set of useful tools that showcase how to interact with our framework. These apps are made available by calling the sym+<shortcut-name-of-app> command in your terminal or PowerShell.

Shell Command Tool
You can start a basic shell command support tool that translates natural language commands into shell commands. To start the shell command tool, simply run:

symsh "<your-query>"
You can also use the --help flag to get more information about the tool and available arguments.

symsh --help
Here is an example of how to use the tool:

$> symsh "PowerShell edit registiry entry"

# :Output:
# Set-ItemProperty -Path <path> -Name <name> -Value <value>

$> symsh "Set-ItemProperty -Path <path> -Name <name> -Value <value>" --add "path='/Users/myuser' name=Demo value=SymbolicAI"

# :Output:
# Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI

$> symsh "Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI" --del "string quotes"

# :Output:
# Set-ItemProperty -Path /Users/myuser -Name Demo -Value SymbolicAI

$> symsh "Set-ItemProperty -Path '/Users/myuser' -Name Demo -Value SymbolicAI" --convert "linux"

# :Output:
# export Demo="SymbolicAI"
Chatbot
You can start a basic conversation with Symbia. Symbia is a chatbot that uses SymbolicAI to detect the content of your request and switch between different contextual modes to answer your questions. These mode include search engines, speech engines and more. To start the chatbot, simply run:

symchat
This will start now a chatbot interface:

Symbia: Hi there! I'm Symbia, your virtual assistant. How may I help you?
$> 
You can exit the conversation by either typing exit, quit or pressing Ctrl+C.

100 Other Use Cases
We compiled a few examples to show how to use our Symbolic API. You can find them in the notebooks folder.

Basics: See our basics notebook to get familiar with our API structure (notebooks/Basics.ipynb)
Queries: See our query manipulation notebook for contextualized operations (notebooks/Queries.ipynb)
News & Docs Generation: See our news and documentation generation notebook for stream processing (notebooks/News.ipynb)
ChatBot: See how to implement a custom chatbot based on semantic narrations (notebooks/ChatBot.ipynb)
You can solve many more problems with our Symbolic API. We are looking forward to see what you will build with it. Keep us posted on our shared community space on Discord: AI Is All You Need / SymbolicAI.

Community demos
We are listing all your cool demos and tools that you build with our framework. If you want to add your project just PM on Twitter at @SymbolicAPI or via Discord.

man_shrugging Why SymbolicAI?
SymbolicAI tries to close the gap between classical programming or Software 1.0 and modern data-driven programming (aka Software 2.0). It is a framework that allows to build software applications, which are able to utilize the power of large language models (LLMs) wtih composability and inheritance - two powerful concepts from the object-oriented classical programming paradigm.

This allows to move along the spectrum between the classical programming realm and data-driven programming realm as illustrated in the following figure:



As briefly mentioned, we adopt a divide and conquer approach to decompose a complex problem into smaller problems. We then use the expressiveness and flexibility of LLMs to evaluate these sub-problems and by re-combining these operations we can solve the complex problem.

In this turn, and with enough data, we can gradually transition between general purpose LLMs with zero and few-shot learning capabilities, and specialized fine-tuned models to solve specific problems (see above). This means that each operations could be designed to use a model with fine-tuned task-specific behavior.

 Tell me some more fun facts!
In its essence, SymbolicAI was inspired by the neuro-symbolic programming paradigm.

Neuro-symbolic programming is a paradigm for artificial intelligence and cognitive computing that combines the strengths of both deep neural networks and symbolic reasoning.

Deep neural networks are a type of machine learning algorithms that are inspired by the structure and function of biological neural networks. They are particularly good at tasks such as image recognition, natural language processing etc. However, they are not as good at tasks that require explicit reasoning, such as long-term planning, problem solving, and understanding causal relationships.

Symbolic reasoning, on the other hand uses formal languages and logical rules to represent knowledge and perform tasks such as planning, problem solving, and understanding causal relationships. Symbolic reasoning systems are good at tasks that require explicit reasoning, but are not as good at tasks that require pattern recognition or generalization, such as image recognition or natural language processing.

Neuro-symbolic programming aims to combine the strengths of both neural networks and symbolic reasoning to create AI systems that can perform a wide range of tasks. One way this is done is by using neural networks to extract information from data and then using symbolic reasoning to make inferences and decisions based on that information. Another way is to use symbolic reasoning to guide the generative process of neural networks and make them more interpretable.

Embedded accelerators for LLMs will, in our opinion, be ubiquitous in future computation platforms, such as wearables, smartphones, tablets or notebooks. They will contain models similar to GPT-3, ChatGPT, OPT or Bloom.



These LLMs will be able to perform a wide range of computations, such as natural language understanding or decision making. Furthermore, neuro-symbolic computation engines will be able to learn concepts how to tackle unseen tasks and solve complex problems by querying various data sources for solutions and executing logical statements on top. In this turn, to ensure the generated content is in alignment with our goals, we need to develop ways to instruct, steer and control the generative processes of machine learning models. Therefore, our approach is an attempt to enable active and transparent flow control of these generative processes.



As shown in the figure above, one can think of this generative process as shifting a probability mass of an input stream of data towards an output stream of data, in a contextualized manner. With properly designed conditions and expressions, one can also validate and steer the behavior towards a desired outcome, or repeat expressions that failed to fulfil our requirements. Our approach is to define a set of fuzzy operations that manipulate the data stream and conditions the LLMs to align with our goals. In essence, we consider all data objects, such as strings, letters, integers, arrays, etc. as symbols and we see natural language as the main interface to interact with. See the following figure:



We show that as long as we can express our goals in natural language, we can use the power of LLMs for neuro-symbolic computations. In this turn, we create operations that manipulate these symbols to generate new symbols from them. Each symbol can be interpreted as a statement. Multiple statements can be combined to form a logical expression.

Therefore, by chaining statements together we can build causal relationships and computations, instead of relying only on inductive approaches. Consequently, the outlook towards an updated computational stack resembles a neuro-symbolic computation engine at its core and, in combination with established frameworks, enables new applications.

face_in_clouds How does it work?
We now show how we define our Symbolic API, which is based on object-oriented and compositional design patterns. The Symbol class is the base class for all functional operations, which we refer to as a terminal symbol in the context of symbolic programming (fully resolved expressions). The Symbol class holds helpful operations that can be interpreted as expressions to manipulate its content and evaluate to new Symbols.

books Symbolic operations
Let us now define a Symbol and perform some basic manipulations. We start with a translation operation:

sym = ai.Symbol("Welcome to our tutorial.")
sym.translate('German')
:[Output]: 
<class 'symai.expressions.Symbol'>(value=Willkommen zu unserem Tutorial.)
Ranking objects
Our API can also perform basic data-agnostic operations to filter, rank or extract patterns. For example, we can rank a list of numbers:

sym = ai.Symbol(numpy.array([1, 2, 3, 4, 5, 6, 7]))
res = sym.rank(measure='numerical', order='descending')
:[Output]: 
<class 'symai.expressions.Symbol'>(value=['7', '6', '5', '4', '3', '2', '1'])1 / 1ChatGPTChatGPTThe provided code snippet demonstrates the usage of the SymbolicAI API. It starts with importing the symai library. The API allows building applications with large language models (LLMs) at their core, combining classical and differentiable programming in Python.The documentation suggests installing the symbolicai package using pip:Copy codepip install symbolicai
To use the SymbolicAI API, you need to set up API keys for the required engines. The API keys are environment variables, and you can set them using the export command in Linux or MacOS, or the $Env: syntax in Windows PowerShell. For example:bashCopy code# Linux / MacOS
export OPENAI_API_KEY="<OPENAI_API_KEY>"

# Windows (PowerShell)
$Env:OPENAI_API_KEY="<OPENAI_API_KEY>"
Alternatively, you can create a symai.config.json file in your project path with the engine properties.The API provides various engines, including the Neuro-Symbolic Engine (OpenAI's LLMs), Embedding Engine (OpenAI's Embedding API), Symbolic Engine (WolframAlpha), Search Engine (SerpApi), OCR Engine (APILayer), SpeechToText Engine (OpenAI's Whisper), WebCrawler Engine (Selenium), Image Rendering Engine (DALLÂ·E 2), Indexing Engine (Pinecone), and CLIP Engine (Hugging Face). Each engine requires its respective API key.The documentation also mentions optional dependencies and installations for certain engines, such as ffmpeg for the SpeechToText Engine and ChromeDriver for the WebCrawler Engine.Additionally, the documentation provides examples of how to use the SymbolicAI API through demo applications and notebooks. The examples cover various use cases, including shell command support, chatbot, news and documentation generation, and more.The API supports symbolic operations, such as translation, ranking, and pattern extraction. It utilizes the power of LLMs for neuro-symbolic computations and allows chaining statements together to build causal relationships and computations.The provided code snippet demonstrates the usage of the Symbol class and its methods, such as translate() for translation and rank() for ranking a list of numbers.Overall, the SymbolicAI API provides a framework for building applications that leverage the power of LLMs and combines classical and differentiable programming paradigms.1 / 1Evaluating Expressions by best effort
As an inspiration, we relate to an approach demonstrated by word2vec.

Word2Vec generates dense vector representations of words by training a shallow neural network to predict a word given its neighbors in a text corpus. The resulting vectors are then used in a wide range of natural language processing applications, such as sentiment analysis, text classification, and clustering.

Below we can see an example how one can perform operations on the word embeddings (colored boxes). The words are tokenized and mapped to a vector space, where we can perform semantic operations via vector arithmetics.



Similar to word2vec we intend to perform contextualized operations on different symbols, however, instead of operating in the vector space, we operate in the natural language domain. This gives us the ability to perform arithmetics on words, sentences, paragraphs, etc. and verify the results in a human readable format.

The following examples show how to evaluate such an expression via a string representation:

ai.Symbol('King - Man + Women').expression()
:[Output]:
<class 'symai.expressions.Symbol'>(value=Queen)
Dynamic casting
We can also subtract sentences from each other, where our operations condition the neural computation engine to evaluate the Symbols by best effort. In the following example, it determines that the word enemy is present in the sentence, therefore deletes it and replaces it with the word friend (which is added):

res = ai.Symbol('Hello my enemy') - 'enemy' + 'friend'
:[Output]: 
<class 'symai.expressions.Symbol'>(value=Hello my friend)
What we also see is that the API performs dynamic casting, when data types are combined with a Symbol object. If an overloaded operation of the Symbol class is used, the Symbol class can automatically cast the second object to a Symbol. This is a convenient modality to perform operations between Symbolobjects and other types of data, such as strings, integers, floats, lists, etc. without bloating the syntax.

Fuzzy Comparisons
In this example we are fuzzily comparing two number objects, where the Symbol variant is only an approximation of numpy.pi. Given the context of the fuzzy equals == operation, this comparison still succeeds and returns True.

sym = ai.Symbol('3.1415...')
sym == numpy.pi
:[Output]:
True
brain Causal Reasoning
Our framework was built with the intention to enable reasoning capabilities on top of statistical inference of LLMs. Therefore, we can also perform deductive reasoning operations with our Symbol objects. For example, we can define a set of operations with rules that define the causal relationship between two symbols. The following example shows how the & is used to compute the logical implication of two symbols.

res = ai.Symbol('The horn only sounds on Sundays.') & ai.Symbol('I hear the horn.')
:[Output]:
<class 'symai.expressions.Symbol'>(value=It is Sunday.)
The current &-operation overloads the and logical operator and sends few-shot prompts how to evaluate the statement to the neural computation engine. However, we can define more sophisticated logical operators for and, or and xor via formal proof statements and use the neural engines to parse data structures prior to our expression evaluation. Therefore, one can also define custom operations to perform more complex and robust logical operations, including constraints to validate the outcomes and ensure a desired behavior.

To provide a more complete picture, we also sketch more comprehensive causal examples below, where one tries to obtain logical answers, based on questions of the kind:

# 1) "A line parallel to y = 4x + 6 passes through (5, 10). What is the y-coordinate of the point where this line crosses the y-axis?"
# 2) "Bob has two sons, John and Jay. Jay has one brother and father. The father has two sons. Jay's brother has a brother and a father. Who is Jay's brother."
# 3) "is 1000 bigger than 1063.472?"
To give an rough idea of how we would approach this with our framework is by, first, using a chain of operations to detect the neural engine that is best suited to handle this task, and second, prepare the input for the respective engine. Let's see an example:

val = "<one of the examples above>"

# First define a class that inherits from the Expression class
class ComplexExpression(ai.Expression): # more to the Expression class in later sections
    # write a method that returns the causal evaluation
    def causal_expression(self):
        pass # see below for implementation

# instantiate an object of the class
expr = ComplexExpression(val)
# set WolframAlpha as the main expression engine to use
expr.command(engines=['symbolic'], expression_engine='wolframalpha')
# evaluate the expression
res = expr.causal_expression()
Now, the implementation of causal_expression could in principle look like this:

def causal_expression(self):
    # very which case to use `self.value` contains the input
    if self.isinstanceof('mathematics'):
        # get the mathematical formula
        formula = self.extract('mathematical formula')
        # verify which problem type we have
        if formula.isinstanceof('linear function'):
            # prepare for wolframalpha
            question = self.extract('question sentence')
            req = question.extract('what is requested?')
            x = self.extract('coordinate point (.,.)') # get coordinate point / could also ask for other points
            query = formula @ f', point x = {x}' @ f', solve {req}' # concatenate to the question and formula
            res = query.expression(query) # send prepared query to wolframalpha

        elif formula.isinstanceof('number comparison'):
            res = formula.expression() # send directly to wolframalpha

        ... # more cases

    elif self.isinstanceof('linguistic problem'):
        sentences = self / '.' # first split into sentences
        graph = {} # define graph
        for s in sentences:
            sym = ai.Symbol(s)
            relations = sym.extract('connected entities (e.g. A has three B => A | A: three B)') / '|' # and split by pipe
            for r in relations:
                ... # add relations and populate graph => alternatively, read also about CycleGT

    ... # more cases
    return res
The above example shows how we can use the causal_expression expression method to step-wise iterate and extract information which we can then either manually or using external solvers resolve.

Attention: We hint the reader that this is a very rough sketch and that the implementation of the causal_expression method would need much more engineering effort. Furthermore, the currently used GPT-3 LLM backend often fails to extract the correct information or resolve the right comparison. However, we strongly believe in the advances of the field and that this will change in the future, specifically with fine-tuned models like ChatGPT with Reinforcement Learning from Human Feedback (RLHF).

Lastly, it is also noteworthy that given enough data, we could fine-tune methods that extract information or build our knowledge graph from natural language. This would enable us to perform more complex reasoning tasks, such as the ones mentioned above. Therefore, we also point the reader to recent publications for translating Text-to-Graphs. This means that in the attempt to answer the query, we can simply traverse the graph and extract the information we need.

In the next section, we will explore operations.

mask Operations
Operations are at the core of our framework. They are the building blocks of our API and are used to define the behavior of our symbols. We can think of operations as contextualized functions that take in a Symbol object, send it to the neuro-symbolic engine for evaluation, and return one or multiple new objects (mainly new symbols; but not necessarily limited to that). Another fundamental property is polymorphism, which means that operations can be applied to different types of data, such as strings, integers, floats, lists, etc. with different behaviors, depending on the object instance.

The way we execute operations is by using the Symbol object value attribute containing the original data type that is then sent as a string representations to the engines to perform the operations. Therefore all values are casted to a string representation. This also means, that for custom objects one needs to define a proper __str__ method to cast the object to a string representation and ensure preservation of the semantics of that object.

Lastly, we need to talk about inheritance. Our API is built on top of the Symbol class, which is the base class of all operations. This means that all operations are inherited from the Symbol class. This provides a convenient modality to add new custom operations by sub-classing Symbol, yet, ensuring to always have a set of base operations at our disposal without bloating the syntax or re-implementing many existing functionalities. This also means that we can define contextualized operations with individual constraints, prompt designs and therefore behaviors by simply sub-classing the Symbol class and overriding the corresponding method. However, we recommend sub-classing the Expression class as we will see later, it adds additional functionalities.

Here is an example of how to define a custom == operation by overriding the __eq__ method and providing a custom prompt object with a list of examples:

class Demo(ai.Symbol):
    def __eq__(self, other) -> bool:
        @ai.equals(examples=ai.Prompt([
              "1 == 'ONE' =>True",
              "'six' == 7 =>False",
              "'Acht' == 'eight' =>True",
              ...
          ])
        )
        def _func(_, other) -> bool:
            return False # default behavior on failure
        return _func(self, other)
As shown in the above example, this is also the way we implemented the basic operations in Symbol, by defining local functions that are then decorated with the respective operation decorator from the symai/core.py file. The symai/core.py is a collection of pre-defined operation decorators that we can quickly apply to any function. The reason why we use locally defined functions instead of directly decorating the main methods, is that we do not necessarily want that all our operations are sent to the neural engine and could implement a default behavior. Another reason is that we want to cast return types of the operation outcome to symbols or other derived classes thereof. This is done by using the self._sym_return_type(...) method and can give contextualized behavior based on the defined return type. See more details in the actual Symbol class.

In the next section, we will show that almost all operations in symai/core.py are derived from the more generic few_shot decorator.

test_tube Custom Operations
One can also define customized operations. For example, let us define a custom operation to generate a random integer between 0 and 10:

class Demo(ai.Symbol):
    def __init__(self, value = '') -> None:
        super().__init__(value)
    
    @ai.zero_shot(prompt="Generate a random integer between 0 and 10.",
                  constraints=[
                      lambda x: x >= 0,
                      lambda x: x <= 10
                  ])
    def get_random_int(self) -> int:
        pass
As we show, the Symbolic API uses Python Decorators to define operations. The @ai.zero_shot decorator is used to define a custom operation that does not require any demonstration examples, since the prompt is expressive enough. In the shown example, the zero_shot decorator takes in two arguments: prompt and constraints. The former is used to define the prompt that conditions our desired operation behavior. The latter is used to define validation constraints of the computed outcome, to ensure it fulfills our expectations.

If the constraint is not fulfilled, the above implementation would reach out to the specified default implementation or default value. If no default implementation or value was found, the Symbolic API would raise an ConstraintViolationException.

We also see that in the above example the return type is defined as int. Therefore, the resulting value from the wrapped function will be of type int. This works because our implementation uses auto-casting to a user specified return data type. If the cast fails, the Symbolic API will raise a ValueError. If no return type is specified, the return type will be Any.

Few-shot operations
The @ai.few_shot decorator is the a generalized version of @ai.zero_shot and is used to define a custom operation that requires demonstration examples. To give a more complete picture, we present the function signature of the few_shot decorator:

def few_shot(prompt: str,
             examples: Prompt, 
             constraints: List[Callable] = [],
             default: Optional[object] = None, 
             limit: int = 1,
             pre_processor: Optional[List[PreProcessor]] = None,
             post_processor: Optional[List[PostProcessor]] = None,
             **wrp_kwargs):
The prompt and constraints attributes behavior is similar to the zero_shot decorator. The examples and limit arguments are new. The examples argument is used to define a list of demonstrations that are used to condition the neural computation engine. The limit argument is used to define the maximum number of examples that are returned, give that there are more results. The pre_processor argument takes a list of PreProcessor objects which can be used to pre-process the input before it is fed into the neural computation engine. The post_processor argument takes a list of PostProcessor objects which can be used to post-process the output before it is returned to the user. The wrp_kwargs argument is used to pass additional arguments to the wrapped method, which are also stream-lined towards the neural computation engine and other engines.

To give a more holistic picture ouf our conceptional implementation, see the following flow diagram containing the most important classes:



The colors indicate logical groups of data processing steps. Yellow indicates the input and output data. Blue indicates places you can customize or prepare the input of your engine. Green indicates post-processing steps of the engine response. Red indicates the application of constraints (which also includes the attempted casting of the return type signature, if specified in the decorated method). Grey indicates the custom method which defines all properties, therefore has access to all the above mentioned objects.

To conclude this section, here is an example how to write a custom Japanese name generator with our @ai.zero_shot decorator:

import symai as ai
class Demo(ai.Symbol):
    @ai.few_shot(prompt="Generate Japanese names: ",
                 examples=ai.Prompt(
                   ["æå­", "åè±", "ä¸é", "åæ"]
                 ),
                 limit=2,
                 constraints=[lambda x: len(x) > 1])
    def generate_japanese_names(self) -> list:
        return ['æå­', 'åè±'] # dummy implementation
Should the neural computation engine not be able to compute the desired outcome, it will reach out to the default implementation or default value. If no default implementation or value was found, the method call will raise an exception.

Prompt Design
The way all the above operations are performed is by using a Prompt class. The Prompt class is a container for all the information that is needed to define a specific operation. The Prompt class is also the base class for all other Prompt classes.

Here is an example how to define a Prompt to enforce the neural computation engine for comparing two values:

class CompareValues(ai.Prompt):
    def __init__(self) -> ai.Prompt:
        super().__init__([
            "4 > 88 =>False",
            "-inf < 0 =>True",
            "inf > 0 =>True",
            "4 > 3 =>True",
            "1 < 'four' =>True",
            ...
        ])
For example, when calling the <= operation on two Symbols, the neural computation engine will evaluate the symbols in the context of the CompareValues prompt.

res = ai.Symbol(1) <= ai.Symbol('one')
This statement evaluates to True, since the fuzzy compare operation was conditions our engine to compare the two Symbols based on their semantic meaning.

:[Output]:
True
In a more general notion, depending on the context hierarchy of the expression class and used operations the semantics of the Symbol operations may vary. To better illustrate this, we show our conceptual prompt design in the following figure:



The figure shows our hierarchical prompt design as a container of all the information that is provided to the neural computation engine to define a task-specific operation. The Yellow and Green highlighted boxes indicate mandatory string placements. The dashed boxes are optional placeholders. and the Red box indicates the starting point of the model prediction.

Conceptually we consider three main prompt designs: Context-based Prompts, Operational Prompts, and Templates. The prompts can be curated either by inheritance or by composition. For example, the Static Context can be defined by inheriting from the Expression class and overriding the static_context property. An Operation and Template prompt can be created by providing an PreProcessor to modify the input data.

We will now explain each prompt concept in more details:

The Context-based Prompts (Static, Dynamic and Payload) are considered optional and can be defined in a static manner, either by sub-classing the Expression class and overriding the static_context property, or at runtime by updating the dynamic_context property or passing an payload kwargs to a method. Here is an example how to use the payload kwargs via the method signature:

# creating a query to ask if an issue was resolve or not
sym = Symbol("<some-community-conversation>")
q = sym.query("Was the issue resolved?")
# write manual condition to check if the issue was resolved
if 'not resolved' in q:
    # do a new query but payload the previous query answer to the new query
    sym.query("What was the resolution?", payload=q)
    ...
else:
    pass # all good
Regardless of how we set the context, our contextualized prompt defines the desired behavior of the Expression operations. For example, if we want to operate in the context of a domain-specific language, without having to override each base class method. See more details in this notebook.

The Operation prompts define the behavior of an atomic operation and is therefore mandatory to express the nature of such an operation. For example, the +-operation is used to add two Symbols together and therefore the +-operation prompt explains its behavior. Examples defines another optional structure that provides the neural computation engine with a set of demonstrations that are used to properly condition the engine. For example, the +-operation prompt can be conditioned on how to add numbers by providing a set of demonstrations, such as 1 + 1 = 2, 2 + 2 = 4, etc.

The Template prompts are optional and encapsulates the resulting prediction to enforce a specific format. For example, to generate HTML tags we can use a curated <html>{{placeholder}}</html> template. This template will enforce the neural computation engine to start the generation process already in the context of a HTML tags format, and not produce irrelevant descriptions about its task.

expressionless Expressions
An Expression is a non-terminal symbol, which can be further evaluated. It inherits all the properties from Symbol and overrides the __call__ method to evaluate its expressions or values. From the Expression class, all other expressions are derived. The Expression class also adds additional capabilities i.e. to fetch data from URLs, search on the internet or open files. These operations are specifically separated from Symbol since they do not use the value attribute of the Symbol class.

SymbolicAI' API closely follows best practices and ideas from PyTorch, therefore, one can build complex expressions by combining multiple expressions as a computational graph. Each Expression has its own forward method, which has to be overridden. The forward method is used to define the behavior of the expression. The forward method is called by the __call__ method, which is inherited from the Expression base class. The __call__ evaluates an expression and returns the result from the implemented forward method. This design pattern is used to evaluate the expressions in a lazy manner, which means that the expression is only evaluated when the result is needed. This is a very important feature, since it allows us to chain complex expressions together. We already implemented many useful expressions, which can be imported from the symai.components file.

Other important properties that are inherited from the Symbol class are _sym_return_type and static_context. These two properties define the context in which the current Expression operates, as described in the Prompt Design section. The static_context therefore influences all operations of the current Expression sub-class. The _sym_return_type ensures that after each evaluation of an Expression, we obtain the desired return object type. This is usually implemented to return the current type, but can be set to return a different type.

Expressions can of course have more complex structures and be further sub-classed, such as shown in the example of the Sequence expression in the following figure:



A Sequence expression can hold multiple expressions, which are evaluated at runtime.

Sequence expressions
Here is an example how to define a Sequence expression:

# first import all expressions
from symai import *
# define a sequence of expressions
Sequence(
    Clean(),
    Translate(),
    Outline(),
    Compose('Compose news:'),
)
Stream expressions
As we saw earlier, we can create contextualized prompts to define the behavior of operations on our neural engine. However, this also takes away a lot of the available context size and since e.g. the GPT-3 Davinci context length is limited to 4097 tokens, this might quickly become a problem. Luckily, we can use the Stream processing expression. This expression opens up a data stream and performs chunk-based operations on the input stream.

A Stream expression can easily be wrapped around other expressions. For example, the chunks can be processed with a Sequence expression, that allows multiple chained operations in sequential manner. Here is an example how to define such a Stream expression:

Stream(Sequence(
    Clean(),
    Translate(),
    Outline(),
    Embed()
))
The shown example opens a stream, passes a Sequence object which cleans, translates, outlines and embeds the input. Internally, the stream operation estimates the available model context size and chunks the long input text into smaller chunks, which are passed to the inner expression. The returned object type is a generator.

The issue with this approach is, that the resulting chunks are processed independently. This means there is no shared context or information among chunks. To solve this issue, we can use the Cluster expression instead, where the independent chunks are merged based on their similarity. We illustrate this in the following figure:



In the shown example all individual chunks are merged by clustering the information within each chunk. This gives us a way to consolidate contextually related information and merge them in a meaningful way. Furthermore, the clustered information can then be labeled by streaming through the content of each cluster and extracting the most relevant labels, providing us with interpretable node summaries.

The full example is shown below:

stream = Stream(Sequence(
    Clean(),
    Translate(),
    Outline(),
))
sym = Symbol('<some long text>')
res = Symbol(list(stream(sym)))
expr = Cluster()
expr(res)
In a next step, we could recursively repeat this process on each summary node, therefore, build a hierarchical clustering structure. Since each Node resembles a summarized sub-set of the original information we can use the summary as an index. The resulting tree can then be used to navigate and retrieve the original information, turning the large data stream problem into a search problem.

Alternatively, we could use vector-base similarity search to find similar nodes. For searching in a vector space we can use dedicated libraries such as Annoy, Faiss or Milvus.

x Error Handling
A key idea of the SymbolicAI API is to be able to generate code. This in turn means that errors may occur, which we need to handle in a contextual manner. As a future vision, we even want our API to self extend and therefore need to be able to resolve issues automatically. To do so, we propose the Try expression, which has a fallback statements built-in and retries an execution with dedicated error analysis and correction. This expression analyses the input and the error, and conditions itself to resolve the error by manipulating the original code. If the fallback expression succeeds, the result is returned. Otherwise, this process is repeated for the number of retries specified. If the maximum number of retries is reached and the problem was not resolved, the error is raised again.

Let us assume, we have some executable code that was previously generated. However, by the nature of generative processes syntax errors may occur. By using the Execute expression, we can evaluate our generated code, which takes in a symbol and tries to execute it. Naturally, this will fail. However, in the following example the Try expression resolves this syntactic error and the receive a computed result.

expr = Try(expr=Execute())
sym = Symbol('a = int("3,")') # some code with a syntax error
res = expr(sym)
The resulting output is the evaluated code, which was corrected:

:Output:
a = 3
We are aware that not all errors are as simple as the shown syntactic error example, which can be resolved automatically. Many errors occur due to semantic misconceptions. Such issues require contextual information. Therefore, we are further exploring means towards more sophisticated error handling mechanism. This includes also the usage of streams and clustering to resolve errors in a more hierarchical contextual manner. It is also noteworthy that neural computations engines need to be further improved to better detect and resolve errors.

spider Interpretability, Testing & Debugging
Perhaps one of the greatest benefits of using neuro-symbolic programming is, that we can get a clear understanding of how well our LLMs understand simple operations. Specifically we gain knowledge about if, and at which point they fail, enabling us to follow their StackTraces and determine the failure points. In our case, neuro-symbolic programming allows us to debug the model predictions based on dedicated unit test for simple operations. To detect conceptual misalignments we can also use a chain of neuro-symbolic operations and validate the generative process. This is of course not a perfect solution, since the verification may also be error prone, but it gives us at least a principle way to detect conceptual flaws and biases in our LLMs.

Unit Testing Models
Since our premise is to divide and conquer complex problems, we can curate conceptual unit test and target very specific and tracktable sub-problems. The resulting measure, i.e. success rate of the model prediction, can then be used to evaluate their performance, and hint towards undesired flaws or biases.

This allows us to design domain-specific benchmarks and see how well general learners, such as GPT-3, adapt with certain prompts to a set of tasks.

For example, we can write a fuzzy comparison operation, that can take in digits and strings alike, and perform a semantic comparison. LLMs can then be asked to evaluate these expressions. Often times, these LLMs still fail to understand the semantic equivalence of tokens in digits vs strings and give wrong answers.

The following code snipped shows a unit test to perform semantic comparison of numbers (between digits and strings):

import unittest
from symai import *

class TestComposition(unittest.TestCase):
  def test_compare(self):
      res = Symbol(10) > Symbol(5)
      self.assertTrue(res)
      res = Symbol(1) < Symbol('five')
      self.assertTrue(res)
      ...
fireDebugging
When creating very complex expressions, we debug them by using the Trace expression, which allows to print out the used expressions, and follow the StackTrace of the neuro-symbolic operations. Combined with the Log expression, which creates a dump of all prompts and results to a log file, we can analyze where our models potentially failed.

Example: News Summary
In the following example we create a news summary expression that crawls the given URL and streams the site content through multiple expressions. The outcome is a news website that is created based on the crawled content. The Trace expression allows to follow the StackTrace of the operations and see what operations are currently executed. If we open the outputs/engine.log file we can see the dumped traces with all the prompts and results.

# crawling the website and creating an own website based on its facts
news = News(url='https://www.cnbc.com/cybersecurity/',
            pattern='cnbc',
            filters=ExcludeFilter('sentences about subscriptions, licensing, newsletter'),
            render=True)
expr = Log(Trace(news))
res = expr()
Here is the corresponding StackTrace of the model:



The above code creates a webpage with the crawled content from the original source. See the preview below, the entire rendered webpage image here and resulting [code of webpage here](https://raw.githubusercontent.com/Xpitfire/symbolicai/main/examples/results/news.html.1 / 1ChatGPTChatGPTThe passage you shared appears to be a technical document discussing the design and functionality of a symbolic AI framework. It describes various concepts and features of the framework, such as evaluating expressions, dynamic casting, fuzzy comparisons, causal reasoning, custom operations, prompt design, error handling, interpretability, testing, and debugging.The document introduces the idea of performing operations on symbols in the natural language domain, similar to how word embeddings are used in word2vec. It explains that the framework allows for arithmetics on words, sentences, paragraphs, etc. and provides human-readable results.The document also mentions the use of neural computation engines to evaluate expressions and perform various operations. It discusses the implementation of custom operations, including zero-shot and few-shot operations, using Python decorators. It explains the concept of prompts, which define the behavior of operations, and provides examples of prompt designs.Additionally, the document discusses the use of expressions, including sequences and streams, to build computational graphs and process data. It introduces the concept of the Try expression, which handles errors and attempts to resolve them automatically. It also highlights the importance of interpretability, testing, and debugging in neuro-symbolic programming, and suggests using unit tests and the Trace expression for debugging purposes.Overall, the document provides an overview of the design and capabilities of the symbolic AI framework, focusing on the implementation of operations, prompt design, expression evaluation, error handling, and debugging techniques.1 / 1arrow_forward Play around with our API
Launch and explore the notebook here:

Binder

There are many more examples in the examples folder and in the notebooks folder. You can also explore the test cases in the tests folder.

chart_with_upwards_trend Interface for Query and Response Inspection
SymbolicAI is by design a data-driven framework. This means that we can collect data from API interactions while we provide the requested responses. For very agile, dynamic adaptations or prototyping we can integrate user desired behavior quickly into existing prompts. However, we can also log the user queries and model predictions to make them available for post-processing. Therefore, we can customize and improve the model's responses based on real-world data.

In the following example, we show how we can use an Output expression to pass a handler function and access input prompts of the model and model predictions. These, can be used for data collection and later fine-tuning stages. The handler function provides a dictionary and offers keys for input and output values. The content can then be sent to a data pipeline for further processing.

sym = Symbol('Hello World!')
def handler(res):
    input_ = res['input']
    output = res['output']
expr = Output(expr=sym.translate, 
              handler=handler, 
              verbose=True)
res = expr('German')
Since we called verbose, we can also see the console print of the Output expression:

Input: (['Translate the following text into German:\n\nHello World!'],)
Expression: <bound method Symbol.translate of <class 'symai.symbol.Symbol'>(value=Hello World!)>
args: ('German',) kwargs: {'input_handler': <function OutputEngine.forward.<locals>.input_handler at ...
Dictionary: {'wrp_self': <class 'symai.components.Output'>(value=None), 'func': <function Symbol.output.<locals>._func at ...
Output: Hallo Welt!
robot Engines
Due to limited compute resources we currently rely on OpenAI's GPT-3 API for the neuro-symbolic engine. However, given the right compute resources, it is possible to use local machines to avoid high latencies and costs, with alternative engines such as OPT or Bloom. This would allow for recursive executions, loops, and more complex expressions.

Furthermore, as we interpret all objects as symbols only with a different encodings, we integrated a set of useful engines that transform these objects to the natural language domain to perform our operations.

Symbolic Engine
Although in our work, we mainly focus on how LLMs can evaluate symbolic expressions, many formal statements were already well implemented in existing symbolic engines, like WolframAlpha. Therefore, given an API KEY from WolframAlpha, we can use their engine by setting the expression_engine attribute. This avoids error prune evaluations from neuro-symbolic engines for mathematical operations. The following example shows how to use WolframAlpha to compute the result of the variable x:

expr = Expression()
expr.command(engines=['symbolic'], expression_engine='wolframalpha')
res = expr.expression('x^2 + 2x + 1')
:Output:
x = -1
Speech Engine
To interpret audio files we can perform speech transcription by using whisper. The following example shows how to transcribe an audio file and return the text:

expr = Expression()
res = expr.speech('examples/audio.mp3')
:Output:
I may have overslept.
OCR Engine
To "read" text from images we can perform optical character recognition (OCR) with APILayer. The following example shows how to transcribe an image and return the text:

expr = Expression()
res = expr.ocr('https://media-cdn.tripadvisor.com/media/photo-p/0f/da/22/3a/rechnung.jpg')
The OCR engine returns a dictionary with a key all_text where the full text is stored. See more details in their documentation here.

:Output:
China Restaurant\nMaixim,s\nSegeberger Chaussee 273\n22851 Norderstedt\nTelefon 040/529 16 2 ...
Search Engine
To obtain fact-based content we perform search queries via SerpApi with a Google backend. The following example shows how to search for a query and return the results:

expr = Expression()
res = expr.search('Birthday of Barack Obama')
:Output:
August 4, 1961
WebCrawler Engine
To access any data source from the web, we can use Selenium. The following example shows how to crawl a website and return the results:

expr = Expression()
res = expr.fetch(url="https://www.google.com/", 
                 pattern="google")
The pattern property can be used to detect if the document as been loaded correctly. If the pattern is not found, the crawler will timeout and return an empty result.

:Output:
GoogleKlicke hier, wenn du nach einigen Sekunden nicht automatisch weitergeleitet wirst.GmailBilderAnmelden ...
Drawing Engine
To render nice images from text description we use DALLÂ·E 2. The following example shows how to draw a text description and return the image:

expr = Expression('a cat with a hat')
res = expr.draw()
:Output:
https://oaidalleapiprodscus.blob.core.windows.net/private/org-l6FsXDfth6Uct ...
Don't worry, we would never hide an image of a cat with a hat from you. Here is the image preview and link:


File Engine
To perform file operations we use the file system of the OS. At the moment, we support only PDF files and plain text files. This is a very early stage and we are working on more sophisticated file system access and also remote storage. The following example shows how to read a PDF file and return the text:

expr = Expression()
res = expr.open('./LICENSE')
:Output:
BSD 3-Clause License\n\nCopyright (c) 2023 ...
Indexing Engine
We use Pinecone to index and search for text. The following example shows how to store text as an index and then retrieve the most related match of it:

expr = Expression()
expr.add(Expression('Hello World!').zip())
expr.add(Expression('I like cookies!').zip())
res = expr.get(Expression('hello').embed().value).ast()
res['matches'][0]['id']
:Output:
Hello World
Here the zip method creates a pair of strings and embedding vectors. Afterwards they are added to the index. The line with get basically retrieves the original source based on the vector value of hello and uses ast to cast the value to a dictionary.

One can set several kwargs for the indexing engine. See the symai/backend/engine_index.py file for more details.

CLIP Engine
To perform text-based image few-shot classification we use CLIP. This implementation is very experimental and conceptually does not fully integrate the way we intend it, since the embeddings of CLIP and GPT-3 are not aligned (embeddings of the same word are not identical for both models). Aligning them is an open problem for future research. For example, one could learn linear projections from one embedding space to the other.

The following example shows how to classify the image of our generated cat from above and return the results as an array of probabilities:

expr = Expression()
res = expr.vision('https://oaidalleapiprodscus.blob.core.windows.net/private/org-l6FsXDfth6...', 
                  ['cat', 'dog', 'bird', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe'])
:Output:
array([[9.72840726e-01, 6.34790864e-03, 2.59368378e-03, 3.41371237e-03,
        3.71197984e-03, 8.53193272e-03, 1.03346225e-04, 2.08464009e-03,
        1.77942711e-04, 1.94185617e-04]], dtype=float32)
Local Neuro-Symbolic Engine
One can use the a locally hosted instance for the Neuro-Symbolic Engine. Out of the box we provide a Hugging Face client-server backend and host the model EleutherAI/gpt-j-6B to perform the inference. As the name suggests this is a six billion parameter model and requires a GPU with ~16GB RAM to run properly. The following example shows how to host and configure the usage of the local Neuro-Symbolic Engine.

Fist we start the backend server:

# optional: set cache folder for transformers (Linux/MacOS)
export TRANSFORMERS_CACHE="<path-to-cache-folder>"
# start server backend (default model is EleutherAI/gpt-j-6B)
symsvr
# initialize server with client call
symclient
Then use once the following code to set up the local engine:

from symai.backend.engine_nesy_client import NeSyClientEngine
# setup local engine
engine = NeSyClientEngine()
setting = Expression()
setting.setup(engines={'neurosymbolic': engine})
Now you can use the local engine to perform symbolic computation:

# do some symbolic computation with the local engine
sym = Symbol('cats are cute')
res = sym.compose()
...
Custom Engine
If you want to replace or extend the functionality of our framework, you can do this by customizing the existing engines or creating new engines. The Symbol class provides for this functionality some helper methods, such as command and setup. The command method can pass on configurations (as **kwargs) to the engines and change functionalities or parameters. The setup method can be used to re-initialize an engine with your custom engine implementation which must sub-class the Engine class. Both methods can be specified to address one, more or all engines.

Here is an example how to initialize your own engine. We will sub-class the existing GPT3Engine and override the prepare method. This method is called before the neural computation and can be used to modify the parameters of the actual input prompt that will be passed in for execution. In this example, we will replace the prompt with dummy text for illustration purposes:

from symai.backend.engine_gpt3 import GPT3Engine
class DummyEngine(GPT3Engine):
    def prepare(self, args, kwargs, wrp_params):
        wrp_params['prompts'] = ['Go wild and generate something!']
custom_engine = DummyEngine()
sym = Symbol()
sym.setup(engines={'neurosymbolic': custom_engine})
res = sym.compose()
To configure an engine, we can use the command method. In this example, we will enable verbose mode, where the engine will print out what methods it is executing and the parameters it is using. This is useful for debugging purposes:

sym = Symbol('Hello World!')
sym.command(engines=['neurosymbolic'], verbose=True)
res = sym.translate('German')
:Output:
<symai.backend.engine_gpt3.GPT3Engine object at 0, <function Symbol.translate.<locals>._func at 0x7fd68ba04820>, {'wrp_self': <class 'symai.symbol.S ['\n\nHallo Welt!']
Here is the list of names of the engines that are currently supported:

neurosymbolic - GPT-3
symbolic - WolframAlpha
ocr - Optical Character Recognition
vision - CLIP
speech - Whisper
embedding - OpenAI Embeddings API (ada-002)
userinput - User Command Line Input
search - SerpApi (Google search)
crawler - Selenium
execute - Python Interpreter
index - Pinecone
open - File System
output - Output Callbacks (e.g. for printing to console or storage)
imagerendering - DALLÂ·E 2
Finally, let's assume you want to create a entirely new engine, but still keep our workflow, then you can use the _process_query function from symai/functional.py and pass in your engine including all other specified objects (i.e. Prompt, PreProcessor, etc.; see also section Custom Operations).1 / 1ChatGPTChatGPTIt seems like you provided a description of the SymbolicAI framework and its various engines. However, without access to the actual API or notebook you mentioned, I won't be able to interact with it directly or run any code.If you have any specific questions or need assistance with a particular aspect of the SymbolicAI framework, please let me know and I'll do my best to help you.1 / 1I just want you to tell me what this software does.1 / 1ChatGPTChatGPTThe SymbolicAI framework is a data-driven framework that combines natural language processing (NLP) and symbolic computation to enable interactions between humans and AI systems. It aims to bridge the gap between symbolic reasoning, which deals with abstract concepts and formal logic, and the power of large-scale language models like GPT-3.The framework provides a set of engines that can be used to perform various tasks and operations. These engines include:Neuro-Symbolic Engine: This engine utilizes OpenAI's GPT-3 API to perform neuro-symbolic computations. It allows for dynamic adaptations and prototyping by integrating user-desired behavior into prompts. The interactions with this engine can be logged for data collection and later fine-tuning of the model's responses.Symbolic Engine: This engine integrates with WolframAlpha, a powerful computational engine, to perform mathematical operations and evaluations. It provides an alternative to neuro-symbolic engines for tasks related to formal statements and mathematical computations.Speech Engine: This engine uses Whisper for speech transcription. It can transcribe audio files and convert them into text.OCR Engine: The OCR (Optical Character Recognition) engine utilizes APILayer to "read" text from images. It performs text extraction from images and returns the extracted text.Search Engine: This engine performs search queries using SerpApi with a Google backend. It allows you to search for queries and retrieve fact-based content from the web.WebCrawler Engine: The WebCrawler engine uses Selenium to crawl websites and retrieve information from them. It can fetch data from web pages and provide the results.Drawing Engine: This engine uses DALLÂ·E 2 to render images based on text descriptions. It can generate images from textual descriptions.File Engine: The File Engine allows performing file operations such as reading PDF files or plain text files. It provides basic file system access for tasks involving file manipulation.Indexing Engine: This engine uses Pinecone to index and search for text. It allows you to store and retrieve text-based indexes efficiently.CLIP Engine: The CLIP engine performs text-based image classification using the CLIP model. It can classify images based on textual descriptions and return probabilities for different categories.Custom Engine: The framework allows for the customization and extension of existing engines or the creation of new engines. You can customize the behavior of the engines to suit your specific needs and integrate them into the workflow.Overall, the SymbolicAI framework aims to provide a flexible and extensible platform for combining symbolic reasoning and natural language processing, enabling a wide range of AI applications and interactions.1 / 1Termgpt: OpenAI Chatbot
This program uses the OpenAI API to create a chatbot that can converse with users. The chatbot is powered by the GPT-3.5-turbo (or 4) language model and can answer a wide range of questions. If you are like me and want to stay in the terminal, this is the tool for you.

Breaking change: Now you can call gpt3 or gpt4 (if you have an api key for it)
Beware that using gpt4 is expensive (15x more than 3.5-turbo), so use it with care.

Install
You will need and openAI api key, the app expects that the key is available as an environment variable: OPENAI_API_KEY.

$ pip install termgpt
Usage
$ gpt3 
> who are you?

I am an AI language model created by OpenAI. My purpose is to be of assistance and respond to your queries to the best of my abilities.
or ask question about a file:

$ gpt3 lotr.txt
> what is this file about?

This file is about The Lord of the Rings, a high-fantasy novel by J.R.R. Tolkien. It describes the plot, characters, and setting of the book, as well as its publication history, critical 
reception, and cultural impact. It also mentions Tolkien's influences and the numerous adaptations and derivative works that the novel has inspired.
[New] you can resume you previous conversation
We keep track of your conversation on a file now chatgpt_history.json so we can resume from it by passing the -r flag.

$ gpt3 -r
--Resuming previous session--
[System] You are a helpful assistant.

> what is relu
ReLU (Rectified Linear Unit) is an activation function commonly used in deep neural networks. It is defined as f(x) = max(0, x). In other 
words, the output of the function is zero when the input is negative, and equal to the input when the input is positive. ReLU has become 
popular in deep learning because it helps to address the vanishing gradient problem and allows for faster training of neural networks.
> and gelu?
GeLU (Gaussian Error Linear Unit) is another activation function used in deep neural networks. It is defined as f(x) = 0.5 * x * (1 + erf(x /
sqrt(2))), where erf is the error function. GeLU is a smooth approximation of the ReLU function, and has been shown to work well in certain 
types of neural networks. It is particularly useful in sequence modeling tasks such as natural language processing, where the input data 
often has a Gaussian distribution. GeLU is similar to ReLU in terms of its computational efficiency, but can potentially improve the 
performance of a neural network by providing a more accurate representation of the input data.
> 
[New] Run commands in your Terminal (at your own risk!)
$ gpt3 -c "list all files in this folder with sizes"
ls -lh

total 40
-rw-r--r--  1 tcapelle  staff   2.4K Mar  6 09:43 README.md
drwxr-xr-x  4 tcapelle  staff   128B Mar  3 16:22 build
-rw-r--r--  1 tcapelle  staff   276B Mar  6 13:55 chatgpt_history.json
drwxr-xr-x  4 tcapelle  staff   128B Mar  3 17:07 dist
-rw-r--r--  1 tcapelle  staff    51B Mar  3 15:33 key
-rw-r--r--  1 tcapelle  staff   2.5K Mar  3 16:40 lotr.txt
-rw-r--r--  1 tcapelle  staff   955B Mar  3 18:17 setup.py
drwxr-xr-x  6 tcapelle  staff   192B Mar  6 09:00 termgpt
drwxr-xr-x  8 tcapelle  staff   256B Mar  6 08:34 termgpt.egg-info
Recover output
The history of your conversation is stored in chatgpt_history.json so you can recover it later. You also use the -o flag to store the output in a plain text file.

$ gpt3 -o "poem.txt"
> Can you write a short poem about chatbots, guacamole and cars?

Chatbots beep and bloop,
Serving customers with ease,
Guac and chips in hand.

Cars race on, onwards,
As chatbots assist the ride,
Dipping chips divine.

Time taken: 2.27 seconds
Saving history to chatgpt_history.json, you can restore this session with `--resume`
Saving output to poem.txt1 / 1ChatGPTChatGPTTermgpt is a program that utilizes the OpenAI API to create a chatbot that can communicate with users through the terminal. It is powered by the GPT-3.5-turbo (or GPT-4) language model and can answer a wide range of questions and engage in conversations.To use Termgpt, you need to have an OpenAI API key, which should be set as an environment variable called OPENAI_API_KEY. The program can be installed using pip with the command "pip install termgpt".Once installed, you can start the chatbot by running the command "gpt3" in the terminal. The chatbot will prompt for input, and you can ask questions or provide text files for it to process. For example, you can ask about a specific file or engage in a conversation on a particular topic.Termgpt also provides features for resuming previous conversations by using the "-r" flag. It keeps track of the conversation history in a file called "chatgpt_history.json". Additionally, it allows you to run commands in your terminal by using the "-c" flag, although this feature should be used with caution.You can also save the output of the chatbot to a plain text file using the "-o" flag.Overall, Termgpt provides a convenient way to interact with the OpenAI GPT-3.5-turbo (or GPT-4) model through the terminal, allowing for natural language conversations and retrieving information from files.1 / 1Requirements
To use this repository, you need setuptools installed. You can install it using pip install setuptools. Make sure that you have the last version of pip: pip install --upgrade pip

To use the 'api' backend (the default), you need a database backend (SQLite by default, any configurable in SQLAlchemy allowed).

Installation
Code
From packages
Install the latest version of this software directly from github with pip:

pip install git+https://github.com/mmabrouk/chatgpt-wrapper
From source (recommended for development)
Install the latest version of this software directly from git:
git clone https://github.com/mmabrouk/chatgpt-wrapper.git
Install the development package:
cd chatgpt-wrapper
pip install -e .
Backend
The wrapper works with several different backends to connect to the ChatGPT models, and installation is different for each backend.

API (REST-based): DEFAULT
Pros:
Fast (many operations run locally for speed)
Simple API authentication
Full model customizations
You control your data
Cons:
Only paid version available (as of this writing)
More complex setup suitable for technical users
Grab an API key from https://platform.openai.com/account/api-keys

Export the key into your local environment:

export OPENAI_API_KEY=<API_KEY>
Windows users, see here for how to edit environment variables.

To tweak the configuration for the current profile, see Configuration

Database configuration
The API backend requires a database server to store conversation data. The wrapper leverages SQLAlchemy for this.

The simplest supported database is SQLite (which is already installed on most modern operating systems), but you can use any database that is supported by SQLAlchemy.

Check the database setting from the config command above, which will show you the currently configured connection string for a default SQLite database.

If you're happy with that setting, nothing else needs to be done -- the database will be created automatically in that location when you run the program.

Initial user creation and login
Once the database is configured, run the program with no arguments:

chatgpt
It will recognize no users have been created, and prompt you to create the first user:

Username: Required, no spaces or special characters
Email: Optional
Password: Optional, if not provided the user can log in without a password
Once the user is created, execute the /login command with the username:

/login [username]
Once you're logged in, you have full access to all commands.

IMPORTANT NOTE: The user authorization system from the command line is 'admin party' -- meaning every logged in user has admin privileges, including editing and deleting other users.

Setting a per-user default preset
The API backend supports configuring a preset per user.

To do so, run /user-edit and selecting a default preset will be one of the options.1 / 1ChatGPTChatGPTThe requirements to use this repository are as follows:Setuptools: You need to have setuptools installed. You can install it using the command pip install setuptools. Make sure you have the latest version of pip by running pip install --upgrade pip.To install the software, you have two options:Install from Packages: You can install the latest version directly from GitHub using pip with the command pip install git+https://github.com/mmabrouk/chatgpt-wrapper.Install from Source (recommended for development): Clone the repository from GitHub using the command git clone https://github.com/mmabrouk/chatgpt-wrapper.git. Then navigate to the chatgpt-wrapper directory and install the development package using pip install -e ..The wrapper works with different backends to connect to the ChatGPT models, and the installation process for each backend is different.API (REST-based): This is the default backend.Pros: Fast, simple API authentication, full model customizations, and you control your data.Cons: Only the paid version is available, and the setup is more complex.Obtain an API key from https://platform.openai.com/account/api-keys.Export the key to your local environment using the command export OPENAI_API_KEY=<API_KEY>. For Windows users, see the documentation for instructions on editing environment variables.The API backend requires a database server to store conversation data. The wrapper uses SQLAlchemy for this purpose. The default database is SQLite, but you can use any database supported by SQLAlchemy. Check the database setting from the configuration command mentioned above to see the currently configured connection string. If you're satisfied with the default setting, no additional steps are required.After configuring the database, run the program with no arguments: chatgpt. It will prompt you to create the first user by providing a username, email (optional), and password (optional). Once the user is created, you can log in using the /login [username] command. The user with admin privileges can edit and delete other users.The API backend also supports configuring a preset per user. You can use the /user-edit command to set a default preset for a user.Please note that this is a summary of the installation process. For more detailed instructions and configurations, refer to the documentation provided with the repository.1 / 1Connections with the previous topics.1 / 1ChatGPTChatGPTThe previous topics discussed the following:SymbolicAI: SymbolicAI is a data-driven framework that allows for the integration of user-desired behavior into existing prompts. It provides an interface for query and response inspection, enabling the collection of data from API interactions. This data can be used for post-processing, customization, and improvement of model responses based on real-world data.Neuro-Symbolic Engine: SymbolicAI focuses on the evaluation of symbolic expressions using language models like GPT-3. However, for mathematical operations, it can utilize existing symbolic engines like WolframAlpha. The example demonstrated how to use the WolframAlpha engine by setting the expression_engine attribute and performing a mathematical computation.API Backend: The Termgpt software discussed in the later part of the conversation is an OpenAI chatbot that uses the GPT-3.5-turbo or GPT-4 language model. It provides a command-line interface for interacting with the chatbot and can be customized to use different backends. The API backend is the default and requires an OpenAI API key. It also uses a database backend, with SQLite being the default option.Installation: The installation requirements and steps for the Termgpt software were provided. It involves installing the termgpt package and configuring the API backend with the OpenAI API key. The software utilizes different technologies such as setuptools, Git, and database servers (e.g., SQLite).In summary, the previous topics introduced the SymbolicAI framework, discussed different engines (symbolic, neuro-symbolic, OCR, search, etc.) for various tasks, and finally mentioned the Termgpt software, which is an OpenAI chatbot utilizing the GPT language model with an API backend and database storage.1 / 1And I discussed chatgpt-wrapper.1 / 1ChatGPTChatGPTApologies for missing that part. Yes, you mentioned the chatgpt-wrapper repository, which is a wrapper for the ChatGPT models from OpenAI. It provides a simplified interface and additional functionalities for interacting with the models. The installation instructions for the chatgpt-wrapper repository were provided, including the steps to install it from source using Git and pip.The chatgpt-wrapper supports different backends to connect to the ChatGPT models, and the API backend (REST-based) is the default option. It requires an API key from OpenAI, which needs to be set as an environment variable (OPENAI_API_KEY). The backend also requires a database server to store conversation data, with SQLite being the default option. The database configuration and initial user creation process were explained.Overall, the chatgpt-wrapper repository complements the discussion on the Termgpt software by providing a wrapper for interacting with the ChatGPT models in a more user-friendly manner, with support for different backends and database storage.1 / 1A list of everything we've talked about so far.1 / 1ChatGPTChatGPTCertainly! Here's a list of everything we've talked about so far:Termgpt: An OpenAI ChatbotA program that uses the OpenAI API to create a chatbot that can converse with users.Powered by the GPT-3.5-turbo (or GPT-4) language model.Can be used in the terminal to interact with the chatbot.Installation and Usage of TermgptInstallation of Termgpt using pip.Usage examples of Termgpt, including basic conversation, file-related queries, and command execution in the terminal.Resuming previous conversations using the "-r" flag.Saving conversation history and output to files.Requirements for the Termgpt RepositoryInstallation of setuptools and upgrading pip.Different backends for connecting to the ChatGPT models.Database configuration using SQLAlchemy.API backend (REST-based) as the default option.Setting up the API key from OpenAI and configuring the database.Discussion on the chatgpt-wrapper RepositoryInstallation of chatgpt-wrapper from GitHub using pip or from source using Git.Support for different backends to connect to ChatGPT models.API backend (REST-based) as the default option, requiring an API key and database configuration.Initial user creation and login process.Setting a per-user default preset.If there's anything specific you would like to know more about or if there are any other topics you'd like to discuss, please let me know!1 / 1And the neurosymbolic ai.1 / 1ChatGPTChatGPTNeurosymbolic AI is an area of research and development that combines principles from neural networks (AI) and symbolic reasoning (logic and knowledge representation). It aims to integrate the strengths of both approaches to create more robust and explainable AI systems.Neural networks, such as deep learning models, are powerful for learning patterns and making predictions from large amounts of data. They excel at tasks like image recognition, natural language processing, and speech recognition. However, they lack the ability to reason explicitly about concepts and perform logical operations.On the other hand, symbolic reasoning approaches, such as rule-based systems and knowledge graphs, are good at representing and manipulating structured knowledge. They can handle logical rules, infer relationships, and perform complex reasoning tasks. However, they struggle with learning from data and handling uncertainty.Neurosymbolic AI aims to bridge this gap by integrating neural networks and symbolic reasoning. It combines the data-driven learning capabilities of neural networks with the logic-based reasoning capabilities of symbolic systems. The goal is to create AI models that can learn from data, reason about concepts, and provide transparent and interpretable explanations for their decisions.There are different approaches to neurosymbolic AI, including:Neurosymbolic Integration: This approach focuses on combining neural networks and symbolic reasoning models in a modular architecture. The neural network handles data-driven learning tasks, while the symbolic reasoning component handles logical reasoning and knowledge representation.Neural-Symbolic Learning: This approach aims to incorporate symbolic reasoning directly into the learning process of neural networks. It involves encoding symbolic representations into the neural network architecture and training the model to learn both from data and logical constraints.Hybrid Models: These models combine neural networks and symbolic reasoning in a unified framework. They aim to leverage the strengths of both approaches to perform complex tasks that require both pattern recognition and logical reasoning.Neurosymbolic AI has applications in various domains, including robotics, healthcare, natural language understanding, and scientific discovery. It enables AI systems to not only make accurate predictions but also provide explanations and insights into their decision-making process.It's important to note that the term "neurosymbolic AI" is relatively broad, and ongoing research is exploring different techniques and architectures within this field. The specific implementation and approaches may vary depending on the research or development context.1 / 1I mean Xpitfire
/
symbolicai
Public
Fork your own copy of Xpitfire/symbolicai
Code
Issues
1
Pull requests
Actions
Projects
Security
Insights
Xpitfire/symbolicai
Latest commit
@Xpitfire
Xpitfire Added new shortcut type for creating simple LLM functions
â¦
2 days ago
Git stats
 138
Files
Type
Name
Latest commit message
Commit time
assets/images
Add files via upload
2 months ago
docs
Fixed broken link
4 months ago
examples
Fixed style composition on news component
2 months ago
notebooks
Added demo with solver + new example
4 months ago
symai
Added new shortcut type for creating simple LLM functions
2 days ago
tests
Added new shortcut type for creating simple LLM functions
2 days ago
.gitignore
Added initial experiment with graph coherence
3 months ago
CITATION.cff
Update CITATION.cff
5 months ago
CONTRIBUTING.md
Added improved documentation
5 months ago
LICENSE
Added improved documentation
5 months ago
MANIFEST.in
Added improved documentation
5 months ago
README.md
Added support for ChatGPT and GPT-4 engines
2 months ago
environment.yml
Added demo with solver + new example
4 months ago
pyproject.toml
Update pyproject.toml
2 months ago
setup.py
Added improved documentation
5 months ago
README.md
SymbolicAI


A Neuro-Symbolic Perspective on Large Language Models (LLMs)
Building applications with LLMs at its core through our Symbolic API leverages the power of classical and differentiable programming in Python.1 / 1ChatGPTChatGPTThe Xpitfire/symbolicai repository is related to a project that explores a neuro-symbolic perspective on large language models (LLMs). The goal is to build applications with LLMs at their core using a Symbolic API that combines classical and differentiable programming in Python.The repository includes various components and functionalities for working with LLMs and symbolic reasoning. Some key features and concepts covered in the repository are:Symbolic API: The project provides a Symbolic API that allows users to leverage the power of classical and differentiable programming in Python. It enables the integration of LLMs with symbolic reasoning and facilitates the development of neuro-symbolic applications.Neuro-Symbolic Integration: The project explores the integration of large language models (LLMs), such as GPT-3 and GPT-4, with symbolic reasoning techniques. It aims to combine the data-driven learning capabilities of LLMs with the logical reasoning and knowledge representation abilities of symbolic systems.Examples and Notebooks: The repository includes examples and notebooks that demonstrate the usage of the Symbolic API and showcase the capabilities of neuro-symbolic applications. These examples cover various domains and tasks, highlighting the potential of combining LLMs with symbolic reasoning.Testing and Development: The repository also includes test cases and code for ensuring the reliability and correctness of the implemented functionalities. It follows best practices for testing and development to maintain the quality of the codebase.The Xpitfire/symbolicai repository provides a platform for exploring and experimenting with neuro-symbolic AI approaches using large language models. It offers a framework for building applications that combine the power of LLMs with symbolic reasoning, opening up new possibilities for creating intelligent and explainable AI systems.1 / 1Other Use Casesï
We compiled a few examples to show how to use our Symbolic API. You can find them in the notebooks folder.

Basics: See our basics notebook to get familiar with our API structure (notebooks/Basics.ipynb)

Queries: See our query manipulation notebook for contextualized operations (notebooks/Queries.ipynb)

News & Docs Generation: See our news and documentation generation notebook for stream processing (notebooks/News.ipynb)

ChatBot: See how to implement a custom chatbot based on semantic narrations (notebooks/ChatBot.ipynb)

You can solve many more problems with our Symbolic API. We are looking forward to see what you will build with it.1 / 1ChatGPTChatGPTThe Symbolic API provided by Xpitfire/symbolicai offers a range of use cases and applications. Here are some examples:Basics: The basics notebook (notebooks/Basics.ipynb) provides an introduction to the API structure and helps you get familiar with the fundamentals of using the Symbolic API. It covers essential concepts and operations.Queries: The query manipulation notebook (notebooks/Queries.ipynb) demonstrates how to perform contextualized operations on queries. It shows how to manipulate and modify queries to extract relevant information or perform specific tasks.News & Docs Generation: The news and documentation generation notebook (notebooks/News.ipynb) focuses on stream processing. It showcases how to use the Symbolic API to generate news articles or documentation by leveraging symbolic reasoning and language modeling capabilities.ChatBot: The chatbot notebook (notebooks/ChatBot.ipynb) provides a step-by-step guide to implementing a custom chatbot using semantic narrations. It demonstrates how to leverage the Symbolic API to build an intelligent and interactive conversational agent.These examples provide a starting point for understanding the capabilities of the Symbolic API and how it can be applied in various domains. They serve as practical demonstrations of how to use the API to solve different problems and build sophisticated applications.Beyond these specific examples, the Symbolic API can be used to solve a wide range of problems and address diverse use cases. Its flexible and extensible nature allows developers to leverage symbolic reasoning and language modeling to create innovative and intelligent applications.The Xpitfire/symbolicai team looks forward to seeing what you will build with the Symbolic API and how you will further explore its potential in your projects.1 / 1Hi there!
Adding two symbols together.

res = sym + 'how are you?'
res
Hi there! How are you?
If one of the objects is a symbol then the other object is converted to a symbol.

A Symbol instance takes in any type of object and preserves its original value type until it is evaluated and sent to the neuro-symbolic engine:

sym = Symbol(np.array([5, 2, 42, 1]))
sym.type()
numpy.ndarray
One can also easily retriev the object by accessing the value attribute:

sym.value
array([ 5,  2, 42,  1])
We can add multiple values together and their operation will be contextualized evaluated. Here we use the shift operator to integrate a new value into the existing symbol:

res = sym << 2
res
['5', '2', '42', '1', '2']
We could do the same manipulation with the + operator, however, the prompts designed for each individual operator may contain different information, therefore, therefore may not evaluated to similar outcomes. In the following example it is clear that the + operator is not to shift the value into the array:

res = sym + 2
res
['5', '2', '42', '1', 2]
However, if we use the + operator to evaluate arithmetic operations, the results are quite different:

x = Symbol('x')
x += 1
x
x1
In that case the neural engines believes that the goal is to concatenate the two values together. Assuming that we want to add to mathematical operations, we need to use the expression operator:

sym = Symbol('x + 1').expression('self + 2')
sym
x + 3
Here we get the expected result. The self statement in the expression method is a reference to the current symbol (x + 1). This is useful when we want to access values from the current symbol using the expression method.1 / 1ChatGPTChatGPTHello! It seems like you're working with the Symbol class and performing various operations on symbols. Let's break down the code snippets and explanations:Adding two symbols together:pythonCopy coderes = sym + 'how are you?'
res
In this case, if one of the objects is a Symbol instance (sym), then the other object ('how are you?') is converted to a Symbol as well. The resulting symbol res will contain the concatenated value of the two symbols: "Hi there! How are you?"Preserving value type with Symbol:pythonCopy codesym = Symbol(np.array([5, 2, 42, 1]))
sym.type()
The Symbol class can take in any type of object and preserve its original value type until evaluation. In this example, sym is initialized with a NumPy array, and sym.type() returns numpy.ndarray, indicating that the original value type is preserved.Accessing the value attribute:pythonCopy codesym.value
The value attribute of a Symbol instance allows you to access the original object's value. In this case, sym.value returns the NumPy array [5, 2, 42, 1].Shifting a value into the existing symbol:pythonCopy coderes = sym << 2
res
The shift operator (<<) can be used to integrate a new value into the existing symbol. In this example, the value 2 is shifted into the symbol, resulting in ['5', '2', '42', '1', '2'].Contextual evaluation with different operators:pythonCopy coderes = sym + 2
res
The + operator is used here, but the contextual evaluation is different compared to the shift operator. In this case, the value 2 is added to each element of the symbol, resulting in ['5', '2', '42', '1', 2].Using the expression operator for arithmetic operations:pythonCopy codex = Symbol('x')
x += 1
x
When using the += operator for arithmetic operations, the neural engines interpret it as concatenation rather than addition. In this example, x += 1 concatenates the value 1 to the symbol x, resulting in x1.Using the expression method for mathematical operations:pythonCopy codesym = Symbol('x + 1').expression('self + 2')
sym
To perform mathematical operations, the expression operator (expression) is used. In this example, the initial symbol is defined as 'x + 1', and the expression method is called with 'self + 2' to add 2 to the current symbol. The resulting symbol sym evaluates to x + 3.These examples demonstrate how the Symbol class can be used to manipulate symbols, preserve value types, and perform contextualized evaluations using different operators and expressions.1 / 1SymbolicAI: Basics
Get Imports
import os
import warnings
warnings.filterwarnings('ignore')
os.chdir('../') # set the working directory to the root of the project
from symai import *
from IPython.display import display
Using Symbols
sym = Symbol('Hi there!')
sym
Hi there!
Adding two symbols together.

res = sym + 'how are you?'
res
Hi there! How are you?
If one of the objects is a symbol then the other object is converted to a symbol.

A Symbol instance takes in any type of object and preserves its original value type until it is evaluated and sent to the neuro-symbolic engine:1 / 1ChatGPTChatGPTThe code snippet you provided is from the "SymbolicAI: Basics" section. It demonstrates how to use the Symbol class from the SymbolicAI library. Let's break down the code:Importing the required modules:pythonCopy codeimport os
import warnings
warnings.filterwarnings('ignore')
os.chdir('../')  # set the working directory to the root of the project
from symai import *
from IPython.display import display
Here, the necessary modules are imported. os is imported for working with the operating system, warnings is imported to filter out warnings, and symai is imported to access the Symbol class. IPython.display is imported to enable better display of results in an IPython environment.Creating a Symbol:pythonCopy codesym = Symbol('Hi there!')
sym
This code creates a Symbol instance named sym with the value "Hi there!".Adding two symbols together:pythonCopy coderes = sym + 'how are you?'
res
The + operator is used to add two symbols together. If one of the objects is a Symbol instance (sym), the other object ('how are you?') is automatically converted to a Symbol. The resulting symbol res contains the concatenated value of the two symbols: "Hi there! How are you?"Preservation of value types:pythonCopy codesym = Symbol('Hi there!')
The Symbol class can take any type of object as input and preserves its original value type until it is evaluated and sent to the neuro-symbolic engine. In this example, the Symbol instance sym is initialized with a string value.These examples showcase the basic usage of the Symbol class from the SymbolicAI library, including symbol creation and addition of symbols.1 / 1Evaluating Expressions
Similar to word2vec we intend to preform contextualized operations on different symbols.

Word2vec is a machine learning algorithm that is used to generate dense vector representations of words. It works by training a shallow neural network to predict a word given its neighbors in a text corpus. The resulting vectors are then used in a wide range of natural language processing applications, such as sentiment analysis, text classification, and clustering.

Below we can see an example how one can perform operations on the word embedding vectors (colored boxes).


However, we can also perform operations on the natural language space itself. For example, we can add two the word expressions similar to how we added them in the word2vec space:

Symbol('King - Man + Women').expression()
Queen
As we can see, if the expression method is empty the default implementation of Symbol uses only the value stored within the current symbol.

Now let's try to evaluate a more complex expression:

sym = Symbol()
res = sym.expression('x^2 + 2x + 1')
res
x^2 + 2x + 1
Well, not exactly simplified the way we intended it.

This is because using LLMs for expression evaluations is still very limited, therefore, to leverage the full power of symbolic programming we can use the expression method to evaluate an expression via WolframAlpha:

expr = Symbol()
expr.command(engines=['symbolic'], expression_engine='wolframalpha')
res = expr.expression('x^2 + 2x + 1')
res
x = -1
There we go! The command method configures the symbolic engine to evaluate expressions via WolframAlpha. One can see that this evaluates the expression and returns the correct result.

Showing other basic operations
Sometimes we want to simply concatenate to symbols together without any other neural operation. This is easily done with the @ operation:

# define a second string
sym = Symbol("Welcome to our tutorial.")
test2 = 'Hello world!'
# concatenate strings
res = sym @ test2
res
Welcome to our tutorial.Hello world!
We can of course define full sentences as Symbols and perform several operations on them.

sym = Symbol("""Images and videos of domestic cats make up some of the most viewed content on the World Wide Web, particularly image macros in the form of lolcats. ThoughtCatalog has described cats as the "unofficial mascot of the Internet".[1]
The subject has attracted the attention of various scholars and critics, who have analyzed why this form of low art has reached iconic status. Although it may be considered frivolous, cat-related Internet content contributes to how people interact with media and culture.[2] Some argue that there is a depth and complexity to this seemingly simple content, with a suggestion that the positive psychological effects that pets have on their owners also hold true for cat images viewed online.[3]
Research has suggested that viewing online cat media is related to positive emotions, and that it even may work as a form of digital therapy or stress relief for some users. Some elements of research also shows that feelings of guilt when postponing tasks can be reduced by viewing cat content.[4]
""")
Here we translate the existing Symbol to German:

sym.translate('German')
Bilder und Videos von Haustieren machen einen GroÃteil der am meisten angesehenen Inhalte im World Wide Web aus, insbesondere Bildmacros in Form von Lolcats. ThoughtCatalog beschrieb Katzen als den "unoffiziellen Maskottchen des Internets". [1] Das Thema hat die Aufmerksamkeit verschiedener Wissenschaftler und Kritiker auf sich gezogen, die analysiert haben, warum diese Form der And now, we try to classify how the mood of the above sentences:

sym.choice(['angry', 'neutral', 'hate-speech', 'happy', 'unk'], default='unk')
neutral
Documentation Generator Example
from examples.docs import Docs, CppDocs
docs = Docs()
doc = docs("""def execute(default: str = None,
            constraints: List[Callable] = [],
            pre_processor: List[PreProcessor] = [],
            post_processor: List[PostProcessor] = [],
            *wrp_args,
            **wrp_kwargs):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(wrp_self, *args, **kwargs):
            return execute_func(wrp_self, 
                                func=func,
                                code=str(wrp_self),
                                constraints=constraints, 
                                default=default, 
                                pre_processor=pre_processor, 
                                post_processor=post_processor,
                                wrp_args=wrp_args,
                                wrp_kwargs=wrp_kwargs,
                                args=args, kwargs=kwargs)
        return wrapper
    return decorator
""")
print(doc)
"""Executes a function with the given parameters.

Args:
    default (str, optional): The default value to be returned if the task cannot be solved. Defaults to None.
    constraints (List[Callable], optional): A list of constrains applied to the model output to verify the output. Defaults to [].
    pre_processor (List[PreProcessor], optional): A list of pre-processors to be applied to the input and shape the input to the model. Defaults to None.
    post_processor (List[PostProcessor], optional): A list of post-processors to be applied to the model output and before returning the result. Defaults to [].
    *wrp_args: Variable length argument list.
    **wrp_kwargs: Arbitrary keyword arguments.

Returns:
    decorator: A decorator that wraps the given function with the given parameters.
"""
Markdown
We can actually on the fly also generate markdown documentation for our notebooks. This is done by using the built in query method. The query method is used to query the symbolic engine for information about the current symbol. The query method can therefore be used to ask the engine to generate documentation in a specific format.

res = expr.query(context="Write a very detailed Markdown documentation the News class.", max_tokens=3000)
print(res)
# News

The News class is a custom Expression class used to fetch and process news articles. It contains methods to fetch a news article from a given URL, process the article using a specified pattern, and render the article in an HTML template. 

## Constructor

The constructor takes four parameters:

- `url`: A string representing the URL of the news article to fetch
- `pattern`: A string representing the pattern to use when processing the news article
- `filters`: An optional list of Expressions used to filter the news article
- `render`: An optional boolean indicating whether or not to render the news article in an HTML template

The constructor also initializes the following fields:

- `data_stream`: A Stream object containing a Sequence of Clean, Translate, Outline, and Compose expressions
- `header_style`: A Style object used to style the HTML template
- `html_template`: A Symbol object containing the HTML template
- `html_template_seq`: A Template object used to insert the rendered news article into the HTML template
- `html_stream`: A Stream object containing a Sequence of the HTML template and style

## Methods

### render

The render method takes a Symbol object as a parameter and returns a Symbol object containing the rendered news article. It uses the header_style to style the HTML template, the html_template_seq to insert the rendered news article into the HTML template, and the html_stream to style the rendered article.

### forward

The forward method fetches the news article from the given URL, processes it using the specified pattern, and clusters the results. It then maps the clusters and, if render is set to True, renders the mapped results. Finally, it returns a Symbol object containing the rendered news article.
 1 / 1ChatGPTChatGPTThe code snippet you provided demonstrates various examples of evaluating expressions using the SymbolicAI library. Let's break down each example:Word2vec-like operations:pythonCopy codeSymbol('King - Man + Women').expression()
This example shows how to perform operations on word embedding vectors. The expression 'King - Man + Women' represents the operation of subtracting the vector for "Man" from the vector for "King" and adding the vector for "Women" to it. The resulting symbol represents the closest word in the embedding space, which in this case is "Queen".Evaluating simple expressions:pythonCopy codesym = Symbol()
res = sym.expression('x^2 + 2x + 1')
res
Here, the expression 'x^2 + 2x + 1' is evaluated. However, since LLMs have limited capabilities in evaluating mathematical expressions, the result is not simplified.Evaluating expressions using WolframAlpha:pythonCopy codesym = Symbol()
sym.command(engines=['symbolic'], expression_engine='wolframalpha')
res = sym.expression('x^2 + 2x + 1')
res
To leverage the full power of symbolic programming, the expression is evaluated using WolframAlpha. The command method configures the symbolic engine to use WolframAlpha for expression evaluation. The resulting symbol correctly evaluates the expression and returns the simplified result: x = -1.Concatenating symbols:pythonCopy codesym = Symbol("Welcome to our tutorial.")
test2 = 'Hello world!'
res = sym @ test2
res
The @ operator is used to concatenate two symbols together. In this example, the symbol sym is concatenated with the string 'Hello world!', resulting in the symbol "Welcome to our tutorial.Hello world!".Translating symbols:pythonCopy codesym = Symbol("""Images and videos of domestic cats make up some of the most viewed content on the World Wide Web...""")
sym.translate('German')
The translate method is used to translate a symbol to a different language. In this example, the symbol containing a paragraph about cats is translated to German using the translate method. The resulting symbol contains the German translation.Classifying the mood of a sentence:pythonCopy codesym.choice(['angry', 'neutral', 'hate-speech', 'happy', 'unk'], default='unk')
The choice method is used to classify the mood of a sentence. In this example, the sentence is classified into one of the given categories: angry, neutral, hate-speech, happy, or unknown (default).Generating documentation:pythonCopy codefrom examples.docs import Docs, CppDocs
docs = Docs()
doc = docs("""def execute(default: str = None,
            constraints: List[Callable] = [],
            pre_processor: List[PreProcessor] = [],
            post_processor: List[PostProcessor] = [],
            *wrp_args,
            **wrp_kwargs):
    ...
""")
print(doc)
This example shows how to generate documentation for a function using the Docs class. The function is passed as a multiline string, and the docs method generates the documentation for it. The resulting documentation is printed.Overall, these examples demonstrate how to evaluate expressions using the SymbolicAI library. From performing word2vec-like operations to evaluating mathematical expressions and generating documentation, the library provides capabilities for symbolic programming and manipulation of symbols.1 / 1symbolicai  notebooks
ChatBot
Get Imports
import os
import warnings
warnings.filterwarnings('ignore')
os.chdir('../') # set the working directory to the root of the project
from symai import *
from IPython.display import display
Writing a chatbot is fairly easy with our framework. All we need to do is basically derive from the ChatBot class and implement the forward method. The base class ChatBot has already some helper capabilities and context detection dictionaries. All we have to do is use the self.narrate method to instruct our chatbot to say what we want.

Afterwards, we can use the self.context_choice method to classify the context of the user input. This is done by using a dictionary of context keywords. The self.context_choice method returns the context key that matches the user input. This key can then be used to determine the next action / condition of the chatbot.

See the following example:

from symai.chat import ChatBot


class SymbiaChat(ChatBot):
    def forward(self) -> str:
        message = self.narrate('Symbia introduces herself, writes a greeting message and asks how to help.')        
        while True:
            # query user
            usr = self.input(message)
            
            # detect context
            ctxt = self.context_choice(usr)
            
            if 'option 3' in ctxt: # exit
                self.narrate('Symbia writes goodbye message.', end=True)
                break # end chat
            
            elif 'option 4' in ctxt: # help
                message = self.narrate('Symbia writes for each capability one sentence.', 
                                       context=self.capabilities)
                      
            elif 'option 1' in ctxt: # chit chat
                message = self.narrate('Symbia replies to the user question in a casual way.')
        
            elif 'option 2' in ctxt: 
                # detect command
                option = self.capabilities_choice(usr)
                
                if 'option 1' in option:
                    q = usr.extract('user query request')
                    rsp = self.search(q)
                    message = self.narrate('Symbia replies to the user based on the online search results.', 
                                           context=rsp)                    
                elif 'option 2' in option:
                    q = usr.extract('URL')
                    site = self.fetch(q)
                    site.save('tmp.html')
                    message = self.narrate('Symbia explains that the website is downloaded to the `tmp.html` file.') 
                elif 'option 3' in option:
                    pass
                
                # TODO ...
By creating an instance of the SymbiaChat and calling the forward method, we can start a chat with our chatbot. The forward method takes a user input and returns a chatbot response.

chat = SymbiaChat()
chat()
The above bot can answer some trivia, use the Google search engine to retrieve information and1 / 1ChatGPTChatGPTThe code snippet you provided demonstrates how to write a chatbot using the SymbolicAI framework. Here's a breakdown of the example:Importing necessary modules:pythonCopy codeimport os
import warnings
warnings.filterwarnings('ignore')
os.chdir('../')
from symai import *
from IPython.display import display
This code imports the required modules for the chatbot implementation, including the symai library and the display function from IPython.Creating a chatbot class:pythonCopy codeclass SymbiaChat(ChatBot):
    def forward(self) -> str:
        # Implementation goes here
In this example, a new chatbot class named SymbiaChat is derived from the base class ChatBot. The forward method is overridden and serves as the main logic for the chatbot.Implementing the chatbot logic:pythonCopy codedef forward(self) -> str:
    message = self.narrate('Symbia introduces herself, writes a greeting message and asks how to help.')
    while True:
        usr = self.input(message)  # Query user
        ctxt = self.context_choice(usr)  # Detect context
        # Check different contexts and take appropriate actions
        if 'option 3' in ctxt:  # Exit
            self.narrate('Symbia writes goodbye message.', end=True)
            break
        elif 'option 4' in ctxt:  # Help
            message = self.narrate('Symbia writes for each capability one sentence.', context=self.capabilities)
        elif 'option 1' in ctxt:  # Chit chat
            message = self.narrate('Symbia replies to the user question in a casual way.')
        elif 'option 2' in ctxt:
            option = self.capabilities_choice(usr)  # Detect command
            # Handle different command options
            if 'option 1' in option:
                q = usr.extract('user query request')
                rsp = self.search(q)
                message = self.narrate('Symbia replies to the user based on the online search results.', context=rsp)
            elif 'option 2' in option:
                q = usr.extract('URL')
                site = self.fetch(q)
                site.save('tmp.html')
                message = self.narrate('Symbia explains that the website is downloaded to the `tmp.html` file.')
            elif 'option 3' in option:
                pass
            # TODO: Handle more options
In the forward method, the chatbot interacts with the user by using the narrate method to display messages and ask for user input. It then uses the context_choice method to classify the context of the user input and takes appropriate actions based on the detected context and user commands.Starting the chat:pythonCopy codechat = SymbiaChat()
chat()
After creating an instance of the SymbiaChat class, the chatbot can be started by calling the forward method. This method takes user input and returns a chatbot response.This example provides a basic structure for building a chatbot using the SymbolicAI framework. You can customize the logic, add more contexts, and extend the functionality of the chatbot to suit your specific requirements.1 / 1SymbolicAI: Basics
Get Imports
import os
import warnings
warnings.filterwarnings('ignore')
os.chdir('../') # set the working directory to the root of the project
from symai import *
from IPython.display import display
Handling large / long context lengths
We can create contextual prompts to define the semantic operations for our model. However, this takes away a lot of our context size and since the GPT-3 context length is limited to 4097 tokens, this might quickly become a problem. Luckily we can use the Stream processing expression. This expression opens up a data stream and computes the remaining context length for processing the input data. Then it chunks the sequence and computes the result for each chunk. The chunks can be processed with a Sequence expression, that allows multiple chained operations in a sequential manner.

In the following example we show how we can extract news from a particular website and try to recombine all individual chunks again by clustering the information among the chunks and then recombining them. This gives us a way to consolidate contextually related information and recombine them in a meaningful way. Furthermore, the clustered information can then be labeled by looking / streaming through the values within the cluster and collecting the most relevant labels.


If we repeat this process, we now get a way of building up a hierarchical cluster with labels as entry points to allow information retrieval from our new data structure.

To make manners more concrete, lets take a look at how to build up a news generator. Let us first start by importing some pre-defined string constants. These constants are used to define how the text is processed and how we desire the output to be formatted.

from examples.news import HEADER_STYLE_DESCRIPTION, HTML_TEMPLATE, HTML_STREAM_STYLE_DESCRIPTION
News Generator
We sub-class the Expression class and define the __init__ implementation. Similar to PyTorch we can define the graph in the __init__ method and then call the forward method to compute the result. Afterwards, the data from the web URL is streamed through a Sequence of operations. This cleans the text from all the clutter such as \n, \t, etc. and then extracts the news from the text. The news are then filtered and re-composed. The resulting news texts are then clustered and the clusters are labeled. The labeled clusters are then recombined to return a rendered HTML format.

class News(Expression):
    """The `News` class sub-classes `Expression` and provides a way to fetch and render news from a given url. It uses a `Stream` object to process the news data, with a sequence of `Clean`, `Translate`, `Outline`, and `Compose` expressions. 
    It also defines a `Style` for the header, and a `Symbol` for the HTML templates. 
    """
    def __init__(self, url: str, pattern: str, filters: List[Expression] = [], render: bool = False):
        """The `News` class constructor requires three arguments - `url`, `pattern` and `filters`. 
        * `url` is a `str` containing the url to fetch the news from. 
        * `pattern` is a `str` containing the name of the search key to be found on the web page.
        * `filters` is a `List[Expression]` containing any additional filters that should be applied to the news data. 
        It defaults to an empty list if not specified. 
        The `News` class also has an optional `render` argument which is a `bool` indicating whether the news should be rendered. It defaults to `False` if not specified. 
        """
        super().__init__()
        self.url = url
        self.pattern = pattern
        self.render_ = render
        filters = filters if isinstance(filters, List) or isinstance(filters, tuple) else [filters]
        self.data_stream = Stream(Sequence(
            Clean(),
            Translate(),
            Outline(),
            *filters,
            Compose(f'Compose news paragraphs. Combine only facts that belong topic-wise together:\n'),
        ))
        self.header_style = Style(description=HEADER_STYLE_DESCRIPTION, 
                                  libraries=['https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css', 
                                             'https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js',
                                             'https://ajax.googleapis.com/ajax/libs/jquery/3.6.1/jquery.min.js'])
        
        self.html_template = Symbol(HTML_TEMPLATE)
        self.html_template_seq = Template()
        self.html_stream = Stream(
            Sequence(
                self.html_template_seq,
                Style(description=HTML_STREAM_STYLE_DESCRIPTION)
            )
        )
        
    def render(self, sym: Symbol) -> Symbol:
        """The `render` method takes a `Symbol` as an argument and returns a `Symbol` containing the rendered news. 
        It first sets the `html_template_seq` property of the `html_stream` to the result of applying the `header_style` to the `html_template`. 
        It then iterates through the `data_stream` and collects the strings resulting from each expression. 
        These strings are combined into a single `Symbol` object which is then clustered. 
        Finally, the `render` method applies the `html_template` to the clustered `Symbol` and returns the result. 
        """
        tmp = self.header_style(self.html_template, max_tokens=2000)
        self.html_template_seq.template_ = str(tmp)
        res = '\n'.join([str(s) for s in self.html_stream(sym)])
        res = Symbol(str(tmp).replace('{{placeholder}}', res))
        return res
        
    def forward(self) -> Symbol:
        """The `forward` method is used to fetch and process the news data. 
        It first calls the `fetch` method with the `url` and `pattern` arguments. 
        It then iterates through the `data_stream` and collects the `Symbol` object resulting from each expression. 
        These `Symbol` objects are then combined into a single `Symbol` object which is then mapped. 
        If `render` is `False`, the mapped `Symbol` is returned. Otherwise, the `render` method is called with the `Symbol` and the resulting `Symbol` is returned.
        """
        res = self.fetch(url=self.url, pattern=self.pattern)
        vals = []
        for news in self.data_stream(res):
            vals.append(str(news))
        res = Symbol(vals).cluster()
        sym = res.map()
        if not self.render_:
            return sym
        return self.render(sym)
Here you can try the news generator:

# crawling the website and creating an own website based on its facts
news = News(url='https://www.cnbc.com/cybersecurity/',
            pattern='cnbc',
            filters=ExcludeFilter('sentences about subscriptions, licensing, newsletter'),
            render=True)
Since the generative process will evaluate multiple expression, we can use the Trace and Log classes to keep track of what is happening.

expr = Log(Trace(news))
res = expr()
os.makedirs('results', exist_ok=True)
path = os.path.abspath('results/news.html')
res.save(path, replace=False)
Streaming over a PDF File
Another example is to read in a PDF file and extract the text from it to create a website based on its content.

from examples.paper import Paper
The process is fairly similar to the news generator. We first read in the PDF file and then stream the text through a sequence of operations. The text is then cleaned and the sentences are extracted. The sentences are then clustered and labeled. The labeled clusters are then recombined to return a rendered HTML format.

paper = Paper(path='examples/paper.pdf')
expr = Log(Trace(paper))
res = expr(n_pages=1)
os.makedirs('results', exist_ok=True)
path = os.path.abspath('results/news.html')
res.save(path, replace=False)1 / 1ChatGPTChatGPTThe code snippet you provided demonstrates how to handle large or long context lengths using the SymbolicAI framework. Here's a breakdown of the example:Importing necessary modules:pythonCopy codeimport os
import warnings
warnings.filterwarnings('ignore')
os.chdir('../')
from symai import *
from IPython.display import display
This code imports the required modules for the example, including the symai library and the display function from IPython.Creating a news generator:pythonCopy codefrom examples.news import HEADER_STYLE_DESCRIPTION, HTML_TEMPLATE, HTML_STREAM_STYLE_DESCRIPTION

class News(Expression):
    def __init__(self, url: str, pattern: str, filters: List[Expression] = [], render: bool = False):
        super().__init__()
        self.url = url
        self.pattern = pattern
        self.render_ = render
        filters = filters if isinstance(filters, List) or isinstance(filters, tuple) else [filters]
        self.data_stream = Stream(Sequence(
            Clean(),
            Translate(),
            Outline(),
            *filters,
            Compose(f'Compose news paragraphs. Combine only facts that belong topic-wise together:\n'),
        ))
        self.header_style = Style(description=HEADER_STYLE_DESCRIPTION, 
                                  libraries=['https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css', 
                                             'https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js',
                                             'https://ajax.googleapis.com/ajax/libs/jquery/3.6.1/jquery.min.js'])
        
        self.html_template = Symbol(HTML_TEMPLATE)
        self.html_template_seq = Template()
        self.html_stream = Stream(
            Sequence(
                self.html_template_seq,
                Style(description=HTML_STREAM_STYLE_DESCRIPTION)
            )
        )
        
    def render(self, sym: Symbol) -> Symbol:
        tmp = self.header_style(self.html_template, max_tokens=2000)
        self.html_template_seq.template_ = str(tmp)
        res = '\n'.join([str(s) for s in self.html_stream(sym)])
        res = Symbol(str(tmp).replace('{{placeholder}}', res))
        return res
        
    def forward(self) -> Symbol:
        res = self.fetch(url=self.url, pattern=self.pattern)
        vals = []
        for news in self.data_stream(res):
            vals.append(str(news))
        res = Symbol(vals).cluster()
        sym = res.map()
        if not self.render_:
            return sym
        return self.render(sym)
In this example, a News class is defined by subclassing the Expression class. The __init__ method sets up the necessary attributes and creates the data stream with a sequence of operations such as Clean, Translate, Outline, and additional filters. The render method is used to render the news as HTML based on the collected information. The forward method fetches the news from the provided URL, processes it through the data stream, clusters the results, and returns the rendered news if render is True.Using the news generator:pythonCopy codenews = News(url='https://www.cnbc.com/cybersecurity/',
            pattern='cnbc',
            filters=ExcludeFilter('sentences about subscriptions, licensing, newsletter'),
            render=True)
This code creates an instance of the News class, specifying the URL to fetch the news from, a pattern to identify the relevant content on the web page, and any additional filters to apply. The render parameter is set to True to indicate that the news should be rendered as HTML.Streaming over a PDF file:pythonCopy codefrom examples.paper import Paper
This code imports the Paper class from the examples.paper module.The process for streaming over a PDF file is similar to the news generator. You create an instance of the Paper class, provide the path to the PDF file, and then process the text through a sequence of operations. The resulting text is cleaned, sentences are extracted, clustered, labeled, and then rendered as HTML.Please note that the complete code for the Paper class and the specifics of processing the PDF file are not provided in the snippet you shared.These examples demonstrate how to handle large context lengths and process text data to generate meaningful output using the SymbolicAI framework.1 / 1from sympy import symbols, Eq, solve

# Define variables
red, green, white, yellow, blue = symbols('red green white yellow blue')
englishman, swede, dane, norwegian, german = symbols('englishman swede dane norwegian german')
tea, coffee, milk, beer, water = symbols('tea coffee milk beer water')
pall_mall, dunhill, blend, blue_masters, prince = symbols('pall_mall dunhill blend blue_masters prince')
birds, dogs, cats, horses, fish = symbols('birds dogs cats horses fish')

# Define constraints
constraints = [
    Eq(englishman, red),
    Eq(swede, dogs),
    Eq(dane, tea),
    Eq(green - white, -1),
    Eq(green, coffee),
    Eq(pall_mall, birds),
    Eq(yellow, dunhill),
    Eq(milk, 3),
    Eq(norwegian, 1),
    Eq(abs(blend - cats), 1),
    Eq(blue_masters, beer),
    Eq(abs(horses - dunhill), 1),
    Eq(german, prince),
    Eq(abs(norwegian - blue), 1),
    Eq(abs(blend - water), 1)
]

# Find solution
solution = solve(constraints, [fish])

# Print solution
print(f"The {solution} keeps fish.")
The [] keeps fish.1 / 1ChatGPTChatGPTThe code you provided uses the sympy library to define variables and constraints for a logical puzzle known as the "Einstein's Riddle" or "Zebra Puzzle." It aims to find the person who keeps fish based on a set of given constraints.However, the current code does not provide a solution because the constraints specified in the constraints list are inconsistent. As a result, the solve function does not find a valid solution for the given constraints.To obtain a valid solution, you need to carefully define the constraints to ensure they are consistent and can be satisfied. The constraints should establish unique relationships between the variables and provide enough information to deduce the person who keeps fish.Once the constraints are correctly defined, the solve function can be used to find a solution, and the result can be printed using the appropriate format.1 / 1Yeah it looks incomplete, based on what we discussed earlier, give something with more functionality.1 / 1ChatGPTChatGPTCertainly! Here's an extended version of the code that includes additional functionality for solving the Einstein's Riddle:pythonCopy codefrom sympy import symbols, Eq, solve

# Define variables
colors = ['red', 'green', 'white', 'yellow', 'blue']
nationalities = ['englishman', 'swede', 'dane', 'norwegian', 'german']
drinks = ['tea', 'coffee', 'milk', 'beer', 'water']
cigarettes = ['pall_mall', 'dunhill', 'blend', 'blue_masters', 'prince']
pets = ['birds', 'dogs', 'cats', 'horses', 'fish']

variables = colors + nationalities + drinks + cigarettes + pets
symbols_dict = {var: symbols(var) for var in variables}
locals().update(symbols_dict)

# Define constraints
constraints = [
    Eq(englishman, red),
    Eq(swede, dogs),
    Eq(dane, tea),
    Eq(green - white, -1),
    Eq(green, coffee),
    Eq(pall_mall, birds),
    Eq(yellow, dunhill),
    Eq(milk, 3),
    Eq(norwegian, 1),
    Eq(abs(blend - cats), 1),
    Eq(blue_masters, beer),
    Eq(abs(horses - dunhill), 1),
    Eq(german, prince),
    Eq(abs(norwegian - blue), 1),
    Eq(abs(blend - water), 1)
]

# Find solution
solution = solve(constraints, variables)

# Print solution
for var, val in solution.items():
    print(f"The {var} has {val}.")
In this version, the code defines separate lists for the different categories such as colors, nationalities, drinks, cigarettes, and pets. It also creates a dictionary symbols_dict that maps each variable to its corresponding sympy symbol using a loop.The constraints list includes equations that establish the relationships between the variables based on the given puzzle constraints.The solve function is then used to find a solution that satisfies all the constraints. The resulting solution is a dictionary mapping each variable to its assigned value.Finally, the code prints out the solution by iterating over the solution dictionary and displaying the variable and its corresponding value.Note that the code assumes that there is a unique solution that satisfies all the constraints. If the constraints are inconsistent or insufficient, the code may not produce a valid solution.1 / 1What kind of functionality does this library have?1 / 1ChatGPTChatGPTThe sympy library provides a wide range of mathematical and symbolic computation functionalities. Some of the key features and functionalities of sympy include:Symbolic Mathematics: sympy allows you to work with symbolic expressions, symbols, and equations. It can perform algebraic manipulations, simplify expressions, expand and factorize expressions, solve equations and systems of equations, compute derivatives and integrals, and more.Symbolic Simplification: sympy can simplify complex mathematical expressions, perform trigonometric simplifications, simplify rational functions, simplify boolean expressions, and handle algebraic simplifications.Equation Solving: sympy can solve algebraic equations, transcendental equations, differential equations, and systems of equations. It supports both exact and numerical solutions.Calculus: sympy provides a comprehensive suite of calculus functionalities, including differentiation, integration, limits, series expansion, and differential equations.Linear Algebra: sympy offers a range of linear algebra capabilities, such as matrix operations (addition, multiplication, inversion), solving linear systems, eigenvalue and eigenvector computations, matrix factorization, and more.Discrete Mathematics: sympy includes functionalities for combinatorics, number theory, graph theory, and discrete mathematics. It can generate permutations, combinations, partitions, perform combinatorial operations, factorize integers, work with prime numbers, and analyze graphs.Numeric Evaluation: sympy supports numerical evaluation of expressions using arbitrary-precision arithmetic. It can handle both real and complex numbers and perform numeric computations with high precision.Plotting: sympy provides a plotting module that can generate 2D and 3D plots of mathematical functions, expressions, and data.LaTeX Output: sympy can generate LaTeX code for mathematical expressions, making it convenient for generating mathematical formulas and equations in LaTeX documents.Code Generation: sympy allows you to generate code in various programming languages, including Python, C, Fortran, and more, from symbolic expressions. This enables the translation of symbolic computations into executable code.These are just some of the main functionalities offered by sympy. The library is actively developed and maintained, and it continues to expand its capabilities with each new release.1 / 1SymbolicAI1 / 1ChatGPTChatGPTSymbolicAI is a framework that combines symbolic programming with large language models (LLMs) to enable the development of intelligent applications. It leverages the power of classical and differentiable programming in Python to build applications with LLMs at their core.The SymbolicAI framework provides several key components and features:Symbolic API: The SymbolicAI framework introduces a Symbolic API that allows you to work with symbolic expressions, symbols, and operations. It provides a high-level interface for defining and manipulating symbolic objects, performing symbolic computations, and integrating them with LLMs.Neuro-Symbolic Integration: SymbolicAI enables the integration of symbolic programming and neural networks. It allows you to combine the strengths of both approaches, leveraging the expressiveness and interpretability of symbolic programming with the learning and generalization capabilities of neural networks.Contextualized Operations: With SymbolicAI, you can perform contextualized operations on symbols and expressions. This means that the operations can be dynamically evaluated based on the context in which they are applied, allowing for more flexible and adaptive computations.Stream Processing: The framework includes stream processing capabilities, which allow you to process data streams and perform sequential operations on them. This is particularly useful for handling large or long context lengths, where data needs to be processed in chunks or sequences.Documentation Generation: SymbolicAI provides functionality for generating documentation from symbolic expressions. It can generate Markdown documentation for notebooks, making it easier to document and share your code and models.Chatbot Development: The framework includes features for building chatbots. It provides a base class for chatbot development, allowing you to derive custom chatbot classes and implement the forward method to define the chatbot's behavior and interactions.Data Manipulation and Analysis: SymbolicAI offers tools for data manipulation and analysis. It provides functionality for cleaning and processing data, extracting information, clustering data, labeling clusters, and performing various operations on data streams.Integration with External Engines: SymbolicAI allows for integration with external engines and services, such as WolframAlpha, to perform specific computations or evaluations. This enables access to a wider range of computational capabilities beyond what is available within the framework itself.Overall, SymbolicAI aims to bridge the gap between symbolic programming and large language models, enabling the development of intelligent applications that leverage both approaches. It provides a flexible and powerful framework for symbolic computations, context-aware operations, and integration with LLMs, opening up new possibilities for advanced AI applications.1 / 1Do you remember earlier when we discussed Lojban and universal languages?1 / 1ChatGPTChatGPTYes, I remember our discussion about Lojban and universal languages. Lojban is an artificial language that was designed with the goal of being culturally neutral and logically unambiguous. It was created in the late 20th century and is based on the principles of predicate logic.Lojban aims to be a universal language that can be easily understood and used by people from different linguistic backgrounds. It has a regular grammar and a precise syntax, which helps in avoiding the ambiguities and inconsistencies found in natural languages. The vocabulary of Lojban is derived from a combination of several natural languages, with words chosen based on their international recognition and simplicity.The design of Lojban focuses on making the language expressive and flexible, allowing for precise communication of ideas. It is based on predicate logic, which means that sentences in Lojban can be understood as logical propositions with clear subject-predicate structures.The idea behind universal languages, including Lojban, is to create a common language that can be understood and used by people from different linguistic backgrounds. The goal is to overcome the barriers caused by language differences and facilitate communication and understanding among people.However, it's worth noting that the adoption and widespread use of a universal language like Lojban face significant challenges. Natural languages are deeply embedded in cultures and societies, and they carry rich nuances, cultural references, and historical contexts that may be difficult to capture in a constructed language. Additionally, the learning and adoption of a new language require time and effort, and there must be a compelling motivation for individuals and communities to invest in learning and using a universal language.While the concept of universal languages is intriguing and has been explored by linguists and language enthusiasts, the practical realization of a widely adopted universal language remains a complex and ongoing challenge.1 / 1Ok well I meant to say how come there was no mention of Pythagoras and Theano's suggestion for geometry, music, and mathematics as rational, relational, universal languages.1 / 1ChatGPTChatGPTI apologize for not mentioning Pythagoras and Theano's suggestion regarding geometry, music, and mathematics as rational, relational, universal languages. Pythagoras, an ancient Greek philosopher and mathematician, and his follower Theano, proposed that these disciplines could serve as universal languages for understanding and expressing fundamental principles of the universe.According to Pythagoras, geometry, music, and mathematics were interconnected and represented the harmonious order of the cosmos. He believed that numbers and ratios were fundamental to understanding the structure of the universe. Pythagoras and his followers explored the mathematical relationships found in geometric figures, musical harmonies, and numerical patterns, seeing them as reflections of deeper truths.Theano, who was both a mathematician and Pythagoras' wife, further developed these ideas. She suggested that the principles of rationality and relationality inherent in mathematics and geometry could be applied universally. By studying these disciplines, one could gain insights into the fundamental nature of reality and establish a common language that transcended linguistic and cultural barriers.The concept of using geometry, music, and mathematics as universal languages was rooted in the belief that these disciplines had inherent order, logic, and beauty that could be understood by individuals across different cultures and backgrounds. The symbolic and abstract nature of these disciplines allowed for the expression and communication of ideas in a way that transcended specific languages and cultural contexts.It's important to note that Pythagoras and Theano's ideas were influential in their time and contributed to the development of mathematics, philosophy, and the sciences. However, the concept of using geometry, music, and mathematics as universal languages has evolved and been interpreted in various ways throughout history. Different approaches and theories have emerged regarding the nature of universal languages and the extent to which they can bridge linguistic and cultural gaps.Ultimately, the quest for a truly universal language, whether through constructed languages like Lojban or through the application of mathematics and other disciplines, continues to be an ongoing exploration in the fields of linguistics, philosophy, and communication.1 / 1
;;lynxspace;;

::gtt::sudo apt-get install
::upd::sudo apt-get update
::upg::sudo apt-get upgrade

;; llast ;; last loop(?) ;; exit status ;; did it work?  -- 0 indicates success; 1 +, failure
::lastcommand::echo $?`n

::sa::{î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­}

; a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z
; î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­

::2sga::a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z = symbols('î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­')

;; bash bashsh ;;

::lasthour::find . -mmin -60 -print -exec tail -n 2 \{\} \;1 / 1ChatGPTChatGPTIt seems like you're using a custom script or system that includes certain commands and symbols. However, I'm unable to understand the specific purpose or context of these commands and symbols. Could you please provide more information or clarify your question?1 / 1It's a script to generate symbols for simply using standard Galactic alphabet in unicode, as seen a few other shortcuts.1 / 1ChatGPTChatGPTAh, I see! The script you provided allows you to define shortcuts for certain commands or symbols using the Galactic alphabet in Unicode representation. This can be a fun way to add some personalization or novelty to your scripting or command line experience.For example, the ::2sga::a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z = symbols('î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­,î­') line assigns the Galactic alphabet symbols to the corresponding variables a to z using the symbols() function.Similarly, the ::gtt::sudo apt-get install, ::upd::sudo apt-get update, and ::upg::sudo apt-get upgrade lines define shortcuts for running specific commands.It's a creative way to incorporate the Galactic alphabet symbols into your scripting or command line interactions.1 / 1
;; installing ubuntu on termux

/*
::instructshions::
(
Update termux: apt-get update && apt-get upgrade -y
Install wget:: apt-get install wget -y
Install proot:: apt-get install proot -y
Install git:: apt-get install git -y
Go to HOME folder: cd ~
Download script: git clone https://github.com/MFDGaming/ubuntu-in-termux.git
Go to script folder: cd ubuntu-in-termux
Give execution permission: chmod +x ubuntu.sh
Run the script: ./ubuntu.sh -y
Now just start ubuntu: ./startubuntu.sh
)
*/

;; ubuntu in termux ;;

::get termux::git clone https://github.com/MFDGaming/ubuntu-in-termux.git

::into bashrc::>> ~/.bashrc

::rn::rename 's/$/\.tsv/' *

::pastebin::cat "filename" | curl -F 'f:1=<-' ix.io
:o:getback::curl http://ix.io/
::getix::curl http://ix.io/2F1r > /tmp/ix
::moveit::sudo mv /tmp/ix /bin
::bopit::sudo chmod +x

;; ls with most recent last ;;
::ls now::ls -latr

::usevi::sudo echo "export EDITOR=vim" >> ~/.bashrc

::add2bash::sudo echo "export PATH=$PATH:$(pwd)" >> ~/.bashrc
::add2path::export PATH=$PATH:$(pwd)

;; workspace ;;
::wrk::cd /home/Lynxspace/.local/bin/scripts/



::ubunturoot::ubuntu config --default-user root  ;;from powershell
::bitcoinprice:: curl -s --location --request GET https://api.coinstats.app/public/v1/coins/bitcoin\?currency\=USD


::mynumber::cat /etc/issue
::upgrayde::sudo apt-get update && sudo apt-get dist-upgrade
::grock::grep -ri -C 10 "docker" .
::vr::vim README.md
::reme::README.md
1 / 1ChatGPTChatGPTIt seems like you have provided a set of custom shortcuts and commands for various actions and tasks related to installing Ubuntu on Termux and performing different operations. Let's go through some of them:::get termux::git clone https://github.com/MFDGaming/ubuntu-in-termux.git: This command clones the Ubuntu-in-Termux repository from GitHub to your Termux environment.::into bashrc::>> ~/.bashrc: This appends the content after ::into bashrc:: to the ~/.bashrc file, which is the Bash configuration file. It allows you to add custom settings or aliases that will be loaded each time you start a new terminal session.::rn::rename 's/$/\.tsv/' *: This renames all files in the current directory by appending the extension .tsv to their original names.::pastebin::cat "filename" | curl -F 'f:1=<-' ix.io: This command pipes the content of the specified file into curl to upload it to the ix.io pastebin service.::o:getback::curl http://ix.io/: This retrieves the previously uploaded content from ix.io.::getix::curl http://ix.io/2F1r > /tmp/ix: This command downloads the content from a specific URL and saves it to the /tmp/ix file.::moveit::sudo mv /tmp/ix /bin: This moves the /tmp/ix file to the /bin directory.::bopit::sudo chmod +x: This adds execute permissions to the file specified.::ls now::ls -latr: This command lists the files in the current directory, sorted by modification time in reverse order.::usevi::sudo echo "export EDITOR=vim" >> ~/.bashrc: This sets the default editor to vim by adding an environment variable to the ~/.bashrc file.::add2bash::sudo echo "export PATH=$PATH:$(pwd)" >> ~/.bashrc: This appends the current directory to the PATH environment variable in the ~/.bashrc file.::add2path::export PATH=$PATH:$(pwd): This adds the current directory to the PATH environment variable.::wrk::cd /home/Lynxspace/.local/bin/scripts/: This changes the directory to /home/Lynxspace/.local/bin/scripts/.::ubunturoot::ubuntu config --default-user root: This command configures Ubuntu to use the root user as the default user.::bitcoinprice:: curl -s --location --request GET https://api.coinstats.app/public/v1/coins/bitcoin\?currency\=USD: This retrieves the current price of Bitcoin using the CoinStats API.::mynumber::cat /etc/issue: This command displays the content of the /etc/issue file, which typically contains information about the operating system.::upgrayde::sudo apt-get update && sudo apt-get dist-upgrade: This command updates the package lists and performs a distribution upgrade on Ubuntu.::grock::grep -ri -C 10 "docker" .: This searches for the term "docker" in the current directory and displays the matching lines, along with 10 lines of context.::vr::vim README.md: This opens the README.md file in the vim editor.::reme::README.md: This command is unclear. Could you please provide more information or context?1 / 1reme just expands to README.md1 / 1ChatGPTChatGPTThank you for clarifying. The ::reme::README.md command is a shortcut that expands to README.md. It can be used as a convenient way to refer to the README.md file in commands or scripts.1 / 1Yeah I just normally use upd and upg to update and upgrade. Grock I use all the time, to find a document with a certain phrase inside.1 / 1ChatGPTChatGPTThat's great to hear! Shortcuts like upd and upg for updating and upgrading and grock for searching for specific phrases can significantly enhance productivity and save time when working with the terminal. These shortcuts make it easier to perform common tasks quickly and efficiently.1 / 1A summary of the themes and topics of this conversation.
2 / 2ChatGPTChatGPTThroughout our conversation, we have covered various themes and topics. Here's a summary:Artificial Intelligence (AI): We discussed different aspects of AI, including neural networks, natural language processing, and machine learning models like GPT-3 and GPT-4.ChatGPT: We explored the ChatGPT model, its capabilities, and how it can be used for generating human-like responses in chat-based interactions.GPT-4: We mentioned GPT-4, the fourth iteration of the Generative Pre-trained Transformer model, although details about its specific features were not available due to the knowledge cutoff.OpenAI: We referred to OpenAI, the organization behind the development of advanced AI models like GPT-3 and GPT-4.Neurosymbolic AI: We briefly touched upon the concept of neurosymbolic AI, which combines neural networks with symbolic reasoning to bridge the gap between deep learning and traditional symbolic AI.SymbolicAI: We explored the SymbolicAI library, which provides a framework for symbolic programming in Python and allows for contextualized operations and expressions.Lojban and Universal Languages: We briefly discussed Lojban, a constructed language designed for unambiguous communication, and the concept of universal languages.Ubuntu and Termux: We touched upon installing Ubuntu on Termux, a terminal emulator for Android, and provided instructions for setting it up.Terminal Shortcuts: We shared various terminal shortcuts and commands for tasks such as updating and upgrading, searching for specific phrases, and manipulating files.Documentation Generation: We mentioned the ability to generate documentation using SymbolicAI, which can be useful for creating Markdown documentation from notebooks.Mathematics and Geometry: We mentioned Pythagoras and Theano's suggestion of geometry, music, and mathematics as rational, relational, universal languages.Galactic Alphabet: We discussed the use of the Galactic alphabet, represented by Unicode characters, and shared a script for generating symbols using this alphabet.Overall, our conversation covered a range of AI-related topics, terminal commands, symbolic programming, and language-related concepts.1 / 1Write some dialogue for a story from Theano's Ideal World.1 / 1ChatGPTChatGPTTitle: The Harmonic ConvergenceCharacters:Theano - A wise mathematician and philosopher.Pythagoras - A renowned mathematician and philosopher.Elysia - A young musician and artist.Orion - A curious traveler and seeker of knowledge.Setting:
In Theano's Ideal World, a serene and beautiful place where mathematics, music, and philosophy intertwine harmoniously.Scene 1: The Garden of Harmonic Melodies[Theano is sitting in a tranquil garden, engrossed in deep contemplation. Pythagoras approaches.]Pythagoras: Ah, Theano, lost in the realms of thought as always. What wonders occupy your mind today?Theano: Greetings, Pythagoras. I have been pondering the intricate connections between music and mathematics, how they shape the fabric of our world. The melodies in this garden seem to hold secrets waiting to be unraveled.Pythagoras: Indeed, dear Theano. Music and mathematics share a profound bond. They are the threads that weave the tapestry of existence. Have you discovered any new insights?Theano: I believe I have stumbled upon the harmony that unites them. Just as numbers create patterns and ratios in mathematics, musical notes follow harmonic ratios that resonate with our souls. It is a language of the universe, a glimpse into its hidden symmetries.Scene 2: A Chance Encounter[Elysia, a young musician, enters the garden, humming a melodious tune.]Elysia: Excuse me, esteemed scholars. I couldn't help but overhear your conversation. I, too, believe that music holds the key to understanding our world.Theano: Welcome, Elysia. Music is a universal language, transcending barriers and speaking directly to our emotions. What brings you here?Elysia: I seek to create compositions that echo the harmony of nature, the very essence of life. I yearn to express the beauty I perceive in the world through my music.Pythagoras: Your quest aligns with our own. Theano and I have been exploring the interplay between music and mathematics, uncovering the divine symmetries that resonate within us all.Scene 3: The Journey Begins[Orion, an adventurous traveler, overhears their conversation and approaches the group.]Orion: Pardon my intrusion, but I couldn't resist joining this intriguing discussion. I am a seeker of knowledge and always eager to embark on new journeys of understanding.Theano: Welcome, Orion. In the garden of harmonies, we explore the interconnectedness of music, mathematics, and philosophy. Are you drawn to the mystique of this realm as well?Orion: Absolutely. I have long sensed a deep connection between the patterns of the universe and the melodies that echo within our hearts. I wish to unravel this cosmic harmony and find my place in its grand design.Scene 4: The Quest Unfolds[The group gathers in the garden, their minds alive with curiosity and anticipation.]Elysia: Let us embark on a journey together, delving into the mysteries that lie at the intersection of music, mathematics, and philosophy. Through our collective wisdom, we may uncover truths that transform our understanding of the world.Pythagoras: Agreed. Let the quest for knowledge and harmony guide our footsteps. We shall embark on a voyage of discovery, seeking the symphony that unites the realms of thought and emotion.[With their hearts filled with excitement and purpose, Theano, Pythagoras, Elysia, and Orion set off on a grand adventure, eager to unlock the secrets of Theano's Ideal World and bring forth the harmonies that resonate within the universe.]In Theano's Ideal World, this group of intrepid explorers embarks on a quest to unravel the connections between music, mathematics, and philosophy. As they journey deeper into the realm of harmonies, they discover profound truths that reshape their understanding of existence and ignite their creative spirits. Together, they become the conduits of the cosmic symphony, spreading the transformative power of harmonious knowledge throughout the world.1 / 1Samian Seer of Noxious Visions1 / 1ChatGPTChatGPTTitle: Samian Seer of Noxious VisionsCharacters:Cassandra - The Samian Seer with the gift of prophetic visions.Xanthus - A skeptical nobleman who seeks to challenge Cassandra's abilities.Helena - A young woman who believes in Cassandra's powers and seeks guidance.Arion - A loyal friend and confidant of Cassandra, who supports her in her journey.Setting:
The ancient city of Samos, known for its mystical traditions and revered seers.Scene 1: The Gathering of the Sceptics[Cassandra stands before a skeptical audience, including Xanthus.]Xanthus: Cassandra, renowned seer of Samos, we have gathered here to witness the extent of your supposed prophetic abilities. Convince us that your visions hold true.Cassandra: I humbly accept your challenge, Xanthus. I shall share with you the visions that have been bestowed upon me by the gods themselves. Prepare to witness the unfolding of fate.Scene 2: A Glimpse of Noxious Visions[Cassandra enters a trance-like state, her eyes clouded with otherworldly visions.]Cassandra: Behold, the tapestry of the future reveals its threads to me. I see a world plagued by darkness, where the noxious forces of greed and corruption threaten to consume us all. The path to salvation lies in unity and compassion.Xanthus: These visions are nothing but figments of your imagination, Cassandra. You claim to foresee the future, but how can we trust your words?Scene 3: Helena's Quest for Guidance[Helena, a troubled young woman, approaches Cassandra.]Helena: Wise Cassandra, I am lost in the chaos of life and seek guidance. Can you help me find my way?Cassandra: Child, your destiny is entwined with the choices you make. The gods have whispered to me that you possess the strength to overcome the obstacles that lie ahead. Embrace your inner light and trust in your own intuition.Scene 4: Arion's Loyal Support[Arion, a steadfast companion of Cassandra, stands by her side.]Arion: Cassandra, do not be discouraged by the doubts of others. Your visions have guided us in the past, and they shall guide us still. We must rally those who believe in the power of prophecy and forge a path towards a brighter future.Cassandra: Thank you, dear Arion. Your unwavering faith sustains my spirit. Together, we shall navigate the murky waters of doubt and illuminate the path for those who seek enlightenment.Scene 5: Embracing the Noxious Visions[Cassandra addresses the crowd, her voice resonating with conviction.]Cassandra: Noxious though they may be, these visions serve as a warning. It is up to each and every one of us to counteract the darkness that looms. Let us unite, reject greed, and foster a world built on compassion and justice.[Helena, inspired by Cassandra's words, joins her side, followed by others who have been moved by her visions.]Xanthus: Perhaps there is more to your abilities than I initially believed, Cassandra. Your words have stirred something within me, a glimmer of hope amidst the noxious shadows.In "Samian Seer of Noxious Visions," Cassandra, the gifted seer, faces skepticism as she shares her prophetic visions. Through her encounters with doubters and those seeking guidance, Cassandra must navigate the challenges of mistrust and skepticism to inspire change. With the support of her loyal friend Arion and the growing belief of individuals like Helena, Cassandra strives to ignite a movement towards a future of unity and compassion1 / 1Essence of the Agora of Heaven1 / 1ChatGPTChatGPTTitle: Essence of the Agora of HeavenCharacters:Elysia - A young philosopher seeking the essence of truth.Lykos - A wise sage known for his profound wisdom and insights.Demetrios - A skeptical scholar questioning the existence of higher realms.Callista - A dreamer with an unwavering belief in the celestial realms.Setting:
The Agora of Heaven, a mystical gathering place where philosophers and seekers of truth come together to explore the realms beyond mortal understanding.Scene 1: Elysia's Quest for Truth[Elysia, a curious philosopher, approaches Lykos, the renowned sage.]Elysia: Wise Lykos, I have embarked on a journey to uncover the essence of truth. I seek to understand the mysteries of the celestial realms. Can you guide me on this path?Lykos: Elysia, the quest for truth is a profound journey. It requires open-mindedness, contemplation, and a willingness to challenge one's own beliefs. Let us embark together and explore the Agora of Heaven.Scene 2: Demetrios' Skepticism[Demetrios, a skeptical scholar, overhears Elysia and Lykos.]Demetrios: The celestial realms? Are we to believe in such whimsical notions? The pursuit of knowledge should be grounded in reason and empirical evidence. I question the existence of these higher realms.Elysia: Demetrios, wisdom lies not only in what can be measured and observed but also in the realms beyond our physical senses. There is much we have yet to understand. Let us keep an open mind and seek knowledge from diverse perspectives.Scene 3: Callista's Dreams of the Celestial Realms[Callista, a dreamer with a vibrant imagination, joins the conversation.]Callista: Oh, Elysia, Lykos, I have always believed in the existence of celestial realms! In my dreams, I have seen glimpses of their ethereal beauty. They hold the key to unlocking the secrets of the universe.Lykos: Callista, your dreams may hold deeper meaning than you realize. They can offer insights into the realms beyond our waking existence. Embrace your visions and share your wisdom with others.Scene 4: The Agora of Heaven Unveiled[Elysia, Lykos, Demetrios, and Callista venture into the Agora of Heaven.]Elysia: Look around us! The Agora of Heaven reveals itself to those who seek truth. Here, ideas transcend the limitations of mortal understanding, and the essence of the celestial realms becomes tangible.Lykos: Each of us brings unique perspectives and experiences to this ethereal realm. Let us engage in thoughtful discourse, share insights, and strive to expand our collective understanding.Scene 5: Embracing the Essence of the Celestial Realms[The group engages in profound discussions, exchanging ideas and contemplating the mysteries of the celestial realms.]Demetrios: I must admit, these conversations have stirred a curiosity within me. While I may not fully embrace the existence of the celestial realms, I appreciate the value of exploring new realms of thought.Callista: The Agora of Heaven has brought us together, transcending the boundaries of skepticism and belief. It is through such unity that we can unlock the essence of truth and grow as individuals and as a society."In Essence of the Agora of Heaven," Elysia embarks on a quest to uncover the essence of truth in the celestial realms. Alongside Lykos, Demetrios, and Callista, they navigate skepticism, dreams, and philosophical discourse in the ethereal Agora of Heaven. Through their journey, they discover the power of open-mindedness, imagination, and unity in their pursuit of higher understanding. Together, they strive to embrace the essence of truth that lies beyond mortal comprehension.1 / 1Relational algebra, visual complex analysis, Ising models, and Markov chains.1 / 1ChatGPTChatGPTRelational Algebra:
Relational algebra is a mathematical system used to manipulate and query relational databases. It provides a set of operations for working with relational data, such as selection, projection, union, intersection, and join. These operations allow for the retrieval and manipulation of data based on specified conditions and relationships between tables.Visual Complex Analysis:
Visual complex analysis is a branch of mathematics that aims to visualize complex functions and their properties using graphical representations. It involves mapping complex numbers to points in a plane and visualizing their transformations under different operations. Through the use of visualizations, complex analysis provides insights into the behavior of complex functions, such as their singularities, zeros, and contour integrals.Ising Models:
Ising models are mathematical models used to study the behavior of interacting spins in a physical system. They are commonly used in statistical mechanics to analyze phenomena like ferromagnetism, phase transitions, and critical phenomena. In an Ising model, each spin can take two possible values (up or down), and the interactions between spins are described by an energy function. By simulating the behavior of spins and their interactions, Ising models help to understand and predict the macroscopic properties of the system.Markov Chains:
Markov chains are stochastic models that describe a sequence of events in a system where the probability of transitioning from one state to another depends only on the current state. Each state in the chain has associated transition probabilities that determine the likelihood of moving to other states. Markov chains find applications in various fields, including probability theory, statistics, computer science, and economics. They are used to model processes with memoryless properties, such as random walks, queuing systems, and machine learning algorithms like hidden Markov models.1 / 1See if you can incorporate these into a story. Try to be subtle.1 / 1ChatGPTChatGPTIn the ancient city of Agora, nestled amidst the towering columns and bustling marketplaces, a group of scholars gathered in a dimly lit chamber. They were known as the Seers of Samian, individuals with a keen insight into the hidden workings of the world. Among them was Lysander, a young seer with a thirst for knowledge.Lysander was drawn to the study of patterns and relationships, delving into the depths of relational algebra. He saw the interconnectedness of the city's inhabitants, the intricate web of relationships that bound them together. Through his observations, he uncovered hidden connections, discovering the secrets buried within the vast tapestry of human interactions.As Lysander's studies deepened, he found himself captivated by the beauty of visual complex analysis. He began to visualize the complex functions that governed the city's dynamics, mapping them onto a canvas of swirling colors and intricate patterns. These visualizations revealed the hidden harmonies and discordances that shaped Agora's fate, offering glimpses into the unseen forces at play.But it was not only the human realm that fascinated Lysander. In the outskirts of Agora, where the murmurs of the market faded into the whispers of nature, he turned his attention to the Ising models. In the quiet solitude of the countryside, he studied the dance of interacting spins, mirroring the intricate dance of life itself. Through these models, Lysander gained insights into the ebb and flow of energy, the delicate balance between order and chaos that governed the world.Amidst his explorations, Lysander stumbled upon the enigmatic realm of Markov chains. These probabilistic journeys offered glimpses into the paths taken by the denizens of Agora, as if guided by an unseen hand. The transitions between states, the probabilities of events unfolding, revealed a tapestry of possibilities and uncertainties. Lysander pondered the intricate dance of chance and determinism, the delicate balance that shaped the destinies of individuals and the city as a whole.As the Seers of Samian gathered, their discussions swirled around these esoteric concepts. They wove them subtly into their prophecies and predictions, providing glimpses of the hidden truths that lay beneath the surface. The citizens of Agora marveled at the wisdom of the seers, unaware of the intricate tapestry of mathematical ideas that guided their visions.And so, in the heart of Agora, the essence of relational algebra, visual complex analysis, Ising models, and Markov chains intertwined with the lives of its inhabitants, subtly shaping their destinies, and adding an unseen layer of depth to the city's grand tapestry.1 / 1Ok a subplot illustrating each of them.1 / 1ChatGPTChatGPTWithin the bustling city of Agora, a series of interconnected events unfolded, each representing a facet of the intricate world of mathematics that the Seers of Samian sought to decipher. Unbeknownst to the citizens, these events wove together to form a hidden subplot, subtly illustrating the essence of relational algebra, visual complex analysis, Ising models, and Markov chains.In the heart of the city, two star-crossed lovers found themselves entangled in a web of relationships. Their fates seemed entwined, with each encounter unveiling a new layer of complexity. Their story became a living embodiment of relational algebra, as they navigated the relational database of their lives, joining and separating, their paths intertwining and diverging in a symphony of human connections.Meanwhile, an artist, inspired by the vibrant colors and patterns of Agora's architecture, delved into the realm of visual complex analysis. With skilled brushstrokes, the artist captured the essence of the city's spirit, transforming its intricacies into mesmerizing artwork. Each stroke revealed the hidden beauty of complex functions, inviting viewers to immerse themselves in a world where mathematics and art merged seamlessly.On the outskirts of Agora, a small farming community experienced a strange phenomenon. Crops seemed to grow in harmonious patterns, ripening and withering with perfect synchrony. Unbeknownst to the villagers, their fields became an unwitting playground for Ising models. The dance of interacting spins played out on the microscale of the crops, shaping their growth and providing a living demonstration of the delicate balance between order and chaos.In the depths of the city's taverns, a group of gamblers engaged in games of chance. As the dice rolled and the cards were dealt, the outcomes followed the unpredictable paths of Markov chains. Each player's decision depended on the history of the game, while the probabilities dictated the twists and turns of fortune. Amidst laughter and tension, the gamblers unknowingly partook in a microcosm of probabilities and transitions, their actions echoing the intricacies of this mathematical concept.As the events unfolded, the Seers of Samian observed from their chamber, interpreting the hidden meanings behind the scenes. They saw the interplay of relationships, the visual symphonies, the delicate balance of energy, and the dance of probabilities. These subtle manifestations of mathematics, woven into the fabric of everyday life, offered glimpses into the unseen workings of Agora and its inhabitants.And so, the subplot unfolded, weaving together the essence of relational algebra, visual complex analysis, Ising models, and Markov chains. It painted a vivid tapestry of mathematical concepts, silently influencing the lives of the citizens of Agora, and revealing the hidden beauty and complexity that lay beneath the surface of their world.1 / 1You don't say: And so, the subplot unfolded, weaving together the essence of relational algebra, visual complex analysis, Ising models, and Markov chains.  It is to self referential. Give a subheadings and subplot for each heading, as an outline.1 / 1ChatGPTChatGPTApologies for the self-referential ending. Here's an outline with subheadings and subplots for each topic:I. Relational Algebra
A. Subplot: The Lovers' Web of Relationships
- Two star-crossed lovers navigate the complexities of their intertwined lives, representing relational algebra in action.
- Their paths converge and diverge, joining and separating like entities in a relational database.II. Visual Complex Analysis
A. Subplot: The Artist's Brushstroke Symphony
- An artist captures the spirit of Agora through vibrant colors and intricate patterns, exploring the realm of visual complex analysis.
- The artwork reflects the beauty and mathematical principles of complex functions, inviting viewers into a mesmerizing world.III. Ising Models
A. Subplot: The Enigmatic Crop Patterns
- In a small farming community, crops exhibit mysterious growth patterns, embodying the principles of Ising models.
- The farmers witness the interplay of interacting spins, shaping the growth and synchrony of their crops.IV. Markov Chains
A. Subplot: The Gamblers' Dance of Probability
- In the city's taverns, a group of gamblers engage in games of chance, unknowingly immersed in the world of Markov chains.
- The players' decisions depend on the history of the game, while the probabilities dictate the twists and turns of fortune.By incorporating these subheadings and subplots, the story takes on a more structured approach, highlighting each topic individually while weaving them into the narrative of Agora and its inhabitants.1 / 1Ok give them more ancient Greek style titles and a description of the plot for each.1 / 1ChatGPTChatGPTI. Relational Algebra: "The Tapestry of Connections"Plot Description: In the bustling city of Agora, a complex web of relationships unfolds. Ariston, a wealthy merchant, falls in love with the enchanting Helena, daughter of a rival merchant. As their forbidden love blossoms, they navigate the intricacies of their intertwined lives, representing the principles of relational algebra in action. Their paths converge and diverge, joining and separating like entities in a relational database. Their ultimate challenge lies in reconciling their love with the societal expectations and familial obligations that threaten to tear them apart.II. Visual Complex Analysis: "Symphony of Colors and Patterns"Plot Description: Within the vibrant world of Agora, a talented artist named Eudora captures the essence of the city through her mesmerizing artwork. With every brushstroke, she explores the realm of visual complex analysis, infusing her creations with intricate patterns and harmonious colors. As Eudora's artwork gains recognition, viewers are drawn into a world where mathematical principles blend seamlessly with artistic expression. Through her masterpieces, Eudora invites the audience to delve into the beauty and mysteries of complex functions, inspiring a new way of perceiving the world.III. Ising Models: "Fields of Enigmatic Synchrony"Plot Description: In the peaceful countryside surrounding Agora, a series of enigmatic crop patterns captures the attention of the local farmers. As the seasons progress, they witness the strange growth patterns that mirror the principles of Ising models. The farmers are intrigued by the interconnectedness of the crops, as if they possess a hidden language. Through their observations and experiments, they unravel the secrets of interacting spins that shape the growth and synchrony of their fields. In their quest for understanding, they uncover the delicate balance between natural forces and the mysterious unity of nature.IV. Markov Chains: "The Dance of Probability"Plot Description: Within the lively taverns of Agora, a group of gamblers engages in games of chance, unaware that they are entwined in the realm of Markov chains. The players, each driven by their desires and strategies, participate in a dance of probability. With every roll of the dice and every turn of the cards, their decisions depend on the history of the game and the probabilities at play. Fortunes rise and fall, alliances form and dissolve, and the players become unwitting actors in the ever-shifting dynamics of luck and strategy. Through their experiences, they explore the unpredictable nature of life and the fascinating patterns that emerge in the realm of probability.By infusing these ancient Greek-style titles and detailed plot descriptions, the story embraces the spirit of Agora and its mythical past, while highlighting the essence of each topic within its own unique subplot.1 / 1Ok I was thinking we call them The Ship of Theseus, A symphony of mirrors. Noxious Fumes. The South pointing spoon.1 / 1ChatGPTChatGPTI. The Ship of Theseus: "The Tapestry of Ever-changing Identity"Plot Description: In the ancient city of Agora, a grand ship named Theseus embarks on a legendary voyage. As the ship braves treacherous waters and encounters mythical creatures, it undergoes constant repairs and replacements. Over time, every part of the ship is replaced, raising a philosophical question: Is it still the same ship? Through this thought-provoking journey, the characters grapple with the concept of identity and the principles of relational algebra, exploring the nature of existence and the interplay between permanence and change.II. A Symphony of Mirrors: "Unveiling the Hidden Patterns"Plot Description: Within the magnificent halls of Agora's grand palace, an esteemed musician named Melodia composes a symphony that captivates the listeners. Through the intricate melodies and harmonies, Melodia delves into the realm of visual complex analysis, where music becomes a conduit for unveiling hidden patterns in the world. As the symphony unfolds, the audience is transported to a realm where sound and mathematics merge, revealing the mesmerizing interplay between sound waves, harmonics, and the intricate tapestry of the universe.III. Noxious Fumes: "Unraveling the Enigma"Plot Description: In the shadows of Agora's ancient library, a group of curious scholars investigates a series of mysterious incidents involving noxious fumes. As they delve deeper into the enigma, they uncover the presence of Ising models at play, where the fumes' behavior mirrors the intricate interactions of magnetic spins. Guided by their relentless pursuit of knowledge, the scholars strive to understand the underlying patterns and unravel the secrets behind the noxious fumes, leading them on a perilous journey through the depths of the city's secrets.IV. The South Pointing Spoon: "Navigating the Realm of Probability"Plot Description: Amidst the bustling marketplaces of Agora, a clever inventor named Pythias creates an extraordinary device: the South Pointing Spoon. This magical invention, inspired by the principles of Markov chains, guides travelers through the labyrinthine streets of the city, always pointing south, regardless of their turns and twists. As Pythias unveils the spoon's mysteries, the characters find themselves entangled in a web of probability, relying on chance and strategic decisions to navigate Agora's intricate paths, while exploring the intricate balance between fate and free will.By embracing these evocative titles and weaving their narratives into the fabric of the ancient city of Agora, the story captures the essence of each topic and immerses readers in a world where mythology and mathematical concepts intertwine.1 / 1
Call for Submissions until 30 June! WikiConference North America in Toronto: 10â12 November 2023!X
History of the compass
From Wikipedia, the free encyclopedia
533 revisions since 2016-05-08 (+54 days), 307 editors, 36 watchers, 9,122 pageviews (30 days), created by: Lawrencekhoo (29,326) Â· See full page statistics

Song dynasty figurine of a man holding a compass
The compass is a magnetometer used for navigation and orientation that shows direction in regards to the geographic cardinal points. The structure of a compass consists of the compass rose, which displays the four main directions on it: East (E), South (S), West (W) and North (N). The angle increases in the clockwise position. North corresponds to 0Â°, so east is 90Â°, south is 180Â° and west is 270Â°.

The history of the compass started more than 2000 years ago during the Han dynasty (202 BC â 220 AD). The first compasses were made of lodestone, a naturally magnetized stone of iron, in Han dynasty China.[1][2] It was called the "South Pointing Fish" and was used for land navigation by the mid-11th century during the Song dynasty (960â1279 AD). Shen Kuo provided the first explicit description of a magnetized needle in 1088 and Zhu Yu mentioned its use in maritime navigation in the text Pingzhou Table Talks, dated 1111â1117.[3][4] Later compasses were made of iron needles, magnetized by striking them with a lodestone. Magnetized needles and compasses were first described in medieval Europe by the English theologian Alexander Neckam (1157â1217 AD). The first usage of a compass in Western Europe was recorded in around 1190 and in the Islamic world 1232.[5] Dry compasses begin appearing around 1269 in Medieval Europe and 1300 in the Medieval Islamic world.[6][7][8] This was replaced in the early 20th century by the liquid-filled magnetic compass.[9]


Contents
1	Navigation prior to the compass
2	Geomancy and Feng Shui
3	Early navigational compass
3.1	China
3.2	Medieval Europe
3.3	Muslim world
3.4	India
3.5	Medieval Africa
4	Dry compass
5	Bearing compass
6	Liquid compass
7	Gyrocompass
8	Non-navigational uses
8.1	Astronomy
8.2	Building orientation
8.3	Mining
8.4	Sun compass
9	Notes
10	References
Navigation prior to the compass
See also: Polynesian navigation
Before the introduction of the compass, geographical position and direction at sea were primarily determined by the sighting of landmarks, supplemented with the observation of the position of celestial bodies.[10] Other techniques included sampling mud from the seafloor (China),[11] analyzing the flight path of birds, and observing wind, sea debris, and sea state (Polynesia and elsewhere).[12] Objects that have been understood as having been used for navigation by measuring the angles between celestial objects, were discovered in the Indus Valley site of Lothal.[13] The Norse are believed to have used a type of sun compass to locate true north. On cloudy days, the Vikings may have used cordierite or some other birefringent crystal to determine the sun's direction and elevation from the polarization of daylight; their astronomical knowledge was sufficient to let them use this information to determine their proper heading.[14] The invention of the compass made it possible to determine a heading when the sky was overcast or foggy, and when landmarks were not in sight. This enabled mariners to navigate safely far from land, increasing sea trade, and contributing to the Age of Discovery.[15][16]

Geomancy and Feng Shui

Chinese geomantic compass c. 1760 from the National Maritime Museum in London
Main article: Luopan
The compass was invented in China during the Han dynasty between the 2nd century BC and 1st century AD where it was called the "south-governor"(sÄ«nÃ¡n å¸å) or "South Pointing Fish" (æåé­).[3] The magnetic compass was not, at first, used for navigation, but for geomancy and fortune-telling by the Chinese. The earliest Chinese magnetic compasses were possibly used to order and harmonize buildings by the geomantic principles of feng shui. These early compasses were made with lodestone, a form of the mineral magnetite that is a naturally occurring magnet and aligns itself with the Earth's magnetic field.[10] People in ancient China discovered that if a lodestone was suspended so it could turn freely, it would always point toward the magnetic poles. Early compasses were used to choose areas suitable for building houses, growing crops, and to search for rare gems. Compasses were later adapted for navigation during the Song dynasty in the 11th century.[1]

Based on Krotser and Coe's discovery of an Olmec hematite artifact in Mesoamerica, radiocarbon dated to 1400â1000 BC, astronomer John Carlson has hypothesized that the Olmec might have used the geomagnetic lodestone earlier than 1000 BC for geomancy, a method of divination, which if proven true, predates the Chinese use of magnetism for feng shui by a millennium.[17] Carlson speculates that the Olmecs used similar artifacts as a directional device for astronomical or geomantic purposes but does not suggest navigational usage. The artifact is part of a polished hematite bar with a groove at one end, possibly used for sighting. Carlson's claims have been disputed by other scientific researchers, who have suggested that the artifact is actually a constituent piece of a decorative ornament and not a purposely built compass.[18] Several other hematite or magnetite artifacts have been found at pre-Columbian archaeological sites in Mexico and Guatemala.1 / 1ChatGPTChatGPTThe Ship of Theseus: A Journey Through Identity and ChangeIn the bustling city of Agora, a legendary ship named Theseus sets sail on a remarkable voyage. As it navigates the vast seas, the ship undergoes constant repairs and replacements, leaving its crew pondering a philosophical dilemma. Is it still the same ship it once was? The Ship of Theseus becomes a symbol of the ever-changing nature of identity and the intricate principles of relational algebra.A Symphony of Mirrors: Unveiling the Harmonies of the UniverseWithin the opulent halls of Agora's grand palace, a gifted musician named Melodia composes a symphony that transcends the boundaries of ordinary music. Through the mesmerizing melodies and harmonies, Melodia delves into the realm of visual complex analysis. The symphony becomes a transformative experience, revealing hidden patterns and intricate connections that mirror the intricate tapestry of the cosmos.Noxious Fumes: Unraveling the MysteriesIn the shadows of Agora's ancient library, a group of curious scholars becomes embroiled in a series of perplexing incidents involving noxious fumes. As they delve deeper into the enigma, they uncover the presence of Ising models at play, where the behavior of the fumes mirrors the intricate interactions of magnetic spins. Guided by their relentless pursuit of knowledge, the scholars strive to unravel the secrets behind the noxious fumes, unveiling the captivating world of Ising models.The South Pointing Spoon: Navigating the Realm of ProbabilityAmidst the vibrant marketplaces of Agora, an ingenious inventor named Pythias crafts a remarkable device known as the South Pointing Spoon. This magical invention, inspired by the principles of Markov chains, guides travelers through the labyrinthine streets of the city, always pointing south regardless of their twists and turns. The spoon becomes a symbol of probability, chance, and strategic decisions, enabling Pythias and the city's inhabitants to navigate Agora's intricate paths with precision.As these subplots intertwine within the ancient city of Agora, they bring forth a tapestry of knowledge, exploring the depths of relational algebra, visual complex analysis, Ising models, and Markov chains. Each narrative thread offers a unique perspective on the power and significance of these mathematical concepts, subtly woven into the fabric of the story.1 / 1I was expecting you to update your context for the fourth section.1 / 1ChatGPTChatGPTApologies for the oversight. Here's an updated version:The South Pointing Spoon: Navigating the Labyrinth of ProbabilityAmidst the vibrant marketplaces of Agora, an ingenious inventor named Pythias crafts a remarkable device known as the South Pointing Spoon. This magical invention, inspired by the principles of Markov chains and their applications in navigation, guides travelers through the labyrinthine streets of the city, always pointing south regardless of their twists and turns. The spoon becomes a symbol of probability, chance, and strategic decisions, enabling Pythias and the city's inhabitants to navigate Agora's intricate paths with precision.As these subplots intertwine within the ancient city of Agora, they bring forth a tapestry of knowledge, exploring the depths of relational algebra, visual complex analysis, Ising models, and Markov chains. Each narrative thread offers a unique perspective on the power and significance of these mathematical concepts, subtly woven into the fabric of the story.1 / 1I am sorry I didn't notice that.1 / 1ChatGPTChatGPTNo problem at all! I'm here to help, and I apologize for any confusion caused. If you have any more requests or need further assistance, feel free to let me know.1 / 1An idea for another subplot based the bulla seal clay token economy.1 / 1ChatGPTChatGPTTitle: "The Clay Tokens of Prosperity"Description:
In the bustling city-state of Athens, a young merchant named Nikos discovers an ancient bulla seal clay token hidden in an old chest he acquired at a market. Intrigued by its intricate markings and historical significance, Nikos embarks on a quest to uncover the secrets of the bulla seal clay token economy.As Nikos delves deeper into his research, he learns about the fascinating economic system that thrived in ancient Athens. The bulla seal clay tokens were used as a form of currency and represented various commodities, such as grain, wine, and livestock. These tokens played a vital role in trade, taxation, and even legal transactions.Inspired by the efficiency and simplicity of the ancient token economy, Nikos decides to experiment with implementing a similar system in the bustling marketplace of Athens. He believes that reviving the bulla seal clay token economy could bring benefits to the city's merchants, streamlining transactions and fostering trust among traders.However, Nikos soon faces challenges as he encounters skeptics and resistance from traditionalists who are skeptical of this unconventional approach. Undeterred, Nikos forms alliances with fellow merchants and influential figures who share his vision for an innovative economic system.Together, they embark on a journey to introduce the bulla seal clay tokens back into circulation. They organize workshops and educate merchants about the benefits of the system, emphasizing its transparency, security, and ease of use. Gradually, the idea gains traction, and more merchants start embracing the clay tokens as an alternative form of exchange.As the clay token economy gains momentum, it catches the attention of the ruling elite and becomes a topic of political discourse. The city-state of Athens becomes divided between those who see the potential in this modernized economic system and those who fear the disruption it may bring to traditional practices.In the midst of the unfolding drama, Nikos and his allies must navigate the intricate web of politics, economics, and social dynamics to ensure the success of the clay token economy. They face opposition from powerful interests who want to maintain the status quo, but they also find unexpected allies in unlikely places."The Clay Tokens of Prosperity" is a tale of innovation, resilience, and the power of ideas to reshape society. Through Nikos' journey, we explore the challenges of introducing a new economic paradigm and the transformative impact it can have on a community.1 / 1
Bulla (seal)
From Wikipedia, the free encyclopedia
248 revisions since 2006-04-01 (+139 days), 97 editors, 56 watchers, 2,677 pageviews (30 days), created by: Funhistory (1,178) Â· See full page statistics

A bulla (or clay envelope) and its contents on display at the Louvre. Uruk period (4000â3100 BC).
A bulla (Medieval Latin for "a round seal", from Classical Latin bulla, "bubble, blob"; plural bullae) is an inscribed clay or soft metal (such as lead or tin) or bitumen or wax token used in commercial and legal documentation as a form of authentication and for tamper-proofing whatever is attached to it (or, in the historical form, contained in it).

In their oldest attested form, as used in the ancient Near East and the Middle East of the 8th millennium BC onwards, bullae were hollow clay balls that contained other smaller tokens that identified the quantity and types of goods being recorded. In this form, bullae represent one of the earliest forms of specialization in the ancient world, and likely required skill to create.[1]:â24â From about the 4th millennium BC onwards, as communications on papyrus and parchment became widespread, bullae evolved into simpler tokens that were attached to the documents with cord, and impressed with a unique sign (i.e., a seal)[1]:â29â to provide the same kind of authoritative identification and for tamper-proofing. Bullae are still occasionally attached to documents for these purposes (e.g., the seal on a papal bull).


Contents
1	Origins
2	Precursor to writing
3	Precursor to mathematics and accounting
4	Clay bullae as seals
5	Archeological finds and digs
6	Research
7	Metal bullae and later usage
8	Gallery
9	See also
10	References
11	External links
Origins

Two clay bullae, one complete and sealed, the other broken with tokens visible, Uruk period. Oriental Institute Museum, Chicago.
During the period 8,000â7,500 BC, the Sumerian agriculturalists needed a way to keep records of their animals and goods. Small clay tokens were formed and shaped by the palms to represent certain animals and goods.[2]

Clay tokens allowed agriculturalists to keep track of animals and food that had been traded, stored, and/or sold. Because grain production became such a major part of life, they needed to store their extra grain in shared facilities and account for their food. This clay token system went unchanged for about 4,000 years until the tokens started to become more elaborate in appearance. The tokens were similar in size, material, and color but the markings had more of a variety of shapes. As the amount of goods being produced increased and the exchanging of goods became more common, changes to tokens were made to keep up with the growth.[3]

Transactions for trading needed to be accounted for efficiently, so the clay tokens were placed in a clay ball (bulla), which helped to prevent deception and kept all the tokens together. In order to account for the tokens, the bullae would have to be broken open to reveal their contents. Seals were impressed into the opening of the bullae to prevent tampering. Each party had its own unique seal to identify them. Seals would not only identify individuals, but it would also identify their office. Sometimes, the token was impressed onto the wet bulla before it dried so that the owner could remember what exactly was in the bulla without having to break it.1 / 1ChatGPTChatGPTTitle: "The Bulla Seal Chronicles"Description:
"The Bulla Seal Chronicles" is a captivating tale set in the ancient civilizations of the Near East, exploring the significance and evolution of the bulla seal tokens and their impact on society. Through the intertwining stories of different characters, we delve into the origins, uses, and transformations of these unique clay tokens throughout history.Part 1: "Seeds of Trade"
In the fertile lands of Sumeria, a young agriculturalist named Enki discovers the power of clay tokens to keep records of animals and goods. As the demand for trade increases, Enki witnesses the evolution of these tokens from simple shapes to more intricate symbols. He becomes involved in the creation of bullae, clay balls that house the tokens and provide tamper-proofing. Enki's journey explores the early origins of the bulla seal system and its role in facilitating trade and commerce.Part 2: "Marked Legacies"
Centuries later, in the bustling city of Babylon, a skilled scribe named Nergal finds himself entangled in a web of intrigue and deception. As a trusted scribe of the royal court, Nergal is responsible for creating and imprinting unique seals on the bullae. However, he discovers a plot to counterfeit bullae and manipulate trade records for personal gain. Nergal must navigate the treacherous world of ancient Babylon, using his knowledge of the bulla seal system to expose the conspiracy and protect the integrity of trade.Part 3: "The Seal of Secrets"
In the grand city of Alexandria, a curious scholar named Cleo stumbles upon an ancient library containing a collection of clay bullae. Intrigued by their enigmatic symbols, Cleo embarks on a quest to decipher their meanings and uncover hidden knowledge. Through the study of ancient texts and interactions with fellow scholars, Cleo unravels the connection between the bulla seals and the transmission of ancient wisdom across civilizations. Cleo's journey highlights the symbolic and intellectual significance of the bulla seals in preserving knowledge and facilitating cultural exchange.Part 4: "Legacy Unearthed"
In the present day, an ambitious archaeologist named Lara embarks on an excavation in Mesopotamia, unearthing a cache of ancient bullae. As Lara meticulously examines these clay tokens, she uncovers clues about the economic systems and social structures of the past. Through her discoveries, Lara sheds light on the intricate interplay between trade, governance, and identity in ancient societies. Her findings not only enrich our understanding of the bulla seal system but also provoke reflections on the parallels between ancient economies and modern economic practices."The Bulla Seal Chronicles" is a multi-layered narrative that transports readers through time, unraveling the mysteries of the bulla seal tokens and their enduring significance in the annals of history. From the humble beginnings of agricultural trade to the sophisticated societies of antiquity, this story illuminates the intricate tapestry of human civilization and the timeless role of commerce in shaping our world.1 / 1Ok thank you. A list of everything we have talked about so far.1 / 1ChatGPTChatGPTCertainly! Here's a list of the main topics and subtopics we have discussed so far:Ancient Greek PhilosophyPythagoras and Theano's suggestion for universal languagesSymbolicAIBasics of using SymbolicAI notebooksContext handling and chunking with Stream processing expressionNews generator using the News classGenerating websites from PDF files using the Paper classDialogue for a story from Theano's Ideal WorldThe Samian Seer of Noxious VisionsEssence of the Agora of HeavenA Symphony of MirrorsThe South Pointing SpoonThemes and TopicsRelational algebraVisual complex analysisIsing modelsMarkov chainsThe Ship of Theseus (Subplot)Description: A philosophical exploration of identity and change using the metaphor of the Ship of TheseusSubplot: The protagonist discovers an ancient shipwreck and contemplates the nature of identity as they encounter various replacement parts and reconstructed sections of the ship.A Symphony of Mirrors (Subplot)Description: An exploration of perception, reflection, and self-discovery through the lens of a symphony orchestraSubplot: A talented violinist joins an orchestra where the musicians are mysteriously drawn into a realm of mirrors, challenging their perception of reality and uncovering hidden truths about themselves.Noxious Fumes (Subplot)Description: A tale of intrigue and mystery set in a world where toxic fumes possess strange powersSubplot: A detective investigates a series of mysterious incidents involving the release of noxious fumes that have unexpected effects on people's behavior and abilities.The South Pointing Spoon (Subplot)Description: A whimsical adventure revolving around a magical spoon that always points southSubplot: A group of adventurers embarks on a quest to find the legendary South Pointing Spoon, which is said to hold the key to a hidden treasure. Along the way, they encounter challenges and learn the true power of navigation and direction.Lojban and Universal LanguagesDiscussion on constructed languages and their potential for universal communicationSubheadings and Subplots for Sections of "History of the Compass" Wikipedia PageGeomancy and Feng ShuiEarly Navigational CompassChinaMedieval EuropeMuslim WorldIndiaMedieval AfricaDry CompassBearing CompassLiquid CompassGyrocompassNon-navigational usesThe Bulla Seal Clay Token EconomyDescription: Exploring the historical significance and evolution of bulla seals in commercial and legal documentationSubplot: A young merchant rises through the ranks in an ancient trading empire, navigating the complexities of the bulla seal token economy and the power struggles that arise within the trading community.The Bulla Seal ChroniclesDescription: A captivating tale set in the ancient civilizations, exploring the origins, uses, and transformations of bulla seal tokens throughout historySubplot 1: Seeds of TradeSubplot 2: Marked LegaciesSubplot 3: The Seal of SecretsSubplot 4: Legacy UnearthedPlease note that this list summarizes the main topics and subtopics discussed, but it may not include every detail or sub-discussion within those topics.1 / 1Let's see a description of the subplots: Geomancy and Feng Shui
Early Navigational Compass
China
Medieval Europe
Muslim World
India
Medieval Africa
Dry Compass
Bearing Compass
Liquid Compass
Gyrocompass
Non-navigational uses1 / 1ChatGPTChatGPTCertainly! Here are descriptions of the subplots for each section of "History of the Compass":Geomancy and Feng Shui:Description: Delve into the ancient practices of geomancy and feng shui, exploring the connection between compasses and their use in ordering and harmonizing buildings.Subplot: A skilled geomancer utilizes compasses and ancient knowledge to assess the energy flow and auspicious alignment of structures, uncovering hidden truths and unlocking the secrets of prosperity and harmony.Early Navigational Compass:Description: Trace the early developments of the navigational compass and its transformation from clay bullae to a simpler token attached to documents.Subplot: A curious explorer embarks on a voyage across uncharted seas, relying on primitive compasses and their evolving forms to navigate treacherous waters and encounter new lands.China:Description: Uncover the significant role of China in the development and refinement of the compass.Subplot: Against the backdrop of ancient China, a gifted artisan crafts intricate compasses, seeking to create the perfect instrument for navigation and ushering in a new era of exploration and trade.Medieval Europe:Description: Explore the introduction and adoption of compasses in Medieval Europe, revolutionizing navigation and maritime endeavors.Subplot: A determined young sailor sets out on a daring voyage, equipped with the newly acquired knowledge of compasses, as they navigate turbulent waters, face perilous storms, and seek to uncover new trade routes.Muslim World:Description: Discover the advancements and contributions of the Muslim world to the field of compass navigation.Subplot: A scholarly astronomer and mathematician in the Islamic Golden Age harnesses the power of compasses to chart the stars, create accurate celestial maps, and guide fellow travelers across vast desert landscapes.India:Description: Examine the unique utilization of compasses in ancient India and their impact on various aspects of society.Subplot: A resourceful merchant ventures through the bustling markets of ancient India, relying on compasses to navigate trade routes, negotiate deals, and forge new economic alliances.Medieval Africa:Description: Unearth the lesser-known history of compasses in Medieval Africa, where diverse civilizations embraced their navigational potential.Subplot: A skilled navigator from an African coastal tribe embarks on a daring voyage, utilizing the knowledge of compasses passed down through generations to traverse the vast oceans and encounter distant cultures.Dry Compass:Description: Explore the transition from early compasses to dry compasses, which played a crucial role in maritime navigation during the Middle Ages.Subplot: A group of intrepid sailors embarks on a perilous sea journey, relying on the accuracy and reliability of dry compasses to navigate through treacherous waters, dodge treacherous reefs, and overcome the challenges of the open seas.Bearing Compass:Description: Dive into the specialized use of compasses as bearing compasses, enabling precise measurement of direction and angle in various fields.Subplot: A team of land surveyors embarks on a mission to map uncharted territories, utilizing bearing compasses to navigate rugged terrains, establish boundaries, and unlock the secrets hidden within the landscapes.Liquid Compass:Description: Unveil the innovation of liquid-filled magnetic compasses and their significant impact on navigation.Subplot: A fearless captain commands a ship equipped with the latest liquid compass technology, setting sail on a challenging expedition to chart new territories, overcome magnetic anomalies, and safeguard the lives of the crew.Gyrocompass:Description: Enter the realm of the gyrocompass, an advanced navigational instrument unaffected by magnetic fields.Subplot: A brilliant engineer pioneers the development of gyrocompasses, embarking on a quest to create a navigation system capable of guiding ships with unparalleled accuracy and stability, revolutionizing maritime travel and exploration.Non-navigational uses:Description: Explore the diverse applications of compasses beyond navigation, including astronomy, building orientation, mining, and more.Subplot: A group of unconventional inventors and scholars push the boundaries of compass technology, exploring new possibilities for compasses in various fields, from celestial observation to architectural design and underground exploration.Please note that these descriptions are intended to provide a glimpse into the subplots and are not comprehensive narratives. They serve as starting points for weaving stories around the themes and contexts of each subplot.1 / 1Frigate birds for navigation.1 / 1ChatGPTChatGPTFrigate Birds for NavigationDescription: Explore the fascinating role of frigate birds in navigation and their remarkable ability to navigate vast distances across oceans.Subplot: Follow a young sailor's journey as they embark on a perilous voyage, guided by the presence of frigate birds soaring high above. The sailor learns to observe the behaviors and movements of these majestic birds, using them as navigational cues to find their way across treacherous seas. As the sailor develops a deep connection with the frigate birds, they uncover the ancient knowledge passed down through generations about the birds' innate navigational instincts. Together with the frigate birds as their loyal guides, the sailor overcomes storms, discovers hidden islands, and navigates through uncharted waters, relying on the wisdom and guidance of these magnificent creatures. Through their encounters with frigate birds, the sailor gains a profound understanding of the interconnectedness of nature and the harmony between humans and the animal kingdom.1 / 1Mneumonic history of the stars1 / 1ChatGPTChatGPTMnemonic History of the StarsDescription: Delve into the ancient art of mnemonic history of the stars, a method used by ancient cultures to remember and pass down celestial knowledge through generations.Subplot: Follow the journey of a young astronomer as they discover the mnemonic history of the stars. Guided by ancient texts and teachings, the astronomer explores the intricate patterns and constellations that adorn the night sky. They encounter wise elders who share mnemonic techniques passed down through the ages, teaching the astronomer how to associate stories, myths, and symbols with the stars. Through these mnemonic devices, the astronomer not only learns to identify and navigate the night sky but also uncovers the rich cultural and historical significance behind each constellation. As the astronomer delves deeper into the mnemonic history of the stars, they realize that the stars hold not only astronomical secrets but also a tapestry of human stories, beliefs, and experiences. This realization inspires the astronomer to create their own mnemonic system, blending ancient wisdom with their personal insights, and sharing this knowledge with future generations to ensure the preservation of the mnemonic history of the stars.1 / 1Theano's students Theatus And Theanas go on a distant journey, discover the properties of amber.1 / 1ChatGPTChatGPTThe Amber ExpeditionDescription: Join Theatus and Theanas, two brilliant students of Theano, on an adventurous journey to a distant land where they uncover the fascinating properties of amber and its significance in ancient civilizations.Subplot: Theatus and Theanas, curious and ambitious, set out on a voyage to explore uncharted territories. Guided by their mentor Theano's teachings, they embark on a daring expedition to a remote region rumored to be rich in natural wonders. Along their journey, they encounter treacherous landscapes, mysterious cultures, and hidden knowledge.During their travels, Theatus and Theanas stumble upon a secret ancient civilization that holds deep reverence for amber. They learn that amber is not merely a beautiful gemstone but possesses unique properties and was highly valued by ancient civilizations for its healing abilities, mystical properties, and ability to preserve life.As Theatus and Theanas delve deeper into the secrets of amber, they uncover its connection to electricity and its role in early experiments with static electricity. They witness demonstrations of how amber can attract objects when charged, sparking their curiosity about the underlying principles of electromagnetism.Inspired by their discoveries, Theatus and Theanas experiment with amber and develop innovative ways to harness its electrical properties. They create rudimentary devices and conduct experiments to understand the practical applications of electricity. Their groundbreaking work in understanding the properties of amber lays the foundation for future discoveries in the field of electromagnetism.Throughout their journey, Theatus and Theanas face numerous challenges, including rival explorers and dangerous encounters with wildlife. But their determination, combined with their knowledge gained from Theano's teachings, allows them to overcome obstacles and make groundbreaking discoveries that shape the understanding of the natural world.Upon their return to Theano's school, Theatus and Theanas share their findings with their mentor and fellow students. Their expedition not only enriches their own knowledge but also contributes to the advancement of science and sparks new avenues of exploration for future generations.1 / 1ChatGPT may produce inaccurate information about people, places, or facts. ChatGPT May 24 Version/c/f412f6fd-6bde-461f-a32b-c1ad078bc798
------MultipartBoundary--e0KgSZErrpOGbk1KVscskuMnkhQAmwwoxNQEx6azxm----
Content-Type: text/css
Content-Transfer-Encoding: binary
Content-Location: cid:css-0dd17783-3cb0-4850-b7ee-7c57fe6336e9@mhtml.blink

@charset "utf-8";

.react-scroll-to-bottom--css-oteab-79elbk { position: relative; }

.react-scroll-to-bottom--css-oteab-1n7m0yu { height: 100%; overflow-y: auto; width: 100%; }

.react-scroll-to-bottom--css-oteab-1tj0vk3 { background-color: rgba(0, 0, 0, 0.2); border-radius: 10px; border-width: 0px; bottom: 5px; cursor: pointer; height: 20px; outline: 0px; position: absolute; right: 20px; width: 20px; }

.react-scroll-to-bottom--css-oteab-1tj0vk3:hover { background-color: rgba(0, 0, 0, 0.4); }

.react-scroll-to-bottom--css-oteab-1tj0vk3:active { background-color: rgba(0, 0, 0, 0.6); }
------MultipartBoundary--e0KgSZErrpOGbk1KVscskuMnkhQAmwwoxNQEx6azxm----
Content-Type: text/css
Content-Transfer-Encoding: binary
Content-Location: cid:css-f58ed92e-0427-46b1-b33c-40f9eb60a3bb@mhtml.blink

@charset "utf-8";

@keyframes intercom-lightweight-app-launcher { 
  0% { opacity: 0; transform: scale(0.5); }
  100% { opacity: 1; transform: scale(1); }
}

@keyframes intercom-lightweight-app-gradient { 
  0% { opacity: 0; }
  100% { opacity: 1; }
}

@keyframes intercom-lightweight-app-messenger { 
  0% { opacity: 0; transform: scale(0); }
  40% { opacity: 1; }
  100% { transform: scale(1); }
}

.intercom-lightweight-app { position: fixed; z-index: 2147483001; width: 0px; height: 0px; font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif; }

.intercom-lightweight-app-gradient { position: fixed; z-index: 2147483002; width: 500px; height: 500px; bottom: 0px; right: 0px; pointer-events: none; background: radial-gradient(at right bottom, rgba(29, 39, 54, 0.16) 0%, rgba(29, 39, 54, 0) 72%); animation: 200ms ease-out 0s 1 normal none running intercom-lightweight-app-gradient; }

.intercom-lightweight-app-launcher { position: fixed; z-index: 2147483003; border: none; bottom: 20px; right: 20px; max-width: 48px; width: 48px; max-height: 48px; height: 48px; border-radius: 50%; background: rgb(32, 33, 35); cursor: pointer; box-shadow: rgba(0, 0, 0, 0.06) 0px 1px 6px 0px, rgba(0, 0, 0, 0.16) 0px 2px 32px 0px; transition: transform 167ms cubic-bezier(0.33, 0, 0, 1) 0s; box-sizing: content-box; padding: 0px !important; margin: 0px !important; }

.intercom-lightweight-app-launcher:hover { transition: transform 250ms cubic-bezier(0.33, 0, 0, 1) 0s; transform: scale(1.1); }

.intercom-lightweight-app-launcher:active { transform: scale(0.85); transition: transform 134ms cubic-bezier(0.45, 0, 0.2, 1) 0s; }

.intercom-lightweight-app-launcher:focus { outline: none; }

.intercom-lightweight-app-launcher-icon { display: flex; align-items: center; justify-content: center; position: absolute; top: 0px; left: 0px; width: 48px; height: 48px; transition: transform 100ms linear 0s, opacity 80ms linear 0s; }

.intercom-lightweight-app-launcher-icon-open { opacity: 1; transform: rotate(0deg) scale(1); }

.intercom-lightweight-app-launcher-icon-open svg { width: 24px; height: 24px; }

.intercom-lightweight-app-launcher-icon-open svg path { fill: rgb(255, 255, 255); }

.intercom-lightweight-app-launcher-icon-self-serve { opacity: 1; transform: rotate(0deg) scale(1); }

.intercom-lightweight-app-launcher-icon-self-serve svg { height: 44px; }

.intercom-lightweight-app-launcher-icon-self-serve svg path { fill: rgb(255, 255, 255); }

.intercom-lightweight-app-launcher-custom-icon-open { max-height: 24px; max-width: 24px; opacity: 1; transform: rotate(0deg) scale(1); }

.intercom-lightweight-app-launcher-icon-minimize { opacity: 0; transform: rotate(-60deg) scale(0); }

.intercom-lightweight-app-launcher-icon-minimize svg path { fill: rgb(255, 255, 255); }

.intercom-lightweight-app-messenger { position: fixed; z-index: 2147483003; overflow: hidden; background-color: white; animation: 250ms cubic-bezier(0, 1, 1, 1) 0s 1 normal none running intercom-lightweight-app-messenger; transform-origin: right bottom; inset: 0px; border-radius: 16px; }

.intercom-lightweight-app-messenger-header { height: 64px; border-bottom: none; background: rgb(32, 33, 35); }

.intercom-lightweight-app-messenger-footer { position: absolute; bottom: 0px; width: 100%; height: 80px; background: rgb(255, 255, 255); font-size: 14px; line-height: 21px; border-top: 1px solid rgba(0, 0, 0, 0.05); box-shadow: rgba(0, 0, 0, 0.05) 0px 0px 25px; }

@media print {
  .intercom-lightweight-app { display: none; }
}
------MultipartBoundary--e0KgSZErrpOGbk1KVscskuMnkhQAmwwoxNQEx6azxm----
Content-Type: text/css
Content-Transfer-Encoding: binary
Content-Location: https://chat.openai.com/_next/static/css/47152cc18edae978.css

@charset "utf-8";

@font-face { font-display: swap; font-family: Signifier; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/signifier/signifier-light.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: Signifier; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/signifier/signifier-light-italic.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: Signifier; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/signifier/signifier-bold.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: Signifier; font-style: italic; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/signifier/signifier-bold-italic.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-buch.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-buch-kursiv.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: normal; font-weight: 500; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-kraftig.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: italic; font-weight: 500; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-kraftig-kursiv.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: normal; font-weight: 600; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-halbfett.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: italic; font-weight: 600; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-halbfett-kursiv.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: "SÃ¶hne Mono"; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-mono-buch.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: "SÃ¶hne Mono"; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-mono-halbfett.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: "SÃ¶hne Mono"; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-mono-buch-kursiv.woff2") format("woff2"); }

*, ::after, ::before { border: 0px solid rgb(217, 217, 227); box-sizing: border-box; }

::after, ::before { --tw-content:""; }

html { text-size-adjust: 100%; font-feature-settings: normal; font-family: SÃ¶hne, ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, Ubuntu, Cantarell, "Noto Sans", sans-serif, "Helvetica Neue", Arial, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji"; font-variation-settings: normal; line-height: 1.5; tab-size: 4; }

body { line-height: inherit; margin: 0px; }

hr { border-top-width: 1px; color: inherit; height: 0px; }

abbr:where([title]) { text-decoration: underline dotted currentcolor; }

h1, h2, h3, h4, h5, h6 { font-size: inherit; font-weight: inherit; }

a { color: inherit; text-decoration: inherit; }

b, strong { font-weight: bolder; }

code, kbd, pre, samp { font-family: "SÃ¶hne Mono", Monaco, "Andale Mono", "Ubuntu Mono", monospace; font-size: 1em; }

small { font-size: 80%; }

sub, sup { font-size: 75%; line-height: 0; position: relative; vertical-align: baseline; }

sub { bottom: -0.25em; }

sup { top: -0.5em; }

table { border-collapse: collapse; border-color: inherit; text-indent: 0px; }

button, input, optgroup, select, textarea { color: inherit; font-family: inherit; font-size: 100%; font-weight: inherit; line-height: inherit; margin: 0px; padding: 0px; }

button, select { text-transform: none; }

[type="button"], [type="reset"], [type="submit"], button { appearance: button; background-color: transparent; background-image: none; }

progress { vertical-align: baseline; }

::-webkit-inner-spin-button, ::-webkit-outer-spin-button { height: auto; }

[type="search"] { appearance: textfield; outline-offset: -2px; }

::-webkit-search-decoration { appearance: none; }

::-webkit-file-upload-button { appearance: button; font: inherit; }

summary { display: list-item; }

blockquote, dd, dl, fieldset, figure, h1, h2, h3, h4, h5, h6, hr, p, pre { margin: 0px; }

fieldset, legend { padding: 0px; }

menu, ol, ul { list-style: none; margin: 0px; padding: 0px; }

textarea { resize: vertical; }

input::-webkit-input-placeholder, textarea::-webkit-input-placeholder { color: rgb(172, 172, 190); }

input::placeholder, textarea::placeholder { color: rgb(172, 172, 190); }

[role="button"], button { cursor: pointer; }

:disabled { cursor: default; }

audio, canvas, embed, iframe, img, object, svg, video { display: block; vertical-align: middle; }

img, video { height: auto; max-width: 100%; }

[hidden] { display: none; }

[multiple], [type="date"], [type="datetime-local"], [type="email"], [type="month"], [type="number"], [type="password"], [type="search"], [type="tel"], [type="text"], [type="time"], [type="url"], [type="week"], select, textarea { --tw-shadow:0 0 transparent; appearance: none; background-color: rgb(255, 255, 255); border-color: rgb(142, 142, 160); border-radius: 0px; border-width: 1px; font-size: 1rem; line-height: 1.5rem; padding: 0.5rem 0.75rem; }

[multiple]:focus, [type="date"]:focus, [type="datetime-local"]:focus, [type="email"]:focus, [type="month"]:focus, [type="number"]:focus, [type="password"]:focus, [type="search"]:focus, [type="tel"]:focus, [type="text"]:focus, [type="time"]:focus, [type="url"]:focus, [type="week"]:focus, select:focus, textarea:focus { --tw-ring-inset:var(--tw-empty, ); --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:#2563eb; --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); border-color: rgb(37, 99, 235); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow); outline: transparent solid 2px; outline-offset: 2px; }

input::-webkit-input-placeholder, textarea::-webkit-input-placeholder { color: rgb(142, 142, 160); opacity: 1; }

input::placeholder, textarea::placeholder { color: rgb(142, 142, 160); opacity: 1; }

::-webkit-datetime-edit-fields-wrapper { padding: 0px; }

::-webkit-date-and-time-value { min-height: 1.5em; }

::-webkit-datetime-edit, ::-webkit-datetime-edit-day-field, ::-webkit-datetime-edit-hour-field, ::-webkit-datetime-edit-meridiem-field, ::-webkit-datetime-edit-millisecond-field, ::-webkit-datetime-edit-minute-field, ::-webkit-datetime-edit-month-field, ::-webkit-datetime-edit-second-field, ::-webkit-datetime-edit-year-field { padding-bottom: 0px; padding-top: 0px; }

select { background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 20 20'%3E%3Cpath stroke='%238e8ea0' stroke-linecap='round' stroke-linejoin='round' stroke-width='1.5' d='m6 8 4 4 4-4'/%3E%3C/svg%3E"); background-position: right 0.5rem center; background-repeat: no-repeat; background-size: 1.5em 1.5em; padding-right: 2.5rem; -webkit-print-color-adjust: exact; }

[multiple] { background-image: none; background-position: 0px 0px; background-repeat: repeat; background-size: initial; padding-right: 0.75rem; -webkit-print-color-adjust: inherit; }

[type="checkbox"], [type="radio"] { --tw-shadow:0 0 transparent; appearance: none; background-color: rgb(255, 255, 255); background-origin: border-box; border-color: rgb(142, 142, 160); border-width: 1px; color: rgb(37, 99, 235); display: inline-block; flex-shrink: 0; height: 1rem; padding: 0px; -webkit-print-color-adjust: exact; user-select: none; vertical-align: middle; width: 1rem; }

[type="checkbox"] { border-radius: 0px; }

[type="radio"] { border-radius: 100%; }

[type="checkbox"]:focus, [type="radio"]:focus { --tw-ring-inset:var(--tw-empty, ); --tw-ring-offset-width:2px; --tw-ring-offset-color:#fff; --tw-ring-color:#2563eb; --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow); outline: transparent solid 2px; outline-offset: 2px; }

[type="checkbox"]:checked, [type="radio"]:checked { background-color: currentcolor; background-position: 50% center; background-repeat: no-repeat; background-size: 100% 100%; border-color: transparent; }

[type="checkbox"]:checked { background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg viewBox='0 0 16 16' fill='%23fff' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M12.207 4.793a1 1 0 0 1 0 1.414l-5 5a1 1 0 0 1-1.414 0l-2-2a1 1 0 0 1 1.414-1.414L6.5 9.086l4.293-4.293a1 1 0 0 1 1.414 0z'/%3E%3C/svg%3E"); }

[type="radio"]:checked { background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg viewBox='0 0 16 16' fill='%23fff' xmlns='http://www.w3.org/2000/svg'%3E%3Ccircle cx='8' cy='8' r='3'/%3E%3C/svg%3E"); }

[type="checkbox"]:checked:focus, [type="checkbox"]:checked:hover, [type="radio"]:checked:focus, [type="radio"]:checked:hover { background-color: currentcolor; border-color: transparent; }

[type="checkbox"]:indeterminate { background-color: currentcolor; background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 16 16'%3E%3Cpath stroke='%23fff' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' d='M4 8h8'/%3E%3C/svg%3E"); background-position: 50% center; background-repeat: no-repeat; background-size: 100% 100%; border-color: transparent; }

[type="checkbox"]:indeterminate:focus, [type="checkbox"]:indeterminate:hover { background-color: currentcolor; border-color: transparent; }

[type="file"] { background: initial; border-color: inherit; border-radius: 0px; border-width: 0px; font-size: inherit; line-height: inherit; padding: 0px; }

[type="file"]:focus { outline: -webkit-focus-ring-color auto 1px; }

h1 { font-size: 1.875rem; line-height: 2.25rem; }

h1, h2, h3 { font-weight: 600; }

h2, h3 { font-size: 1.5rem; line-height: 2rem; }

*, ::after, ::before { --tw-border-spacing-x:0; --tw-border-spacing-y:0; --tw-translate-x:0; --tw-translate-y:0; --tw-rotate:0; --tw-skew-x:0; --tw-skew-y:0; --tw-scale-x:1; --tw-scale-y:1; --tw-pan-x: ; --tw-pan-y: ; --tw-pinch-zoom: ; --tw-scroll-snap-strictness:proximity; --tw-gradient-from-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; --tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spacing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:rgba(69,89,164,0.5); --tw-ring-offset-shadow:0 0 transparent; --tw-ring-shadow:0 0 transparent; --tw-shadow:0 0 transparent; --tw-shadow-colored:0 0 transparent; --tw-blur: ; --tw-brightness: ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --tw-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ; --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity: ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; }

::-webkit-backdrop { --tw-border-spacing-x:0; --tw-border-spacing-y:0; --tw-translate-x:0; --tw-translate-y:0; --tw-rotate:0; --tw-skew-x:0; --tw-skew-y:0; --tw-scale-x:1; --tw-scale-y:1; --tw-pan-x: ; --tw-pan-y: ; --tw-pinch-zoom: ; --tw-scroll-snap-strictness:proximity; --tw-gradient-from-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; --tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spacing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:rgba(69,89,164,0.5); --tw-ring-offset-shadow:0 0 transparent; --tw-ring-shadow:0 0 transparent; --tw-shadow:0 0 transparent; --tw-shadow-colored:0 0 transparent; --tw-blur: ; --tw-brightness: ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --tw-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ; --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity: ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; }

::backdrop { --tw-border-spacing-x:0; --tw-border-spacing-y:0; --tw-translate-x:0; --tw-translate-y:0; --tw-rotate:0; --tw-skew-x:0; --tw-skew-y:0; --tw-scale-x:1; --tw-scale-y:1; --tw-pan-x: ; --tw-pan-y: ; --tw-pinch-zoom: ; --tw-scroll-snap-strictness:proximity; --tw-gradient-from-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; --tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spacing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:rgba(69,89,164,0.5); --tw-ring-offset-shadow:0 0 transparent; --tw-ring-shadow:0 0 transparent; --tw-shadow:0 0 transparent; --tw-shadow-colored:0 0 transparent; --tw-blur: ; --tw-brightness: ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --tw-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ; --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity: ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; }

:root { --color-primary:#19c37d; --color-secondary:#715fde; --color-error:#ef4146; --gradient-primary:linear-gradient(90deg,#a29bd4,#989fdd); --text-primary:#202123; --text-default:#353740; --text-secondary:#6e6e80; --text-disabled:#acacbe; --text-error:var(--color-error); }

::-webkit-scrollbar { height: 1rem; width: 0.5rem; }

::-webkit-scrollbar:horizontal { height: 0.5rem; width: 1rem; }

::-webkit-scrollbar-track { background-color: transparent; border-radius: 9999px; }

::-webkit-scrollbar-thumb { --tw-border-opacity:1; background-color: rgba(217, 217, 227, 0.8); border-color: rgba(255,255,255,var(--tw-border-opacity)); border-radius: 9999px; border-width: 1px; }

::-webkit-scrollbar-thumb:hover { --tw-bg-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.dark::-webkit-scrollbar-thumb { --tw-bg-opacity:1; background-color: rgba(86,88,105,var(--tw-bg-opacity)); }

.dark::-webkit-scrollbar-thumb:hover { --tw-bg-opacity:1; background-color: rgba(172,172,190,var(--tw-bg-opacity)); }

@media (min-width: 768px) {
  .scrollbar-trigger ::-webkit-scrollbar-thumb { visibility: hidden; }
  .scrollbar-trigger:hover ::-webkit-scrollbar-thumb { visibility: visible; }
}

.container { width: 100%; }

@media (min-width: 640px) {
  .container { max-width: 640px; }
}

@media (min-width: 768px) {
  .container { max-width: 768px; }
}

@media (min-width: 1024px) {
  .container { max-width: 1024px; }
}

@media (min-width: 1280px) {
  .container { max-width: 1280px; }
}

@media (min-width: 1536px) {
  .container { max-width: 1536px; }
}

.prose { color: var(--tw-prose-body); max-width: 65ch; }

.prose :where([class~="lead"]):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-lead); font-size: 1.25em; line-height: 1.6; margin-bottom: 1.2em; margin-top: 1.2em; }

.prose :where(a):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-links); font-weight: 500; text-decoration: underline; }

.prose :where(strong):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-bold); font-weight: 600; }

.prose :where(a strong):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(blockquote strong):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(thead th strong):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(ol):not(:where([class~="not-prose"] *)) { list-style-type: decimal; margin-bottom: 1.25em; margin-top: 1.25em; padding-left: 1.625em; }

.prose :where(ol[type="A"]):not(:where([class~="not-prose"] *)) { list-style-type: upper-alpha; }

.prose :where(ol[type="a"]):not(:where([class~="not-prose"] *)) { list-style-type: lower-alpha; }

.prose :where():not(:where([class~="not-prose"] *)) { list-style-type: upper-alpha; }

.prose :where():not(:where([class~="not-prose"] *)) { list-style-type: lower-alpha; }

.prose :where(ol[type="I"]):not(:where([class~="not-prose"] *)) { list-style-type: upper-roman; }

.prose :where(ol[type="i"]):not(:where([class~="not-prose"] *)) { list-style-type: lower-roman; }

.prose :where():not(:where([class~="not-prose"] *)) { list-style-type: upper-roman; }

.prose :where():not(:where([class~="not-prose"] *)) { list-style-type: lower-roman; }

.prose :where(ol[type="1"]):not(:where([class~="not-prose"] *)) { list-style-type: decimal; }

.prose :where(ul):not(:where([class~="not-prose"] *)) { list-style-type: disc; margin-bottom: 1.25em; margin-top: 1.25em; padding-left: 1.625em; }

.prose :where(ol > li):not(:where([class~="not-prose"] *))::marker { color: var(--tw-prose-counters); font-weight: 400; }

.prose :where(ul > li):not(:where([class~="not-prose"] *))::marker { color: var(--tw-prose-bullets); }

.prose :where(hr):not(:where([class~="not-prose"] *)) { border-color: var(--tw-prose-hr); border-top-width: 1px; margin-bottom: 3em; margin-top: 3em; }

.prose :where(blockquote):not(:where([class~="not-prose"] *)) { border-left-color: var(--tw-prose-quote-borders); border-left-width: 0.25rem; color: var(--tw-prose-quotes); font-style: normal; font-weight: 500; margin-bottom: 1.6em; margin-top: 1.6em; padding-left: 1em; quotes: "â" "â" "â" "â"; }

.prose :where(blockquote p:first-of-type):not(:where([class~="not-prose"] *))::before { content: open-quote; }

.prose :where(blockquote p:last-of-type):not(:where([class~="not-prose"] *))::after { content: close-quote; }

.prose :where(h1):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-size: 2.25em; font-weight: 800; line-height: 1.11111; margin-bottom: 0.888889em; margin-top: 0px; }

.prose :where(h1 strong):not(:where([class~="not-prose"] *)) { color: inherit; font-weight: 900; }

.prose :where(h2):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-size: 1.5em; font-weight: 700; line-height: 1.33333; margin-bottom: 1em; margin-top: 2em; }

.prose :where(h2 strong):not(:where([class~="not-prose"] *)) { color: inherit; font-weight: 800; }

.prose :where(h3):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-size: 1.25em; font-weight: 600; line-height: 1.6; margin-bottom: 0.6em; margin-top: 1.6em; }

.prose :where(h3 strong):not(:where([class~="not-prose"] *)) { color: inherit; font-weight: 700; }

.prose :where(h4):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-weight: 600; line-height: 1.5; margin-bottom: 0.5em; margin-top: 1.5em; }

.prose :where(h4 strong):not(:where([class~="not-prose"] *)) { color: inherit; font-weight: 700; }

.prose :where(img):not(:where([class~="not-prose"] *)) { margin-bottom: 2em; margin-top: 2em; }

.prose :where(figure > *):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; margin-top: 0px; }

.prose :where(figcaption):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-captions); font-size: 0.875em; line-height: 1.42857; margin-top: 0.857143em; }

.prose :where(code):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-code); font-size: 0.875em; font-weight: 600; }

.prose :where(code):not(:where([class~="not-prose"] *))::before { content: "`"; }

.prose :where(code):not(:where([class~="not-prose"] *))::after { content: "`"; }

.prose :where(a code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(h1 code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(h2 code):not(:where([class~="not-prose"] *)) { color: inherit; font-size: 0.875em; }

.prose :where(h3 code):not(:where([class~="not-prose"] *)) { color: inherit; font-size: 0.9em; }

.prose :where(h4 code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(blockquote code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(thead th code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(pre):not(:where([class~="not-prose"] *)) { background-color: transparent; border-radius: 0.375rem; color: currentcolor; font-size: 0.875em; font-weight: 400; line-height: 1.71429; margin: 0px; overflow-x: auto; padding: 0px; }

.prose :where(pre code):not(:where([class~="not-prose"] *)) { background-color: transparent; border-radius: 0px; border-width: 0px; color: inherit; font-family: inherit; font-size: inherit; font-weight: inherit; line-height: inherit; padding: 0px; }

.prose :where(pre code):not(:where([class~="not-prose"] *))::before { content: none; }

.prose :where(pre code):not(:where([class~="not-prose"] *))::after { content: none; }

.prose :where(table):not(:where([class~="not-prose"] *)) { font-size: 0.875em; line-height: 1.71429; margin-bottom: 2em; margin-top: 2em; table-layout: auto; text-align: left; width: 100%; }

.prose :where(thead):not(:where([class~="not-prose"] *)) { border-bottom-color: var(--tw-prose-th-borders); border-bottom-width: 1px; }

.prose :where(thead th):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-weight: 600; padding-bottom: 0.571429em; padding-left: 0.571429em; padding-right: 0.571429em; vertical-align: bottom; }

.prose :where(tbody tr):not(:where([class~="not-prose"] *)) { border-bottom-color: var(--tw-prose-td-borders); border-bottom-width: 1px; }

.prose :where(tbody tr:last-child):not(:where([class~="not-prose"] *)) { border-bottom-width: 0px; }

.prose :where(tbody td):not(:where([class~="not-prose"] *)) { vertical-align: baseline; }

.prose :where(tfoot):not(:where([class~="not-prose"] *)) { border-top-color: var(--tw-prose-th-borders); border-top-width: 1px; }

.prose :where(tfoot td):not(:where([class~="not-prose"] *)) { vertical-align: top; }

.prose { --tw-prose-body:#374151; --tw-prose-headings:#111827; --tw-prose-lead:#4b5563; --tw-prose-links:#111827; --tw-prose-bold:#111827; --tw-prose-counters:#6b7280; --tw-prose-bullets:#d1d5db; --tw-prose-hr:#e5e7eb; --tw-prose-quotes:#111827; --tw-prose-quote-borders:#e5e7eb; --tw-prose-captions:#6b7280; --tw-prose-code:#111827; --tw-prose-pre-code:#e5e7eb; --tw-prose-pre-bg:#1f2937; --tw-prose-th-borders:#d1d5db; --tw-prose-td-borders:#e5e7eb; --tw-prose-invert-body:#d1d5db; --tw-prose-invert-headings:#fff; --tw-prose-invert-lead:#9ca3af; --tw-prose-invert-links:#fff; --tw-prose-invert-bold:#fff; --tw-prose-invert-counters:#9ca3af; --tw-prose-invert-bullets:#4b5563; --tw-prose-invert-hr:#374151; --tw-prose-invert-quotes:#f3f4f6; --tw-prose-invert-quote-borders:#374151; --tw-prose-invert-captions:#9ca3af; --tw-prose-invert-code:#fff; --tw-prose-invert-pre-code:#d1d5db; --tw-prose-invert-pre-bg:rgba(0,0,0,0.5); --tw-prose-invert-th-borders:#4b5563; --tw-prose-invert-td-borders:#374151; font-size: 1rem; line-height: 1.75; }

.prose :where(p):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; margin-top: 1.25em; }

.prose :where(video):not(:where([class~="not-prose"] *)) { margin-bottom: 2em; margin-top: 2em; }

.prose :where(figure):not(:where([class~="not-prose"] *)) { margin-bottom: 2em; margin-top: 2em; }

.prose :where(li):not(:where([class~="not-prose"] *)) { margin-bottom: 0.5em; margin-top: 0.5em; }

.prose :where(ol > li):not(:where([class~="not-prose"] *)) { padding-left: 0.375em; }

.prose :where(ul > li):not(:where([class~="not-prose"] *)) { padding-left: 0.375em; }

.prose :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.75em; margin-top: 0.75em; }

.prose :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.25em; }

.prose :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; }

.prose :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.25em; }

.prose :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; }

.prose :where(ul ul, ul ol, ol ul, ol ol):not(:where([class~="not-prose"] *)) { margin-bottom: 0.75em; margin-top: 0.75em; }

.prose :where(hr + *):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(h2 + *):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(h3 + *):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(h4 + *):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(thead th:first-child):not(:where([class~="not-prose"] *)) { padding-left: 0px; }

.prose :where(thead th:last-child):not(:where([class~="not-prose"] *)) { padding-right: 0px; }

.prose :where(tbody td, tfoot td):not(:where([class~="not-prose"] *)) { padding: 0.571429em; }

.prose :where(tbody td:first-child, tfoot td:first-child):not(:where([class~="not-prose"] *)) { padding-left: 0px; }

.prose :where(tbody td:last-child, tfoot td:last-child):not(:where([class~="not-prose"] *)) { padding-right: 0px; }

.prose :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-sm :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.571429em; margin-top: 0.571429em; }

.prose-sm :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.14286em; }

.prose-sm :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.14286em; }

.prose-sm :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.14286em; }

.prose-sm :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.14286em; }

.prose-sm :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-sm :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-base :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.75em; margin-top: 0.75em; }

.prose-base :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.25em; }

.prose-base :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; }

.prose-base :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.25em; }

.prose-base :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; }

.prose-base :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-base :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-lg :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.888889em; margin-top: 0.888889em; }

.prose-lg :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.33333em; }

.prose-lg :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.33333em; }

.prose-lg :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.33333em; }

.prose-lg :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.33333em; }

.prose-lg :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-lg :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-xl :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.8em; margin-top: 0.8em; }

.prose-xl :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.2em; }

.prose-xl :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.2em; }

.prose-xl :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.2em; }

.prose-xl :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.2em; }

.prose-xl :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-xl :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-2xl :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.833333em; margin-top: 0.833333em; }

.prose-2xl :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.33333em; }

.prose-2xl :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.33333em; }

.prose-2xl :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.33333em; }

.prose-2xl :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.33333em; }

.prose-2xl :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-2xl :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-invert { --tw-prose-body:var(--tw-prose-invert-body); --tw-prose-headings:var(--tw-prose-invert-headings); --tw-prose-lead:var(--tw-prose-invert-lead); --tw-prose-links:var(--tw-prose-invert-links); --tw-prose-bold:var(--tw-prose-invert-bold); --tw-prose-counters:var(--tw-prose-invert-counters); --tw-prose-bullets:var(--tw-prose-invert-bullets); --tw-prose-hr:var(--tw-prose-invert-hr); --tw-prose-quotes:var(--tw-prose-invert-quotes); --tw-prose-quote-borders:var(--tw-prose-invert-quote-borders); --tw-prose-captions:var(--tw-prose-invert-captions); --tw-prose-code:var(--tw-prose-invert-code); --tw-prose-pre-code:var(--tw-prose-invert-pre-code); --tw-prose-pre-bg:var(--tw-prose-invert-pre-bg); --tw-prose-th-borders:var(--tw-prose-invert-th-borders); --tw-prose-td-borders:var(--tw-prose-invert-td-borders); }

.form-input, .form-multiselect, .form-select, .form-textarea { --tw-shadow:0 0 transparent; appearance: none; background-color: rgb(255, 255, 255); border-color: rgb(142, 142, 160); border-radius: 0px; border-width: 1px; font-size: 1rem; line-height: 1.5rem; padding: 0.5rem 0.75rem; }

.form-input:focus, .form-multiselect:focus, .form-select:focus, .form-textarea:focus { --tw-ring-inset:var(--tw-empty, ); --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:#2563eb; --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); border-color: rgb(37, 99, 235); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow); outline: transparent solid 2px; outline-offset: 2px; }

.form-input::-webkit-input-placeholder, .form-textarea::-webkit-input-placeholder { color: rgb(142, 142, 160); opacity: 1; }

.form-input::placeholder, .form-textarea::placeholder { color: rgb(142, 142, 160); opacity: 1; }

.form-input::-webkit-datetime-edit-fields-wrapper { padding: 0px; }

.form-input::-webkit-date-and-time-value { min-height: 1.5em; }

.form-input::-webkit-datetime-edit, .form-input::-webkit-datetime-edit-day-field, .form-input::-webkit-datetime-edit-hour-field, .form-input::-webkit-datetime-edit-meridiem-field, .form-input::-webkit-datetime-edit-millisecond-field, .form-input::-webkit-datetime-edit-minute-field, .form-input::-webkit-datetime-edit-month-field, .form-input::-webkit-datetime-edit-second-field, .form-input::-webkit-datetime-edit-year-field { padding-bottom: 0px; padding-top: 0px; }

.btn { align-items: center; border-color: transparent; border-radius: 0.25rem; border-width: 1px; display: inline-flex; font-size: 0.875rem; line-height: 1.25rem; padding: 0.5rem 0.75rem; pointer-events: auto; }

.btn:focus { outline: transparent solid 2px; outline-offset: 2px; }

.btn:disabled { cursor: not-allowed; opacity: 0.5; }

.btn-primary { --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(16,163,127,var(--tw-bg-opacity)); color: rgba(255,255,255,var(--tw-text-opacity)); }

.btn-primary:hover { --tw-bg-opacity:1; background-color: rgba(26,127,100,var(--tw-bg-opacity)); }

.btn-primary:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); --tw-ring-offset-width:2px; box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.btn-primary.focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(25,195,125,var(--tw-ring-opacity)); }

.btn-primary:focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(25,195,125,var(--tw-ring-opacity)); }

.btn-danger { --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(185,28,28,var(--tw-bg-opacity)); color: rgba(255,255,255,var(--tw-text-opacity)); }

.btn-danger:hover { --tw-bg-opacity:1; background-color: rgba(153,27,27,var(--tw-bg-opacity)); }

.btn-danger:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); --tw-ring-offset-width:2px; box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.btn-danger.focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(220,38,38,var(--tw-ring-opacity)); }

.btn-danger:focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(220,38,38,var(--tw-ring-opacity)); }

.btn-danger:disabled:hover { --tw-bg-opacity:1; background-color: rgba(185,28,28,var(--tw-bg-opacity)); }

.btn-neutral { --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); border-color: rgba(0, 0, 0, 0.1); border-width: 1px; color: rgba(64,65,79,var(--tw-text-opacity)); font-size: 0.875rem; line-height: 1.25rem; }

.btn-neutral:hover { --tw-bg-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.btn-neutral:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); --tw-ring-offset-width:2px; box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.btn-neutral.focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(99,102,241,var(--tw-ring-opacity)); }

.btn-neutral:focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(99,102,241,var(--tw-ring-opacity)); }

.dark .btn-neutral { --tw-border-opacity:1; --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); border-color: rgba(86,88,105,var(--tw-border-opacity)); color: rgba(217,217,227,var(--tw-text-opacity)); }

.dark .btn-neutral:hover { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.btn-dark { --tw-border-opacity:1; --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); border-color: rgba(86,88,105,var(--tw-border-opacity)); border-width: 1px; color: rgba(255,255,255,var(--tw-text-opacity)); }

.btn-dark:hover { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.btn-light { --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); color: rgba(0,0,0,var(--tw-text-opacity)); }

.btn-light:hover { --tw-bg-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); }

.btn-disabled { --tw-bg-opacity:1; --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); cursor: not-allowed; }

.btn-disabled, .btn-disabled:hover { background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.btn-disabled:hover { --tw-bg-opacity:1; }

.btn-small { padding: 0.25rem 0.5rem; }

.sr-only { clip: rect(0px, 0px, 0px, 0px); border-width: 0px; height: 1px; margin: -1px; overflow: hidden; padding: 0px; position: absolute; white-space: nowrap; width: 1px; }

.pointer-events-none { pointer-events: none; }

.pointer-events-auto { pointer-events: auto; }

.visible { visibility: visible; }

.\!invisible { visibility: hidden !important; }

.invisible { visibility: hidden; }

.static { position: static; }

.fixed { position: fixed; }

.absolute { position: absolute; }

.relative { position: relative; }

.\!sticky { position: sticky !important; }

.sticky { position: sticky; }

.inset-0 { left: 0px; right: 0px; }

.inset-0, .inset-y-0 { bottom: 0px; top: 0px; }

.-left-2 { left: -0.5rem; }

.-top-0 { top: 0px; }

.-top-0\.5 { top: -0.125rem; }

.-top-4 { top: -1rem; }

.bottom-0 { bottom: 0px; }

.bottom-1 { bottom: 0.25rem; }

.bottom-1\.5 { bottom: 0.375rem; }

.bottom-2 { bottom: 0.5rem; }

.bottom-4 { bottom: 1rem; }

.bottom-\[10px\] { bottom: 10px; }

.bottom-\[124px\] { bottom: 124px; }

.bottom-full { bottom: 100%; }

.left-0 { left: 0px; }

.left-1 { left: 0.25rem; }

.left-1\.5 { left: 0.375rem; }

.left-1\/2 { left: 50%; }

.left-2 { left: 0.5rem; }

.left-4 { left: 1rem; }

.right-0 { right: 0px; }

.right-1 { right: 0.25rem; }

.right-2 { right: 0.5rem; }

.right-3 { right: 0.75rem; }

.right-4 { right: 1rem; }

.right-6 { right: 1.5rem; }

.top-0 { top: 0px; }

.top-1 { top: 0.25rem; }

.top-1\/2 { top: 50%; }

.top-14 { top: 3.5rem; }

.top-2 { top: 0.5rem; }

.top-\[-3px\] { top: -3px; }

.top-\[-6px\] { top: -6px; }

.top-\[20px\] { top: 20px; }

.top-full { top: 100%; }

.-z-0, .z-0 { z-index: 0; }

.z-10 { z-index: 10; }

.z-20 { z-index: 20; }

.z-50 { z-index: 50; }

.z-\[14\] { z-index: 14; }

.z-\[15\] { z-index: 15; }

.z-\[16\] { z-index: 16; }

.z-\[17\] { z-index: 17; }

.z-\[2\] { z-index: 2; }

.z-\[60\] { z-index: 60; }

.order-1 { order: 1; }

.order-2 { order: 2; }

.col-auto { grid-column: auto / auto; }

.col-span-1 { grid-column: span 1 / span 1; }

.col-start-2 { grid-column-start: 2; }

.row-auto { grid-row: auto / auto; }

.row-start-2 { grid-row-start: 2; }

.float-left { float: left; }

.m-0 { margin: 0px; }

.m-1 { margin: 0.25rem; }

.m-2 { margin: 0.5rem; }

.m-4 { margin: 1rem; }

.m-6 { margin: 1.5rem; }

.m-auto { margin: auto; }

.-my-0 { margin-bottom: 0px; margin-top: 0px; }

.-my-0\.5 { margin-bottom: -0.125rem; margin-top: -0.125rem; }

.-my-1 { margin-bottom: -0.25rem; margin-top: -0.25rem; }

.mx-1 { margin-left: 0.25rem; margin-right: 0.25rem; }

.mx-2 { margin-left: 0.5rem; margin-right: 0.5rem; }

.mx-3 { margin-left: 0.75rem; margin-right: 0.75rem; }

.mx-6 { margin-left: 1.5rem; margin-right: 1.5rem; }

.mx-8 { margin-left: 2rem; margin-right: 2rem; }

.mx-\[10px\] { margin-left: 10px; margin-right: 10px; }

.mx-auto { margin-left: auto; margin-right: auto; }

.my-0 { margin-bottom: 0px; margin-top: 0px; }

.my-1 { margin-bottom: 0.25rem; margin-top: 0.25rem; }

.my-1\.5 { margin-bottom: 0.375rem; margin-top: 0.375rem; }

.my-2 { margin-bottom: 0.5rem; margin-top: 0.5rem; }

.my-3 { margin-bottom: 0.75rem; margin-top: 0.75rem; }

.-mb-28 { margin-bottom: -7rem; }

.-mb-40 { margin-bottom: -10rem; }

.-ml-0 { margin-left: 0px; }

.-ml-0\.5 { margin-left: -0.125rem; }

.-ml-1 { margin-left: -0.25rem; }

.-ml-4 { margin-left: -1rem; }

.-ml-\[1px\] { margin-left: -1px; }

.-ml-\[8px\] { margin-left: -8px; }

.-ml-px { margin-left: -1px; }

.-mr-1 { margin-right: -0.25rem; }

.-mr-12 { margin-right: -3rem; }

.-mr-2 { margin-right: -0.5rem; }

.-mt-0 { margin-top: 0px; }

.-mt-0\.5 { margin-top: -0.125rem; }

.-mt-\[3px\] { margin-top: -3px; }

.mb-0 { margin-bottom: 0px; }

.mb-0\.5 { margin-bottom: 0.125rem; }

.mb-1 { margin-bottom: 0.25rem; }

.mb-10 { margin-bottom: 2.5rem; }

.mb-12 { margin-bottom: 3rem; }

.mb-2 { margin-bottom: 0.5rem; }

.mb-3 { margin-bottom: 0.75rem; }

.mb-4 { margin-bottom: 1rem; }

.mb-5 { margin-bottom: 1.25rem; }

.mb-6 { margin-bottom: 1.5rem; }

.mb-7 { margin-bottom: 1.75rem; }

.mb-8 { margin-bottom: 2rem; }

.mb-auto { margin-bottom: auto; }

.ml-1 { margin-left: 0.25rem; }

.ml-12 { margin-left: 3rem; }

.ml-5 { margin-left: 1.25rem; }

.ml-auto { margin-left: auto; }

.mr-0 { margin-right: 0px; }

.mr-1 { margin-right: 0.25rem; }

.mr-2 { margin-right: 0.5rem; }

.mr-3 { margin-right: 0.75rem; }

.mr-4 { margin-right: 1rem; }

.mr-8 { margin-right: 2rem; }

.mr-auto { margin-right: auto; }

.mt-1 { margin-top: 0.25rem; }

.mt-2 { margin-top: 0.5rem; }

.mt-3 { margin-top: 0.75rem; }

.mt-3\.5 { margin-top: 0.875rem; }

.mt-4 { margin-top: 1rem; }

.mt-5 { margin-top: 1.25rem; }

.mt-6 { margin-top: 1.5rem; }

.mt-8 { margin-top: 2rem; }

.mt-auto { margin-top: auto; }

.line-clamp-1 { -webkit-line-clamp: 1; }

.line-clamp-1, .line-clamp-2 { -webkit-box-orient: vertical; display: -webkit-box; overflow: hidden; }

.line-clamp-2 { -webkit-line-clamp: 2; }

.line-clamp-3 { -webkit-box-orient: vertical; -webkit-line-clamp: 3; display: -webkit-box; overflow: hidden; }

.block { display: block; }

.inline-block { display: inline-block; }

.inline { display: inline; }

.flex { display: flex; }

.inline-flex { display: inline-flex; }

.table { display: table; }

.grid { display: grid; }

.contents { display: contents; }

.hidden { display: none; }

.\!h-5 { height: 1.25rem !important; }

.h-1 { height: 0.25rem; }

.h-10 { height: 2.5rem; }

.h-11 { height: 2.75rem; }

.h-12 { height: 3rem; }

.h-16 { height: 4rem; }

.h-2 { height: 0.5rem; }

.h-24 { height: 6rem; }

.h-3 { height: 0.75rem; }

.h-32 { height: 8rem; }

.h-4 { height: 1rem; }

.h-5 { height: 1.25rem; }

.h-6 { height: 1.5rem; }

.h-7 { height: 1.75rem; }

.h-8 { height: 2rem; }

.h-9 { height: 2.25rem; }

.h-\[12px\] { height: 12px; }

.h-\[14px\] { height: 14px; }

.h-\[18px\] { height: 18px; }

.h-\[19px\] { height: 19px; }

.h-\[21px\] { height: 21px; }

.h-\[25px\] { height: 25px; }

.h-\[30px\] { height: 30px; }

.h-\[36px\] { height: 36px; }

.h-\[404px\] { height: 404px; }

.h-\[42px\] { height: 42px; }

.h-\[50px\] { height: 50px; }

.h-\[60px\] { height: 60px; }

.h-\[70px\] { height: 70px; }

.h-full { height: 100%; }

.h-px { height: 1px; }

.h-screen { height: 100vh; }

.max-h-0 { max-height: 0px; }

.max-h-5 { max-height: 1.25rem; }

.max-h-60 { max-height: 15rem; }

.max-h-64 { max-height: 16rem; }

.max-h-72 { max-height: 18rem; }

.max-h-\[28rem\] { max-height: 28rem; }

.max-h-\[80vh\] { max-height: 80vh; }

.min-h-0 { min-height: 0px; }

.min-h-\[1\.5rem\] { min-height: 1.5rem; }

.min-h-\[20px\] { min-height: 20px; }

.min-h-\[24px\] { min-height: 24px; }

.min-h-\[28px\] { min-height: 28px; }

.min-h-\[71px\] { min-height: 71px; }

.\!w-5 { width: 1.25rem !important; }

.w-1\/2 { width: 50%; }

.w-10 { width: 2.5rem; }

.w-11 { width: 2.75rem; }

.w-12 { width: 3rem; }

.w-14 { width: 3.5rem; }

.w-16 { width: 4rem; }

.w-2 { width: 0.5rem; }

.w-3 { width: 0.75rem; }

.w-4 { width: 1rem; }

.w-5 { width: 1.25rem; }

.w-6 { width: 1.5rem; }

.w-64 { width: 16rem; }

.w-7 { width: 1.75rem; }

.w-8 { width: 2rem; }

.w-96 { width: 24rem; }

.w-\[103px\] { width: 103px; }

.w-\[184px\] { width: 184px; }

.w-\[18px\] { width: 18px; }

.w-\[2\.5px\] { width: 2.5px; }

.w-\[209px\] { width: 209px; }

.w-\[218px\] { width: 218px; }

.w-\[21px\] { width: 21px; }

.w-\[260px\] { width: 260px; }

.w-\[30px\] { width: 30px; }

.w-\[42px\] { width: 42px; }

.w-\[70px\] { width: 70px; }

.w-\[860px\] { width: 860px; }

.w-\[88px\] { width: 88px; }

.w-\[960px\] { width: 960px; }

.w-\[calc\(100\%-50px\)\] { width: calc(100% - 50px); }

.w-auto { width: auto; }

.w-full { width: 100%; }

.w-screen { width: 100vw; }

.min-w-0 { min-width: 0px; }

.min-w-\[100vw\] { min-width: 100vw; }

.min-w-\[180px\] { min-width: 180px; }

.min-w-\[8rem\] { min-width: 8rem; }

.max-w-2xl { max-width: 42rem; }

.max-w-7xl { max-width: 80rem; }

.max-w-\[100vw\] { max-width: 100vw; }

.max-w-\[44rem\] { max-width: 44rem; }

.max-w-\[560px\] { max-width: 560px; }

.max-w-full { max-width: 100%; }

.max-w-lg { max-width: 32rem; }

.max-w-md { max-width: 28rem; }

.max-w-sm { max-width: 24rem; }

.max-w-xl { max-width: 36rem; }

.max-w-xs { max-width: 20rem; }

.flex-1 { flex: 1 1 0%; }

.flex-auto { flex: 1 1 auto; }

.flex-initial { flex: 0 1 auto; }

.flex-none { flex: 0 0 auto; }

.flex-shrink { flex-shrink: 1; }

.flex-shrink-0 { flex-shrink: 0; }

.shrink { flex-shrink: 1; }

.shrink-0 { flex-shrink: 0; }

.flex-grow { flex-grow: 1; }

.flex-grow-0 { flex-grow: 0; }

.grow { flex-grow: 1; }

.border-separate { border-collapse: separate; }

.border-spacing-0 { --tw-border-spacing-x:0px; --tw-border-spacing-y:0px; border-spacing: var(--tw-border-spacing-x) var(--tw-border-spacing-y); }

.-translate-x-1\/2 { --tw-translate-x:-50%; }

.-translate-x-1\/2, .-translate-x-\[calc\(100\%\+4px\)\] { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.-translate-x-\[calc\(100\%\+4px\)\] { --tw-translate-x:calc(-100% + -4px); }

.-translate-x-full { --tw-translate-x:-100%; }

.-translate-x-full, .-translate-y-1\/2 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.-translate-y-1\/2 { --tw-translate-y:-50%; }

.translate-x-0 { --tw-translate-x:0px; }

.translate-x-0, .translate-x-0\.5 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.translate-x-0\.5 { --tw-translate-x:0.125rem; }

.translate-x-1 { --tw-translate-x:0.25rem; }

.translate-x-1, .translate-x-1\/2 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.translate-x-1\/2 { --tw-translate-x:50%; }

.translate-x-full { --tw-translate-x:100%; }

.translate-x-full, .translate-y-0 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.translate-y-0 { --tw-translate-y:0px; }

.translate-y-1 { --tw-translate-y:0.25rem; }

.translate-y-1, .translate-y-3 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.translate-y-3 { --tw-translate-y:0.75rem; }

.translate-y-\[calc\(100\%-71px\)\] { --tw-translate-y:calc(100% - 71px); }

.-rotate-180, .translate-y-\[calc\(100\%-71px\)\] { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.-rotate-180 { --tw-rotate:-180deg; }

.-rotate-45 { --tw-rotate:-45deg; }

.-rotate-45, .rotate-180 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.rotate-180 { --tw-rotate:180deg; }

.rotate-45 { --tw-rotate:45deg; }

.rotate-45, .transform { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

@-webkit-keyframes slideLeftAndFade { 
  0% { opacity: 0; transform: translateX(2px); }
  100% { opacity: 1; transform: translateX(0px); }
}

.animate-slideLeftAndFade { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideLeftAndFade; }

@-webkit-keyframes spin { 
  100% { transform: rotate(1turn); }
}

@keyframes spin { 
  100% { transform: rotate(1turn); }
}

.animate-spin { animation: 1s linear 0s infinite normal none running spin; }

.cursor-auto { cursor: auto; }

.cursor-default { cursor: default; }

.cursor-not-allowed { cursor: not-allowed; }

.cursor-pointer { cursor: pointer; }

.select-none { user-select: none; }

.resize-none { resize: none; }

.resize { resize: both; }

.list-disc { list-style-type: disc; }

.list-none { list-style-type: none; }

.appearance-none { appearance: none; }

.grid-cols-1 { grid-template-columns: repeat(1, minmax(0px, 1fr)); }

.grid-cols-2 { grid-template-columns: repeat(2, minmax(0px, 1fr)); }

.grid-cols-\[10px_minmax\(300px\,_100\%\)_10px\] { grid-template-columns: 10px minmax(300px, 100%) 10px; }

.grid-cols-\[minmax\(10px\,_auto\)_minmax\(300px\,_800px\)_minmax\(10px\,_auto\)\] { grid-template-columns: minmax(10px, auto) minmax(300px, 800px) minmax(10px, auto); }

.grid-rows-\[minmax\(10px\,_1fr\)_auto_minmax\(10px\,_1fr\)\] { grid-template-rows: minmax(10px, 1fr) auto minmax(10px, 1fr); }

.flex-row { flex-direction: row; }

.flex-col { flex-direction: column; }

.flex-col-reverse { flex-direction: column-reverse; }

.flex-wrap { flex-wrap: wrap; }

.place-items-center { place-items: center; }

.items-start { align-items: flex-start; }

.items-end { align-items: flex-end; }

.items-center { align-items: center; }

.items-stretch { align-items: stretch; }

.justify-start { justify-content: flex-start; }

.justify-end { justify-content: flex-end; }

.justify-center { justify-content: center; }

.justify-between { justify-content: space-between; }

.justify-around { justify-content: space-around; }

.gap-0 { gap: 0px; }

.gap-1 { gap: 0.25rem; }

.gap-1\.5 { gap: 0.375rem; }

.gap-16 { gap: 4rem; }

.gap-2 { gap: 0.5rem; }

.gap-2\.5 { gap: 0.625rem; }

.gap-3 { gap: 0.75rem; }

.gap-3\.5 { gap: 0.875rem; }

.gap-4 { gap: 1rem; }

.gap-5 { gap: 1.25rem; }

.gap-6 { gap: 1.5rem; }

.space-x-1 > :not([hidden]) ~ :not([hidden]) { --tw-space-x-reverse:0; margin-left: calc(0.25rem*(1 - var(--tw-space-x-reverse))); margin-right: calc(0.25rem*var(--tw-space-x-reverse)); }

.space-x-1\.5 > :not([hidden]) ~ :not([hidden]) { --tw-space-x-reverse:0; margin-left: calc(0.375rem*(1 - var(--tw-space-x-reverse))); margin-right: calc(0.375rem*var(--tw-space-x-reverse)); }

.space-y-2 > :not([hidden]) ~ :not([hidden]) { --tw-space-y-reverse:0; margin-bottom: calc(0.5rem*var(--tw-space-y-reverse)); margin-top: calc(0.5rem*(1 - var(--tw-space-y-reverse))); }

.self-end { align-self: flex-end; }

.self-center { align-self: center; }

.self-stretch { align-self: stretch; }

.overflow-auto { overflow: auto; }

.overflow-hidden { overflow: hidden; }

.overflow-x-auto { overflow-x: auto; }

.overflow-y-auto { overflow-y: auto; }

.overflow-x-hidden { overflow-x: hidden; }

.overflow-y-hidden { overflow-y: hidden; }

.truncate { overflow: hidden; white-space: nowrap; }

.overflow-ellipsis, .text-ellipsis, .truncate { text-overflow: ellipsis; }

.whitespace-nowrap { white-space: nowrap; }

.\!whitespace-pre { white-space: pre !important; }

.whitespace-pre-line { white-space: pre-line; }

.\!whitespace-pre-wrap { white-space: pre-wrap !important; }

.whitespace-pre-wrap { white-space: pre-wrap; }

.break-words { overflow-wrap: break-word; }

.break-all { word-break: break-all; }

.rounded { border-radius: 0.25rem; }

.rounded-2xl { border-radius: 1rem; }

.rounded-\[5px\] { border-radius: 5px; }

.rounded-full { border-radius: 9999px; }

.rounded-lg { border-radius: 0.5rem; }

.rounded-md { border-radius: 0.375rem; }

.rounded-none { border-radius: 0px; }

.rounded-sm { border-radius: 0.125rem; }

.rounded-xl { border-radius: 0.75rem; }

.rounded-b-lg { border-bottom-left-radius: 0.5rem; border-bottom-right-radius: 0.5rem; }

.rounded-l-md { border-bottom-left-radius: 0.375rem; border-top-left-radius: 0.375rem; }

.rounded-r-md { border-bottom-right-radius: 0.375rem; border-top-right-radius: 0.375rem; }

.rounded-t { border-top-left-radius: 0.25rem; border-top-right-radius: 0.25rem; }

.rounded-t-md { border-top-left-radius: 0.375rem; border-top-right-radius: 0.375rem; }

.rounded-t-xl { border-top-left-radius: 0.75rem; border-top-right-radius: 0.75rem; }

.rounded-br-sm { border-bottom-right-radius: 0.125rem; }

.border { border-width: 1px; }

.border-0 { border-width: 0px; }

.border-\[0\.5px\] { border-width: 0.5px; }

.border-b { border-bottom-width: 1px; }

.border-l { border-left-width: 1px; }

.border-l-4 { border-left-width: 4px; }

.border-r { border-right-width: 1px; }

.border-r-0 { border-right-width: 0px; }

.border-t { border-top-width: 1px; }

.border-none { border-style: none; }

.border-black\/10 { border-color: rgba(0, 0, 0, 0.1); }

.border-black\/20 { border-color: rgba(0, 0, 0, 0.2); }

.border-black\/30 { border-color: rgba(0, 0, 0, 0.3); }

.border-black\/5 { border-color: rgba(0, 0, 0, 0.05); }

.border-gray-100 { --tw-border-opacity:1; border-color: rgba(236,236,241,var(--tw-border-opacity)); }

.border-gray-200 { --tw-border-opacity:1; border-color: rgba(217,217,227,var(--tw-border-opacity)); }

.border-gray-300 { --tw-border-opacity:1; border-color: rgba(197,197,210,var(--tw-border-opacity)); }

.border-gray-400 { --tw-border-opacity:1; border-color: rgba(172,172,190,var(--tw-border-opacity)); }

.border-gray-500 { --tw-border-opacity:1; border-color: rgba(142,142,160,var(--tw-border-opacity)); }

.border-gray-700 { --tw-border-opacity:1; border-color: rgba(64,65,79,var(--tw-border-opacity)); }

.border-gray-800 { --tw-border-opacity:1; border-color: rgba(52,53,65,var(--tw-border-opacity)); }

.border-green-500 { --tw-border-opacity:1; border-color: rgba(25,195,125,var(--tw-border-opacity)); }

.border-indigo-400 { --tw-border-opacity:1; border-color: rgba(129,140,248,var(--tw-border-opacity)); }

.border-orange-500 { --tw-border-opacity:1; border-color: rgba(224,108,43,var(--tw-border-opacity)); }

.border-red-500 { --tw-border-opacity:1; border-color: rgba(239,68,68,var(--tw-border-opacity)); }

.border-transparent { border-color: transparent; }

.border-white { --tw-border-opacity:1; border-color: rgba(255,255,255,var(--tw-border-opacity)); }

.border-white\/20 { border-color: rgba(255, 255, 255, 0.2); }

.\!bg-gray-700 { background-color: rgba(64,65,79,var(--tw-bg-opacity)) !important; }

.\!bg-gray-700, .\!bg-white { --tw-bg-opacity:1 !important; }

.\!bg-white { background-color: rgba(255,255,255,var(--tw-bg-opacity)) !important; }

.bg-\[\#050509\] { --tw-bg-opacity:1; background-color: rgba(5,5,9,var(--tw-bg-opacity)); }

.bg-\[\#FFF3C9\] { --tw-bg-opacity:1; background-color: rgba(255,243,201,var(--tw-bg-opacity)); }

.bg-black { --tw-bg-opacity:1; background-color: rgba(0,0,0,var(--tw-bg-opacity)); }

.bg-blue-100 { --tw-bg-opacity:1; background-color: rgba(219,234,254,var(--tw-bg-opacity)); }

.bg-blue-200 { --tw-bg-opacity:1; background-color: rgba(191,219,254,var(--tw-bg-opacity)); }

.bg-gray-100 { --tw-bg-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.bg-gray-200 { --tw-bg-opacity:1; background-color: rgba(217,217,227,var(--tw-bg-opacity)); }

.bg-gray-300 { --tw-bg-opacity:1; background-color: rgba(197,197,210,var(--tw-bg-opacity)); }

.bg-gray-50 { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.bg-gray-500 { --tw-bg-opacity:1; background-color: rgba(142,142,160,var(--tw-bg-opacity)); }

.bg-gray-500\/90 { background-color: rgba(141, 141, 160, 0.9); }

.bg-gray-600 { --tw-bg-opacity:1; background-color: rgba(86,88,105,var(--tw-bg-opacity)); }

.bg-gray-700 { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.bg-gray-800 { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.bg-gray-900 { --tw-bg-opacity:1; background-color: rgba(32,33,35,var(--tw-bg-opacity)); }

.bg-green-100 { --tw-bg-opacity:1; background-color: rgba(210,244,211,var(--tw-bg-opacity)); }

.bg-green-500 { --tw-bg-opacity:1; background-color: rgba(25,195,125,var(--tw-bg-opacity)); }

.bg-green-500\/10 { background-color: rgba(25, 195, 125, 0.1); }

.bg-green-600 { --tw-bg-opacity:1; background-color: rgba(16,163,127,var(--tw-bg-opacity)); }

.bg-orange-500 { --tw-bg-opacity:1; background-color: rgba(224,108,43,var(--tw-bg-opacity)); }

.bg-orange-500\/10 { background-color: rgba(224, 108, 43, 0.1); }

.bg-red-100 { --tw-bg-opacity:1; background-color: rgba(254,226,226,var(--tw-bg-opacity)); }

.bg-red-200 { --tw-bg-opacity:1; background-color: rgba(254,202,202,var(--tw-bg-opacity)); }

.bg-red-500 { --tw-bg-opacity:1; background-color: rgba(239,68,68,var(--tw-bg-opacity)); }

.bg-red-500\/10 { background-color: rgba(239, 68, 68, 0.1); }

.bg-red-600 { --tw-bg-opacity:1; background-color: rgba(220,38,38,var(--tw-bg-opacity)); }

.bg-transparent { background-color: transparent; }

.bg-white { --tw-bg-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); }

.bg-white\/20 { background-color: rgba(255, 255, 255, 0.2); }

.bg-yellow-100 { --tw-bg-opacity:1; background-color: rgba(254,249,195,var(--tw-bg-opacity)); }

.bg-yellow-200 { --tw-bg-opacity:1; background-color: rgba(250,230,158,var(--tw-bg-opacity)); }

.bg-opacity-75 { --tw-bg-opacity:0.75; }

.bg-gradient-to-l { background-image: linear-gradient(to left,var(--tw-gradient-stops)); }

.bg-gradient-to-t { background-image: linear-gradient(to top,var(--tw-gradient-stops)); }

.from-gray-100 { --tw-gradient-from:#ececf1 var(--tw-gradient-from-position); --tw-gradient-to:rgba(236,236,241,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.from-gray-800 { --tw-gradient-from:#343541 var(--tw-gradient-from-position); --tw-gradient-to:rgba(52,53,65,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.from-gray-900 { --tw-gradient-from:#202123 var(--tw-gradient-from-position); --tw-gradient-to:rgba(32,33,35,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.from-gray-900\/0 { --tw-gradient-from:rgba(32,33,35,0) var(--tw-gradient-from-position); --tw-gradient-to:rgba(32,33,35,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.from-\[60\%\] { --tw-gradient-from-position:60%; }

.to-gray-900 { --tw-gradient-to:#202123 var(--tw-gradient-to-position); }

.bg-contain { background-size: contain; }

.bg-center { background-position: 50% center; }

.bg-no-repeat { background-repeat: no-repeat; }

.fill-gray-800 { fill: rgb(52, 53, 65); }

.object-cover { object-fit: cover; }

.p-0 { padding: 0px; }

.p-0\.5 { padding: 0.125rem; }

.p-1 { padding: 0.25rem; }

.p-2 { padding: 0.5rem; }

.p-3 { padding: 0.75rem; }

.p-4 { padding: 1rem; }

.p-6 { padding: 1.5rem; }

.px-0 { padding-left: 0px; padding-right: 0px; }

.px-0\.5 { padding-left: 0.125rem; padding-right: 0.125rem; }

.px-1 { padding-left: 0.25rem; padding-right: 0.25rem; }

.px-1\.5 { padding-left: 0.375rem; padding-right: 0.375rem; }

.px-2 { padding-left: 0.5rem; padding-right: 0.5rem; }

.px-3 { padding-left: 0.75rem; padding-right: 0.75rem; }

.px-4 { padding-left: 1rem; padding-right: 1rem; }

.px-5 { padding-left: 1.25rem; padding-right: 1.25rem; }

.px-6 { padding-left: 1.5rem; padding-right: 1.5rem; }

.px-8 { padding-left: 2rem; padding-right: 2rem; }

.py-0 { padding-bottom: 0px; padding-top: 0px; }

.py-0\.5 { padding-bottom: 0.125rem; padding-top: 0.125rem; }

.py-1 { padding-bottom: 0.25rem; padding-top: 0.25rem; }

.py-1\.5 { padding-bottom: 0.375rem; padding-top: 0.375rem; }

.py-2 { padding-bottom: 0.5rem; padding-top: 0.5rem; }

.py-3 { padding-bottom: 0.75rem; padding-top: 0.75rem; }

.py-4 { padding-bottom: 1rem; padding-top: 1rem; }

.py-6 { padding-bottom: 1.5rem; padding-top: 1.5rem; }

.py-8 { padding-bottom: 2rem; padding-top: 2rem; }

.py-\[10px\] { padding-bottom: 10px; padding-top: 10px; }

.\!pt-0 { padding-top: 0px !important; }

.pb-0 { padding-bottom: 0px; }

.pb-0\.5 { padding-bottom: 0.125rem; }

.pb-1 { padding-bottom: 0.25rem; }

.pb-2 { padding-bottom: 0.5rem; }

.pb-3 { padding-bottom: 0.75rem; }

.pb-4 { padding-bottom: 1rem; }

.pb-8 { padding-bottom: 2rem; }

.pl-1 { padding-left: 0.25rem; }

.pl-10 { padding-left: 2.5rem; }

.pl-12 { padding-left: 3rem; }

.pl-3 { padding-left: 0.75rem; }

.pl-4 { padding-left: 1rem; }

.pl-5 { padding-left: 1.25rem; }

.pl-6 { padding-left: 1.5rem; }

.pr-1 { padding-right: 0.25rem; }

.pr-1\.5 { padding-right: 0.375rem; }

.pr-10 { padding-right: 2.5rem; }

.pr-11 { padding-right: 2.75rem; }

.pr-12 { padding-right: 3rem; }

.pr-14 { padding-right: 3.5rem; }

.pr-2 { padding-right: 0.5rem; }

.pr-3 { padding-right: 0.75rem; }

.pr-5 { padding-right: 1.25rem; }

.pr-6 { padding-right: 1.5rem; }

.pr-7 { padding-right: 1.75rem; }

.pr-9 { padding-right: 2.25rem; }

.pr-\[4\.5rem\] { padding-right: 4.5rem; }

.pt-1 { padding-top: 0.25rem; }

.pt-2 { padding-top: 0.5rem; }

.pt-20 { padding-top: 5rem; }

.pt-28 { padding-top: 7rem; }

.pt-3 { padding-top: 0.75rem; }

.pt-4 { padding-top: 1rem; }

.pt-40 { padding-top: 10rem; }

.pt-5 { padding-top: 1.25rem; }

.pt-\[67\%\] { padding-top: 67%; }

.text-left { text-align: left; }

.text-center { text-align: center; }

.text-right { text-align: right; }

.align-top { vertical-align: top; }

.font-mono { font-family: "SÃ¶hne Mono", Monaco, "Andale Mono", "Ubuntu Mono", monospace; }

.font-sans { font-family: SÃ¶hne, ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, Ubuntu, Cantarell, "Noto Sans", sans-serif, "Helvetica Neue", Arial, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji"; }

.text-2xl { font-size: 1.5rem; line-height: 2rem; }

.text-3xl { font-size: 1.875rem; line-height: 2.25rem; }

.text-4xl { font-size: 2.25rem; line-height: 2.5rem; }

.text-\[10px\] { font-size: 10px; }

.text-\[28px\] { font-size: 28px; }

.text-base { font-size: 1rem; line-height: 1.5rem; }

.text-lg { font-size: 1.125rem; line-height: 1.75rem; }

.text-sm { font-size: 0.875rem; line-height: 1.25rem; }

.text-xl { font-size: 1.25rem; line-height: 1.75rem; }

.text-xs { font-size: 0.75rem; line-height: 1rem; }

.font-bold { font-weight: 700; }

.font-medium { font-weight: 500; }

.font-normal { font-weight: 400; }

.font-semibold { font-weight: 600; }

.uppercase { text-transform: uppercase; }

.capitalize { text-transform: capitalize; }

.normal-case { text-transform: none; }

.italic { font-style: italic; }

.leading-3 { line-height: 0.75rem; }

.leading-5 { line-height: 1.25rem; }

.leading-6 { line-height: 1.5rem; }

.leading-normal { line-height: 1.5; }

.leading-tight { line-height: 1.25; }

.tracking-wide { letter-spacing: 0.025em; }

.tracking-widest { letter-spacing: 0.1em; }

.text-\[\#756B5C\] { --tw-text-opacity:1; color: rgba(117,107,92,var(--tw-text-opacity)); }

.text-black { --tw-text-opacity:1; color: rgba(0,0,0,var(--tw-text-opacity)); }

.text-black\/50 { color: rgba(0, 0, 0, 0.5); }

.text-black\/60 { color: rgba(0, 0, 0, 0.6); }

.text-black\/70 { color: rgba(0, 0, 0, 0.7); }

.text-blue-400 { --tw-text-opacity:1; color: rgba(58,136,255,var(--tw-text-opacity)); }

.text-blue-500 { --tw-text-opacity:1; color: rgba(69,89,164,var(--tw-text-opacity)); }

.text-blue-600 { --tw-text-opacity:1; color: rgba(37,99,235,var(--tw-text-opacity)); }

.text-blue-700 { --tw-text-opacity:1; color: rgba(29,78,216,var(--tw-text-opacity)); }

.text-brand-green { --tw-text-opacity:1; color: rgba(25,195,125,var(--tw-text-opacity)); }

.text-brand-purple { --tw-text-opacity:1; color: rgba(171,104,255,var(--tw-text-opacity)); }

.text-gray-100 { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.text-gray-200 { --tw-text-opacity:1; color: rgba(217,217,227,var(--tw-text-opacity)); }

.text-gray-300 { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.text-gray-400 { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.text-gray-500 { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.text-gray-600 { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

.text-gray-700 { --tw-text-opacity:1; color: rgba(64,65,79,var(--tw-text-opacity)); }

.text-gray-800 { --tw-text-opacity:1; color: rgba(52,53,65,var(--tw-text-opacity)); }

.text-gray-900 { --tw-text-opacity:1; color: rgba(32,33,35,var(--tw-text-opacity)); }

.text-green-500 { --tw-text-opacity:1; color: rgba(25,195,125,var(--tw-text-opacity)); }

.text-green-600 { --tw-text-opacity:1; color: rgba(16,163,127,var(--tw-text-opacity)); }

.text-green-700 { --tw-text-opacity:1; color: rgba(26,127,100,var(--tw-text-opacity)); }

.text-indigo-500 { --tw-text-opacity:1; color: rgba(99,102,241,var(--tw-text-opacity)); }

.text-orange-500 { --tw-text-opacity:1; color: rgba(224,108,43,var(--tw-text-opacity)); }

.text-red-300 { --tw-text-opacity:1; color: rgba(252,165,165,var(--tw-text-opacity)); }

.text-red-500 { --tw-text-opacity:1; color: rgba(239,68,68,var(--tw-text-opacity)); }

.text-red-600 { --tw-text-opacity:1; color: rgba(220,38,38,var(--tw-text-opacity)); }

.text-red-700 { --tw-text-opacity:1; color: rgba(185,28,28,var(--tw-text-opacity)); }

.text-red-800 { --tw-text-opacity:1; color: rgba(153,27,27,var(--tw-text-opacity)); }

.text-white { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.text-white\/50 { color: rgba(255, 255, 255, 0.5); }

.text-white\/80 { color: rgba(255, 255, 255, 0.8); }

.text-yellow-400 { --tw-text-opacity:1; color: rgba(255,198,87,var(--tw-text-opacity)); }

.text-yellow-500 { --tw-text-opacity:1; color: rgba(234,179,8,var(--tw-text-opacity)); }

.text-yellow-700 { --tw-text-opacity:1; color: rgba(161,98,7,var(--tw-text-opacity)); }

.text-yellow-900 { --tw-text-opacity:1; color: rgba(146,114,1,var(--tw-text-opacity)); }

.underline { text-decoration-line: underline; }

.\!no-underline { text-decoration-line: none !important; }

.antialiased { -webkit-font-smoothing: antialiased; }

.placeholder-gray-500::-webkit-input-placeholder { --tw-placeholder-opacity:1; color: rgba(142,142,160,var(--tw-placeholder-opacity)); }

.placeholder-gray-500::placeholder { --tw-placeholder-opacity:1; color: rgba(142,142,160,var(--tw-placeholder-opacity)); }

.opacity-0 { opacity: 0; }

.opacity-100 { opacity: 1; }

.opacity-20 { opacity: 0.2; }

.opacity-30 { opacity: 0.3; }

.opacity-50 { opacity: 0.5; }

.opacity-70 { opacity: 0.7; }

.opacity-80 { opacity: 0.8; }

.\!shadow-none { --tw-shadow:0 0 transparent !important; --tw-shadow-colored:0 0 transparent !important; box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow) !important; }

.shadow { --tw-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px -1px rgba(0,0,0,0.1); --tw-shadow-colored:0 1px 3px 0 var(--tw-shadow-color),0 1px 2px -1px var(--tw-shadow-color); }

.shadow, .shadow-\[0_0\.5px_2px_rgba\(0\,0\,0\,0\.15\)\] { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-\[0_0\.5px_2px_rgba\(0\,0\,0\,0\.15\)\] { --tw-shadow:0 0.5px 2px rgba(0,0,0,0.15); --tw-shadow-colored:0 0.5px 2px var(--tw-shadow-color); }

.shadow-\[0_1px_2px_rgba\(0\,0\,0\,0\.45\)\] { --tw-shadow:0 1px 2px rgba(0,0,0,0.45); --tw-shadow-colored:0 1px 2px var(--tw-shadow-color); }

.shadow-\[0_1px_2px_rgba\(0\,0\,0\,0\.45\)\], .shadow-\[0_1px_7px_0_rgba\(0\,0\,0\,0\.03\)\] { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-\[0_1px_7px_0_rgba\(0\,0\,0\,0\.03\)\] { --tw-shadow:0 1px 7px 0 rgba(0,0,0,0.03); --tw-shadow-colored:0 1px 7px 0 var(--tw-shadow-color); }

.shadow-\[0_1px_7px_0px_rgba\(0\,0\,0\,0\.06\)\] { --tw-shadow:0 1px 7px 0px rgba(0,0,0,0.06); --tw-shadow-colored:0 1px 7px 0px var(--tw-shadow-color); }

.shadow-\[0_1px_7px_0px_rgba\(0\,0\,0\,0\.06\)\], .shadow-\[0_2px_12px_0px_rgba\(0\,0\,0\,0\.08\)\] { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-\[0_2px_12px_0px_rgba\(0\,0\,0\,0\.08\)\] { --tw-shadow:0 2px 12px 0px rgba(0,0,0,0.08); --tw-shadow-colored:0 2px 12px 0px var(--tw-shadow-color); }

.shadow-\[0_2px_24px_rgba\(0\,0\,0\,0\.05\)\] { --tw-shadow:0 2px 24px rgba(0,0,0,0.05); --tw-shadow-colored:0 2px 24px var(--tw-shadow-color); }

.shadow-\[0_2px_24px_rgba\(0\,0\,0\,0\.05\)\], .shadow-lg { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-lg { --tw-shadow:0 10px 15px -3px rgba(0,0,0,0.1),0 4px 6px -4px rgba(0,0,0,0.1); --tw-shadow-colored:0 10px 15px -3px var(--tw-shadow-color),0 4px 6px -4px var(--tw-shadow-color); }

.shadow-md { --tw-shadow:0 4px 6px -1px rgba(0,0,0,0.1),0 2px 4px -2px rgba(0,0,0,0.1); --tw-shadow-colored:0 4px 6px -1px var(--tw-shadow-color),0 2px 4px -2px var(--tw-shadow-color); }

.shadow-md, .shadow-sm { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-sm { --tw-shadow:0 1px 2px 0 rgba(0,0,0,0.05); --tw-shadow-colored:0 1px 2px 0 var(--tw-shadow-color); }

.shadow-xl { --tw-shadow:0 20px 25px -5px rgba(0,0,0,0.1),0 8px 10px -6px rgba(0,0,0,0.1); --tw-shadow-colored:0 20px 25px -5px var(--tw-shadow-color),0 8px 10px -6px var(--tw-shadow-color); }

.shadow-xl, .shadow-xs { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-xs { --tw-shadow:0 0 15px rgba(0,0,0,0.1); --tw-shadow-colored:0 0 15px var(--tw-shadow-color); }

.shadow-xxs { --tw-shadow:0 1px 7px 0 rgba(0,0,0,0.03); --tw-shadow-colored:0 1px 7px 0 var(--tw-shadow-color); box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-indigo-400 { --tw-shadow-color:#818cf8; --tw-shadow:var(--tw-shadow-colored); }

.outline-none { outline: transparent solid 2px; outline-offset: 2px; }

.ring-1 { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.ring-inset { --tw-ring-inset:inset; }

.ring-black\/10 { --tw-ring-color:rgba(0,0,0,0.1); }

.filter { filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow); }

.filter-none { filter: none; }

.transition { transition-duration: 0.15s; transition-property: color, background-color, border-color, text-decoration-color, fill, stroke, opacity, box-shadow, transform, filter, backdrop-filter, -webkit-transform, -webkit-filter, -webkit-backdrop-filter; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-all { transition-duration: 0.15s; transition-property: all; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-colors { transition-duration: 0.15s; transition-property: color, background-color, border-color, text-decoration-color, fill, stroke; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-opacity { transition-duration: 0.15s; transition-property: opacity; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-transform { transition-duration: 0.15s; transition-property: transform, -webkit-transform; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-width { transition-duration: 0.15s; transition-property: width; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.duration-100 { transition-duration: 0.1s; }

.duration-150 { transition-duration: 0.15s; }

.duration-200 { transition-duration: 0.2s; }

.duration-300 { transition-duration: 0.3s; }

.duration-500 { transition-duration: 0.5s; }

.ease-in { transition-timing-function: cubic-bezier(0.4, 0, 1, 1); }

.ease-in-out { transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.ease-linear { transition-timing-function: linear; }

.ease-out { transition-timing-function: cubic-bezier(0, 0, 0.2, 1); }

.will-change-\[opacity\,transform\] { will-change: opacity, transform; }

.will-change-transform { will-change: transform; }

body, html { height: 100%; }

.dark body, .dark html { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

#intercom-container { display: none; }

#__next, #root { height: 100%; }

.markdown ol { counter-reset: item 0; }

.markdown ul li { display: block; margin: 0px; position: relative; }

.markdown ul li::before { content: "â¢"; font-size: 0.875rem; line-height: 1.25rem; margin-left: -1rem; position: absolute; }

.markdown { max-width: none; }

.markdown h1, .markdown h2 { font-weight: 600; }

.markdown h2 { margin-bottom: 1rem; margin-top: 2rem; }

.markdown h3 { font-weight: 600; }

.markdown h3, .markdown h4 { margin-bottom: 0.5rem; margin-top: 1rem; }

.markdown h4 { font-weight: 400; }

.markdown h5 { font-weight: 600; }

.markdown blockquote { --tw-border-opacity:1; border-color: rgba(142,142,160,var(--tw-border-opacity)); border-left-width: 2px; line-height: 1rem; padding-left: 1rem; }

.markdown ol, .markdown ul { display: flex; flex-direction: column; padding-left: 1rem; }

.markdown ol li, .markdown ol li > p, .markdown ol ol, .markdown ol ul, .markdown ul li, .markdown ul li > p, .markdown ul ol, .markdown ul ul { margin: 0px; }

.markdown table { --tw-border-spacing-x:0px; --tw-border-spacing-y:0px; border-collapse: separate; border-spacing: var(--tw-border-spacing-x) var(--tw-border-spacing-y); width: 100%; }

.markdown th { background-color: rgba(236, 236, 241, 0.2); border-bottom-width: 1px; border-left-width: 1px; border-top-width: 1px; padding: 0.25rem 0.75rem; }

.markdown th:first-child { border-top-left-radius: 0.375rem; }

.markdown th:last-child { border-right-width: 1px; border-top-right-radius: 0.375rem; }

.markdown td { border-bottom-width: 1px; border-left-width: 1px; padding: 0.25rem 0.75rem; }

.markdown td:last-child { border-right-width: 1px; }

.markdown tbody tr:last-child td:first-child { border-bottom-left-radius: 0.375rem; }

.markdown tbody tr:last-child td:last-child { border-bottom-right-radius: 0.375rem; }

.markdown a { text-decoration-line: underline; text-underline-offset: 2px; }

.conversation-item-time::before { content: attr(data-time); }

button.scroll-convo { display: none; }

@-webkit-keyframes blink { 
  100% { visibility: hidden; }
}

@keyframes blink { 
  100% { visibility: hidden; }
}

.animate-flash { animation: 2s steps(60, start) 0s 1 normal none running flash; }

@-webkit-keyframes flash { 
  0% { background-color: rgba(255, 255, 255, 0.4); }
}

@keyframes flash { 
  0% { background-color: rgba(255, 255, 255, 0.4); }
}

.result-streaming > :not(ol):not(ul):not(pre):last-child::after, .result-streaming > ol:last-child li:last-child::after, .result-streaming > pre:last-child code::after, .result-streaming > ul:last-child li:last-child::after { animation: 1s steps(5, start) 0s infinite normal none running blink; content: "â"; margin-left: 0.25rem; vertical-align: baseline; }

@-webkit-keyframes toast-open { 
  0% { opacity: 0; transform: translateY(-100%); }
  100% { transform: translateY(0px); }
}

@keyframes toast-open { 
  0% { opacity: 0; transform: translateY(-100%); }
  100% { transform: translateY(0px); }
}

@-webkit-keyframes toast-close { 
  0% { opacity: 1; }
  100% { opacity: 0; }
}

@keyframes toast-close { 
  0% { opacity: 1; }
  100% { opacity: 0; }
}

.toast-root { align-items: center; display: flex; flex-direction: column; height: 0px; transition: all 0.24s cubic-bezier(0, 0, 0.2, 1) 0s; }

.toast-root[data-state="entered"], .toast-root[data-state="entering"] { animation: 0.24s cubic-bezier(0.175, 0.885, 0.32, 1.175) 0s 1 normal both running toast-open; }

.toast-root[data-state="exiting"] { animation: 0.12s cubic-bezier(0.4, 0, 1, 1) 0s 1 normal both running toast-close; }

.toast-root .alert-root { box-shadow: rgba(67, 90, 111, 0.3) 0px 0px 1px, rgba(67, 90, 111, 0.3) 0px 5px 8px -4px; flex-shrink: 0; pointer-events: all; }

.interact-bounce { transition-duration: 0.15s; transition-property: transform, -webkit-transform; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.interact-bounce:hover { --tw-scale-x:1.05; --tw-scale-y:1.05; }

.interact-bounce:active, .interact-bounce:hover { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.interact-bounce:active { --tw-scale-x:0.9; --tw-scale-y:0.9; }

.PopoverContent { z-index: 1000; }

.dark .dark\:prose-invert { --tw-prose-body:var(--tw-prose-invert-body); --tw-prose-headings:var(--tw-prose-invert-headings); --tw-prose-lead:var(--tw-prose-invert-lead); --tw-prose-links:var(--tw-prose-invert-links); --tw-prose-bold:var(--tw-prose-invert-bold); --tw-prose-counters:var(--tw-prose-invert-counters); --tw-prose-bullets:var(--tw-prose-invert-bullets); --tw-prose-hr:var(--tw-prose-invert-hr); --tw-prose-quotes:var(--tw-prose-invert-quotes); --tw-prose-quote-borders:var(--tw-prose-invert-quote-borders); --tw-prose-captions:var(--tw-prose-invert-captions); --tw-prose-code:var(--tw-prose-invert-code); --tw-prose-pre-code:var(--tw-prose-invert-pre-code); --tw-prose-pre-bg:var(--tw-prose-invert-pre-bg); --tw-prose-th-borders:var(--tw-prose-invert-th-borders); --tw-prose-td-borders:var(--tw-prose-invert-td-borders); }

.placeholder\:text-gray-300::-webkit-input-placeholder { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.placeholder\:text-gray-300::placeholder { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.after\:content-\[\'\"\'\]::after, .before\:content-\[\'\"\'\]::before { --tw-content:"\""; content: var(--tw-content); }

.last\:mb-2:last-child { margin-bottom: 0.5rem; }

.last\:border-0:last-child { border-width: 0px; }

.last-of-type\:border-b-0:last-of-type { border-bottom-width: 0px; }

.checked\:border-blue-600:checked { --tw-border-opacity:1; border-color: rgba(37,99,235,var(--tw-border-opacity)); }

.checked\:bg-blue-600:checked { --tw-bg-opacity:1; background-color: rgba(37,99,235,var(--tw-bg-opacity)); }

.focus-within\:z-10[focus-within] { z-index: 10; }

.focus-within\:z-10:focus-within { z-index: 10; }

.focus-within\:border-indigo-600[focus-within] { --tw-border-opacity:1; border-color: rgba(79,70,229,var(--tw-border-opacity)); }

.focus-within\:border-indigo-600:focus-within { --tw-border-opacity:1; border-color: rgba(79,70,229,var(--tw-border-opacity)); }

.focus-within\:ring-1[focus-within] { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus-within\:ring-1:focus-within { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus-within\:ring-indigo-600[focus-within] { --tw-ring-opacity:1; --tw-ring-color:rgba(79,70,229,var(--tw-ring-opacity)); }

.focus-within\:ring-indigo-600:focus-within { --tw-ring-opacity:1; --tw-ring-color:rgba(79,70,229,var(--tw-ring-opacity)); }

.hover\:border-black\/10:hover { border-color: rgba(0, 0, 0, 0.1); }

.hover\:border-gray-700:hover { --tw-border-opacity:1; border-color: rgba(64,65,79,var(--tw-border-opacity)); }

.hover\:\!bg-gray-50:hover { --tw-bg-opacity:1 !important; background-color: rgba(247,247,248,var(--tw-bg-opacity)) !important; }

.hover\:bg-\[\#2A2B32\]:hover { --tw-bg-opacity:1; background-color: rgba(42,43,50,var(--tw-bg-opacity)); }

.hover\:bg-black:hover { --tw-bg-opacity:1; background-color: rgba(0,0,0,var(--tw-bg-opacity)); }

.hover\:bg-black\/10:hover { background-color: rgba(0, 0, 0, 0.1); }

.hover\:bg-gray-100:hover { --tw-bg-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.hover\:bg-gray-200:hover { --tw-bg-opacity:1; background-color: rgba(217,217,227,var(--tw-bg-opacity)); }

.hover\:bg-gray-300:hover { --tw-bg-opacity:1; background-color: rgba(197,197,210,var(--tw-bg-opacity)); }

.hover\:bg-gray-50:hover { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.hover\:bg-gray-50\/50:hover { background-color: rgba(247, 247, 248, 0.5); }

.hover\:bg-gray-500\/10:hover { background-color: rgba(141, 141, 160, 0.1); }

.hover\:bg-gray-700:hover { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.hover\:bg-gray-800:hover { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.hover\:bg-green-100:hover { --tw-bg-opacity:1; background-color: rgba(210,244,211,var(--tw-bg-opacity)); }

.hover\:pr-14:hover { padding-right: 3.5rem; }

.hover\:pr-4:hover { padding-right: 1rem; }

.hover\:text-black\/50:hover { color: rgba(0, 0, 0, 0.5); }

.hover\:text-black\/70:hover { color: rgba(0, 0, 0, 0.7); }

.hover\:text-blue-600:hover { --tw-text-opacity:1; color: rgba(37,99,235,var(--tw-text-opacity)); }

.hover\:text-gray-500:hover { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.hover\:text-gray-600:hover { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

.hover\:text-gray-700:hover { --tw-text-opacity:1; color: rgba(64,65,79,var(--tw-text-opacity)); }

.hover\:text-gray-800:hover { --tw-text-opacity:1; color: rgba(52,53,65,var(--tw-text-opacity)); }

.hover\:text-gray-900:hover { --tw-text-opacity:1; color: rgba(32,33,35,var(--tw-text-opacity)); }

.hover\:text-white:hover { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.hover\:\!opacity-100:hover { opacity: 1 !important; }

.hover\:opacity-100:hover { opacity: 1; }

.hover\:opacity-70:hover { opacity: 0.7; }

.hover\:opacity-75:hover { opacity: 0.75; }

.hover\:opacity-80:hover { opacity: 0.8; }

.focus\:z-10:focus { z-index: 10; }

.focus\:border-green-500:focus { --tw-border-opacity:1; border-color: rgba(25,195,125,var(--tw-border-opacity)); }

.focus\:border-green-600:focus { --tw-border-opacity:1; border-color: rgba(16,163,127,var(--tw-border-opacity)); }

.focus\:border-indigo-500:focus { --tw-border-opacity:1; border-color: rgba(99,102,241,var(--tw-border-opacity)); }

.focus\:bg-gray-50:focus { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.focus\:outline-none:focus { outline: transparent solid 2px; outline-offset: 2px; }

.focus\:ring-0:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(var(--tw-ring-offset-width)) var(--tw-ring-color); }

.focus\:ring-0:focus, .focus\:ring-1:focus { box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus\:ring-1:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); }

.focus\:ring-2:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus\:ring-inset:focus { --tw-ring-inset:inset; }

.focus\:ring-gray-200:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(217,217,227,var(--tw-ring-opacity)); }

.focus\:ring-gray-500:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(142,142,160,var(--tw-ring-opacity)); }

.focus\:ring-green-500:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(25,195,125,var(--tw-ring-opacity)); }

.focus\:ring-green-600:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(16,163,127,var(--tw-ring-opacity)); }

.focus\:ring-indigo-500:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(99,102,241,var(--tw-ring-opacity)); }

.focus\:ring-white:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(255,255,255,var(--tw-ring-opacity)); }

.focus\:ring-offset-2:focus { --tw-ring-offset-width:2px; }

.focus-visible\:ring-0.focus-visible { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus-visible\:ring-0:focus-visible { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.enabled\:bg-brand-purple:enabled { --tw-bg-opacity:1; background-color: rgba(171,104,255,var(--tw-bg-opacity)); }

.enabled\:hover\:text-gray-700:hover:enabled { --tw-text-opacity:1; color: rgba(64,65,79,var(--tw-text-opacity)); }

.disabled\:bottom-0:disabled { bottom: 0px; }

.disabled\:bottom-0\.5:disabled { bottom: 0.125rem; }

.disabled\:cursor-auto:disabled { cursor: auto; }

.disabled\:text-gray-300:disabled { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.disabled\:text-gray-400:disabled { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.disabled\:opacity-20:disabled { opacity: 0.2; }

.disabled\:opacity-40:disabled { opacity: 0.4; }

.disabled\:hover\:bg-gray-900:hover:disabled { --tw-bg-opacity:1; background-color: rgba(32,33,35,var(--tw-bg-opacity)); }

.group:hover .group-hover\:visible { visibility: visible; }

.group:hover .group-hover\:block { display: block; }

.group:hover .group-hover\:hidden { display: none; }

.group\/options:hover .group-hover\/options\:bg-transparent { background-color: transparent; }

.group\/toggle:hover .group-hover\/toggle\:bg-red-500 { --tw-bg-opacity:1; background-color: rgba(239,68,68,var(--tw-bg-opacity)); }

.group:hover .group-hover\:bg-black { --tw-bg-opacity:1; background-color: rgba(0,0,0,var(--tw-bg-opacity)); }

.group:hover .group-hover\:from-\[\#2A2B32\] { --tw-gradient-from:#2a2b32 var(--tw-gradient-from-position); --tw-gradient-to:rgba(42,43,50,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.group\/button:hover .group-hover\/button\:text-brand-green { --tw-text-opacity:1; color: rgba(25,195,125,var(--tw-text-opacity)); }

.group\/button:hover .group-hover\/button\:text-brand-purple { --tw-text-opacity:1; color: rgba(171,104,255,var(--tw-text-opacity)); }

.group\/button:hover .group-hover\/button\:text-orange-500 { --tw-text-opacity:1; color: rgba(224,108,43,var(--tw-text-opacity)); }

.group\/button:hover .group-hover\/button\:text-red-500 { --tw-text-opacity:1; color: rgba(239,68,68,var(--tw-text-opacity)); }

.group\/option:hover .group-hover\/option\:\!text-brand-green { --tw-text-opacity:1 !important; color: rgba(25,195,125,var(--tw-text-opacity)) !important; }

.group\/option:hover .group-hover\/option\:\!text-brand-purple { --tw-text-opacity:1 !important; color: rgba(171,104,255,var(--tw-text-opacity)) !important; }

.group\/option:hover .group-hover\/option\:text-gray-100 { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.group\/option:hover .group-hover\/option\:text-gray-800 { --tw-text-opacity:1; color: rgba(52,53,65,var(--tw-text-opacity)); }

.group:hover .group-hover\:text-gray-500, .group\/options:hover .group-hover\/options\:text-gray-500 { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.group\/options:hover .group-hover\/options\:opacity-0 { opacity: 0; }

.group:hover .group-hover\:opacity-100 { opacity: 1; }

.group:hover .group-hover\:opacity-50 { opacity: 0.5; }

.group-ui-open\:bg-gray-800.group[data-headlessui-state~="open"] { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.group:where([data-headlessui-state~="open"]) .group-ui-open\:bg-gray-800 { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.radix-highlighted\:bg-gray-50[data-highlighted] { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.radix-state-active\:bg-gray-800[data-state="active"] { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.radix-state-active\:text-white[data-state="active"] { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.group[data-state="active"] .group-radix-state-active\:fill-white { fill: rgb(255, 255, 255); }

.radix-state-checked\:translate-x-\[19px\][data-state="checked"] { --tw-translate-x:19px; transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.radix-state-checked\:bg-green-600[data-state="checked"] { --tw-bg-opacity:1; background-color: rgba(16,163,127,var(--tw-bg-opacity)); }

.radix-state-open\:text-gray-600[data-state="open"] { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

@-webkit-keyframes slideDownAndFade { 
  0% { opacity: 0; transform: translateY(-2px); }
  100% { opacity: 1; transform: translateY(0px); }
}

@keyframes slideDownAndFade { 
  0% { opacity: 0; transform: translateY(-2px); }
  100% { opacity: 1; transform: translateY(0px); }
}

.radix-side-bottom\:animate-slideDownAndFade[data-side="bottom"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideDownAndFade; }

@keyframes slideLeftAndFade { 
  0% { opacity: 0; transform: translateX(2px); }
  100% { opacity: 1; transform: translateX(0px); }
}

.radix-side-left\:animate-slideLeftAndFade[data-side="left"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideLeftAndFade; }

@-webkit-keyframes slideRightAndFade { 
  0% { opacity: 0; transform: translateX(-2px); }
  100% { opacity: 1; transform: translateX(0px); }
}

@keyframes slideRightAndFade { 
  0% { opacity: 0; transform: translateX(-2px); }
  100% { opacity: 1; transform: translateX(0px); }
}

.radix-side-right\:animate-slideRightAndFade[data-side="right"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideRightAndFade; }

@-webkit-keyframes slideUpAndFade { 
  0% { opacity: 0; transform: translateY(2px); }
  100% { opacity: 1; transform: translateY(0px); }
}

@keyframes slideUpAndFade { 
  0% { opacity: 0; transform: translateY(2px); }
  100% { opacity: 1; transform: translateY(0px); }
}

.radix-side-top\:animate-slideUpAndFade[data-side="top"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideUpAndFade; }

.dark .dark\:border-\[\#4E4F60\] { --tw-border-opacity:1; border-color: rgba(78,79,96,var(--tw-border-opacity)); }

.dark .dark\:border-black\/20 { border-color: rgba(0, 0, 0, 0.2); }

.dark .dark\:border-gray-300 { --tw-border-opacity:1; border-color: rgba(197,197,210,var(--tw-border-opacity)); }

.dark .dark\:border-gray-600 { --tw-border-opacity:1; border-color: rgba(86,88,105,var(--tw-border-opacity)); }

.dark .dark\:border-gray-700 { --tw-border-opacity:1; border-color: rgba(64,65,79,var(--tw-border-opacity)); }

.dark .dark\:border-gray-800 { --tw-border-opacity:1; border-color: rgba(52,53,65,var(--tw-border-opacity)); }

.dark .dark\:border-gray-900\/50 { border-color: rgba(32, 33, 35, 0.5); }

.dark .dark\:border-white\/10 { border-color: rgba(255, 255, 255, 0.1); }

.dark .dark\:border-white\/20 { border-color: rgba(255, 255, 255, 0.2); }

.dark .dark\:border-white\/30 { border-color: rgba(255, 255, 255, 0.3); }

.dark .dark\:bg-\[\#272832\] { --tw-bg-opacity:1; background-color: rgba(39,40,50,var(--tw-bg-opacity)); }

.dark .dark\:bg-\[\#444654\] { --tw-bg-opacity:1; background-color: rgba(68,70,84,var(--tw-bg-opacity)); }

.dark .dark\:bg-black { --tw-bg-opacity:1; background-color: rgba(0,0,0,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-50 { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-500 { --tw-bg-opacity:1; background-color: rgba(142,142,160,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-600 { --tw-bg-opacity:1; background-color: rgba(86,88,105,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-700 { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-800 { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-800\/30 { background-color: rgba(52, 53, 65, 0.3); }

.dark .dark\:bg-gray-800\/90 { background-color: rgba(52, 53, 65, 0.9); }

.dark .dark\:bg-gray-900 { --tw-bg-opacity:1; background-color: rgba(32,33,35,var(--tw-bg-opacity)); }

.dark .dark\:bg-red-200 { --tw-bg-opacity:1; background-color: rgba(254,202,202,var(--tw-bg-opacity)); }

.dark .dark\:bg-transparent { background-color: transparent; }

.dark .dark\:bg-white { --tw-bg-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); }

.dark .dark\:bg-white\/10 { background-color: rgba(255, 255, 255, 0.1); }

.dark .dark\:bg-white\/5 { background-color: rgba(255, 255, 255, 0.05); }

.dark .dark\:from-gray-700 { --tw-gradient-from:#40414f var(--tw-gradient-from-position); --tw-gradient-to:rgba(64,65,79,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.dark .dark\:fill-gray-500 { fill: rgb(142, 142, 160); }

.dark .dark\:text-blue-400 { --tw-text-opacity:1; color: rgba(58,136,255,var(--tw-text-opacity)); }

.dark .dark\:text-blue-600 { --tw-text-opacity:1; color: rgba(37,99,235,var(--tw-text-opacity)); }

.dark .dark\:text-gray-100 { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.dark .dark\:text-gray-200 { --tw-text-opacity:1; color: rgba(217,217,227,var(--tw-text-opacity)); }

.dark .dark\:text-gray-300 { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.dark .dark\:text-gray-400 { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .dark\:text-gray-500 { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.dark .dark\:text-gray-600 { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

.dark .dark\:text-gray-700 { --tw-text-opacity:1; color: rgba(64,65,79,var(--tw-text-opacity)); }

.dark .dark\:text-gray-900 { --tw-text-opacity:1; color: rgba(32,33,35,var(--tw-text-opacity)); }

.dark .dark\:text-red-500 { --tw-text-opacity:1; color: rgba(239,68,68,var(--tw-text-opacity)); }

.dark .dark\:text-red-800 { --tw-text-opacity:1; color: rgba(153,27,27,var(--tw-text-opacity)); }

.dark .dark\:text-white { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.dark .dark\:text-white\/70 { color: rgba(255, 255, 255, 0.7); }

.dark .dark\:opacity-100 { opacity: 1; }

.dark .dark\:shadow-xs { --tw-shadow:0 0 15px rgba(0,0,0,0.1); --tw-shadow-colored:0 0 15px var(--tw-shadow-color); box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.dark .dark\:ring-white\/20 { --tw-ring-color:hsla(0,0%,100%,0.2); }

.dark .dark\:last\:border-0:last-child { border-width: 0px; }

.dark .dark\:hover\:border-white\/10:hover { border-color: rgba(255, 255, 255, 0.1); }

.dark .dark\:hover\:\!bg-gray-700:hover { --tw-bg-opacity:1 !important; background-color: rgba(64,65,79,var(--tw-bg-opacity)) !important; }

.dark .dark\:hover\:bg-gray-200:hover { --tw-bg-opacity:1; background-color: rgba(217,217,227,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-gray-500\/10:hover { background-color: rgba(141, 141, 160, 0.1); }

.dark .dark\:hover\:bg-gray-600:hover { --tw-bg-opacity:1; background-color: rgba(86,88,105,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-gray-700:hover { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-gray-700\/50:hover { background-color: rgba(64, 65, 79, 0.5); }

.dark .dark\:hover\:bg-gray-800:hover { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-gray-900:hover { --tw-bg-opacity:1; background-color: rgba(32,33,35,var(--tw-bg-opacity)); }

:is(.dark .hover\:dark\:bg-white\/10):hover { background-color: rgba(255, 255, 255, 0.1); }

.dark .dark\:hover\:text-blue-600:hover { --tw-text-opacity:1; color: rgba(37,99,235,var(--tw-text-opacity)); }

.dark .dark\:hover\:text-gray-200:hover { --tw-text-opacity:1; color: rgba(217,217,227,var(--tw-text-opacity)); }

.dark .dark\:hover\:text-gray-400:hover { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .dark\:hover\:text-white:hover { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.dark .dark\:hover\:text-white\/50:hover { color: rgba(255, 255, 255, 0.5); }

:is(.dark .hover\:dark\:text-gray-100):hover { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.dark .dark\:focus\:border-white:focus { --tw-border-opacity:1; border-color: rgba(255,255,255,var(--tw-border-opacity)); }

.dark .dark\:focus\:bg-gray-800:focus { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.dark .dark\:focus\:ring-gray-600:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(86,88,105,var(--tw-ring-opacity)); }

.dark .dark\:focus\:ring-white:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(255,255,255,var(--tw-ring-opacity)); }

:is(.dark .enabled\:dark\:hover\:text-gray-400:hover):enabled { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .dark\:disabled\:text-gray-400:disabled { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .dark\:disabled\:hover\:bg-transparent:hover:disabled { background-color: transparent; }

.dark .dark\:disabled\:hover\:bg-white:hover:disabled { --tw-bg-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); }

:is(.dark .disabled\:dark\:hover\:text-gray-400:hover):disabled { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .group\/option:hover .dark\:group-hover\/option\:text-gray-100 { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.dark .dark\:radix-highlighted\:bg-gray-700[data-highlighted] { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.dark .dark\:radix-state-active\:text-white[data-state="active"] { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.dark .dark\:radix-state-open\:text-gray-400[data-state="open"] { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

@media not all and (min-width: 1024px) {
  .max-lg\:justify-center { justify-content: center; }
}

@media (max-width: 370px) {
  .max-\[370px\]\:hidden { display: none; }
}

@media (min-width: 640px) {
  .sm\:order-1 { order: 1; }
  .sm\:order-2 { order: 2; }
  .sm\:m-6 { margin: 1.5rem; }
  .sm\:mx-1 { margin-left: 0.25rem; margin-right: 0.25rem; }
  .sm\:mb-16 { margin-bottom: 4rem; }
  .sm\:mb-2 { margin-bottom: 0.5rem; }
  .sm\:mt-0 { margin-top: 0px; }
  .sm\:mt-16 { margin-top: 4rem; }
  .sm\:mt-4 { margin-top: 1rem; }
  .sm\:mt-6 { margin-top: 1.5rem; }
  .sm\:mt-\[20vh\] { margin-top: 20vh; }
  .sm\:block { display: block; }
  .sm\:h-10 { height: 2.5rem; }
  .sm\:w-10 { width: 2.5rem; }
  .sm\:w-\[312px\] { width: 312px; }
  .sm\:w-\[calc\(\(100\%-12px\)\/2\)\] { width: calc(50% - 6px); }
  .sm\:w-auto { width: auto; }
  .sm\:min-w-\[148px\] { min-width: 148px; }
  .sm\:min-w-\[312px\] { min-width: 312px; }
  .sm\:max-w-md { max-width: 28rem; }
  .sm\:grid-cols-2 { grid-template-columns: repeat(2, minmax(0px, 1fr)); }
  .sm\:grid-rows-2 { grid-template-rows: repeat(2, minmax(0px, 1fr)); }
  .sm\:flex-row { flex-direction: row; }
  .sm\:flex-row-reverse { flex-direction: row-reverse; }
  .sm\:items-center { align-items: center; }
  .sm\:rounded-2xl { border-radius: 1rem; }
  .sm\:border-r { border-right-width: 1px; }
  .sm\:border-t-0 { border-top-width: 0px; }
  .sm\:p-4 { padding: 1rem; }
  .sm\:p-6 { padding: 1.5rem; }
  .sm\:px-0 { padding-left: 0px; padding-right: 0px; }
  .sm\:px-14 { padding-left: 3.5rem; padding-right: 3.5rem; }
  .sm\:px-4 { padding-left: 1rem; padding-right: 1rem; }
  .sm\:px-6 { padding-left: 1.5rem; padding-right: 1.5rem; }
  .sm\:pb-1 { padding-bottom: 0.25rem; }
  .sm\:pb-10 { padding-bottom: 2.5rem; }
  .sm\:pb-2 { padding-bottom: 0.5rem; }
  .sm\:pb-6 { padding-bottom: 1.5rem; }
  .sm\:pl-3 { padding-left: 0.75rem; }
  .sm\:pr-6 { padding-right: 1.5rem; }
  .sm\:pt-4 { padding-top: 1rem; }
  .sm\:pt-8 { padding-top: 2rem; }
  .sm\:text-left { text-align: left; }
  .sm\:text-4xl { font-size: 2.25rem; line-height: 2.5rem; }
  .sm\:text-base { font-size: 1rem; line-height: 1.5rem; }
  .sm\:text-sm { font-size: 0.875rem; line-height: 1.25rem; }
  .sm\:duration-300 { transition-duration: 0.3s; }
  .sm\:duration-500 { transition-duration: 0.5s; }
}

@media (min-width: 768px) {
  .md\:invisible { visibility: hidden; }
  .md\:static { position: static; }
  .md\:bottom-3 { bottom: 0.75rem; }
  .md\:bottom-3\.5 { bottom: 0.875rem; }
  .md\:bottom-\[120px\] { bottom: 120px; }
  .md\:left-4 { left: 1rem; }
  .md\:right-3 { right: 0.75rem; }
  .md\:m-0 { margin: 0px; }
  .md\:m-auto { margin: auto; }
  .md\:mx-0 { margin-left: 0px; margin-right: 0px; }
  .md\:mx-4 { margin-left: 1rem; margin-right: 1rem; }
  .md\:mb-0 { margin-bottom: 0px; }
  .md\:mb-2 { margin-bottom: 0.5rem; }
  .md\:mb-auto { margin-bottom: auto; }
  .md\:inline-block { display: inline-block; }
  .md\:flex { display: flex; }
  .md\:hidden { display: none; }
  .md\:h-48 { height: 12rem; }
  .md\:h-full { height: 100%; }
  .md\:min-h-\[300px\] { min-height: 300px; }
  .md\:w-1\/2 { width: 50%; }
  .md\:w-\[100\%\] { width: 100%; }
  .md\:w-\[250px\] { width: 250px; }
  .md\:w-\[672px\] { width: 672px; }
  .md\:w-\[680px\] { width: 680px; }
  .md\:w-auto { width: auto; }
  .md\:w-full { width: 100%; }
  .md\:min-w-\[672px\] { min-width: 672px; }
  .md\:max-w-2xl { max-width: 42rem; }
  .md\:max-w-5xl { max-width: 64rem; }
  .md\:max-w-none { max-width: none; }
  .md\:grid-cols-\[60px_minmax\(300px\,_100\%\)_60px\] { grid-template-columns: 60px minmax(300px, 100%) 60px; }
  .md\:grid-cols-\[minmax\(40px\,_30\%\)_minmax\(300px\,_auto\)_minmax\(40px\,_30\%\)\] { grid-template-columns: minmax(40px, 30%) minmax(300px, auto) minmax(40px, 30%); }
  .md\:grid-rows-\[minmax\(20px\,_1fr\)_auto_minmax\(20px\,_1fr\)\] { grid-template-rows: minmax(20px, 1fr) auto minmax(20px, 1fr); }
  .md\:flex-row { flex-direction: row; }
  .md\:flex-col { flex-direction: column; }
  .md\:justify-between { justify-content: space-between; }
  .md\:gap-2 { gap: 0.5rem; }
  .md\:gap-3 { gap: 0.75rem; }
  .md\:gap-6 { gap: 1.5rem; }
  .md\:overflow-visible { overflow: visible; }
  .md\:whitespace-normal { white-space: normal; }
  .md\:border { border-width: 1px; }
  .md\:border-l { border-left-width: 1px; }
  .md\:border-t-0 { border-top-width: 0px; }
  .md\:border-gray-100 { --tw-border-opacity:1; border-color: rgba(236,236,241,var(--tw-border-opacity)); }
  .md\:border-transparent { border-color: transparent; }
  .md\:\!bg-transparent { background-color: transparent !important; }
  .md\:bg-vert-light-gradient { background-image: linear-gradient(rgba(255, 255, 255, 0) 13.94%, rgb(255, 255, 255) 54.73%); }
  .md\:p-2 { padding: 0.5rem; }
  .md\:px-0 { padding-left: 0px; padding-right: 0px; }
  .md\:px-4 { padding-left: 1rem; padding-right: 1rem; }
  .md\:py-2 { padding-bottom: 0.5rem; padding-top: 0.5rem; }
  .md\:py-2\.5 { padding-bottom: 0.625rem; padding-top: 0.625rem; }
  .md\:py-4 { padding-bottom: 1rem; padding-top: 1rem; }
  .md\:py-6 { padding-bottom: 1.5rem; padding-top: 1.5rem; }
  .md\:\!pt-0 { padding-top: 0px !important; }
  .md\:pb-5 { padding-bottom: 1.25rem; }
  .md\:pb-6 { padding-bottom: 1.5rem; }
  .md\:pl-0 { padding-left: 0px; }
  .md\:pl-4 { padding-left: 1rem; }
  .md\:pl-\[30px\] { padding-left: 30px; }
  .md\:pr-1 { padding-right: 0.25rem; }
  .md\:pr-1\.5 { padding-right: 0.375rem; }
  .md\:pr-12 { padding-right: 3rem; }
  .md\:pt-3 { padding-top: 0.75rem; }
  .md\:text-justify { text-align: justify; }
  .md\:text-sm { font-size: 0.875rem; line-height: 1.25rem; }
  .md\:opacity-0 { opacity: 0; }
  .md\:last\:mb-6:last-child { margin-bottom: 1.5rem; }
  .md\:disabled\:bottom-0:disabled { bottom: 0px; }
  .group:hover .md\:group-hover\:visible { visibility: visible; }
  .dark .md\:dark\:border-gray-700 { --tw-border-opacity:1; border-color: rgba(64,65,79,var(--tw-border-opacity)); }
  .dark .md\:dark\:border-transparent { border-color: transparent; }
  .dark .dark\:md\:bg-vert-dark-gradient { background-image: linear-gradient(rgba(53, 55, 64, 0), rgb(53, 55, 64) 58.85%); }
}

@media (min-width: 1024px) {
  .lg\:absolute { position: absolute; }
  .lg\:relative { position: relative; }
  .lg\:-left-3 { left: -0.75rem; }
  .lg\:-right-3 { right: -0.75rem; }
  .lg\:left-auto { left: auto; }
  .lg\:right-0 { right: 0px; }
  .lg\:top-0 { top: 0px; }
  .lg\:top-1\/2 { top: 50%; }
  .lg\:mx-auto { margin-left: auto; margin-right: auto; }
  .lg\:mb-0 { margin-bottom: 0px; }
  .lg\:mt-0 { margin-top: 0px; }
  .lg\:block { display: block; }
  .lg\:hidden { display: none; }
  .lg\:w-1\/3 { width: 33.3333%; }
  .lg\:w-3\/5 { width: 60%; }
  .lg\:w-\[300px\] { width: 300px; }
  .lg\:w-\[896px\] { width: 896px; }
  .lg\:w-\[calc\(\(100\%-24px\)\/3\)\] { width: calc(33.3333% - 8px); }
  .lg\:w-\[calc\(100\%-115px\)\] { width: calc(100% - 115px); }
  .lg\:w-auto { width: auto; }
  .lg\:min-w-\[896px\] { min-width: 896px; }
  .lg\:max-w-2xl { max-width: 42rem; }
  .lg\:max-w-3xl { max-width: 48rem; }
  .lg\:max-w-none { max-width: none; }
  .lg\:max-w-sm { max-width: 24rem; }
  .lg\:max-w-xl { max-width: 36rem; }
  .lg\:-translate-x-full { --tw-translate-x:-100%; }
  .lg\:-translate-x-full, .lg\:-translate-y-1\/2 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }
  .lg\:-translate-y-1\/2 { --tw-translate-y:-50%; }
  .lg\:translate-x-full { --tw-translate-x:100%; }
  .lg\:translate-x-full, .lg\:translate-y-0 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }
  .lg\:translate-y-0 { --tw-translate-y:0px; }
  .lg\:grid-cols-3 { grid-template-columns: repeat(3, minmax(0px, 1fr)); }
  .lg\:gap-1 { gap: 0.25rem; }
  .lg\:self-center { align-self: center; }
  .lg\:rounded-lg { border-radius: 0.5rem; }
  .lg\:rounded-none { border-radius: 0px; }
  .lg\:border { border-width: 1px; }
  .lg\:border-0 { border-width: 0px; }
  .lg\:p-0 { padding: 0px; }
  .lg\:p-6 { padding: 1.5rem; }
  .lg\:px-0 { padding-left: 0px; padding-right: 0px; }
  .lg\:px-14 { padding-left: 3.5rem; padding-right: 3.5rem; }
  .lg\:px-8 { padding-left: 2rem; padding-right: 2rem; }
  .lg\:pl-2 { padding-left: 0.5rem; }
  .lg\:pt-32 { padding-top: 8rem; }
  .lg\:text-left { text-align: left; }
}

@media (min-width: 1280px) {
  @media (min-width: 768px) {
  .xl\:md\:grid-cols-\[minmax\(40px\,_1fr\)_minmax\(300px\,_800px\)_minmax\(40px\,_1fr\)\] { grid-template-columns: minmax(40px, 1fr) minmax(300px, 800px) minmax(40px, 1fr); }
}
  .xl\:w-1\/4 { width: 25%; }
  .xl\:w-\[1024px\] { width: 1024px; }
  .xl\:w-\[350px\] { width: 350px; }
  .xl\:min-w-\[1024px\] { min-width: 1024px; }
  .xl\:max-w-3xl { max-width: 48rem; }
  .xl\:max-w-7xl { max-width: 80rem; }
  .xl\:grid-cols-4 { grid-template-columns: repeat(4, minmax(0px, 1fr)); }
}

@media (min-width: 1536px) {
  .\32 xl\:w-\[400px\] { width: 400px; }
}

tr:last-child .\[tr\:last-child_\&\]\:border-b-0 { border-bottom-width: 0px; }

tr[data-disabled="true"] .\[tr\[data-disabled\=true\]_\&\]\:opacity-50 { opacity: 0.5; }

@font-face { font-family: KaTeX_AMS; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_AMS-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Caligraphic; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Caligraphic-Bold.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Caligraphic; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Caligraphic-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Fraktur; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Fraktur-Bold.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Fraktur; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Fraktur-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Main; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Main-Bold.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Main; font-style: italic; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Main-BoldItalic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Main; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Main-Italic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Main; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Main-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Math; font-style: italic; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Math-BoldItalic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Math; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Math-Italic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_SansSerif; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_SansSerif-Bold.woff2") format("woff2"); }

@font-face { font-family: KaTeX_SansSerif; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_SansSerif-Italic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_SansSerif; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_SansSerif-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Script; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Script-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Size1; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Size1-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Size2; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Size2-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Size3; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Size3-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Size4; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Size4-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Typewriter; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Typewriter-Regular.woff2") format("woff2"); }

.katex { font: 1.21em / 1.2 KaTeX_Main, "Times New Roman", serif; text-indent: 0px; text-rendering: auto; }

.katex * { border-color: currentcolor; }

.katex .katex-version::after { content: "0.16.0"; }

.katex .katex-mathml { clip: rect(1px, 1px, 1px, 1px); border: 0px; height: 1px; overflow: hidden; padding: 0px; position: absolute; width: 1px; }

.katex .katex-html > .newline { display: block; }

.katex .base { position: relative; white-space: nowrap; width: min-content; }

.katex .base, .katex .strut { display: inline-block; }

.katex .textbf { font-weight: 700; }

.katex .textit { font-style: italic; }

.katex .textrm { font-family: KaTeX_Main; }

.katex .textsf { font-family: KaTeX_SansSerif; }

.katex .texttt { font-family: KaTeX_Typewriter; }

.katex .mathnormal { font-family: KaTeX_Math; font-style: italic; }

.katex .mathit { font-family: KaTeX_Main; font-style: italic; }

.katex .mathrm { font-style: normal; }

.katex .mathbf { font-family: KaTeX_Main; font-weight: 700; }

.katex .boldsymbol { font-family: KaTeX_Math; font-style: italic; font-weight: 700; }

.katex .amsrm, .katex .mathbb, .katex .textbb { font-family: KaTeX_AMS; }

.katex .mathcal { font-family: KaTeX_Caligraphic; }

.katex .mathfrak, .katex .textfrak { font-family: KaTeX_Fraktur; }

.katex .mathtt { font-family: KaTeX_Typewriter; }

.katex .mathscr, .katex .textscr { font-family: KaTeX_Script; }

.katex .mathsf, .katex .textsf { font-family: KaTeX_SansSerif; }

.katex .mathboldsf, .katex .textboldsf { font-family: KaTeX_SansSerif; font-weight: 700; }

.katex .mathitsf, .katex .textitsf { font-family: KaTeX_SansSerif; font-style: italic; }

.katex .mainrm { font-family: KaTeX_Main; font-style: normal; }

.katex .vlist-t { border-collapse: collapse; display: inline-table; table-layout: fixed; }

.katex .vlist-r { display: table-row; }

.katex .vlist { display: table-cell; position: relative; vertical-align: bottom; }

.katex .vlist > span { display: block; height: 0px; position: relative; }

.katex .vlist > span > span { display: inline-block; }

.katex .vlist > span > .pstrut { overflow: hidden; width: 0px; }

.katex .vlist-t2 { margin-right: -2px; }

.katex .vlist-s { display: table-cell; font-size: 1px; min-width: 2px; vertical-align: bottom; width: 2px; }

.katex .vbox { align-items: baseline; display: inline-flex; flex-direction: column; }

.katex .hbox { width: 100%; }

.katex .hbox, .katex .thinbox { display: inline-flex; flex-direction: row; }

.katex .thinbox { max-width: 0px; width: 0px; }

.katex .msupsub { text-align: left; }

.katex .mfrac > span > span { text-align: center; }

.katex .mfrac .frac-line { border-bottom-style: solid; display: inline-block; width: 100%; }

.katex .hdashline, .katex .hline, .katex .mfrac .frac-line, .katex .overline .overline-line, .katex .rule, .katex .underline .underline-line { min-height: 1px; }

.katex .mspace { display: inline-block; }

.katex .clap, .katex .llap, .katex .rlap { position: relative; width: 0px; }

.katex .clap > .inner, .katex .llap > .inner, .katex .rlap > .inner { position: absolute; }

.katex .clap > .fix, .katex .llap > .fix, .katex .rlap > .fix { display: inline-block; }

.katex .llap > .inner { right: 0px; }

.katex .clap > .inner, .katex .rlap > .inner { left: 0px; }

.katex .clap > .inner > span { margin-left: -50%; margin-right: 50%; }

.katex .rule { border: 0px solid; display: inline-block; position: relative; }

.katex .hline, .katex .overline .overline-line, .katex .underline .underline-line { border-bottom-style: solid; display: inline-block; width: 100%; }

.katex .hdashline { border-bottom-style: dashed; display: inline-block; width: 100%; }

.katex .sqrt > .root { margin-left: 0.277778em; margin-right: -0.555556em; }

.katex .fontsize-ensurer.reset-size1.size1, .katex .sizing.reset-size1.size1 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size1.size2, .katex .sizing.reset-size1.size2 { font-size: 1.2em; }

.katex .fontsize-ensurer.reset-size1.size3, .katex .sizing.reset-size1.size3 { font-size: 1.4em; }

.katex .fontsize-ensurer.reset-size1.size4, .katex .sizing.reset-size1.size4 { font-size: 1.6em; }

.katex .fontsize-ensurer.reset-size1.size5, .katex .sizing.reset-size1.size5 { font-size: 1.8em; }

.katex .fontsize-ensurer.reset-size1.size6, .katex .sizing.reset-size1.size6 { font-size: 2em; }

.katex .fontsize-ensurer.reset-size1.size7, .katex .sizing.reset-size1.size7 { font-size: 2.4em; }

.katex .fontsize-ensurer.reset-size1.size8, .katex .sizing.reset-size1.size8 { font-size: 2.88em; }

.katex .fontsize-ensurer.reset-size1.size9, .katex .sizing.reset-size1.size9 { font-size: 3.456em; }

.katex .fontsize-ensurer.reset-size1.size10, .katex .sizing.reset-size1.size10 { font-size: 4.148em; }

.katex .fontsize-ensurer.reset-size1.size11, .katex .sizing.reset-size1.size11 { font-size: 4.976em; }

.katex .fontsize-ensurer.reset-size2.size1, .katex .sizing.reset-size2.size1 { font-size: 0.833333em; }

.katex .fontsize-ensurer.reset-size2.size2, .katex .sizing.reset-size2.size2 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size2.size3, .katex .sizing.reset-size2.size3 { font-size: 1.16667em; }

.katex .fontsize-ensurer.reset-size2.size4, .katex .sizing.reset-size2.size4 { font-size: 1.33333em; }

.katex .fontsize-ensurer.reset-size2.size5, .katex .sizing.reset-size2.size5 { font-size: 1.5em; }

.katex .fontsize-ensurer.reset-size2.size6, .katex .sizing.reset-size2.size6 { font-size: 1.66667em; }

.katex .fontsize-ensurer.reset-size2.size7, .katex .sizing.reset-size2.size7 { font-size: 2em; }

.katex .fontsize-ensurer.reset-size2.size8, .katex .sizing.reset-size2.size8 { font-size: 2.4em; }

.katex .fontsize-ensurer.reset-size2.size9, .katex .sizing.reset-size2.size9 { font-size: 2.88em; }

.katex .fontsize-ensurer.reset-size2.size10, .katex .sizing.reset-size2.size10 { font-size: 3.45667em; }

.katex .fontsize-ensurer.reset-size2.size11, .katex .sizing.reset-size2.size11 { font-size: 4.14667em; }

.katex .fontsize-ensurer.reset-size3.size1, .katex .sizing.reset-size3.size1 { font-size: 0.714286em; }

.katex .fontsize-ensurer.reset-size3.size2, .katex .sizing.reset-size3.size2 { font-size: 0.857143em; }

.katex .fontsize-ensurer.reset-size3.size3, .katex .sizing.reset-size3.size3 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size3.size4, .katex .sizing.reset-size3.size4 { font-size: 1.14286em; }

.katex .fontsize-ensurer.reset-size3.size5, .katex .sizing.reset-size3.size5 { font-size: 1.28571em; }

.katex .fontsize-ensurer.reset-size3.size6, .katex .sizing.reset-size3.size6 { font-size: 1.42857em; }

.katex .fontsize-ensurer.reset-size3.size7, .katex .sizing.reset-size3.size7 { font-size: 1.71429em; }

.katex .fontsize-ensurer.reset-size3.size8, .katex .sizing.reset-size3.size8 { font-size: 2.05714em; }

.katex .fontsize-ensurer.reset-size3.size9, .katex .sizing.reset-size3.size9 { font-size: 2.46857em; }

.katex .fontsize-ensurer.reset-size3.size10, .katex .sizing.reset-size3.size10 { font-size: 2.96286em; }

.katex .fontsize-ensurer.reset-size3.size11, .katex .sizing.reset-size3.size11 { font-size: 3.55429em; }

.katex .fontsize-ensurer.reset-size4.size1, .katex .sizing.reset-size4.size1 { font-size: 0.625em; }

.katex .fontsize-ensurer.reset-size4.size2, .katex .sizing.reset-size4.size2 { font-size: 0.75em; }

.katex .fontsize-ensurer.reset-size4.size3, .katex .sizing.reset-size4.size3 { font-size: 0.875em; }

.katex .fontsize-ensurer.reset-size4.size4, .katex .sizing.reset-size4.size4 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size4.size5, .katex .sizing.reset-size4.size5 { font-size: 1.125em; }

.katex .fontsize-ensurer.reset-size4.size6, .katex .sizing.reset-size4.size6 { font-size: 1.25em; }

.katex .fontsize-ensurer.reset-size4.size7, .katex .sizing.reset-size4.size7 { font-size: 1.5em; }

.katex .fontsize-ensurer.reset-size4.size8, .katex .sizing.reset-size4.size8 { font-size: 1.8em; }

.katex .fontsize-ensurer.reset-size4.size9, .katex .sizing.reset-size4.size9 { font-size: 2.16em; }

.katex .fontsize-ensurer.reset-size4.size10, .katex .sizing.reset-size4.size10 { font-size: 2.5925em; }

.katex .fontsize-ensurer.reset-size4.size11, .katex .sizing.reset-size4.size11 { font-size: 3.11em; }

.katex .fontsize-ensurer.reset-size5.size1, .katex .sizing.reset-size5.size1 { font-size: 0.555556em; }

.katex .fontsize-ensurer.reset-size5.size2, .katex .sizing.reset-size5.size2 { font-size: 0.666667em; }

.katex .fontsize-ensurer.reset-size5.size3, .katex .sizing.reset-size5.size3 { font-size: 0.777778em; }

.katex .fontsize-ensurer.reset-size5.size4, .katex .sizing.reset-size5.size4 { font-size: 0.888889em; }

.katex .fontsize-ensurer.reset-size5.size5, .katex .sizing.reset-size5.size5 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size5.size6, .katex .sizing.reset-size5.size6 { font-size: 1.11111em; }

.katex .fontsize-ensurer.reset-size5.size7, .katex .sizing.reset-size5.size7 { font-size: 1.33333em; }

.katex .fontsize-ensurer.reset-size5.size8, .katex .sizing.reset-size5.size8 { font-size: 1.6em; }

.katex .fontsize-ensurer.reset-size5.size9, .katex .sizing.reset-size5.size9 { font-size: 1.92em; }

.katex .fontsize-ensurer.reset-size5.size10, .katex .sizing.reset-size5.size10 { font-size: 2.30444em; }

.katex .fontsize-ensurer.reset-size5.size11, .katex .sizing.reset-size5.size11 { font-size: 2.76444em; }

.katex .fontsize-ensurer.reset-size6.size1, .katex .sizing.reset-size6.size1 { font-size: 0.5em; }

.katex .fontsize-ensurer.reset-size6.size2, .katex .sizing.reset-size6.size2 { font-size: 0.6em; }

.katex .fontsize-ensurer.reset-size6.size3, .katex .sizing.reset-size6.size3 { font-size: 0.7em; }

.katex .fontsize-ensurer.reset-size6.size4, .katex .sizing.reset-size6.size4 { font-size: 0.8em; }

.katex .fontsize-ensurer.reset-size6.size5, .katex .sizing.reset-size6.size5 { font-size: 0.9em; }

.katex .fontsize-ensurer.reset-size6.size6, .katex .sizing.reset-size6.size6 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size6.size7, .katex .sizing.reset-size6.size7 { font-size: 1.2em; }

.katex .fontsize-ensurer.reset-size6.size8, .katex .sizing.reset-size6.size8 { font-size: 1.44em; }

.katex .fontsize-ensurer.reset-size6.size9, .katex .sizing.reset-size6.size9 { font-size: 1.728em; }

.katex .fontsize-ensurer.reset-size6.size10, .katex .sizing.reset-size6.size10 { font-size: 2.074em; }

.katex .fontsize-ensurer.reset-size6.size11, .katex .sizing.reset-size6.size11 { font-size: 2.488em; }

.katex .fontsize-ensurer.reset-size7.size1, .katex .sizing.reset-size7.size1 { font-size: 0.416667em; }

.katex .fontsize-ensurer.reset-size7.size2, .katex .sizing.reset-size7.size2 { font-size: 0.5em; }

.katex .fontsize-ensurer.reset-size7.size3, .katex .sizing.reset-size7.size3 { font-size: 0.583333em; }

.katex .fontsize-ensurer.reset-size7.size4, .katex .sizing.reset-size7.size4 { font-size: 0.666667em; }

.katex .fontsize-ensurer.reset-size7.size5, .katex .sizing.reset-size7.size5 { font-size: 0.75em; }

.katex .fontsize-ensurer.reset-size7.size6, .katex .sizing.reset-size7.size6 { font-size: 0.833333em; }

.katex .fontsize-ensurer.reset-size7.size7, .katex .sizing.reset-size7.size7 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size7.size8, .katex .sizing.reset-size7.size8 { font-size: 1.2em; }

.katex .fontsize-ensurer.reset-size7.size9, .katex .sizing.reset-size7.size9 { font-size: 1.44em; }

.katex .fontsize-ensurer.reset-size7.size10, .katex .sizing.reset-size7.size10 { font-size: 1.72833em; }

.katex .fontsize-ensurer.reset-size7.size11, .katex .sizing.reset-size7.size11 { font-size: 2.07333em; }

.katex .fontsize-ensurer.reset-size8.size1, .katex .sizing.reset-size8.size1 { font-size: 0.347222em; }

.katex .fontsize-ensurer.reset-size8.size2, .katex .sizing.reset-size8.size2 { font-size: 0.416667em; }

.katex .fontsize-ensurer.reset-size8.size3, .katex .sizing.reset-size8.size3 { font-size: 0.486111em; }

.katex .fontsize-ensurer.reset-size8.size4, .katex .sizing.reset-size8.size4 { font-size: 0.555556em; }

.katex .fontsize-ensurer.reset-size8.size5, .katex .sizing.reset-size8.size5 { font-size: 0.625em; }

.katex .fontsize-ensurer.reset-size8.size6, .katex .sizing.reset-size8.size6 { font-size: 0.694444em; }

.katex .fontsize-ensurer.reset-size8.size7, .katex .sizing.reset-size8.size7 { font-size: 0.833333em; }

.katex .fontsize-ensurer.reset-size8.size8, .katex .sizing.reset-size8.size8 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size8.size9, .katex .sizing.reset-size8.size9 { font-size: 1.2em; }

.katex .fontsize-ensurer.reset-size8.size10, .katex .sizing.reset-size8.size10 { font-size: 1.44028em; }

.katex .fontsize-ensurer.reset-size8.size11, .katex .sizing.reset-size8.size11 { font-size: 1.72778em; }

.katex .fontsize-ensurer.reset-size9.size1, .katex .sizing.reset-size9.size1 { font-size: 0.289352em; }

.katex .fontsize-ensurer.reset-size9.size2, .katex .sizing.reset-size9.size2 { font-size: 0.347222em; }

.katex .fontsize-ensurer.reset-size9.size3, .katex .sizing.reset-size9.size3 { font-size: 0.405093em; }

.katex .fontsize-ensurer.reset-size9.size4, .katex .sizing.reset-size9.size4 { font-size: 0.462963em; }

.katex .fontsize-ensurer.reset-size9.size5, .katex .sizing.reset-size9.size5 { font-size: 0.520833em; }

.katex .fontsize-ensurer.reset-size9.size6, .katex .sizing.reset-size9.size6 { font-size: 0.578704em; }

.katex .fontsize-ensurer.reset-size9.size7, .katex .sizing.reset-size9.size7 { font-size: 0.694444em; }

.katex .fontsize-ensurer.reset-size9.size8, .katex .sizing.reset-size9.size8 { font-size: 0.833333em; }

.katex .fontsize-ensurer.reset-size9.size9, .katex .sizing.reset-size9.size9 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size9.size10, .katex .sizing.reset-size9.size10 { font-size: 1.20023em; }

.katex .fontsize-ensurer.reset-size9.size11, .katex .sizing.reset-size9.size11 { font-size: 1.43981em; }

.katex .fontsize-ensurer.reset-size10.size1, .katex .sizing.reset-size10.size1 { font-size: 0.24108em; }

.katex .fontsize-ensurer.reset-size10.size2, .katex .sizing.reset-size10.size2 { font-size: 0.289296em; }

.katex .fontsize-ensurer.reset-size10.size3, .katex .sizing.reset-size10.size3 { font-size: 0.337512em; }

.katex .fontsize-ensurer.reset-size10.size4, .katex .sizing.reset-size10.size4 { font-size: 0.385728em; }

.katex .fontsize-ensurer.reset-size10.size5, .katex .sizing.reset-size10.size5 { font-size: 0.433944em; }

.katex .fontsize-ensurer.reset-size10.size6, .katex .sizing.reset-size10.size6 { font-size: 0.48216em; }

.katex .fontsize-ensurer.reset-size10.size7, .katex .sizing.reset-size10.size7 { font-size: 0.578592em; }

.katex .fontsize-ensurer.reset-size10.size8, .katex .sizing.reset-size10.size8 { font-size: 0.694311em; }

.katex .fontsize-ensurer.reset-size10.size9, .katex .sizing.reset-size10.size9 { font-size: 0.833173em; }

.katex .fontsize-ensurer.reset-size10.size10, .katex .sizing.reset-size10.size10 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size10.size11, .katex .sizing.reset-size10.size11 { font-size: 1.19961em; }

.katex .fontsize-ensurer.reset-size11.size1, .katex .sizing.reset-size11.size1 { font-size: 0.200965em; }

.katex .fontsize-ensurer.reset-size11.size2, .katex .sizing.reset-size11.size2 { font-size: 0.241158em; }

.katex .fontsize-ensurer.reset-size11.size3, .katex .sizing.reset-size11.size3 { font-size: 0.28135em; }

.katex .fontsize-ensurer.reset-size11.size4, .katex .sizing.reset-size11.size4 { font-size: 0.321543em; }

.katex .fontsize-ensurer.reset-size11.size5, .katex .sizing.reset-size11.size5 { font-size: 0.361736em; }

.katex .fontsize-ensurer.reset-size11.size6, .katex .sizing.reset-size11.size6 { font-size: 0.401929em; }

.katex .fontsize-ensurer.reset-size11.size7, .katex .sizing.reset-size11.size7 { font-size: 0.482315em; }

.katex .fontsize-ensurer.reset-size11.size8, .katex .sizing.reset-size11.size8 { font-size: 0.578778em; }

.katex .fontsize-ensurer.reset-size11.size9, .katex .sizing.reset-size11.size9 { font-size: 0.694534em; }

.katex .fontsize-ensurer.reset-size11.size10, .katex .sizing.reset-size11.size10 { font-size: 0.833601em; }

.katex .fontsize-ensurer.reset-size11.size11, .katex .sizing.reset-size11.size11 { font-size: 1em; }

.katex .delimsizing.size1 { font-family: KaTeX_Size1; }

.katex .delimsizing.size2 { font-family: KaTeX_Size2; }

.katex .delimsizing.size3 { font-family: KaTeX_Size3; }

.katex .delimsizing.size4 { font-family: KaTeX_Size4; }

.katex .delimsizing.mult .delim-size1 > span { font-family: KaTeX_Size1; }

.katex .delimsizing.mult .delim-size4 > span { font-family: KaTeX_Size4; }

.katex .nulldelimiter { display: inline-block; width: 0.12em; }

.katex .delimcenter, .katex .op-symbol { position: relative; }

.katex .op-symbol.small-op { font-family: KaTeX_Size1; }

.katex .op-symbol.large-op { font-family: KaTeX_Size2; }

.katex .accent > .vlist-t, .katex .op-limits > .vlist-t { text-align: center; }

.katex .accent .accent-body { position: relative; }

.katex .accent .accent-body:not(.accent-full) { width: 0px; }

.katex .overlay { display: block; }

.katex .mtable .vertical-separator { display: inline-block; min-width: 1px; }

.katex .mtable .arraycolsep { display: inline-block; }

.katex .mtable .col-align-c > .vlist-t { text-align: center; }

.katex .mtable .col-align-l > .vlist-t { text-align: left; }

.katex .mtable .col-align-r > .vlist-t { text-align: right; }

.katex .svg-align { text-align: left; }

.katex svg { fill: currentcolor; stroke: currentcolor; fill-rule: nonzero; fill-opacity: 1; stroke-width: 1; stroke-linecap: butt; stroke-linejoin: miter; stroke-miterlimit: 4; stroke-dasharray: none; stroke-dashoffset: 0; stroke-opacity: 1; display: block; height: inherit; position: absolute; width: 100%; }

.katex svg path { stroke: none; }

.katex img { border-style: none; max-height: none; max-width: none; min-height: 0px; min-width: 0px; }

.katex .stretchy { display: block; overflow: hidden; position: relative; width: 100%; }

.katex .stretchy::after, .katex .stretchy::before { content: ""; }

.katex .hide-tail { overflow: hidden; position: relative; width: 100%; }

.katex .halfarrow-left { left: 0px; overflow: hidden; position: absolute; width: 50.2%; }

.katex .halfarrow-right { overflow: hidden; position: absolute; right: 0px; width: 50.2%; }

.katex .brace-left { left: 0px; overflow: hidden; position: absolute; width: 25.1%; }

.katex .brace-center { left: 25%; overflow: hidden; position: absolute; width: 50%; }

.katex .brace-right { overflow: hidden; position: absolute; right: 0px; width: 25.1%; }

.katex .x-arrow-pad { padding: 0px 0.5em; }

.katex .cd-arrow-pad { padding: 0px 0.55556em 0px 0.27778em; }

.katex .mover, .katex .munder, .katex .x-arrow { text-align: center; }

.katex .boxpad { padding: 0px 0.3em; }

.katex .fbox, .katex .fcolorbox { border: 0.04em solid; box-sizing: border-box; }

.katex .cancel-pad { padding: 0px 0.2em; }

.katex .cancel-lap { margin-left: -0.2em; margin-right: -0.2em; }

.katex .sout { border-bottom-style: solid; border-bottom-width: 0.08em; }

.katex .angl { border-right: 0.049em solid; border-top: 0.049em solid; box-sizing: border-box; margin-right: 0.03889em; }

.katex .anglpad { padding: 0px 0.03889em; }

.katex .eqn-num::before { content: "(" counter(katexEqnNo) ")"; counter-increment: katexEqnNo 1; }

.katex .mml-eqn-num::before { content: "(" counter(mmlEqnNo) ")"; counter-increment: mmlEqnNo 1; }

.katex .mtr-glue { width: 50%; }

.katex .cd-vert-arrow { display: inline-block; position: relative; }

.katex .cd-label-left { display: inline-block; position: absolute; right: calc(50% + 0.3em); text-align: left; }

.katex .cd-label-right { display: inline-block; left: calc(50% + 0.3em); position: absolute; text-align: right; }

.katex-display { display: block; margin: 1em 0px; text-align: center; }

.katex-display > .katex { display: block; text-align: center; white-space: nowrap; }

.katex-display > .katex > .katex-html { display: block; position: relative; }

.katex-display > .katex > .katex-html > .tag { position: absolute; right: 0px; }

.katex-display.leqno > .katex > .katex-html > .tag { left: 0px; right: auto; }

.katex-display.fleqn > .katex { padding-left: 2em; text-align: left; }

body { counter-reset: katexEqnNo 0 mmlEqnNo 0; }

code, pre { font-family: "SÃ¶hne Mono", Monaco, "Andale Mono", "Ubuntu Mono", monospace !important; }

code[class="language-plaintext"] { white-space: pre-line; }

code.hljs, code[class*="language-"], pre[class*="language-"] { overflow-wrap: normal; background: none; color: rgb(255, 255, 255); hyphens: none; line-height: 1.5; tab-size: 4; text-align: left; white-space: pre; word-break: normal; word-spacing: normal; }

pre[class*="language-"] { border-radius: 0.3em; overflow: auto; }

:not(pre) > code.hljs, :not(pre) > code[class*="language-"] { border-radius: 0.3em; padding: 0.1em; white-space: normal; }

.hljs-comment { color: rgba(255, 255, 255, 0.5); }

.hljs-meta { color: rgba(255, 255, 255, 0.6); }

.hljs-built_in, .hljs-class .hljs-title { color: rgb(233, 149, 12); }

.hljs-doctag, .hljs-formula, .hljs-keyword, .hljs-literal { color: rgb(46, 149, 211); }

.hljs-addition, .hljs-attribute, .hljs-meta-string, .hljs-regexp, .hljs-string { color: rgb(0, 166, 125); }

.hljs-attr, .hljs-number, .hljs-selector-attr, .hljs-selector-class, .hljs-selector-pseudo, .hljs-template-variable, .hljs-type, .hljs-variable { color: rgb(223, 48, 121); }

.hljs-bullet, .hljs-link, .hljs-selector-id, .hljs-symbol, .hljs-title { color: rgb(242, 44, 61); }

.token.cdata, .token.comment, .token.doctype, .token.prolog { color: rgb(169, 174, 193); }

.token.punctuation { color: rgb(254, 254, 254); }

.token.constant, .token.deleted, .token.property, .token.symbol, .token.tag { color: rgb(255, 160, 122); }

.token.boolean, .token.number { color: rgb(0, 224, 224); }

.token.attr-name, .token.builtin, .token.char, .token.inserted, .token.selector, .token.string { color: rgb(171, 227, 56); }

.language-css .token.string, .style .token.string, .token.entity, .token.operator, .token.url, .token.variable { color: rgb(0, 224, 224); }

.token.atrule, .token.attr-value, .token.function { color: gold; }

.token.keyword { color: rgb(0, 224, 224); }

.token.important, .token.regex { color: gold; }

.token.bold, .token.important { font-weight: 700; }

.token.italic { font-style: italic; }

.token.entity { cursor: help; }

@media screen and (-ms-high-contrast:active) {
  code[class*="language-"], pre[class*="language-"] { background: window; color: windowtext; }
  :not(pre) > code[class*="language-"], pre[class*="language-"] { background: window; }
  .token.important { background: highlight; color: window; font-weight: 400; }
  .token.atrule, .token.attr-value, .token.function, .token.keyword, .token.operator, .token.selector { font-weight: 700; }
  .token.attr-value, .token.comment, .token.doctype, .token.function, .token.keyword, .token.operator, .token.property, .token.string { color: highlight; }
  .token.attr-value, .token.url { font-weight: 400; }
}
------MultipartBoundary--e0KgSZErrpOGbk1KVscskuMnkhQAmwwoxNQEx6azxm----
Content-Type: image/webp
Content-Transfer-Encoding: binary
Content-Location: https://chat.openai.com/_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2Fa%2FAAcHTtfE_9fVpMOqgyC7Lo43NLrKgIo-u2ToDOuYOa2T%3Ds96-c&w=96&q=75

RIFF¨  WEBPVP8    *` ` >8G¥#¢!2´È 	@»ñÒ_p¨Ï¦?;ÁiÛEoè4õÿ d4ñ?qF|»µè)ô=ÂùýD¹äMÜKÏåçµª0¸vB³6}ª¹½ðöÎ(êLþ)6þ×òäKþfÀðxõ%×?«upXú	ÁYìIZ@ñÜöÌßp SjGNQTÈRÂ½#Eû&9ìI¸]òX[Ú×n¡dÙ÷6{=t­ÑÿXK¯Öí» ÇÍÝ¥\5a?)áÒ^§¿dÓ^§¼ô"xOÅ»?$êh þðêà&qÕîY¿`ù>F*VÓøUª«YèxüoYªeÇõvÕfCÂù:¬¬Ø} y¤ß<¡4*¤¼#	·"I½À@W1ìò@}TYÈn 5ÜjûiÝ=ÂµCUe¾²Äb&3"qþÍLtRjÝtüÛõnõ3¹Ñ]óËÎÓ ·LÏ6I!Bu$)ÚòægÉcowæÕÄ®y`Sã©2TÞ±aW¢=ÝíµN8¼X*ÌÚúÇiaBë¿ªÿ µ.Æ÷{øÍ&[Ó¢4ß]*J¥íËèß¨øâ~.ÜBw!ßÓ« 6Öm£{Æqý'Y¾L8@áqYæÔI¶{y]²Ìeµ»ºa:fi°¸O«ÂI6µ3zß¦Å©(õóüf
G;V¸ë7h6¢¹ÝRã{þÌý¯>½ZQ¹¬ë£/{?AË(8Äæ5¢÷î©]ûæ\®2(Zª°}Z<þf­µ¶hc¶Á@§9ÐNrn´«ÆýÊGgðuY4½ÌÙ^%ð>µ
kõÿnÌÞ1YÓfêªÐ×¼36kF«g1eé(9E]4;¥¬â<«nºrÏ69I\»c9Uá¨Jø:ù ô9ÝDLF¬uâYX(ù|±dÂ`²×ÙA½K)³tií/Å«ÉÐþ6HqøÞN´¶p)é·<Õ[{øpn·&CæÞ¨jWÉô> ¤&Ï"~Ò  .£¢GÂÜªêÒ;µ¿PúôÎÔ1Î½,Þ·°GM/Ò`ÄøXê*`ÜñPÊI;88.°å[ÒT E=ëä"=lDû7v&léÙôK>Ó¶½=F!ÔÿlÙ>BÀÒàÊÐüe
YoÓªUrpÆnY Û&¹Oÿ[h$k<ÿ¢[ðBeª¯¢6E]9âýR÷.ç+ÉÕÓX±hÛj®ùJqø_]nhîÅÜ3°IªCþÿâÅ%àñNhpÑlOëÞIr Ï¨ÃäUE¶Æ¡ò³KgttYÞ8ÀÏîhxWÝîkæUÀÊ,ò÷D|©Pêe;?ãTýl7×ß×¿Æy¤Í¸qäÄÔª55ò6%8¦ÊèÑ?_ÊÉkÃ÷Æa=Çnñ äíÓBÁîÜø2èbÀ:îåÈ#EDÒç;F	¯êé¾(¿,â]ïDxm¨õÅPI*bè®gö£È¦º3dpñé·hV2À*¸múwöM$q½DLD¶yµq»üRèÙÀ?·uÄ¶;$¶Ó>àcå ]¼928µùXÐônF^¸XYëÉ!D[ZôÄ`æ0|1úÒW¡³ßèAÞ`CI§õz,ÄÅÅX(tÉä-·u(@çæeX¡â%2ÑâÜÎÃÜ¦tD}1füØ°ìªì
¬¢ö©>LÆRzÓ ¶ÍB[ºè {KÁN8uüÊ¿3KZ¹ùþúw_ 2N2 òDÜÝ­é½û¨
X=ÆGÊ,\ÉÉ_}¶¦O}uYõÔÛ Yø  
------MultipartBoundary--e0KgSZErrpOGbk1KVscskuMnkhQAmwwoxNQEx6azxm----
Content-Type: text/html
Content-ID: 
Content-Transfer-Encoding: binary


------MultipartBoundary--e0KgSZErrpOGbk1KVscskuMnkhQAmwwoxNQEx6azxm----
Content-Type: text/html
Content-ID: 
Content-Transfer-Encoding: binary





------MultipartBoundary--e0KgSZErrpOGbk1KVscskuMnkhQAmwwoxNQEx6azxm------
