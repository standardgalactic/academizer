So today we have Laura Schultz from the Cognitive Science
Department.
So most of the embodied intelligence seminar
will feature speakers from MIT CCL,
but we also decided to invite some interesting,
distinguished speakers from outside the department.
In this case, Laura Schultz is a professor
at Cognitive Science in the Department of BCS.
She studied philosophy at Michigan,
and therefore, and afterwards, she
went on to study at Berkeley developmental psychology.
She has worked on causal learning, exploration, play
and emotion, and also on how children learn so much from so
little and so quickly.
I think it's very interesting for us researchers in AI
that constantly try to emulate how children learn so
effectively to hear from someone that actually
knows how children learn.
Welcome, Laura Schultz.
Chiefly, I know what I don't know.
But as I gesture towards the end,
I think that's one of the critical questions
about children's learning.
Thank you very much for inviting me here.
I've been hearing about this group from my colleague Josh
Tenenbaum for a while.
I think there's increasing interest on both sides
here in understanding how we might
formalize the kind of learning that takes place
in very early childhood.
So I hope this is the beginning of many additional interactions
with this group.
And I'm going to apologize in advance
for the informality of this talk.
I cobbled together a bunch of different ideas
with the goal really of gesturing at things
that I am just wondering about more than reviewing
the past work I've done.
But I will start with a little review of the things
I think we might know.
And I'll start way back with the research tradition
that I am a part of, which is the idea roughly
of the child as scientist.
And both literally and figuratively,
this is where I began, because this
is a book that came out in 1999, which was the year I
started graduate school.
And the first author, Alison Gopnik,
was my dissertation advisor.
So I began with this very problematic metaphor,
actually, of the child as scientist.
And it's problematic because, of course,
science is a culturally recent invention
practiced by a tiny minority of the human species.
So it might seem like a very odd place
to look for universals of human cognition.
But if you're interested in learning,
science has this peculiar property,
which is that it sometimes gets the world right.
And so if you really want to understand
how you can create new knowledge,
you could do worse, maybe, than trying
to understand what it is that scientists do.
But of course, nobody has a grand uterifying theory
of why science works or how science succeeds.
That remains a hard problem of cognitive science.
Nonetheless, we can say a lot of things
about the kinds of epistemic practices scientists engage in.
And the idea that has driven a lot of my research program
is that those are cultural canalizations of practices
that actually emerge in very early childhood
to solve the hard problem of learning in early childhood,
which is precisely the problem
of how to make rich abstract inferences
from sparse, noisy data.
And that's, of course, a problem
that is common to science as well.
So we now know, I think, a great deal
about the kinds of things that emerge
in the first few years of life
that also characterize many of the practices of science.
And particularly, since I know this is a group
that's interested in exploration and curiosity,
we know that from early in infancy,
through toddlerhood and preschool years,
children selectively explore and systematically explore
evidence that is surprising
with respect to their intuitive theories
and evidence that fails to disambiguate causal structure.
So in fact, it's a method for understanding
what kinds of conceptual representations babies have
to look at their selective looking and exploration
of evidence that violates those concepts.
So because babies tend to look longer
at events that violate their expectations,
we know that babies have expectations about gravity,
about number, about objects and forces,
about agents and goals,
and even about moral behavior from infants.
We know something about the shape of those curves.
So we know that babies tend to look longer
at evidence that are moderately surprising
when you can actually formalize
what surprises might look like in a context.
We know it's not just looking.
We know that when babies see evidence
that violates their intuitive theories
of gravity or support relations,
they see objects pass through walls
or look like they suspended midair.
Babies, when you hand them those objects,
selectively explore them,
which is to say they tend to pound on the objects
that look like they pass through walls
and they drop the ones that look like they floated in midair.
So they conduct exactly the interventions
that look like they map onto violations
of their core intuitive theories.
And by the preschool years,
we know that their exploration
is really closely titrated to quite specific theories.
So six and seven year olds, all children of the same age
may have different intuitive theories about balance.
About half of those children believe
that if you place an object in its geometric center,
it will stay balanced.
Another half of those children have begun to work out
that actually you need to compensate
for the center of gravity,
which might not be the geometric center
of the bottom surface of the object.
And if you show children evidence
that looks like it violates either of those
because you can put magnets in your blocks.
So you can make either of those things happen
and look like the object stays balanced.
Children selectively explore
the one that violates their theories.
We also know it's not just about theory violation
or violation of intuitive expectations of the world.
Children also selectively explore
when evidence is ambiguous or confounded.
So if you show children two levers
that move at exactly the same time
and two toys pop out in the very middle of the box
so they can't tell which lever controls which,
then they go back and play with that box.
If you isolated the variable,
so they know which lever controls which box,
they selectively play with a novel toy.
So they're sensitive to the structure
and the causal structure that gives them information
or does not.
And in some recent work,
we've shown exactly how selective
children's exploration of uncertainty is.
So let me give you just two examples,
one old and one new from this body of work from my own lab.
So this is a paper that's almost a decade old now.
And many of you, when you were children,
may have seen these kinds of plastic beads.
You can pop apart and pop together these snap beads.
We just use them as toys on top of a music box,
which is sort of gestured up by that green box there.
And in one condition, every bead you placed on it
made the box play music.
In the other condition, only half of the beads did.
But there were no visual cues that told you
which beads would work and which beads didn't.
So all that distinguished these two conditions
was the base rate of the causes.
Either everything worked
or only some of the things worked.
Then we took all that material away
and all the kids saw exactly the same things.
They saw a stuck pair of beads
and when you placed it on the box,
they made music and a separable pair of beads.
And when you placed that on the box, it made music.
So the stuck pair of the kids got to try to pull apart,
but they couldn't.
It was epoxy together,
so they really couldn't take them apart.
The separable pair was an ordinary pair of beads
and when you placed it as a pair on the box,
the box played music.
And then we walked away
and we wanted to know what the kids would do
when they played and our idea was this.
If you were in the all beads condition,
you saw every single bead makes music, right?
Then there's not much information
to be gained from either of these pairs.
You should assume that all of these beads make music too
and we thought the kids would play indiscriminately.
But if you were in the some beads condition
and you knew that only about half the beads made music,
well, in that case, really only one of these pairs
let's you isolate the variables, right?
There's only one pair where you could snap the beads apart
and find out which of those two beads was making music
or whether they both were.
So we thought that if kids are sensitive
to the potential ambiguity and they can isolate variables
to design informative interventions,
just in this condition,
they should selectively play with the separable beads.
Is that intuition clear?
And I'm speaking very quickly
because all this is actually the prelude
to the stuff I really want to talk about.
But that's exactly what we found
and the all beads condition,
children basically never snapped apart the beads
in the some beads condition they did
and they about half the kids tried each bead separately,
isolating the variables on the machine.
My graduate student at the time said,
you know, they're doing something kind of interesting
even with the stuck beads.
And I said, what can they possibly do with the stuck beads?
They're stuck, there's nothing to be done.
She said, well, let's run it again.
So we ran it again with again a group
who saw that every bead made music
and only some beads made music.
But this time, all the kids only ever saw
the stuck pair and as a pair,
that pair made music on the box
and I want to show you what children did.
So this is the trial where they learned
that some of the beads make music and some of them don't.
And then we hand the child the stuck pair
and she does what we did.
And she plays with the toy, which also spins.
She does it again.
And then she does something I hadn't thought of,
but it's consistent if you have an intuitive theory
of contact causality with a way of isolating the variables
and figuring out which of those two beads
might in fact make music.
So this is an intervention that the MIT scientists
and responsible for the study hadn't thought of,
but the children in fact generated
informative intervention consistent
with their intuitive theories
and she even replicates it many times,
which is more than many of us remember to do.
So again, we saw about half the kids
generating that kind of intervention
and only in the case where there really was uncertainty
and a high likelihood of information to begin.
So when I talk about children as intuitive scientists,
this is the kind of thing I'm gesturing at, yeah.
At the school, do you have a question
on how children should do it equally or...?
If it's just a good feeling,
they should do it equally often
in the case where there's no information to begin.
So in the all-beats condition,
they have the same stimuli, same setup.
The only thing that differs is their prior belief
that every bead makes music.
So if they just want to flip the toy around,
then they should always flip the toy around.
And one child did, but most of them didn't, right?
So it is certainly the case that it is important
that this is an intervention that's in their grasp, right?
They really can do this.
They can do this easily.
And it's a single, simple, low-cost movement, right?
So I think it does matter
that this is a very available way to isolate variables.
You just pull them apart.
You just go like this or that.
But it's not the case that they're engaging in it uniformly.
So one question is more about, like,
if you ask a bit of a question,
you want to remove the noise in the noise being.
You want to know, is there any way to domestic, you know,
that you don't want to do the noise in the noise?
So in this study, we weren't studying curiosity, right?
Curiosity is one of those words
you could operationalize in a lot of ways.
And I'm going to talk about what I think are
more or less interesting ways of operationalizing it.
All of them count, right?
Curiosity when you look longer at things
that violate your theories.
Curiosity when you look longer at things
that are moderately unpredictable.
It is arguably curiosity when you design an intervention
just in cases where information might be gained.
But do the children have to have metacognitive knowledge
that this action that they're explicitly doing
is going to generate the knowledge?
To do that, you might need an explicit verbal report.
There are a lot of reasons why you might now want
to make that a kind of thing that you get
even from scientists,
a little alone from four and five-year-old children.
But the relationship of the motivational system,
the phenomenology, what's going on inside their heads,
to the behavior they observe,
the best we can do is operationalize.
In this case, we wanted to know,
would children selectively design informative interventions
just when there was ambiguity in the data?
So that was the nature of our question,
our children curious per se.
Does that make sense?
All right.
That was a decade-old study.
I'm going to show you a study
that we hope will come out any day now.
And it's a different kind of study.
But it's another study looking at the relationship
between uncertainty and exploratory play.
And I'm just going to show you
the last experiments we ran in there.
We showed children tubes of marbles.
And in this case, let's say there's nine red marbles
and three green marbles.
And we told the kids,
we're going to pour one of those tubes of marbles
into the box.
And your job is to shake the box
and find out how many marbles there is in it, right?
So this is the kind of game
you might have played in preschool.
Kids get to take that box
and shake it as long as they want.
So let's say nine marbles are actually in the box.
They can shake it and then guess which one's in there.
But what we can do is we can say,
okay, for another child,
there's either nine red marbles
or eight green marbles in the box.
And your job is to shake it
and find out what's in the box, right?
And again, let's say nine marbles
are actually in the box.
Practically speaking,
from a sensory motor perspective,
this is the same box, right?
Nine marbles in it both times.
But if children's exploration is driven
not by what they actually feel or experience,
but by what they might have heard, right?
By the ambiguity of the contrast, right?
And the uncertainty of the contrast.
This is a much harder contrast.
This is a much harder discrimination problem.
So you might expect children in this case
to shake much longer, right?
Because nine from eight is a harder discrimination
than nine from three.
And that is the case,
even though the children only ever hear nine, right?
So they hear the same box,
but if they can simulate what they might have heard instead
and their exploration is driven by that uncertainty,
they should shake longer in this case than in the other case.
This is MIT and marbles.
We can quantitatively vary them.
We can make precise claims about the discriminability
across a whole different set of designs.
We only read children in four contrasts per experiment
so that they never heard the same marbles twice
unless we actually explicitly wanted them to
because we were looking at that in the design.
But collectively we ran 16 contrasts
where we knew the discriminability.
It's a dead simple experiment.
This is what it looks like in practice.
Maybe.
All right, so remember it could either be the one green
or the eight red
and when you know you can put your answer right there.
So go ahead and play.
What?
What?
All right, so remember there could be four yellow
or five blue
and when you know you can put your answer right there.
So go ahead and play.
Five.
All right.
And this child got two more trials and then was done, right?
But across the kids we ran 16 different contrasts
and then we can normalize for kids individual playing time
and look at how long they play based on the discriminability
of the data.
We coded it both from video from the time that we started to end
which includes thinking time
and with an Arduino motion sensor inside the box
so that we can precisely look at how long they're shaking it.
And by both measures,
I'm presenting this as the pinnacle of the work I will ever do
on exploration and uncertainty.
We got an exact precise mapping
of the discriminability to children's relative discrimination
of exploration across all 16 contrasts here.
So I was thrilled by this
and I'm introducing it because the rest of this talk is going to be about
everything I think is perhaps misleading
or a failure of this way of looking at play.
But what I want to suggest is you can certainly use exploratory play
as a very precise measure of uncertainty
and expected information gain.
And just for the record, children's shaking entirely depended
not on what they heard but what they didn't hear.
It was entirely independent of the actual number of marbles in the box.
Everyone clear?
Okay.
So that's great, right?
And it really is.
I have to remember I'm being recorded.
I'm used to pacing so I'm going to try and stand in front of the microphone.
In some ways it's the pinnacle of work that I started
when I came to MIT that I have always been interested in.
Everyone thinks play leads to learning.
That is an incredibly hard thing to make scientifically precise.
We don't have good accounts of play.
We barely have good accounts of learning.
Linking them up with each other is a major pickle.
And yet it's the most uncontroversial claim in the field.
Everyone thinks researchers, educators, parents, play leads to learning.
How exactly is that supposed to work, right?
And this seems very satisfying.
If children are actually sensitive to all the formal principles
that might lead to information gain, right?
That might indicate uncertainty.
If their interventions in the cases where they're capable of generating
informative evidence through play really track this,
then that is a pretty good explanation of how it might lead to learning.
But I have to tell you that the difficulties in this account,
maybe not just an account of learning, but certainly as an account of play,
emerged right away.
They were present in my dissertation research.
So I'm going to show you a little example.
One part of my dissertation gave kids a simple gear toy
where there was a switch and two gears.
And the idea was looking at you to Pearl's interventionist accounts
of causal inference.
And if it's a case like this, you know, it's a simple toy,
but there are a lot of possible causal structures.
The switch might turn on the yellow gear, which moves the blue one.
The switch might turn on the blue gear, which moves the yellow one.
It might be a common cause, and the switch independently can activate either gear.
It might be some weird interaction where neither gear moves
unless both gears are in place, right?
The nice thing is you could find that out because if you say isolate your variables
and the blue gear doesn't move without the yellow gear,
but the yellow gear does move without the blue gear.
When you activate the switch, you can be pretty sure that the yellow gear
made the blue gear move, right?
So again, you can do a simple scientific intervention, isolate the variables,
find out what happens.
We tested this with children.
We tested children both singly and in pairs because we thought in dyads
that it might be even more likely to generate the relevant evidence.
It's super easy to isolate variables if you're competing over resources, right?
And they might get the informative intervention.
And we found that indeed, children, both when we showed them these interventions
and when they generated the evidence themselves in play,
the paper reports accurately that they were, you know, pretty good at figuring out
what the causal structure was from the evidence they observed.
But what I want to show you now are outtakes from the dyads playing in this experiment.
No.
Sometimes they generate the evidence, but in a fairly chaotic way.
Oh.
The green one.
I can hear it inside.
But it's way louder and stillier.
This is where I like to point out that you might not be laughing
if this were your dissertation research.
This is not the exception.
This is the rule.
The exception are our published papers.
In our published papers, we as very clever scientists
or moderately clever scientists who have clever graduate students
find ways to use play as a dependent measure of expected information gain.
We find ways to map it onto what we currently know
and our current best theories and accounts of learning.
But behavior in the wild is this.
If you hand children the stimuli, marbles and boxes, you don't know what you're going to get.
But what you're not going to get is the experiment that I send out to a journal, right?
That's the only thing I can tell you for certain.
And this has bothered me.
It started bothering me there.
It's bothered me for 15 years.
You know, I got tenure here and a lot of these papers showing this nice mapping
and then I stopped working on play and learning for about seven years.
I started working on social cognition and emotion and utility calculus and other things.
And I'm now coming back to it.
And I'm coming back to determined to take play seriously and say,
okay, what's really going on?
Because these are our most intelligent learners, right?
These are the organisms that solve all the hard problems of learning.
All the problems we would like our computers to solve.
They can't drive cars.
They can't play jeopardy.
They can't let go.
They have no market value.
But they recognize faces at a glance.
They can learn from one or two examples.
They can't look 20 moves ahead and go,
but they invent imaginary worlds literally as child's play.
And they start doing that around 18 months old, right?
So if we really want to understand human cognition,
if we really want to engineer intelligent behavior,
I think we need to grapple with what is really going on here.
And it's not just in my laboratory experiments.
That was data from around 2004.
This is data from around 2008 and 2009.
This is a baby I know well who was born in 2007.
And I watched her play too.
And I tried really hard to understand this very systematic behavior
she was engaged in.
It was systematic because she engaged in it in various settings.
If we're in the park, she engaged in it with acorns.
If we were in a restaurant, she engaged in it with sugar packets.
And I could try to tell stories that she was learning
something about folk physics or support relations.
Or maybe she was creating sets or collections or groupings of objects.
But as you'll see in a minute, she's perfectly happy to include
that polar bear in the grouping.
And I know perfectly well that she can distinguish the polar bear
from these other things.
Here's the thing you can't really see in the video
because I'm not going to let you see it,
which is it goes on for 25 minutes.
So never let anyone tell you babies have short attention spans.
She engaged in this behavior repeatedly and consistently.
And the main thing I knew is that my hypotheses about what was going on
were deeply under-constrained.
I could make up anything, right?
But I didn't have good evidence or predictive power, explanatory power
for any of what she's doing.
But she's highly motivated to engage in it.
She's deeply persistent.
The only thing I can say for her is that she's set a problem for herself,
which is getting objects from this location into this location.
And she finds this deeply fascinating, right?
And goes on and on.
It gets worse from here, right?
You know, a year later, this is what she's doing, right?
And she's talking to herself the whole time.
So what do I think is going on?
What is the relationship between play and learning?
Let's acknowledge the value of the current accounts
because it's real.
Some kinds of play, especially motor play,
might generalize to real-life skills in adulthood.
This was an account advanced back in the early 19th century, right?
Play as practice.
Even in the animal behavior literature, when you look at meerkats or kittens,
and you want to say, oh, something about the ways they play
and their hunting will make them better hunters as adults,
or a play fighting in wolves will make them have more territorial dominance as adults.
The current papers on that should find null results,
which is to say individual differences in play or opportunities for play
do not seem to actually predict adult success in hunting or fighting.
Nonetheless, it remains possible in a kind of species general way,
and quite likely that some kinds of this play,
and it's certain that if you practice soccer, you'll become a better soccer player, right?
So some kinds of play surely are going to generalize to those skills.
Some kinds of play might help you learn physics and folk psychology
or intuitive theories about objects and forces and agents and goals.
Now, I need to caveat that by saying what we know for certain
is that early in infancy, babies have a lot of intuitive representations
of physics and objects and agents and goals,
and they have those before they can even act on the world themselves.
Nonetheless, despite this really rich initial set of representations,
they might refine specific predictions about the particular mechanics,
the particular interactions of objects in the course of their play.
But for most of the elaborate play you see,
children couldn't possibly play the way they do
unless they already knew a lot about how objects and forces interact.
It is still the case that play might teach kids how to plan in that space,
and I think that's very important.
But I don't think it's teaching them broad general principles
about objects, forces, and agents and goals,
because I think they already know that.
And again, to make that really intuitive,
there are all kinds of pre-cocial animals that hatch and fly, right?
And gazelles that are born and run across cliffs.
We have a rich evolutionary legacy of knowledge about objects and agents and goals.
Not all of which needs to be learned for play.
And then there's the question also of why is play the best way to learn it?
Because you have a lot of experience in the physical world
and a lot of experience with agents that is not play.
But let's hold that out as a possibility.
Some kinds of play might do the kinds of things that my research program said they do.
Support, effective information gain, and improved prediction.
But again, it's just not so clear in the examples I showed you,
and it's certainly not clear when your child says,
okay, I want to make cookies from my sandbox,
or let's see if I can catch the velociraptor who's imaginary
by dropping Play-Doh on it from the couch, right?
Is that supporting expected information gain?
I can tell stories, but I am just telling stories.
Okay, so we can use play to assess these things,
and I think it is important if it didn't play some role
and wasn't sensitive to this, we couldn't use play as a dependent measure.
But I think it can't be the whole story.
One thing is true of play, and from here on out,
it gets totally speculative, right?
So this is what I'm working on right now.
One thing is true of play.
Both exploratory play and pretend play,
and that, by the way, is important because kids,
scientists distinguish them, but kids don't.
When kids are busy catching the velociraptor,
they're busy exploring the properties of the Play-Doh
and the tinfoil they're using to do it, right?
It's an imaginary velociraptor, but they're still engaging
in all kinds of exploratory play designing it.
It's seamless for them.
And we can't always tell which is which.
One thing is true.
Children make up problems and they solve them, right?
That, I think, is generally the case.
And what I want to suggest is that we have to take seriously
that those problems are not...
Playing with dolls does not make children better parents.
Playing with blocks does not make them better architects, right?
That is not what is going on.
But there might be something in the arbitrariness of the problems
that children set for themselves that is the point.
The problems and solutions don't matter.
In fact, often children set problems for themselves
they cannot solve.
They spend all day planning to build a spaceship
and then abandon it as a pile of cardboard and cellophane
on your living room for days until you make them clean it up, right?
But there's never a spaceship and there was never any possibility
that it would be even like the kinds of pictured
spacebooks you see in toy magazines.
Because that's not what kids do.
They start it, they get really into it, they have all these plans,
and then they abandon it because it's really hard
to tape things together at right angles and, you know, it's done.
So what are they doing?
What might matter is exactly this ability,
the ability to invent arbitrary problems and use them
to begin bootstrapping new plans and solutions.
So that's the kind of general idea I'm going to explore from here on out.
Because what I want to suggest is there is a hard problem
that we know about and the really hard problem of learning
is not learning, right?
Learning from data, it turns out that both computers
and children are really good at.
And the really hard problem of learning is maybe coming up
with new ideas and hypotheses in the first place.
So I'm going to borrow some quotes from a talk I gave a couple years ago.
But these quotes are actually from the description of the workshop,
which was a workshop on learning as program induction.
And it said, coming up with the right hypotheses and theories
in the first place is often much harder than ruling among them.
How do people and how can machines expand their hypothesis spaces
to generate whole new ideas, plans, and solutions?
How do people learn rich representations and action plans
expressable as programs through observing and interacting with the world?
These are the hard problems that that workshop was taking on.
And I want to suggest that this may be hard problems for AI,
but they are things that humans are really good at.
Because our ordinary everyday thought is richly productive.
We can quite reliably make up new relevant answers
to pretty much any ad hoc question I ask you at all.
Now the answers may be trivial,
and the answers may and usually will be false,
but they are genuinely new,
which means you didn't have them until you thought of them.
They're generally made up.
You didn't learn them from new data and new testimony.
And they are answers to the question,
which is to say they're possible answers.
They could be wrong or they could be right.
They're not non sequiturs.
Here's an example.
Why doesn't McDonald's sell hot dogs?
How would you get chimney swifts out of your chimney?
What is the origin of the phrase?
Flotsam and Jetsam.
How do peppermints get their strips?
Let's guess you don't really actually know the answer to any of these
unless you're a chimney swift extermination expert
or have some specific knowledge.
But most of you can make up pretty good answers
and you might even convince other people your answers were correct.
That's kind of the business we're all in, right?
But actually as human beings, I would suggest
that's the business we're all in.
What are you doing?
You're not constraining your answers with respect to the data.
And if you constrain them with respect to prior knowledge,
it's of a very general sort,
very specifically mapped to the format and information
in the problems themselves.
You are startlingly good at doing this.
You quickly converge on ideas, plans, and solutions
that may not be right, but they are at least wrong.
Right?
There's a lot of other things they could be, right?
Just repetition of content,
just like peppermints are peppermints.
That's also part of your prior knowledge, right?
But it's not anything.
You or a kindergarten would ever say, right?
We have some accounts of how you might degenerate ideas formally, right?
Using prior knowledge as stochastic recombination of primitives,
some random search methods, right?
A bias towards simpler things.
And the sheer productivity and rapidity of thought,
even in early childhood, has made me think
these are maybe not enough.
And so the proposal I want to suggest is that
problems themselves are the solution to the bigger problem
of how to constrain search.
That having problems imposes informational constraints
on the kinds of ideas and plans you can generate
in a way that lets you generate plans and ideas.
And so the point of the problems is not necessarily to solve them
or even to have them.
The point of the problems is to let you think.
Let me give you some examples.
Not all problems, by the way,
are communicable in natural language.
Any kind of goal is a problem, right?
But some of our problems in humans
are expressed in natural language.
It's a striking fact about humans
and query basically anything with a handful of question words.
And this question word already tells you a lot about how to answer them.
So I can ask who or where or when or what or which or how or why.
And you don't know what I'm asking who, when, where, which, how, why, about,
but you already know that an answer to who is some kind of social network,
an answer to where is some kind of map,
an answer to when is some kind of timeline,
what is some sort of category structure,
which is a Venn diagram, how is some circuit,
why is some kind of causal structure, right?
So you've already constrained your search
just because I've posed it as a query, as a problem, as a kind of question.
And it gets better from there because if I say why does or why did or why can't,
I've already told you a lot more about what you have to say.
Why does some rule or empirical generalization hold?
Why did some unexpected event occur?
Why can't something desirable or seemingly possible happen?
And as soon as I say why did she, then it's an agent.
And as soon as I say why did the chicken, it's a joke, right?
So you already can use just a tiny bit of data to converge on candidate answers
in a way that solves, I think, one of the really, really hard problems that we have in learning,
which is at some point you have to search maybe using all of these other tools
that we know about within a space, but the smaller a space you can search,
and the better, right?
The more likely you are to be able to use all of your other tools
to start getting close to an answer.
So if you can constrain search, you can begin to spin off ideas.
And it's also the case that this is the kind of thing about which we, as humans,
have met a cognition, right?
So we know a lot about our problems.
We can tell you, sorry, I'm going to actually back up because I think I didn't include this slide.
We know a lot about our problems, so I can tell you that something is a great answer
even when I know it's wrong, right?
As faculty, we do this with students all the time.
As PhD students, you do it with your undergraduates.
As undergraduates, you do it with your little siblings, right?
It's a great idea, it's wrong, you know it's wrong.
What do you mean great?
It's actually false of the world.
What do you mean by great?
What you mean is that there's something about the solution that could answer the problem.
It has the right form, it has the right structure, right?
You can also have the sense of being on the right track in generating a solution,
even when you haven't gotten new data, even when you're still really far off,
even when you have a better predict of the world.
We have an intuitive representation that this is making progress, right?
Again, with respect to what?
Not the world, but maybe with respect to the information in the problem.
So I think this is important, and I also think that when we can't do this, right?
When we don't have an abstract representation of what might count as a solution,
then we might have to resort to really inefficient, ineffective searches.
So what it might mean for us to think a problem is tractable or well-posed in an informal sense,
like we understand it.
Might be to recognize that we don't know the answer,
but the problem contains enough information to guide search, right?
And again, this isn't, I think, just true of natural language, but queries broadly.
I have some puzzle pieces down there in the corner,
because as it happens, I'm terrible at spatial relations, right?
So I never understood why puzzles were fun.
If you give me a thousand-piece puzzle, I'm going to try all a thousand pieces
in all four configurations, and guess what?
I think that's boring, and I quit, right?
Those of you who like puzzles probably can represent something about what you're looking for
before you find it, right?
You have some sense of where you should be in the search base.
That metaphorically and in a hand-wavy way is the kind of thing I'm talking about.
If you really have to engage in random stochastic search over every possible solution,
even for a thousand-piece puzzle you're posed, right, that is a bad way to spend time,
and I think boredom and frustration are pretty good epistemic signals
of stop working on that right now.
You're not going to get anywhere fast, right?
Engagement, and part of what I want to mean by what curiosity is,
is you have information in the problem that suggests you could plan.
You could start proposing hypotheses.
You could start moving towards a solution.
The problem has enough structure.
You know enough about that structure that you can begin to make progress.
And again, critically, that is not progress.
There are theories of curiosity out there, which I greatly admire.
Udie and colleagues about increases in predictability
or a sense of your learning rate.
But here, you know, you might be years away from learning anything, right?
You might not be making better predictions in the moment.
What you are doing is generating more and more ideas, right?
What you are able to do is start proposing hypotheses,
and that may matter long before you can tell whether those hypotheses are true about the world.
So what do I think we know about our problems?
I think we know a lot.
So we have a little gesture at some projects that say, you know,
one of the things you know about your problems,
besides whether they are consistent with prior knowledge,
or whether there is pattern, you know,
even if you don't have any evidence directly linking them,
no interventions, no patterns of covariation.
You might know, if I tell you for instance,
I have red and black seeds, right?
And I get different patterns of flowers.
And you might know if your two kinds of seeds come in a 50-50 distribution
and you have a flower patch that is in a 50-50 distribution,
or if you have seeds that are in a 90-10 distribution
and a flower patch in a 90-10 distribution,
you don't know anything about whether red seeds generate one kind of flower,
black seeds another, and there's no features that might link those two together.
But you already know that the proportion of seeds ought to tell you something
about the proportion of flowers, right?
You might not know which of these two causes generates which of these effects,
but if you have a discrete effect and you have a continuous effect
and you have a possible discrete cause and a possible continuous cause,
you should already think the discrete cause is more likely to go
with the discrete effect and the continuous cause with the continuous effect.
You might be wrong, but it's not a bad way to partition your search.
And on and on, for the many things you might know,
you know about the variance, you know about the range of things,
you know how many states they might occupy.
You might know if they're cyclic or not cyclic.
You might know if they're linear or exponential.
You might know if it's an alternating sequence or a continuous sequence.
And even very young children are sensitive to all these abstract features
which help guide their search in the absence of any interventions,
any covariation data, any distinguishing prior knowledge,
and that helps them start to hone into solutions.
So I think, oh, this is the slide I was looking for, but I already said it.
But here's the important point I want to get to on the slide,
is that we can clearly constrain and evaluate our hypotheses
based on how well they fit the data, right?
Their truth, how right they are of the world, how much predictive power they get,
how much they reduce uncertainty, how much they increase inspected information gain.
But we might also constrain them on how well these ideas would solve our problems
if they were true.
So Stephen Colbert, the media made fun of this.
He talked about our predilection for truthiness
and the way politicians can take advantage of us
by posing ideas that are truthy, although not true.
And I think that is certainly a bug of human cognition,
but it might also be a feature.
Our ability to value ideas based on their abstract fit to a former solution, right?
The possibility that they could solve our problems even if they're true
is part of what lets us go so far beyond the data, right?
And lets us make progress in cases where we just have nothing else to go on, right?
We don't have evidence, we don't have interventions,
we don't have distinguishing prior knowledge.
But we have a problem and we have an idea that has the right form
to possibly make progress on that problem.
This is an account that Josh Tenenbaum and I have started referring to
as cognitive pragmatism, where we might evaluate our proposal,
in homage to William James, of course,
where we might evaluate our proposals first and foremost,
not on their fit to the data,
but on how well they might solve a problem or answer a question.
And this might in part explain why we have so many problems,
because one of the species distinctive things about us is that we proliferate problems, right?
We populate the world with problems of our own making.
Some of us want to end poverty or cure cancer,
some of us want to write the great American novels,
some of us want to achieve enlightenment,
some of us want to design great new AI algorithms,
some of us want to understand how children learn and play,
some of us want to eat more hot dogs than anyone else,
and I could go on, right?
I could go on.
A simple story is that, well, we have so many problems because we are so smart,
but I would like to suggest the opposite,
that we are so smart because we can generate all these problems
and each problem sets up a new way of generating new plans
and new ideas and new strategies.
And the lovely thing is you can decouple the ideas you generate
from the problems that were designed to solve.
You don't have to solve the problem to have thought of an idea, right?
And you don't have to care about the problem anymore
to value the ideas that they generate.
So some of my favorite examples are that we have analytic logic
because medieval monks wanted incontrovertible proof of the existence of God.
So they wanted things that were verifiably, provably, and always true.
You don't have to care about the problem to still value the solution that was generated, right?
So our problems are not, interestingly, just confined to all the things that I said there.
We like problems so much that we make up ones that have no basis in reality at all.
We lock a dead body in a room with no entrance or egress,
and we stick Sherlock Holmes in there to try to tell us how that murder happened.
We create mythical beasts and magic wands, and we try to figure out,
we set up incredibly complex dynamics where the only value of those things
is not that they are true or accurate about the world,
but is it a good problem and a satisfying solution?
I was recently giving a talk in Dubrovnik, so I had to throw in this one.
Also, I gather something very bad went down there with some dragons.
We like our problems so much that we invent entirely toy problems thousands and thousands of years ago,
and then we set them up as toy problems to see if there are problems
that our most compelling new intelligent machines can address,
which, again, I think speaks to the power and richness that we get from setting these up.
And part of what I think is important and connected to this idea is about curiosity,
is one reason our motivational system may be as rich as it is
is because goals can further advantages for learning.
And wanting a lot of things, wanting different things, each of us wanting all kinds of different things,
might be a lever into setting up different goals, different problems,
which as a species that shares and transmits knowledge and gets cultural ratchet effects
might allow this kind of knowledge to accumulate.
And one of the things that has struck me a lot is that humans are, of course, sensitive,
even as babies, we are very sensitive to utilities and action, right?
And we can use the fact that one action is more costly than another
to infer that that thing must be more rewarding than another.
And, again, even infants can make those inferences.
Somebody goes further, reaches longer for one thing than another thing,
and then they're both equidistant.
The babies expect that the agent is going to go to the thing
that they put more effort into reaching in the first place.
So they can use knowledge of efficiencies to expect the agents will take shortest paths
towards their goals and that if they do something that violates these utilities,
that they want something more rewarding.
So clearly, we're sensitive to real-world constraints.
And clearly, we are also sensitive to opportunities for learning, for uncertainty,
all the other early work I suggested.
But we can do something that maybe no other creature can do,
which, well, actually, I'm never going to bet against other nonhuman animals.
So I'll retract that.
But we are uniquely specialized in our ability to wantonly incur unnecessary costs
to achieve arbitrary rewards.
And if I'm going to come up with an idea of what play is, it's that.
If the costs and rewards are real, you're no longer playing, right?
But if you are willing to take on unnecessary costs to achieve an arbitrary reward,
maybe you are playing.
And I'm going to skip that bullet point because I can't remember what I wanted to say about it.
But what I do want to suggest is, oh, right.
So ultimately, you might think that that kind of behavior does support learning in some sense, right?
Being able to explore and plan in any of these spaces, right,
is ultimately in the service of reducing uncertainty, supporting prediction, right?
There must be some story that runs back out.
But locally, what it really might do is just allow us to make plans to set up spaces
to explore and think and plan in ways we would not otherwise, right?
Being able to say, well, this is the reward.
These are the costs I'm willing to incur.
You can just take off in different trajectories.
And that might be a big part of what's going on in play.
And this, returning to the first point I was going to make,
if you only explore in ways that increase expected information gain,
you will sort of definitionally be likely to miss many chances to gain entirely unexpected information.
And although we have a lot of uncertainty about the world and there are a lot of things we don't know,
there are probably more things we don't even know we don't know, right?
We're a fairly new species.
We're only recently clever in some of the technologies and the ways that we have exploring.
Creating new problems with no obvious utility in themselves,
taking seriously the idea that the point of play is that it is useless in any local sense.
It's not there to make you a better adult, right?
It's there to help you think, right then, to help you generate a new idea, a new plan, a new proposal.
That might be the best way to discover genuinely new things.
So maybe it's not that we're smart enough to generate new problems and goals.
Having problems and goals might let us be smart.
And the value of these solutions may exceed the generalizability or merits of any given problem or goal.
So returning to this idea of learning as program induction
and all of these ideas that were advanced in that conference a couple of years ago,
I would add to all of the mix of the other ways that we have of thinking new thoughts and engaging in new learning
that we can also use the information and our problems to bootstrap our way towards solutions
and that includes the problems that we invent all by ourselves.
And that's it.
Thank you very much.
We have time for a couple of questions.
Then we will have a social event in the third floor.
So could children be playing just because it's a fun and enjoyable thing to be doing?
Yeah, so when I do have more systematic, or eventually this talk will become more systematic,
but I've already had to write various things that are more systematic.
And when I do that, I talk about, I borrow from this first formulation of play as practice
to generate a few other P hypotheses about what play might be for.
And some of the things play might be for are not cognitive at all.
So play could be for pleasure.
If it turns out that it is evolutionarily adaptive for young monkeys to swing through the trees
and they should find that pleasurable and they should like to cling on to swinging things,
then anything that lets you cling on to swinging things and experience rapid motion might be pleasurable.
And so play might exploit that.
If it's useful to find soft fruit, you might have a slime complex going on right now
among middle school, younger children.
If you're not a parent, you might not know this, but slime is all the rage.
And children are constantly making squishy things.
Why? Presumably because it's pleasurable.
This could be just epiphenomenal things.
It's also true that play could be performative like peacock feathers.
It could show I'm fit and like I have abundant energy and resources.
So play could be for pleasure.
It could be for practice.
It could be a kind of performative gesture.
It could be for prediction.
But I think it's for problems, setting up problems.
In addition.
I have a question.
When you were talking about children setting themselves problems that they couldn't solve,
I didn't fully understand if it was as in things that we know that they cannot solve
or build a spaceship, or they also know that they cannot build it
and they want to know how far they can go.
In general, I think kids care less than you might think
about achieving the plans they create, right?
In the descriptive work on play, there's a lot of studies that show how much time
could Ben setting up play as opposed to playing itself.
So there's been a lot of time designating roles and getting the materials
and like building the infrastructure and then, you know, it's dinner.
So they seem to get a lot of pleasure out of the planning
more than just the solutions.
And yes, I think every children are actually remarkably good at telling you
really engaging in pretend play, but being very clear it's pretend.
Children know they're not actually going to go to Mars.
Yeah.
How do you think about the differences in problems that children pose
on the child and problems that they create themselves?
That is a subtle dynamic because I think if the problem we impose
on the children is sufficiently arbitrary, they'll buy into it as play.
If it smacks of having real-world rewards or costs, it's not playing anymore.
The ones they generate for themselves, they're quite confident
if they're generating them as arbitrary problems that they are playing, right?
Even if they're doing things that look like hard work,
like kids will spend hours writing stories that you could never get them
to assign them in school, right?
But if they impose it on themselves, my sister and I used to wash the garage
extensively because we were playing some game.
If my parents had told us to wash the garage, all that's would have been off.
But I think that what matters is in some sense this word,
I don't have a better way of characterizing except arbitrariness,
not necessarily that it's endogenous because kids will play soccer,
they will play basketball, right, and really get into it.
They will play games that adults suggest them.
They play board games, right?
So obviously they don't have to create all the problems themselves,
but I think they are fairly sensitive to the deep structure of those problems.
So one of the spaceships, for example,
like if I want to have the goal of building spaceships on the curry,
and on the other hand, whatever work they actually do,
doesn't come anywhere with what you've accomplished in the goal of building spaceships
that like what?
What's the relationship?
Yeah, what's the relationship?
What did I like to know?
A spaceship has some things you know about it, right,
that require some preliminary steps.
Like it's reasonably large, it needs to contain you in it.
You might want windows or some transparent material out.
You might want things that you imagine might, you know, conduct heat, right?
So they have a bunch of, we all have ideas about like what a spaceship is, right?
And those ideas let you start thinking,
well, how might I, you know, make something really big
and that would contain all of us and that, you know, can I use the saran wrap
to make a window or whatever it is.
So I think it's just that there's enough information in the idea of a spaceship
that they can back generate some plans
and I think what we might be most sensitive to is the number of plans we can generate.
Like what is rewarding, what is motivating,
what's sustaining about curiosity,
the ways it lets you spin off hypotheses, proposals, and plans.
And that's what those ideas are doing for you.
A spaceship happens to be rich in those.
Catching a velociraptor with Plato is also fairly rich in those.
We're all like, okay, well, it's going to be moving really fast
and we're going to, you know, you already know enough about what that looks like
and that might be all you need to know.
Let's turn the speaker again.
