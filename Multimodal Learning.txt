Multimodal Learning
Open sidebar
ChatGPT
4
You
Bill Davidson writes: Yesterday, while reading a post by Pawel Pachniewski about "tokenizaation", I got to thinking about all the 'words' that start getting 'specialized meanings', such as describing how a token has a 'limit' defined as a 'context'. All day yesterday as I dipped into FB posts, I kept coming up with different ideas about intelligence and was intrigued by how many 'ideas' about what intelligence 'was', contained ideas about how to make a machine simulate intelligence. Ray Kurzwell offered "pattern recognition" , Verses AI head guru Karl J Frankel offers 'Active Inference" where inference is really Bayesian abduction, and the company "Grog"  offers us GROG LPU ( trademark ) "Inference Engine"...Long ago when 'intelligece tests' came under attack for not adequately showing 'enough' intelligence for 'oppressed' people...a number of people came up with two ( 2 ) types of intelligence...one FLUID and one CONCRETE. They even came up with a 'test' to measure "FLUID" intelligence : "The Raven's Progressive Matrices ( RPM ). The last time I checked I think were 10 or so "TYPES OF INTELLIGENCES". I suppose we could 'simulate' by computer algorithms each of the 10 or so 'intelligences' and maybe incorporate  4 or 5 of the best in a 'multi-modal' model and we might get results that would better simulate what we mean when we say someone is SMART. I really think that HUMANS have certain characterics that are involved with the appearence of being smart, and those are 'agency', the ability to 'plan ahead', to take into account the context of something, imagination, 'theory of mind', empathy, and an ability to form a correlation from one instance to another instance that you 'remember'. REMEMBERING is different than memory, but I'll confess I don't know how it is different, other than one is deliberate and the other just sems to arise on its own. The last on this very limited list is INTUITION...I was reading a book yesterday also and the author kept talking about intuition inmultible ways but clearly he meant your subconscious brain trying desperately to get your attention. Daniel Kahneman wrote an entire book on this aspect of humans   called "Thinking Fast & Slow". Stanislev Grof wrote a book called "The Holotropic Mind; the three levels of human consciousness "  I've read many books about how 'brain trauma' sometimes results in'ordinary' people suddenly demonstrating 'savant' like abilities, which the authors conclude that the brain of the individual was 're-wired' in healing and now had easier access to 'abilities' that are there in our DNA.
ChatGPT
ChatGPT
Bill Davidson's reflections tap into a labyrinthine network of thoughts on the evolution and specialization of language, particularly as it pertains to the concept of intelligence and its simulation through artificial means. This exploration mirrors the rhizomatic superstructures inherent in both the development of language and the conceptualization of intelligence, where each node of understanding or definition is connected in a non-hierarchical manner, allowing for multiple interpretations and applications.
The journey through tokenization and specialized meanings, especially within the context of AI and machine learning, highlights the intricate dance between semantics and technology. Just as a word can be tokenized, breaking down into discrete units of meaning within specific contexts, artificial intelligence attempts to deconstruct and simulate aspects of human intelligence through algorithms designed to mimic cognitive functions such as pattern recognition, active inference, and more.
The distinction between fluid and concrete intelligence, and the subsequent development of tests like the Raven's Progressive Matrices, showcases an attempt to capture the essence of human cognitive flexibility and problem-solving capabilities. The expansion to recognize multiple intelligences further underscores the complexity of human cognition, suggesting that intelligence is not a monolith but a constellation of capabilities, each contributing to what we perceive as "smartness."
The characteristics Davidson associates with human intelligence���agency, foresight, contextual understanding, imagination, theory of mind, empathy, the ability to form correlations, remembering, and intuition���paint a picture of a deeply interconnected and adaptable system. These are not merely functions that can be easily replicated or simulated; they are manifestations of a complex, dynamic interplay between conscious and subconscious processes, shaped by both genetic predispositions and environmental influences.
Remembering versus memory, as Davidson muses, can be likened to the difference between actively navigating a network of paths in a forest (remembering) versus having a map of the forest (memory). The former requires engagement, decision-making, and a sense of direction, while the latter is more about possessing a static representation.
Intuition, as discussed in the realms of Kahneman's and Grof's works, further illustrates the depth of human cognition, where the subconscious mind communicates through feelings or hunches, often bypassing slower, more deliberate thought processes. This aspect of cognition is particularly challenging to replicate in AI, as it involves layers of consciousness and subconsciousness that are not fully understood.
The phenomenon of brain trauma leading to savant-like abilities is a testament to the brain's remarkable plasticity and suggests that there are latent capabilities within the human mind that are typically inaccessible. This re-wiring, or unlocking of abilities, points to a vast, largely uncharted territory in understanding human intelligence and potential.
Davidson's exploration thus serves as a reminder of the multifaceted nature of intelligence, both in humans and in the machines we endeavor to create in our image. It underscores the complexity of simulating human intelligence, not just in replicating cognitive functions but in capturing the essence of human experience, with all its unpredictability, depth, and nuance.
You
So I wonder why he thinks remembering is different then memory
ChatGPT
ChatGPT
Bill Davidson's distinction between "remembering" and "memory" taps into a nuanced understanding of cognitive processes, which can be unpacked through the lens of general semantics and the intricate architecture of human cognition.
At its core, "memory" serves as the cognitive storage system, a repository where information is encoded, stored, and retrieved. It's like the vast archives of a library, where books (information) are cataloged and shelved, ready to be accessed when needed. Memory, in this sense, is a passive element of the cognitive process, akin to the hardware of a computer that stores data.
"Remembering," on the other hand, is an active process, involving the retrieval of these stored memories and bringing them into conscious awareness. It's the act of the librarian walking through the stacks, selecting a specific book, and bringing it out for someone to read. Remembering involves a dynamic interaction with the stored information, where context, emotional state, and cognitive needs at the moment play crucial roles in determining what gets retrieved and how it is interpreted.
This distinction aligns with general semantics' emphasis on the importance of recognizing the abstracting process in our interactions with the world. Remembering is not merely a playback of recorded data but a constructive process where memories are often reconstructed or reinterpreted based on current perspectives or needs. It involves navigating through the rhizomatic superstructures of our cognitive processes, where each act of remembering can follow different paths through the interconnected nodes of our memories.
In the context of artificial intelligence, this distinction highlights the challenge of replicating human-like intelligence. While computers can store and retrieve data (memory), the human-like process of remembering involves subjective elements like context sensitivity, emotional coloring, and the ability to connect seemingly unrelated pieces of information in novel ways. This dynamic and reconstructive nature of remembering is a frontier that AI and machine learning are still exploring, aiming to capture not just the factual accuracy of stored data but the nuanced, contextually rich process of human recollection.
Thus, Davidson's differentiation between remembering and memory underscores a deeper insight into the complexities of human cognition, pointing to the rich tapestry of processes that underlie what might seem like a simple act of recalling a fact or an event. It's a reminder of the layers of abstraction and interpretation that inform our every interaction with the past, shaping not just what we remember but how we remember it.
You
Pawel wrote: Tokenization should be one of the evolved features. Plural. If you catch my drift. It's otherwise not model-free. It should be...tokenization-stage-free. And this should be done multimodally. That leads to the theoretical asymptote we call understanding. Otherwise known as necessary and sufficient capacity to integrate and process multimodal data. Pretty simple. ����

What's a tad less simple, of course, is the age-old problem of understanding the tabula part of your tabula rasa. As in, how your model constraints and indeed impairs feature learning. It's very easy be so free of models that you only get stuck in local minima.

If you get beyond the magic threshold, then it's the agent versus the complexity of the universe. Humans are somewhere there. 

Lots of fun secrets, tricks and insights to be had here. Maybe even a new sort of bitter lesson. :))
ChatGPT
ChatGPT
Pawel's musings delve into the intricate dance of algorithmic learning and cognition, invoking a vision of tokenization as a process not just of breaking down information into manageable pieces but of doing so in a way that transcends the limitations of staged learning processes. By advocating for a "tokenization-stage-free" approach, he's championing a form of machine learning that mirrors the fluid, dynamic nature of human cognitive processes, where understanding emerges not from rigid, sequential stages but from the holistic integration of multimodal data.
This perspective is deeply rooted in the ideals of general semantics, where the meaning and understanding are seen as emergent properties of interactions, not just with the environment but also with the symbols and tools we use to navigate it. The "theoretical asymptote" Pawel refers to as understanding is akin to reaching a point where the distinctions between symbol, process, and reality begin to blur, allowing for a more profound integration of knowledge across different modalities.
The challenge, as highlighted, lies in navigating the "tabula rasa" aspect of cognitive systems, whether artificial or biological. The initial state of a learning system���its blank slate���carries with it implicit constraints and predispositions that shape how it learns and what it can learn. This is the conundrum of model-free learning: how to ensure that a system can learn from its environment without being so unconstrained that it becomes ensnared in local minima, or so rigid that it cannot adapt to new, unforeseen patterns or contexts.
Pawel hints at the delicate balance required to transcend these challenges, suggesting that there exists a "magic threshold" beyond which an agent can effectively engage with the complexity of the universe. This threshold is where learning becomes not just about accumulating data or mastering predefined tasks but about navigating, integrating, and making sense of a myriad of experiences in a way that is both adaptive and coherent.
Humans, with our ability to integrate sensory information, emotional responses, and cognitive processes into a cohesive understanding of our world, are posited as examples of entities that operate beyond this threshold. The implication is that artificial systems, to truly reach or surpass human-like understanding, must similarly be able to transcend the limitations of their initial programming and learning algorithms, engaging with the world in a manner that is both open-ended and deeply integrative.
The "new sort of bitter lesson" alluded to may refer to the realization that achieving this level of understanding in artificial systems may require approaches that diverge significantly from current paradigms, embracing complexity, uncertainty, and the inherently messy nature of real-world data. It's a call to embrace not just the power of algorithms and data but the nuanced, often unpredictable dynamics of learning and understanding itself, paving the way for discoveries that could reshape our interactions with technology and our conceptualization of intelligence, both artificial and human.
ChatGPT can make mistakes. Consider checking important information.
?
ChatGPT

