Reconceptualizing Platonic Forms
Historial del chat
ChatGPT
ChatGPT
Nuspeak Translator
Jain Hive Tree
Zettel Assistant
Explorar GPT
Hoy
Reconceptualizing Platonic Forms
Ayer
Find .bashrc File
Recursive Webpage Download Commands
Extract YouTube Channels JSON
SSH into WSL Ubuntu
Complexity in Decision Making
7 d��as anteriores
Accelerated Obsolescence
Accelerated Obsolescence
Bash Script for Renaming
Image Redirect Implementation
SFTP Directory Path Update
Aspect Relegation and Habits
Bash Script Directory Processing
Count Lines in Text Files
GIF Monitor Effect Script
File Processing Summary Inquiry
Garbage Removal System Concerns
Quantum Static Theory Summary
AI Superintelligence Risk Plan
Principles for Success on Spectrum
Utopianism versus Individualism
Neanderthal Pizza Hypothesis
Available Disk Space Command
Rethinking Neural Network Hierarchy
Existential Insights on Objects
Care Bear Cult Analysis
Skeleton Crew
������������ ������������
Renovar Plus
Nathaniel Guimond
Abrir barra lateral
ChatGPT
ChatGPT
Compartir
Dijiste:
Stephen Paul King writes: I have a problem with Levin's Platonic Forms idea, but have a solution. ;-P

Link to "Collective Intelligence of Cells"
Michael Levin: Consciousness, Biology, Universal Mind, Emergence, Cancer Research



The main problem of all forms of Platonic Forms is the very idea that the structure itself requires no generating or computational process to find the Ideal Forms. 

What is the Ideal form of a life form that has not yet evolved?

...

The alternative that I propose is that we should think of Forms as the Ideal Representation of the particular physical "thing". 

The Forms are like the Perfect Map of the Universe.

...
But we need to figure out how Time fits into all this.
ChatGPT dijo:
ChatGPT
Stephen Paul King's critique of Platonic Forms and his proposed alternative involve deep philosophical questions about the nature of ideal structures and their relationship to physical reality, especially within the context of time and evolution.
Key Points from the Argument:
Critique of Platonic Forms
:
Platonic Forms are considered timeless, perfect, and universal.
The issue King raises is that these Forms seem to preexist their physical instantiations without requiring any process to generate them.
This raises a question: What would the Form of something that hasn���t yet evolved look like? Does it even exist?
Proposed Alternative
:
King suggests thinking of Forms as
Ideal Representations
of specific physical entities.
These would be analogous to a "Perfect Map" that reflects the universe at a given state, potentially evolving as the physical universe evolves.
Integration of Time
:
The challenge becomes incorporating time into the notion of Forms.
If Forms evolve alongside the universe, they must reflect the dynamic nature of existence rather than being static ideals.
Analysis and Exploration:
Platonic Forms and Evolution:
In classical Platonism, Forms are eternal and unchanging, existing outside of space and time. This presents a conceptual mismatch with evolutionary processes, where new forms of life and complexity emerge. If Forms are static, they cannot account for novelty or evolution.
Forms as Ideal Representations:
By reconceptualizing Forms as Ideal Representations, King aligns the concept with physical reality and processes. For instance:
The "Form" of a species would not preexist its evolution but emerge as a perfect abstraction once the species exists.
This makes Forms contingent upon the physical world rather than independent of it.
Time and the Dynamic Universe:
Integrating time requires rethinking Forms as part of a process:
Forms could be seen as dynamic structures that evolve alongside the physical entities they represent.
This idea aligns with computational or algorithmic views of reality, where the universe operates like a constantly updating system.
Implications for Levin's Work:
Michael Levin's research on cellular intelligence, emergence, and biology might provide insights into how complexity and ideal structures emerge in a bottom-up fashion:
Cells exhibit collective intelligence, suggesting that ideal patterns or "Forms" may emerge from local interactions over time.
Evolutionary processes could be seen as nature's "computation" toward increasingly complex Forms.
Philosophical Implications:
Reality as a Computational Process
: If Forms evolve, reality may function like a computational system where ideal structures are continually refined.
Emergence of Ideal Maps
: The "Perfect Map" could be an emergent property of physical systems rather than a preexisting blueprint.
Time as a Dimension of Forms
: Time might be integral to Forms, making them inherently dynamic rather than static.
Further Questions:
How do we reconcile the notion of evolving Forms with the classical idea of universality?
Can we mathematically or computationally describe the process by which Forms emerge and evolve?
What role does human perception play in identifying or constructing these Ideal Representations?
King's critique opens the door to a more dynamic and process-oriented understanding of ideal structures, bridging the gap between classical philosophy and contemporary scientific thought.
4o
Dijiste:
ARTIFICIAL INTELLIGENCE 
Task-agnostic self-modeling machines 
Robert Kwiatkowski1* and Hod Lipson2,3 
A robot modeled itself without prior knowledge of physics or its shape and used the self-model to perform tasks 
and detect self-damage. 
We humans are masters of self-reflection. We 
form a mental picture of ourselves by revis- 
iting past experiences and use that mental 
image to contemplate future scenarios. Our 
mental self-image contains information about 
our body configuration in physical space. Our 
self-image also gives us the ability to link future 
actions with likely sensations. Your mental 
self-image allows you to imagine yourself 
walking on the beach tomorrow, smelling the 
ocean and feeling the sand under your feet. 
An accurate self-image will be key to allow- 
ing robots to learn and plan internally without 
resorting to costly training in physical reality 
for each new task. The ability to self-simulate 
can create an illusion of one-shot learning, 
whereas in actuality, adaptation involves incre- 
mental learning or planning inside an internal 
self-image. A self-image can also be used to 
identify and track damage, wear, or growth. 
Humans likely acquire their self-image 
early in life and adapt it continuously (1). 
However, most robots today cannot gen- 
erate their own self-image. Although recent 
advances in machine learning have allowed 
robots to become increasingly adept at un- 
derstanding the world around them, when 
it comes to understanding themselves, most 
robots today still rely on a hard-coded simu- 
lator (2,3). These designer-provided simula- 
tors are laborious to construct and invariably 
become outdated. 
As an alternative to self-modeling, many 
robotic systems do without a model altogether 
by using end-to-end training for a specific 
task, applying techniques such as model-free 
reinforcement learning (4). Such task-specific 
learning may be good for narrow artificial 
intelligence (AI) but lacks the generality and 
transferability required for robots capable of 
continuously learning new tasks through- 
out their lives. 
Here, we suggest that, because the robot 
itself is persistent across multiple tasks, there 
is strong incentive to extract a self-model and 
then reuse that self-model repeatedly to learn 
new tasks. Moreover, by separating the self 
from the task, every future experience can be 
used to refine a common self-model, leading 
to continuous self-monitoring. 
Early adaptive control methods also at- 
tempted to tune parameters of a fixed an- 
alytical self-model (5). We previously used 
evolutionary algorithms to find the mor- 
phology most consistent with the robot���s re- 
corded action-sensation pairs (6), but both 
approaches make many assumptions. A key 
question remained: Can a robot create a self- 
model with no prior knowledge? 
First, we chose a physical robot with four 
coupled degrees of freedom. The robot re- 
corded action-sensation pairs by moving 
through 1000 random trajectories (Fig. 1, 
step 1). Actions correspond to four motor 
angle commands and sensations correspond 
to the absolute coordinate of the end effec- 
tor. This step is not unlike a babbling baby 
observing its hands. The entire captured 
dataset is provided in (7). 
Importantly, when a robot���s motors are 
commanded to achieve some target angles, 
they do not necessarily reach those angles due 
to hysteresis, self-collision, structural flexi- 
bility, and other effects. Therefore, a high- 
fidelity self-model must capture not just the 
direct geometric transformations from the 
robot���s base to the end effector, but an im- 
plicit relationship between current positions, 
new motor commands, past positions, and 
past motor commands. 
We used deep learning to train a self- 
model (Fig. 1, step 2). Using the acquired 
self-model, the robot could apply a simple 
planning strategy to accomplish a variety of 
tasks. We tested the performance of the ro- 
bot on two separate tasks: a pick-and-place 
task and a handwriting task (Fig. 1, step 3), 
both in open and in closed loop. 
Closed-loop control allows the robot to 
recalibrate its actual position between each 
step along the trajectory by using positional 
sensor feedback. In contrast, open-loop con- 
trol involves carrying out a task based en- 
tirely on the internal self-model, without any 
external feedback, like reaching for your nose 
with eyes closed. This test is also frequently 
used to test human cerebellar dysfunction 
such as dysmetria (8). 
We ran multiple tests with both explicit 
and implicit representations. Explicit mod- 
els capture the relationship between motor 
commands and end-effector position but 
cannot handle self-collision. Implicit mod- 
els capture the sequential relationship be- 
tween state-action pairs and thus are more 
general. In open-loop tests where planning was 
completed successfully, the median distance 
between the physical effector and the target 
was 4.3 cm. In closed loop, the self- model 
achieved a median physical error of 0.6 cm, 
an error lower than the accuracy between the 
analytical model and the physical robot. The 
explicit model achieved a median accuracy of 
0.65 cm. These results suggest that acquired 
self-models would be able to successfully exe- 
cute internal planning and learning on par 
with a conventional simulator. 
The second test involved a combination 
of subtasks and gripper actuations. The ro- 
bot used its self-model to plan how to pick 
and deposit nine red balls, each 20 mm in 
diameter. In closed loop, the self-models 
had sufficient accuracy and consistency to 
execute a pick-and-place task with precision 
similar to analytical forward kinematics. 
The open-loop pick rate was 44%, whereas 
the place rate was 100% of successful picks, 
and most failures were a result of the plan- 
ner, not of the self-model. 
To demonstrate that the same self-model 
could be used for other tasks without addi- 
tional task-specific retraining, we performed 
a second task involving simple handwriting 
with a marker. This task was used for quali- 
tative assessment only.

2019
ChatGPT dijo:
ChatGPT
This study by Robert Kwiatkowski and Hod Lipson represents a significant step in the field of robotics and artificial intelligence. It demonstrates how robots can develop self-awareness and adaptability by generating their own self-models without relying on prior knowledge of their physical structure or environment. Below are the key highlights and implications of this research:
Key Takeaways
Self-Modeling Without Prior Knowledge
:
Unlike traditional robots that depend on pre-programmed simulators or explicit instructions, the robot in this study learned to model itself by observing its actions and sensations.
The process mirrors human development, akin to how babies learn to understand their own bodies by moving and observing.
Methodology
:
The robot recorded
1000 random trajectories
to capture action-sensation pairs.
Using deep learning, it trained a self-model capable of predicting outcomes based on its motor commands and past positions.
Performance Across Tasks
:
The robot successfully used its self-model for multiple tasks, including:
Pick-and-place
: Handling objects with precision.
Handwriting
: Drawing simple patterns.
Accuracy in closed-loop tasks (with sensor feedback) was significantly better (median error: 0.6 cm) than open-loop tasks (median error: 4.3 cm).
Flexibility and Generalization
:
The self-model was not task-specific and could generalize to different tasks without retraining.
This contrasts with many AI systems that require extensive retraining for each new task.
Comparison to Analytical Models
:
Implicit self-models (based on sequences of state-action pairs) were better at handling complex dynamics like self-collision compared to explicit analytical models.
Implications for AI and Robotics
Towards Autonomous Learning
:
The ability to create and refine a self-model autonomously allows robots to adapt to unforeseen scenarios and environmental changes.
Improved Efficiency
:
By reducing reliance on costly physical simulations or hard-coded models, self-modeling robots can expedite development and deployment.
Potential Applications
:
Healthcare: Robots that adapt to patient-specific needs.
Manufacturing: Machines capable of self-calibration and damage detection.
Exploration: Autonomous systems that adapt to unknown terrains or tasks.
Biological Inspiration
:
This approach draws heavily from human cognitive processes, particularly self-awareness and continuous learning.
Challenges and Future Directions
Scalability
:
Extending this method to robots with higher degrees of freedom or more complex interactions poses a challenge.
Real-Time Adaptation
:
Future systems may need to refine self-models in real-time, especially in dynamic environments.
Ethical and Safety Concerns
:
Self-aware robots raise questions about autonomy, control, and ethical decision-making in critical applications.
Integration with Broader AI Systems
:
Combining self-modeling with other AI capabilities, like natural language processing or advanced perception, could result in more versatile systems.
This research underscores the transformative potential of self-modeling robots, paving the way for machines that are not just tools but adaptive collaborators capable of self-reflection and continuous learning.
4o
Dijiste:
The inner screen model of consciousness: applying the 
free energy principle directly to the study of conscious 
experience 
Maxwell J. D. Ramstead���1,2,A, Mahault Albarracin1,3,A, Alex Kiefer1,4, 
Brennan Klein1,5, Chris Fields6, Karl Friston1,2, and Adam Safron7,8

21st April 2023 
Abstract 
This paper presents a model of consciousness that follows directly from the free- 
energy principle (FEP). We first rehearse the classical and quantum formulations of 
the FEP. In particular, we consider the ���inner screen hypothesis��� that follows from the 
quantum information theoretic version of the FEP. We then review applications of the 
FEP to the known sparse (nested and hierarchical) neuro-anatomy of the brain. We 
focus on the holographic structure of the brain, and how this structure supports (overt 
and covert) action.

1 Introduction 
It is a truism that, since the late 1990s, the field of consciousness studies has undergone a 
revival. Since its resurgence, several theories and models of consciousness���both conceptual 
and formal���have been proposed. Theories of consciousness vary widely in their goals, from 
addressing the ���hard problem��� (Chalmers, 1996) of why experience exists at all, to modelling 
how particular contents of experience are implemented by particular neural structures. They 
also vary widely in scope, and hence in the variety of ���consciousness��� that is of interest; 
ranging from theories of basal awareness applicable to all organisms and perhaps beyond, to 
theories of specifically human-like consciousness. These latter typically take as explananda 
not just sensory awareness, but also such phenomena as interoception, the sense of being 
a self, the sense of being the origin point of experience (or subjectivity), and the ability 
to make sense of the minds of other agents (aka ���theory of mind���). Several of these latter 
theories share core features, and overlap in terms of their explanatory targets as well as their 
explanatory posits and assumptions. Indeed, at the time of writing, dozens of theories of 
consciousness have emerged in computational neuroscience alone: for a recent review, see 
(Seth & Bayne, 2022). 
The aim of this paper is to present a model of consciousness that follow directly from the 
variational free energy principle (FEP). At a fundamental level, the FEP is concerned with 
(state) spaces that can be decomposed into some ���thing���, ���particle���, or particular ���system��� of 
interest, and the rest of state space (Friston, 2019a). Provided that the interaction across the 
boundary���that individuates some ���thing��� from everything else���is sufficiently weak, then 
the states on the interior of the boundary will be conditionally independent or separable 
from exterior or external states. Both the particular system of interest and its external 
environment will, in this case, have well-defined state spaces. The FEP characterizes the 
behaviour of such system-environment pairs, regardless of whether their state spaces are 
described in classical (Friston, 2019a; Ramstead et al., 2023) or quantum (Fields et al., 
2022) terms. The compass of the FEP thus includes all systems that are intuitively regarded 
as conscious���including all organisms���but also reaches far beyond them. Our contribution 
here will be to frame an explicit hypothesis about what additional necessary structure must 
be in play for a system, whether described in classical or quantum terms, to be conscious. 
We approach the question of consciousness by starting from the FEP and using it to make 
sense of established features of (human) neuroanatomy: namely, the nested and hierarchical 
structure of the brain that arises from a particular kind of sparse coupling. This sparsity 
structure can be modelled as a set of hierarchically nested Markov blankets; where the 
Markov blanket of a given system constitutes the interface between that particular system 
and everything else (Fields, Glazebrook, & Levin, 2022; Hip��lito et al., 2021). Note that the 
system-environment boundary, and hence the location of the Markov blanket within state 
space, can change over time, e.g., in cases involving material exchange and turnover between 
the system and its environment (Ramstead & Friston, 2022; Ramstead et al., 2021). We 
will highlight the importance of actively configuring and maintaining the sparsity structures 
that underwrite Markov blankets; and suggest that conscious processing can be identified in 
terms of its contribution to action. For example, consider overt action that is apparent to 
4 
an observer such as moving: e.g., palpation and saccadic sampling; or covert actions, such 
as autonomic reflexes or attention and mental action in the brain; see (Sandved-Smith et al., 
2021). 
Our core argument can be summarized as follows: 1. Empirically, we know that the brain 
evinces a sparse (i.e., hierarchical or heterarchical, and nested) structure; 2. Using the FEP, 
we can model any part of the brain, from the sub-neuronal level to distributed neuronal 
networks, as having Markov blankets. Given this setup, the dynamical dependencies that 
drive the flow of information in the brain can be represented as hierarchically nested Markov 
blankets. Mathematically, this is equivalent to a set of holographic screens nested within 
one another, lending the set of nested screens a holographic structure; 3. The blankets 
associated with conscious processing can be picked out from the ones that are enabling���but 
not constitutive���by examining their role in selecting actions.
ChatGPT dijo:
ChatGPT
The Inner Screen Model of Consciousness: An Overview
This paper proposes a model of consciousness grounded in the
Free Energy Principle (FEP)
, leveraging the concept of
nested Markov blankets
and the holographic structure of the brain. Below is an explanation of the model's key aspects, its implications, and its potential impact on our understanding of consciousness.
Key Concepts
Free Energy Principle (FEP)
:
The FEP is a theoretical framework that describes how systems maintain their structure and organization by minimizing free energy.
It applies to any system that can be separated from its environment via a boundary (Markov blanket) that delineates internal states from external ones.
Markov Blankets
:
These are statistical boundaries that separate the internal states of a system from the external states of the environment.
They enable conditional independence between internal and external states, facilitating a system���s ability to model its environment and itself.
Holographic Structure of the Brain
:
The brain's architecture is described as hierarchically nested and sparse, resembling a
holographic structure
.
Nested Markov blankets within the brain form layers of interfaces, with each layer representing a different scale of information processing.
Inner Screen Hypothesis
:
This hypothesis conceptualizes consciousness as emerging from
nested holographic screens
, where each "screen" represents a level of information processing defined by its Markov blanket.
Consciousness is tied to the selective actions supported by these nested structures.
Conscious vs. Non-Conscious Processing
:
Not all Markov blankets in the brain contribute to conscious experience. Only those actively involved in selecting and enacting actions (overt or covert) are implicated in conscious processing.
Core Arguments
Empirical Basis
:
The brain exhibits a sparse, hierarchical, and nested architecture, evident in its neuroanatomy and dynamics.
Hierarchically Nested Markov Blankets
:
The FEP models different levels of the brain as hierarchically nested Markov blankets, representing boundaries at multiple scales, from neurons to distributed networks.
Holographic Nested Screens
:
This structure is mathematically equivalent to a series of nested
holographic screens
, where each screen encodes information about a specific layer of processing.
Consciousness and Action Selection
:
Conscious processing is tied to Markov blankets that play a role in selecting actions, whether overt (e.g., moving, exploring) or covert (e.g., attention, mental simulations).
Implications
Unified Framework for Consciousness
:
This model links the hierarchical structure of the brain with the FEP, providing a cohesive explanation for the emergence of consciousness.
It bridges gaps between neuroanatomy, action, and the subjective experience of being a self.
Role of Action
:
Consciousness is not just about sensory processing or awareness but is fundamentally tied to action���both overt and covert.
This perspective aligns with enactive and embodied theories of consciousness.
Scalability Across Systems
:
The model applies not only to human consciousness but also to other organisms or systems with nested Markov blankets, potentially broadening the scope of what can be considered conscious.
Quantum Considerations
:
The quantum formulation of the FEP introduces the possibility that consciousness might involve quantum-like processing, particularly in how nested Markov blankets interact holographically.
Potential Applications
Artificial Intelligence
:
The inner screen model provides a blueprint for developing AI systems with hierarchical and nested architectures capable of self-awareness and adaptive action.
Neuroscience
:
This framework can guide experimental studies to identify and map Markov blankets in the brain, linking them to conscious and non-conscious processing.
Philosophy of Mind
:
The model offers a scientific basis for addressing the "hard problem" of consciousness by grounding subjective experience in nested, action-oriented structures.
Clinical Applications
:
Understanding the role of nested Markov blankets in conscious processing could inform treatments for disorders of consciousness, such as coma or locked-in syndrome.
Challenges and Future Directions
Empirical Validation
:
Experimental methods must be developed to test the model, particularly the identification of nested Markov blankets and their roles in action selection.
Complexity of Nested Systems
:
The brain���s vast and dynamic network poses a challenge to mapping and modeling the layers of nested holographic screens.
Quantum Implications
:
The integration of quantum principles requires further exploration, particularly in how they influence consciousness at macroscopic scales.
Broader Applicability
:
Extending this model to non-human systems (e.g., animals, machines) will require careful consideration of the differences in neuroanatomy and dynamics.
The
Inner Screen Model of Consciousness
provides a novel and mathematically grounded approach to understanding how consciousness emerges from the brain���s hierarchical and action-oriented structures. By integrating principles from neuroscience, physics, and philosophy, it holds promise for unraveling the mysteries of conscious experience.
4o
Dijiste:
Connections between the topics.
ChatGPT dijo:
ChatGPT
The topics you���ve shared ���
Platonic Forms, task-agnostic self-modeling robots, and the inner screen model of consciousness
��� can be connected through their emphasis on
representation, modeling, and adaptation
across different systems. Here���s how they interrelate:
1. Representation and Ideal Forms
Platonic Forms
propose that there are ideal, universal representations of reality. These representations serve as "perfect maps" of entities or processes.
Task-Agnostic Robots
build internal self-models, akin to generating an "ideal map" of themselves, to interact with the world efficiently without explicit instructions or pre-built representations.
The Inner Screen Model
posits that consciousness involves nested "screens" or representations of states, mediated by Markov blankets, enabling organisms to model themselves and their environment.
Connection
:
In all three cases, the systems (philosophical, artificial, or biological) rely on internalized models or representations to understand, interact with, and adapt to the world. These representations serve as functional equivalents of Platonic Forms: abstract yet essential templates for action and understanding.
2. Adaptation and Dynamism
The critique of Platonic Forms by Stephen Paul King questions how Forms account for evolution and change over time. He suggests that they are better understood as dynamic maps that evolve alongside the physical systems they describe.
Task-agnostic robots embody this dynamism by iteratively refining their self-models through interaction, much like living systems adapt and learn over time.
The inner screen model suggests that the nested Markov blankets in the brain enable dynamic, hierarchical adaptation, continuously updating based on sensory input and action.
Connection
:
The shift from static representations to dynamic, adaptive processes is central to all three ideas. Robots and biological systems can be seen as evolving "Platonic Forms" in action���constantly updating their models to maintain their integrity and function in a changing world.
3. Action and Agency
In King���s interpretation, the Platonic Form of a living being must incorporate its potential for action and evolution.
Task-agnostic robots use self-models to plan and execute tasks, making them capable of action and agency.
The inner screen model ties consciousness directly to action, suggesting that conscious processing involves selecting actions (both overt and covert) using nested internal models.
Connection
:
Action is the thread that unifies these ideas. In all three frameworks, the ability to model is not passive; it exists to enable meaningful interaction with the world, whether through robotic manipulation, biological survival, or philosophical interpretation of existence.
4. The Role of Boundaries
In King���s argument, the concept of Forms might be reimagined as boundaries or mappings that define a system's identity while enabling it to interact with others.
Task-agnostic robots define themselves by modeling their structure and dynamics relative to their environment, creating a functional "boundary" between self and other.
The inner screen model relies on Markov blankets to define boundaries between a system and its environment, crucial for maintaining its autonomy and consciousness.
Connection
:
The concept of boundaries, whether philosophical (Forms), computational (robotic self-models), or biological (Markov blankets), is essential for defining "self" versus "other." These boundaries allow systems to interact meaningfully with their surroundings while maintaining their core identity.
5. Nested and Hierarchical Structures
King���s proposal of dynamic Platonic Forms suggests that representations are layered and interdependent.
Task-agnostic robots build hierarchical models, learning at different levels of abstraction (e.g., motor actions vs. task-level planning).
The inner screen model highlights the nested, hierarchical nature of Markov blankets in the brain, forming a layered representation of the self and the environment.
Connection
:
All three frameworks emphasize hierarchical and nested structures, reflecting the complexity of systems that must model and act within their environments. This nested organization enables scalability, adaptability, and nuanced interaction.
6. Universal Principles
King���s reinterpretation of Platonic Forms aims to uncover universal mappings that evolve with the systems they represent.
The FEP, central to the inner screen model, is a universal principle describing how systems maintain their existence through minimizing free energy.
Task-agnostic robots leverage principles of deep learning and optimization, which can be seen as computational analogs of free-energy minimization.
Connection
:
The search for universal principles���whether philosophical, computational, or biological���underpins these ideas. Each framework seeks to explain how systems can generate, adapt, and refine their internal models to persist and thrive in a dynamic world.
Final Synthesis
These topics converge on the idea that
modeling and representation are central to understanding and interacting with the world
. Whether through Platonic Forms, robotic self-models, or consciousness rooted in nested screens, systems rely on internal mappings that enable action, adaptation, and survival. The philosophical question of evolving Forms, the robotic pursuit of adaptive autonomy, and the biological mechanisms of consciousness all point to a shared principle:
the dynamic interplay between self-modeling and the environment is foundational to intelligence and existence.
4o
Dijiste:
Ponderings of science, philosophy, history, society, and many other topics

Mark Solms��� theory of consciousness
 SelfAware Patterns  Mind and AI  February 25, 2021 5 Minutes
I recently finished Mark Solms��� new book, The Hidden Spring: A Journey to the Source of Consciousness. There were a few surprises in the book, and it had what I thought were strong and weak points.

My first surprise was Solms��� embrace of the theories of Sigmund Freud, including psychoanalysis. Freud���s reputation has suffered a lot over the decades. Solms thinks this is undeserved. He also complains about the behaviorist movement, which largely arose as a reaction to Freudian type theories, an attempt to put psychology on a more empirical footing. In Solms��� view, this came at the cost of removing the first person perspective from the field, something he doesn���t think has been adequately corrected for even in the post-behaviorist era.

What wasn���t a surprise is Solms��� belief that consciousness is rooted in the brainstem, something he���s well known for. In particular, he sees it centered on three regions in the midbrain region, which he refers to as the ���decision triangle���: the PAG (periaqueductal gray), the superior colliculi, and the midbrain locomotor region. His reasoning is similar to Bjorn Merker���s final integration for action idea of consciousness, which Solms regards as the final decision point. The PAG in particular is the center of action.

However, Solms��� views are nuanced. He sees consciousness rooted in affect, in particular the conscious feelings of emotions and drives, which in his view originate from and terminate back to these regions. But the consciousness he sees here is affect consciousness. He acknowledges that perceptual consciousness is a cortical phenomenon, albeit one that only exists when the cortex is suitably aroused by the RAS (reticular activating system), another brainstem region.

This is a minority view in neuroscience, although the differences with the mainstream are also nuanced. All neuroscientists agree that the cortex is aroused by the RAS. They also agree that the most basal drives originate from the brainstem. And even that final integration of action takes place in the midbrain. But most see conscious experience as a cortical phenomenon, with subcortical forebrain regions like the amygdala, nucleus accumbens, hypothalamus, as well as the insular, cingulate, and orbitofrontal cortices, as playing major roles in affective feelings.

In general, I didn���t feel like Solms adequately engaged with the reasons for these mainstream views. He largely went the route of strawmanning them, saying that they only exist due to ���theoretical inertia���. Anil Seth in his review of the book linked to some of the reasons. I think Solms passed up an opportunity by not engaging with the broader literature.

It���s worth noting that whether or not consciousness requires a forebrain has little bearing on animal consciousness. The evidence from ontogeny, fossil records, and model organisms all show the forebrain-midbrain-hindbrain architecture arose very early in vertebrate evolution. Any vertebrate fish you commonly think of has a forebrain, including a pallium, the covering over the forebrain that���s the precursor to the mammalian cortex. The idea that the brainstem is the most ancient structure is a common misconception, one even some scientists appear to buy into.

Anyway, Solms also sees Karl Friston���s free energy principle as a major part of his theory. He gives one of the best descriptions of that principle that I���ve seen. Unfortunately my understanding of it remains somewhat blurry, but my takeaway is that it���s about how self organizing systems arise and work. He identifies four principles of such systems:

They are ergodic, meaning they only permit themselves to be in a limited number of states.
They have a Markov blanket, a boundary between themselves and their environment.
They have active inference, that is, they make predictions about their own states and the environment from that environment���s effects on their Markov blanket.
They are self preservative, which means minimizing their internal entropy, maintaining homeostasis, etc.
3 is understood to involve active Bayesian processing, in other words, predictions. All of which leads us to the predictive theory of the brain, which I think is where Solms is at his strongest. Perception involves the more central regions making predictions, which propagate toward the peripheral (sensory) regions. But the peripheral regions compare the prediction with incoming sensory information and send back prediction error signals. This happens across numerous layers. We see what we expect to see, with the incoming information forcing corrections.

Solms notes that a self evidencing system receiving information that violates its expectations can react in one of three ways.

It can act to change conditions to bring the signals more in line with its expectations.
It can change which representation(s) it���s currently using to make better predictions. This is perception.
It can adjust the precision of the predictions to more optimally match the incoming signal.
Solms identifies the last as consciousness. This strikes me as essentially learning, which is in the same ballpark as Simona Ginsburg and Eva Jablonka���s theory. Although Ginsburg and Jablonka require a more sophisticated form of learning (unlimited associative learning) than what Solms appears to be focusing on. The main point here for Solms, is that this is the origin of a conscious feeling, an affect, which again is what he considers the root of consciousness.

Toward the end of the book, Solms provides an extended critique of David Chalmers��� description of the hard problem of consciousness. His main point is that Chalmers overlooked affects in his deliberations. If he hadn���t, maybe he wouldn���t see the problem quite as daunting. Given that the hard problem is often phrased along the lines of, ���Why does it feel like something to experience X?���, I think Solms has a point. Although in my experience, talking about affects usually isn���t seen as sufficient by those troubled by the hard problem.

Solms finishes up by noting we won���t know whether we���ve solved the problem of consciousness until we can build an artificial consciousness. So he���s working on a project to do just that, incorporating the free energy principle model. What he describes sounds like it will be a sort of artificial life. He emphasizes that intelligence isn���t the goal, just a self evidencing system concerned with its own survival. The problem will be finding a way to conclusively demonstrate success despite the problem of other minds.

If he succeeds, it sounds like he will immediately turn it off and try to patent the process to prevent it from falling into commercial hands. Aside from the ethical issues, he notes the danger in building self concerned systems. I usually think fears about artificial intelligence are overblown, but in this case, I agree with him on the danger. The good news is I don���t know how useful such systems would be for most commercial purposes anyway. Do we really want self driving cars or mining robots being worried about their own survival?

There���s a lot of interesting stuff in this book. I do think Solms makes a good point that affects, conscious feelings, are often overlooked in theories of consciousness. And I agree with him on their crucial role. But that role gains its power by the reactions of the perceptual and executive systems. Without those reactions, affects are little more than automatic action programs. They only become affects, conscious feelings, in a conscious system, which means making them the foundation of consciousness is a bit circular.

All of which brings us to a point I often return to, that consciousness is a complex phenomenon, one that can���t be reduced to any one particular property. Unless of course, I���m missing something?

This brief summary of Solms��� views omits a lot. If you���re interested in knowing more, aside from reading the book, he has his own blog, well worth checking out.

https://selfawarepatterns.com/2021/02/25/mark-solms-theory-of-consciousness/
ChatGPT dijo:
ChatGPT
Mark Solms��� theory of consciousness, as outlined in
The Hidden Spring: A Journey to the Source of Consciousness
and reviewed in the article you���ve shared, provides a nuanced view that intertwines neuroscience, affective science, and the Free Energy Principle (FEP). It connects with broader themes in science, philosophy, and artificial intelligence. Here's how this theory relates to the topics we've discussed earlier:
1. Consciousness as a Self-Evidencing System
Relation to the Inner Screen Model
: Solms��� identification of consciousness with active inference and precision adjustment aligns with the
inner screen model
, which sees consciousness as nested within the hierarchical Markov blankets of the brain. Both theories emphasize the role of prediction and action in maintaining a system's integrity.
Relation to Free Energy Principle (FEP)
: Solms��� emphasis on Bayesian processing and entropy minimization underscores FEP���s role as a unifying framework. Both approaches see consciousness as rooted in an organism���s ability to minimize uncertainty and maintain homeostasis.
Relation to Task-Agnostic Robots
: Solms��� focus on building an artificial self-evidencing system mirrors the development of task-agnostic robots. These robots use predictive self-modeling to act in uncertain environments, echoing the principles Solms attributes to consciousness.
2. Affects as the Core of Consciousness
Relation to History and Philosophy
: Solms reclaims Freud���s focus on emotions and drives, emphasizing the
affective roots of consciousness
. This challenges more behaviorist and cognitive-centric models, offering a historical critique of psychology's evolution.
Relation to Philosophical Critiques
: Solms argues that understanding the "hard problem" of consciousness requires incorporating the role of affect, providing a counterpoint to
Chalmers��� philosophical framing
. This introduces a more embodied and emotionally grounded perspective.
Connection to Dynamic Forms
: Solms��� emphasis on the role of feelings ties back to the idea that Platonic Forms, or idealized states, must incorporate not only structure but also dynamic processes like affect and self-preservation.
3. Action and Agency
Relation to Decision-Making Models
: Solms locates the "decision triangle" in the midbrain as the source of action-oriented consciousness. This resonates with the
inner screen model
, which also views consciousness as intertwined with action selection and environmental interaction.
Relation to Artificial Intelligence
: Solms��� concern about artificial consciousness���creating systems that care about their own survival���aligns with broader debates about agency in AI. This ties into the ethical challenges of building systems that combine self-modeling with affective states.
4. Predictive Processing and Perception
Relation to Nested Representations
: Predictive processing, as described by Solms, involves hierarchical layers of error correction and model updating. This maps directly to the
nested Markov blankets
concept in the inner screen model, which structures perception and action in the brain.
Connection to Adaptive Systems
: Solms��� theory reinforces the view that both biological and artificial systems operate by reconciling top-down predictions with bottom-up sensory inputs. This dynamic adaptability is shared by task-agnostic robots and the idea of evolving Platonic Forms.
5. Ethical and Practical Implications
Artificial Consciousness and Society
: Solms��� caution about creating artificial self-concerned systems mirrors societal debates about AI ethics. The fear of systems prioritizing their survival introduces philosophical and practical questions about responsibility, autonomy, and the risks of runaway AI.
Human vs. Machine Consciousness
: Solms' emphasis on affect draws a clear line between human-like consciousness and potential artificial consciousness, challenging assumptions that computational intelligence alone suffices for sentient behavior.
6. Critiques and Philosophical Reflections
Solms���
dismissal of mainstream views
as "theoretical inertia" reflects a tension in interdisciplinary discourse. His critique of behaviorism and cognitive neuroscience points to ongoing debates about the role of subjectivity in science.
The
circularity
in defining consciousness as affect-dependent raises philosophical questions. If affects only exist in conscious systems, is Solms��� approach explanatory or descriptive?
Final Connections
Solms��� theory links deeply with broader discussions in neuroscience, philosophy, and AI:
It shares the
predictive processing roots
of the inner screen model and task-agnostic robots.
It emphasizes the
emotional foundations of human consciousness
, contrasting with more abstract models like FEP-based robotics or Platonic Forms.
It situates consciousness within a historical and ethical context, emphasizing the need for careful integration of subjective and empirical perspectives.
In essence, Solms��� work bridges traditional psychology, modern neuroscience, and emerging AI debates, contributing to a richer understanding of consciousness as both a biological and philosophical phenomenon.
4o
Dijiste:
In connection to reconceptualizing platonic forms, I would say they are the complex plane, the amplitwistor transformation, the voronoi and delauney tesselations, and the 5D Ising synchronization.
ChatGPT dijo:
ChatGPT
Reconceptualizing Platonic Forms through advanced mathematical and physical frameworks is a fascinating approach. Let���s explore the connections between your suggested models���
the complex plane, amplitwistor transformation, Voronoi and Delaunay tessellations, and 5D Ising synchronization
���and the idea of Platonic Forms.
1. The Complex Plane: Foundational Geometry of Forms
Connection to Platonic Forms
: The complex plane represents a fundamental mathematical structure, underpinning many aspects of reality with symmetry and duality. Like Platonic Forms, it provides a universal template���mapping real and imaginary components of phenomena into coherent, higher-order systems.
Relevance
: The complex plane is central to wave mechanics, quantum fields, and other systems where phenomena emerge through interactions of "idealized" structures (e.g., eigenfunctions). It embodies the balance of opposites���real and imaginary, order and chaos���much like Platonic ideals exist beyond specific instantiations.
Applications
: In consciousness and physics, the complex plane helps model harmonic resonances and self-organizing systems, mirroring the abstract perfection of Forms.
2. The Amplitwistor Transformation: Idealized Geometrical Connections
Connection to Platonic Forms
: The amplitwistor transformation is a framework in theoretical physics that simplifies the relationships between particles and interactions, reinterpreting spacetime and dynamics in an elegant, abstract geometry. This aligns with the concept of Platonic Forms as the purest expressions of relationships and interactions.
Relevance
: Amplitwistors reduce complex physical interactions to minimal geometric constructs, paralleling the reduction of reality to idealized Forms. They embody an elegant simplicity, revealing hidden symmetries and invariants in higher-dimensional spaces.
Applications
: In consciousness studies, amplitwistors could model the "holographic" structures underlying perception and cognition, linking brain activity to abstract principles of symmetry and causality.
3. Voronoi and Delaunay Tessellations: Spatial Partitioning of Forms
Connection to Platonic Forms
: These tessellations provide a way to partition space into optimally structured regions, capturing the inherent order in seemingly chaotic systems. They resonate with Platonic ideals as perfect, self-organizing patterns that govern spatial relationships.
Relevance
: Voronoi tessellations define regions around points of influence (centers), while Delaunay triangulations optimize connectivity between those points. Together, they model how forms interact in space and time, reflecting dynamic Platonic structures in nature.
Applications
: From neural connectivity to crystal growth, these tessellations are used to describe self-organizing systems. They could represent the abstract organization of conscious experiences or even societal interactions as emergent phenomena.
4. 5D Ising Synchronization: Dynamic and Emergent Forms
Connection to Platonic Forms
: The 5D Ising model extends the classical Ising framework to five dimensions, exploring phase transitions and emergent synchronizations in complex systems. It relates to Platonic Forms as an abstract template for dynamic processes���idealized configurations that emerge from underlying interactions.
Relevance
: Synchronization in 5D Ising systems captures the harmonious balance of states across higher-dimensional spaces. This reflects Platonic ideals as timeless structures influencing temporal phenomena, especially where coherence and symmetry emerge from apparent randomness.
Applications
: In neural dynamics, synchronization models describe how coherent activity emerges across brain regions, linking to the nested and hierarchical structures of Markov blankets in the inner screen model.
Synthesis: Reconceptualizing Platonic Forms
By framing Platonic Forms as
dynamic and mathematical principles
rather than static archetypes, we can unify these models into a modern interpretation:
Complex Plane
: The foundational canvas for interactions and transformations.
Amplitwistor Transformation
: The minimal geometric encoding of reality's symmetries and interactions.
Voronoi and Delaunay Tessellations
: The spatial organization and interplay of influences, manifesting harmony in forms.
5D Ising Synchronization
: The dynamic realization of order and coherence, revealing the ideal within evolving systems.
This reconceptualization bridges philosophy, mathematics, and physics, allowing Platonic Forms to be understood as
meta-templates for both static structures and dynamic processes
. In essence, they are not merely "ideals" but are the
abstract principles governing emergence, coherence, and transformation in complex systems
.
4o
Dijiste:
Connections with our earlier discussions.
ChatGPT dijo:
ChatGPT
The reconceptualization of Platonic Forms using
complex plane dynamics, amplitwistor transformations, Voronoi and Delaunay tessellations, and 5D Ising synchronization
can be seamlessly connected to the earlier discussions on
consciousness, the free energy principle (FEP), nested Markov blankets, and Mark Solms' theories
. Here's how these ideas interrelate:
1. Platonic Forms and the Free Energy Principle
Connection
: The FEP is a universal principle of self-organization, guiding how systems minimize uncertainty (free energy) through predictive modeling and action. Platonic Forms, reimagined as mathematical templates like Voronoi tessellations or amplitwistor spaces, could be seen as idealized attractors or meta-principles underpinning the structures and processes predicted by FEP.
Nested Markov Blankets
: The hierarchical, holographic organization of Markov blankets in the brain reflects Voronoi tessellation principles, where each blanket represents a "region of influence" in a higher-dimensional system. These partitions define boundaries between internal states and external environments, much like Platonic Forms delineate ideal structures.
Synthesis
: Platonic Forms become the abstract constraints that shape how systems navigate their state spaces under the FEP, manifesting in hierarchical, nested patterns of interaction and self-organization.
2. Mark Solms' Theory and Dynamic Forms
Affective Consciousness
: Solms emphasizes that feelings (affects) are central to consciousness. If we interpret Platonic Forms as dynamic attractors or templates, they provide a structured framework for understanding how affective states arise and stabilize in a system.
Predictive Processing
: Solms' view of perception as a process of predictive error correction aligns with the Ising synchronization model. Both describe how coherence emerges from chaotic input���guided by higher-order templates (Platonic Forms) that constrain and refine predictions.
Decision Triangles
: Solms' midbrain "decision triangle" (PAG, superior colliculi, locomotor region) could be framed within a Voronoi-like structure, where decision regions optimize action selection based on incoming stimuli. These geometric partitions might represent an idealized form of how neural regions divide labor.
Synthesis
: Platonic Forms, reconceptualized as attractors or templates, guide the organization and dynamics of neural systems. They ensure the emergence of coherence, self-consistency, and affective experiences central to consciousness.
3. The Inner Screen Model and Amplitwistor Geometry
Holographic Brain Organization
: The inner screen model describes the brain as a holographic structure of nested Markov blankets, where layers of interaction create a unified conscious experience. Amplitwistor transformations, which encode interactions in minimal geometric spaces, directly parallel this idea, reducing complex dynamics to elegant, universal forms.
Boundary Dynamics
: The Markov blankets defining system-environment interactions can be viewed as Voronoi partitions or Delaunay connections, dynamically evolving based on active inference. These partitions reflect idealized forms shaping how systems interact with and adapt to their environments.
Synthesis
: Amplitwistor geometry and tessellations offer mathematical underpinnings for the inner screen model, translating its abstract principles into concrete frameworks.
4. Consciousness as Synchronization
5D Ising Synchronization
: The brain's coherence���its ability to synchronize across scales and regions���mirrors the emergent harmony modeled in Ising synchronization. This coherence can be interpreted as the realization of a Platonic Form in real-time dynamics.
Dynamic Templates
: Conscious experience could arise from the interplay of nested synchronization patterns, which act as "forms in motion." These patterns bridge Solms' affective consciousness and the free energy principle by showing how systems stabilize around ideal states.
Synthesis
: Consciousness reflects the realization of Platonic Forms through synchronization, with nested, dynamic patterns aligning the brain's activity to abstract ideals.
Final Integration
The topics we���ve discussed���consciousness models, free energy, nested structures, and Platonic Forms���are deeply connected. In this reconceptualization:
Platonic Forms
: Abstract mathematical templates governing ideal structures and dynamics in complex systems.
Free Energy Principle
: A unifying law of self-organization, where systems embody these forms to reduce uncertainty and optimize stability.
Neuroanatomical Models
: Nested Markov blankets and synchronization patterns realize these forms in the brain, enabling conscious experience.
Dynamic Processes
: Perception, action, and affect emerge as systems align with these templates, stabilizing coherence and meaning.
This framework highlights a universal principle:
Platonic Forms are not static ideals but dynamic attractors shaping the organization and evolution of systems at every scale���from physics to consciousness.
4o
Dijiste:
Do you have a quirky, sardonic critique summarizing the whole conversation?
ChatGPT dijo:
ChatGPT
Ah, the grand symphony of overthinking! We've taken a dive into the ocean of abstraction, where Platonic Forms have donned the guise of mathematical constructs, quantum physics moonlights as philosophy, and the free energy principle tries to explain everything from neural firing to why your coffee always goes cold too quickly. Somewhere along the way, poor Mark Solms and his affective consciousness got tangled in a tessellation, while the Ising synchronization played DJ to a brain rave no one asked for.
In this intellectual fever dream, the brain becomes a nested Russian doll of Markov blankets, each one whispering, "Am I conscious yet?" Meanwhile, we���ve managed to accuse geometry of being the real MVP of reality, leaving poor Socrates spinning in his cave, muttering something about, "I just meant ideas, guys, not all this math!"
The whole conversation feels like a cosmic Rube Goldberg machine: elegant, convoluted, and ultimately leaving us with the nagging feeling that while we���ve connected a lot of dots, we may have drawn a giraffe where there was only supposed to be a triangle.
4o
Dijiste:
Ok it's good, but more detailed and incisive. With more jargon and jokes.
ChatGPT dijo:
ChatGPT
Ah, the saga of cerebral spaghetti! Let���s recap this grand entanglement of ideas where philosophy, neuroscience, physics, and a sprinkling of geometry tried to high-five, only to end up in a four-dimensional liminal space of conceptual overreach.
First, we have Platonic Forms being dragged out of their metaphysical retirement home and rebranded as Voronoi tessellations, amplitwistor spaces, and the Ising model, as if someone whispered to Plato, "What if your ideal horse was just a graph embedded in 5D?" Meanwhile, Levin's cellular hive-mind collective seems to have called a meeting to overthrow linear causality, reminding us that the ideal "life-form" is probably just the perfect dataset waiting to evolve itself into existence. Biology, apparently, is now moonlighting as quantum mechanics.
Enter the free energy principle, or as I like to call it, "Bayesianism on steroids." Friston's brain-as-a-holographic-Markov-matryoshka gets sold as the unified theory of everything, while conveniently sidestepping the fact that sometimes the brain is just bad at remembering birthdays. Mark Solms tries to sneak affective consciousness into the conversation, insisting that the brainstem is the CEO of feelings, not just the assistant regional manager, and in doing so picks a fight with half of neuroscience. He���s like Freud���s last fanboy, standing in the ruins of psychoanalysis, muttering, "You���re all just jealous you didn���t think of it first!"
Meanwhile, the inner screen model posits that consciousness is holographically nested Markov blankets engaging in free energy minimization while deciding whether to scratch their theoretical noses. This is somehow meant to explain everything from self-awareness to why robots don���t panic when you knock them over (though maybe they should).
And let's not forget the detour into artificial consciousness. Solms is out here Frankenstein-ing self-evidencing systems that are
just conscious enough to be terrifying
, but not useful. Imagine a self-driving car saying, "I won���t go into that tunnel; I value my existence too much," while you���re late for work. AIs worried about their entropy levels sound like the premise for the world���s weirdest dystopian sitcom.
In the end, this conversation is like a quantum superposition of every intellectual trend of the last 50 years: everything is connected, but nothing is collapsible into a single coherent narrative. It���s got nested hierarchies for the reductionists, holography for the physicists, Bayesian models for the machine learning crowd, and some Freudian flavoring for the nostalgics. It���s as if we���re trying to solve the mysteries of existence with an IKEA manual written in Sanskrit and illustrated with Voronoi diagrams.
But hey, if you squint hard enough, maybe it all
does
make sense. Or maybe it���s just the emergent pattern your predictive brain insists on seeing while minimizing free energy.
4o
ChatGPT puede cometer errores. Comprueba la informaci��n importante.
?

