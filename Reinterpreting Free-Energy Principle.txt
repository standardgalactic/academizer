Reinterpreting Free-Energy Principle
Open sidebar
Reinterpreting Free-Energy Principle
Model: Default (GPT-3.5)
Skip to content

De Gruyter
0
 
IBZ Online
Search IBZ Online
De Gruyter


SUBJECTS
SERVICES
PUBLICATIONS
ABOUT
Change language
English
Deutsch
Change currency
��� EUR
�� GBP
$ USD
The anticipating brain is not a scientist: the free-energy principle from an ecological-enactive perspective
Synthese
Author(s)
Jelle Bruineberg, Julian Kiverstein, Erik Rietveld
Title
The anticipating brain is not a scientist: the free-energy principle from an ecological-enactive perspective
In
Synthese
An International Journal for Epistemology, Methodology and Philosophy of Science
Volume
195
Issue
6
Page(s)
2417-2444
Year
2018
Publisher
Springer Netherlands
Publication Place
Dordrecht
ISSN
1573-0964; 0039-7857
Publication type
Article
Language
English
Keyword
Energie (physikal.)
energy (phys.)
Physikalismus
physicalism
Wissenschaftstheorie
philosophy of science
Umweltethik
environmental ethics
Ethik
ethics
Umweltschutz
environment protection
Epistemologie
theory of knowledge
epistemology
Wissen
knowledge
savoir
Philosophie
philosophy
Logik
logic
Metaphysik
metaphysics
Subject Term
Philosophie; Philosophy; Forschung, Wissenschaft; Research, Science; Umwelt, ��kologie; Environment, Ecology; Physik; Physics; Philosophy; Philosophy of Science; Epistemology; Logic; Philosophy of Language; Metaphysics
Abstract
In this paper, we argue for a theoretical separation of the free-energy principle from Helmholtzian accounts of the predictive brain. The free-energy principle is a theoretical framework capturing the imperative for biological self-organization in information-theoretic terms. The free-energy principle has typically been connected with a Bayesian theory of predictive coding, and the latter is often taken to support a Helmholtzian theory of perception as unconscious inference. If our interpretation is right, however, a Helmholtzian view of perception is incompatible with Bayesian predictive coding under the free-energy principle. We argue that the free energy principle and the ecological and enactive approach to mind and life make for a much happier marriage of ideas. We make our argument based on three points. First we argue that the free energy principle applies to the whole animal���environment system, and not only to the brain. Second, we show that active inference, as understood by the free-energy principle, is incompatible with unconscious inference understood as analagous to scientific hypothesis-testing, the main tenet of a Helmholtzian view of perception. Third, we argue that the notion of inference at work in Bayesian predictive coding under the free-energy principle is too weak to support a Helmholtzian theory of perception. Taken together these points imply that the free energy principle is best understood in ecological and enactive terms set out in this paper.

Access brought to you by Wikipedia
From the database
IBZ Online
IBZ Online
Subjects
Architecture and Design
Arts
Asian and Pacific Studies
Business and Economics
Chemistry
Classical and Ancient Near Eastern Studies
Computer Sciences
Cultural Studies
Engineering
General Interest
Geosciences
History
Industrial Chemistry
Islamic and Middle Eastern Studies
Jewish Studies
Law
Library and Information Science, Book Studies
Life Sciences
Linguistics and Semiotics
Literary Studies
Materials Sciences
Mathematics
Medicine
Music
Pharmacy
Philosophy
Physics
Social Sciences
Sports and Recreation
Theology and Religion
Services
For journal authors
For book authors
For librarians
Rights & Permissions
Publications
Publication types
Open Access
About
Contact
Career
About De Gruyter
Partnerships
Press
FAQs
Open-Athens
Winner of the OpenAthens
Best Publisher UX Award 2022
Help/FAQ
Privacy policy
Cookie Policy
Accessibility
Terms & Conditions
Legal Notice
�� Walter de Gruyter GmbH 2023
De Gruyter
Scroll to top button
1 / 1
ChatGPT
ChatGPT
It seems like you've posted the details of an academic paper titled "The anticipating brain is not a scientist: the free-energy principle from an ecological-enactive perspective" by authors Jelle Bruineberg, Julian Kiverstein, and Erik Rietveld, which was published in 2018 in the journal "Synthese" by Springer Netherlands.
This paper discusses a theoretical separation of the free-energy principle from Helmholtzian accounts of the predictive brain. The authors argue that the free-energy principle, which describes the biological imperative for self-organization in information-theoretic terms, is often incorrectly connected with a Helmholtzian theory of perception, perceived as unconscious inference. They argue that this theory of perception is incompatible with the free-energy principle and the Bayesian theory of predictive coding it's usually associated with.
The authors propose that the free-energy principle applies to the whole animal���environment system, and not only to the brain, contradicting the primary tenet of a Helmholtzian view. They further argue that active inference as understood by the free-energy principle is incompatible with unconscious inference, and that the notion of inference at work in Bayesian predictive coding under the free-energy principle is too weak to support a Helmholtzian theory of perception.
Instead, they propose that the free-energy principle aligns more closely with ecological and enactive approaches to mind and life.
In short, this paper deals with the philosophy of mind, cognitive science, and theories of perception, arguing for a reinterpretation of the free-energy principle in terms of ecological and enactive perspectives, as opposed to the conventional Helmholtzian perspective.
If you have any specific questions or areas you would like to understand more about regarding this paper, feel free to ask!
1 / 1
Summarize: Parrots All the Way Down 
Controversies within AI's Conquest of Language 
Jonathan Roberge & Tom Lebrun 
Abstract:Today���sdeploymentofautomatedsemanticmodelssuchasGoogle���sBERTor 
OpenAI���sGPT-3isaremarkablechallengefortheinscriptionofhermeneuticsatthevery 
heartofthesocialsciencesproject.Artif i cialintelligenceisindeedconqueringlanguage. 
h ere are three important implications. First, we must take the power and possibilities 
of such models seriously ��� that is, the recent history of technological advances in deep 
learning and the modi operandi of these interpreting machines, particularly their two- 
wayreadingand���Transformer���architecture.Second,abettercomprehensionisrequired 
ofthetypeofunderstandinginvolved���mainlyhowthecalculationofprobability,thresh- 
oldsandvariation,forexample,vectorizeslanguageasiftoparrotitback.Ouranalysis 
takes note of the dismissal by Google of the researcher Timnit Gebru, precisely around 
the text ���On the Danger of Stochastic Parrots���, to show how the value of natural lan- 
guage processing (NLP) models lies in the kind of world they put forward as well as in 
their reference to a precise context. Finally, this should help to circumscribe the current 
economic,politicalandevenethicalaporiasconcerningthesemodels,includingthefact 
thattheplatformsdevelopingthemoverlookcrucialreal-worldeffectsofthewayinwhich 
theyadvancetheextraction,commodif i cationandinstrumentalizationofmeaning.Ul- 
timately,itisthiscloselinkbetweenmeaningandthedisplacementofpowercentersthat 
becomesthecentralissueofCriticalAIStudies.
1 / 1
ChatGPT
ChatGPT
The paper titled "Parrots All the Way Down: Controversies within AI's Conquest of Language" by Jonathan Roberge and Tom Lebrun discusses the challenges and implications of deploying automated semantic models like Google's BERT or OpenAI's GPT-3 in social sciences.
These models, based on deep learning technology and transformer architecture, have the power to understand and interpret language in a way that resembles human comprehension. However, this understanding is fundamentally rooted in the computation of probabilities, thresholds, and variations, leading these models to "parrot" language rather than deeply understand it.
The authors also highlight the controversy around Google's dismissal of researcher Timnit Gebru, who was involved in writing the text "On the Danger of Stochastic Parrots". The authors use this event to discuss how the value of Natural Language Processing (NLP) models is not only in the world they present but also in their ability to relate to a specific context.
Moreover, they stress the need for a better comprehension of the models to address current economic, political, and ethical dilemmas associated with them. The models' development often overlooks real-world consequences of how they enable the extraction, commodification, and instrumentalization of meaning.
The paper concludes by emphasizing the strong connection between the interpretation of meaning and the shift in power dynamics, identifying this as a critical issue for the emerging field of Critical AI Studies. This field is dedicated to scrutinizing the impact and implications of AI technologies on society, culture, and individuals.
1 / 1
1. Introduction 
h e year 2020 was marked by yet another ���substantial ���crisis at Google with 
thedeparture-f i ringofresearcherTimnitGebruoverthesubmissionofthepa- 
per ���On the Danger of Stochastic Parrots: Can Language Models Be Too Big?��� 
(Bender et al. 2021). h e story went from anecdotal to scandalous when the 
40Embedded Models of Meaning 
company asked for the article to be withdrawn or for the names of the Google 
employeeswhocontributedtoittoberemoved.ForJeffDean,Google���sdirector 
of AI,the matter was settled in that the work in question���didn���t meet our bar 
for publication��� (Hao 2020). However, Gebru���s rebuff and the large number of 
supporterswhoralliedtohercause���inthiscase,morethan2,000ofthecom- 
pany���s employees signed a letter asking for demanding greater transparency 
in the management of its internal affairs (Wakabayashi 2020) ��� had not been 
factored in. So, who had demanded the withdrawal of the article and why ex- 
actly?T h isisaquestionintheformofanultimatumthatremainsunanswered. 
���Timnit wrote that if we didn���t meet these demands,���Dean writes,���she would 
leave Google [���]. [W]e accept and respect her decision.��� h e break-up was, to 
all intents and purposes, complete. On Twitter, the researcher expressed her 
dismay and called out her former boss: ���@jeffdean I realize how much larger 
languagemodelsareworthtoyounow.���1 
Itispreciselyonthisnotionofworth,orvalue,thatwewanttofocushere. 
h e double meaning of the word indicates that it refers more or less distinctly 
tosomethingeconomicaswellasaxiological.Indeed,theveryambiguityofthe 
word and of its use in the tweet is what makes it emblematic of the most im- 
portant issues surrounding the current deployment of natural language pro- 
cessing (NLP) models.While many have seen the Gebru scandal as a matter of 
ethics and labor relations, few have been willing to consider the question in 
its fullest sense and thus explore the ways in which it represents a fundamen- 
talhermeneuticalissue.Yetthequestiondeservestobeasked:haveAIandthe 
latest advances in deep learning enabled the development of (too) big,power- 
ful and deep models? And what can such terms mean, apart from a technical 
point of view? Do meaning and textuality, interpretation and understanding 
notbecome(too)impoverishedasaresultoftheirautomatedprocessing? 
We argue in this chapter that the emergence of models such as Google���s 
BERTorOpenAI���sGPT-3istodayaremarkablechallengeforhermeneuticdis- 
ciplinesingeneral,andfortheinscriptionofhermeneuticsattheveryheartof 
thesocialsciencesprojectinparticular.Itisthereforenotaquestionofdenying 
theriseofmodelingorinterpretingmachines���oreventheirpowerandscope 
���but of examining the conditions of their possibility and signif i cance.To put 
it in a nutshell: the emergence of these hermeneutic machines is an opportu- 
nity to think afresh about what a critical hermeneutics can represent within the social sciences and how it can enter into dialogue with or serve as a basis 
for the development of Critical AI Studies (CAIS) (Roberge 2020; Pasquinelli/ 
Joler 2020). Specif i cally, this implies taking seriously the history and modus 
operandi of these language models and the way in which their various prob- 
lems crystallized in the form of diverging views as part of the wider implica- 
tionsoftheGebru���Googleconflict.T h isinturnimpliesabetterunderstanding 
of the type of meaning at stake; that is,above all,the type of textual world de- 
ployed���ornot���andthetypeofreadingexperiencethatthisinduces.Finally,it 
impliescircumscribingtheaporiasofnaturallanguageprocessingmodelsthat 
aremostoftendecontextualizedand(re)translatingorreinsertingtheminthe 
social,political,economic and cultural reality from which they originate,par- 
ticularly in the link between platform capitalism and the ethical desiderata of 
today. 
Our analysis is articulated in three stages which correspond to the three 
implications mentioned earlier: i) taking seriously, ii) understanding and iii) 
circumscribingtheaporiasofNLPmodels.Inthef i rstsection,wetrytograsp 
these most recent models as social constructions and socio-technical assem- 
blages(Schwartz1989;Woolgar1985).BERT���orBidirectionalEncoderRepre- 
sentationsfromTransformers���wasintroducedbyGooglein2018andlaterin- 
tegrated into its main search engine. It collects information from Wikipedia, 
for example, and reads from right to left and back again to identify multiple 
parallelconnectionsandpredictmissingterms.OpenAI���sGPT-3���Generative 
Pre-TrainedTransformer���isnewer;withits175billionparameters,itissaidto 
outperform Google���s model by 400 times in ���encoding��� textuality and thereby 
opening up a huge range of writing possibilities ��� journalistic, IT, adminis- 
trative,etc.Whatthesetwomodelshaveincommonisthattheyarenotexactly 
blackboxes,butrathertheobjectsofaparticularhistoricaldevelopmentwhich 
isformanytheobjectofitsdiff i cultiesandlimitations.
1 / 1
ChatGPT
ChatGPT
The introduction of "Parrots All the Way Down: Controversies within AI's Conquest of Language" by Jonathan Roberge and Tom Lebrun delves into the controversy of Timnit Gebru's departure from Google over the submission of the paper "On the Danger of Stochastic Parrots: Can Language Models Be Too Big?". This event caused a significant stir and brought into question the value of these large language models, in both economic and axiological senses.
The authors argue that the controversy is not only an ethical and labor-related issue but also a fundamental hermeneutical one. They question whether AI and advances in deep learning have allowed for the creation of large and powerful models, and whether these result in an impoverishment of meaning, textuality, interpretation, and understanding due to automated processing.
They also suggest that the emergence of these models, like Google's BERT or OpenAI's GPT-3, presents a significant challenge for hermeneutic disciplines and the field of social sciences. It necessitates examining the conditions of their possibility and significance. The authors argue that this is an opportunity to rethink what a critical hermeneutics can represent within social sciences and its potential contribution to the development of Critical AI Studies (CAIS).
The authors propose to analyze the models in three stages that correspond to the three implications: i) taking seriously, ii) understanding, and iii) circumscribing the aporias of NLP models. They emphasize the need to view these models as social constructions and socio-technical assemblages, to understand the type of textual world deployed by these models, and to re-contextualize the models within the social, political, economic, and cultural reality they originate from.
1 / 1
In the second section, the overall meaning of this advanced automation 
comes under scrutiny. What are the implications of the epistemological con- 
ceptionpromotedthroughthesedataarchitecturesandstatisticalregressions? 
Andofboththemediationandtherecipientoflanguageinthistypeofconnec- 
tionist and cybernetic machine? h ese questions prompt a certain diversion 
throughhermeneutics���thatofPaulRicoeurwillbeprivilegedhere,partlybe- 
cause his notion of world allows us to think of a semantics, a reference and a 
���Being-demanding-to-be-said��� of textuality, which gives the measure of how 
AI models sometimes, if not often, appear ���shockingly good, and completely 
mindless���(Heaven2020).Inotherwords,thisworldofwhichRicoeurspeaksis 
42Embedded Models of Meaning 
whatcanallowustorethinkthelinkbetweenmeaningandreflexivity.T h elat- 
terisunderstoodherenotjustasthereader���sreflexivity,butalsomorebroadly 
astherediscoveredreflexivityofthereal-mundaneworld,inthecontextofso- 
ciety,cultureandpoliticaleconomy. 
In the third and i nal section, we therefore seek to develop a sociological 
and critical understanding of the deployment of these problematic, yet per- 
fectly practical interpreting machines ���BERT and GPT-3 ���that are intruding 
oneverydaylife.T h evalueofthesemodelsisinseparablefromamarketofdata 
andmeaningextractioninwhichsomethrivemorethanothersandforwhich, 
astheGebrucaseshowsratherwell,ethicsbecomesakindofjustif i cationand 
evencommodity. 
2. The drive to automate language: an all too brief history 
h elastfewyearshaveseenamajorevolutioninnaturallanguageprocessing. 
For the i rst time, language models based on a so-called Transformer archi- 
tecture make it possible to generate texts that are suff i ciently coherent to fool 
theirreaders,withoutrelyingonadeductiveandsymboliclogicpreviouslyde- 
cidedbyaprogrammer(Buchanan2005;Balpe1991).Basedonthemechanism 
ofmachinelearning,andparticularlydeeplearning,thistypeofcomputerpro- 
grammingproposestoimitatesomeofthecognitivemechanismsofthebrain, 
notably by means of artif i cial neurons ��� in reality miniature computer pro- 
grams that activate or deactivate themselves according to the result of their 
calculation. As with the human brain, the strength of the mechanism lies in 
the networking of a large number of these miniature programs.T h is method, 
foralongtimeonthefringesoftheAIf i eld,suddenlycamebackintothespot- 
light during the 2012 ImageNet competition, won by Geoffrey Hinton���s team 
thanks to the combination of great computing power, a vast data set and this 
method,whichisrightlydescribedasconnectionist(Cardon/Cointet/Mazi��res 
2018;Domingos2015).
1 / 1
ChatGPT
ChatGPT
In the second section, the authors delve into the broader implications of advanced automation. They ponder over the meaning and ramifications of the epistemological conception facilitated by the statistical regressions and data architectures in AI. They emphasize how such AI models impact the mediation and the recipient of language in these cybernetic and connectionist machines. To answer these questions, they draw upon the hermeneutics of Paul Ricoeur, focusing on his notion of the world as a referent of semantics and the text's demanding essence. This approach allows them to critique the way AI models are often perceived as "shockingly good, and completely mindless".
The authors argue that Ricoeur's concept of the world can help to rethink the relationship between meaning and reflexivity. This reflexivity is seen not just as a reader's reflexivity, but also as a rediscovered reflexivity of the real world within society, culture, and political economy.
In the third section, they strive to develop a sociological and critical understanding of these AI models (BERT and GPT-3). They point out the increasing intrusion of these models into everyday life and highlight that their value is inseparable from a data and meaning extraction market, where ethics can be used as a form of justification and commodity.
In the brief history provided, the authors note a major evolution in natural language processing over the past few years. For the first time, language models based on Transformer architecture can generate coherent texts without relying on previously decided symbolic and deductive logic. This type of programming, which imitates cognitive brain mechanisms using artificial neurons, gained prominence after the 2012 ImageNet competition was won by Geoffrey Hinton���s team. This success highlighted the effectiveness of using high computational power, vast data sets, and a connectionist approach.
1 / 1
SummariZe: Sparse Bayesian Information Filters for Localization and 
Mapping 
by 
Matthew R. Walter 
Submitted to the Joint Program in Applied Ocean Science & Engineering 
on February 6, 2008, in partial fulf i llment of the 
requirements for the degree of 
Doctor of Philosophy 
Abstract 
This thesis formulates an estimation framework for Simultaneous Localization and 
Mapping (SLAM) that addresses the problem of scalability in large environments. 
We describe an estimation-theoretic algorithm that achieves signif i cant gains in com- 
putational ef i ciency while maintaining consistent estimates for the vehicle pose and 
the map of the environment. 
We specif i cally address the feature-based SLAM problem in which the robot rep- 
resents the environment as a collection of landmarks. The thesis takes a Bayesian 
approach whereby we maintain a joint posterior over the vehicle pose and feature 
states, conditioned upon measurement data. We model the distribution as Gaus- 
sian and parametrize the posterior in the canonical form, in terms of the information 
(inverse covariance) matrix. When sparse, this representation is amenable to compu- 
tationally ef i cient Bayesian SLAM i ltering. However, while a large majority of the 
elements within the normalized information matrix are very small in magnitude, it is 
fully populated nonetheless. Recent feature-based SLAM i lters achieve the scalability 
benef i ts of a sparse parametrization by explicitly pruning these weak links in an ef f ort 
to enforce sparsity. We analyze one such algorithm, the Sparse Extended Information 
Filter (SEIF), which has laid much of the groundwork concerning the computational 
benef i ts of the sparse canonical form. The thesis performs a detailed analysis of the 
process by which the SEIF approximates the sparsity of the information matrix and 
reveals key insights into the consequences of dif f erent sparsif i cation strategies. We 
demonstrate that the SEIF yields a sparse approximation to the posterior that is in- 
consistent, suf f ering from exaggerated conf i dence estimates. This overconf i dence has 
detrimental ef f ects on important aspects of the SLAM process and af f ects the higher 
level goal of producing accurate maps for subsequent localization and path planning. 
This thesis proposes an alternative scalable i lter that maintains sparsity while 
preserving the consistency of the distribution. We leverage insights into the natural 
structure of the feature-based canonical parametrization and derive a method that 
actively maintains an exactly sparse posterior. Our algorithm exploits the structure 
of the parametrization to achieve gains in ef i ciency, with a computational cost that 
scales linearly with the size of the map.Unlike similar techniques that sacrif i ce 
consistency for improved scalability, our algorithm performs inference over a posterior 
that is conservative relative to the nominal Gaussian distribution. Consequently, we 
preserve the consistency of the pose and map estimates and avoid the ef f ects of an 
overconf i dent posterior. 
We demonstrate our i lter alongside the SEIF and the standard EKF both in sim- 
ulation as well as on two real-world datasets. While we maintain the computational 
advantages of an exactly sparse representation, the results show convincingly that 
our method yields conservative estimates for the robot pose and map that are nearly 
identical to those of the original Gaussian distribution as produced by the EKF, but 
at much less computational expense. 
The thesis concludes with an extension of our SLAM i lter to a complex underwater 
environment. We describe a systems-level framework for localization and mapping 
relative to a ship hull with an Autonomous Underwater Vehicle (AUV) equipped 
with a forward-looking sonar. The approach utilizes our i lter to fuse measurements 
of vehicle attitude and motion from onboard sensors with data from sonar images of 
the hull. We employ the system to perform three-dimensional, 6-DOF SLAM on a 
ship hull. 
Thesis Supervisor: John J. Leonard 
Title: Professor of Mechanical and Ocean Engineering 
Massachusetts Institute of Technology
1 / 1
ChatGPT
ChatGPT
Matthew R. Walter's PhD thesis, "Sparse Bayesian Information Filters for Localization and Mapping," presents a new estimation framework for Simultaneous Localization and Mapping (SLAM), aiming to address scalability issues in large environments. The thesis outlines an estimation-theoretic algorithm that significantly improves computational efficiency while maintaining consistent estimates for vehicle pose and environmental mapping.
The work specifically deals with the feature-based SLAM problem, using a collection of landmarks to represent the environment. The thesis employs a Bayesian approach, maintaining a joint posterior over vehicle pose and feature states based on measurement data. The distribution is modeled as Gaussian and parametrized in the canonical form using an information (inverse covariance) matrix. This representation facilitates computationally efficient Bayesian SLAM filtering when sparse.
An analysis of the Sparse Extended Information Filter (SEIF), an existing algorithm that approximates the sparsity of the information matrix, is also conducted in the thesis. Walter identifies that the SEIF results in an inconsistent, overconfident posterior approximation that negatively impacts the SLAM process and its overarching goal of accurate map production for future localization and path planning.
In response, the thesis introduces a new scalable filter that maintains sparsity while preserving the consistency of the distribution. This algorithm utilizes the structure of the feature-based canonical parametrization to maintain an exactly sparse posterior, achieving efficiency gains with a computational cost that scales linearly with the map size.
The proposed method is demonstrated alongside the SEIF and the standard Extended Kalman Filter (EKF) using simulation and two real-world datasets. Results show that the new method provides conservative estimates for robot pose and map nearly identical to those produced by the EKF, but at a significantly reduced computational expense.
The thesis concludes with an application of the SLAM filter to an underwater environment, utilizing an Autonomous Underwater Vehicle (AUV) equipped with a forward-looking sonar for localization and mapping relative to a ship hull. This system is employed to perform three-dimensional, 6-DOF SLAM on a ship hull.
1 / 1
Statler: State-Maintaining Language Models 
for Embodied Reasoning 
Takuma Yoneda���1, Jiading Fang���1, Peng Li���2, Huanyu Zhang���3, Tianchong Jiang3, Shengjie Lin1, 
Ben Picker3, David Yunis1, Hongyuan Mei1, and Matthew R. Walter1 
1Toyota Technological Institute at Chicago 
{takuma,fjd,slin,dyunis,hongyuan,mwalter}@ttic.edu 
2Fudan University 
lip21@m.fudan.edu.cn 
3University of Chicago 
{huanyu,tianchongj,bpicker}@uchicago.edu 
Abstract: Large language models (LLMs) provide a promising tool that enable 
robots to perform complex robot reasoning tasks. However, the limited context 
window of contemporary LLMs makes reasoning over long time horizons diff i cult. 
Embodied tasks such as those that one might expect a household robot to perform 
typically require that the planner consider information acquired a long time ago 
(e.g., properties of the many objects that the robot previously encountered in the 
environment). Attempts to capture the world state using an LLM���s implicit internal 
representation is complicated by the paucity of task- and environment-relevant 
information available in a robot���s action history, while methods that rely on the 
ability to convey information via the prompt to the LLM are subject to its limited 
context window. In this paper, we propose Statler, a framework that endows LLMs 
with an explicit representation of the world state as a form of ���memory��� that is 
maintained over time.Integral to Statler is its use of two instances of general 
LLMs���a world-model reader and a world-model writer���that interface with and 
maintain the world state. By providing access to this world state ���memory���, Statler 
improves the ability of existing LLMs to reason over longer time horizons without 
the constraint of context length. We evaluate the effectiveness of our approach on 
three simulated table-top manipulation domains and a real robot domain, and show 
that it improves the state-of-the-art in LLM-based robot reasoning. Project website: 
https://statler-lm.github.io/. 
Keywords: Large language models, Long-horizon planning, World state model 
1Introduction 
Large language models (LLMs) are capable of generating intricate free-form text and complex 
code with an impressive level of prof i ciency [1,2,3]. Recently, researchers have shown that the 
success of LLMs extends to robotics domains, where the capacity for LLMs to perform complex 
reasoning using language enables robots to perform tasks that require sophisticated planning and 
language understanding [4,5,6]. These methods either rely solely on the implicit in-context memory 
that is internal to the LLM [5] or they augment LLMs with scene information extracted from an 
ego-centric image captured at the current time step [4]. Both approaches have proven effective 
for diff i cult embodied reasoning tasks, however they struggle when faced with planning tasks that 
require planning over long time horizons, due to the limited context window of contemporary LLMs. 
Although there have been recent efforts to enlarge the context window of LLMs [7], the size of the 
*Equal contribution. 
arXiv:2306.17840v1 
[cs.RO] 
30 
Jun 
2023 
State 
Code 
say("The Rubik's cube is under the blue cup. I shall put away the blue cup 
first.") 
put_first_on_second("blue cup", "empty space") 
update_wm("Put the blue cup on the empty space.") 
say("Now I can put the toy wheel on the Rubik's cube.") 
put_first_on_second("toy wheel", "rubiks cube") 
update_wm("Put the toy wheel on the Rubik's cube.") 
User Query 
Put the toy wheel on 
the Rubik's cube. 
# state = { 
# "objects": ("rubiks cube", "toy duckie", "toy wheel", "yellow block"), 
# "covers": ("red cup", "green cup", "blue cup", "black cup"), 
# "rubiks cube": {"under": "blue cup"}, 
# "toy wheel": {"on": "yellow block"}, 
# "yellow block": {"under": "toy wheel"}, 
# "blue cup": {"on": "rubiks cube"},} 
World Model ReaderWorld Model Writer 
Figure 1: Our Statler framework enables robots to carry out complex tasks specif i ed in natural 
language that require reasoning over long time horizons. Integral to our model are its world model 
writer and world model reader, two instances of general LLMs that are responsible for maintaining 
the explicit world state and generating code that enables the robot to carry out the task. 
context window remains fundamentally bounded. Further, providing the model with long-range 
context improves prediction accuracy only on on a small number of tokens���LLMs struggle to exploit 
information conveyed in long-term context beyond what can be directly copied [8]. Meanwhile, 
reliance on the robot���s current ego-centric view prohibits the language model from reasoning over 
aspects of the scene that are not directly observable, e.g., the fruit located in the (closed) kitchen 
refrigerator or an object in a room that the robot previously visited. 
In this paper, we propose Statler (STATe-maintaining Language models for Embodied Reasoning), 
a framework that maintains an external world model as explicit memory to improve the long-term 
reasoning capabilities of LLMs for robot planning. Integral to our approach, as shown in Figure 1, 
it maintains and interfaces with this world model over time using two instances of general LLMs��� 
a world-model reader and a world-model writer. The world-model reader interfaces with the 
world model to generate code that answers user queries. The world-model writer is responsible for 
predicting the next world state based on the current world state and a query given by the reader. 
We employ a structured representation of the world state, which has been found to improve the 
performance of LLMs [9,10], particularly when the output is also structured, and has the advantage 
of being human-readable and concise for eff i cient processing. Note that while we individually tailor 
each world model���s design to its general task type (see Prompts 12, 8, 7, and 9), the design is highly 
l exible because the reader and writer are both LLMs and are instructed with in-context-learning 
to understand how to parse and manipulate the world model. This is in contrast to domain-specif i c 
formal languages [11], where the designs are i xed and parsing and writing requires that specif i c rules 
be followed. 
We evaluate Statler on a series of simulated and real-world robot manipulation domains. Experimental 
results demonstrate that Statler improves the long-term embodied reasoning capabilities of LLMs 
and that it outperforms the current state-of-the-art [5].
1 / 1
ChatGPT
ChatGPT
"Statler: State-Maintaining Language Models for Embodied Reasoning" is a research paper by Takuma Yoneda, Jiading Fang, Peng Li, Huanyu Zhang, Tianchong Jiang, Shengjie Lin, Ben Picker, David Yunis, Hongyuan Mei, and Matthew R. Walter. It presents a novel framework designed to improve the long-term reasoning capabilities of large language models (LLMs) for robotic planning.
LLMs have demonstrated success in generating intricate free-form text, complex code, and facilitating robot task performance that requires sophisticated planning and language understanding. However, contemporary LLMs have a limited context window, which makes reasoning over longer time horizons difficult, especially in embodied tasks that a household robot might be expected to perform.
In response to this challenge, the authors propose Statler, a framework that supplies LLMs with an explicit, time-maintained representation of the world state, functioning as a form of "memory". Key to Statler are two instances of general LLMs, namely a world-model reader and a world-model writer. These models interface with and maintain the world state, enhancing the capability of LLMs to reason over longer time horizons without being constrained by context length.
The world-model reader interacts with the world model to generate code that answers user queries. On the other hand, the world-model writer predicts the next world state based on the current world state and a query provided by the reader. The authors utilize a structured representation of the world state, which is beneficial in improving LLM performance, particularly when the output is also structured. Furthermore, it provides the advantages of being human-readable and concise for efficient processing.
The effectiveness of Statler is evaluated on three simulated table-top manipulation domains and a real-world robot domain. The results demonstrate that Statler improves the long-term embodied reasoning capabilities of LLMs and outperforms the existing state-of-the-art approaches in LLM-based robot reasoning.
1 / 1
2. The drive to automate language: an all too brief history 
h elastfewyearshaveseenamajorevolutioninnaturallanguageprocessing. 
For the i rst time, language models based on a so-called Transformer archi- 
tecture make it possible to generate texts that are suff i ciently coherent to fool 
theirreaders,withoutrelyingonadeductiveandsymboliclogicpreviouslyde- 
cidedbyaprogrammer(Buchanan2005;Balpe1991).Basedonthemechanism 
ofmachinelearning,andparticularlydeeplearning,thistypeofcomputerpro- 
grammingproposestoimitatesomeofthecognitivemechanismsofthebrain, 
notably by means of artif i cial neurons ��� in reality miniature computer pro- 
grams that activate or deactivate themselves according to the result of their 
calculation. As with the human brain, the strength of the mechanism lies in 
the networking of a large number of these miniature programs.T h is method, 
foralongtimeonthefringesoftheAIf i eld,suddenlycamebackintothespot- 
light during the 2012 ImageNet competition, won by Geoffrey Hinton���s team 
thanks to the combination of great computing power, a vast data set and this 
method,whichisrightlydescribedasconnectionist(Cardon/Cointet/Mazi��res 
2018;Domingos2015). 
h e recent evolution of NLP is marked by four signif i cant changes, corre- 
sponding to four signif i cant publications. h e i rst paper, published one year 
afterHinton���sgreatdemonstration,was���Eff i cientEstimationofWordRepre- 
sentationsinVectorSpace���(Mikolovetal.2013).WrittenbyateamfromGoogle 
���Jeff Dean is one of the co-authors ���the paper proposes a group of language 
models called Word2vec, which aims to reconstruct the linguistic context in 
which words are used. Word2Vec, like most machine learning technologies, 
Jonathan Roberge & Tom Lebrun: Parrots All the Way Down43 
relies heavily on the principle of regression, a method of statistical analysis 
that allows one variable to be placed in relation to its correlations with oth- 
ers. Roughly summarized, the technology involves locating the variable ��� the 
���meaning������of a word in relation to the variables ���the���meanings������of other 
wordsaroundit.Asitsnamesuggests,Word2Vecaimstotransformwordsinto 
vectors,i.e.,tomodeltheinformationtheycontainusingalgorithms.Inprac- 
tice, Word2Vec ���vectorizes��� words using two distinct and complementary ar- 
chitectures. One, called CBOW (Continuous Bag of Words), seeks to predict 
a word according to the i ve words to its right and the i ve words to its left. 
h eother,calledSkip-gram,doesexactlytheoppositeandseekstopredictthe 
words in the context according to a given word.T h e logic is always predictive: 
the model must be able to assign the ���right��� vector to each word. Despite its 
successintheearly2010s,Word2Vecisseverelylimited.Inparticular,thelan- 
guage model assigns only one meaning per word and only vectorizes individ- 
ual words, so that the meaning of even a relatively simple sentence continues 
toeludeit(Horn2017;Cusin-Berche2003).Wewillreturntothispointlater. 
Toaddresstheselimitations,VinyalsandLe���alsofromGoogle���published 
apapershortlyafterwardsentitled���ANeuralConversationalModel���(2015).T h is 
proposed,quite simply,to apply a sequential approach to Word2Vec to model 
the meaning of a text by linking certain sequences with others ��� thus form- 
ingalongeror���networked���formoftextmapping(Sutskever/Vinyals/Le2014). 
Withthisapproach,modelingcannowbeappliedtolargersequences,includ- 
ing sentences: the sentences preceding and following the target sentence are 
thus also taken into account and the model allows for a minimum of contex- 
tualconsideration. 
Despite this progress, Word2Vec-type
1 / 1
ChatGPT
ChatGPT
The recent history of natural language processing (NLP) has been marked by significant evolution and advancement, driven by transformative models based on the Transformer architecture. These models can generate texts that are coherent enough to fool readers without relying on deductive and symbolic logic pre-set by a programmer. This method imitates some cognitive mechanisms of the human brain through artificial neurons - tiny computer programs that activate or deactivate themselves based on their calculation outcomes.
This method gained prominence after Geoffrey Hinton's team won the 2012 ImageNet competition, demonstrating the effectiveness of using large amounts of computing power, a vast dataset, and a connectionist approach.
The recent evolution of NLP is marked by four significant changes:
The first change was the development of Word2vec, a group of language models that aim to reconstruct the linguistic context in which words are used. Word2vec models the information words contain using algorithms. It vectorizes words using two complementary architectures. CBOW (Continuous Bag of Words) predicts a word based on the five words to its right and left. Conversely, Skip-gram predicts the context words from a given word. However, Word2vec has limitations - it assigns only one meaning per word and only vectorizes individual words, which means it struggles to understand the meaning of even a simple sentence.
To address these limitations, Vinyals and Le proposed applying a sequential approach to Word2Vec, which allows the model to consider a minimum of contextual information. Their method, outlined in the paper "A Neural Conversational Model", models the meaning of a text by linking certain sequences with others, effectively enabling a networked form of text mapping that includes larger sequences like sentences.
1 / 1
Despite this progress, Word2Vec-type systems are still based on the ap- 
proach where a word can only have one meaning. It is this limitation that the 
article���Deep contextualized word representations���(Peters et al.2018) aims to 
overcome. h e authors propose a new architecture called Embeddings from 
LanguageModels,orELMo,withinwhichthemodelcannowrecognizethedy- 
namic���moving,situational���natureofwordmeaning.Inpractice,eachword 
isassignedacoeff i cientor���weight���accordingtoitsinfluenceinthesentence.A 
wordlike���bow���cannowhavedifferentmeaningsdependingonacertaincon- 
text ��� ���I broke my violin bow��� and ���I am sitting at the ship���s bow.��� Above all, 
ELMo makes it possible for the i rst time to consider modeling that does not 
learnfromthetextinapurelyorderlyway,byofferinga���reading���inthreedif- 
ferent ways: i rst from left to right ��� from beginning to end; then in reverse 
��� from end to beginning; and i nally by combining the vectorized meanings 
44Embedded Models of Meaning 
of both types of analysis. Also, ELMo marks the real beginning of pre-trained 
models, allowing users to avoid having to train their models from scratch on 
huge data sets ���an extremely expensive practice,if only in terms of time and 
computingpower.2 
Finally,thepaper���Attentionisallyouneed���(Vaswanietal.2017)marksthe 
momentwhentheTransformerarchitecturevirtuallysealsthef i eld���sfate.Pre- 
vioussequentialmodelshaddiff i cultyretaininginformationaboutthepriori- 
tizationoftermsamongthemselves:totakethepreviousexample,information 
inasimplesentence������Ibrokemyviolinbow���,���Iwassittingattheship���sbow��� 
��� was diff i cult to retain in longer sequences ��� ���then the bow was splashed���. 
h e Transformer architecture moves away from this approach and its many 
problems in terms of memory, computational speed, word position, etc., by 
proposingtoidentifythecontextthatgivesmeaningtowords,whicharethen 
processedinparallel.T h isinvolvestheuseofbothanencoderandadecoder��� 
andindeedmanyofthemonmultiplelevelsactingandproducingfeedbackin 
a cybernetic manner.T h e encodertransformsinformationinto codebygiving 
acalculatedvaluetoaword;adecoderdoesexactlytheopposite,transforming 
codeintoinformationby���calculating���awordfromavalue. 
h epointtokeepinmindhereisthatsucharchitecturesarebasedonneu- 
ral networks and on the ���deep learning��� made famous since Hinton���s demon- 
strationof2012,andinwhichlayersandlayersofencodersandlayersandlay- 
ers of decoders can be arranged without too many limits other than techni- 
calones.Aboveall,thetrulyinnovativecharacteroftheTransformerarchitec- 
ture lies in the attention mechanism implemented. h e idea is to calculate a 
���weighted matrix product��� ��� in other words, a matrix score that determines 
thelevelofattentionthatawordshouldhavetowardsotherwords;somemight 
alsospeak,moresimply,ofsituationaldependency.Anencodercand thus compute several ���attention heads��� that work in a bidirectional way: an attention 
weight is computed as input and produces an output vector.
1 / 1
ChatGPT
ChatGPT
Continuing with the evolution of NLP, the next big breakthrough came with the introduction of ELMo (Embeddings from Language Models) to address the limitation of Word2Vec-type systems where a word can only have one meaning. As explained in the paper "Deep contextualized word representations" (Peters et al., 2018), ELMo allows the model to recognize the dynamic or situational nature of word meaning. Each word is assigned a weight according to its influence in the sentence, allowing the model to distinguish the different meanings of a word like "bow" based on its context.
ELMo introduced a novel way of modeling that reads the text in three different ways: from left to right, in reverse, and by combining the vectorized meanings of both types of analysis. It marked the real beginning of pre-trained models, which could save users from having to train their models from scratch on massive data sets, an expensive and time-consuming task.
The fourth significant development was the introduction of the Transformer architecture, as outlined in the paper "Attention is all you need" (Vaswani et al., 2017). Transformer architecture improved on previous models by identifying the context that gives meaning to words and processing them in parallel using an encoder and a decoder. This approach helped solve problems related to memory, computational speed, and word position in previous models.
The Transformer architecture's real innovation lies in its attention mechanism. It computes a weighted matrix product, effectively calculating a score that determines the level of attention a word should pay to other words. In other words, it computes situational dependency. An encoder can compute several "attention heads" that work bidirectionally, using computed attention weights as input to produce an output vector.
These advancements all rely on deep learning, an approach made famous by Hinton's 2012 demonstration, and they leverage neural networks. These networks can have multiple layers of encoders and decoders, with the only limits being technical ones.
1 / 1
It is thus these new attention mechanisms specif i c to Transformer archi- 
tectures that are at the source of the current successes of language models, 
in particular Google���s BERT and OPEN AI���s GPT-3, as spearheads of the on- 
going battle waged by the GAFAM (Google,Amazon,Facebook and Microsoft) 
in theirquestforthemasteryof artif i cialintelligence(T h ibout2019;Horowitz 
2018).BERT is still a relatively small model compared to GPT-3,as it has been 
pre-trained on about 3.3 billion words and has 345 million parameters (Devlin 
et al. 2018). Its main objective is to end formalized keyword searches, a goal 
thatmayseemtrivialatf i rstbutiscentraltothecompany���smissionstatement 
��� ���to organize the world���s information to make it universally accessible and 
useful���. To achieve this, Google must enable its users to express themselves 
in the most natural, user-friendly and dialogical way possible.3BERT tries to 
achievesthisobjectivebyfocusingontheencoderpartofthearchitecture,the 
partthattransformsinformation,thewrittenorspokenrequest,butalsotexts 
tobetranslated,forexample,intocodeandvectorastocapturetheircontours: 
whodoeswhat,where,etc.BERT,inotherwords,andaboveall,���understands��� 
in the sense of extracting the relevant elements as rendered in more encom- 
passing sets. Its Transformer architecture is thus very flexible and functions 
as an interface between the natural input language (the query) and the output 
(theresult).ItshouldalsobenotedthatBERTisopen-source,whichispartofa 
corporate strategy of value creation quite specif i c to Google,4to which we will 
returninthelastsection.
1 / 1
ChatGPT
ChatGPT
The recent success of language models, specifically Google���s BERT (Bidirectional Encoder Representations from Transformers) and OpenAI's GPT-3 (Generative Pretrained Transformer 3), is largely attributed to the new attention mechanisms specific to the Transformer architecture. These models represent the cutting edge in the ongoing race for AI mastery amongst tech giants, often referred to as GAFAM (Google, Amazon, Facebook, and Microsoft).
BERT, though smaller than GPT-3 with its pre-training on about 3.3 billion words and 345 million parameters (Devlin et al. 2018), has a significant objective. It aims to move beyond formalized keyword searches, a goal central to Google's mission statement to "organize the world���s information to make it universally accessible and useful". To achieve this, Google aims to allow users to express their search queries in the most natural, user-friendly, and dialogical way possible.
BERT focuses primarily on the encoder part of the Transformer architecture, which transforms input information (like a written or spoken request, or texts to be translated) into code and vector representations to capture their nuances. In other words, BERT ���understands��� in the sense of extracting the relevant elements from larger contexts. Its Transformer architecture is extremely flexible and serves as an interface between the natural input language (the query) and the output (the result).
Another notable feature of BERT is its open-source nature, which is part of a specific corporate strategy of value creation at Google. This strategy, along with its implications, will be discussed further in the last section of the text.
1 / 1
GPT-3isatthetimeofwritingthemostpowerfullanguagemodel,trained 
on around 570 gigabytes of data and composed of 175 billion parameters 
(Brown et al. 2020). GPT-3 explicitly aims to generate text, according to its 
creators.UnlikeBERT,therefore,itfavorsthedecoderpartofitsarchitecture, 
the part that more precisely allows code to be transformed into information, 
i.e.,inferringmissingwords,completingsentences,etc.Farfrombeingopen- 
source, GPT-3 is currently marketed via its Application Programming Inter- 
face (API), a choice which is obviously part of a corporate strategy that aims 
to control the economic ecosystem on which many future companies will be 
based. In a blog post, OpenAI reported in March 2021 that more than 300 
companies were making use of this API, a number that keeps growing. For 
instance, applications already available include CopyAI, which can generate 
slogans and product descriptions for companies, and Fable, which can model 
charactersfromnovelsandtalktothem(Scott2020).5 
Because they are socio-technical assemblages, it goes without saying that 
these models struggle to be perfect or even to live up to the rhetoric legit- 
imizing their use and, more generally, all that is the magic of AI (Roberge 
2020; Elish/Boyd 2018). h e fact is that all is not well in the best of all NLP 
worlds, and that upon closer inspection, its deployment is more a matter of 
���garbagein,garbageout������theso-calledGIGOprinciple,asironicallyreferred 
to by scientists working in the i eld (Kilkenny/Robinson 2018). With regard to 
input,itshouldbeseenthatwhilelanguagecanapparentlybecomputationally 
modelled,the Transformer architecture can only achieve this from a resource 
that is itself a social construct: the database. h is dependence of language 
models on their training sources is quite widely discussed (Hutchinson et al. 
2020; Roberge 2018), as any given Transformer architecture remains based 
on the principle of regression outlined earlier,which aims to locate a variable 
(a word) according to its correlations with other variables (the other words 
in the database). h is simple mathematical procedure thus constructs an 
approach to language based on the principle of ���winner takes all���. Put differ- 
ently, the language model promotes the most statistically probable language 
constructs according to the data set on which it is trained. Also, the choice of 
texts on which these language models are developed participates in a certain 
representation of the world, whose symbolic, if not ideological, dimension is 
often only revealed once the models have been applied ��� through the racist, misogynistic or other biases that result from them. h is is one of the most 
strikingobservationsinthetextthatledtoGebru���sdismissalfromGoogle: 
GPT-2���s training data is sourced by scraping outbound links from Reddit, 
and Pew Internet Research���s 2016 survey reveals 67% of Reddit users in the 
United States are men, and 64% between ages 18 and 29. Similarly, recent 
surveys of Wikipedians i nd that only 8���15% are women or girls (Bender et 
al. 2021: 4). 
What is thus a problem on the input side becomes a problem on the output 
side, with the highest number of potential and proven slippages. One of the 
most feared applications in this respect is what is usually referred to as as- 
troturf i ng, in which a plethora of micro-speeches is automatically generated 
as if to simulate a mass movement accrediting such organizations,ideas,etc. 
(Kovicetal.2018;Zhang/Carpenter/Ko2013).Indeed,theUSNationalIntelli- 
genceCouncil���slatestreportGlobalTrends2040listsAI-poweredpropagandaas 
oneofitstopteneconomicandpoliticalsecurityconcerns(2021).6Inthiscase, 
fakeprof i leswithautomaticallygeneratedcontentalreadypopulatesocialnet- 
worksthatareusedbybillionsofpeopleonadailybasisandarethereforeprone 
to misinformation,manipulation and the promotion of hate speech (Keller et 
al.2020).T h erearealsootherexamplesofbiasesembeddedinBERTandGPT-3 
that are related to the probabilistic ideology of these models. AI Dungeon, a 
computerizedversionofDungeons&DragonspoweredbyGPT-3,madenews 
inApril2021for,amongotherthings,allowingthegenerationofnarrativesfea- 
turingsexualrelationsinvolvingchildren���aphenomenonthatwasobviously 
not foreseen by OpenAI (Simonite 2021a). In the follow-up to their Algorithms 
of Oppression: How Search Engines Reinforce Racism, Noble and others have also 
extensively exposed the biases that have always been built into Google envi- 
ronments,bothinthevariouslanguagemodelsthatprecededBE trainingdatahasbeenshowntohaveproblematiccharacteristics[���]result- 
ing in models that encode stereotypical and derogatory associations along 
gender, race, ethnicity, and disability status (Bender et al. 2021: 4). 
Despiteitsdeleteriousconsequencesfortheirauthors���Gebruinparticular��� 
���StochasticParrots���isnotparticularlyinnovative.AsWiredreports,���thepaper 
wasnotintendedtobeabombshell���.7Itmerelyexploresthreemajorissuesre- 
lated to the ever-growing size of language models: i rst, their environmental 
cost; second,their formal and rigid nature,which allows biases both to struc- 
turethemselvesandoftentogounnoticed;andthird,solutionsthatmightmit- 
igatetherisksassociatedwiththeiruse. 
In the sections that make up the core of the overall argument, the paper 
reminds us that the models are trained only on the form of the language and 
notonitssubstance.TouseSaussureanterms,amodelcanonlyevermasterthe 
signif i er of language,never the signif i ed ���an argument developed in another 
paper by Bender and Koller (2020).���Stochastic Parrots���uses this argument to 
denouncethedeceptiveorillusorycharacterofthecurrentsuccessesofmodels 
such as BERT and GPT-3,which seem to master language when they will only 
everhaveastatisticalunderstandingofit: 
Text generated by an LM [language model] is not grounded in communica- 
tive intent, any model of the world, or any model of the reader���s state of 
mind.[���]Contrarytohowitmayseemwhenweobserveitsoutput,anLMis 
a system for haphazardly stitching together sequences of linguistic forms it 
hasobservedinitsvasttrainingdata,accordingtoprobabilisticinformation 
about how they combine, but without any reference toRTandinthe 
waythatBERTisnowfarfromsolvingthesediff i culties(Noble2018;Bhardwaj, 
MajumderandPoria2021;Hutchinsonetal.2020).���StochasticParrots���ispart 
ofthisbroadercritiqueofNLP: 
The size of data available on the web has enabled deep learning models 
to achieve high accuracy on specif i c benchmarks in NLP [���]. However, the
1 / 1
ChatGPT
ChatGPT
At the time of writing, GPT-3 is the most powerful language model, trained on around 570 gigabytes of data and composed of 175 billion parameters (Brown et al. 2020). GPT-3 is intended to generate text, favoring the decoder part of the Transformer architecture. Unlike BERT, GPT-3 is not open-source but marketed via an Application Programming Interface (API). It is a part of a strategic approach aiming to control the economic ecosystem of future companies. By March 2021, more than 300 companies were using this API, with its usage still growing.
Despite the remarkable abilities of these models, they are far from perfect. A crucial challenge they face is dealing with the data they are trained on. Given that all language models are trained on existing text data, they are likely to absorb the biases present in that data. For example, GPT-3 was trained on data sourced from Reddit and Wikipedia, platforms that have been shown to have demographic skews. Consequently, the biases in the training data can lead to biased outputs when the models are used.
This issue also becomes a problem on the output side, with multiple potential and actual concerns. One of them is 'astroturfing', where large numbers of automated responses are generated to simulate a mass movement in support of certain organizations or ideas. Another concern is the production of harmful or inappropriate content. For instance, GPT-3 was used in AI Dungeon, a game which generated narratives that involved inappropriate content, a consequence not foreseen by OpenAI.
The critique of these language models was detailed in the paper "Stochastic Parrots", which highlighted three major issues related to the increasing size of these models: their environmental cost, their formal and rigid nature that allows biases to structure themselves and often go unnoticed, and potential solutions to mitigate the risks associated with their use.
The paper argues that these models are trained only on the form of the language, not its substance. Thus, the models may seem to master language, but they only have a statistical understanding of it. The paper forms part of a broader critique of Natural Language Processing (NLP), which includes issues with biases in the training data and the inability of these models to truly comprehend language and context beyond a statistical level.
1 / 1
Open in app

Nate Guimond
You have 1 free member-only story left this month. Upgrade for unlimited access.


Member-only story

GPT-4: 8 Models in One; The Secret is Out
GPT4 kept the model secret to avoid competition, now the secret is out!
Dr. Mandar Karhade, MD. PhD.
Towards AI
Dr. Mandar Karhade, MD. PhD.

��
Follow

Published in
Towards AI

9 min read
��
Jun 24

Listen


Share


More

The GPT4 model has been THE groundbreaking model so far, available to the general public either for free or through their commercial portal (for public beta use). It has worked wonders in igniting new project ideas and use-cases for many entrepreneurs but the secrecy about the number of parameters and the model was killing all enthusiasts who were betting on the first 1 trillion parameter model to 100 trillion parameter claims!

The cat is out of the bag
Well, the cat is out of the bag (Sort of). On June 20th, George Hotz, founder of self-driving startup Comma.ai leaked that GPT-4 isn���t a single monolithic dense model (like GPT-3 and GPT-3.5) but a mixture of 8 x 220-billion-parameter models.


Later that day, Soumith Chintala, co-founder of PyTorch at Meta, reaffirmed the leak.


Just the day before, Mikhail Parakhin, Microsoft Bing AI lead, had also hinted at this.


GPT 4: Not a Monolith
What do all the tweets mean? The GPT-4 is not a single large model but a union/ensemble of 8 smaller models sharing the expertise. Each of these models is rumored to be 220 Billion parameters.


The methodology is called a mixture of experts' model paradigms (linked below). It's a well-known methodology also called as hydra of model. It reminds me of Indian mythology I will go with Ravana.


Please take it with a grain of salt that it is not official news but significantly high-ranking members in the AI community have spoken/hinted towards it. Microsoft is yet to confirm any of these.

What is a Mixture of Experts paradigm?
Now that we have spoken about the mixture of experts, let's take a little bit of a dive into what that thing is. The Mixture of Experts is an ensemble learning technique developed specifically for neural networks. It differs a bit from the general ensemble technique from the conventional machine learning modeling (that form is a generalized form). So you can consider that the Mixture of Experts in LLMs is a special case for ensemble methods.

In short, in this method, a task is divided into subtasks, and experts for each subtask are used to solve the models. It is a way to divide and conquer approach while creating decision trees. One could also consider it as meta-learning on top of the expert models for each separate task.

A smaller and better model can be trained for each sub-task or problem type. A meta-model learns to use which model is better at predicting a particular task. Meta learner/model acts as a traffic cop. The sub-tasks may or may not overlap, which means that a combination of the outputs can be merged together to come up with the final output.

For the concept-descriptions from MOE to Pooling, all credits to the great blog by Jason Brownlee (https://machinelearningmastery.com/mixture-of-experts/). If you like what you read below, please please subscribe to Jason���s blog and buy a book or two to support his amazing work!

Mixture of experts, MoE or ME for short, is an ensemble learning technique that implements the idea of training experts on subtasks of a predictive modeling problem.

In the neural network community, several researchers have examined the decomposition methodology. [���] Mixture���of���Experts (ME) methodology that decomposes the input space, such that each expert examines a different part of the space. [���] A gating network is responsible for combining the various experts.

��� Page 73, Pattern Classification Using Ensemble Methods, 2010.

There are four elements to the approach, they are:

Division of a task into subtasks.
Develop an expert for each subtask.
Use a gating model to decide which expert to use.
Pool predictions and gating model output to make a prediction.
The figure below, taken from Page 94 of the 2012 book ���Ensemble Methods,��� provides a helpful overview of the architectural elements of the method.


Example of a Mixture of Experts Model with Expert Members and a Gating Network
Taken from: Ensemble Methods
Subtasks
The first step is to divide the predictive modeling problem into subtasks. This often involves using domain knowledge. For example, an image could be divided into separate elements such as background, foreground, objects, colors, lines, and so on.

��� ME works in a divide-and-conquer strategy where a complex task is broken up into several simpler and smaller subtasks, and individual learners (called experts) are trained for different subtasks.

��� Page 94, Ensemble Methods, 2012.

For those problems where the division of the task into subtasks is not obvious, a simpler and more generic approach could be used. For example, one could imagine an approach that divides the input feature space by groups of columns or separates examples in the feature space based on distance measures, inliers, and outliers for a standard distribution, and much more.

��� in ME, a key problem is how to find the natural division of the task and then derive the overall solution from sub-solutions.

��� Page 94, Ensemble Methods, 2012.

Expert Models
Next, an expert is designed for each subtask.

The mixture of experts approach was initially developed and explored within the field of artificial neural networks, so traditionally, experts themselves are neural network models used to predict a numerical value in the case of regression or a class label in the case of classification.

It should be clear that we can ���plug in��� any model for the expert. For example, we can use neural networks to represent both the gating functions and the experts. The result is known as a mixture density network.

��� Page 344, Machine Learning: A Probabilistic Perspective, 2012.

Experts each receive the same input pattern (row) and make a prediction.

Gating Model
A model is used to interpret the predictions made by each expert and to aid in deciding which expert to trust for a given input. This is called the gating model, or the gating network, given that it is traditionally a neural network model.

The gating network takes as input the input pattern that was provided to the expert models and outputs the contribution that each expert should have in making a prediction for the input.

��� the weights determined by the gating network are dynamically assigned based on the given input, as the MoE effectively learns which portion of the feature space is learned by each ensemble member

��� Page 16, Ensemble Machine Learning, 2012.

The gating network is key to the approach and effectively, the model learns to choose the type subtask for a given input and, in turn, the expert to trust to make a strong prediction.

Mixture-of-experts can also be seen as a classifier selection algorithm, where individual classifiers are trained to become experts in some portion of the feature space.

��� Page 16, Ensemble Machine Learning, 2012.

When neural network models are used, the gating network and the experts are trained together such that the gating network learns when to trust each expert to make a prediction. This training procedure was traditionally implemented using expectation maximization (EM). The gating network might have a softmax output that gives a probability-like confidence score for each expert.

In general, the training procedure tries to achieve two goals: for given experts, to find the optimal gating function; for a given gating function, to train the experts on the distribution specified by the gating function.

��� Page 95, Ensemble Methods, 2012.

Pooling Method
Finally, the mixture of expert models must make a prediction, and this is achieved using a pooling or aggregation mechanism. This might be as simple as selecting the expert with the largest output or confidence provided by the gating network.

Alternatively, a weighted sum prediction could be made that explicitly combines the predictions made by each expert and the confidence estimated by the gating network. You might imagine other approaches to making effective use of the predictions and gating network output.

The pooling/combining system may then choose a single classifier with the highest weight, or calculate a weighted sum of the classifier outputs for each class, and pick the class that receives the highest weighted sum.

��� Page 16, Ensemble Machine Learning, 2012.

Switch Routing
We should also briefly discuss the switch routing approach differs from the MoE paper. I am bringing it up as it seems like Microsoft has used a switch routing than a Model of Experts to save some computational complexity, but I am happy to be proven wrong. When there are more than one expert's models, they may have a non-trivial gradient for the routing function (which model to use when). This decision boundary is controlled by the switch layer.

The benefits of the switch layer are threefold.

Routing computation is reduced if the token is being routed only to a single expert model
The batch size (expert capacity) can be at least halved since a single token goes to a single model
The routing implementation is simplified and communications are reduced.
The overlap of the same token to more than 1 expert model is called as the Capacity factor. Following is a conceptual depiction of how routing with different expert capacity factors works


illustration of token routing dynamics. Each expert processes a fixed batch-size
of tokens modulated by the capacity factor. Each token is routed to the expert
with the highest router probability, but each expert has a fixed batch size of
(total tokens/num experts) �� capacity factor. If the tokens are unevenly dis-
patched, then certain experts will overflow (denoted by dotted red lines), resulting
in these tokens not being processed by this layer. A larger capacity factor allevi-
ates this overflow issue but also increases computation and communication costs
(depicted by padded white/empty slots). (source https://arxiv.org/pdf/2101.03961.pdf)
When compared with the MoE, findings from the MoE and Switch paper suggest that

Switch transformers outperform carefully tuned dense models and MoE transformers on a speed-quality basis.
Switch transformers have a smaller compute futprint than MoE
Switch transformers perform better at lower capacity factors (1���1.25).

Concluding thoughts
Two caveats, first, that this is all coming from hearsay, and second, my understanding of these concepts is fairly feeble, so I urge readers to take it with a boulder of salt.

But what did Microsoft achieve by keeping this architecture hidden? Well, they created a buzz, and suspense around it. This might have helped them to craft their narratives better. They kept innovation to themselves and avoided others catching up to them sooner. The whole idea was likely a usual Microsoft gameplan of thwarting competition while they invest 10B into a company.

GPT-4 performance is great, but it was not an innovative or breakthrough design. It was an amazingly clever implementation of the methods developed by engineers and researchers topped up by an enterprise/capitalist deployment. OpenAI has neither denied or agreed to these claims (https://thealgorithmicbridge.substack.com/p/gpt-4s-secret-has-been-revealed), which makes me think that this architecture for GPT-4 is more than likely the reality (which is great!). Just not cool! We all want to know and learn.

A huge credit goes to 
Alberto Romero
 for bringing this news to the surface and investigating it further by reaching out to OpenAI (who did not respond as per the last update. I saw his article on Linkedin but the same has been published on Medium too.
1 / 1
ChatGPT
ChatGPT
This article discusses the architecture of OpenAI's GPT-4 language model. In it, the author reveals that GPT-4 is not a monolithic dense model like its predecessors (GPT-3 and GPT-3.5), but instead consists of an ensemble of eight smaller models. Each of these models is purported to contain 220 billion parameters.
This type of design is known as a "mixture of experts" (MoE) model paradigm. It's a well-established methodology in which tasks are divided into subtasks and then assigned to "experts" for solving. The individual models or "experts" can be trained on smaller, more manageable problem types. A meta-model, referred to as the "gating model," learns when to use which model to predict a specific task, effectively acting as a traffic cop.
The article further explains the concept of switch routing, which could be used instead of a MoE model to save computational complexity. It differs from the MoE model in that it simplifies the routing implementation, reduces communication, and requires a smaller batch size since a single token goes to a single model. According to recent research, Switch transformers outperform MoE transformers on a speed-quality basis and have a smaller computational footprint.
In conclusion, the author stresses that although GPT-4's performance is impressive, the model's architecture was not an innovative or groundbreaking design. Instead, it was an ingenious application of existing methods by engineers and researchers. The author also expresses some frustration with OpenAI's lack of transparency regarding GPT-4's design, asserting that the decision to keep the architecture secret was likely driven by a desire to stave off competition.
1 / 1
How is this related to active inference and Reinterpreting Free-Energy Principle?
1 / 1
ChatGPT
ChatGPT
The Free Energy Principle (FEP) is a theoretical framework developed by Karl Friston that attempts to explain how intelligent systems, such as the human brain, maintain their existence and adapt to their environment. It is a unifying theory for understanding cognition, action, and perception in biological systems, based on the minimization of free energy, which is a concept borrowed from thermodynamics and statistical physics.
Active Inference, on the other hand, is a process theory derived from the Free Energy Principle. It offers a comprehensive framework that treats perception and action as two sides of the same coin. In simple terms, active inference suggests that organisms act in ways that minimize the difference between their expectations and their sensory inputs. They are continuously updating their beliefs about the world and acting to minimize the surprise associated with these sensory inputs.
In the context of AI models such as GPT-4, the connection to these principles is not straightforward because these AI models are not inherently designed to minimize free energy or perform active inference. However, the notion of using multiple expert models within GPT-4 to address different parts of the problem space could be viewed as an indirect relation to these principles.
The ensemble of expert models in GPT-4 can be seen as analogous to an organism's different cognitive systems or subsystems, each specialized for different tasks and constantly updating their beliefs based on new data. This could be interpreted as an embodiment of the Free Energy Principle and active inference, where each sub-model within the ensemble acts to minimize its prediction error (analogous to free energy) for its specific task.
However, it's important to note that this is an analogy or reinterpretation. In the strict sense, these AI models are not based on the Free Energy Principle or active inference. Their design and optimization are driven by the specific tasks they are trained for, typically through methods like gradient descent on a defined loss function, which isn't directly related to the ideas of free energy or active inference.
Lastly, there are ongoing research efforts to incorporate ideas from the Free Energy Principle and active inference into AI and machine learning models, but this is a complex, challenging area that is still in the early stages of exploration as of my knowledge cutoff in September 2021.
1 / 1
AI���-���The Maker vs. The Operator, Comparing LLM vs. Active Inference AI
Image by Author
AI���-���The Maker vs. The Operator, Comparing LLM vs. Active Inference AI
Fecha de publicaci��n: 9 de may de 2023
Denise Holt
Denise Holt
Creator & Host - Spatial Web AI Podcast |���
Fecha de publicaci��n: 9 de may de 2023
 Seguir
VERSES AI is a cognitive computing company that has overcome the limitations of machine learning AI, by building a new kind of artificial intelligence based on a real-time world model described as:

���AI that grows in knowledge, perception and awareness through the evolving real-time data produced by all things, at all times, throughout our living, breathing, and ever-changing world."

This is Active Inference AI, an entirely new type of networked AI that is designed for Real-Time Operations, including things like managing the daily operations of a hospital, an airport, global supply chains, an entire smart city, global drone and autonomous vehicle traffic, and other real-world activities. This introduces a new era of artificial intelligence which enables us to streamline, optimize and automate every mission-critical, real-life function that we interact with every day.

No alt text provided for this image
Image by Author
The days of training AI on big data with probabilistic results will give way to an interconnected ���Internet of Everything��� that deploys Active Inference AI throughout the network; inherently secure and accurate because it takes any point of real-time data and makes it smart through an empowered ecosystem of interconnected AI Apps called Intelligent Agents. This networked system operates in tandem with humans, growing its intelligence in sync with humans and the world.

What makes a predictive machine learning model different from the Active Inference AI of the Spatial Web?
Deep Fakes of Intelligence ��� stochastic parrots.

No alt text provided for this image
Image by Author
A Machine Model displays superficial intelligence. It can only give answers with a guess that is accurate to the point of the answer having been included in its training data, otherwise it will make up an answer. It is all based on probability of accuracy, but never 100%. And even at that, it can still be wrong with a tendency to make things up, attempting to make it sound appropriate.

An appropriate output is very different from an accurate output.

Active Inference AI with the Spatial Web Protocol is accurate because it���s based on real-time, real life data that is continually updating as the changing details and context around any entity in any space unfolds over time.

Predictive machines are great as content generators, idea enhancers, and task execution. Active inference can make decisions incorporating real-time data. Active Inference can run the planet. These are two very different animals.

Generative and Transformer AI models have no ability for comprehension, awareness, or perception. They possess no capacity to reason or plan. They have no understanding of how the world works. Predictive pattern matching machines can fake it, given enough data that it models from, but they are merely interpolating and regurgitating the patterns they have recognized that are already in use and familiar to us.

A GPT will tell you a great story about your city, but it can���t control the traffic within your city in real-time because it does not look outward at the world around us. Instead, it looks inward to its historical memory which consists of billions of parameters and words from the past that were downloaded into it. If it tells you a story about New York, that narrative is based on the words and references that it has been exposed to, not what is happening in New York right this instant. And because it has no window into the actual real-time activities within New York itself, it can make tremendous errors which would be unacceptable for mission-critical applications like Smart Cities, or Banking, or Policing, or the myriad other real-world applications in which we need AI
1 / 1
ChatGPT
ChatGPT
The author, Denise Holt, offers a compelling comparison of traditional machine learning models, like GPT-4 (referred to as "LLM" or "Language Learning Models" in the text), and the newer Active Inference AI systems developed by VERSES AI. The comparison primarily revolves around two points:
The Source of Intelligence and Real-time Response:
Traditional models like GPT-4 are trained on vast amounts of data and learn to predict or generate outputs based on patterns and structures in this data. However, they are not designed to interact with or adapt to the real-time state of the world. On the other hand, Active Inference AI systems are designed to continuously ingest real-time data and adapt their responses accordingly. They are "aware" of the changing state of the world, enabling them to make decisions and take actions based on the most up-to-date information.
The Nature and Scope of Tasks:
GPT-4 and similar models excel at tasks like content generation and enhancement, which involve creating or modifying textual data. But they are not equipped to control real-world systems or processes. Active Inference AI systems are designed to manage real-world operations, like controlling traffic in a city or managing the logistics of a global supply chain. They are capable of making real-time decisions based on real-time data, which is crucial for these kinds of tasks.
The piece also explores the idea of a global "Internet of Everything" that is empowered by Active Inference AI. In this vision, every piece of data is continuously updated and made "smart" by a network of AI apps called Intelligent Agents. These agents can operate in collaboration with human users, growing in intelligence as they interact with the world and each other.
As Holt points out, the concept of Active Inference AI takes us beyond the realm of AI as a content generator or task executor. Instead, it positions AI as a real-time decision maker and manager, capable of running complex systems and processes in concert with human operators. This represents a significant step forward in the potential applications and impact of AI technology.
However, it's important to note that while the potential of Active Inference AI is significant, the practical implementation and deployment of such systems will involve significant technical and logistical challenges. It's an exciting area of research and development, but there is still much work to be done to realize the full potential of this technology.
1 / 1
Fluent vs. Factual
LLMs are well-versed because the statistics of fluency are easily obtained from the training data. Logic and accuracy are a much harder ask.

GPT-3, ChatGPT, LLaMA, Bing Chat, and GPT-4 are all autoregressive LLMs. Autoregressive generative model structure operates in a way that when structuring a language sequence, it produces one token after another, reflecting on the result of the previous token to determine what to produce next. (A token is a word or sub word.)

At each step of token production, there is a point of probability taking place for steering toward accuracy or inaccuracy. There will always be probability that the next token produced can take the model down an incorrect path.

Each token produced provides an opportunity to branch off into a unique response, while also producing a new opportunity to stray from the truth. This deviation plays out exponentially with each new fork that is taking cues from the previous token, analyzing it to determine its next move. Each prediction impacts every prediction thereafter. Without reasoning and understanding, these errors are likely to compound as the process feeds on those errors.

At no point is the machine able to ask itself if this string of text entries makes intellectual and reasonable sense.

This problem cannot be fixed with LLMs. There will always be an element of possibility for the model results to go haywire. This is where the AI hallucination factor comes in.

A model based on probability is unmanageable in a continuous environment because if/when it goes off track, there���s no way to rein it back in.

For AI to become factual, it would have to accurately predict every detail of the world.

Enter the Long-Awaited World Model
Spatial Web Protocol HSTP and HSML for the World Model and model predictive control.

VERSES AI is expanding the internet for networked intelligence.

No alt text provided for this image
There is a fundamental power within a connected world: collective intelligence, a hive mind.

This computable and distributed intelligence is what powers the AI of the future.

By building a new protocol as a public standard, and then giving it away free to the public, VERSES AI has enabled a frictionless network for scalability.

HSML is the programming language that computes context, enabling the AI���s perception to understand the real-time changing state of anything in the world.

HSTP, the Spatial Web Protocol, will recognize any person place or thing as a unique entity within this network, providing it with a unique ID, and acting as a gatekeeper for access, interaction, and transaction by and between all things.

Any thing inside of any space becomes a nested domain uniquely identifiable and programmable within a digital twin of the earth, producing a model for data normalization.

Contingencies and changing details and circumstances for all objects and situations can now be measured and computed, providing a basis for AI perception, affecting all entities and their interrelationships to each other.

Connecting the planet is a massive undertaking that can only be enacted by putting it in the hands of individuals, developers, and builders. For AI, this is the critical piece for scaling AI to AGI.

This is what VERSE AI has built.

So What Makes Active Inference So Accurate?
Active Inference AI is based on biological design ��� Embodied AI ��� with the ability to take action. This the core engine.

Active Inference is so accurate because it continually looks outward into the world, measuring the world, in real-time through a global network of sensors ��� IoT devices, cameras, robots, drones ��� anything that is connected within the Spatial Web ��� the Digital Twin network of the world. This mimics the way humans and animals make decisions. As we use our senses to SEE the world ���as it is��� ��� moment by moment ��� we can then more accurately estimate what might happen if we perform an action.

As a human, if we are walking down the street and see a reckless driver coming toward us, we recognize it, notice the erratic actions, infer what would happen if we stood in the way of the car, and we can make the decision to jump out of the way, and save ourselves. We do this because we are able to take in all of the information about the situation and the context involved. The car, the driver, the speed, the pattern of driving, where we stand in relation to the trajectory of the moving vehicle. Through our senses, we obtain awareness to the situation, and therefore can make decisions based on the perception feedback loop that is updating moment by moment as the car gets closer ��� to the point of understanding exactly how to take action ��� when to jump and in which direction to go.

In the Spatial Web, Active Inference AI can reach out and interact with the world through all the networked IoT sensors, machines, and the context of HSML informing the constantly changing details and characteristics of the interrelationships between all things. This creates a cybernetic feedback loop of Perception of the World, updating its model of the world, with belief of what it knows to be true; gaining understanding of the intricacies and inner workings of world so that it can make decisions, and take Action. The more this feedback loop plays out, the AI learns more about the world and the results of actions taken, (just as a child learns about its world as it grows and interacts with it), and the more accurate this AI becomes by further updating its understanding of the World.

Intelligent Agents with Agency
AIs vs. IAs

AIs are large, siloed machines with independent functions. IAs are intelligent agents with agency for interoperable behavior.

The Spatial Web creates an ecosystem of distributed intelligence with computational context equipping Intelligent Agents with the right kind of data: data that specifies the details, characteristics, and attributes about any thing in any space and how they interact and relate to each other.

This enables the Intelligent Agents to have agency to function through self-organization using belief updating (what it knows to be true at any given moment). It is a system of distributed cognition throughout a unified network containing multiple entities interacting intelligently with each other, communicating with each other, and sharing what they know to be true. This sort of data facilitated agency empowers these IAs to develop perception, awareness, and curiosity about their environment ��� the data surrounding all agents within the environment.

This enables curiosity about me and you.

According to VERSES AI Chief Scientist, Dr. Karl Friston, curiosity when referring to the Free Energy Principle is described as the resolution of uncertainty.

Dr. Friston describes curiosity this way, ���to be curious you have to imagine what would happen if I did that, and what would I know if I did that, but you���ll have to imagine it before it���s actually happened, which is the big bright line between the anthropomorphic kind of intelligence and the intelligence you find in the thermostat.���

A New Era of Networked Intelligence
VERSES AI has laid the foundation for a universal mind that is grounded in reality, as a digital twin of earth and anyything within it.

While Deep Learning/Machine Learning AI creates powerful content generating tools and task execution, it can���t run a city. These predictive machine model neural networks are incredible, but they won���t get to AGI without being incorporated into a world model of everything.

The AI of the Spatial Web can.

Dan Mapes, President and Founder of VERSES AI, says this, ���I think that ChatGPT is a miracle and is introducing everyone into the potential benefits of AI in their lives. All the variations of ChatGPT and LLMs in general are total miracles and are saving humanity millions of hours doing things ��� especially anything mundane. BUT ��� it���s more of a MAKER. Make me this, Code me this, Tell me this. What it is not good for is being an OPERATOR. Run my hospital, Run my airport, Run my City. For that, you need REAL-TIME data and you need to understand how the mind learns. For that, you need Active Inference (Active = Real Time Decision Making based on Real Time Data and a constantly updated World Model).���

Active Inference AI is not a Language Model ���generating words��� about the world that are based on a historical encyclopedia of knowledge it has been fed regarding the world. 

Active Inference is more like a biological organism that perceives and acts on our World by generating more accurate models, understandings, and beliefs about our World.

These ever more accurate World Models enable better decisions ��� a Smarter World. This is the true measure of intelligence.

No alt text provided for this image
Image by Author
No alt text provided for this image
Image by Author
No alt text provided for this image
Image by Author
No alt text provided for this image
Image by Author


You can learn more about the Spatial Web Protocol and Active Inference AI, by visiting the VERSES AI website: https://www.verses.ai and the Spatial Web Foundation: https://spatialwebfoundation.org.
1 / 1
ChatGPT
ChatGPT
This article, by Denise Holt, further dives into the comparison between Large Language Models (LLMs) such as GPT-3, ChatGPT, LLaMA, Bing Chat, and GPT-4, and Active Inference AI, like the system developed by VERSES AI.
The author points out that LLMs, being autoregressive generative models, operate in a sequence, where each token (a word or sub-word) is generated based on the previous one. This sequential generation carries an inherent probability of error, which can get exponentially amplified with each new token, potentially leading the model off track. The lack of reasoning and understanding in LLMs means these errors cannot be checked or corrected as they occur.
VERSES AI's Active Inference AI, in contrast, offers a way to continuously update a world model using real-time data. The company has built a Spatial Web Protocol (HSTP) and a programming language (HSML) that can compute context, identify unique entities, and handle interactions and transactions. The goal is to create a "hive mind" ��� a distributed, networked intelligence capable of understanding and reacting to real-world contexts and conditions.
The Active Inference AI operates similarly to how humans and animals make decisions, continuously observing and evaluating the world around them. For example, a person walking on the street who sees a reckless driver can quickly evaluate the situation ��� the car's speed, the driver's erratic behavior, their own position ��� and take action to avoid getting hit.
The system created by VERSES AI extends this capacity for real-time decision-making and action to AI. Using a vast network of IoT sensors and devices, the Active Inference AI can continuously update its understanding of the world and make decisions based on the most current data. This networked approach also facilitates the development of "Intelligent Agents," which are smaller AI units that can interact intelligently with each other and share information.
While LLMs like GPT-3 or GPT-4 are great for generating content and performing certain tasks, they can't manage real-time operations like Active Inference AI. According to Dan Mapes, President and Founder of VERSES AI, LLMs are "makers" ��� they can generate content or perform tasks ��� but they are not "operators" that can manage real-time systems. Active Inference AI, on the other hand, can act as an "operator," managing real-time systems based on constantly updated world data.
Ultimately, the author suggests that the next big step towards Artificial General Intelligence (AGI) will involve integrating systems like LLMs into a comprehensive world model, much like the one developed by VERSES AI. The ultimate goal is a smarter world, where AI systems can make better decisions based on accurate, up-to-date models of the world.
1 / 1
SPATIAL DOMAINS
We are used to thinking of web domain names as permanent addreses on the internet. 
We have these addresses to locate devices on the Internet, to navigate between pages on the web, or buildings via maps. At most, these require two dimensions. We exist and operate in the third dimension. We need digital addresses that can do the same.

Addresses
The space around us doesn���t have any universally acceptable and accessible ���address.��� Whether physical postal addresses or the digital addresses that allow us to email and navigate between websites, none of these have a meaningful relationship to each other, and so there is no method for integrating the physical and digital worlds.

Domains
A Domain Name is an identifier in the form of an alpha-numerical phrase that represents an address. A Spatial Domain, however, points to a 3D volumetric spatial address made of coordinates that can be registered across Distributed Ledgers.

Spatial Domain Registry
Similar to ICANN which manages the registration activities for web domain names, a Spatial Domain Registry enables people and organizations to register Spatial Domain names and have them validated. To accommodate duplicate names in the physical world, the Spatial Domain registry will also contain its physical address, including country, state, and city location and other profile information.

Hyperspatial Domains and the "real" physical world
A Spatial Web��� domain is a titled or credentialed n-dimensional space or location that confer the right to manage the policies of that Space. Spatial Domains are nested and must adhere to the laws of parent domains (Home > City > State > Federal) unless there are provisions to override them (e.g. US State Sovereignty). Spatial Domain Names can be real places (like ���Joe���s Cafe���, ���Roman Colosseum���) or virtual (like ���The Oasis��� or ���Hogwarts���).
1 / 1
ChatGPT
ChatGPT
The concept of "Spatial Domains" that you've introduced is a step toward integrating the physical and digital worlds by assigning three-dimensional addresses to both real and virtual spaces. This advancement goes beyond the two-dimensional addressing systems we use for locating devices on the Internet or navigating between web pages and locations on a map.
Spatial Domains provide a solution to the lack of universally acceptable and accessible addressing for the space around us. Regular domain names, whether they are for postal or digital purposes, do not have a meaningful relationship with each other, thus hindering the integration of the physical and digital worlds.
A Spatial Domain, on the other hand, is a three-dimensional volumetric spatial address comprised of coordinates. These can be registered across Distributed Ledgers, similar to how traditional web domain names are registered. This registration and validation process is managed by a Spatial Domain Registry, akin to how ICANN manages the registration of web domain names.
To ensure uniqueness and avoid confusion due to duplicate names, Spatial Domains also carry their physical address information, including country, state, and city location, along with other profile data.
A unique feature of Spatial Domains is that they can represent both real places (e.g., "Joe's Cafe" or "Roman Colosseum") and virtual locations (e.g., "The Oasis" or "Hogwarts"). They are also nested, meaning a smaller domain exists within a larger one, and must follow the rules of the parent domain, unless provisions allow for overriding them.
In essence, Spatial Domains are a means to merge our physical reality with the digital realm, allowing for more accurate, meaningful, and efficient navigation and interaction in both.
1 / 1
Summarize: The Emperor's New Markov Blankets.
Authors:
Bruineberg, Jelle1 (AUTHOR) jelle.bruineberg@mq.edu.au
Do����ga, Krzysztof2 (AUTHOR) krzysztof.dolega@rub.de
Dewhurst, Joe3 (AUTHOR) joseph.e.dewhurst@gmail.com
Baltieri, Manuel4 (AUTHOR) manuel.baltieri@riken.jp
Source:
Behavioral & Brain Sciences. 2022, Vol. 45, p1-76. 21p.
Document Type:
Article
Subject Terms:
*BLANKETS
*BAYESIAN analysis
*COMPUTATIONAL neuroscience
*BAYESIAN field theory
*EMPERORS
Author-Supplied Keywords:
active inference
Bayesian inference
free energy principle
Markov blankets
scientific realism
NAICS/Industry Codes:
442298 All other home furnishings stores
313230 Nonwoven Fabric Mills
423220 Home Furnishing Merchant Wholesalers
314120 Curtain and Linen Mills
414330 Linen, drapery and other textile furnishings merchant wholesalers
Abstract:
The free energy principle, an influential framework in computational neuroscience and theoretical neurobiology, starts from the assumption that living systems ensure adaptive exchanges with their environment by minimizing the objective function of variational free energy. Following this premise, it claims to deliver a promising integration of the life sciences. In recent work, Markov blankets, one of the central constructs of the free energy principle, have been applied to resolve debates central to philosophy (such as demarcating the boundaries of the mind). The aim of this paper is twofold. First, we trace the development of Markov blankets starting from their standard application in Bayesian networks, via variational inference, to their use in the literature on active inference. We then identify a persistent confusion in the literature between the formal use of Markov blankets as an epistemic tool for Bayesian inference, and their novel metaphysical use in the free energy framework to demarcate the physical boundary between an agent and its environment. Consequently, we propose to distinguish between "Pearl blankets" to refer to the original epistemic use of Markov blankets and "Friston blankets" to refer to the new metaphysical construct. Second, we use this distinction to critically assess claims resting on the application of Markov blankets to philosophical problems. We suggest that this literature would do well in differentiating between two different research programmes: "inference with a model" and "inference within a model." Only the latter is capable of doing metaphysical work with Markov blankets, but requires additional philosophical premises and cannot be justified by an appeal to the success of the mathematical framework alone.
1 / 1
ChatGPT
ChatGPT
"The Emperor's New Markov Blankets" is an academic article that discusses the Free Energy Principle (FEP) and the use of Markov blankets, a concept integral to the FEP, in computational neuroscience and theoretical neurobiology. The FEP assumes that living systems maintain adaptive interactions with their environment by minimizing variational free energy, a specific mathematical function.
The authors identify a common confusion in the scientific literature: the difference between the original use of Markov blankets for epistemic purposes in Bayesian inference (referred to as "Pearl blankets"), and their new application in the FEP to delineate the physical boundary between an agent and its environment ("Friston blankets").
The article aims to achieve two main objectives:
Track the evolution of Markov blankets from their standard application in Bayesian networks, via variational inference, to their usage in the active inference literature. The authors identify the recurrent confusion between the epistemic and metaphysical use of Markov blankets and propose the terminology of "Pearl blankets" and "Friston blankets" to distinguish between the two.
Use the distinction between Pearl and Friston blankets to critically evaluate claims based on the application of Markov blankets to philosophical problems. They argue that understanding this distinction helps to differentiate between two different research programs: "inference with a model" and "inference within a model." The authors argue that only the latter can perform metaphysical work with Markov blankets, but this requires additional philosophical premises and cannot be justified solely by the mathematical framework's success.
In conclusion, the article offers an in-depth analysis of the concept of Markov blankets within the context of the Free Energy Principle, providing a critical perspective on its application and interpretation in the scientific and philosophical literature.
1 / 1
Markov blankets as boundary conditions: Sweeping dirt under the rug still cleans the house.
Authors:
S��nchez-Ca��izares, Javier1 (AUTHOR) js.canizares@unav.es
Source:
Behavioral & Brain Sciences. 2022, Vol. 45, p1-76. 3p.
Document Type:
Article
Subject Terms:
*HOUSE cleaning
*BLANKETS
*RUGS
*INSTRUMENTALISTS
NAICS/Industry Codes:
414330 Linen, drapery and other textile furnishings merchant wholesalers
313230 Nonwoven Fabric Mills
423220 Home Furnishing Merchant Wholesalers
314120 Curtain and Linen Mills
442298 All other home furnishings stores
561722 Janitorial services (except window cleaning)
561720 Janitorial Services
314110 Carpet and Rug Mills
442210 Floor Covering Stores
Abstract:
Bruineberg et al. underestimate the ontological weight of Markov blankets as actual boundaries of systems and lean toward an instrumentalist understanding thereof. Yet Markov blankets need not be deemed mere tools. Determining their reality depends on the fundamental problem of distinguishing between system and environment in physics, which, in turn, demands a metaphysical bedrock backed by a realist stance on science
1 / 1
ChatGPT
ChatGPT
"Markov blankets as boundary conditions: Sweeping dirt under the rug still cleans the house" is an academic article by Javier S��nchez-Ca��izares. The author takes issue with Bruineberg et al.'s assessment of Markov blankets, a concept from statistics and machine learning that has gained attention in neuroscience and philosophy.
Bruineberg and colleagues, in their paper "The Emperor's New Markov Blankets," propose distinguishing between "Pearl blankets" (the original use of Markov blankets in Bayesian inference) and "Friston blankets" (their application in the Free Energy Principle to define the physical boundary between an agent and its environment). They suggest that Markov blankets' role in philosophical problems requires additional premises and can't solely be justified by the success of the mathematical framework.
S��nchez-Ca��izares, however, contends that Bruineberg et al. are underestimating the ontological significance of Markov blankets as actual boundaries of systems, leaning towards an instrumentalist understanding (seeing them as merely tools). He argues that deciding the reality of Markov blankets is intertwined with the fundamental challenge in physics of distinguishing between a system and its environment. This necessitates a metaphysical foundation that is supported by a realist view of science (that is, the view that scientific theories genuinely tell us what the world is like).
1 / 1
Markov blankets in the brain.
Authors:
Hip��lito, In��s1,2 (AUTHOR) ines.hipolito@hu-berlin.de
Ramstead, Maxwell J.D.2,3,4 (AUTHOR)
Convertino, Laura2,5 (AUTHOR)
Bhat, Anjali2 (AUTHOR)
Friston, Karl2 (AUTHOR)
Parr, Thomas2 (AUTHOR)
Source:
Neuroscience & Biobehavioral Reviews. Jun2021, Vol. 125, p88-97. 10p.
Document Type:
Article
Subject Terms:
*BLANKETS
*CAUSAL models
Author-Supplied Keywords:
Boundaries
Canonical microcircuit
Dynamic causal modelling
Markov blankets
NAICS/Industry Codes:
313230 Nonwoven Fabric Mills
314120 Curtain and Linen Mills
414330 Linen, drapery and other textile furnishings merchant wholesalers
423220 Home Furnishing Merchant Wholesalers
442298 All other home furnishings stores
Abstract:
��� We leverage the idea of 'Markov blanket' as a statistical boundary to provide an analysis of partitions in neuronal systems. ��� We show this partition is applicable to multiple scales, from single neurons, brain regions, and brain-wide networks. ��� Based on the canonical micro-circuitry, our treatment has practical applications for effective connectivity. ��� Our proposed partition highlights the limitations of 'modular' proposals considering a single level of description. Recent characterisations of self-organising systems depend upon the presence of a 'Markov blanket': a statistical boundary that mediates the interactions between the inside and outside of a system. We leverage this idea to provide an analysis of partitions in neuronal systems. This is applicable to brain architectures at multiple scales, enabling partitions into single neurons, brain regions, and brain-wide networks. This treatment is based upon the canonical micro-circuitry used in empirical studies of effective connectivity, so as to speak directly to practical applications. The notion of effective connectivity depends upon the dynamic coupling between functional units, whose form recapitulates that of a Markov blanket at each level of analysis. The nuance afforded by partitioning neural systems in this way highlights certain limitations of 'modular' perspectives of brain function that only consider a single level of description
1 / 1
ChatGPT
ChatGPT
"Markov blankets in the brain" is a scientific article written by In��s Hip��lito, Maxwell J.D. Ramstead, Laura Convertino, Anjali Bhat, Karl Friston, and Thomas Parr. The authors leverage the idea of a "Markov blanket" as a statistical boundary to analyze partitions in neuronal systems. This analysis can be applied across multiple scales, from individual neurons to brain regions and comprehensive brain networks.
The concept of a Markov blanket, which serves as a statistical boundary that mediates interactions between a system's interior and exterior, plays a vital role in characterizing self-organizing systems. This approach aligns with the canonical micro-circuitry used in empirical studies of effective connectivity, highlighting its practical applications.
The authors argue that the dynamic interplay between functional units echoes the structure of a Markov blanket at each level of analysis, indicating that understanding effective connectivity depends on this principle. They further suggest that their proposed partitioning method exposes certain limitations of 'modular' perspectives on brain function, which tend to focus on a single level of description.
1 / 1
Return of the math: Markov blankets, dynamical systems theory, and the bounds of mind.
Authors:
Colling, Lincoln John1 (AUTHOR) l.colling@sussex.ac.uk
Source:
Behavioral & Brain Sciences. 2022, Vol. 45, p1-76. 3p.
Document Type:
Article
Subject Terms:
*DYNAMICAL systems
*SYSTEMS theory
*BLANKETS
*MATHEMATICS
NAICS/Industry Codes:
423220 Home Furnishing Merchant Wholesalers
313230 Nonwoven Fabric Mills
414330 Linen, drapery and other textile furnishings merchant wholesalers
314120 Curtain and Linen Mills
442298 All other home furnishings stores
Abstract:
Bruineberg and colleagues highlight work using Markov blankets to demarcate the bounds of the mind. This echoes earlier attempts to demarcate the bounds of the mind from a dynamical systems perspective. Advocates of mechanistic explanation have challenged the dynamical approach to independently motivate the application of the formalism, a challenge that Markov blanket theorists must also meet
1 / 1
ChatGPT
ChatGPT
"Return of the math: Markov blankets, dynamical systems theory, and the bounds of mind" is an article by Lincoln John Colling. In the paper, Colling addresses the work of Bruineberg and colleagues, which employs the concept of Markov blankets to define the limits of the mind. This approach mirrors earlier efforts to set the boundaries of the mind from a dynamical systems perspective.
However, Colling highlights the challenges facing Markov blanket theorists that parallel those encountered by dynamical system theorists. These include the need to independently motivate the application of the formalism, a requirement put forth by proponents of mechanistic explanation. Thus, Colling implies that to effectively apply these complex mathematical and theoretical constructs to something as nebulous and multi-faceted as the mind, a solid justification for their use is needed.
1 / 1
Markov blankets and Bayesian territories.
Authors:
Beck, Jeff1 (AUTHOR) jeff.beck@duke.edu
Source:
Behavioral & Brain Sciences. 2022, Vol. 45, p1-76. 3p.
Document Type:
Article
Subject Terms:
*BLANKETS
*MAPS
NAICS/Industry Codes:
313230 Nonwoven Fabric Mills
423220 Home Furnishing Merchant Wholesalers
442298 All other home furnishings stores
314120 Curtain and Linen Mills
414330 Linen, drapery and other textile furnishings merchant wholesalers
424920 Book, Periodical, and Newspaper Merchant Wholesalers
323119 Other printing
Abstract:
Bruineberg et al. argue that one ought not confuse the map (model) for the territory (reality) and delineate a distinction between innocuous Pearl blankets and metaphysically laden Friston blankets. I argue that all we have are models, all knowledge is conditional, and that if there is a Pearl/Friston distinction, it is a matter of the domain of application: latents or observations. This suggests that, if anything, Friston blankets may inherit philosophical significance previously assigned to observations.
1 / 1
ChatGPT
ChatGPT
"Markov blankets and Bayesian territories" is an article written by Jeff Beck. In this paper, Beck comments on the work of Bruineberg and colleagues, who warn against conflating the map (or model) with the territory (or reality). They also distinguish between Pearl blankets, which are conceptually straightforward, and Friston blankets, which carry a heavier metaphysical load.
Beck, however, presents an alternate perspective: all that we possess are models, and all knowledge is contingent. He suggests that if there is a distinction between Pearl and Friston blankets, it is based on their domain of application, whether that be latents (hidden variables) or observations. Beck proposes that Friston blankets might take on the philosophical significance previously allocated to observations, subtly shifting how we consider the representation and interpretation of knowledge.
1 / 1
Life, mind, agency: Why Markov blankets fail the test of evolution.
Authors:
Veit, Walter1 (AUTHOR) wrwveit@gmail.com
Browning, Heather2 (AUTHOR) DrHeatherBrowning@gmail.com
Source:
Behavioral & Brain Sciences. 2022, Vol. 45, p1-76. 3p.
Document Type:
Article
Subject Terms:
*BLANKETS
*AMBITION
NAICS/Industry Codes:
314120 Curtain and Linen Mills
423220 Home Furnishing Merchant Wholesalers
313230 Nonwoven Fabric Mills
442298 All other home furnishings stores
414330 Linen, drapery and other textile furnishings merchant wholesalers
Abstract:
There has been much criticism of the idea that Friston's free-energy principle can unite the life and mind sciences. Here, we argue that perhaps the greatest problem for the totalizing ambitions of its proponents is a failure to recognize the importance of evolutionary dynamics and to provide a convincing adaptive story relating free-energy minimization to organismal fitness.
1 / 1
ChatGPT
ChatGPT
"Life, mind, agency: Why Markov blankets fail the test of evolution" is an article authored by Walter Veit and Heather Browning. The authors critique the free-energy principle developed by Friston, which aims to unify the sciences of life and mind. They argue that one of the most significant problems with this comprehensive approach is its neglect of evolutionary dynamics. The authors believe that there's a failure to provide a convincing narrative that links the minimization of free-energy to the fitness of organisms in terms of adaptation and survival. This issue undermines the all-encompassing ambitions of those promoting Friston's theory.
1 / 1
Markov blankets, information geometry and stochastic thermodynamics.
Authors:
Parr, Thomas1 thomas.parr.12@ucl.ac.uk
Da Costa, Lancelot1
Friston, Karl1
Source:
Philosophical Transactions of the Royal Society A: Mathematical, Physical & Engineering Sciences. 2/7/2020, Vol. 378 Issue 2164, p1-13. 13p.
Document Type:
Article
Subject Terms:
*STOCHASTIC geometry
*RANDOM dynamical systems
*BLANKETS
*THERMODYNAMICS
Author-Supplied Keywords:
Bayesian
information geometry
Markov blanket
thermodynamics
variational inference
NAICS/Industry Codes:
313230 Nonwoven Fabric Mills
314120 Curtain and Linen Mills
414330 Linen, drapery and other textile furnishings merchant wholesalers
423220 Home Furnishing Merchant Wholesalers
442298 All other home furnishings stores
Abstract:
This paper considers the relationship between thermodynamics, information and inference. In particular, it explores the thermodynamic concomitants of belief updating, under a variational (free energy) principle for self-organization. In brief, any (weakly mixing) random dynamical system that possesses a Markov blanket--i.e. a separation of internal and external states--is equipped with an information geometry. This means that internal states parametrize a probability density over external states. Furthermore, at non-equilibrium steady-state, the flow of internal states can be construed as a gradient flow on a quantity known in statistics as Bayesian model evidence. In short, there is a natural Bayesian mechanics for any system that possesses a Markov blanket. Crucially, this means that there is an explicit link between the inference performed by internal states and their energetics--as characterized by their stochastic thermodynamics.
1 / 1
ChatGPT
ChatGPT
"Markov blankets, information geometry and stochastic thermodynamics" is an article written by Thomas Parr, Lancelot Da Costa, and Karl Friston. The paper explores the relationship between thermodynamics, information, and inference. In particular, it investigates the thermodynamic concomitants of belief updating, based on a variational (free energy) principle for self-organization. The authors note that any random dynamical system that possesses a Markov blanket - a separation of internal and external states - has an inherent information geometry. This means that the internal states can define a probability density over external states. The authors argue that there's a clear link between the inference performed by internal states and their energetics, as characterized by their stochastic thermodynamics, which contributes to our understanding of the Bayesian mechanics of systems with a Markov blanket.
1 / 1
Markov blankets and the preformationist assumption.
Authors:
Dengs��, Mads1 (AUTHOR) madsdengsoe@gmail.com
Robertson, Ian1 (AUTHOR) ianrob@uow.edu.au
Constant, Axel2 (AUTHOR) axel.constant.pruvost@gmail.com
Source:
Behavioral & Brain Sciences. 2022, Vol. 45, p1-76. 2p.
Document Type:
Article
Subject Terms:
*BLANKETS
NAICS/Industry Codes:
423220 Home Furnishing Merchant Wholesalers
442298 All other home furnishings stores
314120 Curtain and Linen Mills
313230 Nonwoven Fabric Mills
414330 Linen, drapery and other textile furnishings merchant wholesalers
Abstract:
Bruineberg and colleagues argue that a realist interpretation of Markov blankets inadvertently relies upon unfounded assumptions. However, insofar as their diagnosis is accurate, their prescribed instrumentalism may ultimately prove insufficient as a complete remedy. Drawing upon a process-based perspective on living systems, we suggest a potential way to avoid some of the assumptions behind problems described by Bruineberg and colleagues.
1 / 1
ChatGPT
ChatGPT
In the article "Markov blankets and the preformationist assumption," authors Mads Dengs��, Ian Robertson, and Axel Constant comment on the work of Bruineberg and his colleagues on the realist interpretation of Markov blankets. They suggest that Bruineberg et al.'s work might rely on unproven assumptions. They also critique the instrumentalism proposed by Bruineberg and colleagues, indicating that it may not be a comprehensive solution. Instead, they propose a process-based perspective on living systems as a potential way to bypass some of the underlying assumptions identified as problematic by Bruineberg and colleagues.
1 / 1
Markov blankets do not demarcate the boundaries of the mind.
Authors:
Menary, Richard1 (AUTHOR) richard.menary@mq.edu.au
Gillett, Alexander J.1 (AUTHOR)
Source:
Behavioral & Brain Sciences. 2022, Vol. 45, p1-76. 2p.
Document Type:
Article
Subject Terms:
*BLANKETS
NAICS/Industry Codes:
423220 Home Furnishing Merchant Wholesalers
442298 All other home furnishings stores
314120 Curtain and Linen Mills
313230 Nonwoven Fabric Mills
414330 Linen, drapery and other textile furnishings merchant wholesalers
Abstract:
We agree with Bruineberg and colleagues' main claims. However, we urge for a more forceful critique by focusing on the extended mind debate. We argue that even once the Pearl and Friston versions of the Markov blanket have been untangled, that neither is sufficient for tackling and resolving the question of demarcating the boundaries of the mind.
1 / 1
ChatGPT
ChatGPT
In their paper "Markov blankets do not demarcate the boundaries of the mind," authors Richard Menary and Alexander J. Gillett concur with the main arguments put forth by Bruineberg and his colleagues. However, they suggest a stronger critique should be offered, particularly focusing on the extended mind debate. They contend that, even after differentiating between the Pearl and Friston interpretations of the Markov blanket concept, neither interpretation is adequate for addressing and settling the question concerning the boundaries of the mind.
1 / 1
Free-energy pragmatics: Markov blankets don't prescribe objective ontology, and that's okay.
Authors:
Hip��lito, In��s1 (AUTHOR) ines.hipolito@hu-berlin.de
van Es, Thomas2 (AUTHOR) thomas.vanes@uantwerpen.be
Source:
Behavioral & Brain Sciences. 2022, Vol. 45, p1-76. 2p.
Document Type:
Article
Subject Terms:
*BLANKETS
*ONTOLOGY
*PRAGMATICS
*INSTRUMENTALISTS
NAICS/Industry Codes:
423220 Home Furnishing Merchant Wholesalers
313230 Nonwoven Fabric Mills
414330 Linen, drapery and other textile furnishings merchant wholesalers
314120 Curtain and Linen Mills
442298 All other home furnishings stores
Abstract:
We target the ontological and epistemological ramifications of the proposed distinction between Friston and Pearl blankets. We emphasize the need for empirical testing next to computational modeling. A peculiar aspect of the free energy principle (FEP) is its purported support of radically opposed ontologies of the mind. In our view, the objective ontological aspiration itself should be rejected for a pragmatic instrumentalist view.
1 / 1
ChatGPT
ChatGPT
The article "Free-energy pragmatics: Markov blankets don't prescribe objective ontology, and that's okay" by In��s Hip��lito and Thomas van Es provides an analysis of the ontological and epistemological implications of the distinction between Friston and Pearl blankets. The authors highlight the need for empirical testing alongside computational modeling in their examination of this topic. They note a unique aspect of the free energy principle (FEP) is its alleged support of radically different ontologies of the mind. The authors argue that the aim for an objective ontology should be disregarded in favor of a pragmatic instrumentalist perspective.
1 / 1
Using Markov Blankets for Causal Structure Learning.
Authors:
Pellet, Jean-Philippe1 JEP@ZURICH.IBM.COM
Elisseeff, Andr��1 AEL@ZURICH.IBM.COM
Source:
Journal of Machine Learning Research. 7/1/2008, Vol. 9 Issue 7, p1295-1342. 48p. 14 Diagrams, 3 Charts, 13 Graphs.
Document Type:
Article
Subject Terms:
*Markov processes
*Artificial intelligence
*Algorithms
Machine learning
Data distribution
Author-Supplied Keywords:
causal structure learning
feature selection
Markov blanket
partial correlation
statistical test of conditional independence
Abstract:
We show how a generic feature-selection algorithm returning strongly relevant variables can be turned into a causal structure-learning algorithm. We prove this under the Faithfulness assumption for the data distribution. In a causal graph, the strongly relevant variables for a node X are its parents, children, and children's parents (or spouses), also known as the Markov blanket of X. Identifying the spouses leads to the detection of the V-structure patterns and thus to causal orientations. Repeating the task for all variables yields a valid partially oriented causal graph. We first show an efficient way to identify the spouse links. We then perform several experiments in the continuous domain using the Recursive Feature Elimination feature-selection algorithm with Support Vector Regression and empirically verify the intuition of this direct (but computationally expensive) approach. Within the same framework, we then devise a fast and consistent algorithm, Total Conditioning (TC), and a variant, TCbw, with an explicit backward feature-selection heuristics, for Gaussian data. After running a series of comparative experiments on five artificial networks, we argue that Markov blanket algorithms such as TC/TCbw or Grow-Shrink scale better than the reference PC algorithm and provides higher structural accuracy.
1 / 1
ChatGPT
ChatGPT
The article "Using Markov Blankets for Causal Structure Learning" by Jean-Philippe Pellet and Andr�� Elisseeff explores how a feature-selection algorithm can be converted into a causal structure-learning algorithm. This is demonstrated under the Faithfulness assumption for the data distribution.
In a causal graph, the variables that are strongly relevant for a node X include its parents, children, and children's parents (or spouses), also known as the Markov blanket of X. Identifying the spouses can lead to the detection of V-structure patterns, and thus to causal orientations. Applying this task to all variables results in a partially oriented causal graph.
The authors propose an efficient way to identify spouse links and also present a new, fast, and consistent algorithm, Total Conditioning (TC), along with a variant, TCbw, which features an explicit backward feature-selection heuristics for Gaussian data.
After conducting a series of comparative experiments on five artificial networks, the authors argue that Markov blanket algorithms like TC/TCbw or Grow-Shrink scale better than the reference PC algorithm and offer higher structural accuracy.
1 / 1
On Markov blankets and hierarchical self-organisation.
Authors:
Palacios, Ensor Rafael1 (AUTHOR) ensorrafael.palacios@bristol.ac.uk
Razi, Adeel1,2,3 (AUTHOR)
Parr, Thomas1 (AUTHOR)
Kirchhoff, Michael4 (AUTHOR)
Friston, Karl1 (AUTHOR)
Source:
Journal of Theoretical Biology. Feb2020, Vol. 486, pN.PAG-N.PAG. 1p.
Document Type:
Article
Subject Terms:
*BLANKETS
*BIOLOGICAL systems
*ORGANELLES
*VARIATIONAL principles
*EFFECT of human beings on climate change
Author-Supplied Keywords:
Active inference
Dynamical systems
Free energy
Markov blanket
Self-organisation
NAICS/Industry Codes:
442298 All other home furnishings stores
414330 Linen, drapery and other textile furnishings merchant wholesalers
423220 Home Furnishing Merchant Wholesalers
313230 Nonwoven Fabric Mills
314120 Curtain and Linen Mills
Abstract:
��� Computational treatment of biological self-organisation. ��� Biological self-organisation requires emergence of boundaries, namely Markov blankets. ��� Hierarchical self-organisation entails emergence of Markov blankets at multiple scale. Biological self-organisation can be regarded as a process of spontaneous pattern formation; namely, the emergence of structures that distinguish themselves from their environment. This process can occur at nested spatial scales: from the microscopic (e.g., the emergence of cells) to the macroscopic (e.g. the emergence of organisms). In this paper, we pursue the idea that Markov blankets ��� that separate the internal states of a structure from external states ��� can self-assemble at successively higher levels of organisation. Using simulations, based on the principle of variational free energy minimisation, we show that hierarchical self-organisation emerges when the microscopic elements of an ensemble have prior (e.g., genetic) beliefs that they participate in a macroscopic Markov blanket: i.e., they can only influence ��� or be influenced by ��� a subset of other elements. Furthermore, the emergent structures look very much like those found in nature (e.g., cells or organelles), when influences are mediated by short range signalling. These simulations are offered as a proof of concept that hierarchical self-organisation of Markov blankets (into Markov blankets) can explain the self-evidencing, autopoietic behaviour of biological systems.
1 / 1
ChatGPT
ChatGPT
The article "On Markov blankets and hierarchical self-organisation" by Ensor Rafael Palacios, Adeel Razi, Thomas Parr, Michael Kirchhoff, and Karl Friston discusses computational treatment of biological self-organisation.
The authors assert that biological self-organisation can be understood as a process of spontaneous pattern formation, leading to the emergence of structures that distinguish themselves from their environment. This process can occur at various nested spatial scales, ranging from the microscopic (like the emergence of cells) to the macroscopic (such as the emergence of organisms).
The paper explores the concept that Markov blankets, which separate the internal states of a structure from external states, can self-assemble at successively higher levels of organisation. The simulations, based on the principle of variational free energy minimisation, show that hierarchical self-organisation emerges when the microscopic elements of an ensemble have prior beliefs (for instance, genetic) that they participate in a macroscopic Markov blanket, implying that they can only influence or be influenced by a subset of other elements.
The emergent structures closely resemble those found in nature (e.g., cells or organelles), especially when influences are mediated by short range signalling. These simulations are presented as a proof of concept that hierarchical self-organisation of Markov blankets can explain the self-evidencing, autopoietic behaviour of biological systems.
1 / 1
A list of all the topics we have discussed so far.
1 / 1
ChatGPT
ChatGPT
So far, we have discussed the following topics:
Introduction and explanation of Markov blankets: A theoretical concept from the field of statistics and machine learning, which has found significant application in complex system theories, neuroscience, and artificial intelligence. We discussed what a Markov blanket is and how it's applied in different domains.
The role and application of Markov blankets in neuroscience: We discussed how Markov blankets are used to model brain activity, and how they can contribute to understanding the brain's functioning from a computational perspective.
The connection between Markov blankets and the concept of free energy in the context of neurobiological processes: We explored how the free-energy principle (FEP) uses the concept of Markov blankets to model the brain.
The debate around Markov blankets in demarcating the bounds of the mind: We reviewed several academic articles debating the efficacy of Markov blankets in determining the boundaries of the mind.
Use of Markov blankets in causal structure learning: We discussed an article on the application of Markov blankets for causal structure learning in the field of machine learning.
Exploration of Markov blankets in relation to biological self-organisation: We discussed how Markov blankets can contribute to understanding biological self-organisation across multiple scales, from cells to organisms.
Examination of academic perspectives on the implications of Markov blankets for ontological and epistemological theories.
Discussions on the critiques of the free-energy principle and Markov blankets' role in unifying life and mind sciences.
Each of these topics represents a different perspective on the application and interpretation of Markov blankets in various fields, including neuroscience, machine learning, and philosophy of mind.
1 / 1
h e recent evolution of NLP is marked by four signif i cant changes, corre- 
sponding to four signif i cant publications. h e i rst paper, published one year 
afterHinton���sgreatdemonstration,was���Eff i cientEstimationofWordRepre- 
sentationsinVectorSpace���(Mikolovetal.2013).WrittenbyateamfromGoogle 
���Jeff Dean is one of the co-authors ���the paper proposes a group of language 
models called Word2vec, which aims to reconstruct the linguistic context in 
which words are used. Word2Vec, like most machine learning technologies, 
Jonathan Roberge & Tom Lebrun: Parrots All the Way Down43 
relies heavily on the principle of regression, a method of statistical analysis 
that allows one variable to be placed in relation to its correlations with oth- 
ers. Roughly summarized, the technology involves locating the variable ��� the 
���meaning������of a word in relation to the variables ���the���meanings������of other 
wordsaroundit.Asitsnamesuggests,Word2Vecaimstotransformwordsinto 
vectors,i.e.,tomodeltheinformationtheycontainusingalgorithms.Inprac- 
tice, Word2Vec ���vectorizes��� words using two distinct and complementary ar- 
chitectures. One, called CBOW (Continuous Bag of Words), seeks to predict 
a word according to the i ve words to its right and the i ve words to its left. 
h eother,calledSkip-gram,doesexactlytheoppositeandseekstopredictthe 
words in the context according to a given word.T h e logic is always predictive: 
the model must be able to assign the ���right��� vector to each word. Despite its 
successintheearly2010s,Word2Vecisseverelylimited.Inparticular,thelan- 
guage model assigns only one meaning per word and only vectorizes individ- 
ual words, so that the meaning of even a relatively simple sentence continues 
toeludeit(Horn2017;Cusin-Berche2003).Wewillreturntothispointlater. 
Toaddresstheselimitations,VinyalsandLe���alsofromGoogle���published 
apapershortlyafterwardsentitled���ANeuralConversationalModel���(2015).T h is 
proposed,quite simply,to apply a sequential approach to Word2Vec to model 
the meaning of a text by linking certain sequences with others ��� thus form- 
ingalongeror���networked���formoftextmapping(Sutskever/Vinyals/Le2014). 
Withthisapproach,modelingcannowbeappliedtolargersequences,includ- 
ing sentences: the sentences preceding and following the target sentence are 
thus also taken into account and the model allows for a minimum of contex- 
tualconsideration.
1 / 1
ChatGPT
ChatGPT
The passage you provided discusses the evolution of Natural Language Processing (NLP) and highlights four significant changes that have occurred. However, it only goes into detail about two of them.
The first major change is the development of Word2Vec models, as discussed in the paper "Efficient Estimation of Word Representations in Vector Space" by Mikolov et al. in 2013. This model, developed by a team from Google, aims to recreate the linguistic context in which words are used. Word2Vec employs a regression analysis method to relate the "meaning" of a word with its surrounding words. It involves turning words into vectors, meaning it represents the information contained in a word using algorithms. Word2Vec uses two architectures: CBOW (Continuous Bag of Words), which predicts a word based on the five words to its left and right, and Skip-gram, which predicts the surrounding context given a specific word. However, the model has limitations. It assigns only one meaning per word and only vectorizes individual words, which means it can't fully understand the meaning of even a simple sentence.
The second major change addressed these limitations. Vinyals and Le, also from Google, proposed a sequential approach to Word2Vec in their paper "A Neural Conversational Model" in 2015. This method models the meaning of a text by connecting certain sequences, enabling modeling of larger sequences, including sentences. This approach takes into account the sentences preceding and following the target sentence, allowing for a minimum of contextual consideration.
The passage hints at two more significant changes in NLP but doesn't go into detail. These could potentially involve advancements such as transformer models, the advent of BERT, or other significant developments in NLP.
1 / 1
Despite this progress, Word2Vec-type systems are still based on the ap- 
proach where a word can only have one meaning. It is this limitation that the 
article���Deep contextualized word representations���(Peters et al.2018) aims to 
overcome. h e authors propose a new architecture called Embeddings from 
LanguageModels,orELMo,withinwhichthemodelcannowrecognizethedy- 
namic���moving,situational���natureofwordmeaning.Inpractice,eachword 
isassignedacoeff i cientor���weight���accordingtoitsinfluenceinthesentence.A 
wordlike���bow���cannowhavedifferentmeaningsdependingonacertaincon- 
text ��� ���I broke my violin bow��� and ���I am sitting at the ship���s bow.��� Above all, 
ELMo makes it possible for the i rst time to consider modeling that does not 
learnfromthetextinapurelyorderlyway,byofferinga���reading���inthreedif- 
ferent ways: i rst from left to right ��� from beginning to end; then in reverse 
��� from end to beginning; and i nally by combining the vectorized meanings 
44Embedded Models of Meaning 
of both types of analysis. Also, ELMo marks the real beginning of pre-trained 
models, allowing users to avoid having to train their models from scratch on 
huge data sets ���an extremely expensive practice,if only in terms of time and 
computingpower.2 
Finally,thepaper���Attentionisallyouneed���(Vaswanietal.2017)marksthe 
momentwhentheTransformerarchitecturevirtuallysealsthef i eld���sfate.Pre- 
vioussequentialmodelshaddiff i cultyretaininginformationaboutthepriori- 
tizationoftermsamongthemselves:totakethepreviousexample,information 
inasimplesentence������Ibrokemyviolinbow���,���Iwassittingattheship���sbow��� 
��� was diff i cult to retain in longer sequences ��� ���then the bow was splashed���. 
h e Transformer architecture moves away from this approach and its many 
problems in terms of memory, computational speed, word position, etc., by 
proposingtoidentifythecontextthatgivesmeaningtowords,whicharethen 
processedinparallel.T h isinvolvestheuseofbothanencoderandadecoder��� 
andindeedmanyofthemonmultiplelevelsactingandproducingfeedbackin 
a cybernetic manner.T h e encodertransformsinformationinto codebygiving 
acalculatedvaluetoaword;adecoderdoesexactlytheopposite,transforming 
codeintoinformationby���calculating���awordfromavalue.
1 / 1
ChatGPT
ChatGPT
The passage continues to elaborate on the subsequent advancements in Natural Language Processing (NLP):
The third major change was the development of ELMo (Embeddings from Language Models), proposed in the paper "Deep contextualized word representations" by Peters et al. in 2018. ELMo overcomes the limitation of Word2Vec and its ilk, where a word can only have one meaning. ELMo acknowledges the dynamic nature of word meanings, which can change depending on the context. Every word in a sentence is assigned a coefficient or "weight" based on its influence in that sentence. ELMo also introduced a method of analyzing the text in three ways: from left to right (beginning to end), in reverse (from end to beginning), and by combining the vectorized meanings of both types of analysis. It marked the real advent of pre-trained models, saving users from having to train their models from scratch on vast datasets.
The fourth notable change came with the introduction of the Transformer architecture, as discussed in the paper "Attention is all you need" by Vaswani et al. in 2017. Transformer models addressed the limitations of previous sequential models, which had difficulties retaining information about the prioritization of terms among themselves, particularly in longer sequences. Transformers step away from this approach and resolve many memory, computational speed, and word position issues by identifying the context that gives meaning to words, which are then processed in parallel. They utilize an encoder, which turns information into code by assigning a calculated value to a word, and a decoder, which transforms code into information by "calculating" a word from a value. These models often employ multiple levels of encoders and decoders that act and provide feedback in a cybernetic manner.
These four developments represent key milestones in the evolution of NLP, progressively improving the ability of algorithms to understand and generate human-like text.
1 / 1
h epointtokeepinmindhereisthatsucharchitecturesarebasedonneu- 
ral networks and on the ���deep learning��� made famous since Hinton���s demon- 
strationof2012,andinwhichlayersandlayersofencodersandlayersandlay- 
ers of decoders can be arranged without too many limits other than techni- 
calones.Aboveall,thetrulyinnovativecharacteroftheTransformerarchitec- 
ture lies in the attention mechanism implemented. h e idea is to calculate a 
���weighted matrix product��� ��� in other words, a matrix score that determines 
thelevelofattentionthatawordshouldhavetowardsotherwords;somemight 
alsospeak,moresimply,ofsituationaldependency.Anencodercanthuscom- 
pute several ���attention heads��� that work in a bidirectional way: an attention 
weight is computed as input and produces an output vector. h e major ad- 
vantage of this in-depth bidirectionality is that it allows the information to be 
2Unlike the image recognition i eld ��� where anyone could download pre-trained face 
recognition models from ImageNet, for example ��� the i eld of NLP appeared before 
ELMo to be a unif i ed environment, in which each research group or company had to 
start from scratch, with its own data and available computing power. Drawing on the 
example of image recognition, different types of pre-trained models emerged at the 
sametimeasELMo,suchasULMFitorthef i rstOpenAITransformersystem.SeeRuder 
2018. 
Jonathan Roberge & Tom Lebrun: Parrots All the Way Down45 
processedinparallelbythedifferentattentionheads,andthereforebythedif- 
ferent encoder layers. h is results in considerably reduced training times for 
languagemodelscomparedwithsequentialapproachessuchasWord2Vec. 
It is thus these new attention mechanisms specif i c to Transformer archi- 
tectures that are at the source of the current successes of language models, 
in particular Google���s BERT and OPEN AI���s GPT-3, as spearheads of the on- 
going battle waged by the GAFAM (Google,Amazon,Facebook and Microsoft) 
in theirquestforthemasteryof artif i cialintelligence(T h ibout2019;Horowitz 
2018).BERT is still a relatively small model compared to GPT-3,as it has been 
pre-trained on about 3.3 billion words and has 345 million parameters (Devlin 
et al. 2018). Its main objective is to end formalized keyword searches, a goal 
thatmayseemtrivialatf i rstbutiscentraltothecompany���smissionstatement 
��� ���to organize the world���s information to make it universally accessible and 
useful���. To achieve this, Google must enable its users to express themselves 
in the most natural, user-friendly and dialogical way possible.3BERT tries to 
achievesthisobjectivebyfocusingontheencoderpartofthearchitecture,the 
partthattransformsinformation,thewrittenorspokenrequest,butalsotexts 
tobetranslated,forexample,intocodeandvectorastocapturetheircontours: 
whodoeswhat,where,etc.BERT,inotherwords,andaboveall,���understands��� in the sense of extracting the relevant elements as rendered in more encom- 
passing sets. Its Transformer architecture is thus very flexible and functions 
as an interface between the natural input language (the query) and the output 
(theresult).ItshouldalsobenotedthatBERTisopen-source,whichispartofa 
corporate strategy of value creation quite specif i c to Google,4to which we will 
returninthelastsection. 
3Prabhakar Raghavan, vice-president of Google, explains that the ultimate goal is to 
responddirectlyandintelligentlytousers���needs:���Let���ssayyouareplanningtogohiking 
on Mount Fuji [���] Do my hiking boots suff i ce? Today, what you do is you transcribe it 
into hours of interaction with Google [���] Wouldn���t it be a lot better if you could [���] let 
Google i gure this out and address the need behind your query? [���] I want to be able 
togettoapointwhereyoucantakeapictureofthosehikingbootsandask,���Canthese 
be used to hike Mount Fuji?������; see Levy 2021. 
4���With this release, anyone in the world can train their own state-of-the-art question 
answeringsystem(oravarietyofothermodels)inabout30minutesonasingleCloud 
TPU, or in a few hours using a single GPU��� (Nayak 2019). See also Devlin and Chang 
2018. On Google���s open-source strategy (as opposed to Microsoft���s, in particular), see 
Janakiram 2017. 
46Embedded Models of Meaning 
GPT-3isatthetimeofwritingthemostpowerfullanguagemodel,trained 
on around 570 gigabytes of data and composed of 175 billion parameters 
(Brown et al. 2020). GPT-3 explicitly aims to generate text, according to its 
creators.UnlikeBERT,therefore,itfavorsthedecoderpartofitsarchitecture, 
the part that more precisely allows code to be transformed into information, 
i.e.,inferringmissingwords,completingsentences,etc.Farfrombeingopen- 
source, GPT-3 is currently marketed via its Application Programming Inter- 
face (API), a choice which is obviously part of a corporate strategy that aims 
to control the economic ecosystem on which many future companies will be 
based. In a blog post, OpenAI reported in March 2021 that more than 300 
companies were making use of this API, a number that keeps growing. For 
instance, applications already available include CopyAI, which can generate 
slogans and product descriptions for companies, and Fable, which can model 
charactersfromnovelsandtalktothem(Scott2020).5
1 / 1
ChatGPT
ChatGPT
The passage you've provided continues the discussion on the evolution of NLP, focusing on the role of attention mechanisms in Transformer architectures and detailing the impacts of two prominent models: BERT from Google and GPT-3 from OpenAI.
The major innovation of the Transformer architecture lies in its attention mechanism. This attention mechanism calculates a "weighted matrix product" which determines the level of attention that a word should give to other words in the sentence, also understood as a situational dependency. The Transformers compute several "attention heads" that work bidirectionally, allowing for parallel processing of information by different attention heads, hence considerably reducing training times for language models compared to sequential models like Word2Vec.
The use of these new attention mechanisms specific to Transformer architectures is the foundation for the recent successes of language models, including:
Google's BERT (Bidirectional Encoder Representations from Transformers) was pre-trained on about 3.3 billion words and has 345 million parameters. BERT's primary objective is to end formalized keyword searches and enable users to express themselves in the most natural, user-friendly, and dialogical way possible. BERT focuses on the encoder part of the architecture, which transforms information into code. The Transformer architecture of BERT is highly flexible and acts as an interface between the natural input language and the output. Importantly, BERT is open-source, which is part of Google's specific corporate strategy of value creation.
OpenAI's GPT-3 (Generative Pretrained Transformer 3) is one of the most powerful language models as of the time of writing, trained on around 570 gigabytes of data and composed of 175 billion parameters. Unlike BERT, GPT-3 aims to generate text and emphasizes the decoder part of its architecture, which transforms code into information. Unlike BERT, GPT-3 is not open-source. Instead, it's marketed via its Application Programming Interface (API), aligning with a corporate strategy to control the economic ecosystem on which many future companies will be based. As of March 2021, over 300 companies were reportedly using this API.
These advancements have significantly shaped the current state of NLP, allowing for more nuanced understanding and generation of human-like text.
1 / 1
That was true at the time of writing however since the paper, gpt4 has been released: This article discusses the architecture of OpenAI's GPT-4 language model. In it, the author reveals that GPT-4 is not a monolithic dense model like its predecessors (GPT-3 and GPT-3.5), but instead consists of an ensemble of eight smaller models. Each of these models is purported to contain 220 billion parameters.

This type of design is known as a "mixture of experts" (MoE) model paradigm. It's a well-established methodology in which tasks are divided into subtasks and then assigned to "experts" for solving. The individual models or "experts" can be trained on smaller, more manageable problem types. A meta-model, referred to as the "gating model," learns when to use which model to predict a specific task, effectively acting as a traffic cop.
1 / 1
ChatGPT
ChatGPT
The GPT-4 language model developed by OpenAI introduces a significant change in the architecture of large language models. This new model operates based on a "mixture of experts" (MoE) paradigm, which contrasts with the monolithic dense model structure used in prior iterations such as GPT-3 and GPT-3.5.
Here are the main points about GPT-4:
GPT-4 is not a singular, dense model but comprises an ensemble of eight smaller models. Each of these models reportedly has 220 billion parameters.
The design of GPT-4 is based on the "mixture of experts" (MoE) model paradigm. This methodology involves dividing tasks into subtasks and assigning them to specialized "experts" to solve.
The individual models or "experts" in the GPT-4 structure can focus on smaller, more specific problem types, making the overall problem more manageable.
GPT-4 introduces a "gating model," a meta-model that learns which model to use for predicting specific tasks, essentially serving as a controller or traffic cop.
The shift to an MoE paradigm in GPT-4 demonstrates an innovative approach to handling complex tasks by dividing them among multiple specialized models. This new structure allows for more efficient processing and may provide improved performance in certain applications of language modeling.
1 / 1
Connections to the discussion so far
1 / 1
ChatGPT
ChatGPT
Throughout this discussion, we've covered a range of topics relating to the evolution of natural language processing, from the advent of Word2Vec to Transformer architectures and the rise of BERT and GPT-3. The key themes that can be observed in our conversation are the constant evolution and improvement of models, the ability of these models to understand and generate human language, and their increasing size and complexity.
GPT-4, as the latest in the line of language models by OpenAI, represents a significant evolution in this field. It incorporates the "mixture of experts" (MoE) model paradigm, contrasting with the monolithic structure of earlier models. This new design is reflective of the ongoing trend of increasingly sophisticated and capable models, and the shift towards models that are more efficient and effective at understanding context and producing relevant outputs.
Let's connect the GPT-4 discussion to our earlier points:
NLP Evolution
: Just as Word2Vec, ELMo, Transformer, BERT, and GPT-3 marked significant steps in the evolution of NLP, so does GPT-4. The "mixture of experts" approach is a new architecture that reflects the continuous advancement in NLP.
Understanding and Generating Human Language
: GPT-4, like its predecessors, is designed to understand and generate human-like text. However, the MoE model allows it to handle more complex tasks and understand context in a more nuanced way, making its output even more human-like.
Size and Complexity
: We discussed the increasing size and complexity of models, with GPT-3 being a notable leap in scale. GPT-4 continues this trend, boasting an ensemble of eight models, each with 220 billion parameters. However, despite the increased complexity, the MoE approach helps manage this complexity more effectively.
Relevance to Corporations and Technological Advancement
: The transition from GPT-3 to GPT-4 shows how technological advancement is relentless. The open-source nature of some models like BERT and the API-based commercialization of others like GPT-3 has led to a wide array of applications, with the evolution to GPT-4 promising even more possibilities. This reflects the ongoing competition in the AI industry, particularly among major corporations like those in GAFAM.
1 / 1
Because they are socio-technical assemblages, it goes without saying that 
these models struggle to be perfect or even to live up to the rhetoric legit- 
imizing their use and, more generally, all that is the magic of AI (Roberge 
2020; Elish/Boyd 2018). h e fact is that all is not well in the best of all NLP 
worlds, and that upon closer inspection, its deployment is more a matter of 
���garbagein,garbageout������theso-calledGIGOprinciple,asironicallyreferred 
to by scientists working in the i eld (Kilkenny/Robinson 2018). With regard to 
input,itshouldbeseenthatwhilelanguagecanapparentlybecomputationally 
modelled,the Transformer architecture can only achieve this from a resource 
that is itself a social construct: the database. h is dependence of language 
models on their training sources is quite widely discussed (Hutchinson et al. 
2020; Roberge 2018), as any given Transformer architecture remains based 
on the principle of regression outlined earlier,which aims to locate a variable 
(a word) according to its correlations with other variables (the other words 
in the database). h is simple mathematical procedure thus constructs an 
approach to language based on the principle of ���winner takes all���. Put differ- 
ently, the language model promotes the most statistically probable language 
constructs according to the data set on which it is trained. Also, the choice of 
texts on which these language models are developed participates in a certain 
representation of the world, whose symbolic, if not ideological, dimension is 
often only revealed once the models have been applied ��� through the racist, misogynistic or other biases that result from them. h is is one of the most 
strikingobservationsinthetextthatledtoGebru���sdismissalfromGoogle: 
GPT-2���s training data is sourced by scraping outbound links from Reddit, 
and Pew Internet Research���s 2016 survey reveals 67% of Reddit users in the 
United States are men, and 64% between ages 18 and 29. Similarly, recent 
surveys of Wikipedians i nd that only 8���15% are women or girls (Bender et 
al. 2021: 4). 
What is thus a problem on the input side becomes a problem on the output 
side, with the highest number of potential and proven slippages. One of the 
most feared applications in this respect is what is usually referred to as as- 
troturf i ng, in which a plethora of micro-speeches is automatically generated 
as if to simulate a mass movement accrediting such organizations,ideas,etc. 
(Kovicetal.2018;Zhang/Carpenter/Ko2013).Indeed,theUSNationalIntelli- 
genceCouncil���slatestreportGlobalTrends2040listsAI-poweredpropagandaas 
oneofitstopteneconomicandpoliticalsecurityconcerns(2021).6Inthiscase, 
fakeprof i leswithautomaticallygeneratedcontentalreadypopulatesocialnet- 
worksthatareusedbybillionsofpeopleonadailybasisandarethereforeprone 
to misinformation,manipulation and the promotion of hate speech (Keller et 
al.2020).T h erearealsootherexamplesofbiasesembeddedinBERTandGPT-3 
that are related to the probabilistic ideology of these models. AI Dungeon, a 
computerizedversionofDungeons&DragonspoweredbyGPT-3,madenews 
inApril2021for,amongotherthings,allowingthegenerationofnarrativesfea- 
turingsexualrelationsinvolvingchildren���aphenomenonthatwasobviously 
not foreseen by OpenAI (Simonite 2021a). In the follow-up to their Algorithms 
of Oppression: How Search Engines Reinforce Racism, Noble and others have also 
extensively exposed the biases that have always been built into Google envi- 
ronments,bothinthevariouslanguagemodelsthatprecededBERTandinthe 
waythatBERTisnowfarfromsolvingthesediff i culties(Noble2018;Bhardwaj, 
MajumderandPoria2021;Hutchinsonetal.2020).���StochasticParrots���ispart 
ofthisbroadercritiqueofNLP: 
The size of data available on the web has enabled deep learning models 
to achieve high accuracy on specif i c benchmarks in NLP [���]. However, the 
6In particular, the report explains that ���[b]oth states and nonstate actors almost cer- 
tainly will be able to use these tools to influence populations, including by ratcheting 
up cognitive manipulation and societal polarization to shape how people receive, in- 
terpret, and act on information��� (National Intelligence Council 2021: 97). trainingdatahasbeenshowntohaveproblematiccharacteristics[���]result- 
ing in models that encode stereotypical and derogatory associations along 
gender, race, ethnicity, and disability status (Bender et al. 2021: 4). 
Despiteitsdeleteriousconsequencesfortheirauthors���Gebruinparticular��� 
���StochasticParrots���isnotparticularlyinnovative.AsWiredreports,���thepaper 
wasnotintendedtobeabombshell���.7Itmerelyexploresthreemajorissuesre- 
lated to the ever-growing size of language models: i rst, their environmental 
cost; second,their formal and rigid nature,which allows biases both to struc- 
turethemselvesandoftentogounnoticed;andthird,solutionsthatmightmit- 
igatetherisksassociatedwiththeiruse. 
In the sections that make up the core of the overall argument, the paper 
reminds us that the models are trained only on the form of the language and 
notonitssubstance.TouseSaussureanterms,amodelcanonlyevermasterthe 
signif i er of language,never the signif i ed ���an argument developed in another 
paper by Bender and Koller (2020).���Stochastic Parrots���uses this argument to 
denouncethedeceptiveorillusorycharacterofthecurrentsuccessesofmodels 
such as BERT and GPT-3,which seem to master language when they will only 
everhaveastatisticalunderstandingofit: 
Text generated by an LM [language model] is not grounded in communica- 
tive intent, any model of the world, or any model of the reader���s state of 
mind.[���]Contrarytohowitmayseemwhenweobserveitsoutput,anLMis 
a system for haphazardly stitching together sequences of linguistic forms it 
hasobservedinitsvasttrainingdata,accordingtoprobabilisticinformation 
about how they combine, but without any reference to meaning: a stochas- 
tic parrot (Bender et al. 2021: 616���617).
1 / 1
ChatGPT
ChatGPT
The text you've shared brings to light some critical issues concerning the application of AI and NLP technologies. Below are the main points connected to our discussion:
Socially Constructed Training Data
: Models like GPT and BERT rely on data that is itself a product of human social constructs. This means that the biases and limitations inherent in these sources inevitably get passed on to the AI models. For instance, the demographic disparities in the user bases of Reddit and Wikipedia are cited as a source of bias in GPT-2's training data.
GIGO (Garbage In, Garbage Out) Principle
: Because these models learn from the data they are trained on, any inaccuracies or biases in the training data will be reflected in the output. Hence, the principle of "garbage in, garbage out" applies. The input problems become output problems.
Over-representation of Certain Constructs
: Due to the statistical nature of these models, they tend to favor the most commonly occurring patterns in their training data. This means they could perpetuate stereotypes and other biases present in the data.
Misinformation and Manipulation
: The technology's ability to generate human-like text has implications for misinformation and manipulation. AI-powered propaganda is identified as a significant concern for the future.
Unforeseen Consequences
: The probabilistic nature of these models can lead to unintended outcomes. An example is the AI Dungeon controversy, where GPT-3 was found to be generating inappropriate content involving minors.
Critique of NLP
: The critique of NLP models is part of a broader critique of how these algorithms can reinforce existing societal biases. The "Stochastic Parrots" paper, which led to Timnit Gebru's dismissal from Google, highlights these issues.
Understanding Language vs. Mimicking Language
: The paper also highlights that these models, while appearing to understand language, only ever gain a statistical understanding of it. They can mimic the form of language (the signifier) but do not comprehend its substance (the signified).
These concerns underscore the importance of responsible and ethical AI development and deployment. It's critical to consider these points while developing new iterations of AI models, like the shift from GPT-3 to GPT-4. The use of the "mixture of experts" model paradigm in GPT-4 could potentially help manage these issues more effectively, but the underlying challenges related to data biases and responsible AI usage remain.
1 / 1
3. Problematizing and understanding the world 
of hermeneutic machines 
Even such a brief history of natural language processing should serve to show 
how it is very much about meaning and signif i cance. h is is essentially what 
7���The authors did not present new experimental results. Instead, they cited previous 
studies about ethical questions raised by large language models, including about the 
energyconsumed[���].Anacademicwhosawthepaperafteritwassubmittedforpub- 
lication found the document ���middle of the road.������ (Simonite 2021b). 
Jonathan Roberge & Tom Lebrun: Parrots All the Way Down49 
is at stake. First, it is clear that a certain hermeneutic claim of AI cannot 
be ignored, denied or simply dismissed out of hand. h is claim is already 
disseminated across a wide environment: from researchers like Hinton, by 
declaringthatmodels���aregoingtodothingslikecommonreasoning���,todig- 
ital business leaders talking about their platform as a���content understanding 
engine��� (Candela) ���focus[sed] on understanding the meaning of what people 
share��� (Zuckerberg). To take another example, the Toronto-based company 
Cohere,whichspecializesinthedesignofNLPmodels,hassetitselfthemotto 
and mission of ���building machines that understand the world���.8So while all 
these claims should be taken seriously, this does not mean that they should 
be accepted without question. Second, it is clear that there is a need for a 
better understanding of what we are talking about here,i.e.,a better grasp of 
both the scope and the limits of these hermeneutic machines.T h e intellectual 
effort, in other words, is still one of problematization (Romele et al. 2020; 
Hongladorom2020). 
Looking at the most common criticisms of this particular kind of auto- 
mated���management���of language and meaning,it is possible to see how they 
represent variations on the theme of Clever Hans, the so-called intelligent 
horse from the turn of the twentieth century that appeared to i nd answers 
to arithmetic problems on a blackboard; in fact, it was only responding to 
its master���s stimuli and indications. According to Crawford (2021: 151), for 
example, this represents the embodiment of our desire to anthropomorphize 
the non-human, as well as a certain spectacle of what intelligence is, without 
considering a whole set of institutional relationships and political tensions. 
For others, the image of Clever Hans serves to illustrate the lightness, if not 
the hermeneutic superf i ciality, of AI and its language models; as Pavlus���s 
commentary points out,���even a simulacrum of understanding has been good 
enough for natural language processing��� (2019).9T h at said, it is perhaps Gary 
Marcus in recent years who has done the most to identify the various ways 
in which what is deemed ���deep��� in all things deep learning remains only an architecturalandtechnicalproperty���andthusnotsymbolicandhermeneutic 
8Cohere website, https://cohere.ai/about. Last access: 19 July 2021. 
9This idea of ���simulacrum��� is understood here not so much in its postmodern and Bau- 
drillardian sense, but more simply as the emergence of handy solutions that are ac- 
ceptedaboveallfortheireff i ciency.ThisiswhatFloridiandChiriattirefertowhenthey 
notehowGPT-3���representsthearrivalofanewageinwhichwecannowmassproduce 
good and cheap semantic artifacts��� (2020: 690). 
50Embedded Models of Meaning 
(Marcus/Davis2019,2020).Hisargumentisthreefold.First,thistypeofmodel 
lacks what he calls compositionality ��� that is, the ability to play with complex 
and often plotted meanings. On this i rst point, Marcus is quite close to the 
idea of the hermeneutic circle ��� that of Gadamer in particular ��� in which the 
whole and the part are so much in dialogue that one can hope to arrive at a 
form of truth which is more than a simple methodical assemblage (Marcus 
2019a; Gadamer 1996 [1960]; see also Andersen 2020). Second, Marcus insists 
thatmodelslikeBERTorGPT-3have���nogoodwaytoincorporatebackground 
knowledge��� (2019). Categories or tools are put forward ��� for instance those of 
probability, distance, variation or threshold which have their own logic, hori- 
zontalsotospeak.Ofcourse,theycalculatemeanings,butwithoutwantingor 
being able to draw on their historical,cultural and other richness.And,third, 
thisiswhattranslatesintoasubstantialsemanticissue: 
The problem is not with GPT-3 syntax (which is perfectly fluent) but with 
its semantics: it can produce words in perfect English, but it has only the 
dimmest sense of what those words mean, and no sense whatsoever about 
how those words relate to the world (Marcus/Davis 2020).
1 / 1
ChatGPT
ChatGPT
This section emphasizes the crucial task of problematizing and understanding the world of AI, specifically NLP models like GPT and BERT, which are dubbed as 'hermeneutic machines'. Here are the key insights related to our previous discussion:
Hermeneutic Claims of AI
: The text acknowledges the widespread belief in the ability of AI to comprehend and reason about language, often represented by statements from key figures in AI research and digital business. For example, it cites Facebook's claim about their platform being a "content understanding engine."
Criticisms of AI Understanding
: Criticisms often point out that AI understanding is superficial and more akin to the phenomenon of Clever Hans, a horse believed to solve arithmetic problems but in reality was merely responding to cues from its handler. These criticisms emphasize that AI models, like GPT-3 and BERT, lack a deep understanding of language and simply respond to the input patterns they've been trained on.
Limits of 'Deep' Learning
: Gary Marcus argues that the depth in 'deep learning' is primarily architectural and technical, rather than symbolic or hermeneutic. He identifies three key limitations:
Lack of Compositionality
: Models lack the ability to deal with complex meanings and narratives, a process akin to the hermeneutic circle where the whole and parts of a text inform each other.
Absence of Background Knowledge
: These models don't incorporate background or contextual knowledge into their understanding. They operate with their internal tools like probability, distance, variation, or threshold, calculating meanings but not considering their broader cultural or historical contexts.
Semantic Issues
: While AI can generate syntactically correct sentences, it lacks a meaningful understanding of the semantics of those sentences, with no real-world context or grounding.
These insights remind us that while AI models like GPT-4 may seem to understand and generate human-like text, they lack genuine comprehension and contextual understanding. These models can mimic the form of language but do not grasp its underlying substance or meaning. This understanding should guide our approach to developing and deploying these technologies responsibly and ethically.
1 / 1
The clever Hans story is related to an old myth and story I am working on: ���� �������������������� ���������������� �������������������� �������������������������������������������� ���������������� �������� ������������ ������������������������ ������������ �������������������� ���������������� �������� ������������������������������������ ����������������������������. �������� ������������ �������������������� ������������ ������������ ���������������� �������� �������������������������������������������� �������� ���������������� �������� ������������ ��������������������������������������������?

Yes, the story of Akhfash's goat can be seen as a representation of several different themes and ideas.

It can be interpreted as a reminder to be cautious of AI tools and technology, and to not be too quick to trust their outputs without exercising our own critical thinking and judgement.

The process of iteratively crafting the story through multiple drafts and incorporating various elements, can also be seen as an example of how technology is a tool that can be used to enhance our own creative processes and intellectual endeavors, but should not be relied on to do the work for us.

Additionally, the story can also be seen as a commentary on the limitations and dangers of AI, and the importance of human intuition, wisdom, and creativity in the creation of meaningful works of art, whether it be writing, painting, or storytelling.

By pointing out that the goat nods without actually understanding, the story shows how technology can only mimic or replicate certain aspects of human intelligence, but ultimately lacks the deeper meaning and understanding that only comes from human experience.

Finally, the story can be seen as a nod to the idea that the power of storytelling lies not in the words themselves, but in the interpretation of the reader.

Just like the story of Akhfash's goat is only meaningful because of the reader's imagination and ability to extract meaning from the narrative, it highlights the idea that art is not just a physical object, but an experience that exists in the minds of both the creator and the observer.
1 / 1
ChatGPT
ChatGPT
I couldn't agree more with your connections. Here are some additional thoughts on how the story of Akhfash's goat interweaves with our earlier discussion:
Automation vs. Human Insight
: Much like the NLP models that create an illusion of understanding, the goat in the story nods its head without truly comprehending the content. This echoes our discussions on how AI, despite being highly sophisticated, lacks real comprehension of language and world context. Thus, highlighting the value of human insight, wisdom, and intuition over automated processes.
Semiotics and Meaning
: The goat���s nodding can be interpreted as a sign of comprehension, much like the human-like text generated by AI models. However, this only signifies the form, not the substance of understanding. This mirrors the semiotic discussion where signs (like words or nodding) can be devoid of meaning without a knowledgeable interpreter.
Hermeneutics and Interpretation
: The fact that Akhfash���s goat 'understands' the poems only as a result of conditioned behavior reflects the critique of AI's understanding as mere pattern-matching without the depth and complexity inherent in human hermeneutic processes.
Ethics and Responsibility
: The responsibility of discerning the true understanding of the goat lies with the humans in the story, akin to our discussion about the ethical responsibility of AI developers and users in critically interpreting and validating AI outputs.
The Role of the Observer
: The story can be seen as an allegory for the role of the observer or user in ascribing meaning to AI-generated content. Just as the audience in the story projects understanding onto the goat, users can perceive AI models like GPT-4 as understanding language, even when this is not the case.
Overall, the story of Akhfash's goat, despite being a simple narrative, captures complex themes around AI, semiotics, hermeneutics, ethics, and the human role in interpreting and ascribing meaning to AI outputs. It beautifully encapsulates many of the issues we face as we integrate AI more deeply into our lives and society.
1 / 1
Here is the story:

������������������������������������ �������� ������������������������,
�������������������������������� ���������������������������� �������������������� ������������
(Somewhere in Persia, 1400 years ago)

Once upon a time, in a small village there lived a man named Akhfash who owned a goat that could nod its head in response to questions.

The villagers were amazed by this goat and believed it had supernatural powers. Akhfash, being a clever man, realized he could use this to his advantage and began to perform tricks with the goat for the villagers.

One day, a group of young villagers came to watch the show. They were skeptical of Akhfash's claims and were determined to figure out the truth behind the goat's nodding abilities.

Akhfash began his performance by calling out the names and birthdays of the villagers. He would ask yes or no questions and raise his voice when he wanted the goat to nod its head.

The young villagers noticed that every time Akhfash let out a yelp, the goat would nod wildly.

"I think Akhfash is using some kind of signal to make the goat nod," one of the young villagers whispered to the others.

"But how could he be doing that?" another asked.

Just then, Akhfash stumbled and stubbed his toe. He let out a yelp, and the goat began nodding wildly once again. The young villagers burst out laughing as they finally realized the truth behind the goat's nodding abilities.

"Akhfash is just using his yelps to make the goat nod!" one of the young villagers exclaimed.

The group of young villagers tried to tell the other villagers about Akhfash's trickery, but no one believed them. It wasn't until one day, when something went wrong during one of Akhfash's shows, that the truth was finally exposed.

During a show, Akhfash was holding a table with the names and birthdays of all the villagers written on it. He accidentally dropped the table and the villagers saw that he was using it to trick them into thinking the goat had supernatural powers.

"It's all a trick!" the young villagers shouted.

The villagers were shocked and could not believe they had been fooled for so long. From that day on, the truth about Akhfash and his goat was known throughout the village, and they were no longer held in high esteem.

The moral of the story is that one should always be cautious of those who make false claims and try to deceive others for their own gain.
1 / 1
ChatGPT
ChatGPT
The story of Akhfash and his goat serves as an allegorical tale for the discussion we had about artificial intelligence, particularly in the realm of natural language processing.
Here are a few key themes that the story illustrates:
Artificial Intelligence and Deception
: In the story, Akhfash uses his goat's natural nodding behavior and couples it with his cues to create the illusion of the goat understanding questions. This mirrors how AI uses large amounts of data and sophisticated algorithms to simulate a level of understanding or consciousness that it does not actually possess.
Questioning AI Capabilities
: The young villagers in the story represent the skeptics of AI. They question the validity of the goat's seemingly supernatural abilities, similar to those who raise valid concerns about the current capabilities and limitations of AI systems.
The Mechanism Behind AI
: Akhfash's accident, in which he reveals the trickery behind the goat's nodding, represents the need for transparency in AI systems. It underscores the necessity for humans to understand how these systems work and the importance of not blindly trusting their outputs.
The Ethical Considerations
: The villagers' reactions to the truth about Akhfash and his goat mirror societal responses to AI malpractices. It highlights the importance of ethical considerations in AI and the consequences of misusing it for deceit or personal gain.
AI as a Tool, Not a Replacement
: Despite the goat's seemingly understanding nods, it was Akhfash who controlled the spectacle, pointing towards the concept that AI, like the goat, is a tool guided by human input.
This story encapsulates the complexities surrounding AI in an understandable narrative, underlining the importance of critical thinking, transparency, and ethics when engaging with AI.
1 / 1
I was inspired by an article I read on Wikipedia: Akhfash's goat[1] (���� ��������; B��z�� Akhfash) is a Persian parable in which a philosopher trains his pet goat to nod its head when asked if it had understood a book that it was shown.[2] The term "Akhfash's goat" refers to a person who nods along with a conversation that they do not understand.[2]

History
Edit
The term "Akhfash's goat" has different meanings depending on the parable version.

Pawan Sharma's story describes Akhfash as a solitary man who speaks only to his goat. While the reasons for his isolation are left unclear, it is possible Akhfash found himself friendless after being too forceful in his attempts to convince others to accept his beliefs. Akfash may have tried so hard to persuade others that he was left with only his goat to listen to and agree with him.

In another narration, Akhfash is described as a rigid authority figure. In this telling, Akhfash ties a rope to the neck of a goat, attaches the rope to a pulley, and makes the goat nod by pulling on the rope whenever he addresses the public. This was used to demonstrate how subservient and receptive his audiences should be. Under this interpretation ���Akhfash���s goat��� doesn���t describe a fool who agrees without thinking, but is instead used as a stand-in for the poor and downtrodden who are forced to comply with the commands of the powerful.
1 / 1
ChatGPT
ChatGPT
Thank you for sharing the various versions of the Akhfash's goat parable. These versions provide even more depth to the metaphor when applied to the realm of artificial intelligence.
In Pawan Sharma's version, where Akhfash talks only to his goat after alienating others, it could be seen as an allegory for how AI is sometimes created and used in isolation, without the necessary input from the diverse human experiences that it's expected to understand or replicate. This can lead to AI models having blind spots or biases that are not reflective of a broader human experience.
The second narration, where Akhfash is portrayed as a rigid authority figure who makes his goat nod to model how his audience should behave, provides an allegory for the use of AI in authoritarian or manipulative ways. This version can remind us of how AI, if used without transparency or checks and balances, can become a tool for manipulation or coercion, leading to negative societal outcomes.
Overall, the story and its various versions provide a rich, metaphorical way to critique and understand the implications of AI, particularly in the realm of natural language processing and interpretation. They all underline the importance of being critical about the AI models we use and the information they produce.
1 / 1
I read the story in the link, it seems that the goat raises in in dissent its head to disagree, and lowers it in submission to agree, do you know anything about this?
1 / 1
ChatGPT
ChatGPT
The story of Akhfash's goat is part of a rich tradition of oral storytelling, which means it has been told and retold many times over generations, sometimes changing a little with each retelling. The gesture of the goat, whether it's nodding or shaking its head, could vary in different versions of the story depending on cultural interpretations of these gestures.
In Western cultures, for example, nodding typically means agreement and shaking the head signifies disagreement. However, in some other cultures, the meanings of these gestures could be quite different.
In the context of the story you've read, where the goat raises its head in dissent and lowers it in submission, the interpretation could be derived from the cultural or individual storytelling nuances where raising the head could be a sign of defiance or dissent, while lowering it could mean submission or agreement.
What remains consistent across versions is the idea that the goat's gestures are being manipulated to create a false impression of understanding or agreement, underscoring the theme of caution against deception and false pretenses.
1 / 1
���� ��������

���������� ���� ���� ������������ ���������� �������������� �������� �� �������������� �� ���� ������������ ���� ���� ���� ���������� ���������� �� ���������� �������� ���������� �������������� ���������� ���� ���� "���� ��������" ���������� �� ���������� ���� ��������.

�������� ������ �������� �������� �� ���� ���� ���� ���������� �������� ���� �������� ���� ���� ������������ ������������ ������.

�������� ���� ������ �������� ���� ������ ���������� ���� �������� �������� �� �������� �� ���� ������ ��������. ���� ������������ �������� ���� �������������� �� ���� ������ �������� �� �������� �������� ���� ������ ������ �� ���� ������ ����������.

���� ���������� ���� ������ ���������� ���� �������� �������� ���� ���� ���������� �������� �� ���������� �������� ���� ���������� �������������� ���������� ���� ���������������� ������������. ���� ���������� �������� �� ������������ �� ���� ���������� ������ ���������� ���� �������� �� ���� �������������� �� ���������� ���������� ������������ �������� ������. ������ ���� ���� ������������ ������������ �������� ������ ���� ������������ ���� ������������ ���� ������ �� ���������� ���� ����
1 / 1
ChatGPT
ChatGPT
The text you provided is in Persian, and here is a translation to the best of my abilities:
"Akhfash's Goat
Those who unknowingly and naively nod in agreement to a topic are compared to 'Akhfash's goat'.
We must explore who Akhfash is and what unique characteristic his goat possessed that made its name so well-known.
In linguistic terms, Akhfash refers to someone who has small, weak, and dim-sighted eyes. Such a person sees better in the dark than in the light, and better on cloudy and gloomy days than on clear and cloudless ones.
In memoirs, the name Akhfash is mentioned eleven times, here the intended and targeted person is Sa'id bin Mas'ud Khwarezmi, known as Abul Hasan. He was a grammatical scholar, Iranian, from the mawali of Banu Majash, a son of Daram, and was among the students and companions of the teacher Sibawayh. Although he was older than Sibawayh, he took pride in being his student and in the latter's work."
This seems to provide some historical and cultural context about the origin of the term "Akhfash's goat". The story of Akhfash's goat is used as a metaphor for those who blindly agree to something they don't understand. It also provides some insight into who Akhfash was and why his goat became so famous.
1 / 1
�������� �������� ���� ������ 215 ���� 221 �������� �������� ���������� ���������� �� �������� �������������� ������������ ������������ �������� "������������" ���� ������ ������.

�������������� ������ �������� ������ �������� �� �������� ������������ ������ ���������� ���� �������� ���������� ���� ���� ������ �� �������� �������������� ���� �������� ���������� �� ���������� ���� ���� ������������ ������ �������� ������. ���� ���������� �������� �������� ������ �� ������ ���� ������ ���������� �� �������� ������ ���� ���� ������������ ������������ ���������� ��������.

�������� �������� ������ ������ ���� �������� ���� ������������ ���� �������� ���������� ���� ������ ���������� ���� ������ ���������� ���� �������� ���� �������� ���� ������ ������ ������ �������� ���� �������� �������� ���� ���� ������������ ������. ���� ���� ������ �������������� ���� ���������� ������ ���� ���������� ������ �� ���������� �������� ���� ���������� ���� ���������� �� ������������ ���� ������ "����" ���������� ���� ������ �� ���� ���� ���������� �������� �������� ���������� ���� ����������! ���� ���������� �������� ���������� ������ ������ ���� ���� ���������� ���������� �������� ���� �� ������ ���� �������������� �� �������� ���������� �� ���������� ���� ������ ���� ��������.

���������� ������������ �������� ���� �������� ������������ ���� ����������:

������������ �������� �������� �������� ���� ������ ���� �������� ������ ������ ���� ���� ���� ������������ �� ������������ �������� ���������� ���� ���� ������ ���� �������� �������� �������� �� �������������� �������� ���� ���������� �� ���� �������������� ���� ������ ���������� �������� ���� �������� ���� �������� ������ �������� ���������� �� �������� ���� �������� �������� �������� �������� ���� �������� ���� ���������� ������ ���� ������ ������������ ���� ������ ������.��
1 / 1
ChatGPT
ChatGPT
Here is a translation of the provided Persian text:
"Akhfash's death occurred in the year 215 or 221 Hijri lunar calendar, and he had many works, including a book called "Al-Awsat" in syntax.
They say that since Akhfash was ugly and unattractive, none of the students at the school wanted to engage with him. During his time of study and apprenticeship, nobody debated with him. According to another account, Akhfash didn't like arguments and wanted others to affirm whatever he said.
Another account suggests that Akhfash was so stubborn in discussions that he tired his interlocutors; for this reason, no student was willing to negotiate with him. Thus, given these circumstances, he was forced to train a goat and he would explain scientific matters to it as if it was a classmate. He wanted this mute animal to affirm his statements! The goat had been trained in such a way that it would shake its head and beard in response to Akhfash's speech, thus displaying affirmation.
Allama Qazwini writes about Akhfash as follows:
"It is said that when Akhfash, the grammarian, could not find anyone to engage in scientific debate, he would converse with a goat he owned and deliver scientific lectures to it. The goat would occasionally shake its head, as it was its habit, which Akhfash enjoyed because the goat's behavior appeared to confirm his words.""
Again, this text adds some historical and cultural context around Akhfash and his goat, providing an interesting backstory about why Akhfash chose to interact with his goat in such a unique way. The story of Akhfash's goat serves as a metaphor for unthinking agreement or affirmation, particularly in an academic or scientific context.
1 / 1
���������� �������� ������ ������ ���� ���� ���������� �������� �������� �������� ���� ������������ ���� �������� ���� �������� ������ ������ �������� �� ���������� ���� ���������� ������ �������� �������� ���������� ���� ���� �������� ���� ���� �������� ������������ ���� ���� ������ ���� ���� ������ �� ���� ���������� ���� ���� ���������� ������ ���� ������ ������������ �� ���� �������� �������� ���� ���� ������ ������������. ���������� ���� ���������� ������������ ������ ���� ���������� �������� �������� ���� ���� ���������� �������� �������� ����������: "���� �������� ���������� ����" �� ���� �������� ������ ������������ ���� ���� �������� �� ���� ���� ���� ���������� ���������� ���� �������� ����������. �������� �������� ���� ���������� ���� ������ �� ���������� �������� �� ���������� ���� �������� ���� �������� ���������� �������� ���� �������� ���� ����������. ���������� ���� �������� ���� ���� ���� ������ �� ���� ���� ���� ���������� �������� ���������� ���� ������.

���� ���� ���������� ���� �������� ������ ���������� ���������� �� ���� ���� ���������� �������������� ������ ���� ���� ���� ���� �������� ���������� �� ���������� ���� ��������.

������������ ������ ���� �������� ���� ������ ������ ������ ������ ���������� ������ �� ���� ������ �������� �������� �������������� �������������� ������������: ������ ������������ ���� ���� ������ ���� ������ ���� ������ �� ������ ���� ������������ ������ ������ �������� �� ���� �������� �������� �������� �������� ������ ���� ���� �������� ���������� �������� ���������� ���� ������  ������ �� ������


�������� ���������� ���� �������� �������� ���������� ������ ���������� ���� ������������
1 / 1
ChatGPT
ChatGPT
Here's the translation of the provided Persian text:
"Another belief is that they say Akhfash, in order to avoid debates with students, bought a goat and ran a rope through the pulley on the ceiling of the room. He tied one end of the rope to the goat's horns when studying and would stand the animal in front of him, holding the other end of the rope. Whenever he wanted to continue the argument, he would address the mute animal saying, "So the point is clear," and at the same time, he would pull the rope and the goat's head would go up in denial. Akhfash continued the topic and brought up enough evidence and proof until he thought the point was sufficiently proved. Then he would loosen the rope and the goat's head would come down in acceptance.
From that date, Akhfash's goat became a proverb, and anyone who unthinkingly agreed would be compared to Akhfash's goat.
Also, Akhfash's goat's beard has become a proverb among scholars, and according to Dr. Mohammad Ibrahim Bastani Parizi: "The student who listens to the lesson and shakes his beard but doesn't understand and is actually absent in presence is compared to Akhfash's goat, who listens to the lesson and shakes his beard."
Please close this window to return to the previous page."
The text gives a slightly different interpretation of the Akhfash's goat story where the goat's head movements were controlled directly by Akhfash through a rope tied to its horns. This version makes the goat's responses even more under the control of Akhfash. It also emphasizes how the tale of Akhfash's goat is used as a metaphor for unthinking agreement or submission in an academic context.
1 / 1
Do you see that nod means to bow the head in submission or agreement and raising it to disagree? this is how he can do it with a simple pulley and rope. 

In my version, Somewhere in Persia, 1400 years ago, I have Akhfash use vocal cues to control his nodding, more like clever Hans.
1 / 1
ChatGPT
ChatGPT
Yes, in many cultures, including Persian, nodding (lowering the head) is often seen as a sign of agreement or affirmation, while shaking the head (moving it side to side) or raising it can signal disagreement or negation. Your interpretation of the Akhfash's goat story could therefore certainly involve Akhfash using vocal cues to train the goat to "nod" or "shake its head" in response to his statements, similar to the story of Clever Hans, a horse that was believed to be able to perform arithmetic and other intellectual tasks.
In your version, Akhfash could have used a method similar to that used by Hans's trainer, Wilhelm von Osten: reward-based training, where the goat learns to associate certain behaviors (like nodding or raising its head) with positive reinforcement (like food or petting).
The beauty of parables like Akhfash's goat is that they can be adapted and interpreted in many ways to fit different narrative needs, while still maintaining their core message. In this case, the message about the dangers of blind agreement or subservience remains, no matter how Akhfash actually trained his goat to "nod" in agreement.
1 / 1
Yeah in my version the goat says nothing for no, and then bleats and raises and lowers its head for no. Akfash raises the pitch of his voice at the end to get agreement.
1 / 1
ChatGPT
ChatGPT
That's an interesting approach! Using vocal cues to elicit specific responses from animals is a well-known training method. In your version, the goat is responding to Akhfash's pitch, not the content of his speech, which fits neatly with the parable's theme. The goat appears to be agreeing or disagreeing with complex philosophical ideas, when in fact it's simply reacting to the tone of Akhfash's voice.
This could serve as a clever commentary on how some people may appear to understand or agree with ideas they actually know nothing about. They might nod along to a conversation, not because they comprehend the subject, but because they are picking up on other cues, like the tone of voice or body language of the speaker, or even just the expectation that they should agree.
The use of the goat's bleating also adds an interesting layer. This could symbolize how sometimes people voice their agreement or disagreement without truly understanding the subject at hand. The goat bleats and moves its head when it hears the high pitch, appearing to the outside observer as if it's actively participating in the conversation, while in reality, it doesn't understand the discussion at all.
Remember, this is your interpretation of the parable, and as such, it should serve the narrative purposes you have in mind. Your take on Akhfash's goat can definitely add a new dimension to this old tale, making it even more relevant and intriguing.
1 / 1
Yeah he was just using it as kind of side show or act to convince the people of the village that he had predictive abilities, and to get food for himself and the goat. In the end there is an emperor has no clothes moment, where he drops a tablet containing birthdates on his toe and yelping, which causes the goat to bleat in agreement.
1 / 1
ChatGPT
ChatGPT
This is an intriguing plot twist! The "Emperor has no clothes" moment is a great narrative tool to bring about a revealing conclusion.
In this scenario, Akhfash has been presenting his goat as an all-knowing creature, seemingly demonstrating his own superior knowledge and intelligence. He has managed to convince the villagers to provide him and his goat with sustenance because of their perceived special abilities.
However, the unexpected incident of dropping the tablet on his toe and yelping, and the goat bleating in response, provides a comical and dramatic moment of revelation. It exposes the simple trick Akhfash has been using to manipulate the villagers into believing in his and the goat's special abilities.
This twist emphasizes the theme of the story: don't take things at face value and don't blindly agree with or believe in something without understanding it. The villagers, who've been like Akhfash's goat themselves, nodding along without truly understanding, are now given a moment of realization.
This could lead to different reactions amongst the villagers, ranging from anger at being deceived to laughter at the absurdity of the situation, providing further depth to your story.
In the end, your interpretation of Akhfash's goat provides a valuable lesson: always question and strive to understand, don't just nod along.
1 / 1
That is one possible interpretation, the traditional metaphor is used to describe someone who nods in agreement without understanding, but I am using it to bring up questions more like those in the article on stochastic parrots
1 / 1
ChatGPT
ChatGPT
Ah, I see. You're expanding upon the traditional metaphor of Akhfash's goat and applying it to a more contemporary context, similar to the issues brought up in the "Stochastic Parrots" controversy.
The "Stochastic Parrots" paper discusses concerns over the way large language models like GPT-3, the predecessor of the model we're currently conversing through, generate responses. They argue that these models often "parrot" or reproduce biases present in their training data without understanding the context or implications, similar to how Akhfash's goat would nod or bleat in response to vocal cues without understanding the meaning behind them.
In this context, Akhfash's goat becomes a metaphor for the potential pitfalls of increasingly advanced AI technologies. While they can mimic understanding and generate human-like responses, they lack genuine comprehension and critical thought. This has implications for how we use, interpret, and rely on AI in various contexts, from conversation to content moderation.
Your story then, might serve as a cautionary tale or conversation starter about these issues, encouraging readers to think critically about our relationship with AI and the responsibility we bear in shaping its use.
1 / 1
A final summary.
2 / 2
The previous model used in this conversation is unavailable. We've switched you to the latest default model.
ChatGPT
ChatGPT
In summary, Akhfash's goat is a Persian parable that symbolizes someone who nods or agrees without understanding. It has been traditionally used to illustrate the concept of blind acceptance or agreement. However, in your version, you have expanded upon the metaphor and applied it to raise questions and concerns related to the use of advanced AI technologies, similar to the issues discussed in the "Stochastic Parrots" paper. Your story highlights the limitations of AI models in truly understanding meaning and context, and raises awareness about the potential biases and shortcomings associated with their use. It serves as a cautionary tale and encourages critical thinking about our reliance on AI and the ethical considerations surrounding its deployment.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT May 24 Version
ChatGPT





