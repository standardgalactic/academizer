Welcome, everyone, to the Cartesian Cafe.
We're very lucky to have Scott Aronson here with us today.
Scott Aronson is a professor of computer science
at University of Texas at Austin and director
of its quantum information center.
Previously, he received his PhD at UC Berkeley
and was a faculty member at MIT in electrical engineering
and computer science from 2007 to 2016.
Scott has won numerous prizes for his research
on quantum computing and complexity theory,
including the Alan T. Waterman Award in 2012
and the ACM Prize in computing in 2020.
In addition to being a world-class scientist,
Scott is famous for his highly informative
and entertaining blog, Shtetl Optimized,
which has kept the scientific community up to date
on quantum hype for the past two decades.
Welcome, Scott. How are you doing today?
I'm doing all right.
Thanks so much, Tim. It's great to be here.
Yeah, great to have you here.
You're clearly one of the best guys to talk to
about quantum computing.
But before we get into that,
I wanted to get to know you better as a writer and thinker
and dive a bit into your famous blog.
You have such a unique writing style.
It's some mixture of refreshing honesty,
self-deprecating humor, scientific profundity,
and it's really inspired so many people, including myself.
I just wanted to get your thoughts on blogging overall.
You're part of this small vanguard of scientists
who began blogging early on and continue to blog
people like John Baez, Peter White, Sabina Hossenfelder.
What's the journey been like?
Are there any highlights you'd like to share
and how has blogging shaped your scientific career?
Well, when I started my blog,
it felt like I was very late to the game, right?
So from like 2002 and three and four,
people kept telling me,
well, gosh, you should start a blog sky.
You seem to have a lot of a strong opinions about things.
And I gave them all sorts of reasons
why that would be a terrible idea.
I could put my foot in my mouth,
I could say the wrong thing and could be blamed for it.
I'd have to, it would take up all this time.
Anyway, long story short,
all of those reasons turn out to be valid reasons.
So, you know, but I think in late 2005,
I just had as a little experiment,
I had guest posted on Lance Fortnell's blog previously,
since that had given me a little taste for it.
And so I started a little thing on blogger
and I wasn't sure if anyone was going to read it.
It might just be a few posts and then it would go away, right?
But for whatever reason,
it did attract an audience.
And then I think what happened was that around 2007,
you started seeing the beginnings of,
I would say, the sort of crazy misleading quantum computing
hype that is now there's 50 times as much of it, right?
But you saw the beginning of it there.
And it was weird because within the quantum computing,
research community, like everyone knew
that this stuff is not serious, right?
That these claims in the popular press
are wildly exaggerated or blah, blah, blah,
or just completely misunderstanding basic concepts.
But then those things would just keep getting repeated, right?
And somehow there was no one who was just saying,
look, just taking stuff that is not controversial at all
within the academic community
and then just saying it for a broader audience,
where suddenly it was controversial
because it was going against this narrative
that people were using to raise funds
and so forth.
And so then my blog kind of fell into that niche
just because of the lack of an alternative,
just because it just seemed like it just became
a place of last resort for getting that message out.
And then what happened was that,
like science journalists would start calling me
or would sort of use my blog as they're jumping off point.
And then, not only about quantum computing,
but about whatever other science stories.
And so then that's how it kind of picked up
this momentum, I guess.
I don't blog as much now as I used to.
I mean, for one thing, I have two kids now.
I have students and postdocs.
So real life can be annoying that way,
that it gets in the way of blogging, right?
And then also, I feel like in the 2000s,
it was just fun.
You could just explore ideas.
You could try to push the envelope,
even be controversial, people would argue with you,
but no one really cared that much.
Also at that time, I was a relatively unknown postdoc.
And now, if I say one thing that's wrong,
it's Scott Aaronson, Director of the Quantum Information
Center at UT Austin has put his foot in his mouth
by saying such and such,
and that'll be all over Twitter and all over, right?
So, it's like, I don't want to,
I don't think that I'm cowardly,
and I have taken all kinds of controversial public fans
on my blog, right?
But it's gonna, I have to think very,
I have to think carefully about it, right?
But, and am I willing to spend the time
to deal with all of the blowback that I would get
if I talked about this issue, right?
And maybe I should just post things on Facebook, right?
Or it's a little bit lower stakes, right?
And so, I do feel like the internet has become more
of a battle zone.
And so, I feel like I still want to use my blog
for outreach, but it's somehow,
it's harder to just play around and have fun with ideas
than it was years ago.
Now, as for its effect on my career,
I mean, that's hard to say.
I am very happy that, I do have research papers
that were my blog kind of played a major role
in their origin.
I did a survey about the busy beaver function
a couple of years ago.
And I had to keep expanding that survey
because of new observations, new ideas
that came from readers of my blog, right?
So, yeah, I mean, no, no, no, no, no.
That was kind of perfect for that
because it's kind of a recreational math topic
or with a very low barrier to entry.
But also in quantum computing research, I mean,
I have posted things on my blog,
like, here is this quantum algorithm called this QAOA.
This was maybe, I don't know, eight years ago or so, right?
Here, this amazing claim that gets a better approximation
factor for an NP-complete problem.
And then a bunch of classical computer scientists say,
like, no, we can beat that classically, right?
And that's because they saw it on my blog, right?
So, it's kind of been a clearinghouse
in connecting people to each other
or to results that they might wanna pay attention to.
And yeah, and it has had some impact on my research,
I guess, not a decisive one.
Now, it is hard to separate.
Like when I went on the job market,
the blog meant that people might have hated me,
but they knew who I was, right?
So, I do, I am kind of, I do sometimes try
to maintain some distance between research and blogging,
like not hawking my own papers on my blog too much
because I don't wanna feel like I have an unfair advantage
over people who are not blogging, right?
Sometimes I'm just too excited about something
that I'm working on.
Well, you're too kind, I feel like in the,
like for example, with machine learning,
it's all about drawing up the Twitter audience
and getting people to see your paper, right?
So, I think you're too kind.
I have still refused to get a Twitter account
just because Twitter reminds me too much
of like the cafeteria of my high school.
This was like the whole thing that I was trying
to get away from in life, right?
And I have lots of friends who are on Twitter.
I read some of them, I mean, you can't ignore
what people are saying on Twitter all the time,
even if you might like to,
but I decided that the blog is enough for me.
And the blog, at least if people are angry at me,
they have enough space to spell out their argument for why.
Well, I'm glad you're alive and well,
and so is your blog.
Thank you so much.
This year, something interesting happened too.
You're on sabbatical, I guess,
and you decided to work with OpenAI a bit.
Can you say a little bit about that?
Because I guess that's maybe a little unexpected,
at least when I saw that.
Well, how is that a continuation of the things
you're interested in and how does that,
yeah, fall into your interest?
Yeah, well, this actually did start from my blog.
Oh, how it shaped your career.
So in my comment section, someone was saying,
well, Scott, like, how much money would it take
to get you to stop wasting your time
on all of this quantum computing theory?
And you're welcome, like, the one problem
that really matters for the future of civilization,
which is AI safety, right?
And I show that, but aren't you,
this is where your self-deprecating humor comes in.
Did you say something like,
did you say something like,
why prove things that we can't do
using computers we haven't built?
Something to that effect.
No, I study what we can't do
with computers that we don't have.
Exactly, which is hilarious.
I mean, of course, that is a lot of what I do
in quantum computing, but, you know,
I, you know, now, one thing that happened
since I started my blog in 2005 was that, you know,
a lot of the same people who would read my blog
were the people who were part of this rationality community
that formed around, you know, Eliezer Yankowski
and Robin Hansen and people like that, right?
Who, you know, also had blogs and, you know,
that, you know, were read by a lot of the same people.
And so I became very familiar, you know,
early on with their ideas, which were, you know,
many of them involved, you know, that, well, AI, you know,
might, you know, in the relatively near future,
just, you know, exceed human abilities, you know,
across just about every domain.
And, you know, this will, you know, by default,
if we don't do anything else,
this will be very, really terrible for humans.
And, you know, and we should maybe just drop everything else
that were, you know, even climate change and nuclear war,
these are all just kind of like minor worries
compared to this worry about AI becoming super intelligent
and taking over the world.
And, you know, and we should really think about, you know,
how to prevent that and how to make sure
that the AI is friendly.
And, you know, so I was familiar with this
and I always kept it at arm's length, right?
Because, you know, it's, I mean, you know,
part of it might have just been it was sort of,
it was presented in this very kind of prophetic way, right?
Like, you know, it did not look at all
like academic research, right?
And, you know, it struck many, many people
as looking kind of like a cult, right?
You know, with like these sort of messianic prophecies
and these, you know, right?
And, you know, now, now, rationally,
I could not say that I knew any reason
why this was impossible, right?
Like, yeah, you know, science fiction has been there
for, you know, generations before, right?
Asimov was writing about such things in the 1940s, right?
And of course, I, you know, read his stories as a kid
and was, you know, hugely influenced by them
by, you know, his three laws of robotics and so forth.
And so, you know, I can't say that any of that is impossible.
But first of all, you know, I did study AI somewhat
when I was a grad student at Berkeley.
I spent a year doing machine learning
before I sort of fell in with the quantum crowd, you know,
which I sort of secretly, I guess,
I wanted to do quantum computing,
although it was the AI people who recruited me to Berkeley.
Yeah, and even in 2000, you know, 2001, you know,
I had a sense, yeah, that this machine learning thing
might turn out to be pretty important, right?
But it was just so hard to prove anything.
And I just-
It still is.
Yeah, yeah, right, exactly.
And I just had more fun doing quantum computing.
And that was kind of the reason I got drawn there.
But, you know, then, you know, this was, you know,
this was all more than a decade
before the deep learning revolution, right?
And at the time, you know, you could look at the state of AI
and say, like, this is not actually, you know,
anywhere close to human abilities, you know,
in an interesting way, right?
This is-
And who the hell knows how long that could possibly take
until you get an AI that you would really want to describe
as understanding something, right?
And, you know, it could be hundreds of years
for all we know, right?
And so then, you know, you get to this position.
Actually, my mentor, my first year in grad school
was named Andrew Whitton who is now a very famous,
you know, machine learning person.
But one thing he's famous for is for this quote
that worrying about, you know, AI taking over the world
is kind of like worrying about overpopulation on Mars.
Yeah, it's just like, it's so far in the future
that like, even if you decided to be worried about it,
it's like, great, we'll walk,
what do you want to do about it, right?
Like, I didn't really see anything that looked
like a clear research vision, right?
But now, you know, starting around 2011, 2012, you know,
I think the thing that very, very few people predicted
was that just taking the same ideas
that had been around for decades, right?
Of, you know, bad propagation, neural nets, you know,
that hadn't worked that well before, right?
But if you just scale them up enough
and you just train them on enough data,
then they do work, right?
Like, usually you take a non-working idea
and you scale it up by 10,000,
it's still a non-working idea, right?
But in this case now, in this case, it started working
and it started, you know, handling a translation
and recognizing images.
And then within the last few years,
we have seen these absolutely astounding new artifacts
like GPT and Dali and, you know, and Lambda
and, you know, and the amazing things
that DeepMind has done, you know, AlphaZero, AlphaFold,
AlphaTensor, you know, that discovered
new matrix multiplication algorithms, right?
I mean, so we now have AIs that can, you know, make art.
I mean, you know, well enough that it's going
to sort of revolutionize the commercial art industry,
you know, they can write poems that like, if I didn't know,
it came from the AI, I would think it was just something
from the New Yorker or whatever, right?
And, you know, that all came about
because, you know, a few new ideas
like transformers and so forth,
but mostly just scale, right?
And so we're, you know, and a lot of my colleagues,
I think, are still in denial about this.
They're still in the mode of like trying to invent reasons
why it doesn't really count or it doesn't really matter, right?
And I think that it does really matter, you know,
regardless of whether you say it really understands
or it doesn't really understand.
Like we're now at the point where just the existing AI, right,
is already going to have massive effects on civilization.
That just, you know, in fact, I'm astounded that it's like,
you know, the sort of, you know,
that the world has not woken up to this,
to the, you know, extent that it should have.
You know, it reminds me of like when I was an adolescent
in like 1992 or 1993, and I first saw this thing
called the World Wide Web, right?
Like why isn't everyone using this?
Why isn't this the biggest story in the world?
And within a year or two, it would be, right?
But, you know, when you use GPT,
like that is how I feel right now, right?
And so I had already been primed that like,
this is a thing to think about.
And also this sort of suddenly changes the calculus
about, you know, the AI safety program, right?
Because now there are actual AI systems
that are going to be deployed in the world.
There are hopefully, you know, GPT or something like that
is not going to destroy the world, right?
But, you know, it's going to be used by 100 million students
to, you know, write their term papers, right?
Or at least they're gonna be tempted to use it for that, right?
It's gonna be used for propaganda.
It's gonna be used for impersonating people, right?
It's gonna be misused in all kinds of ways
that, you know, we can try to think about
and we can think about how would we mitigate that?
Okay, and these questions seem continuous
with the eventual questions that you would face
about, you know, how do you deal with an AI
that is just smarter than humans are
across just about everything, right?
And so now there's like an actual research program
in AI safety where you can get feedback
from the external world,
but you can have something external to just,
you know, your pure thought that is telling you
when you've got it wrong, right?
And to me, that is kind of the crucial prerequisite
to making progress in just about, you know,
any area of science, right?
Like either you need experiments or you need math, right?
But, you know, you need something
to tell you when you are wrong, right?
And so then, so what happened was, you know,
that this person's commenter on my blog
was asking me when I work on AI safety.
And I'm like, you know, well, you know,
it would just depend on whether I could find
a concrete problem to work on.
Like maybe I'd be open to it.
And so it turns out that open AI people read my blog.
And so then they got in touch with me
and they're like, are you serious about this?
And I'm like, oh shoot, now I have to figure out,
was I serious?
So I talked to them.
Somebody else put money where your mouth is.
Yeah, I guess so.
Yeah, no, and they said, you know,
you can stay in Austin, you know,
where your family and your students are,
you can still run your research group.
And we'll just, you know, sort of like buy you out of,
you know, so you don't have to teach for the year.
And, you know, and you can think about, you know,
we want you to think about what can complexity theory
contribute to AI safety.
And they gave me some examples of what they had in mind.
Actually, the whole safety group at Open AI was started,
or co-founded, I should say, by a former student of mine
from MIT named Paul Cristiano.
Okay, and so Paul did a, you know,
worked with me, then did a PhD in quantum computing
at Berkeley from Umesh Vazharani,
who was also my advisor,
and then switched from quantum computing
fully into AI safety.
Because he decided that that was just more important
to the world.
And so helped start the safety research at Open AI,
has since left and now has his own AI safety organization.
Okay, but Paul had really convinced the AI safety world
that maybe like interactive proofs,
like, you know, like in theoretical computer science,
we know a lot about how a very, very weak verifier
can sort of force a very, very powerful prover
to do its bidding, right?
And like, ah, so that's exactly the kind of thing
that we need for safe AI, right?
We need to know how to control these entities
that are actually much smarter than we are,
verify their behavior.
And so I said, okay, you know,
it's still not completely obvious what I'm going to do there,
but you know, I can see that there is going to be technical,
you know, there is going to be actual progress
that can now happen in this field.
And maybe it would be exciting to be in
on the ground floor of that.
And so I'm spending a year
and I'm thinking about various things.
And I guess if we do a different conversation,
maybe at the end of the year,
you can ask me about AI safety
and tell you what thoughts I'm having about that.
Okay, well, thank you for that, Scott.
Let's actually talk about quantum computing.
All right then.
All right, at long last.
So let's see, I think this is obviously a very timely topic.
We did mention that a Nobel Prize
was awarded to several individuals this year
for their work in verifying Bell's inequality.
So quantum physics has been in the popular
mind space for a while now.
And of course, you have a lot of
thought and expertise on this.
And part of that is also sort of putting the hype
on the right footing.
Of course, you know, quantum computing is important
and worth setting, otherwise you wouldn't be doing it.
On the other hand, as you mentioned through your blog,
there's a lot of overhype
and you have, I guess a moral obligation to fight that off.
And I thought what would be unique on our episode
is that because we have a whiteboard,
we can actually explain quantum computing in a way
that's more than what an audio-based podcast can do.
And also even more than what, say,
a typical blog post can do.
But also, you know, and kind of get the right perspectives
with the technical detail so that we really can kind of
get the idea across, right?
So I think one way to start out is just giving a high level
of what your take on the field is.
And the way we're gonna start out is by looking at an excerpt
of this funny Saturday morning breakfast cereal cartoon
that you are a co-author of.
It's a long cartoon, you know,
maybe there's like 30 or 40 of these kind of images.
I just took the relevant ones.
It's called the talk.
Sort of obviously a play on a typical talk
that an adult would have with their child.
But this is the talk to sort of get the story straight
about quantum computing, right?
Do you wanna say in your own words a little bit
about this cartoon and what you wanna convey
about how to understand quantum computing
at a high level?
Yeah, yeah, so I got to know Zach Wienersmith
who is the author of SMBC comics,
which is this, you know, fantastic nerd webcomic, right?
It's the one that's not XKCD, the other one, okay?
But, and actually like the, you know,
Zach and I decided to do this comic
about quantum computing where like actually
the mouseover text, like if you click,
you can see Zach saying,
now out nerd me now Randall, right?
Randall Monroe being the author of XKCD, right?
But so we, it's basically like a parent,
discovers their mother, discovers her son in his bedroom
with all of these trashy popular magazines
that are mis-explaining the basics of quantum computing,
right?
Saying that a, you know, a cube bit is just a bit
that is both zero and one at the same time.
You know, a quantum computer can solve a hard problem
by just trying all of the possible answers at once
and then just magically picking the best one, right?
It can store, you know, two to the thousand bits
of information and only a thousand cube bits
and all this stuff that, you know,
that sounds like amazing, like, you know,
too good to be true almost, right?
And in a way it is too good to be true, right?
It's all trying to get at something true,
but just sort of skipping over, you know,
like subtleties that are actually really, really crucial
to the story, right?
And to sort of why this story is sort of weirder
than any science fiction writer
would have had the imagination to invent, right?
And so then the mother just kind of has to explain,
like, look, you can't understand this
without talking about, you know, linear algebra,
a little bit, right?
And, you know, what is a cube bit,
which is the basic building block of a quantum computer,
right?
And so, you know, what every popular article wants to say
is that what classical bit has to be either zero or one,
but a cube bit can be both zero and one at the same time,
right?
It is, you know, just like Schrodinger's cat
to be both dead and alive, right?
And once, and, but, you know, now that the trouble is,
well, what does it mean for something to be zero
and one at the same time?
Does it mean that the zero and the one
are just like both, you know, being maintained,
like you can see them both?
Well, no, clearly it doesn't mean that
because when you look, you only see one of them, right?
As soon as you measure a cube bit,
then you force it to make up its mind
about what it wants to be, right?
And then, you know, with some probability,
it will collapse to zero.
And with some probability, it will collapse to one, right?
And then, you know, and then that's all you see.
You don't see the other possibility.
So then as soon as people understand that,
then they say, oh, so then all a cube it is,
is it just some fancy way of saying
that you don't know whether the bit is zero or one, right?
It's one or the other, you just don't know which.
So you just say it's in superposition, right?
You know, it's just a pompous way to describe that.
And then, you know, you look and then you know
which one it is, and that's collapsing the superposition,
right, and really it's just one or the other, okay?
And then what you have to explain is that, no,
there is another ontological category
that you've missed, right?
It's not and and it's not or either.
It is a complex linear combination, okay?
It is somehow a sum of the two, right?
Of the form like alpha zero plus beta one,
where here alpha and beta
are going to be complex numbers, okay?
So they're gonna be numbers that, you know,
like, you know, if you would ever thought
that complex numbers were just something
that mathematicians made up to, you know,
to be perverse or something in the 1500s, well, guess what?
We learned with quantum mechanics
that complex numbers are there at like
at the deepest level of physical reality
that anyone has ever discovered.
May I suggest maybe?
Because I think we'll get to that
and write equations soon enough.
I thought maybe, I thought what you're gonna talk about
actually was this trying all things in parallel kind of quip.
Oh, yeah, yeah, that's what I was thinking.
Why don't we go over that?
And then once we get, we'll go to the nitty gritty teals
and start to add in qubits.
Yeah, yeah, yeah, no, no, I mean, I mean, so yeah,
no, I mean, I was getting there, but, you know,
the issue is, you know, if you, you know,
what a superposition means is it's like,
it's a vector of these amplitudes.
That's what we call these complex numbers, right?
You have to assign one of these amplitudes
to every possible configuration that you could see
when you looked at your qubits.
And now the key is if you have, let's say, 100 qubits, right?
Then you need two to the 100 power amplitudes, okay?
One for every possible hundred bit string.
If you have a thousand qubits,
then you need two to the thousand power amplitudes.
Okay, that's already more amplitudes
than you could write down
in the entire observable universe, right?
And, you know, so then, you know,
so then that is amazing, right?
That this is a staggering metaphysical claim
about the world, okay?
But it doesn't mean that you can literally see
these two to the thousand numbers, right?
You know, somehow these numbers
are just going to be involved
in calculating the probabilities
of the things that you can see, right?
And when you look,
you're just going to see a single thousand bit string, okay?
But now the crucial point is that, you know,
these amplitudes are more than just probabilities, right?
So the amplitude is related to how likely it is
that you will see this particular string when you look,
right, the greater the amplitude,
the greater the probability, okay?
But the amplitudes are not probabilities, right?
And we know that because they can be positive or negative,
you know, or even complex numbers,
whereas of course a probability
is always from zero to one, okay?
So, you know, what would it mean
to have a negative 30% chance of, you know,
someone, you know, winning in the midterm election
or whatever it was, right?
That would be nonsense, okay?
But amplitudes can be these complex numbers.
And when we don't make a measurement,
then then these complex numbers evolve by rules
that are unfamiliar to everyday experience.
They evolve by some linear equation,
namely the Schrodinger equation, right?
And the key in quantum computation is always
that if something could happen one way
with let's say a positive amplitude
and another way with a negative amplitude,
then you can get two contributions
that is to say interfere destructively
and cancel each other out
so that the total amplitude is zero
and then that thing doesn't happen at all, right?
Whereas, and so with every quantum algorithm,
what you're trying to do is sort of choreograph
a pattern of interference
so that for each wrong answer,
each answer you don't wanna see,
the different contributions to its amplitude
are canceling each other out.
They're sort of pointing every which way
in the complex plane,
whereas for the right answer,
for the answer you do wanna see,
the amplitudes, the contributions to its amplitude
are reinforcing each other, right?
And this is the ability,
that this is the new ability
that quantum mechanics gives you, right?
So it's as if nature has just provided
this absolutely bizarre new hammer,
like one that no one asked for
or imagined would be possible, right?
And then the job of the quantum algorithm designer
is to figure out which nails can that hammer hit, okay?
All right, but the hammer is all about interference.
If you can't choreograph this pattern
of positive and negative amplitudes,
then a quantum computer is not going to help you
and you might as well just use a classical computer.
Okay, great.
Why don't we actually,
because you said a lot of things there
and I wanna unpack what you said in writing
because that's the benefit of our podcast.
So why don't, let me kind of write a brief outline
of what I think we can talk about.
Maybe share me your thoughts on that.
But I think the first thing we'll do
is just set up the setup in terms of what qubits are
and how that differs from classical bits, for example, right?
And then the second thing, just to really get concrete
because you said a lot of things there,
but I think what we really wanna do
is dive deep into a particular example to see how it works.
So the kind of one-on-one example
of how you get quantum computing magic, so to speak,
is this Deutsch-
Oh, you want the Deutsch-
Yeah, yeah, I think it's the simplest one, right?
I mean, the other ones are a little bit more involved.
This was historically also the first one, right?
Yeah, and I think it already illustrates all,
essentially the essential concepts already in this example,
right?
So this is where we'll see kind of,
for lack of a better term, quantum magic, so to speak,
or where you start diverging from classical computation, right?
And I think from there,
probably one thing we could mention
is sort of the complexity classes
because I think that's where things really,
I'd say this is where you can really disentangle
sort of the hype by saying,
this is what quantum computers can or cannot do
and versus classical computers, right?
And then time permitting,
maybe a few remarks about quantum supremacy
because that's also then sort of a landmark result
and of course you have a lot to say about that.
So I think that, how does that look like as an outline?
Sure, looks fine to me.
Okay, great, all right, so let's do it.
Shall we start with what is a qubit then?
Yeah, exactly, let's do that.
What's a qubit, Scott?
So like I just said,
a qubit is a bit that can be in a complex linear combination
of the zero state and the one state, okay?
So now what do we mean by that, right?
Well, okay, so if we start with just a classical bit, right?
It can be either zero or one, okay?
And if I have n bits,
then well, now I have two to the n possibilities, right?
So I could say that I have a string x,
which is an element of the set zero comma one to the n,
like that, okay?
And now the next thing we could have
is a probability distribution over strings, right?
So if I have a bit and I don't know
whether it's a zero or a one,
well, then I'm going to give it some probability
of being zero, right?
And some probability of being one,
these two probabilities, they should be real numbers.
So let's say they should be between zero and one
and they should add up to one, okay?
So now I could say that my knowledge of the bit
is described by a two-dimensional vector, right?
Of real numbers adding up to one, okay?
And then the one other thing to say is what would happen
if I had a bit and I had a bit and I had a bit and I had a bit
is what would happen if something were done to the bit?
So for example, if without looking at this bit,
I apply a not gate to it, right?
Which flip zero and one,
or imagine that I flip the coin
and then without looking to see whether it's heads or tails,
I now flip it over, right?
What does that do to this vector?
Well, it just acts on it by some linear transformation, okay?
So in this case, it's just a linear transformation,
zero, one, one, zero, okay?
So I can apply a linear transformation
that will change this factor.
Okay, well, why is it linear?
Well, intuitively because sort of it really is
in one of the states, right?
And whichever state it is in,
that should determine the probability distribution
over the next state that it could be in, right?
And it's merely that I don't know,
which state it's in, right?
And if you think about it,
then that kind of means that the transformation
of the vector of probability should be linear, okay?
So now, I guess the one other thing to say
is, well, what happens if I've got multiple bits, okay?
So for example, I could have two bits.
Let's say one of them is,
let's say a one with probability P
and zero with probability one minus P.
And my second bit will be one with probability Q
and zero with probability one minus Q.
Okay, so just to clarify,
so are you kind of motivating the transition
from classical bits to quantum bits right now?
Or are you, okay, is that, okay, yeah, okay, great.
Just wanted to clarify, okay.
Yeah, okay, yeah, yeah.
So, okay, right.
So now, what I can do is I can say,
I now have a two bit state, okay?
And that state can be written
as what we would call a tensor product
of these two vectors of length two.
And I draw it like that.
That's the tensor product symbol.
And now I get a vector of length four,
which has an entry for each possible two bit string.
So I could say both bits are zero
with probability one minus P times one minus Q, right?
And then I get like a one minus P times Q
for the probability that the first bit is zero
and the second bit is one.
And then I get a P times one minus Q
for the probability that the first bit is one
and the second is zero.
And then P times Q for both bits to be one.
Sure, maybe just one clarifying remark,
just to keep this pedagogical.
You mentioned this tensor product.
Let me just say very quickly what it is.
So we have a tensor product, right?
And just to be concrete,
because we're gonna work with complex vector spaces.
But if I have the tensor product
of say two vector spaces, CN and CM,
then this will just be written as CN tensor CM.
CN tensor CM.
And it's also a complex vector space
of dimension N times N.
So it's gonna be isomorphic to C to the N times M.
And you could sort of think of it
as sort of multiply the basis vectors, right?
So every basis vector-
That's what I did here.
Exactly, every basis vector of CN
and every basis vector of CM, multiply or tensor
to give you a basis vector of C to the N times M.
And that's exactly what you did there.
These are kind of the zero one,
so-called computational basis.
And as you wrote here, there's zero, zero,
zero, one, one, zero, one, one,
all the possible combinations.
Okay, just wanted to-
Yeah, yeah.
Thank you.
That is the much more professional way
to say little example, yes.
Okay, great.
Okay, so now I guess the one interesting thing
that we can observe here for the future
is that we could also have a probability distribution
over two-bit strings where I do something like this.
I say
with half probability, both of my bits are zero
and with half probability, both of my bits are one, okay?
And there is no chance that they are different, okay?
And now this is a distribution over two-bit strings,
which cannot be factorized as a tensor product, okay?
So there is no, you know, you can,
if you just think about it,
you see that there is no P and Q
for which this equation is satisfied.
Right.
Oh, yeah, actually, this is a good point to clarify
because the tensor product
of CN and CM are all linear combinations, right?
Yes.
Of, let's say, U tensor V,
where U is in the first vector space,
V is in the second.
And what you're saying is that this state you wrote here
is not a simple tensor.
It's another words, it's not,
this cannot be equal to some fixed U and fixed V,
but rather it has to be a linear combination of them.
Yeah, yeah, exactly.
So, or another way to say it is that what I've done
is I've just correlated the two bits.
Yeah, okay.
Actually, what's the correct name?
Is it simple or product?
I think product state maybe, or what do you call it?
Well, I mean, I would just call this
a correlated probability distribution.
I see, okay.
I wasn't sure what the linear algebra term
off the top of my head is.
Okay, or, yeah, or I would just call it a,
I think a product state maybe, yeah.
It is a vector in the tensor product space
that is not itself a tensor product, right?
Okay, yeah.
I'll call it product state, yeah.
Yeah, this state is not a product state.
And learning about one of the bits
can tell you something about the other.
Okay, if I looked at one of the bits
and I saw that it was one,
immediately I would know that the other one is also one,
right?
And it doesn't matter how far apart they are.
One could be on Earth, the other one could be on Mars, right?
And often people will talk about that
as the signature of quantum entanglement, okay?
It's not, okay?
So far, we've said nothing about quantum mechanics, right?
This is a purely classical phenomenon that if I,
if you take a pair of matching socks,
this was John Bell's example, right?
And you put one on Earth and the other one on Mars
and you then look at one to see that it's red,
then immediately you know that the other sock is also red.
Sure, sure.
No one calls that spooky action at a distance.
I wanted to make clear, like all of the picture,
all of the elements of the quantum picture
that sometimes people go on and on about
as special to quantum mechanics and none of them are, right?
These are all things that we can just see
and we just have seen as features
of classical probability theory, okay?
So now what is new with quantum mechanics, right?
What is the crucial change that we're going to make, okay?
And that change is going to be that we're going to upgrade
the components of our vector
from probabilities to amplitudes.
Amplitudes can be complex numbers, okay?
So-
Right, so it was already implicit the fact that,
yeah, it was already implicit that these were
complex vector spaces though,
but I'll emphasize it, complex linear combination.
It's that complex linear combination
that's key to what you just said.
Yeah, yeah, that's right, that's right.
This is what's going to distinguish quantum mechanics
from just conventional probability theory, right?
From just saying that the thing is in one state
or the other and you just don't know which, okay?
Right, okay.
And now imagine that I have a,
I again, want to have a vector with two components,
which I'll call alpha and beta.
You know, I guess we'll use Greek letters
to make it a little bit fancier, right?
And so this is a complex vector.
Now, we could ask what should be the analog of,
you know, the probabilities adding up to one, right?
And we could say, well, maybe it's that
it should be a unit vector, right?
So, okay, but when I have complex numbers,
you know, the meaning of having a unit vector,
a vector of length one becomes a little bit different,
you know, from the Pythagorean theorem,
it's just that the sum of the square should be one,
or since these are complex numbers,
actually the squared absolute values, okay?
So this is what it means to have a unit vector
of complex numbers, okay?
That the sum of the squares of the absolute values
of the two components should be one, okay?
And in some sense, this is what we mean by a qubit.
We mean, you know, a unit vector in C squared.
Yeah, and just to make this clear, right?
C two, we think of as the span of the zero basis vector
and the one basis vector.
We haven't yet, you know, said anything about
ket notation, you know, actually for computer scientists
who are learning the subject,
like that is like the single biggest hurdle for them.
Oh, really?
Okay.
Like, you know, linear algebra, they know, right?
But then, you know, this weird notation for vectors,
like where does that come from?
Sure, do you want to say about,
or do you want to use ket notation?
Okay, let me just say, yeah, sure, I'm happy to.
So what we do is we just give these nice little names
to the basis vectors, you know, of our vector space.
So like the zero vector, like, you know,
like the bit having the value zero, right?
We just, we write it like this.
The bit having the value one,
which is a vector that's orthogonal to that.
Okay, we write like this.
And these asymmetrical brackets, these are, you know,
these are what are called kets.
So it was a notation introduced by Paul DeRocque, okay,
in 1930 and that, you know, physicists still use to this day.
Okay, and the nice thing about it is that then, you know,
you have these very nice labels for your basis vectors
and then you can just write other vectors
as just linear combinations of those basis vectors
without having to write some gigantic number of zeros,
you know, to fill out your,
because we will be dealing with quite enormous vectors, right?
Yeah.
So, so, so for example, let's just,
just think about the possible values of a qubit
where both of the amplitudes are real.
Sure, maybe just while we're on this ket thing,
it's a people who don't know,
ket is just a, it's the second syllable of bracket, right?
Because you deal with inner products
and sort of inner products involve two vectors
and the ket is sort of like half the bracket.
So just maybe just worth mentioning.
Yeah, sure, right.
And the other half is called the bra.
Exactly.
Which is, you know, these are actually kind of terrible names,
but-
I agree, but yeah, okay, it's stuck.
Yeah, yeah, yeah, yeah.
All right, great.
Yeah, so, so, so kets are column vectors
and the corresponding row vectors are called bra vectors.
Okay, so, so now if I just say that both amplitudes
have to be real,
then my normalization equation simplifies
to alpha squared plus beta squared equals one.
This of course is just the equation of the unit circle.
I guess with some, I guess with norms there, yeah.
No, no, I said if they're real.
Oh, if real, I'm sorry.
Okay, yeah, okay.
Yeah, I'm sorry.
What I just said, right?
Okay, okay.
In order to be able to draw this in two dimensions-
Sure, sure, okay.
It is convenient function that they are real.
And then, and then I just get a circle.
Okay, so now what I see is that the horizontal direction
is the zero qubit.
The vertical direction is the one qubit,
but now I also have all of the other points on the circle.
So for example, I have this one here,
which is zero plus one over the square root of two.
Okay, an equal superposition of the zero and one state.
This is important enough that we give it its own name.
We call it the plus state, okay?
It's just cat, cat plus, okay?
And there's also another superposition of zero and one,
which is orthogonal to plus.
We'll be not surprisingly, we call it minus, okay?
The minus state.
And what is this?
It is cat zero minus cat one over the square root of two.
Okay, and I could have any other possibility.
I could have a state here, which is mostly zero,
but with a little bit of one mixed in, right?
And now, you know, now the, you know,
there are sort of two,
so these are what my states look like, right?
And okay, so now there were two, given these states,
there are two main things that I can do with them, okay?
The first is that I can make a measurement.
So I can look at a qubit and ask it whether,
let's say it is zero or one, okay?
And the rule for what happens if I do that
is that the probability that I see the outcome one
is just equal to the squared absolute value
of the amplitude for the outcome one, okay?
And we could say,
if I have a vector of n amplitudes
and I now measure it in the standard basis,
so like to ask it, like, which one are you?
Are you one, two, three up to n?
Then it tells me that it is the i-th one
with probability equal to the squared absolute value
of the i-th amplitude, okay?
But in addition to that,
the entire vector collapses to just the i-th basis vector,
okay?
So basically after nature decides
that it wants the answer to be i,
then it just, you know, it makes the vector i,
it sticks with it.
Let's pause there because this is really kind of also
one of the spooky things about quantum mechanics.
And in some sense, well,
I don't know a controversial to the right word,
but there are various interpretations
of quantum mechanics.
And this is, I guess, the default one, so to speak,
the one you learn in university courses at least.
Right, right, at this point,
I'm not making any statement about interpretation.
I'm just saying this is how quantum mechanics gets used.
Yeah, yeah, fair enough, fair enough, sorry.
Yeah, yeah, yeah, yeah.
So this is what's called the Copenhagen interpretation wave.
I am not committing myself
to the Copenhagen interpretation, right?
You know, regardless of whether
there is something deeper underlying this,
like this is how you use it.
Sorry, what I wanted to, okay.
Yeah, okay, let me push back a little bit
because you did say, you did use the word collapse.
And that's sort of one of the key words
for the Copenhagen interpretation
as opposed to say many worlds or whatnot, right?
So that's a whole, I don't wanna go down that rabbit hole,
but I just wanted to emphasize
that that's part of that package, I suppose, is that right?
I mean, Copenhagen would say that collapse is then,
just a fundamental part of the picture
and is not to be explained by anything deeper, right?
It is just because all,
or you shouldn't even ask for anything deeper
because all that you have the right to ask for from physics
is that it account for your observations.
The many worlders or the Evradians would say that,
no, you too have a quantum state.
You are part of, in fact,
the global quantum state of the whole universe.
And this whole process of measurement and collapse
is just to be explained as a side effect
of you becoming entangled with the system
that you are measuring, right?
So that is the difference between the Copenhagenists
and the many worlders.
They both, if they're actually in the lab,
they're both gonna completely agree
about doing exactly the thing that I just said.
Yeah, sure, sure, sure.
Okay, yeah, yeah, yeah, okay.
Okay, I think unfrolling that will take us way aside.
Yeah, yeah, yeah, yeah, yeah.
I just wanted to-
No, I mean, we could spend the entire time
just talking about that debate, but-
Yeah, yeah, sure, but okay, but okay, but yeah,
the point is, forget whatever metaphysics
that surrounds what's going on here.
The point is that you have a vector,
there is a non-unitary operation after you measure it,
which is this collapse of the wave function
to sort of the, now the direct distribution
on the measurement that you observed, but-
Okay, sure, yeah, yeah, yeah, yeah, I mean, yeah.
It's funny how your clarifications
actually use much fancier words than I was using,
but that might actually be like for mathematicians
who are listening, like they might understand
the fancy words much better than the simple words.
Oh, I see, well, maybe, well, let's hope that our
different cells are constructively interfering
and not destructively so, okay.
Yeah, yeah, right, all right, all right.
Okay, well, I guess the listeners will pick-
You or me to listen to what they want, okay, great, all right.
Yeah, okay, okay, so if all I could do was measure,
then you might have just said, well then,
why do the complex phases even matter at all, right?
Like I might as well have just talked about
the squared absolute values of these amplitudes,
the probabilities, in other words,
I've just been done with it, right?
But now we kind of come to the key about quantum mechanics,
which is that I don't have to just measure in one basis,
I can do a change of basis, okay?
And to sort of rotate our state,
to sort of change its basis, okay?
I can apply, in principle, quantum mechanics says
that I can apply any linear transformation
that preserves the norm, okay?
That maps one unit vector to another unit vector, okay?
And such transformations are called unitary, okay?
So sort of all of the unitary transformations
so the transformations with the property
that the norm of UV equals the norm of V for all V, right?
These are the transformations that I am allowed to apply, okay?
So let's just look at some examples
for what are some unitary transformations
that can act on a single qubit, okay?
Well, there's the identity, of course,
which just says do absolutely nothing to my qubit.
There is the logical not operation,
which we already saw, okay?
Which says just map one to zero and map zero to one, okay?
But now there are some things
that have no classical analog,
such as this one here,
which says flip the amplitude,
flip the sign of the amplitude if the qubit is one, okay?
But if it's zero, then do nothing, okay?
So this is called a phase operation.
I could even have some complex phases like, you know,
I could say if the qubit is one,
then multiply the amplitude by I, okay?
And now I can also do things that will rotate
between the zero state and the one state.
So here is an example.
I could do one over the square root of two,
one minus one, one, one, okay?
What does this do?
If you think about it,
this is actually a 45 degree counterclockwise rotation
in the plane, okay?
So what this is saying is that if my qubit is zero,
then I should map it to plus.
If it's plus, then I should map it to one, okay?
You know, and if it's one,
then I should map it to this thing here,
which is minus the minus state, okay?
And then if I do it yet again,
then I should map it to minus zero, okay?
Now one very curious feature of quantum mechanics
is that the global phase is irrelevant.
So if I multiply my entire quantum state vector
by a scalar, that has no effect.
So for example, the zero state and the minus zero state
are just two different notations
for exactly the same quantum state, right?
There's no physical difference between those two, okay?
So in some sense, I've gotten back to the zero state
just by rotating, okay?
But something interesting has happened here
because just by taking the zero state
and rotating it twice, I've gotten to the one state.
And so it's kind of like I've applied
a square root of the not gate, right?
And that's already something with no classical analog, right?
There is no operation on a single classical bit
where if I apply it twice in succession,
then I get the not operation, right?
I would, yeah.
There's a lot of, just to emphasize more
what you just said, right?
So it's the overall phase, as it matter,
but of course the key magic are relative phases, right?
So, you know, zero and minus zero, there's no distinction,
but one plus zero and one minus zero,
those are different, right?
Exactly, exactly, yes.
Yeah, and I guess you can already see it from the picture.
I mean, the magic behind the quantum world,
there's more room to move, right?
Because bits are just discrete things.
You could basically only permute things.
It's rigid, but in quantum physics,
you have a continuous space of transformations.
Yes, yes.
So, yeah, so it is sort of this beautiful way
of sort of enlarging this discrete space,
you know, zero, one to the n to this whole continuum, right?
All the unit vectors.
And so now just to emphasize the point,
okay, now the key to, or AK to quantum computation
is going to be that when I have multiple qubits, right?
Then how does this picture change?
Well, you know, a single qubit was just a unit vector
in C squared, okay?
If I have two qubits, that's going to be a unit vector
in the tensor product space,
C squared times C squared,
which is isomorphic to C to the fourth, right?
And now if I had 1,000 qubits,
then that's going to be a unit vector in C squared,
tensored with itself 1,000 times, okay?
Which is isomorphic to C to the two to the 1,000, okay?
So already with 1,000 qubits,
I now have a two to the 1,000 dimensional vector space, okay?
And we can understand that very, very concretely.
It's just saying that if I have 1,000 qubits,
then my state, you know,
and often we use the Greek letter psi
to denote some arbitrary quantum states,
some, you know, arbitrary superposition state.
I now have to write it like this.
I now have to write for every possible 1,000-bit string X,
what is the amplitude for that X?
Okay, so you can see that just to specify the state
of 1,000 qubits, right?
I may in general need two to the 1,000 complex numbers.
Yeah, let me interject here
because I think there's something very interesting.
Is this where the distinction between hardware
and classical storage of bits really makes a distinction?
Because for example, like at a high level,
even something like the number pi, right?
If you want to store all the digits of pi, you couldn't do it.
It would exhaust any computer.
But yet, you know, I don't know,
to the extent that there's a physical object in the world
that is of length pi or whatever real number or whatever.
In other words, the things that exist out there
kind of can contain unbounded information
merely by them existing in some sense, right?
Well, you know, this becomes very tricky
because it depends what you mean.
Can you actually see the information when you look, right?
Like I could say that I could encode pi
in just a single coin by just let's say making a coin
that is heads with probability one over pi
and tails the rest of the time, right?
Okay, but then, you know, even supposing
that I knew how to do that, do it exactly,
which, you know, of course, in real life,
it's never going to be exact, right?
But even supposing I could do it exactly,
like it would be of limited use, you might say,
because then all I get to do is look at the coin,
see whether it's heads or tails,
and that might give me this extremely crude approximation
as to whether, you know, pi is likely
or to be large or small or something, right?
But I can't just look at the coin
in order to read off the digits.
Amplitudes are going to be subject
to that same limitation, okay?
That in some sense, they are there
in the physical description of the system.
You know, we need them there
because we need them to calculate the probabilities
of the things that we can see.
And yet we can never directly see the amplitudes, right?
The amplitudes are just, are only used
to calculate the probabilities of the things that we can see.
And so even though the amplitudes form a continuum,
you know, we would not really say
that we can usefully store infinite information into them
because as soon as you look, we don't see the amplitudes.
Yeah, yeah.
And I think this is what I was trying to get
because it's like, you know, you can make a, whatever,
a thousand qubits in the lab, right?
That's just a matter of making,
being able to make a qubit and making a thousand of them,
right?
And that's what I meant in the sense
of like hardware versus storing information.
And how the qubits kind of contain all,
I guess contain is in quotes,
I guess is the point you're trying to make,
contains all this information.
And somehow it's a little bit tricky
to kind of think about in terms of storing it all
in a classical way, right?
Right, right.
But now, you know, even after we've sort of understood
that point about, you know, that you don't get
to see the amplitudes and, you know, you don't, you know,
if I stored the complete works of Shakespeare
or all the digits of Pi in the binary expansion
of some amplitude, I couldn't then read it out afterwards,
right?
Even after, you know, all that,
like there's still something going on here
with this entangled state of a thousand qubits,
which is that even just to represent this state
approximately, right?
Forget about exactly now, okay?
Even just to approximate it to any reasonable precision,
you would already need something like two
to the thousand bits of information, right?
Yeah, assuming it's not infinitely many,
but exponentially more than you might have thought, right?
Assuming it's not a product state,
because if it were a product state, then you would,
then you would just, yeah, yeah, yeah.
But in general, it doesn't have to be a product state, right?
So, okay, so maybe we should come back to this point, okay?
Because now, you know, how do you create
these kinds of programs, right?
I talked about unitary operations
that act on only one qubit, right?
But we are not restricted to only those, okay?
So like I could have two particles
that, you know, each one would store a qubit
and let's say it's spin state or something like that.
Okay, but these, you know,
nature has interactions between particles, right?
If I bring two particles close to one another,
then, you know, some unitary operation could act
that couples the two particles together, okay?
And so let me give an example of that, okay?
So now we're gonna talk,
we were talking about a unitary operation
that acts on C2s, tensor C2, right?
So it better be a four by four unitary, okay?
And we can have such unitaries
which are not just tensor products of one qubit unitaries,
but which actually couple the two together.
So here is maybe the simplest example.
This, in quantum computing,
we call the controlled knot or the CNOT operation, okay?
And if you think about it, what it is doing
is it's saying the string 00 should be mapped to itself.
You know, I mean, you know, I can think of what it's doing,
you know, it's just permuting the basis states, right?
It's a permutation matrix.
The string 01 should be mapped to itself,
but now the string 10 should be mapped to 11
and 11 should be mapped to 10, okay?
So basically it's saying if the first bit is zero,
then do nothing, but if the first bit is one,
then flip the second bit, okay?
So in that way, it is coupling the two bits, right?
It's saying act on the second bit in a way
that depends on the value of the first bit.
Exactly, another way of writing it in a synced formula
would be x, y goes to x and then y plus x.
Yes, excellent, yes, good.
So yeah, you know, in quantum computing,
we like to use this notation of quantum circuits.
Actually, David Deutsch, who's the co-founder
of quantum computing, hates this term circuits
because, you know, they're not actually loops, right?
You know, they're not closed loops,
but they are, they're sort of, by a quantum circuit,
we mean a sort of list of what simple unitaries
you want to apply to your qubits in which order.
So when you draw them, they almost look like a musical score.
Yeah, but you know, we do have circuit boards that aren't loop,
I'm just wondering what sense of circuit is to be a loop,
I don't know, okay, anything else?
Yeah, yeah, yeah, you could call them, you know, networks
or whatever, okay, but we, well, I'm fine to call them circuits.
So what we do is we sort of list the qubits
from top to bottom, you know, with their initial states.
Like, so here I'm saying I want two qubits
that both start in the zero state,
which is like the traditional initial state
for a qubit to have.
And then I can say, now I want to Hadamard the first qubit,
okay, so I'm going to draw that like this.
So I should say, what is the Hadamard gate?
This is a very, very important one qubit gate.
Which is just this two by two matrix here, okay?
And the Hadamard gate has the very important property
that its square is the identity, okay?
So it's a little bit like that 45 degree rotation
that I had before, except, you know,
the minus one is now in a different place.
Okay, so it's actually a rotation
composed with a reflection, okay?
That's what the Hadamard is.
And you can think of Hadamard as just the gate
that switches you between two different orthogonal bases,
the zero and one basis and the plus and minus basis, right?
So like Hadamard of zero is plus
and Hadamard of one is minus.
And the reverse is also true.
Hadamard of plus is zero, Hadamard of minus is one, okay?
So now, you'll very often see Hadamard gate
on these quantum circuits.
So that would look like this.
And so now I've said, my first qubit is now
in an equal superposition of the zero state
and the one state, right?
So it looks like this.
Right, because that's the plus state, yep.
Yeah, that's the plus state, right?
And now that is still in tensor product
with my second qubit, which remains in the state zero
because I haven't done anything to it yet, okay?
But now I can use a C naught to couple the two qubits.
So let me draw a C naught, okay?
C naught looks like that.
So we call the top qubit the control qubit
and the bottom one is the target qubit, right?
Okay, and now C naught, remember it says
if the first qubit is one, then flip the second qubit
and otherwise do nothing, okay?
So let's see what that does.
I had zero plus one over square root of two,
tensor with zero, okay?
Now that is just the same thing as zero, zero
plus one, zero over square root of two, right?
I can take the tensor and I can distribute it
among the zero.
Of course, yes, that's right.
Okay, and by the way,
if I write something like zero, zero,
oh, I mean, that's just a shorthand for zero, tensor, zero.
Yes, yes, we've been using that shorthand implicitly
for a while now.
Yes, yeah, all right.
Okay, but now I do a C naught.
Okay, now everything in quantum mechanics is,
well, other than with the possible exception
of measurement, right?
All of the unitary transformations are linear.
Okay, since they're linear,
I can think about what they do
by just thinking of each basis state independently, right?
So what does a C naught do to this basis state zero, zero?
Well, it just maps it to itself, to zero, zero, okay?
But what does it do to one, zero?
Well, now it's gonna flip the second bit.
It's gonna make that one, one.
So when I do the C naught,
I get zero, zero plus one, one over square root of two,
and now I have an entangled state, okay?
So this shows how starting with two qubits
that were unentangled, both in the zero state,
I do a hat and a mart and then a C naught,
and then I can get an entangled state.
I can force the qubits to no longer have separate,
uh, uh, states.
Let me ask maybe a very naive question.
You could have also made this state
by just preparing zero, zero, preparing one, one,
and just adding them, I suppose, right?
Oh, you want to?
Yeah, but adding them is not a sort of physical thing
that I can physically do to my qubits.
Oh, I see.
It's a thing that I can do
in the mathematical description of my space of states.
I see.
But then there would still be the question,
what do I physically do to my qubits, you know,
that are in my magnetic trap or in my, you know,
my dilution refrigerator or whatever
in order to get that linear combination?
I see.
I see.
So I guess the whole point is that circuits are implementable
and circuits are a sequence of unitaries.
Is that the point?
Exactly.
Okay.
Exactly.
Yes, that's right.
So a circuit is kind of telling me,
what do I physically have to do to my qubits
and in what order?
I see.
In order to get the unitary transformation that I want.
Yeah, I mean, not being in the no, it's not, I say,
actually what you said is appalling to me
because as a mathematician,
adding two vectors is the most trivial thing you can do yet.
You say it's physically difficult.
On the other hand, it sounds like what you're saying
is that an arbitrary unitary is somehow physically
realizable, which is counterintuitive
because an arbitrary unitary
is like a complicated object, right?
Well, yeah, no, no.
So now everything is going to come down to a question of,
well, given a description of the unitary
that I might want on N qubits.
So the group of unitaries that act on N qubits
is going to be, I guess, U of two to the N, right?
So it's going to be, we're talking about two to the N
by two to the N matrices, right?
Which take like four to the N real parameters to specify, okay?
And so these can be immensely large objects, okay?
And now, a first question that you might ask
is just for any such unitary,
acting on some, let's say N is, I don't know,
100 or 1,000, I have some huge number of qubits.
Can any such unitary be decomposed
into just unitaries that act only
on one or two qubits at a time, right?
And that are the identity on all of the other qubits.
So can I sort of take any N qubit unitary
and realize it by one of these musical scores
by these quantum circuits?
Now, the answer turns out to be yes.
That is a theorem that one needs to prove, right?
It was proved in the early to mid-1990s, okay?
Is there a name for the theorem?
I think it's just like universality
of various sets of quantum gates.
Okay, we just call this universality.
So what was proven was that various sets
of one and two qubit gates have the,
in fact, even if I just took, let's say the C knot gate
plus the set of all possible one qubit gates, okay?
This already has this property of universality, okay?
Which means that by composing enough of those things,
I could get any unitary I want on any number of qubits.
And is there a bound on the length of that circuit?
Excellent, excellent.
Cause now, right, good, because now, you know,
you might say, aren't we done?
Haven't we just solved quantum computing theory?
Well, the reason why we haven't is that in general,
the number of one and two qubit gates that you would need
is going to grow like four to the n power, okay?
So, you know, if N is 100, right?
This could already be astronomical, right?
If N is 1000, like more than the number
of subatomic particles in the known universe, okay?
So, and we can see that this has to be true, right?
And the way that we can see that it has to be true
is just by accounting.
Like we can say, how many parameters does it take
to specify an N qubit unitary, right?
If we need four to the n parameters,
even just to specify such an object, right?
And so then, you know, the, if I have, you know,
much fewer than that number of gates, then, you know,
just even if I vary those gates, however I like,
I will generate a manifold whose dimension is just too small
to encompass the full unitary group, right?
And so just by counting dimensions,
I can see that four to the n must be necessary, okay?
Okay, but now this still, you know,
that was, that's kind of an abstract argument
and it doesn't, it tells me nothing
about how many gates would I need
to implement some specific unitary
that I might care about, right?
And so now we come to like the whole subject matter
of quantum algorithms and quantum complexity theory, right?
Which is all about, well, how many gates do you need
to do some particular unitary that will, you know,
produce some interesting behavior
that will help you solve some computational problem
that you would like to solve, right?
And so now what we always want
in quantum computing theory is we want
to apply unitaries where that I can compose using only a,
using a number of gates that is only polynomial
in the number of qubits, right?
So I want the complexity of my unitary to grow
only like the number of qubits raised to some fixed power.
What did you write here?
I couldn't tell.
I wrote n to the L of one.
Okay, okay.
Or, you know, n to the c power, okay?
So given any n qubit unitary,
I can define the complexity of that unitary
to just be the minimum number of gates that you might need,
you know, in any circuit that produces that unitary, right?
And then what we've just said is that for most use,
c of u will grow like four to the n, okay?
Yeah, let's take a step back here
because this is kind of like a general question
about the complexity of algorithms
and distinction of building your own handcraft algorithm
from the get go like Deutsch, Yosha and Grovers, et cetera,
right?
I just think that there are two different ways
of thinking about it.
I don't know, yeah.
Well, okay, no, I mean, you know, also, you know,
if you're, you know, building a concrete algorithm, right?
The first question that people will have for you is,
well, how many gates do you need to implement that algorithm?
Right?
The reason why Schor's algorithm was a breakthrough, right?
Was that, you know, it solves the problem
of factoring an n-digit number.
But, you know, the number of gates
that you need to do that is not exponential in n, okay?
Oh, sure.
It is only quadratic in n.
Yeah, I guess what I was trying to get at was,
I mean, maybe I wasn't clear enough.
In practice, do people come up with the unit,
some unitary and then try to look at the,
how minimal you can express it?
Or did they come up with the clever circuit to begin with
and then the value that circuit was
in the fact that it was short to begin with?
You see what I'm saying?
Yeah, that's a fair question.
People do it both ways.
Oh, I see, okay, got it, got it.
Either way, I mean, in that,
we can talk about the case of Schor's factoring algorithm
since that's the most famous quantum algorithm of all, right?
You know, in that case, Schor first knew
that he wanted a certain unitary operation,
what we now call the QFT,
the quantum Fourier transform, right?
He then said, now I have the technical problem.
How do I produce a small circuit?
Got it.
Okay.
That QFT.
Got it.
And he then was able to solve that problem.
Okay, that makes a lot of sense now.
Yeah, okay, okay, great, great, great.
Yeah, because I was thinking of Doge-Joseph,
it was like, okay, you just write the circuit, okay.
Well, yeah, right, so the issue is,
you said that Doge-Joseph had all the main ideas
and the issue is there were several years
where people knew about Doge-Joseph
and they were just not impressed, right?
Okay.
So Doge-Joseph was like the first quantum algorithm
that we ever saw that was not about
simulating quantum mechanics itself, right?
And it was able to get a clear speedup for something,
like for some classical task,
but the speedup was just not an impressive one.
So it was more theoretical than a practical interest.
Maybe there's just slightly, slightly more to say.
Because so the name of the game in quantum algorithms
is going to be that I have some problem that I wanna solve,
like find the prime factors of this number
or whatever it is.
And now in order to help me solve that problem,
I can initialize a whole bunch of qubits
into let's say the zero state,
then I can act on them via some network of,
or some circuit of a one and two qubit gates,
such as Hadamard and CNOT and various other gates.
Hadamard and CNOT by themselves actually will not be enough.
This is an interesting fact,
but I can have as soon as I throw in a few more
one qubit gates, then I can get a universal set
or at least an approximately universal set,
which is good enough in practice, okay?
And then at the very end, I have to measure my qubits.
So these little speedometers,
this is how we would denote the measurements
in a quantum circuit, okay?
And these sort of force the qubit to randomly collapse
to either zero or one,
and then we read out what's the outcome, okay?
According to that rule I said before,
that the probability of some outcome
equals the squared absolute value of its amplitude.
Right, and the key here is that measurement,
you can do it component-wise,
that's exactly what you're doing here, right?
Yeah, yeah, that's right.
I can also, I haven't really gone into this,
but I could also choose to measure some of the qubits
and not measure others.
Sure, that's right.
That turns out to like in a certain technical sense,
not be needed, right?
I could always, without loss of generality,
defer the measurements to the end, if I want to, okay?
But, you know, often in practice,
the way we think about quantum algorithms,
we will imagine measuring some qubits
even at intermediate stages, okay?
And certainly if I wanna ever correct my qubits,
then in practice, I will be measuring.
Yeah, actually maybe just to clarify,
when you measure, I guess,
because we had this discussion about
what's like physically realizable,
I guess are you always gonna measure
with respect to some relatively simple basis?
Because, which-
Yes, yes, good.
Right, so here I was just imagining
that I could just pick some individual qubit
and measure it in the basis zero comma one.
Right, right.
Okay, right?
And now, I'm like, if I just write this,
if I just draw this measurement symbol
and don't say anything else, then that is what it means.
Now, of course, if I had wanted to measure
in the basis plus and minus,
then I could have easily done that as well.
I mean, for one thing,
I could have just first applied the Hadamard gate
and then measured in the standard basis.
Sure.
Right, that'll have exactly the same effect
as measuring in the Hadamard basis.
Okay, I could also just invent a new symbol for it,
like measure in the Hadamard basis or something like that.
Okay, but I can't just write down some enormous unitary
on thousands of qubits and just plunk it into my circuit.
Like, oh, now I'm gonna apply that.
Right.
Like the engineer is gonna come back to me and say,
how do I actually realize that?
Right.
And by realize it,
they mean using simple operations
on only one or two qubits at a time.
Yeah, yeah, yeah.
I realized actually,
this is actually now obvious in hindsight,
because with all these things,
just like a unitary can act on the bra or the cat,
of course you can't have an arbitrarily complicated
bra vector because you could just shove
the unitary in there, right?
So it's sort of like, yeah,
that's basically the point.
So your bra had better be a simple vector as well.
Otherwise you could just smuggle your unitary
into there basically.
Yes, yes, yes.
Right, so we have rules against smuggling complexity
into your definitions, right?
Because then ultimately,
when you have to build the actual device,
then you will have to implement all the complexity
one way or the other, right?
Right, right.
So good.
Okay, so now what I've just told you about
is called the quantum circuit model, right?
And this is kind of a fundamental way
that we tend to think about quantum computation.
We think of a quantum algorithm in some sense,
is a quantum circuit, right?
That's right.
Or a little bit more precisely than that,
it is just a classical algorithm.
So just some piece of code
that can run on your ordinary classical computer,
but which will then output
a description of a quantum circuit, okay?
So if you actually walk into a quantum computing lab,
what you will see is usually some grad students
sitting at computers that are running windows
or Linux or something that are quite ordinary computers, right?
But they are hooked up to microcontrollers
that then have wires going into a dilution refrigerator
or lasers that can control the ions in a trap
or something like that.
So the classical computer is sending instructions
to sort of tell these devices
which gates to apply to the qubits.
Sure.
Maybe the way to say it is the circuit
is basically a classical API.
And then there's some backend
that translates that into a quantum implementation
because what you don't wanna do,
and this is the whole point,
what you don't wanna do
is write out the full unitary as a classical matrix, right?
That's right.
That's right.
And we also don't wanna play any tricks where we say,
well, even just to the quantum circuit
that I have in mind is a quantum circuit
whose very description encodes the solution
to the halting problem or something like that, right?
And then you say, okay, great.
Well, now, again, the engineer says,
how do I write down that circuit, right?
So what you have to do is you have to give them
a classical computer program,
they can run on the classical computer
and that will generate the quantum circuit
that will sort of generate the instructions
to send out to the qubits to say,
which simple unitaries do you apply to which qubits when?
And ultimately, that is what we mean by a quantum algorithm.
So I think because the halting problem, of course,
is famously not a subtle problem on a classical machine,
but what was this remark you make?
Could something about quantum computers,
are they able to do something special in this regard?
No, they're not.
And I just said the definition of what we mean
by a quantum algorithm is not allowed to smuggle things in.
Oh, I see what you're saying.
Okay, yeah, okay, got it, got it, okay, yeah, yeah.
Right, so this is why we say,
you need an ordinary computer program
that can output descriptions of the quantum circuits,
given the input,
given how many qubits you wanna be operating on and so forth.
Yeah, in other words,
a quantum computer is still a Turing machine in some sense,
in that you can't have these oracles
that just do magic things for you.
Yeah, exactly, exactly.
Now, I should say this was not the original way
that people thought about quantum computation.
Like David Deutsch in the 80s,
and then Bernstein and Vasarani in 1993,
when they tried to write down theoretical foundations
of quantum computing,
like their first idea was that you have to take
the whole notion of a Turing machine
and make it quantum.
Ah, I see.
So you have to have a quantum tape,
you have to have a quantum tape head
that can be going a superposition of moving left
and moving right,
and that can be entangled with the contents of the tape
and on and on.
Now, that turns out to be doable,
but tremendously complicated and nasty
to work out the details of.
And what people realized shortly afterward
was that the version that I told you
where you just have a classical computer
that is controlling a quantum circuit,
that is mathematically equivalent.
Oh, wow.
And it's a hundred times simpler to think about.
Yes, well, that's a great result.
Is that, is that?
Yeah, it is.
Are there some names associated to that?
Andy Yal, who actually won the Turing Award.
Not for this specifically,
but this was a paper of his in 1993.
Okay.
And yeah, so people realized that there is this equivalence
between the sort of quantum Turing machine
and quantum circuit models.
And the circuit model actually,
not only is it simpler to think about,
it corresponds more directly
to what the experimentalists will actually do,
which is use a classical computer
for everything that you can use it for
and use the qubits only where they're actually going to help.
Yeah.
I mean, I guess you could say this is one of the,
I don't know, rare triumphs of complexity theory,
where you actually know something's equal to something else.
No, I mean, we know many, many results
about things being equal to other things.
I mean, you know, we do, you know,
if that's the definition of a triumph,
then we have many, many triumphs of that kind.
Okay, okay, okay.
Although there's still a lot more to know.
Triumphs of the kind that look like P not equal to NP,
those are much rarer.
Okay, okay, okay.
Yeah, yeah.
Okay, great.
Okay, so, all right, so, so, so, so, do it, Joseph.
Yeah, let's do it.
All right, all right, let's do it.
So, you know, having defined this whole model
of quantum circuits, right?
You know, unfortunately, you know,
when you get to a concrete problem,
we almost never know,
like what is the smallest quantum circuit for that,
you know, for that, you know, to solve the problem we want
or implement the unitary that we want, right?
The best we can say as well, like, here's a circuit,
I know, maybe, you know, here's a better circuit, right?
But as for what is the best circuit, you know,
typically we've got no idea, okay?
And, you know, this is deeply closely related
to some of the hardest open problems
in all of computer science or, you know,
really math for that matter,
like the P versus NP problem, right?
And things like that.
We're just not very good at, you know,
proving that natural problems
require exponentially many operations,
even when we strongly suspect that that's the case, okay?
But now one thing that people realized very early on
is that there is one simplifying assumption
that you can make where you can start getting,
you know, immensely sharper answers, right?
About what is and isn't possible, you know?
And this is already true with classical computation,
but it's even more true with quantum computation, okay?
And so the thing that you do is that you switch attention
to a model that is called query complexity.
And it's also, it goes under other names.
There's also called the black box or the Oracle model, okay?
And so these all mean the same thing, okay?
But what they mean is that we're going to have
some kind of subroutine that computes some function, okay?
So like this, okay?
And the resource that we're going to care about
is how many calls to that subroutine do we have to make,
right, in order to learn some property
of the function that it's computed, right?
And the only way we get to learn about the function
is to call this subroutine, okay?
So we do not get to look inside of it.
We don't get to look at its code.
And, you know, that's why it's called black box, right?
It is, you know, like literally a black box, okay?
Now, in, you know, now, often this does model
how we think about algorithms, right?
Like you say, like, if you're trying to, you know,
do optimization, right?
You're trying to find the minimum of some cost function,
right?
And then often the way that you'll think about that
is just that we're given any solution,
you can evaluate what it's, you know, what is its cost.
And now you want to kind of move around
in the space of solutions to find a solution
that has the lowest cost, right?
But as you do this, you're just going to be treating
the cost function itself as a black box.
You're not going to be looking inside of it, right?
And in that setting, very often we can actually prove things
about what is the best possible algorithm
that you could have, right?
Maybe the analogy would be like if you do gradient descent
and machine learning, right?
Like I don't need to know what the definition
of the function is.
I just need to call, you know, dot grad basically.
And that's it.
Yeah, that's right.
So gradient descent, that would be an excellent example
of an algorithm that does use only black box access
to your function, right?
And, you know, and so then if we can show
that a problem is easy, even in the black box sounding,
then voila, we have a useful algorithm, right?
Whenever someone provides that black box,
then we just, you know, we just combine it with what we did
and get our algorithm, right?
So now what does this black box model look like
in the world of quantum computing, right?
Well, now the new twist in quantum computing
is that, you know, since everything is, you know,
quantum can be in superposition,
we also get to call our black box, our subroutine,
on a superposition of inputs, okay?
And get a superposition of outputs, okay?
So this is the gonna be the big new twist.
Yes, yeah, I have to say,
I don't know if I'm jumping ahead of it,
but I know I've looked at Doge Joe's several times
and I find that to be the biggest,
I don't know what to write to call it, leap of the...
Yeah, yeah, there is a conceptual leap here, right?
And the truth is, you know, if all you knew about
was Doge Joe's though, like it is not at all obvious
why there is any net gain.
Exactly, exactly, because it seems like
you've actually done a slight where you said,
well, I'm gonna work in a world
where my query complexity is larger
because another way you could say,
oh, here's an allowable query,
I'm just gonna write a really large vector,
evaluate F on every component of that vector,
and that's my new query.
So of course you're going to be able
to get away with fewer things.
Yeah, right, right, okay, but again, remember,
we're still subject to the limitation
that at the very end, you have to make a measurement
on your state to get a classical output, right?
And if I just had an equal superposition
over all the different answers,
and I just, let me show you what that looks like.
Yeah, sure, sure, okay.
So let's say that I have, you know, n qubits.
So now I could easily create an equal superposition
over all possible n-bit strings,
which will look like this, okay?
You know, and I could get that
by just taking my n qubits and hat-amorting them all.
Like this.
Yep, yep, yep, right?
So this is an easy thing to do, okay?
And then I could even take a function
and I could, let's say a black box function
and evaluate it on the superposition.
And that could give me a state that would look like this.
So I'm over all x of cat x tensor cat f of x, okay?
So I can sort of evaluate my function
on all possible inputs in superposition, right?
And, you know, and this is what makes
the popular articles all excited, right?
That now sounds like I get this free exponential
parallelism, right?
But so far, you know, I haven't yet done anything useful
because if I now just measure this superposition
not having done anything else, okay?
In the standard basis, then all I'm going to see
is some pair x f of x for a random x.
Right, let's just call it x star or something like that.
There's some x star, you just get one value.
Yeah, yeah, yeah, yeah, good, right.
And if that was all I wanted,
then I could have just flipped the coin a bunch of times.
Sure.
You could have the bits of x
and I could have saved all the billions of dollars
to build this quantum computer, right?
So the only hope of getting a speed up
from a quantum computer is going to be
to do something else afterwards, right?
Which is going to have to be some unitary transformation
on this vector that is going to choreograph
a pattern of interference that's going to cancel out
all the different contributions to the answers
that I don't want.
And it's going to produce constructive interference
on the answers that I do want.
Yeah, maybe let's pause here.
Yeah, because I think the key conceptual hurdle for me
is that, okay, so as you said,
there's a difference between the unitary operator
and then getting useful information through measurement.
But I guess what I'm struggling to understand is
how would you build this unitary operator
efficiently in the first place?
Because naively, to build it classically,
you would have to build this matrix
where you're evaluating f at every entry.
But somehow, by not having to measure,
you avoid that computation.
So how do you...
Oh yeah, okay, so that part I can explain, right?
Okay, okay.
Okay, this I can explain.
Okay, so what do we mean by a quantum black box?
So the most common definition would look like this.
Let me give it a name.
So let's say that I have some function f
that I'm interested in,
then I could define a unitary transformation,
which I'll call use of f, okay?
And what's it going to do?
All right, well, it should somehow take x
and give me f of x, okay?
But now, the catch is it's still gotta be unitary, right?
So I can't just take x and overwrite it with f of x, right?
Because if f is not a permutation,
then that won't be unitary, right?
Even if it is, I still might not know how to apply that, right?
I might still have exactly the problem that you said, right?
I can't just take x and then write f of x next to it.
Because again, if I'm just saying,
take whatever was next to x and replace it by f of x,
then that's also not unitary
because it would destroy information.
Whereas we know that every unitary transformation
is necessarily invertible, okay?
So the definition that turns out to work
is that I take f of x and I xor it into an answer register,
which is next to x, okay?
So I sort of write it into that answer register,
where if a was all zeros,
then I'm just writing f of x here, okay?
But if the answer register were initialized
to something else, then I would just be overwriting,
I mean, I would just be xoring f of x into that.
Yeah, so c naught is just u of f,
where f is the identity, correct?
C naught would be u sub f,
where f is the, yeah, yeah, that's right, that's right.
Yeah, exactly, good, good, good.
So, yeah, so you do the c naught kind of thing,
but just generalize to any f, right?
And this will be unitary, in fact,
the square of this is just the identity, right?
Because x or employees gives me back
what I started with.
That's right.
And now, there's a further very crucial fact, okay?
Which is that if I have an efficient program for f,
like just in the ordinary classical sense,
like I know how to compute f efficiently given x,
then I also get an efficient quantum circuit for u sub f.
Okay, so whenever f is efficiently computable,
then so is this u sub f, okay?
This is another theorem that one can prove.
Yeah, what does this mean exactly?
So it's going back to the c naught, right?
So like, obviously the ending map is very efficient
to compute, yet naively to compute u sub f,
you have to kind of run through every basis factor.
Right, but you don't, you don't.
Okay, so let's say that we're going to do
I'm saying that whenever I have an efficient algorithm for f,
so that's not going to be for every f, right?
Sure, sure, sure.
But whenever f is something that is efficiently computable,
then u sub f is as well.
So maybe it would be instructive
to go through why that is.
Yes, exactly, exactly.
So the first thing to say is that there are quantum gates
that can simulate like a universal set of classical gates,
like the and or and not gates, okay?
So and or and not are universal for classical computation, right?
Like any, when I say that f is efficiently computable,
I mean that it has a small circuit made of and or and not gates.
Okay, okay.
And, you know, which is sort of
equivalent to, you know, in the sort of non-uniform sense
to there being a polynomial time algorithm for f, right?
Okay.
And now there is this gate called the Toffoli gate.
Okay, Toffoli looks like this.
It's the controlled, controlled not gate, okay?
And so it's just the general,
generalization of the C not gate to three qubits, okay?
So it just says like, if I have three qubits X, Y and Z,
then I want to flip the third qubit,
if and only if the first two qubits are both one.
And otherwise do nothing, okay?
So, and now the key is that this,
this can now simulate an and gate, right?
Cause like, if I initialize Z to zero,
then what is going to be written in the third qubit?
It's just the and X and Y.
It can also simulate a not gate, right?
Cause like, if I just wrote,
if I put ones into X and Y,
then this is just going to map Z to not Z, right?
Once I have and and not,
then that's a universal set of classical logic gates, right?
So I can now do any,
by chaining together enough Toffolis,
I can do any classical computation that I want, right?
So quantum computation
can simulate classical computation, right?
You know, I've said, this is kind of like,
you could use the space shuttle to drive around the parking.
Right?
It's that kind of, you know, theorem, okay?
But now, so now, you know, remember what we wanted.
We wanted to take X comma A
and map it to X comma A
exclusive or with F of X, right?
So now our, you know,
and we know that we can compute F by some,
let's say by assumption, you know,
we can compute F by some short sequence of Toffoli gates, right?
But now are we done?
Well, not quite, okay?
There's one more detail that we have to worry about.
So the one thing that we still have to worry about
is that, you know, after I,
so I can take my input X
and I can do some network of Toffoli gates,
which I'll, you know, just to draw it schematically,
it'll look something like this and blah, this, this, this
and so on.
I can do some network of Toffoli gates,
which will give me, you know, X,
the answer that I want, F of X.
So, you know, I may be,
I initialize these Q bits to zero or something,
but then there could also be all kinds of scratch work,
which is leftover.
And the technical term for all of that stuff is garbage, okay?
So, you know, we could have a lot of garbage bits left over
in addition to F of X.
And so now I do not have the unitary that I want
because I've got all this garbage still hanging around.
And in quantum computing, that's actually a huge problem.
Garbage can prevent the interference phenomena
that you want from occurring, right?
And in any case, it means that I have not achieved
the definition from before, okay?
But now fortunately, there's a trick to deal with it, okay?
The trick is when you just have to clean up after yourself,
okay?
If you leave garbage, you just have to clean it up, okay?
But how do you clean it up?
So now the-
Okay, is this a schematic?
It's not a product of X, garbage, and F.
Otherwise, you could just-
Well, it's a tensor problem.
Oh, I see.
I mean, X, no, oh, so sorry.
Oh, right, right, right, right.
So, if X were a classical string, right?
I was assuming that X was just the classical basis state,
then what we will end up with is a tensor product.
Oh, I see.
X, tensor, garbage, tensor, F of X.
However, ultimately, we want to be applying this
to a superposition.
Got it, yep, yep, yep, yep, we see.
And then the garbage is now entangled with X.
Yes, yes.
And with F of X, and that's the problem.
Yep, yep, yep.
Okay?
So that's why we need to get rid of it.
Yes, yes.
Okay?
So, okay, so the key trick for doing this
was actually invented by Charlie Bennett in the 1980s.
And it's called uncomputing, or computing in reverse.
Okay?
And so what you're going to do
is you're going to take the final answer,
like let's say the final answer is here.
And after it's been, you know, F of X,
after it's been computed, you're going to C not it.
You're gonna C not it into the answer register A.
And then you're going to run your entire computation
in reverse, okay?
So every gate that you applied,
you're going to apply the inverse of that gate, okay?
And you're going to apply them in the reverse order
as you applied them, you know, going forward.
Okay?
So like if you had this, you know,
the Toffoli gate happens to be its own inverse.
So, you know, so that would just look like this.
Okay?
So the whole musical score reverses itself.
Suppose you have whatever,
you have this Toffoli gate, right?
Yes.
And so you have some other stuff, whatever.
So are you, is the reverse gate now the guy
that's just the mirror reflection?
Is that what you're calling in reverse?
Yeah, yeah, yeah, yeah.
So if my, look, if my, okay.
If my original sequence of gates was let's say G1 up to GK.
Yep.
Then my new sequence of gates is going to be GK inverse
and then GK minus one inverse and so on.
And finally G1 inverse.
Oh yeah, okay, yeah, yeah.
So it's just the, right,
the inverse of the associated unitaries.
Yeah.
It's literally the, it's literally the inverse.
Yeah.
Okay.
Yeah, okay.
So I'll just call it the flag.
Right, right.
So now the key is, you know,
if I had just applied the unitary and then its inverse
with nothing in the middle,
I would have just done a very fancy implementation
of the identity, right?
But I was careful to write down to copy the answer
at the very, you know, in the middle.
Oh, that's brilliant.
Yeah, yeah, yeah.
Okay.
And so now what I end up with is just my input X
and then AXOR with FFX, right?
Which is what I wanted.
Okay.
So that is the uncomputing trick.
That is how given any efficient algorithm for F,
I get an efficient quantum circuit
for querying F on a superposition of inputs.
Okay.
So I get use of F.
Okay.
Yeah, I think I know enough to fill in the details,
but let me just verbally state.
So, okay.
So basically,
since F by hypothesis was simple to compute classically,
you stack the appropriate quantum gates to implement F.
Basically, you kind of shove it into a CNAA gate
in some sense, so that you can kind of,
so that you can kind of have this scratch bit
that will record F, right?
And then you do this reversing trick
to erase all the intermediate stuff you don't care about
and boom, there you go.
That's right.
Yeah, yeah, exactly.
Exactly.
Okay.
All right.
Now, to explain the Deutsch-Joseph algorithm,
okay, the one further detail that I need to say
is that we can, if F is a Boolean function,
so like if the output of F is just a zero or a one,
then I can actually have
this behavior where I will take
F and I will write it into the amplitude
of the basis state X, okay?
So I will multiply the amplitude of cat X
by minus one to the F of X power, right?
And how do I do that, right?
Well, one way to do it, all I have to do,
I actually give this as a homework exercise
and like undergrad quantum computing course,
but I'll give it as a freebie, okay?
So it turns out all you have to do
is just do that use of F that I explained before.
But now have, initialize A,
the answer register to the plus state.
Ah, yeah.
Here.
Yeah, yeah, yeah.
Yeah, yeah.
Okay, let me just say, so here is X, okay?
And what you can show is that the answer register
will always be left in the plus state.
You know what?
Not the plus state, the minus state, I'm sorry.
The minus state.
Oh yeah, of course.
It's not gonna work.
Minus state, okay?
So I initialize the answer register A to the minus state,
okay, and then the minus state has the property
that if you apply a not gate to it,
then it maps minus two, minus two.
Right, the point, the special thing about the minus state
is that whenever there's a bit flip, there's a sign change.
That's exactly what minus one of the F is doing.
Yeah, yeah, yeah.
Yeah, exactly.
So it does this.
And this is in practice, you know,
whenever F is a Boolean function,
this is often how we wanna think about a query to F,
you know, as you're writing the answer into the amplitude.
Okay, you know, yeah, so the thing is that
the only quantum computing book that I've consulted
based on my, you know, a non-experience with the subject
has been Nielsen and Chuang.
I should look at your book, of course,
but I've only looked at Nielsen and Chuang
and they don't go into, all this backfill
would have been so helpful for me,
because I was like, never by this black box.
Well, yeah, no, no, no, there are plenty of books
that explain this.
You could also look at my undergrad lecture notes,
you know, actually is actually even more so
than quantum computing since Democritus,
because that was kind of, you know,
that my Democritus book was based on lectures
that I had given for students
who already knew all this stuff.
Oh, I see, okay, okay.
Explain something, you know,
something more philosophical to them,
but my undergrad lecture notes that are on my homepage,
I do carefully explain all of this.
Great, great, okay.
So, all right, so now, you know,
knowing that we can make those phase queries, right,
and that it only costs the same as a normal query.
Okay, now what is the Deutsch-Joseph algorithm, right?
Well, so now what we're going to imagine
is that F is just a function mapping one bit of input
to one bit of output, like that.
Okay, so, you know,
there are only four possible such functions, right?
There's the constant zero function,
the constant one function, the identity function,
and the not function, right?
Okay, and now what do we want to know?
We want to know the parity of F of zero and F of one.
Okay, so this is what we want.
Okay, and now we can ask how many queries to F
are necessary and sufficient to get this information,
you know, the XOR of the two different F values, right?
And like, you know, if I ask this classically,
like this is a completely trivial question, right?
The answer is two queries, right?
You know, I can, I have a choice, I guess,
which one to learn first, right?
But whichever one I learn,
I still got to learn the other one, right?
Or else I don't know their parity, right?
So we could say the classical query complexity
of this problem equals two, okay?
And now what we want to prove is the remarkable result
that the quantum query complexity of this problem
is only one, okay?
So it is half of the classical query complexity, okay?
And this is the, you know, this was historically
the first example of a quantum speedup in query complexity.
As I said, not very impressive.
It is merely by a factor of two,
which normally in theoretical computer science,
like we don't even bother to count constant factors.
Yeah, I think historically,
this was the first case that Deutsch worked out
by himself, right?
So this is another Deutsch algorithm.
This was actually, actually,
Deutsche didn't even do this
because it only worked with half probability, okay?
Okay, okay.
So this is still a special case.
No, and then, and then, and then Deutsche,
I think Deutsche and Joe's kind of corrected it later.
I see.
But I've been saying,
if I've been saying his name wrong,
I've said Yoja, but is it Joe's, is it J, or J?
Oh, I see.
I wish you corrected me earlier.
I just thought that some of the Js.
Yeah, no, no, no, no, no, no, no, no, no, no, no, no, no,
then there is a generalization of it to end this,
but yeah, that to me is not, you know,
it's again going to be a constant separation
if we do a fair comparison between the quantum algorithm
and a classical probabilistic algorithm.
So it's, you know, so we might as well
just do the case with one bit, I think.
I see.
Yeah, yeah, yeah, yeah, of course.
Let's just keep it simple.
Yeah, yeah, yeah.
Okay.
Yeah, even simpler, right?
Yeah, yeah.
Okay, so now how are we going to learn,
so now this is the question,
how are we going to learn the XOR of two bits
using only one query, right?
Well, clearly we can't just query the bits one at a time,
right?
We're going to have to query them in superposition, okay?
What I'm going to do,
well, I can just write this,
I can just write it in circuit notation
and then we can talk through it, okay?
So I'm going to start with a qubit in the state zero.
I'm going to Hadamard that qubit,
which puts it into the plus state,
the equal superposition of zero and one, okay?
And then I'm going to query F,
so I'm going to apply that use of F
and you can see that I've taken the answer qubit
and I've initialized it to the minus state
in order to get that phase query behavior, right?
And then there's just going to be one more Hadamard gate
and then there's going to be a measurement, okay?
This is the entire Deutsch-Jose algorithm.
Okay, now we just have to explain what it's doing, okay?
So, all right, so as I said,
the zero qubit is going to be mapped by the Hadamard
to the plus state,
which is also called zero plus one
over the square root of two, okay?
Now, we're going to apply this use of F,
which as I said is going to act as a phase query,
which is going to do this.
It's going to give us...
Okay, so now you're keeping track only at the first bit, right?
We've kept the minus bit fixed on the second...
Yeah, that's right, that's right, yeah, exactly.
I don't care about the...
The only purpose of the second qubit
was to get this phase query on the first qubit, right?
And this is actually a very common thing
in quantum algorithms.
So, Deutsch-Jose actually has a structure
that recurs from one quantum algorithm to the other.
Like step one is to just create an equal superposition
over all different inputs.
Step two is make a query on that superposition, right?
Step three is throw away the answer to the query.
And then you say like, wait a minute, what?
What was the point of making the query
if I don't even look at the answer, right?
If I throw away the answer register like that, okay?
Well, it was the only reason I cared about the query
was because of the effect
that making the query had on my input register.
Can you map your terminology
to what's going on in the circuitry?
So this is the...
Yeah, so the first, the top one is the input register.
Yeah, okay, yep.
The second one is the answer register.
Yep.
Okay?
Mm-hmm.
And now, you know, I am making a use of F
is applying a query that will write the value
of F of zero or F of one into the answer register.
But the only reason I care about that
is because of the effect that it will have
on the input register.
Yes, yes, yes.
Okay?
And again, you know, again, this is very, very common,
you know, Simon's algorithm, Bernstein-Vasarani algorithm,
Schor's algorithm, you know, the core of Schor's algorithm,
Grover's algorithm, they all have
that same kind of character, okay?
Yeah, yeah, right.
So just, yeah, just to wrap this up.
So you only care about this guy
and this thing is just,
it doesn't matter what's going on anymore, yeah.
That's right.
It doesn't matter anymore what's going on
in the answer register, okay?
Yeah, okay, good.
And now what we're doing is, okay,
so I applied use of F in order to get this state here,
which it looks like minus one to the F of zero, zero,
plus minus one to the F of one, one, okay?
And now what I'm doing here is I'm taking that qubit
and I am measuring it in the Hadamard basis.
Okay, right, I mean, you know,
that's what a Hadamard followed by a measurement means, right?
Now I'm checking to see like,
is that qubit plus or minus, right?
And now here is the key observation, okay?
Suppose that F of zero equals F of one, right?
Which is to say, suppose that their parity is zero, okay?
If F of zero equals F of one,
then this state at the bottom here is the plus state, right?
Well, it's either the plus state
or else it's minus the plus state,
which as we said is just the same thing
since global phase doesn't matter, right?
Okay, now suppose on the contrary
that F of zero is different from F of one,
which is to say, suppose that the parity is one, okay?
In that case, this state down here is the minus state,
right?
Because I've got either zero minus one
or else I've got minus zero plus one, right?
Which is either the minus state
or else minus the minus state, okay?
Yes, so let me just write this out in cases.
So this is either gonna be plus
if F of zero equals F of one,
or plus or proportional, I guess,
it's gonna be proportional to,
and then it'd be minus if F of zero is not equal to F of one.
Right, okay.
Yeah, yep.
Okay, yeah.
So that's the Deutsch-Joseph algorithm.
Yeah, and in terms of the accounting,
it's sort of like four became two
because the overall phase didn't matter.
I don't know if that's the right way to think of it,
but I'm just looking at the numerology right now.
Yeah, right, right.
You could also say like we only got out one bit at the end.
Like if we had wanted both F of zero and F of one, right?
We could not have gotten both of them, right?
But the one bit that we got out happens to have been
the parity of F of zero and F of one,
which is the one bit that we wanted, okay?
So that's one way to think about it.
Another way to think about it is like
if you just explicitly wrote out all of the contributions
to the amplitudes, you could say,
look, when I make this measurement at the very end,
there are sort of two different contributions
that could have given me the output
that is not the parity, but they canceled each other out.
One of them was positive and the other one was negative.
And so I get a destructive interference.
Like if I just multiply out the matrices explicitly,
then I'll see that.
Like if F of zero equals F of one, for example,
then I could calculate the final amplitude
of the state of the output one
as like a half minus a half, right?
So it'll be zero, right?
So whereas the final amplitude of the state zero,
which is the output I wanted,
that one will be a half plus a half, it'll be one, okay?
So in this case, I get perfect
constructive and destructive interference, right?
It gives me an amplitude of one on the correct answer,
the one I wanted, and it gives me an amplitude of zero
on the incorrect answer.
Yep, yep, yep, yep.
You say like this is like the paradigm case, right?
And then in every other quantum algorithm,
you are trying to, you know,
for some much more interesting and more impressive problem,
but you're trying to do something
that in the best case will be approximately like that.
Mm, yes, yes, okay.
Wow, this is great.
So actually, I think maybe this is a good segue
into what BQP is,
because I think you just basically alluded to that, right?
You just walked right into it.
Yeah, so okay, so let's just recap really quick.
So we've set up the qubit language
and explain what's magical about quantum physics.
We've now explicitly shown an example
of where there's a quantum, I mean,
quantum complexity reduction through the query structure,
let's say, and then now the next thing to do
is to kind of take a step back and to look at
what is the relationship between quantum complexity classes
and classical complexity classes?
Because this isn't really,
well, first of all, this is not a useful problem,
but second of all,
this isn't really a speed up in any meaningful way
in terms of like, you know,
reducing the search complexity or whatnot, right?
So I think, I mean, what we talk about next
will be clarifying about that.
I mean, to be clear,
computing parity can be useful, right?
But it's just that all that Deutsch-Jose gives you
is that you could compute the parity of n bits
using n over two queries, right?
So it's a factor of two speed up
and then, you know, in the way that you would do it
is you take your n bits,
you just group, you pair them off,
you just, you know, split them up into pairs,
you run Deutsch-Jose on each pair separately, right?
That gives you your factor of two, right?
And then it's not even kind of a real speed up
because then you would have to get the final answer,
you have to take the parity of all those final bits anyway,
right?
And there's another n over two.
So it's only a factor of two savings
in terms of query complexity,
not in terms of the total number of steps, right?
So, yeah, so as you said,
it's not really directly useful, right?
The Deutsch-Jose, but then, you know,
and there were people who saw it and said,
you know, that's probably going to be the general case, right?
You know, it's just like, it's, you know,
actually apparently assignment.
So Shor's factory algorithm grew out of an earlier quantum
algorithm called Simon's algorithm, right?
And Simon's algorithm came about because Simon apparently
looked at Deutsch-Jose and did a later thing
called Bernstein-Vasarani.
And Simon said, I really don't think that these quantum
speed ups are, you know, are that impressive.
And let me try to prove that kind of you never get
an exponential quantum speed up for like, you know,
in a truly interesting sense.
And that turned out to be false.
And Simon's algorithm was the counter example, okay?
It was still for a quite artificial problem,
but in that case, it was an exponential speed up
where you can show that any classical algorithm,
even a probabilistic classical algorithm, you know,
must make at least like two to the N over two queries
to this function F in order to learn a certain property of it.
Whereas there is a quantum algorithm
that makes only N queries.
So Simon's algorithm was the first example
of an exponential speed up for one of these query complexity
or black box problems, okay?
That, you know, it had, it was this kind of reduction, okay?
And then the story goes that Simon submitted his paper
about that to, you know, one of the premier conferences
of theoretical computer science,
which is called stock or Fox, and it was rejected, okay?
It was rejected because people said,
well, this is just this black box model, right?
Like who knows if this is telling us anything
about the real world, right?
And, you know, it doesn't seem that interesting, okay?
But there was one guy on the program committee
who said, I think it is interesting,
and that was Peter Schor.
And so then Peter Schor said, well, it seems clear
that if you just change the black box problem
to one that looks a little bit different,
that's like about, you know,
finding a hidden structure in a different abelian group,
like Z mod N instead of Z2 to the N, right?
Then, you know, you would get finding the period
of a periodic function, right?
You would get a fast quantum algorithm
for a period finding.
And then, you know, it was obvious to Peter Schor,
albeit not to most people, right?
That if you could find the periods of periodic functions,
then just through some classical number theory,
you would also be able to quickly factor large numbers
and calculate discrete algorithms, okay?
Which would then break, you know, most of the cryptography
that is relied on for the, you know, on the internet, okay?
So, you know, and now to work out all the details of that,
you know, took Schor like a year, okay?
So he had to figure out, you know,
what is a small circuit
for the quantum Fourier transform, for example, okay?
But, you know, he ultimately did all of that.
And that was, you know, that was then what put quantum computing
kind of on the map as a field,
rather than just as an idea that, you know,
a few odd balls had worked in.
What year was that?
That was 1994.
I see, okay, when Schor's algorithm came out.
Yeah, that is when Schor's algorithm came out, right?
And that's,
so,
yeah, I think assignment's algorithm
was actually earlier in 1994.
So that was kind of a crucial year
for the history of quantum computing, right?
Okay, okay.
Okay, but so now you asked me, you know, what is BQP?
Yeah, right.
So in some sense, you know, BQP,
well, it stands for
bounded-hour quantum polynomial time.
And I'm not gonna try to write that with my finger.
Sure.
But that is the central object of study
in quantum computing theory.
And you can think of it as the class of all of the problems
that are efficiently solvable using a quantum computer.
Right, up to some bounded error.
Up to some bounded error, exactly.
So, you know, we will allow the quantum computer
to make, you know, to have, you know, so formally,
it's a class of only of yes or no questions,
like what we call decision problems in computer science.
Okay, and this is not a huge,
this is not as big of a restriction as you'd think
because many other problems can be phrased
as decision problems, right?
Actually, yeah.
Yeah.
Yeah, I was wondering.
Yeah.
The bounded error, how essential is that?
Yeah, yeah, so that is pretty essential.
Okay.
So, you know, because in practice, most, you know,
so the Deutsch-Jose algorithm,
which we saw was an exact quantum algorithm, right?
It had no error in it.
Okay, with most quantum algorithms,
we do not get that lucky.
Okay, with most quantum algorithms,
the interference that we're able to arrange
is, you know, is pretty good, but not perfect, right?
Which means that there will be some probability
of measuring and seeing the wrong answer, okay?
But, you know, computer scientists have understood
since the 1970s, if not earlier, right?
That as long as the probability of a wrong answer
can be bounded, you know, is small,
then it's just not a big deal at all.
And the reason is simply that you always have the option
to repeat your algorithm a whole bunch of times
and then output the majority answer.
Sure.
Just like if you had a bias coin with a slight edge,
you could just keep flipping it over and over
until the overall edge you get
exceeds whatever threshold you have.
Yeah, exactly, exactly.
It's just the law of large numbers, right?
So like as long as on every input,
your algorithm has at least a two-thirds chance
of getting the right answer, right?
Then, you know, if you wanna be more confident in that,
then all you do is you rerun the algorithm,
say a thousand times, right?
And in computer science, we don't really care about a thousand,
not just some constant factor, right?
And then, you know, you take the majority
of all the outputs and at that point,
the chance that, you know, your computer would have,
you know, the chance that your algorithm
would have given you the wrong answer
because of some gigantic fluctuation, you know,
is probably smaller than the chance
that like an asteroid would have just hit your house
at that exact moment, right?
Sure, sure.
So you're not really worried about it anymore.
How about this?
In terms of complexity, if you did not allow bounded error,
do we know that to be strictly a subset of BQP?
Well, we, you know, we know almost nothing
to be strictly a subset of BQP.
Oh, okay.
Because like, we don't even know
that P is strictly a subset of P space, for example.
Oh, I see, although this is about determinism
and not determinism, I thought maybe there'd be
a different kind of...
Yeah, yeah, yeah, yeah, right, right, right, right.
But now, like, if we looked at the version with no error,
which is called EQP, or Exact Quantum Polynomial Time.
Okay.
Like in some sense, like, it's not even very well-defined
as a complexity class.
And the reason for that is that, you know,
which EQP you get might depend on your choice of gates.
Okay, so like which...
So depending on which set of gates you allow,
you might get a different set of problems
that are exactly solvable, right?
Whereas with BQP, you don't have that problem.
Wouldn't you solve that problem
by like taking the union over all circuits or something?
Well, yeah, but you still need some way to specify
which gate you have at a given moment, right?
Okay.
Like you're, again, you need a classical computer program
that can output a description of the quantum circuit, okay?
Which means it needs some finitary way
to refer to the gates, right?
And if there's a whole continuum of gates,
then most of the gates will have no finite description, right?
Okay, okay.
So, okay.
So you could say, all right, I want to allow all gates
with rational, you know, matrix entries,
or I want to allow, you know,
just this particular finite collection.
Oh, I see, I see, I see.
Or you could even say all gates with computable entries.
All, you know, there's a nice thing with that, right?
And then, you know, as far as anyone knows,
you know, the EQP might be sensitive
to those kind of low level choices, right?
I see, I see.
And now the truth is that in actual practice
in building a quantum computer,
none of that would ever matter.
Right, because there's already noise and things like that.
Yeah, exactly, you've got so much noise
in the system anyway, right?
Okay, got it, got it.
And so then, you know, in some sense,
BQP is the much more robust and natural complexity place,
right?
And it can be proven to be insensitive to those choices
of like exactly which set of gates do you do that.
So, you know, in computer science,
one of the main things that we try to do
is we try to understand the space
of all computational problems
and sort of organize that space
in terms of what are called complexity classes, right?
The classes of problems that are solvable
within different kinds of resource constraints, okay?
So the most basic complexity classes
are first of all, there's P,
which stands for polynomial time, right?
And this is just all of the decision problems, you know,
so like families of yes or no questions
for which there is some algorithm running
on a standard computer, you know,
that will solve, you know, deterministic, you know,
that will solve each instance of the problem
and that will use an amount of time
that is polynomial in the length of the instance, right?
At most the number of bits raised to some fixed power, okay?
So examples of problems in P would be like,
I give you a graph, you know,
or like a description of a graph by a string of bits.
Now, is that graph connected?
Like is every vertex reachable from every other, right?
This is, you know, like every undergrad in computer science
would learn how to solve that problem, you know,
breadth-first search or depth-first search
or some algorithm like that.
Another example would be,
I give you an integer written in binary,
is it prime or not, right?
That's a much more non-trivial example, okay?
That one was only proven to be in the class P in 2002
in a breakthrough by Agrawal, Kyle, and Saxena, right?
It had been known long before that
to have a fast probabilistic algorithm, okay?
But the deterministic one was it was a big breakthrough.
Okay?
So that's, yeah, good.
So primes is in P, right?
Yeah, yeah, so that's P.
And now the second most famous complexity class after that
is called NP, which stands
for non-deterministic polynomial time, okay?
And this is, you know, intuitively,
it's the class of all of the decision problems
for which whenever the answer is yes,
there is a short proof that can be efficiently checked, okay?
So there doesn't, so I'm not saying
that there has to be a fast algorithm
to find a solution.
I'm just saying that if there is a solution,
if there is a positive solution,
then it must be efficiently checkable,
you know, once you've seen it, okay?
So a classic example of a problem in NP would be factoring.
Like I give you a huge integer
and I asked you to find its prime factorization, right?
Now, technically I would have to rephrase this
as a decision problem somehow.
Like I could ask, for example, given this integer,
does it have a prime factor ending in a three, you know?
Right, you know, but if I can answer all the different
yes or no questions about the prime factorization,
then I can easily recover the prime factorization itself.
So often we'll just be sloppy
and we'll talk about factoring itself as an NP problem, right?
And so now the key point is that, you know, given, you know,
if I give you, let's say a 10,000 digit integer, right?
No one knows any fast algorithm
running on a conventional computer
to find its prime factorization, right?
And every time we order something from Amazon
or, you know, we visit any HTTPS website, you know,
our data is being protected by a crypto system
that depends on the belief that factoring
and some closely related problems are hard, are not in P, right?
Do not have polynomial time algorithms, okay?
But, you know, the factoring problem
is easily seen to be an NP, which means, like,
if I, you know, claim to you that, yes,
this number does have a prime factor ending in three
and you say, well, I don't believe you, right?
There's always a way I could convince you of that,
which is, I just show you the factor, right?
I say, here it is, okay?
And now if you're given that factor,
you can very easily check it.
I mean, first of all, I already said
that primality testing is in P, right?
So you can check that it's prime, okay?
And you can also check that it divides the input number, right?
That's, you know, at least using a computer,
that's a very easy thing to do, is a division, right?
So the factoring problem is a perfect example
of an NP problem, which might, you know,
which might not be in P, right?
But where the answers are easy to check, okay?
Now, I should say that P is a subset of NP, okay?
So every P problem is also an NP problem.
And this is simply because, well,
if you can solve a problem yourself,
then, you know, you don't even need the witness, right?
For the yes answer, right?
The witness to the yes answer
can just be the empty string or something, right?
So, okay.
And now the super famous question
that sort of is sort of the defining question
of theoretical computer science itself, if you like,
is the question, is this a strict containment?
So is P equal to NP, okay?
And, you know, hopefully, you know,
I don't have to make the case to people listening
of the importance of this problem.
I mean, it's been featured on the Simpsons and Futurama,
you know.
I didn't know that, okay.
Yeah, yeah.
That's not the main reason it's famous, but okay.
Yeah, yeah, that's right.
No, but it's one of the clay millennium problems.
It's, you know, and I would personally put it forward
as the most important of the clay millennium problems, okay?
And the argument for that is simply that with P equal to NP
and via an algorithm that was very efficient in practice,
then it would not only mean that, you know,
and you could prove that,
it would not only mean that you could solve that clay problem,
it would mean that you could program your computer
to solve the other six, right?
You could just say, is there a proof
of the Riemann hypothesis that is at most like,
in some formal language like ZF set theory,
that is at most 100 million symbols long, right?
And if such a proof exists,
then you should be able to find that in time
that is linear or quadratic or whatever in 100 million, right?
And so on for every other mathematical question, okay?
So in some sense, P versus NP is really asking
about to what extent can mathematical creativity itself
be completely automated, right?
You know, as soon as I tell you that a problem is efficiently,
that solutions to it are efficiently checkable,
does that also mean that the solutions
are efficiently findable, okay?
And most of us would conjecture that the answer is no.
You know, I like to say that if we were physicists,
we would have just declared that to be a law of nature
and maybe given ourselves Nobel prizes for it, okay?
But, you know, by mathematical standards,
it has to be called an open problem, okay?
So now a major role in this story is played
by what are called the NP complete problems, okay?
So let me just put at the very top of NP,
drawing the line to not include factoring, okay?
These NP complete problems, informally,
these are the hardest problems in NP, okay?
And what that means is a problem is NP complete
if number one, it's in NP.
And number two, an efficient algorithm for that problem
could be efficiently transformed into an efficient algorithm
for any other NP problem, right?
And so, you know, that sounds like a weird concept
the first time you hear it, right?
Because it's like a priori, like is it even clear
that there are any NP complete problems, right?
But what turned out in the early 1970s
was that not only do there exist NP complete problems, okay?
But the great majority of the problems that people care about
in like combinatorial optimization and, you know,
scheduling and all kinds of practical fields are NP complete, okay?
So, you know, three coloring a graph, like, you know,
color a map with three colors
so that no two neighboring countries are colored the same.
You know, I give you a map and I ask, can that be done?
That is an NP complete problem.
I give you the social network of Facebook and I ask you,
are there, you know, a thousand people
who are all friends with each other, right?
Find the maximum clique in this graph.
That is an NP complete problem, okay?
I give you the dimensions of a bunch of boxes
and I ask, can all of these fit into the trunk of your car?
You know, that is called packet.
That is an NP complete problem.
Yeah, some people might have experience with that being,
you know, a hard combinatorial problem, okay?
Minesweeper, you know, if you've played that,
turns out to be NP complete, right?
And Sudoku, okay?
So, you know, in addition to much more significant things
like finding a proof of a theorem of bounded lengths, right?
Okay, and so, if any NP complete problem were in P,
then all of them would be
and then in fact, P would equal NP, right?
If any one of them is not in P, then P is not equal to NP.
Okay, so those are the stakes.
And, you know, these are not the only complexity classes.
So, for example, you know, just above NP, even above NP,
we have this class called PSPACE,
which is everything that a classical computer could do
with a polynomial and N amount of memory,
but possibly an exponential amount of time, right?
And then even above PSPACE, we have what's called EXP,
which is what you can do in an exponential amount of time
and possibly also exponential amount of memory, right?
So, okay, now if you ask like,
which of these containments are strict, right?
So, what we know is that P is contained in NP,
NP is contained in PSPACE,
and PSPACE is contained in EXP, okay?
And now if you ask which of these are strict,
well, we have known since the 1960s
that P is strictly contained in EXP, okay?
This is called the time hierarchy theorem, okay?
It was proved by Hartmanus and Stearns.
Hartmanus was one of the founders
of computational complexity.
He just passed away this year, okay?
But since now knowing that P is not equal to EXP,
of course that tells us that either P is not equal to NP
or NP is not equal to PSPACE,
or PSPACE is not equal to EXP, right?
At least one of those three must be true.
Most people's guess is that all three of them are true, right?
That all of these containments are strict,
but that is what like,
it will take a revolution in mathematics
before we are able to prove statements of that kind, okay?
These have all been open problems
for more than half a century, okay?
So now into this, you could say that there's already
incredibly like difficult and rich space
comes waiting BQP, right?
Quantum polynomial time.
And so now, of course, the key question
of quantum complexity theory is, well,
how does BQP fit in, right?
Like, or how does, you know, making things quantum
actually, you know, change this picture, right?
And so, okay.
So the first, you know,
this was exactly the question
that Bernstein and Vasarani studied in 1993
when they, you know, wrote their now seminal paper
which defined the class BQP, right?
And then kind of asked all the obvious questions about,
well, where does it fit in, right?
And so, some of the things they showed
are that first of all, BQP contains classical P, right?
This is not a great surprise, right?
I already told you about how the Toffoli gate
can be used to simulate classical computation, right?
So, okay.
So whatever a classical computer can do
in principle, a quantum computer can do as well.
It might be ridiculous overkill to, you know,
to use it for that.
It's not even in principle.
It's an explicit algorithm to do it.
Yeah, that's right.
Yeah, that's right.
Okay, yeah.
That's right.
Okay, and then now another thing that they showed
is that BQP is contained in P space.
Okay.
So they showed that, you know,
you can always take an efficient quantum algorithm
and you can simulate it classically,
possibly using exponential time,
but in any case, using a polynomial amount of memory.
I'm trying to think, I see, because I'm trying to think,
if you did all these matrix multiplications,
you never need more than to store, you know,
like maybe like one bit at a time or something like this.
Yeah, kind of like that.
Right, okay, so maybe to step back,
the first point I should make
is that BQP is contained in X, right?
Okay.
So, right, I mean, you know,
that would be the weaker result here, right?
So anything that a quantum computer can do
in polynomial time, a classical computer
can also do in exponential time, right?
Which means that there is, you know,
quantum computers cannot change
the theory of computability.
Like there cannot be a quantum algorithm
for the halting problem, for example,
because if there were,
then there would also be a classical algorithm,
which is what Turing proved was impossible, right?
And why do we know this?
We know this because you could always
just take a quantum algorithm
and simulate it classically
by just writing out the entire quantum state,
writing out the entire wave function, right?
And, you know, there is one little observation
that you need to make,
which is that you don't need to represent
the amplitudes to infinite precision, right?
Just, you know, because of the assumption of bounded error,
you know, in the BQP, right?
It is enough to represent each amplitude
to just, you know, a reasonable number of bits of precision,
right?
You know, you can just in exponential memory
just write down the entire amplitude vector
and then simulating the quantum computation
is a simple matter of doing a bunch
of matrix vector multiplications, right?
Okay, and, okay, but then, you know,
Bernstein and Vasarani proved a stronger result.
They showed that BQP is contained in P space.
Now, why is that true?
Well, for anyone who has studied physics,
I could say the answer in one phrase.
It's because of the Feynman path integral, right?
We could say, you know, it is because you can always,
you know, in quantum mechanics,
if you're trying to calculate an amplitude,
you can always write the amplitude as a sum
over exponentially many different contributions.
I see, and so since you have a cumulative sum,
you just need to keep track of the state
at one state at a time, essentially.
Yeah, precisely.
And you can then evaluate that sum
by just reusing the same memory over and over.
Yeah, and I think explicitly what I said in terms like,
you know, to keep track of a matrix multiplication,
you know, you can kind of do things like, you know,
like entry by entry or something like that.
Your scratch pad is fine.
Yeah, that's right.
Yeah, that's good.
That's right.
That would be a different way of saying it.
Yeah, yeah.
So, okay, now the fact that BQP is contained in P space
tells us something else that is very important, okay?
It tells us that in our current state of knowledge
of complexity theory, we have no hope of proving
unconditionally that BQP is larger than P, right?
So you could say like, you know,
a central goal of quantum computing ought to be just prove
that you can do something in quantum polynomial time
that you cannot do in classical polynomial time, right?
So prove that P is strictly contained in BQP, right?
I will put this as a conjecture, right?
Okay.
Now, certainly like if you believe that factoring,
so, okay, so sure as great achievement was to show
that the factoring problem is in BQP, right?
Factoring has a polynomial time quantum algorithm, okay?
So if you believe that factoring is not in P,
then that would mean that, you know,
BQP is larger than P, right?
Okay, but, you know, we have no hope of proving
unconditionally in our current state of knowledge
that BQP is larger than P.
Why is that?
Well, it's because we can't even prove
that P space is larger than P.
You could say like, you know,
it's not our fault as quantum computing people, right?
Got it, got it.
The progress is blocked by even just our lack of understanding
of how to prove separations in classical complexity.
Got it, yes.
Okay, so, okay, so, okay,
but now what else can we say about BQP?
So, so here is P, here's NP, here's P space.
Yeah, and I guess the way this is gonna tie up
is you're gonna eventually point
to what the quantum supremacy guys did in, in, in, in,
right, yeah.
Yeah, yeah.
Okay, here's the NP complete problems.
And now, what does BQP look like?
I like to draw it with a kind of wavy boundary
since, you know, everything quantum is, you know,
spooky and mysterious, of course.
So, so here's our kind of our picture
of where BQP would go.
Let me, let me put factor in here.
That's just a big example of something
that's in, in BQP, but not known to be in P.
Okay, now, I may, you know,
now you might be able to already see this from the picture,
but a central open problem is what is the relationship
between BQP and NP, right?
As far as we know today,
they may be incomparable to each other, okay?
Neither containing the other, right?
So on the one hand, we do not know
of an efficient quantum algorithm
for the NP complete problems, right?
Which is equivalent to asking,
is NP contained in BQP, right?
This is, this is not known to be true.
And most of us don't believe that it's true, right?
And this is, this is the precise point
where most of the popularizations of quantum computing
go off the rails, right?
They talk about Schor's algorithm
as if it were just a simple matter
of try all the possible solutions in parallel.
And if that were true,
then that would not just be for factoring, right?
That would also work for the NP complete problems, right?
But we don't think that a general basis
to NP complete problems, right?
Schor really had to take advantage
of very, very special properties of factoring.
Like I said, the fact that you can reduce it
to finding the period of a periodic function, okay?
So, okay, so that's one direction.
Then in the other direction,
we also don't know whether BQP is contained in NP, okay?
So this is the question,
like if a quantum computer can solve a problem,
then is there always at least a short classical proof
of the answer, right?
Even if it's hard to find,
or could quantum computers solve problems
where the answer cannot even be efficiently checked
by a classical computer, let alone found.
Actually, if BQP were in NP,
would that put quantum computing out of business,
or what would that mean?
No, no, no, no, no, it wouldn't.
If BQP were in NP, like you could still have
that factoring would be in BQP, but not in P, for example,
right, as long as P is not equal to NP.
Oh, okay, okay, okay, okay, I see, I see, yeah.
Okay, so, yeah.
So, you know, just the question you're talking about
is, you know, let me just write it explicitly.
The question of is BQP equal to P, okay?
So, yeah, but okay, but now we're talking
about the question of can a classical computer
always check the answer to a quantumly easy problem?
And we don't know, and I would say,
we don't have very strong evidence one way or the other,
kind of in the real world.
We have in the oracle or black box world,
we do know something about this question,
but, you know, I personally think
that this could go either way.
Okay, okay, all right.
So, that was a little bit about BQP
and where it fits in with classical complexity classes.
All right, so, you know, you could say like,
like the long-term goal in quantum computing research
would be build a scalable quantum computer, you know,
that is able to run, you know,
Shores factoring algorithm or something like that.
Right, and at that point,
there is no more arguing with the skeptics
who think that it's impossible, right?
You just say to the skeptics,
okay, just give me your 10,000 digit number, you know,
I will give you back, you know, the prime factors
after a few minutes.
And then, you know, you must agree
that either I have built a quantum computer
or else I've done something else
that is equally remarkable, right?
You know, and you can check the prime factors for yourself,
right?
You don't have to take my word for anything, right?
Okay, so we are clearly, we are not there yet, right?
And so, we don't have,
we don't yet have truly scalable quantum computers,
you know, that can scale up to millions of qubits, right?
And, you know, we could, you know,
the reasons why that's such a hard engineering problem,
that would be a whole further discussion
that could, you know, we could easily spend
another couple of hours on that,
on decoherence and quantum error correcting codes,
you know, and that's a whole nother story, okay?
But suffice it to say, you know,
there's been remarkable progress in the 20 years or so
that I've been in this field, you know, toward, you know,
getting qubits that you can control well enough
that then you can start using error correcting codes
to simulate, you know, basically perfect qubits, you know,
that you could, that could maintain
their superposition states for as long as you want, right?
And that's kind of what we ultimately want
in order to run quantum algorithms
like Schor's algorithm and, you know, and do factoring
and also to simulate quantum mechanics,
which is, you know, maybe, you know, even more important
for, you know, industry or for practice, right?
And then reading other people's emails, right?
But, you know, we, as an engineering matter,
we are not yet at the point where we can build
a scalable quantum computer with, you know,
with thousands or millions of error corrected qubits.
No one knows exactly when we'll get there.
There are some people who are very optimistic
that it will happen within the next decade, okay?
And, you know, and billions of dollars
are now being invested in it by Google, Microsoft,
Amazon, IBM, dozens of startup companies.
So, you know, if it fails,
it's not going to be for lack of trying, okay?
But, you know, where people are now
is that they can build devices with, let's say,
50 or 60 relatively noisy qubits, right?
That will not maintain their superposition state
for arbitrary amounts of time.
In fact, they'll only maintain it for, you know,
let's say 20 or 30 microseconds, something like that.
Okay, but, you know, that could be enough
to do maybe a circuit with a thousand or so gates, okay?
So now you start thinking like 50 qubits, a thousand gates.
Is that already enough to do something
that would be hard to simulate for a classical computer?
And that would at least prove the point that, yeah,
we can exploit this like vector space C
to the two to the 50, right?
We can exploit this, you know,
quadrillion dimensional complex vector space
to solve some problem where a classical,
even a classical supercomputer
would have a very hard time keeping up, okay?
So that brings us to this milestone
of quantum supremacy, right?
So not everyone likes the name, okay?
But the name was coined in, thank you,
the name was coined in a decade ago by John Preskell.
Listeners may have heard of.
And he was trying to codify a set of,
possible experiments that I and others had proposed
about a year before that, okay?
And so, you know, we had been thinking actually
just about quantum complexity theory about, you know,
things like BQP versus P, right?
And about like, what would be the most straightforward
demonstration that you could do
that a quantum computer is doing something
that is hard to simulate classically, okay?
And the key realization that we had, and this was,
so this was me and my student, Alex,
named Alex Arkapov in 2011.
And then independently of us,
Bremner, Joseph and Shepard, okay?
At around the same time.
We all kind of, you know, from different starting points,
kind of converged on this same idea,
which is that it actually becomes much, much easier
to see the advantages of a quantum computer
if you're willing to broaden your notion
of what a computational problem is, okay?
So when we talked about BQP,
we talked about decision problems, right?
Which are just problems where the answer
is always yes or no, right?
And I said that a lot of other problems
can be encoded as decision problems, okay?
But not quite all of them, okay?
So there were also another class of problems
in computer science is what are called sampling problems.
We're like, I described to you in some way
a probability distribution, let's say over n-bit strings.
And now your challenge is to output a sample
from that distribution, okay?
So an example might be, you know,
I give you a graph and I ask you to sample
a random matching in that graph, right?
Or I describe to you a convex body by like, you know,
the equations of its bounding surfaces.
And I ask you to sample a random point
in the interior of that convex body, right?
Now, you know, these kind of problems
have a long history in computer science.
Knuth, you know, talks about them
in the art of computer programming, right?
But now what we realized is that as soon as you talk
about sampling problems, it could be much, much easier
to see the advantages of a quantum computer
over a classical one, both theoretically,
like in the sense of separating the complexity classes
of, you know, quantum sampling versus classical sampling.
And also in the practical sense,
that it might be much, much easier
to actually realize those kind of quantum speed ups
in the lab, you might not have to build
the full fault tolerant quantum computer
that would be able to run Schwarz's algorithm.
50 noisy qubits might already be enough
to start seeing the advantages
for some of these sampling problems, okay?
That was the key realization that some of us had
11 or 12 years ago, okay?
And so Archipave and I, we had a proposal
which we called boson sampling, okay?
Which was basically to solve a sampling problem
that involved photonics.
So, you know, generate a bunch of photons,
then pass them through some basically random
but polynomial sized network of beam splitters
and then just measure to see where the photons.
Is this the same approach that the Google group used
or did they use something different?
It is not.
Okay, okay.
They were inspired by it, but then they said,
okay, but in order to do boson sampling,
we would have to spend a hundred million dollars
to like redesign our whole experiment.
So we're going to do something,
an analogous thing with superconducting qubits
and we will trust you, the theorists,
to adapt your theory to our experiment.
And we said, okay, we can do that.
Okay, okay, okay, I see.
So the thing that Google did is now called RCS
or random circuit sampling, okay?
And so you could say this boson sampling
which is what Archipave and I proposed.
What's called commuting Hamiltonians
which is the Bremner, Joseph and Shepard proposal
and the random circuit sampling
which is what Google ended up doing, right?
They're all like at a very high level,
they're all kind of a similar idea, right?
That you sort of apply this kind of more or less
random set of operations, you know,
if you just kind of scramble up the state of your qubits,
get a kind of random looking state of your qubits
but which will have little inhomogeneities in it.
Like some output states will be somewhat
likelier than others, right?
Just because of, you know, some of them just by chance
will suffer a little bit more destructive interference.
And other ones by chance
will enjoy a little bit more constructivity.
Yeah, and I think the point is, if I understand right,
basically the probability density, right?
Each of those terms are hard to compute classically.
And so you know that if you get samples
that are within some threshold
of your true probability density,
and the other key thing is you also know
that the classical problem approximation is also hard
or at least you believe it to be hard,
then that's how you sort of know
that you had to get some quantum advantage, right?
Exactly, so the point is, look, you know,
both, you know, to actually calculate these final,
you know, the probabilities of the final outputs
in your distribution,
that we expect to be an exponentially hard problem,
both for a quantum computer and for a classical computer.
Yeah, yeah.
But what the quantum computer can do just by construction
is it can sample from the distribution, right?
And now what we did in the Boson sampling paper
is we gave theoretical evidence
that even that sampling problem
should already be exponentially hard
for a classical computer
under some reasonable complexity assumptions, right?
Which, you know, it would take time
to explain the details of that, okay?
But so we gave some evidence that there is a separation
between quantum and classical
in terms of their ability to efficiently sample
from these kinds of probability distributions.
And so then that is what kind of suggested this, you know,
and we came at this purely from complexity theory, right?
You know, we weren't even thinking
about doing a practical experiment,
but then we started talking to quantum optics people
and they got very excited about it.
And so then, you know, we started realizing that, you know,
maybe this could actually be done
within like the next decade or so.
What happened was that in 2014,
Google hired John Martinez,
who was maybe like the top superconducting qubits
experimentalist in the world.
And they decided they're going to build
like a 50 to 70 qubit chip
that would be program, you know, programmable
with using superconducting qubits.
And, you know, and then they had the question,
what do we do with that?
And, you know, it's not obvious what you do
with 50 qubits, right?
But then they said, okay, maybe we can do something
like Boson sampling, but for, you know,
adapted to superconducting qubits.
So we had, we talked to them about that in 2015.
We kind of helped hammer out the proposal of, you know,
what exactly are they going to do?
How do you verify it once you've done it?
Which is, you know, a major drawback of these experiments
because it does take exponential time
with a classical computer,
even just to verify, you know, the results, okay?
But, you know, with 50 qubits,
you can still just barely do it, right?
If you use a big supercomputer, okay?
And then, you know, and then like, how do we know
that the problem is hard for a classical computer?
Or, you know, are we sufficiently convinced?
And then, you know, Google worked on this experiment
and in late 2019, they announced that they had done it
with a 53 qubit chip, which they called Sycamore,
which sampled from this probability distribution
over 53-bit strings,
which we do not know how to sample, you know,
they estimated that it would take 10,000 years.
Right, and this is where I got a little technically, yeah.
From that same distribution,
that turned out to be kind of wildly over-optimistic
or pessimistic.
Right, because these are estimates, right?
Because what they have to do is because you have to,
I say, because you still have to use a classical computer
to check a hard problem,
and of course you don't have 10,000 years to check,
what you do is you wouldn't extrapolate, right?
So you kind of approximate, you form a family
of simpler and simpler problems,
and you sort of see what the trend is.
And of course, if you weren't so precise with your estimates,
right?
But that was not even the sticking point.
That was not the sticking point, okay?
So, you know, like with enough computer power,
they could have done the full verification with 53 qubits,
but it turned out that the reason
that why they could have done it is that, you know,
they also could have spoofed the results
with 53 qubits, right?
So basically it was just that their classical algorithm
that they had in mind to simulate the experiment
was not the best one, right?
And people then came up with,
so their experiment was fine, right?
The experiment sees the signal of, you know,
where you are correlated with the outputs
that you want to be, right?
And it was an amazing experiment, right?
And I think, you know, from a, you know, truthfully,
you know, scientifically, the most interesting thing
that we learned from the experiment
was not quantum supremacy itself.
It was just that the errors behave in just, you know,
according to the most naive possible model, right?
Where, you know, it's just the total fidelity
of the circuit just goes like the fidelity
of each individual gate raised to the power
of how many gates there are.
I see. Okay.
Which means, you know, and as long as that is true,
then quantum error correction ultimately ought to work.
I see. So supremacy, yeah.
So supremacy in some sense is really just a subjective term
in that there's a threshold.
If they had just pushed it with a few more qubits,
then everyone would be happy it sounds like.
Well, no, because, okay, I mean, yes, more qubits
would help, but, you know, the trouble right now
is because of the exponential cost of verification.
Like if you go to so many qubits, like, you know, AD,
let's say, is that a classical computer?
Oh, I see.
It wouldn't even have a chance.
I see.
Then a classical computer also can't verify the answers.
Got it.
So right now you're kind of stuck
with this cat and mouse game,
where the difficulty of classical verification
is linked to the difficulty of classical spoofing.
So that kind of limits you, right?
But then, you know, the other issue is just that, you know,
even while the classical simulation time is exponential,
people can get very, very clever about it, right?
And they can do all kinds of tricks
to cut it down to a milder exponential, okay?
And that is exactly what we have seen
in the past three years, right?
That people have used what are called tensor network methods
to get a faster simulation.
And nowadays, we know that, you know,
if you spent enough money on like AWS, right,
or just buying enough, you know, classical computing time,
then you could spoof the Google experiment, you know,
in just a matter of seconds, right?
It was, you know, faster than the thing itself.
But you would still be using hundreds of times
more electricity than the quantum computer.
I see, I can see, okay.
And, you know, and the quantum computer is not exactly, you know,
I mean, it's already using a dilution refrigerator
that's the size of a closet, right?
Which is using like, you know,
I think, you know, tens of kilowatts, right?
But, you know, the classical supercomputer to simulate it,
as far as we know, that could require megawatts, okay?
So you are, you know, so in some sense, you could say,
you still do have quantum supremacy, let's say,
as measured by carbon footprint, right?
I see, I see.
As measured by number of steps, right?
But by total number of operations, right?
So, but, you know, not as measured by wall clock time.
And that's just because the classical simulations
are so parallelizable, right?
That like, you know, to do it faster and faster
is just a question of cost.
It's a question of how many chips, right?
So there are, you know, you do get into kind of, you know,
annoying finicky questions about what is the exact definition
of supremacy, right?
Beating a classical computer, right?
You know, maybe ultimately the question should be dollars,
right?
Sure.
But, now the other key issue here is that
there is a lot of noise in the circuit.
So each of their two qubit gates in the Google experiment,
for example, has like 99.5% fidelity, right?
Meaning like only a one in 200 chance of an error, right?
Which is, you know, by the standards of like,
when I joined this field 20 years ago, right,
you would have been thrilled to get 50% fidelity, right?
So that's like amazing, okay?
But it's still not good enough.
Like if I have a thousand gates,
I'm now taking 0.995 and I'm raising it to the thousand power,
right?
And then I end up with something that's rather small, right?
And so this is exactly the issue with the Google experiment,
right, that they just are able,
they're able to measure a signal
that it's just a little bit distinguishable
from purely uniform noise, you know,
if they take millions of samples, right?
Which they can do in about three minutes, okay?
So, okay, but now there are classical simulations
that can exploit the noise to run faster, right?
So what the classical people say is, well, look,
if the quantum computer itself is noisy,
then it's perfectly fair for our simulation
to also be noisy, right?
And then it can run, you know, maybe it can run faster, right?
And so all of the, you know, we're still in the era
when we're gonna see back and forth claims
and counterclaims about, you know,
like to what extent has quantum supremacy been achieved?
The hope is that at some point,
quantum computing just completely pulls away, right?
At least for those special problems where, you know,
where it wins, right?
And then, you know, and that there's not even
a comparison anymore, right?
Or, you know, the classical computers
would have no hope of keeping up.
But now a huge question,
which I personally do not know the answer to,
a huge question is, will the quantum computers
be able to decisively pull away, you know,
in the current era of these noisy,
non-error corrected devices, right?
Or will pulling away only be possible
once you have fully error-corrected qubits, right?
And that is a huge question where, you know, right now,
for better or worse, billions of dollars
are riding on the answer to that question.
Wow.
Okay, well, great.
Thank you for that great summary of the field
that we spent so much time talking.
I wanted to thank you so much for our interesting discussion.
Yeah, this is very informative.
Sure, yeah.
Yeah, no, it was fun.
