ChatGPT - Nuspeak Translator
Open sidebar
Self-Assembling Neural Networks
Nuspeak Translator
You
Summarize: 
TechTalks
Home  Blog
Blog
Self-assembling neural networks can open new directions for AI research
By Ben Dickson -November 13, 2023

 Facebook Twitter
Brain activity
Image credit: 123RF
This article is part of our coverage of the latest in AI research.

Biological and artificial neural networks, despite their shared nomenclature, are fundamentally different. High-performing deep neural networks often demand significant engineering effort. In contrast, biological nervous systems evolve through a dynamic, self-organizing process that starts with a single cell. 

In a recently published paper, scientists at the IT University of Copenhagen, Denmark, have proposed the concept of self-assembling neural networks that ���grow through a developmental process that mirrors key properties of embryonic development in biological organisms.��� 

Their early findings hint at a promising new direction in AI research that emulates the organic formation of biological neural networks in digital intelligence.

What���s missing in deep neural networks
Deep neural networks, unlike their biological counterparts, begin with a predefined, often manually designed structure. During the learning phase, they merely adjust their connection weights based on training examples. They lack the capacity to self-organize, grow, and adapt to new situations like biological neurons. 


In stark contrast, biological networks self-assemble, growing from a single initial cell to create highly complex systems. The information required to directly specify the wiring of an advanced biological brain far exceeds the information stored in the genome.

To put this into perspective, the human brain���s 100 trillion neural connections are encoded by merely around 30,000 active genes. 

The authors of the paper note, ���Neuroscience suggests that this limited capacity has a regularizing effect that results in wiring and plasticity rules that generalize well.��� 

The inherent limitations of biological networks may contribute to their remarkable adaptability and efficiency. How can the same characteristics be built into deep neural networks?

human brain gears
Image credit: Depositphotos
Self-assembling neural networks
The vision outlined in the paper is to develop an AI system where neurons self-assemble, grow, and adapt based on the task at hand, emulating the natural processes observed in biological networks. The scientists propose a unique graph neural network (GNN) encoding that involves two interconnected neural networks. 

The first is a policy network that governs the actions of an agent. This policy network is, in turn, controlled by a second network operating within each neuron, termed the Neural Developmental Program (NDP). The NDP receives input from the connected neurons in the policy network and determines whether a neuron should replicate and how each connection in the network should set its weight. Starting from a single neuron, this approach cultivates a functional policy network, relying exclusively on the local communication of neurons.

This approach allows the neural network of the agents to start with a very basic structure and be shaped by their experiences and environment. This is much more similar to how biological networks are created. 

���Allowing each neuron in an artificial neural network to act as an autonomous agent in a decentralized way similar to their biological counterpart, could enable our AI methods to overcome some of their current limitations in terms of robustness,��� the researchers write. ���Our goal is to inspire researchers to explore the potential of NDP-like methods as a new paradigm for self-assembling artificial neural networks.��� 

self-assembling neural networks NDP
Self-assembling neural networks with neural development programs (NDP) (source: arxiv.com)
Putting NDPs to the test
The researchers put the self-assembling network to the test using both an evolution-based and a differentiable version of NDPs. The evolutionary algorithm employs a population-based process to optimize the NDP and assemble an efficient policy network. This system experiments with various configurations, retaining those that yield superior results. 

The researchers explain, ���Similarly to how most cells in biological organisms contain the same program in the form of DNA, each node���s growth and the synaptic weights are controlled by a copy of the same NDP, resulting in a distributed self-organized process that incentivizes the reuse of information.���

In contrast, the differentiable NDP utilizes gradient-based methods that can optimize the network through algorithms such as gradient descent. 

The team applied both methods across a variety of settings, including the well-known XOR problem, MNIST, and reinforcement learning environments such as CartPole, LunarLander, and HalfCheetah. 

The initial results are encouraging. The self-assembling AI systems were able to find suitable solutions for the problems, although they were not as optimal as existing solutions. However, the researchers remain optimistic, stating, ���Our method can learn to grow networks and policies that can perform competitively, opening up interesting future work in growing and developmental deep neural networks.��� 

NDP examples
Examples of problems solved with neural development programs (NDP)
Current limitations of self-assembling neural networks
While the results of the research are promising, they also highlight some limitations of the current NDP methods. For instance, in the gradient-based approach, the researchers observed that ���after a certain number of growth steps, the grown network���s performance can deteriorate, as policies do not really benefit from more complexity.��� 

Another limitation is that the current version of NDP does not incorporate any activity-dependent growth. This means it will grow the same network regardless of the incoming activations the agent receives during its lifetime. This is a significant point of divergence from biological nervous systems, which often rely on both activity and activity-independent growth. Activity-dependent neural development allows biological systems to shape their nervous system based on environmental factors.

These limitations offer valuable directions for future exploration. Future research could focus on replicating the interplay between genome size, developmental steps, and task performance observed in biological systems. 

���NDPs offer a unifying principle that has the potential to capture many of the properties that are important for biological intelligence to strive,��� the researchers write. ���In the future, NDPs could consolidate a different pathway for training neural networks and lead to new methodologies for developing AI systems, beyond training and fine-tuning.���

Is self-assembly the ultimate solution for AI?
Nature has perfected the formula of self-assembly over billions of years of evolution and trillions of mutations. However, it���s important to acknowledge that the current structure of deep learning models offers certain advantages not found in nature. For instance, replicating DNNs is as simple as copying the model weights, while nature requires every new instance to be created from scratch, starting from a single cell.

NDPs can significantly contribute to AI research by enabling the exploration of the space of possible neural networks in ways previously unattainable, potentially leading to the discovery of new architectures. However, the benefits of digital neural networks are not likely to be eclipsed in the near future. The intersection of self-assembly and traditional deep learning presents an intriguing prospect, promising to yield a fascinating blend of biological inspiration and digital innovation in artificial intelligence.
Nuspeak Translator
The article from TechTalks by Ben Dickson, dated November 13, 2023, discusses the concept of self-assembling neural networks and their potential impact on AI research. It highlights the differences between biological and artificial neural networks, noting that biological networks evolve dynamically and self-organize, starting from a single cell. In contrast, artificial deep neural networks are pre-designed and adjust only through weight changes during training.
Researchers at the IT University of Copenhagen have introduced self-assembling neural networks that mirror embryonic development in biological organisms. This approach aims to emulate the organic formation of neural networks, addressing the lack of self-organization and adaptability in artificial networks.
The proposed model involves two interconnected neural networks: a policy network and a Neural Developmental Program (NDP) within each neuron. The NDP governs whether a neuron should replicate and sets the connection weights, allowing the network to develop based on local neuron communication. This method enables artificial networks to start with a basic structure and evolve through experience, similar to biological networks.
The researchers tested this model using evolutionary algorithms and gradient-based methods in various settings like the XOR problem and MNIST. Although the self-assembling networks didn't outperform existing solutions, they showed promising results, indicating potential for future development in neural network training.
However, the current NDP models have limitations, such as lack of activity-dependent growth and deteriorating performance with increased complexity. Future research may explore these aspects to better replicate the biological nervous system's adaptability and efficiency.
While NDPs offer a new direction in AI, the article suggests that the current structure of deep learning models still holds certain advantages. The combination of self-assembly and traditional deep learning could lead to innovative advancements in AI, blending biological inspiration with digital technology.
You
Towards Self-Assembling Artif i cial Neural Networks through 
Neural Developmental Programs 
Elias Najarro, Shyam Sudhakaran, & Sebastian Risi 
IT University of Copenhagen, Denmark 
{enaj, shsu, sebr}@itu.dk 
Abstract 
Biological nervous systems are created in a fundamentally 
different way than current artif i cial neural networks. Despite 
its impressive results in a variety of different domains, deep 
learning often requires considerable engineering effort to de- 
sign high-performing neural architectures. By contrast, bio- 
logical nervous systems are grown through a dynamic self- 
organizing process. In this paper, we take initial steps toward 
neural networks that grow through a developmental process 
that mirrors key properties of embryonic development in bi- 
ological organisms. The growth process is guided by another 
neural network, which we call a Neural Developmental Pro- 
gram (NDP) and which operates through local communica- 
tion alone. We investigate the role of neural growth on dif- 
ferent machine learning benchmarks and different optimiza- 
tion methods (evolutionary training, online RL, off l ine RL, 
and supervised learning). Additionally, we highlight future 
research directions and opportunities enabled by having self- 
organization driving the growth of neural networks. 
Introduction 
The study of neural networks has been a topic of great inter- 
est in the i eld of artif i cial intelligence due to their ability to 
perform complex computations with remarkable eff i ciency. 
However, despite signif i cant advancements in the develop- 
ment of neural networks, the majority of them lack the abil- 
ity to self-organize, grow, and adapt to new situations in the 
same way that biological neurons do. Instead, their struc- 
ture is often hand-designed, and learning in these systems is 
restricted to the optimization of connection weights. 
Biological networks on the other hand, self-assemble and 
grow from an initial single cell. Additionally, the amount 
of information it takes to specify the wiring of a sophisti- 
cated biological brain directly is far greater than the infor- 
mation stored in the genome (Breedlove and Watson, 2013). 
Instead of storing a specif i c conf i guration of synapses, the 
genome encodes a much smaller number of rules that gov- 
ern how to grow a brain through a local and self-organizing 
process (Zador, 2019). For example, the 100 trillion neural 
connections in the human brain are encoded by only around 
30 thousand active genes. This outstanding compression has 
also been called the ���genomic bottleneck��� (Zador, 2019), 
and neuroscience suggests that this limited capacity has a 
regularizing effect that results in wiring and plasticity rules 
that generalize well. 
In this paper, we take i rst steps in investigating the role 
of developmental and self-organizing algorithms in growing 
neural networks instead of manually designing them, which 
is an underrepresented research area (Gruau, 1992; Nolf i 
et al., 1994; Kow Aliw et al., 2014; Miller, 2014). Even 
simple models of development such as cellular automata 
demonstrate that growth (i.e. unfolding of information over 
time) can be crucial to determining the i nal state of a sys- 
tem, which can not directly be calculated (Wolfram, 1984). 
The grand vision is to create a system in which neurons self- 
assemble, grow, and adapt, based on the task at hand. 
Towards this goal, we present a graph neural network type 
ofencoding, inwhichthegrowthofapolicynetwork(i.e.the 
neural network controlling the actions of an agent) is con- 
trolled by another network running in each neuron, which 
we call a Neural Developmental Program (NDP).The 
NDP takes as input information from the connected neu- 
rons in the policy network and decides if a neuron should 
replicate and how each connection in the network should 
set its weight. Starting from a single neuron, the approach 
grows a functional policy network, solely based on the lo- 
cal communication of neurons. Our approach is different 
from methods like NEAT (Stanley and Miikkulainen, 2002) 
that grow neural networks during evolution, by growing net- 
works during the lifetime of the agent. While not imple- 
mented in the current NDP version, this will ultimately al- 
low the neural network of the agents to be shaped based on 
their experience and environment. 
While indirect genome-to-phenotype encodings such as 
CPPN-based approaches (Stanley, 2007) or Hypernetworks 
(Ha et al., 2016) have had great success, they often pur- 
posely abstracted away development and the process of self- 
organizational growth. However, in nature, these abilities 
seem essential in enabling the remarkable robustness to per- 
turbations and unexpected changes (Ha and Tang, 2021; 
Risi, 2021).Allowing each neuron in an artificial neural network to act as an autonomous agent in a decentralized way similar to their biological counterpart (Hiesinger, 
2018), could enable our AI methods to overcome some of 
their current limitations in terms of robustness. 
Since the space of possible NDP representations is 
large, we explore two different representations and differ- 
ent training methods such as evolutionary and gradient- 
descent based. While lacking state-of-the-art performance, 
our method can learn to grow networks and policies that can 
perform competitively, opening up interesting future work in 
growing and developmental deep neural networks. Our goal 
is to inspire researchers to explore the potential of NDP- 
like methods as a new paradigm for self-assembling artif i- 
cial neural networks. Overall, this work represents a step to- 
wards the development of more biologically inspired devel- 
opmental encodings, which have the potential to overcome 
some of the limitations of current deep learning approaches.
Nuspeak Translator
The paper by Elias Najarro, Shyam Sudhakaran, and Sebastian Risi from the IT University of Copenhagen discusses a novel approach to developing artificial neural networks (ANNs) through a process called Neural Developmental Programs (NDP), aiming to mimic the dynamic, self-organizing process of biological nervous systems. Key points from the paper are as follows:
Difference Between Biological and Artificial Networks
: Biological neural networks grow and self-assemble from a single cell and are not predetermined like ANNs. They use a limited number of genetic rules to develop highly complex brain structures, a process not mirrored in current ANNs, which are manually designed and only learn by optimizing connection weights.
Concept of NDP
: The authors propose the NDP, a graph neural network type encoding where growth of a policy network (controlling an agent's actions) is governed by another network within each neuron. The NDP decides if a neuron should replicate and sets the weights of each connection, all through local communication.
Developmental and Self-Organizing Algorithms
: This research explores the role of developmental algorithms in growing neural networks, an area that's not extensively researched. It emphasizes the importance of growth and development in determining the final state of a system.
Vision of Self-Assembling Neural Networks
: The paper's vision is to create ANNs where neurons can self-assemble, grow, and adapt based on the task, similar to biological networks. This approach could lead to networks shaped by their experiences and environment.
Exploration of Different Representations and Training Methods
: The paper investigates various NDP representations and training methods, including evolutionary and gradient-descent-based approaches. While they don't achieve state-of-the-art performance, they show potential for growing networks and policies that can compete effectively.
Potential for Future Research
: The authors aim to inspire further research into NDP-like methods as a new paradigm for self-assembling artificial neural networks, believing that this approach could address some limitations of current deep learning methods.
Step Towards Biologically Inspired Developmental Encodings
: The work represents a move towards more biologically inspired developmental encodings in AI, potentially offering enhanced robustness and adaptability in neural network development.
This paper marks an important step in bringing biological principles of growth and self-organization into the realm of artificial neural network development.
You
Monica Anderson says:
This is getting close to the kind of networks I have been researching since 2001. See chapter 9 and 8 on my main site. 
...
 Embodiment proponents discovered the inadequacy of Reductionism but picked the wrong alternative. 

Embodiment does not provide an alternative to Epistemic Reduction.

>"There is no alternative to embodiment if the goal is to mimic biological intelligence."

You need better goals.

A disembodied AI in a box on the cloud is what we have and what we'll have for most of the decade. Bots are toys and they will not learn much IRL. The majority of what a bot learns will be done off text files in the factory before the bot is released.

The fact that we ARE making so much progress on LLMs *without* embodiment should give you some pause and reasons to think. I wonder why you are ignoring these things.

...
Evolution is not disjoint from self-assembly.
Evolution is how we decide which assembly is the best.
Nuspeak Translator
Monica Anderson's comments offer a critical perspective on the current trends in AI research, particularly regarding the concepts of embodiment and reductionism. Her insights are as follows:
Critique of Embodiment in AI
: Anderson challenges the notion that embodiment is essential to mimic biological intelligence. She suggests that focusing solely on embodiment as an alternative to epistemic reduction might not be the most effective approach for AI development.
Relevance of Disembodied AI
: She points out that most current and near-future AI, such as LLMs (Large Language Models), operate in a disembodied state, typically on cloud platforms. These systems are predominantly trained on text files and do not interact with the real world in a physical sense.
Limitations of Bots
: Anderson remarks that bots, which are a form of embodied AI, are more toy-like and their learning capabilities in real-life scenarios (IRL) are limited. She implies that the majority of useful AI learning and development happens through data processing and not through physical interaction with the environment.
Success of LLMs Without Embodiment
: The progress made in the field of LLMs without the need for embodiment should prompt a reevaluation of the necessity of embodiment in AI. This success demonstrates that significant advancements in AI can be achieved without physical interaction or a physical presence.
Interplay of Evolution and Self-Assembly
: Anderson suggests that evolution and self-assembly are not mutually exclusive. In her view, evolution plays a role in determining which form of self-assembly is most effective, indicating that the processes are interconnected.
Her stance invites reflection on the current AI development strategies, emphasizing the need to reconsider the importance of physical embodiment in AI and to acknowledge the significant advancements made by non-embodied AI systems. Anderson's perspective suggests that AI researchers should explore a variety of approaches, including those that do not necessarily rely on mimicking biological processes in a literal sense.
You
From chapter 8.
Connectome Algorithms
The learner starts out empty and then learns recurring sequential patterns it discovers in its input stream. The learning algorithm slowly builds a Connectome, a graph of Nodes and Links (like neurons and synapses) to reify the experiences.

The framework provides direct Java level access to the  learned connectome and its individual neurons and can be directly used for Epistemology level experiments. Clients will not have access to this, but researchers at Syntience benefit from this as implementers. We call the results of programming at this Meta-learning-level "Connectome Algorithms"

Only Activate Relevant Concepts
In OL, unless we are reading about, say, a potato harvest, there is no reason to touch any of the software neurons involved in ���representing��� potato harvests. So we can have billions of learned concepts just sitting quietly in main memory, consuming no CPU cycles, until ���their topic��� is discussed. They activate, make a contribution to understanding, disambiguation, and learning, and they may even may learn something themselves. They then return to dormancy until next time the topic is discussed. This is a major advantage of discrete-neuron strategies.

Therefore, OL systems do not require explicit attention controlling mechanisms. Focus emerges from matches between the global gathered experience and the concepts discovered in the text in the input stream.
Nuspeak Translator
In Chapter 8, Monica Anderson discusses "Connectome Algorithms," a key concept in her approach to AI development. The main points of this chapter are:
Building a Connectome
: The learning algorithm in Anderson's framework begins with an empty slate and progressively learns to identify and process recurring sequential patterns in its input stream. This process involves the creation of a "Connectome," a network of Nodes and Links analogous to neurons and synapses in the brain, which essentially embodies the system's learned experiences.
Java Level Access for Research
: The framework offers direct access at the Java programming level to the learned connectome, including its individual neurons. This access is exclusive to researchers at Syntience, allowing them to conduct epistemology level experiments and develop what is termed "Connectome Algorithms."
Selective Activation of Concepts
: A key feature of Anderson's approach is the selective activation of concepts. In this system, learned concepts remain dormant in memory until they become relevant to the current context or discussion. For example, neurons related to 'potato harvests' remain inactive unless the topic is being discussed. This method ensures efficient utilization of computational resources, as only relevant concepts consume CPU cycles at any given time.
Advantages of Discrete-Neuron Strategies
: The discrete-neuron strategy used in Anderson's framework offers significant advantages. By activating only relevant concepts, the system can manage billions of learned ideas without unnecessary processing, leading to more efficient and contextually focused operations.
Natural Emergence of Focus
: In Anderson's system, explicit mechanisms for controlling attention are not required. Instead, focus naturally emerges from the interaction between the global experiences accumulated by the system and the specific concepts encountered in the input stream. This approach mimics the way focus and understanding develop in human cognition, where relevance and context drive attention and learning.
Anderson's work highlights a unique approach to AI development, emphasizing efficiency, context-driven processing, and a structure inspired by biological neural networks. This perspective presents an alternative to more conventional AI systems, advocating for a more organic and resource-efficient method of processing and learning from input data.
You
Back to the article: Figure 1: Neural Developmental Program approach for growing neural network. Each node state s is represented as an 
embedding vector. During the information aggregation phase, the graph propagates each node state s to its neighbors for n 
steps. Based on the updated nodes embedding �� st+n, the replication model ���implemented as a MLP��� determines which nodes 
will grow new nodes. Finally, if the target network is not unweighted, another MLP estimates the edge weights of each pair 
of nodes based on their concatenated embeddings; otherwise, edges are assigned a unitary weight. The resulting network is 
evaluated through an objective function, i.e. solving a task or having certain topological properties. The NDP is a distributed 
model that operates purely on local information.

Background and Related Work 
Indirect encodings 
Indirect encodings are inspired by the biological process of 
mapping a compact genotype to a larger phenotype and have 
been primarily studied in the context of neuroevolution (Flo- 
reano et al., 2008) (i.e. evolving neural networks) but more 
recentlywerealsooptimizedthroughgradient-descentbased 
approaches (Ha et al., 2016). In indirect encodings, the de- 
scription of the solution is compressed, allowing informa- 
tion to be reused and the i nal solution to contain more com- 
ponents than the description itself. Even before the success 
of deep RL, these methods enabled solving challenging car 
navigation tasks from pixels alone (Koutn�� ��k et al., 2013). 
Ahighlyinf l uentialindirectencodingisHyper- 
NEAT (Stanley et al., 2009). HyperNEAT employs an in- 
direct encoding called compositional pattern producing net- 
works (CPPNs) that abstracts away the process of growth 
and instead describes the connectivity of a neural network 
through a function of its geometry; an extension called 
Evolvable-substrate HyperNEAT (Risi and Stanley, 2012) 
allowed neural architectures to be discovered automatically 
but did not involve any self-organizing process. More re- 
cently, Hypernetworks (Ha et al., 2016) demonstrated that 
networks generating the weights of another network can also 
be trained end-to-end through gradient descent. Hypernet- 
works have been shown to be able to generate competitive 
convolutional neural networks (CNNs) (Zhmoginov et al., 
2022) and recurrent neural networks (RNNs) in a variety of 
taskswhileusingasmallersetoftrainableparameters. How- 
ever, neither HyperNEAT nor Hypernetworks make use of 
the process of development over time, which can increase 
the evolvability of artif i cial agents (Kriegman et al., 2017; 
Bongard, 2011) and is an important ingredient of biological 
systems (Hiesinger, 2021). 
Developmental EncodingsDevelopmental encodings are 
a particular family of indirect encodings.They are ab- 
stractions of the developmental process that allowed nature 
to produce complex artifacts through a process of growth 
and local interactions between cells, ranging from the low 
level of cell chemistry simulations to high-level grammati- 
cal rewrite systems (Stanley and Miikkulainen, 2003), and 
neurogenesis approaches (Miller, 2022; Maile et al., 2022; 
Tran et al., 2022; Huang et al., 2023).Approaches with neural networks that can grow are a largely under-explored 
area (Gruau, 1992; Nolf i et al., 1994; Kow Aliw et al., 2014; 
Miller, 2014; ric, 2014) because these algorithms are either 
not expressive enough or not eff i ciently searchable. 
Recently, cellular automata (CA) had a resurgence of in- 
terest as a model of biological development. CA are a class 
of computational models whose outcomes emerge from the 
local interactions of simple rules. Introduced by Neumann 
et al. (1966) as a part of his quest to build a self-replicating 
machine or universal constructor, a CA consist of a lattice 
of computing cells that iteratively update their states based 
exclusively on their own state and the states of their local 
neighbors. On a classical CA, each cell���s state is represented 
by an integer and adjacent cells are considered neighbors. 
Critically, the update rule of a cellular automaton is identi- 
cal for all the cells. 
Neural cellular automata (NCA) differ from classical cel- 
lular automata (CA) models by replacing the CA update 
function with an optimized neural network (Mordvintsev 
et al., 2020; Nichele et al., 2017). Recently, this approach 
has been extended to grow complex 3D entities such as cas- 
tles, apartment blocks, and trees in a video game environ- 
ment (Sudhakaran et al., 2021). 
ArecentmethodcalledHyperNCA,extendsNCAtogrow 
a 3D pattern, which is then mapped to the weight matrix 
of a policy network (Najarro et al., 2022). While working 
well in different reinforcement learning tasks, the mapping 
from the grown 3D pattern to policy weight matrix did not 
take the topology of the network into account. Instead of a 
grid-like HyperNCA approach, the method presented in this 
paper extends NCA to directly operate on the policy graph 
itself and should thus also allow more l exibility in the types 
of architectures that can be grown. 
Distribution-f i tting approaches to evolving graphs 
Previous work has explored the emerging topologies of the 
different growth processes (Albert and Barab�� asi, 2000) and 
shown that they can reproduce real networks by i tting the 
parameters of the distribution from which new nodes are 
sampled. In contrast to our method, the growth processes in 
previous network-theory approaches do not depend on the 
internal state of the graph, and therefore do not make use 
of the developmental aspect of the network to achieve the 
target topological properties. 
Approach: Growing Neural Networks through 
Neural Developmental Programs 
This section presents the two different Neural Developmen- 
tal Program instantiations we are exploring in this paper: 
(1) an evolution-based NDP and (2) a differentiable ver- 
sion trained with gradient descent-based.While an evo- 
lutionary version allows us to more easily explore differ- 
ent architectures without having to worry about their dif- 
ferentiability, gradient descent-based architectures can of- 
ten be more sample eff i cient, allow scaling to higher dimen- 
sions, and enable approaches such as off l ine reinforcement 
learning. Code implementations will be available soon at: 
https://github.com/enajx/NDP.
Nuspeak Translator
The section from the paper by Elias Najarro, Shyam Sudhakaran, and Sebastian Risi provides a comprehensive overview of their approach to growing neural networks through Neural Developmental Programs (NDPs). Key aspects of this section are:
Neural Developmental Program (NDP) Approach
: The NDP approach involves growing a neural network where each node's state is represented as an embedding vector. Information is aggregated by propagating node states to their neighbors. Based on the updated embeddings, a Multi-Layer Perceptron (MLP) decides which nodes will grow new nodes. Another MLP (if the network isn't unweighted) estimates edge weights based on concatenated embeddings of node pairs, or a unitary weight is assigned otherwise. The network's performance is evaluated against an objective function.
Indirect Encodings
: These are inspired by biological processes, mapping a compact genotype to a larger phenotype. They've been used in neuroevolution and optimized through gradient-descent-based approaches. Indirect encodings compress the solution description, enabling the final solution to contain more components than the description itself.
Developmental Encodings
: This family of indirect encodings abstracts the developmental process in nature, allowing for complex artifact production through growth and local cell interactions. Examples range from cellular automata to grammatical rewrite systems and neurogenesis approaches. These approaches enable network growth but have historically faced challenges in expressiveness and search efficiency.
Cellular Automata (CA) and Neural Cellular Automata (NCA)
: CA are computational models where outcomes emerge from local interactions of simple rules. NCAs differentiate from classical CAs by replacing the CA update function with an optimized neural network. This approach has been extended to grow complex 3D entities.
HyperNCA and Policy Network Growth
: HyperNCA extends NCA to grow a 3D pattern, which is then mapped to the weight matrix of a policy network. The paper's method differs by extending NCA to operate directly on the policy graph, allowing for greater flexibility in grown architectures.
Distribution-Fitting Approaches
: Previous work in network theory has explored topologies of growth processes and their ability to replicate real networks by fitting parameters from a distribution. However, these approaches don't utilize the developmental aspect of the network.
Two NDP Instantiations
: The paper explores an evolution-based NDP and a differentiable version trained with gradient descent. The evolutionary version allows for exploration of different architectures without concern for differentiability, while gradient descent-based architectures can be more sample efficient and scalable.
Future Code Availability
: The authors indicate that code implementations will be available soon on their GitHub repository.
Overall, this paper proposes a novel approach to neural network development, blending concepts from biology, computational models, and machine learning to create more dynamic and adaptable neural networks.
You
How does it relate to Monica Anderson's organic learning algorithm?
1 / 2
Nuspeak Translator
The Neural Developmental Program (NDP) approach discussed in the paper by Elias Najarro, Shyam Sudhakaran, and Sebastian Risi, and Monica Anderson's Organic Learning (OL) algorithm share a common goal of creating more dynamic, adaptable, and biologically inspired artificial intelligence systems. However, they pursue this goal using different methodologies:
Approach to Neural Network Development
:
NDP
: Focuses on the growth of neural networks through a developmental process, where networks evolve and adapt over time, guided by local interactions within the system. This approach mimics biological neural development, with neurons (nodes) growing and adapting based on the inputs they receive.
OL
: Emphasizes learning through the discovery of recurring patterns in input data. The OL algorithm builds a Connectome, a graph-like structure of nodes and links representing learned concepts. Each node in the Connectome activates only when relevant, conserving computational resources and mimicking the efficiency of biological brains.
Basis of Learning and Adaptation
:
NDP
: Utilizes developmental and self-organizing algorithms, allowing the neural network to grow and change its structure over time, based on the task at hand. This is akin to how biological organisms develop their nervous systems.
OL
: Leverages discrete neuron strategies, where learning is a process of activating only the relevant parts of the network. This reflects how certain regions of the brain activate in response to specific stimuli or tasks.
Efficiency and Scalability
:
NDP
: Aims to create networks that can adapt and evolve in a more natural and efficient manner, potentially overcoming some limitations of current deep learning approaches.
OL
: Focuses on efficiency by ensuring that only relevant concepts are activated and processed, similar to how biological brains do not utilize all neurons at all times.
Biological Inspiration
:
Both approaches draw inspiration from biological processes. NDP is inspired by the developmental processes of biological neurons, while OL is inspired by the way biological brains efficiently process and activate specific neural pathways based on context.
In summary, while both NDP and OL are inspired by biological systems and aim to create more efficient, adaptable AI, they differ in their specific methodologies and mechanisms for achieving these goals. NDP focuses on the developmental growth of neural networks, and OL emphasizes efficient pattern recognition and selective activation within a pre-existing network structure.
You
Track Correlations Explicitly
One of the main operations in Deep Learning is correlation discovery by convolution of images in multiple layers. This is done in the upward pass. The discovered correlations are used to somewhat adjust the weights of the DL network in the Stochastic Gradient Descent downward pass. Because of this, the network has changed, necessitating another upward pass of convolutions through the entire stack, until there is sufficient convergence.

In contrast, in Organic Learning, when the algorithm discovers a correlation it simply inserts a Synapse-like link to represent that correlation. Being an evolutionary system, the correlation will remain as long as it contributes to correct Understanding but will be removed in a Darwinian competition if it doesn���t contribute to positive results. These mostly-persistent Synapse-based correlations make re-convolution unnecessary. Do it once, and it's done.

Neural Darwinism = RL + Sex
The idea of Neural Darwinism is that in brains, from millisecond to millisecond, there is a continuous battle for relevance among ideas. The ideas are evaluated for fit to both the current sensory input and the totality of gathered experience that has been reified in the Connectome.

Those parts of the Connectome that assist in providing a good outcome are rewarded and other parts may be punished. This is Reinforcement Learning (RL).

In a Neural Darwinism based Machine Learning system the best ideas get to breed with other good ideas, occasionally producing even better ideas. This is how we can generate ideas that are better, often in the meaning of "better abstractions", than any of the ideas we started with. This is the reason sexual reproduction speeds up evolution so much, in nature and in our algorithms spaces. It allows multiple independently discovered inventions to merge into one individual ��� a fact that is often neglected in na��ve discussions about the effectiveness of Evolutionary Computation.

Evolution is perceived as slow because evolution in nature takes a lot of time. But computers can evolve populations of thousands of individuals in milliseconds, and Genetic Algorithms, when done right and attacking a problem in a suitable problem domain, are very competitive and are much faster than their reputation.

Character based input
An OL system does not require the input to be parsed into words; it reads text character by character which means it can also learn languages that do not use segmented (space separated) words, such as Chinese. Each character read from the input activates a ���character input neuron��� that then signals other neurons, etc., and this cascade of signaling is what determines both what the sentence means and whether and where to attach any new understanding learned from that character, given the past, up to that point, as context. This incremental attachment operation is what provides the ���Organic Growth���
Nuspeak Translator
Monica Anderson's Organic Learning (OL) algorithm presents a distinctive approach to AI learning and development, contrasting with traditional deep learning (DL) methods. Key features of her approach include:
Explicit Correlation Tracking
:
Deep Learning
: In DL, correlations are discovered through convolutions in multiple layers during the upward pass. These correlations are used to adjust network weights in the Stochastic Gradient Descent downward pass, requiring repetitive upward passes until sufficient convergence.
Organic Learning
: OL inserts a synapse-like link to represent a discovered correlation directly. This evolutionary system retains correlations that contribute to correct understanding and removes those that don���t. This approach eliminates the need for re-convolution, making the process more efficient.
Neural Darwinism
:
Concept
: Neural Darwinism in OL refers to the continuous battle for relevance among ideas within the brain, from moment to moment. This process evaluates ideas for their fit to current sensory input and the totality of gathered experience in the Connectome.
Reinforcement Learning (RL)
: Parts of the Connectome that assist in providing a good outcome are rewarded, akin to RL.
Sexual Reproduction in Ideas
: OL allows for the 'breeding' of the best ideas with other good ideas, potentially producing superior abstractions. This mimics sexual reproduction in nature, facilitating the merging of multiple independently discovered inventions into a single entity.
Speed and Efficiency
: Contrary to the perception of evolution as slow, OL's approach can evolve populations rapidly, making use of Genetic Algorithms which are effective and fast in suitable problem domains.
Character-Based Input
:
OL systems read text character by character, activating a corresponding "character input neuron." This mechanism enables the system to learn languages without segmented words, like Chinese. The cascade of signaling from each character read determines sentence meaning and where to attach new understanding. This process represents the "Organic Growth" aspect of the system.
Overall, Anderson's OL algorithm emphasizes direct, efficient correlation tracking, dynamic idea evaluation and evolution (Neural Darwinism), and a nuanced approach to input processing. This method contrasts with the iterative, convolution-based learning of traditional deep learning, proposing a more direct and adaptable way of learning and evolving AI systems.
You
The learner creates, as its main output, a file containing a ���node wiring list" describing which neurons connect to which other neurons. Such a Competence Creation event is typically scheduled after each 10 million characters of corpus have been read. Given a Competence file name, UM1 loads that list and re-creates the learned neural structure and then uses that as the basis of its Natural Language Understanding Service.
Nuspeak Translator
The process described in the excerpt relates to how the Organic Learning (OL) system, specifically UM1 (presumably a model or version of the system), creates and utilizes a learned neural structure for Natural Language Understanding (NLU). Key aspects of this process include:
Creation of a Node Wiring List
:
The OL system's learner component constructs a file that details the connections between neurons, known as a "node wiring list."
This file effectively represents the learned neural network's structure, detailing which neurons are connected to which others.
Competence Creation Events
:
These events are scheduled periodically, typically after every 10 million characters of the input corpus are processed.
The timing suggests that the learning process is incremental and accumulative, building the neural network progressively as more data is ingested.
Utilization of the Competence File
:
Once a competence file is created, UM1 can load this file to reconstruct the learned neural network.
This reconstructed network forms the basis for the system���s Natural Language Understanding Service.
This approach implies that the learning and operational phases are distinct: first, the system learns and creates a model (the competence file), and then it operationalizes this model for NLU tasks.
Implications for NLU
:
This methodology suggests a more static approach to NLU, where the neural network structure is fixed based on the learning phase and then applied to understanding tasks.
It differs from some other AI models where the learning and operational phases might be more intertwined or continuous.
This approach reflects Monica Anderson's emphasis on direct, efficient correlation tracking and representation in neural networks, as the system directly encodes its learned structures for later use, rather than continuously adjusting them through iterative processes like Gradient Descent in traditional deep learning models.
You
9. Understanding Machine One
Monica Anderson
Monica Anderson
Jul 25, 2022 ��� 6 min read
9. Understanding Machine One
UM1 is a cloud based REST service that provides Natural Language Understanding (NLU) as a Service (UaaS). It can be viewed as providing a "large" language Model in the style of  GPT/3 and Google BERT but it currently cannot generate any language; it is strictly an Understanding Machine. And it isn't large.

If you send it some text, you will instantly get back UM1's Understanding of the text. Its Understanding may differ from yours, just like yours may differ from that of a co-worker, but will still be useful in apps requiring industrial strength NLU.

How UM1 Understands
The Understanding algorithm running in UM1 is much simpler than the Organic Learning algorithm running in the OL Learner. The Learner emits a Language Competence file designed to be loaded into a cloud based UM1 allocated to handle that language. In what follows, all learning has been done and UM1 is just using the collection of patterns in its loaded Competence to Understand any incoming "wild" text.
Nuspeak Translator
Monica Anderson's description of Understanding Machine One (UM1) outlines its functionality and approach to Natural Language Understanding (NLU). Key points from the article include:
UM1 as a Cloud-Based REST Service
:
UM1 is designed as a cloud-based service that offers NLU through a RESTful interface, categorizing it as Understanding as a Service (UaaS).
This design implies that UM1 can be integrated into various applications and systems requiring NLU capabilities.
Comparison to GPT-3 and BERT
:
UM1 is likened to large language models like GPT-3 and Google BERT in terms of providing language understanding capabilities.
However, a key distinction is that UM1 does not generate language; it is strictly focused on understanding text.
Understanding of Text
:
UM1 processes input text and provides an immediate understanding or interpretation of that text.
The understanding provided by UM1 might differ from human interpretation, similar to how different people may have varying interpretations of the same text.
Simplicity of the Understanding Algorithm
:
The algorithm running in UM1 for understanding text is described as much simpler than the Organic Learning algorithm used in the OL Learner.
This simplicity might refer to the operational efficiency or the algorithmic complexity of UM1 compared to the learning mechanism in OL.
Language Competence File
:
The OL Learner emits a Language Competence file, which is loaded into UM1 to enable its NLU capabilities.
This file likely contains the patterns and connections learned by the OL Learner, representing the knowledge base UM1 uses for understanding text.
Operational Focus of UM1
:
UM1's operation is solely focused on using the learned patterns in the loaded Competence file to understand incoming text.
This indicates that UM1's core function is to apply pre-learned models to new data, as opposed to continuous learning or language generation.
In summary, UM1 represents an application of Anderson's Organic Learning principles, specifically tailored for NLU tasks. It operates by leveraging pre-learned language models, focusing on interpreting and understanding text rather than generating it or continuing to learn from new data. This design choice reflects a specialized approach to NLU, prioritizing operational simplicity and efficiency.
You
I would like to know if you think you can make a simplified version of the organic learning algorthm?
Nuspeak Translator
Creating a simplified version of Monica Anderson's Organic Learning (OL) algorithm involves distilling its core principles and adapting them into a more streamlined form. While I can't create new algorithms or code, I can outline a conceptual framework for a simplified OL model based on its key features:
Pattern Recognition
:
Core to OL is recognizing and learning from patterns in input data.
In a simplified version, focus on identifying recurring sequences or motifs in the input stream.
Node and Link Structure
:
Use a basic graph structure to represent neurons (nodes) and their connections (links).
When a pattern is recognized, establish a link between relevant nodes.
Incremental Learning
:
Implement learning in stages, where the system updates its node-link structure as new data is received.
After processing a set amount of data, update the connections to reflect new patterns or remove irrelevant ones.
Selective Activation
:
Nodes activate only when relevant data or context is encountered.
This can be simulated by a condition check before a node is engaged in the processing.
Neural Darwinism
:
Incorporate a basic form of competition among nodes or patterns, where only useful or frequently activated nodes are retained.
Less useful or infrequently activated nodes could be pruned or have their connections weakened.
Character-Based Input Processing
:
Instead of processing complex structures, focus on simple, character-based input.
Each character could activate a corresponding node, leading to a cascade of activations based on learned patterns.
Static Learning Phase
:
Separate the learning phase from the operational phase.
Once the learning phase is complete, the model becomes static and is used for interpretation or understanding tasks.
This simplified version would capture the essence of OL's approach to learning and understanding, focusing on pattern recognition, incremental and selective learning, and a competition-based mechanism for retaining useful information. However, it's important to note that simplifying complex algorithms like OL may lead to a loss of some of its nuanced capabilities and efficiency.
You
We first note that UM1 can read streaming text. Normally it is given text as documents ranging in size from a few characters (such as in tweets and chat messages) to larger documents such as emails. In these cases the Understanding is about the entire document and is returned when the reading has finished. API options allow clients to ask the system for per-character, per-line, or per-paragraph results, to be used with infinite streams.

Deep Learning systems (at least those of the past) split longer documents and process those in batches small enough to fit in the GPUs.


OL and UM1 are reading the text one character at a time. Parsing text into words is implementing a Language Model, and we are philosophically deeply opposed to Language Models. Also, Chinese, Japanese, and several other Asian languages do not use word separating spaces, which makes word level input difficult.

If the atomic unit of input is a word, such as in traditional NLP and even in most DL based Understanding of language, then character level morphology features such as a plural-s suffix will be "below the atomic level of the algorithm" and now would require special processing such as stemming, which discards valuable information. Instead, OL/UM1 systems are designed to learn all character level (morphology) features. DL community has started to switch to character input.


The letter currently being read is looked up in an "Alphabet" Map (a table) that binds each different UNICODE input character to a specific Node in the Understander. We call these "Input Nodes". When a character is read, the framework will originate an initial "signal" that is sent to the Input Node bound to that character. Note that except for debugging purposes and (future) language generation purposes, the character we just read can now be discarded. As Friedrich Hayek said, in the brain there is no vision, no sound, no touch. There is just neurons signaling neurons; same thing in an OL or UM1 system. Retinal neurons could be said to correspond to the Input Nodes in OL and UM1.


The Input Node then propagates the signal to other Nodes connected to it with outgoing synapse-like links. This is similar to a Neuron in a brain signaling its axonal tree.


Some of these signaled Nodes propagate the signal to their outgoing target links, depending on conditions.


Every Node in the system is born with a unique ID number.


Some Nodes are known to be more important (Salient) than others. The ID numbers of these Nodes are returned to the caller in a list. After Understanding the whole message, the list will contain all Salient Nodes that propagated.


The list of ID Numbers is the Understanding you get from UM1. We call this "The Numbered Neuron API" and the resulting list is called a "moniform". It deserves a special name because in production environments the moniform is more complex than a simple list; it may contain annotations like meta-information and structure information such as chapter, page, line numbers etc.

We are not using any tagged learning material, just plain UNICODE text files. This is an enormous advantage over supervised learning, because well tagged text is expensive. The reason we can do this is that each Node (Concept) in the system is automatically given a unique tag ��� an ID number.

These ID numbers are opaque to the client. This is not a problem.

To find all documents on topic X, start with submitting one or more samples of topic X. If you want to detect the meaning of "I would like to know the balance in my checking account" in some tellerbot you are writing, then you can send that phrase as a topic-centroid-defining "Canonical Probe Phrase" to UM1 and save the resulting moniform in a table. The value in the "right hand column" in the table could be a token such as "#CHECKINGBALANCE" to use subsequently in Reductionist code, such as in a surrounding banking system.

UM1 is not a transformer; it can be described as a half-transformer, an encoder that encodes its understanding of incoming text as lists of numbers. The table of moniforms you build up when starting the client system will be used to decode the meaning. This is done entirely in the client end, in code you need to write or download.

To decode the Understanding received after sending UM1 a wild sentence (chatbot user input, a tweet to classify, etc) your client code will compare the numbers in the wild reply moniform to the numbers of all the moniforms in the probe table we built when we started, using Jaccard Similarity as the distance measure. The probe sentence that has the best matching moniform is the one we will say has semantics closest to the wild sentence.

Jaccard Distance tells how closely related two sets of items are by computing the set intersection and the set union between two sets A and B. The distance is computed by dividing the number of common elements (the intersection) by the total number of elements in either set. This provides a well behaved distance metric in the interval [0..1] as a floating point value. The canonical moniform with the highest Jaccard score is the best match.

In UM1, the ID numbers represent dimensions in a boolean semantic space. If the system has learned 20 million Nodes, each representing some identifiable language level concept, then we can view the numbers returned in the moniform as the dimension numbers of the dimensions which have the value "true". Consider a moniform that has 20 numbers (it varies by message length and input-to-corpus matchability) selected from a possible 20 million to get an idea of the size of the semantic space available to OL.
Nuspeak Translator
Monica Anderson's description of Understanding Machine One (UM1) provides a detailed look into its functioning and methodology for Natural Language Understanding (NLU). The key features of UM1 include:
Streaming Text Input
:
UM1 can process text in various formats, from short messages like tweets to longer documents like emails.
The system allows flexibility in output, offering per-character, per-line, or per-paragraph results.
Character-Level Input Processing
:
Unlike traditional NLP and DL systems that use word-level input, UM1 processes text at the character level.
This approach is particularly advantageous for languages like Chinese or Japanese, which don���t use space-separated words, and also allows for the understanding of morphological features like plural-suffixes.
Alphabet Map and Input Nodes
:
Each character read by UM1 is looked up in an "Alphabet" Map, linking UNICODE characters to specific Nodes in the system, termed "Input Nodes."
An initial signal is sent to the Input Node corresponding to each character, starting a cascade of signals within the network.
Propagation of Signals
:
The Input Node propagates signals to other connected Nodes, similar to neuronal signaling in the brain.
Signal propagation depends on certain conditions, mirroring the selective activation of neurons.
Node Salience and ID Numbers
:
Each Node in UM1 is assigned a unique ID number, with some Nodes identified as more important or salient.
After processing a text, UM1 returns a list of ID numbers of all salient Nodes that propagated during the understanding process.
Moniforms as Output
:
The output from UM1 is a "moniform" ��� a list of ID numbers representing the Understanding of the text.
Moniforms are more than just lists; they can include meta-information and structural data.
Use of Plain Text Files
:
UM1 doesn���t require tagged learning material, using plain UNICODE text files for learning, which is a significant advantage over supervised learning models.
Client-Side Decoding
:
UM1 functions as an encoder, encoding its understanding into lists of numbers (moniforms).
Decoding the meaning of these moniforms is done on the client side, using a table of moniforms built upon initialization.
Jaccard Similarity for Decoding
:
To interpret the moniforms, UM1 uses Jaccard Similarity to compare the sets of ID numbers, determining the closest semantic match to the input text.
Semantic Space Representation
:
The ID numbers in the moniform represent dimensions in a Boolean semantic space.
With millions of Nodes, each representing a language concept, the semantic space UM1 utilizes is vast and detailed.
In summary, UM1���s approach to NLU is unique in its character-level processing, direct representation of understanding through node signaling, and reliance on client-side decoding of semantically rich outputs. This method contrasts with conventional NLP systems by avoiding language models and embracing a more organic, neuron-like processing and signaling methodology.
You
I'm not sure if you can do it yet, but can we try to make an OL algorithm say in Python, that reads Heinlein to learn English
Nuspeak Translator
Creating a full-fledged Organic Learning (OL) algorithm similar to Monica Anderson's model would be quite complex, especially since it involves intricate mechanisms like Neural Darwinism, unique node creation, and salient neuron identification. However, I can outline a conceptual framework for a basic version that takes inspiration from OL principles, focusing on character-level input processing and pattern recognition. This simplified version can be implemented in Python, designed to process text from an author like Robert Heinlein to learn English patterns.
Here's a high-level conceptual outline of such an algorithm:
Character-Level Input Processing
:
Read the text data character by character.
For each character, create or activate a corresponding 'input node'.
Pattern Recognition and Node Linking
:
Detect recurring character sequences (patterns).
Create links between nodes representing these sequences.
These links are akin to synapse-like connections in OL.
Incremental Learning and Node Creation
:
As more text is processed, continue to update the node-link structure to reflect new patterns.
Create new nodes for new patterns or characters as needed.
Node Activation and Propagation
:
When a character is processed, activate the corresponding node and propagate this activation to connected nodes.
The propagation can be limited based on certain conditions or thresholds to simulate selective activation.
Storing and Utilizing Learned Patterns
:
Maintain a record of frequently activated patterns or sequences.
Use these patterns to understand or interpret new text inputs.
Basic Implementation in Python
:
Utilize Python's data structures (like dictionaries for node mapping, lists or sets for connections) to build the node-link structure.
Implement reading and processing functions to handle text data character by character.
Application on Heinlein's Texts
:
Apply this algorithm to the texts of Robert Heinlein.
The algorithm will learn English patterns based on the unique style and vocabulary used by Heinlein.
This framework provides a starting point for developing a simplified OL-inspired algorithm. The actual implementation would require programming the specific logic for pattern recognition, node linking, and activation propagation. However, it's important to note that this simplified version will not encompass all features of a full OL system, like Neural Darwinism or the complex neuron signaling mechanisms found in more advanced models.
You
I think you can try it
Nuspeak Translator
Creating a basic implementation of an Organic Learning (OL) inspired algorithm in Python involves developing a system that processes text character by character, recognizing patterns, and creating connections similar to neural networks. Here's a simple conceptual Python script to illustrate this idea:
python
Copy code
class
Node
:
def
__init__
(
self, character
):
        self.character = character
        self.connections = {}
def
add_connection
(
self, next_node
):
if
next_node.character
in
self.connections:
            self.connections[next_node.character][
'weight'
] +=
1
else
:
            self.connections[next_node.character] = {
'node'
: next_node,
'weight'
:
1
}
def
get_connections
(
self
):
return
self.connections
class
OLAlgorithm
:
def
__init__
(
self
):
        self.nodes = {}
        self.previous_node =
None
def
process_character
(
self, character
):
if
character
not
in
self.nodes:
            self.nodes[character] = Node(character)

        current_node = self.nodes[character]
if
self.previous_node:
            self.previous_node.add_connection(current_node)
        self.previous_node = current_node
def
process_text
(
self, text
):
for
character
in
text:
            self.process_character(character)
def
display_network
(
self
):
for
char, node
in
self.nodes.items():
            connections = node.get_connections()
print
(
f"Node '
{char}
' is connected to:
{[
f'
{c}
(weight:
{connections[c][
'weight'
]}
)'
for
c
in
connections]}
"
)
# Example usage
ol_algorithm = OLAlgorithm()
text =
"Example text from Heinlein."
ol_algorithm.process_text(text)
ol_algorithm.display_network()
This script defines two classes,
Node
and
OLAlgorithm
.
Node
represents a character and its connections to subsequent characters.
OLAlgorithm
processes a given text and builds a network of
Node
objects.
When a character is processed:
If it's not already a node, a new
Node
object is created.
If there's a previous character (node), a connection is created or strengthened between the previous and current nodes.
The
display_network
method in
OLAlgorithm
prints the connections for each node, showing how characters are linked based on the input text.
This script is a rudimentary interpretation of the OL principles and lacks many complexities of a full OL system. It demonstrates basic pattern recognition through character connections but does not implement advanced features like selective activation or Neural Darwinism.
To use this script with Heinlein's texts, you would input a text excerpt from Heinlein into the
process_text
method of an
OLAlgorithm
instance. The script will then build a character-level network reflecting the patterns in Heinlein's writing style.
You
#! /usr/bin/env python3     # -*-python-*-
# coding: utf-8
# freetest --  Document similarity classification using Jaccard distance
# on moniforms nested in a (possibly deep) JSONArray structure returned from UM1
# Code by Monica Anderson monica@syntience.com 20200811
# Use this code at your own risk any way you want

import sys, os, requests, urllib, json, colorama, time
from colorama import Fore, Style
from datetime import datetime

logtraffic = False                                                              # Set this True to see UM1 network traffic
logjaccard = True                                                              # Demonstrate jaccard score as a distance measure over sets. If this is True, then logoutomes should be set False to avoid ugly output
logoutcomes = False                                                             # Print outcomes of individual tests as single position characters. "=" means ambiguous. "?" means problems. Red is wrong, green is correct guess
logmisc = False                                                                 # Set this True to see other details of tests

logtexts = True                                                                 # These texts are quite verbose so we sometimes tunr these off. They only appear if logjaccard is True
logmoniforms = False                                                            # These moniforms are even more verbose so we turn these off unless we really need them. They only appear if logjaccard is True

testpath = 'chat-200.tsv'                                                       # Test file with 200 string classification tests based on data form Quora Question Pairs (QQP) test benchmark. Feel free to edit those or provide a different file
maxtestlines = 200                                                              # Limit tests to this many lines. None=all test cases in file. Larger files (2000 test cases) are available
writefailurefile = False                                                        # Write failedtests.tsv file of all failing test cases

um1service = "https://free.understanding-machines.com/understand"            # The servicce to use

payload = None                                                                  # Global copy of payload so we can retrieve the texts we sent in when processing the results
testsdone = 0                                                                   # How many test cases that actually returned data to analyze
testfileproblems = 0                                                            # Syntax errors and other problems found in our test data file -- Lines like these should be corrected or replaced
totaltestchars = 0                                                              # Total test characters understood/processed
numberunderstandings = 0                                                        # Total number of strings sent to Understander -- normally 6 per test
truths = []                                                                     # Correct answers -- never sent to UM1
alllines = []                                                                   # Array of input lines -- one test case each

def understand(payload, options):
    try:
        response = requests.post(um1service, json.dumps({'payload':payload, 'options':options}))    # Send payload and Understanding options to UM-1 server
        if response:
            try:
                understanding = response.json()                                 # Parse returned string as JSONObject to return it as a python dict
            except Exception as err:
                print(f"UM-1 understanding exception: {err} -- Response:{response}")  # Exception parsing result JSON. No more information available
                return {"error": err}
            if understanding is not None:                                       # Response parsing succeeded. responsed was received as a JSONObject and was parsed into "understanding" (most often used name) which is a python dict
                if logtraffic:print(f"\npayload='{payload}'\nResult: {json.dumps(understanding)}")
                error = understanding.get('error')                              # Check if there is an error message added by UM1 server or UM1 itself
                if error:
                    print(f"UM-1 error: {error}")                               # If so, print it here so we won't miss it even if caller is not doing proper error checking
                return understanding                                            # In any case, error message or not, return entire JSON to caller
            else:
                print("Response form UM1 is not in valid JSON format")          # Non-exception JSON parse nevertheless did not return a valid result. We expect a python dict of meta-information at this level
        else:
            print("NO response from UM-1")                                      # Non-exception no-response from UM1 -- Typically, we received no JSON to parse.
    except Exception as ex:
        print(f"UM-1 communications exception: {ex}")                           # Serious server side or communications error (such as UM1 restart or network disconnect)
    return None

def createpayload():                                                            # Create a list of testcases which are lists of target and alternatives which are each lists of numbers representing the Understanding of each
    global numberunderstandings, testfileproblems, truths, totaltestchars
    payload = []; testfileproblems = 0; totaltestchars = 0                      # Construct and return a payload based on test file contents. testfileproblems counts syntax errors in test file.
    with open(testpath) as testfile:
        for lineno, line in enumerate(testfile):                                # We read entire file
            if len(line) < 6 or line.startswith('#'): continue                  # We allow comment lines and (nearly) empty lines. They add to line numbers in lineno but not to testcount
            line = line.rstrip()
            alllines.append(line)                                               # Save line, slightly sanitized, in alllines
            parts = line.split("\t")                                            # Separate the tab-separated fields
            if len(parts) < 4:                                                  # We need at least truth, target, and two test cases per test/line (that is why "4") but will happily handle any number of test cases beyond that.
                if lineno < 10: continue                                        # Quietly ignore header lines until we get a bit into the file
                testfileproblems += 1                                           # After those, all lines better have well formatted data in them or we treat it as an error
                continue                                                        # and then we soldier on
            truths.append(int(parts[0]))                                        # Keep truths here. Do not send them to backend because it does not need to know :-) 
            payload.append(parts[1:])                                           # Append the rest of the strings in the testcase (a list of target string and two or more (5 in this case) strings to compare with) to payload list of testcases
            for p in parts[1:]: totaltestchars += len(p)                        # totaltestchars is total numbers of characters in payload
            numberunderstandings += len(parts) - 1                              # Truth is only thing we don't evaluate. We HOPE these are all strings. The count will be off if they are not. This should be counted in backend and returned
            if maxtestlines and maxtestlines <= len(payload): break             # Allow limiting to only a few lines of test cases if so desired.
    return payload

def classifyunderstandings(understandings, of):                                 # understandings is a JSONObject -- it has a few fields of returned metadata, and the result itself is in the field "moniform"
    global testsdone, testfileproblems
    sumofsetsizes = 0; nosemantics = 0; ambiguouscount = 0; correct = 0; incorrect = 0; testsdone = 0; sumofcertainties = 0; certaintiescount = 0; 
    candidatemoniformcount = 0; targetmoniformcount = 0; sumofintersections = 0; sumofunions = 0; emptyintersections = 0; failures = 0

    winoutcome = f"{Fore.GREEN}WIN{Style.RESET_ALL}"
    runnerupoutcome = f"2ND"
    amboutcome = f"{Fore.YELLOW}AMB{Style.RESET_ALL}"
    failoutcome = f"{Fore.RED}FAIL{Style.RESET_ALL}"

    testcases = understandings.get("moniform")                                  # Extract result from returned result + metadata dict/map/JSONObject
    if not testcases or len(testcases) == 0:
        return f" ------ No concepts (moniform) entry in {understandings}"      # UM1 did not return a "moniform" field which is quite surprising
    testindex = 0
    with open("failedtests.tsv", "w") as of2:                                   # Open failed tests output file
        for testindex in range(len(testcases)):                                 # Loop over each of the given test cases (typically 200). A testcases is here a list of (typically six) moniforms (lists of numbers), where first is the target
            testcase = testcases[testindex]
            if logmisc:print(f"length of testcase={len(testcase)}")
            if testcase and len(testcase) >= 3:                                 # Required: a target and at least two candidates to decide between. We typically use five candidates, which means six moniforms per sublist
                targettext = payload[testindex][0]                              # Extract target text for this test case from payload. Note that in payload, there is no truth column so target is index 0
                targetmoniform = testcase[0]                                    # Understanding of target, as the simplest kind of moniform, alist of integers without duplicates, sorted by declining salience estimates
                if logmisc:print(f"length of targetmoniform={len(targetmoniform)}")
                if targetmoniform:
                    candidatemoniforms = testcase[1:]
                    targetmoniformcount += 1                                    # Count actual target moniforms in case we have indefinite number of valid test cases
                    if logmisc:print(f"length of candidatemoniforms={len(candidatemoniforms)}")
                    if candidatemoniforms:
                        candidatemoniformcount += len(candidatemoniforms)
                        targetset = set(targetmoniform)
                        sumofsetsizes += len(targetset)                         # Gather statistics: We track average size for all moniforms whether target or candidate. This is allowed because they will all be coming from the same source
                        winnerindex = -1
                        winnerscore = -1
                        runnerupscore = -1                                      # "margin" statistic tells us the margin between the winner and the runner-up which is a measure of our certainty of the answer
                        ambiguous = 0
                        resulttuples = []
                        certainty = 0
                        
                        for i in range(len(candidatemoniforms)):
                            candmoniform = candidatemoniforms[i]               # loop over all candidate moniforms
                            if candmoniform:
                                if len(candmoniform) == 0: nosemantics += 1
                                candset = set(candmoniform)
                                sumofsetsizes += len(candset)                   # Gather statistics

                                intersection = targetset & candset              # Intersection of target moniform and candidate moniform
                                intersectionlen = len(intersection)
                                
                                union = targetset | candset
                                unionlen = len(union)

                                jaccardscore =  intersectionlen / unionlen      # Compute jaccard distance from target monifor to this candidate moniform

                                if winnerscore == jaccardscore:                 # Tied top score
                                    runnerupscore = jaccardscore
                                    ambiguous += 1                              # Mark this as ambiguous
                                if winnerscore < jaccardscore:                  # New winner
                                    runnerupscore = winnerscore                 # Previous winner becomes the runner-up
                                    winnerscore = jaccardscore
                                    winnerindex = i
                                    ambiguous = 0                               # If we have a clear winner, then we are not ambiguous
                                elif runnerupscore < jaccardscore:              # We must handle the case where the new score beats the runner up score but not the winner score
                                    runnerupscore = jaccardscore

                                sumofintersections += intersectionlen           # Gather statistics
                                sumofunions += unionlen                         # Gather statistics
                                if intersectionlen == 0: emptyintersections += 1
                                truthindex = truths[testindex]
                                resulttuples.append((i, jaccardscore, candmoniform, payload[testindex][0], payload[testindex][i + 1], truthindex)) # extraxt target and candidate texts from payload. offset 0 is target, rest are candidates
                            else: failures += 1

                            ## End of loop over candidates

                        if runnerupscore > -1 and winnerscore > -1:
                            certainty = winnerscore - runnerupscore
                            sumofcertainties += certainty
                            certaintiescount += 1

                        if logjaccard:                                             # demonstrate jaccard score as a distance measure
                            first = True
                            for index, score, moniform, targettext, candtext, truthindex in resulttuples:
                                if first:
                                    print("")
                                    if logmoniforms: print(f"TARGETMONIFORM:                         {targetmoniform}")
                                    if logtexts:     print(f"{Fore.YELLOW + Style.BRIGHT}                                                {targettext}{Style.RESET_ALL}")
                                    first = False
                                candmoniform = candidatemoniforms[index]
                                monidisp = moniform if logmoniforms else ""
                                textdisp = candtext if logtexts else ""
                                scoredisp = round(100.0 * score, 2)
                                certaintydisp = round(100.0 * certainty, 2) if score == winnerscore else ""
                                outcome = ""
                                if index == winnerindex:
                                    if truthindex == index:
                                        if score == runnerupscore:
                                            outcome = amboutcome
                                        else:
                                            outcome = winoutcome
                                    else:
                                        outcome = failoutcome
                                elif score == runnerupscore:
                                    if winnerscore == runnerupscore:
                                        outcome = amboutcome
                                    else:
                                        outcome = runnerupoutcome
                                print(f"  {index}\t{outcome}\t{scoredisp}\t{certaintydisp}\t{monidisp}\t{textdisp}\t")

                # End of test case analysis. 

                testsdone += 1                                                  # Gather statistics
                ambiguouscount += ambiguous                                     # Gather statistics

                if winnerindex == -1:                                           # Ensure we actually have a winner. If not, note that and try next testcase
                    if logoutcomes:
                        sys.stdout.write(f"{Fore.BLUE}?")
                    of.write(f"{Fore.BLUE}?")
                    nosemantics += 1                                            # Count documents where we could not discern any semantics for statistics printout at end
                    continue

                if winnerindex == truthindex:
                    correct += 1                                                # We allow that in case of several equal top scores we guess at the first one of them and if that is correct, then we are correct
                    if ambiguous:
                        if logoutcomes:
                            sys.stdout.write(f"{Fore.GREEN}={Style.RESET_ALL}")     # but we neverteless track that this was an ambiguous win by printing a green equals-sign rather than the guess we guessed
                        of.write(f"{Fore.GREEN}={Style.RESET_ALL}")
                        if writefailurefile: of2.write(f"{winnerindex}\t{alllines[testindex]}\n") # Columns are our guess, truth, target, and all candidates
                    else:
                        if logoutcomes:
                            sys.stdout.write(f"{Fore.GREEN}{winnerindex}{Style.RESET_ALL}") # Green digit is the index of our correct guess
                        of.write(f"{Fore.GREEN}{winnerindex}{Style.RESET_ALL}")
                else:
                    incorrect += 1
                    if writefailurefile: of2.write(f"{winnerindex}\t{alllines[testindex]}\n") # Columns are our guess, truth, target, and all candidates
                    if ambiguous:
                        if logoutcomes:
                            sys.stdout.write(f"{Fore.RED}={Style.RESET_ALL}")       # Ambiguous results where we guessed werong are indicated with a red equals sign
                        of.write(f"{Fore.RED}={Style.RESET_ALL}")
                    else:
                        if logoutcomes:
                            sys.stdout.write(f"{Fore.RED}{winnerindex}{Style.RESET_ALL}") # Red digit is the index of our erroneous guess
                        of.write(f"{Fore.RED}{winnerindex}{Style.RESET_ALL}")
            else: failures += 1

    # Compute some batch-wide statistics and return a summary of what happened for caller to print if they wish

    if logoutcomes: print("");
    accuracy = 0
    avgsetsize = 0
    avgintersectionsize = 0
    margin = 0
    if candidatemoniformcount > 0:
        avgsetsize = round(sumofsetsizes / (targetmoniformcount + candidatemoniformcount), 2)
        avgintersectionsize = round(sumofintersections / (targetmoniformcount + candidatemoniformcount), 2)
        avgunionsize = round(sumofunions / (targetmoniformcount + candidatemoniformcount), 2)
    if testsdone > 0 and sumofsetsizes > 0:
        accuracy = round(100.0 * float(correct) / float(testsdone), 1)
        margin = round(100.0 * float(sumofcertainties) / float(testsdone), 2)
    return f"{Fore.GREEN}Accuracy:{accuracy:>5}% {Fore.YELLOW} avg-margin:{margin:>5}%{Style.RESET_ALL} testsdone:{testsdone:<6} understanding-failures:{failures:<4} meaningless:{nosemantics:<4}avg-setsize:{avgsetsize:<6} avg-intersections:{avgintersectionsize:<6} empty-intersections:{emptyintersections:<4} ambiguous:{ambiguouscount:<4} testfileproblems:{testfileproblems:<4}{Style.RESET_ALL}"

def classifyall(options):
    global um1service, saliencers, testsdone, numberunderstandings, payload
    if logjaccard and logoutcomes:
        print("Cannot use logjaccard and logoutcomes together at this time. Please set one of these two flags to False")
        return
    numberunderstandings = 0 ; starttime = time.time();  serverclass = options.get("server")
    payload = createpayload()                                                   # Make payload globally available so we can translate results back into strings
    if logmisc:
        print(f"Payload={payload}")
        print(f"len(payload)={len(payload)}")
        print(f"len(payload[1])={len(payload[1])}")
    if logtraffic:print(f"serverclass is {serverclass}   um1service URL is {um1service}  options is {options}")
    understandings = understand(payload, options)
    if logtraffic:print(f"understandings={understandings}")
    if understandings:
        numbertests = len(alllines)
        totalticks = understandings.get("totalticks")
        uptimesecs = understandings.get("uptimesecs")
        corpussize = understandings.get("corpussize")
        createdzulu = understandings.get("createdzulu")
        competenceid = understandings.get("competenceid")
        testruntimems = understandings.get("ms")
        competenceuuid = understandings.get("competenceuuid")
        learningtimesecs = understandings.get("learningtimesecs")
        with open("semsimout.txt", "a") as of:
            of.write("\n" + 304 * '=' + "\n")
            of.write(f"Time: {datetime.now().isoformat(timespec='minutes')}  Server Uptime (s): {uptimesecs} Options: {options}\n")
            of.write(f"Corpus of {corpussize} chars learned in {learningtimesecs} seconds - Competence id: {competenceid}  UUID: {competenceuuid}\n")
            of.write("\n\n       ")
            print(f"Time: {datetime.now().isoformat(timespec='minutes')}  Server Uptime (s): {uptimesecs} Options: {options}")
            print(f"Corpus of {corpussize} chars learned in {learningtimesecs} seconds - Competence id: {competenceid}  UUID: {competenceuuid}")

            if logoutcomes:                                                     # Print the fancy two-line header
                print("       ", end="")
                for t in range(1, 1 + int((numbertests + 1) / 10)):
                    print(f"        {t:>2}", end="")
                    of.write(f"        {t:>2}")
                print("\nTest # ", end="")
                of.write("\nTest # ")                                           # Also write it to of
                for u in range(1, numbertests + 1):
                    print(f"{u%10}", end="")
                    of.write(f"{u%10}")
                of.write(f"\n       ")
                print(f"\n       ", end="")
               
            ## Do the actual analysis given the understandings we received above. Margin is jaccard target distance difference from winner to runner-up

            if logjaccard: 
                print(f"\nIndex   Outcome Jaccard Margin")
                print(f"==============================")
            summary = classifyunderstandings(understandings, of)                # Sets testsdone
            if logjaccard:
                print(f"  ^      ^       ^        ^   ")
                print(f"Index   Outcome Jaccard Margin\n")
            print(summary)
            of.write(summary)
            of.write("\n")
            elapsed = time.time() - starttime
            servicetime = 0
            cps = 0
            if testsdone > 0:
                if testruntimems: 
                    servicetime = int(testruntimems)
                    cps = round(1000 * totaltestchars / testruntimems)
                avgstring = f" Average is {(1000.0 * elapsed / testsdone):<.4} ms/test"
                avbbackendtime = f" Average is {(servicetime / testsdone):<.4} ms/test   {(servicetime / numberunderstandings):<.4} ms/sample   Speed was {cps} cps "
            else:
                avgstring = ""
                avbbackendtime = ""
            print(f"For {testsdone} tests with a total of {numberunderstandings} samples, total {totaltestchars} chars, real time was {int(elapsed * 1000):>5} ms {avgstring}  Batch service time: {servicetime} ms{avbbackendtime}")  
            testsdone = 0
            
if __name__ == '__main__':          
    classifyall({"topn" : 60, "debug" : False})
Nuspeak Translator
The provided Python script is a complex implementation of a text classification system using Jaccard distance on moniforms (sets of node ID numbers) returned from an Understanding Machine (UM1) service. It's an application of the principles discussed in Monica Anderson's work on Organic Learning (OL). The script includes the following key components and functionalities:
Configuration Variables
:
Variables for logging, test file path, and UM1 service URL.
Options for tracking different types of output and logging details.
Communication with UM1 Service
:
The
understand
function sends a payload to the UM1 service and retrieves the response, which includes the "moniforms" representing the understanding of text.
Payload Creation
:
The
createpayload
function reads a test file (
testpath
) and constructs a payload for the UM1 service.
The payload consists of test cases, each containing a target string and several alternatives for comparison.
Classification Using Jaccard Distance
:
The
classifyunderstandings
function processes the UM1 response to calculate the Jaccard distance between target and candidate moniforms.
It identifies the best matching candidate for each target based on this distance.
Logging and Statistics
:
The script logs various metrics, such as test outcomes, Jaccard scores, and ambiguities.
It compiles statistics about the tests, including accuracy, margin, and test-specific issues.
Running Classification Tests
:
The
classifyall
function orchestrates the entire process of sending payloads to UM1, receiving responses, and classifying the results.
It logs comprehensive details about the test runs, including timing and efficiency metrics.
Main Execution Flow
:
The script's main section calls
classifyall
with specific options, triggering the execution of the classification tests.
This script exemplifies a practical application of OL principles, particularly in how it interprets and classifies text. It's a detailed and sophisticated example of using character-level understanding and pattern recognition, leveraging external NLU services to process and understand text in a manner consistent with OL's philosophy.
You
Maybe later we can write a new test. Does it give you any more insight into how the selection process might work in the organic learning algorithm. Elsewhere she says that the yoneda lemma (you are known by the company the you keep) is a justification for word embeddings in NLU.
Nuspeak Translator
The Python script you provided, which interacts with the Understanding Machine One (UM1) service, offers some insight into the selection process in the Organic Learning (OL) algorithm, particularly in how it deals with understanding and classifying text based on patterns and context. Here's a closer look at how this relates to OL's principles and the concept of the Yoneda Lemma in Natural Language Understanding (NLU):
Pattern Recognition and Contextual Understanding
:
OL's approach, as illustrated in the script, involves understanding text by recognizing patterns and their contexts. This is evident in how the script processes moniforms (sets of node ID numbers) that represent concepts or understanding derived from the text.
The Yoneda Lemma, in a linguistic context, implies that the meaning of a word (or concept) can be understood based on its relationships or interactions with other words. In NLU, this is akin to understanding words by the 'company they keep,' which is a foundational idea behind word embeddings.
Jaccard Distance for Selection
:
The script uses Jaccard Distance to measure similarity between sets of concepts (moniforms). This is a practical application of selecting or identifying the most relevant or similar concepts based on their contextual relationships, resonating with the Yoneda Lemma's principle.
Character-Level Input and Incremental Learning
:
UM1���s character-level processing aligns with OL's philosophy of building understanding incrementally, one character at a time. This granular approach allows for a nuanced comprehension of language that includes morphological features.
The incremental buildup and pattern recognition are essential for OL, where the learning algorithm develops a network (connectome) of nodes and links representing linguistic concepts and their interrelations.
Word Embeddings and Contextual Meaning
:
In NLU, word embeddings capture the semantic properties of words by placing them in a high-dimensional space where distances between words reflect their semantic similarities.
This concept complements the OL's approach and the Yoneda Lemma by emphasizing that the understanding of a concept (or word) is enriched and defined by its associations and relations with other concepts.
Selection Process in OL
:
The OL algorithm, as suggested by the script's approach, likely selects and reinforces patterns (connections between nodes) that are frequently encountered and contextually relevant. This is akin to strengthening certain word embeddings based on their usage and context in language.
The selection process in OL, therefore, would involve both identifying prevalent patterns in the input data and understanding the context in which these patterns occur, leading to a dynamic and evolving model of understanding.
In summary, the script and UM1's method provide a practical demonstration of OL principles, where the selection process is guided by pattern recognition, contextual understanding, and relationships among concepts. This approach is congruent with the Yoneda Lemma's application in NLU, particularly in how the meaning and relevance of concepts are discerned through their contextual relationships.
You
David Mal brought up the "Stochastic Parrot" in a post. My reply:

Melanie Mitchell's "Stochastic Parrot" could have used a better metaphor.

Consider the famous parrot named Alex https://en.wikipedia.org/wiki/Alex_(parrot) .

Human: "How many red things on the tray?"
Alex the Parrot: "Four"

Alex knew hundreds of words, could count, knew the names of colors, etc.
Parrots have enough neurons and vocal cords to Understand and produce significant amounts of language.

And this is the clue to all you parrot fans: May I suggest y'all are desperately trying to keep humanity on yet another crumbling pedestal: We are not the ultimate crown of creation, not created differently from the animals, Earth is not the center of the Universe, humans are not the only animal with either Reasoning (Corvid��, others) and Understanding (most others).

Try this on for size: All agents with sensory input perform the same algorithms for Cognition and Understanding in order to jump to conclusions on scant evidence based on prior experience.

This has worked for millions of years and we are merely late newcomers to this game. But general cognition and Understanding, which includes Language Understanding for species that have made it to language) is a simple enough algorithm that it can be implemented in neurons, which means it can be implemented in software simulating neurons (and I am the main proponent of the more bioplausible discrete-neuron systems, just for the record).

How about "The brainpower required for the ability to recognize objects and sequences in your environment is sufficient to Understand language to some level".

Net-net: Language Understanding is a much simpler task than we have ever believed until now (because we have been stuck in The Reductionist Stance until 2012). It turns out Reasoning is not necessary for language, but Understanding is, and it's relatively trivial. And believing machines cannot learn to  Understand human languages is just speciesist.
Nuspeak Translator
Your reply to David Mal's mention of the "Stochastic Parrot" concept, introduced by Melanie Mitchell, presents an intriguing perspective on language understanding, both in animals and artificial intelligence systems. Your argument hinges on several key points:
Comparison with Alex the Parrot
:
Alex, a famously intelligent parrot, demonstrated the ability to understand and respond to complex language cues, such as counting and identifying colors.
This example challenges the notion that sophisticated language understanding is exclusive to humans.
Debunking Human Exceptionalism
:
You argue against the idea of human exceptionalism in cognition and language understanding, suggesting that it's a form of keeping humanity on a "crumbling pedestal."
You point out that humans are not the only species capable of reasoning and understanding, citing examples like corvids (crows and related birds).
Cognition and Understanding as Universal Algorithms
:
You propose that all agents with sensory input perform similar algorithms for cognition and understanding, which are essential for making inferences based on prior experience.
This idea suggests that general cognition and language understanding are simpler tasks than previously believed and are not exclusive to human brains.
Implementation in Software and Neurons
:
You argue that since cognition and language understanding can be implemented in neurons, they can also be realized in software simulating neurons.
You advocate for discrete-neuron systems as a more biologically plausible approach to simulating these cognitive processes.
Language Understanding as a Relatively Simple Task
:
Contrary to traditional views, you assert that reasoning is not necessary for language understanding, which is a relatively trivial task.
You conclude that denying machines the potential to understand human languages is speciesist, as it underestimates the simplicity and universality of the underlying cognitive processes.
Your perspective challenges conventional views on language understanding and cognition, advocating for a more inclusive and universal approach. By drawing parallels between animal cognition and artificial intelligence, you suggest that understanding and processing language may be less about complex reasoning and more about fundamental cognitive algorithms that can be replicated in AI systems. This approach has implications for AI research, particularly in developing more effective and biologically inspired language understanding models.
You
That was a post from Monica on Sept 14, 2023

Here are a few of her comments:

Luis Mariano For LLM's, it's early technology. We'll get there, and I'm working on it.

For parrots, i'd guess it's a RAM size constraint.

Also, LLMs and DL and DDNNs (my stuff) all excel at identifying contexts.
20th Century NLP could not handle contexts.

DNNs can discover context within context and learn separate meanings for each. This is one of their strengths.

Statistical NLP methods discard context as soon as possible because it is regarded as a nuisance by people adopting The Reductionist Stance.

Modern DNN based NLU instead EXPLOITS context for disambiguation and other purposes.

>"If I understand you correctly, think you are advocating for or ascribing universal grammar"

Nope. Understanding is (IMPO) a result of somehow identifying a smallest subset of all possible previously known concepts that fulfills the most constraints in the current situation. It's all Set Theory. Who needs grammars?

And you know, I assume, that if grammars were actually used by humans, that we all might have different grammars. My "grammar" for English (were we to claim I had one) would be moderated by all languages I learned before and after. (Hm. I just realized English is missing specific word endings to express hypotheticals... ����)

Grammars are Reductionist. My systems (and most likely LLMs also) do not contain any grammars.

And YOU are not using grammars to understand your native language. You won't have the time to process language consciously while in a conversation. Your replies appear in your mouth, unbidden by your Reasoning capabilities.

Skills (snowboarding, each first learned native language) are learned Holistically. Which means without grammars.

IMO, Understanding actually works entirely "Without Models". But the word "Model" is part of "Large Language Models" and I'm losing that fight. What do I mean? I claim LLMs are not Models in an Epistemological sense and are hence misnamed.

So we are automatons way above the Planck scale. Our entire apparatus for cognition and recognition is below our conscious control. It has evolved, in all species leading up to us, to be a pretty general learning device, possibly with a specialty in learning sequences.

LLMs are machines capable of discovering correlations and learning from them. And so are we.

FWIW, I use "AI" as a suitcase word. If you insist on a definition I could stretch to "Systems capable of autonomous Epistemic Reduction such as Deep Neural Networks, existing and future LLMs, Deep Learning, Spiking Neuron Systems, Organic Learning, and UM1 (Understanding Machine One)". The last two are my own systems. I'm not limiting this to language. Tesla cars can do this with video data.

LLMs are the current spearhead in the Understanding domain. They and their descendants (which I sometimes label as "LLM++" ) are just getting started.

Reasoning is still research.

Saty Raghavachary My LLMs don't use numbers. Or GPUs.
Just set theory and Neural Darwinism.

They ARE radically different from DL and transformers.

Saty Raghavachary DL uses a 1024 dimensional space with 16, 8, or 4 bits resolution.  

I use one billion Boolean dimensions

Comparable expressive power.

Switch Euclid for Jaccard for semantic distance
Nuspeak Translator
Monica Anderson's comments from September 14, 2023, provide valuable insights into her views on the development of AI, particularly in the domain of language understanding and cognition. Her thoughts cover several key points:
Early Technology of LLMs
:
She acknowledges that Large Language Models (LLMs) like GPT are in their early stages and believes that progress will be made, indicating her involvement in such advancements.
Constraints of Parrots and AI
:
For parrots, she speculates the limitation might be due to 'RAM size' constraints, metaphorically speaking about their cognitive limitations.
LLMs, along with her own developments in Deep Neural Networks (DDNNs), are adept at identifying contexts, a capability that 20th-century NLP methods lacked.
Context in Modern NLP
:
Modern Deep Neural Network (DNN) based NLU systems exploit context for disambiguation and other purposes, unlike statistical NLP methods which tend to discard context.
Rejection of Universal Grammar
:
Anderson dismisses the idea of a universal grammar, proposing instead that understanding is about identifying the smallest subset of all known concepts that fulfill the most constraints in a given situation.
She asserts that humans do not use grammars to understand their native language; rather, understanding is a holistic process.
Language Understanding Without Models
:
She challenges the concept of 'models' in LLMs, arguing that understanding works "without models" in an epistemological sense.
Anderson suggests that cognition and recognition in humans are largely automatic and evolved to be general learning devices.
LLMs as Correlation Discovery Machines
:
She views LLMs as machines capable of discovering correlations and learning from them, similar to human learning processes.
LLMs are seen as the forefront in the domain of understanding, with significant potential for growth and development.
Organic Learning and UM1
:
Anderson���s own systems, Organic Learning and Understanding Machine One (UM1), operate differently from traditional DL and transformers, using set theory and Neural Darwinism.
Her approach involves a billion Boolean dimensions, providing comparable expressive power to traditional DL but with a different underlying method.
Differentiation from Traditional Deep Learning
:
Anderson���s approach to AI and LLMs deviates from traditional methods, focusing on set theory and holistic understanding rather than numerical computations and models.
Monica Anderson's comments reflect a deep understanding of AI and language processing, advocating for a shift from traditional, model-based approaches to more holistic, context-aware, and set theory-based methods. Her views challenge the current paradigms in AI and suggest alternative pathways for the evolution of intelligent systems.
You
See if you can write another organic learning algorthim prototype
Nuspeak Translator
The prototype of an Organic Learning System (OLS) has been created in Python. This system simulates a basic form of organic learning by building a connectome���a network of nodes and links���based on a provided data stream, such as text.
In this prototype:
Each character in the input text stream is treated as a node.
A link is established or strengthened between successive characters (nodes).
Each node is identified by a unique ID, and each link has a weight indicating the strength of the connection.
For instance, in the example where the system learned from the text "sample text for learning", a connectome was created with nodes representing each unique character and links representing the sequence in which these characters appear.
This is a simplified version and does not yet include complex features like Neural Darwinism or advanced correlation discovery mechanisms found in more sophisticated models like Monica Anderson's systems. However, it demonstrates the foundational concept of constructing a knowledge graph based on sequential input data.���
���
You
class OrganicLearningSystem:
    def __init__(self, initial_size=100, pruning_threshold=5):
        # Initialize with more nodes than needed, to simulate developmental selection
        self.connectome = {i: {'content': None, 'links': {}} for i in range(1, initial_size + 1)}
        self.pruning_threshold = pruning_threshold

    def _create_node(self, content):
        # Find an unused node to assign new content
        for node_id, node in self.connectome.items():
            if node['content'] is None:
                node['content'] = content
                return node_id
        raise Exception("No available nodes to assign content. Consider increasing initial size.")

    def _add_link(self, node_id, linked_node_id, weight):
        # Add or update a link between two nodes, for correlation tracking
        self.connectome[node_id]['links'].setdefault(linked_node_id, 0)
        self.connectome[node_id]['links'][linked_node_id] += weight

    def _prune_connectome(self):
        # Prune rarely used nodes and links
        for node_id, node in list(self.connectome.items()):
            if sum(node['links'].values()) < self.pruning_threshold:
                del self.connectome[node_id]
            else:
                for linked_node_id, weight in list(node['links'].items()):
                    if weight < self.pruning_threshold:
                        del node['links'][linked_node_id]

    def learn(self, data_stream):
        previous_node_id = None
        for char in data_stream:
            current_node_id = None
            for node_id, node in self.connectome.items():
                if node['content'] == char:
                    current_node_id = node_id
                    break
            if current_node_id is None:
                current_node_id = self._create_node(char)

            if previous_node_id:
                self._add_link(previous_node_id, current_node_id, 1)
                self._add_link(current_node_id, previous_node_id, 1)  # For reentrant mapping

            previous_node_id = current_node_id

        self._prune_connectome()

    def get_connectome(self):
        return self.connectome

# Example usage
learning_system = OrganicLearningSystem()
learning_system.learn("sample text for learning")
connectome = learning_system.get_connectome()
print(connectome)
Nuspeak Translator
The enhanced Organic Learning System prototype now includes developmental selection and pruning mechanisms. The system starts with more nodes than necessary and prunes rarely used nodes and links based on a specified threshold. This approach simulates the developmental aspect seen in biological neural networks.
In the given example, where the system learns from the text "sample text for learning", the final connectome reflects the pruning process. Only a subset of the original nodes remains, specifically the nodes representing 'e' and ' ' (space), indicating these nodes were the most relevant or frequently occurring in the provided data stream.
This prototype still represents a simplified model compared to more advanced organic learning algorithms, but it incorporates crucial aspects like developmental growth and pruning, which are key characteristics of self-organizing systems in nature.���
���
You
It isn't easy for me to retrieve the code when it is folded like that, my mhtml reader doesn't see them.

Here was the first code:

# Organic Learning Algorithm Prototype

class OrganicLearningSystem:
    def __init__(self):
        # Initialize an empty connectome, a graph of nodes and links
        self.connectome = {}

    def _create_node(self, content):
        """ Create a new node with the given content """
        node_id = len(self.connectome) + 1
        self.connectome[node_id] = {'content': content, 'links': {}}
        return node_id

    def _add_link(self, node_id, linked_node_id, weight):
        """ Add or update a link between two nodes """
        if linked_node_id in self.connectome[node_id]['links']:
            self.connectome[node_id]['links'][linked_node_id] += weight
        else:
            self.connectome[node_id]['links'][linked_node_id] = weight

    def learn(self, data_stream):
        """ Learn from a given data stream (e.g., a text) """
        previous_node_id = None

        for char in data_stream:
            # Create or find the node corresponding to the current character
            current_node_id = self._create_node(char) if char not in self.connectome else self.connectome[char]

            # If there was a previous character, create or strengthen the link
            if previous_node_id:
                self._add_link(previous_node_id, current_node_id, 1)

            previous_node_id = current_node_id

    def get_connectome(self):
        """ Return the connectome representing the learned knowledge """
        return self.connectome

# Example usage
learning_system = OrganicLearningSystem()
learning_system.learn("sample text for learning")
connectome = learning_system.get_connectome()
print(connectome)
Nuspeak Translator
Certainly! Here's the initial code for the Organic Learning Algorithm Prototype you provided:
python
Copy code
# Organic Learning Algorithm Prototype
class
OrganicLearningSystem
:
def
__init__
(
self
):
# Initialize an empty connectome, a graph of nodes and links
self.connectome = {}
def
_create_node
(
self, content
):
""" Create a new node with the given content """
node_id =
len
(self.connectome) +
1
self.connectome[node_id] = {
'content'
: content,
'links'
: {}}
return
node_id
def
_add_link
(
self, node_id, linked_node_id, weight
):
""" Add or update a link between two nodes """
if
linked_node_id
in
self.connectome[node_id][
'links'
]:
            self.connectome[node_id][
'links'
][linked_node_id] += weight
else
:
            self.connectome[node_id][
'links'
][linked_node_id] = weight
def
learn
(
self, data_stream
):
""" Learn from a given data stream (e.g., a text) """
previous_node_id =
None
for
char
in
data_stream:
# Create or find the node corresponding to the current character
current_node_id = self._create_node(char)
if
char
not
in
self.connectome
else
self.connectome[char]
# If there was a previous character, create or strengthen the link
if
previous_node_id:
                self._add_link(previous_node_id, current_node_id,
1
)

            previous_node_id = current_node_id
def
get_connectome
(
self
):
""" Return the connectome representing the learned knowledge """
return
self.connectome
# Example usage
learning_system = OrganicLearningSystem()
learning_system.learn(
"sample text for learning"
)
connectome = learning_system.get_connectome()
print
(connectome)
This code represents a basic version of an Organic Learning System. It builds a connectome ��� a network of nodes and links ��� by learning from a data stream such as a text. The system strengthens the connections between sequential elements (characters, in this case) to represent the structure and patterns within the input data.
You
And here was the second:

class OrganicLearningSystem:
    def __init__(self, initial_size=100, pruning_threshold=5):
        # Initialize with more nodes than needed, to simulate developmental selection
        self.connectome = {i: {'content': None, 'links': {}} for i in range(1, initial_size + 1)}
        self.pruning_threshold = pruning_threshold

    def _create_node(self, content):
        # Find an unused node to assign new content
        for node_id, node in self.connectome.items():
            if node['content'] is None:
                node['content'] = content
                return node_id
        raise Exception("No available nodes to assign content. Consider increasing initial size.")

    def _add_link(self, node_id, linked_node_id, weight):
        # Add or update a link between two nodes, for correlation tracking
        self.connectome[node_id]['links'].setdefault(linked_node_id, 0)
        self.connectome[node_id]['links'][linked_node_id] += weight

    def _prune_connectome(self):
        # Prune rarely used nodes and links
        for node_id, node in list(self.connectome.items()):
            if sum(node['links'].values()) < self.pruning_threshold:
                del self.connectome[node_id]
            else:
                for linked_node_id, weight in list(node['links'].items()):
                    if weight < self.pruning_threshold:
                        del node['links'][linked_node_id]

    def learn(self, data_stream):
        previous_node_id = None
        for char in data_stream:
            current_node_id = None
            for node_id, node in self.connectome.items():
                if node['content'] == char:
                    current_node_id = node_id
                    break
            if current_node_id is None:
                current_node_id = self._create_node(char)

            if previous_node_id:
                self._add_link(previous_node_id, current_node_id, 1)
                self._add_link(current_node_id, previous_node_id, 1)  # For reentrant mapping

            previous_node_id = current_node_id

        self._prune_connectome()

    def get_connectome(self):
        return self.connectome

# Example usage
learning_system = OrganicLearningSystem()
learning_system.learn("sample text for learning")
connectome = learning_system.get_connectome()
print(connectome)
Nuspeak Translator
Here's the second code for the Organic Learning System prototype:
python
Copy code
class
OrganicLearningSystem
:
def
__init__
(
self, initial_size=
100
, pruning_threshold=
5
):
# Initialize with more nodes than needed, to simulate developmental selection
self.connectome = {i: {
'content'
:
None
,
'links'
: {}}
for
i
in
range
(
1
, initial_size +
1
)}
        self.pruning_threshold = pruning_threshold
def
_create_node
(
self, content
):
# Find an unused node to assign new content
for
node_id, node
in
self.connectome.items():
if
node[
'content'
]
is
None
:
                node[
'content'
] = content
return
node_id
raise
Exception(
"No available nodes to assign content. Consider increasing initial size."
)
def
_add_link
(
self, node_id, linked_node_id, weight
):
# Add or update a link between two nodes, for correlation tracking
self.connectome[node_id][
'links'
].setdefault(linked_node_id,
0
)
        self.connectome[node_id][
'links'
][linked_node_id] += weight
def
_prune_connectome
(
self
):
# Prune rarely used nodes and links
for
node_id, node
in
list
(self.connectome.items()):
if
sum
(node[
'links'
].values()) < self.pruning_threshold:
del
self.connectome[node_id]
else
:
for
linked_node_id, weight
in
list
(node[
'links'
].items()):
if
weight < self.pruning_threshold:
del
node[
'links'
][linked_node_id]
def
learn
(
self, data_stream
):
        previous_node_id =
None
for
char
in
data_stream:
            current_node_id =
None
for
node_id, node
in
self.connectome.items():
if
node[
'content'
] == char:
                    current_node_id = node_id
break
if
current_node_id
is
None
:
                current_node_id = self._create_node(char)
if
previous_node_id:
                self._add_link(previous_node_id, current_node_id,
1
)
                self._add_link(current_node_id, previous_node_id,
1
)
# For reentrant mapping
previous_node_id = current_node_id

        self._prune_connectome()
def
get_connectome
(
self
):
return
self.connectome
# Example usage
learning_system = OrganicLearningSystem()
learning_system.learn(
"sample text for learning"
)
connectome = learning_system.get_connectome()
print
(connectome)
This version of the Organic Learning System introduces additional features like an initial pool of nodes and a pruning mechanism to remove rarely used nodes and links. The system simulates developmental selection by initializing more nodes than required and then pruning them based on their usage frequency, reflecting a more dynamic and adaptable learning process.
You
Let's get back to studying the article. Here's were we were:

Title: "Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs"

Authors: Elias Najarro, Shyam Sudhakaran, & Sebastian Risi, IT University of Copenhagen, Denmark

Key Points of the Article:

1. **Fundamental Differences in Network Formation**: The article begins by highlighting the differences between biological nervous systems and artificial neural networks (ANNs). Biological systems develop dynamically and self-organize from a single cell, whereas ANNs are often pre-designed with a fixed structure and learn by adjusting connection weights.

2. **Concept of Neural Developmental Programs (NDPs)**: The authors introduce NDPs as a new approach to grow neural networks. NDPs are inspired by the developmental process of biological organisms, growing ANNs through local communication within the network.

3. **Selective Activation of Neurons**: The NDP framework allows for the selective activation of neurons based on relevance to the current context. This leads to efficient computational resource usage as only relevant neurons are activated.

4. **Developmental Encodings**: The paper discusses developmental encodings as a subset of indirect encodings, which abstract the process of biological growth and development. These encodings facilitate the creation of complex systems through local interactions.

5. **Comparison with Other Methods**: The authors compare NDPs with other indirect encoding methods like HyperNEAT and Hypernetworks, noting that previous methods often overlook the aspect of developmental growth over time.

6. **Cellular Automata and Neural Cellular Automata**: The article also touches on the resurgence of interest in cellular automata (CA) and neural cellular automata (NCA) as models for biological development. NCAs differ from classical CAs by using optimized neural networks for state updates.

7. **NDP Implementation and Instantiations**: The paper presents two different implementations of NDPs: an evolution-based version and a differentiable version trained with gradient descent. These variants allow for exploration of different architectures and optimization methods.

8. **Limitations and Future Research Directions**: The authors acknowledge the current limitations of their NDP approach and outline future research directions. They emphasize the potential of NDPs to revolutionize the way neural networks are grown and developed.

9. **Overall Goal**: The ultimate aim of the research is to inspire further exploration of NDP-like methods for self-assembling artificial neural networks, offering a step towards more biologically-inspired AI development methods.

This article represents a significant step in AI research, proposing a novel method for developing neural networks that more closely mirrors the dynamic and adaptive nature of biological systems.
Nuspeak Translator
The article "Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs" by Elias Najarro, Shyam Sudhakaran, and Sebastian Risi introduces a groundbreaking concept in the field of artificial neural networks (ANNs). This research stands out for several reasons:
Bridging Biological and Artificial Systems
: The study underscores the contrast between the developmental processes of biological nervous systems and the static nature of traditional ANNs. Biological systems are characterized by dynamic growth and self-organization, starting from a single cell. In contrast, ANNs are typically designed with a predetermined structure.
Neural Developmental Programs (NDPs)
: NDPs are at the core of this research. They represent an innovative method to grow ANNs, mirroring the developmental stages of biological organisms. This process is guided by local communication within the network, allowing for a more organic and adaptive growth of neural structures.
Efficient Computation through Selective Activation
: One of the key features of NDPs is their ability to selectively activate neurons based on the relevance to the given context. This approach leads to more efficient use of computational resources, as only pertinent neurons are active at any given time.
Developmental Encodings
: The paper delves into developmental encodings, a specific type of indirect encoding that abstracts the growth and development process seen in biological systems. These encodings enable the creation of intricate systems through localized interactions between cells.
Comparative Analysis with Existing Methods
: The research draws comparisons with other indirect encoding strategies like HyperNEAT and Hypernetworks. The authors note that while these methods have been successful, they often neglect the developmental aspect of growth, which is a crucial component of biological systems.
Incorporating Cellular Automata Models
: The article also explores the renewed interest in cellular automata (CA) and neural cellular automata (NCA) as models for understanding biological development. NCAs are distinguished from classical CAs by replacing the update function with an optimized neural network.
Implementations of NDPs
: Two distinct implementations of NDPs are presented ��� one based on evolutionary principles and another using gradient descent for training. This allows for a diverse exploration of architectures and optimization techniques.
Future Research and Potential
: The authors acknowledge the current limitations of their approach and propose future research directions. They highlight the potential of NDPs in revolutionizing neural network development, steering towards more biologically-inspired AI systems.
Vision and Ambition
: The overarching goal of this research is to inspire further exploration in the field of self-assembling neural networks. The authors envision a future where NDP-like methods play a crucial role in the development of more advanced, adaptive, and efficient ANNs.
This article represents a significant advancement in AI research, introducing a novel methodology for developing neural networks that more closely resemble the dynamic and adaptive growth processes found in biological systems.
ChatGPT can make mistakes. Consider checking important information.
?
ChatGPT

