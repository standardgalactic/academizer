Self-Organisation in the Brain
Open sidebar
Self-Organisation in the Brain
Default (GPT-3.5)
Summarize: Articlehttps://doi.org/10.1038/s41467-023-40141-z 
Experimental validation of the free-energy 
principle with in vitro neural networks 
Takuya Isomura 
1 , Kiyoshi Kotani2, Yasuhiko Jimbo3& Karl J. Friston 
4,5 
Empirical applications of the free-energy principle are not straightforward 
because they entail a commitment to a particular process theory, especially at 
the cellular and synaptic levels. Using a recently established reverse engi- 
neering technique, we conf i rm the quantitative predictions of the free-energy 
principle using in vitro networks of rat cortical neurons that perform causal 
inference. Upon receiving electrical stimuli���generated by mixing two hidden 
sources���neurons self-organised to selectively encode the two sources. Phar- 
macological up- and downregulation of network excitability disrupted the 
ensuing inference, consistent with changes in prior beliefs about hidden 
sources. As predicted, changes in effective synaptic connectivity reduced 
variational free energy, where the connection strengths encoded parameters 
of the generative model. In short, we show that variational free energy mini- 
misationcanquantitativelypredicttheself-organisationofneuronalnetworks, 
in terms of their responses and plasticity. These results demonstrate the 
applicability of the free-energy principle to in vitro neural networks and 
establish its predictive validity in this setting. 
Elucidatingtheself-organisingprinciplesofbiologicalneuralnetworks 
is one of the most challenging questions in the natural sciences, and 
should prove useful for characterising impaired brain function and 
developing biologically inspired (i.e., biomimetic) artif i cial intelli- 
gence. According to the free-energy principle, perception, learning, 
and action���of all biological organisms���can be described as minimis- 
ing variational free energy, as a tractable proxy for minimising the 
surprise (i.e., improbability) of sensory inputs1,2. By doing so, neuronal 
(and neural) networks are considered to perform variational Bayesian 
inference3. (Table 1 provides a glossary of technical terms used com- 
monlyinthefree-energyprincipleandactiveinferenceliterature).This 
inference follows from treating neuronal dynamics as a gradient l ow 
on variational free energy, which can be read as a form of belief 
updating about the network���s external milieu. The free energy in 
question is a function of a generative model that expresses a hypoth- 
esis about how sensory data are generated from latent or hidden 
states. However, to apply the free-energy principle at the cellular and 
synaptic levels, it is necessary to identify the requisite generative 
model thatexplains neuronaldynamics (i.e.,inference) andchangesin 
synaptic eff i cacy (i.e., learning). 
The activity of neurons has also been modelled with realistic 
spiking neuron models4���6or reduced rate coding models7. Moreover, 
synapticplasticity���thatdependsonthef i ringofpre-andpostsynaptic 
neurons8���12���has been modelled as Hebbian-type plasticity rules13���15. 
Although a precise link between the equations that underwrite these 
models���derived from physiological phenomena���and the corre- 
sponding equations from the free-energy principle has not been fully 
established, we recently identif i ed a formal equivalence between 
neural network dynamics and variational Bayesian inference16���18. Spe- 
cif i cally, we reverse-engineered a class of biologically plausible cost 
functions���for canonical neural networks���and showed that the cost 
function can be cast as variational free energy, under a class of well- 
knownpartiallyobservableMarkovdecisionprocess(POMDP)models. 
This suggests that any (canonical) neural network, whose activity and 
Received: 12 October 2022 
Accepted: 13 July 2023 
Check for updates 
1Brain Intelligence Theory Unit, RIKEN Center for Brain Science, 2-1 Hirosawa, Wako, Saitama 351-0198, Japan.2Research Center for Advanced Science and 
Technology, The University of Tokyo, 4-6-1 Komaba, Meguro-ku, Tokyo 153-8904, Japan. 3Department of Precision Engineering, School of Engineering, The 
University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan. 4Wellcome Centre for Human Neuroimaging, Queen Square Institute of Neurology, 
University College London, London WC1N 3AR, UK. 5VERSES AI Research Lab, Los Angeles, CA 90016, USA. e-mail: takuya.isomura@riken.jp 
Nature Communications| (2023) 14:4547 1 
1234567890():,; 1234567890():,; 
plasticity minimise a common cost function, implicitly performs var- 
iational Bayesian inference and learning about external states. This 
���reverse engineering��� approach���guaranteed by formal equivalence��� 
allows us, for the i rst time, to identify the implicit generative model 
from empirical neuronal activity. Further, it can precisely link quan- 
titiesinbiologicalneuronalnetworkswiththoseinvariationalBayesian 
inference. This enables an experimental validation of the free-energy 
principle, when applied to these kinds of canonical networks. 
Having said this, the free-energy principle is sometimes con- 
sidered to be experimentally irrefutable in the sense that it can 
describe any observed biological data19. However, when applying the 
free-energy principle to a particular system, one can examine its pre- 
dictive validity by asking whether it can predict systemic responses18. 
This offers a formal avenue for validation and application of the free- 
energyprinciple.Toestablishpredictivevalidity,oneneedstomonitor 
the long-term self-organisation of neuronal networks and compare 
their dynamics and architecture with theoretical predictions. 
Topursuethiskindofvalidation,weusedapreviouslyestablished 
microelectrode array (MEA) cell culture system for the long-term 
monitoring of the self-organisation of in vitro neural networks20,21. We 
have used this setup to investigate causal inference in cortical cells 
obtained from rat embryos22,23. Causal inference is a simple form of 
Bayesian inference; namely, inferring and disentangling multiple cau- 
ses of sensory inputs in the sense of blind source separation24���26. 
Although blind source separation is essential to explain the cocktail 
party effect���the ability of partygoers to distinguish the speech of one 
speaker from others in a noisy room27,28���its precise neuronal 
mechanisms have yet to be elucidated. We previously demonstrated 
that, upon receiving sensory stimuli, some populations of neurons in 
in vitro neural networks self-organised (or learned) to infer hidden 
sources by responding specif i cally to distinct causes22. Subsequently, 
we showedthatthis sensory learning is consistent with variationalfree 
energyminimisationunderaPOMDPgenerativemodel23.Theseresults 
���andrelatedin vitrowork29���35���speaktothetractabilityandstabilityof 
this neuronal system, making it an ideal tool for examining theoretical 
predictions in a precise and quantitative fashion. 
In the present work, we attempted an experimental validation of 
the free-energy principle by showing that it predicts the quantitative 
self-organisation of in vitro neural networks using an established 
in vitrocausal inference paradigm. Henceforth, we willrefer to in vitro 
neural networks as neuronal networks and reserve the term neural 
network for an in silico model. We reverse-engineered an implicit 
generative model (including prior beliefs), under which a neuronal 
network operates. We subsequently demonstrated that the free- 
energy principle can predict the trajectory of synaptic strengths (i.e., 
learning curve) as well as neuronal responses after learning, based 
exclusively on empirical neuronal responses at the beginning of 
training. 
Using pharmacological manipulations, we further examined 
whether the change in baseline excitability of in vitro networks was 
consistentwiththechangeinpriorbeliefsabouthiddenstates(i.e.,the 
state prior), conf i rming that priors over hidden states are encoded by 
i ring thresholds. These results demonstrate that the self-organisation 
of neuronal networks can be cast as Bayesian belief updating. This 
endorses the plausibility of the free-energy principle as an account of 
self-organisation in neural and neuronal networks. We conclude by 
discussing possible extensions of our reverseengineering approachto 
in vivo data. 
Results 
Equivalence between canonical neural networks and varia- 
tional Bayes 
First, we summarise the mathematical (or natural) equivalence 
betweencanonicalneuralnetworksandvariationalBayesianinference, 
which enables one to apply the free-energy principle to predict 
empirical data. In this work, we adopted an experimental setup that 
could be formulated as a simple POMDP generative process that does 
not exhibit state transitions (Fig. 1a). Here, two binary hidden sources 
s= s1,s2 
??T 
were sampled at random from a prior categorical dis- 
tribution D= D1,D0 
??T 
in a mutually independent manner, where D1 
and D0are prior expectations that satisfy D1+D0=1. Then, 32 sensory 
inputs o= o1,...,o32 
??T 
were generated from s with a categorical dis- 
tribution characterised by a mixing matrix A. Each element of s and o 
took either a 1 (ON) or a 0 (OFF) state. The left stimuli group 
(o1,...,o16) in Fig. 1a (left) took the value of source 1 with a 75% prob- 
ability or the value of source 2 with a 25% probability. In contrast, the 
right group (o17,...,o32) took the value of source 1 or 2 with a 25% or 
75% probability, respectively. Analogous to the cocktail party 
effect27,28, this setup is formally homologous to the task of distin- 
guishing the voices of speakers 1 (s1) and 2 (s2) based exclusively on 
Table 1 | Glossary of terms 
ExpressionDescription 
Free-energy principle (FEP)A principle that can be applied to perception, learning, and action in biological organisms. Technically, the FEP is a 
variational principle of least action that describes action and perception as, effectively, minimising prediction errors. 
Variational Bayesian inferenceAn approximate Bayesian inference scheme that minimises variational free energy as a tractable proxy for���or bound 
on���surprise. Minimising surprise is equivalent to maximising the evidence for a generative model. In machine 
learning, variational free energy is known as an evidence bound. 
Prior beliefProbabilistic beliefs about unobservable variables or states prior to receiving observations, denoted as P ���� ��: 
(Approximate) Posterior belief(Approximate) Bayesian belief about unobservable variables or states after receiving observations, denoted 
as Q ���� �����P �����o����: 
LikelihoodThe likelihood of an observation given unobservable states, denoted as P o���������. 
Generative modelProbabilisticmodelthatexpresses how unobservable states generateobservations,def i ned interms of the likelihood 
and prior beliefs P o,������=P o���������P ���� ��: 
SurpriseThe surprisal or self-information, which scores the improbabilityof an observation under a generative model:def i ned 
as ?lnP o�� ��= ? ln R 
P o,������d�� 
??: 
Here, P o 
�� �� is known as the marginal likelihood or model evidence. It is called the 
marginal likelihood because it marginalises over the unknown causes an observation. 
Variational free energyAn upper bound on surprise���or the negative of an evidence lower bound (ELBO)���def i ned as 
F=EQ �� 
�� ��?lnP o,�� 
����+lnQ ���� 
����?, where EQ �� 
�� ��? �� ? denotes the expectation over Q �� 
�� ��: 
Bayesian belief updatingThe process of usingobservations to updatea prior belieftoa posterior belief.Usually, in biomimeticschemes, belief 
updatingusesvariationalBayesianinference,whereneuronaldynamicsperformagradientdescentonvariationalfree 
energy. 
Partially observable Markov decision pro- 
cess (POMDP) 
A generic generative model that expresses unknown causes of observations in terms of discrete state spaces and 
categorical distributions.
1 / 1
ChatGPT
The article by Takuya Isomura et al. presents experimental validation of the free-energy principle using in vitro neural networks. The researchers used rat cortical neurons and applied the free-energy principle to understand the self-organization principles of biological neural networks, which could offer insights into brain function and the development of biomimetic artificial intelligence.
Through reverse engineering, the researchers confirmed the quantitative predictions of the free-energy principle using in vitro networks. These networks performed causal inference, and upon receiving electrical stimuli, the neurons self-organized to selectively encode two hidden sources. The researchers further observed that pharmacological up- and downregulation of network excitability affected the inference, which was in line with changes in prior beliefs about hidden sources.
Moreover, the team showed that changes in effective synaptic connectivity reduced variational free energy, and the connection strengths encoded parameters of the generative model. This demonstrated the applicability and predictive validity of the free-energy principle in in vitro neural networks.
The study also used pharmacological manipulations to examine changes in baseline excitability, confirming that prior beliefs over hidden states are encoded by firing thresholds. The results endorse the free-energy principle's plausibility in explaining self-organization in neural and neuronal networks, leading to discussions about potential extensions to in vivo data.
1 / 1
Fig. 1 | Reverse engineering of the generative model from empirical data. In 
a���c, panels on the left-hand side depict neural (and neuronal) network formation, 
while panels on the right-hand side depict variational Bayes formation. 
a Schematics of the experimental setup (left) and corresponding POMDP gen- 
erative model (right). Two sequences of independent binary hidden sources gen- 
erate 32 sensory stimuli through a mixing matrix A, which were applied into 
cultured neurons on an MEA as electrical pulses. Waveforms at the bottom repre- 
sent the spiking responses to a sensory stimulus (red line). The diagram on the 
right-handsidedepictsthePOMDPschemeexpressedasaForneyfactorgraph67���69. 
Thevariablesinbold(e.g.,st)denotetheposteriorbeliefsaboutthecorresponding 
variables in non-bold italics (e.g., st). b Equivalence between canonical neural 
networks and variational Bayesian inference. See the main text and Methods for 
details. c Procedure for reverse engineering the implicit generative model and 
predicting subsequent data. (1) The neuronal responses are recorded, and (2) the 
canonical neural network (rate coding model) is used to explain the empirical 
responses. (3) The dynamics of the canonical neural network can be cast as the 
gradient descent on a cost function. Thus, the original cost function L can be 
reconstructed by taking the integral of the network���s neural activity equation. Free 
parameters �� are estimated from the mean response to characterise L. (4) Identi- 
i cation of an implicit generative model and the ensuing variational free energy F 
using the equivalenceoffunctionalformsinTable 2. (5) The synaptic plasticity rule 
is derived as a gradient descent on variational free energy. (6) The obtained plas- 
ticity scheme is used to predict self-organisation of neuronal networks. The details 
are provided in Methods and have been described previously16���18. 
Articlehttps://doi.org/10.1038/s41467-023-40141-z 
Nature Communications| (2023) 14:4547 3 
responses and synaptic plasticity16,17. This cost function can be 
obtained by simply calculating the integral of the neural activity 
equation (Fig. 1b, middle left; see the Methods section ���Canonical 
neural networks��� for details). The reconstructed neural network cost 
function L is biologically plausible because both neuronal responses 
and synaptic plasticity equations can be derived as a gradient descent 
on L. The ensuing synaptic plasticity rule has a biologically plausible 
form, comprising Hebbian plasticity13, accompanied by an activity- 
dependent homeostatic plasticity37(Fig. 1b, bottom left). 
Variational Bayesian inference casts belief updating as revising a 
priorbelief tothe corresponding (approximate) posterior beliefbased 
on a sequence of observations. The experimental setup considered 
here is expressed as a POMDP generative model38,39. The inversion of 
this model���via a gradient descent on variational free energy���corre- 
sponds to inference. In other words, the generative model generates 
sensory consequences from hidden causes (i.e., two sources), while 
model inversion (i.e., inference) maps from sensory consequences to 
hidden causes (Fig. 1a, right). Variational free energy F is specif i ed by 
thesensoryinputandprobabilisticbeliefsabouthiddenstatesundera 
generativemodel.Minimisationofvariationalfreeenergy,withrespect 
to these beliefs, yields the posterior over hidden states st(Fig. 1b, top 
right) and parameters A (Fig. 1b, bottom right), realising Bayesian 
inference and learning, respectively. The explicit forms of posterior 
beliefs are described in the Methods section ���Variational Bayesian 
inference���. 
Crucially, previous work has shown that the neural network cost 
function L can be read asvariationalfree energy F16,17. Thisequivalence 
allows us to identify the physiological implementation of variational 
Bayesian inference by establishing a one-to-one mapping between 
neural network quantities and the quantities in Bayesian inference, as 
summarised in Table 2. Namely, neural activity (x) of the canonical 
neural networks corresponds to the posterior expectation about the 
hidden states (s), synaptic strengths (W) correspond to the posterior 
expectation about the parameters (A), and i ring threshold factors (��) 
correspond to the initial state prior (D). These mappings establish a 
formalrelationshipbetweenaneuralnetworkformulation(Fig.1b,left) 
and a variational Bayesian formulation (Fig. 1b, right). In summary, the 
neural activity and plasticity of canonical networks that minimise a 
common cost function perform variational Bayesian inference and 
learning, respectively. 
Thisnotionisessentialbecause,byobservingneuronalresponses, 
we can reverse engineer the implicit generative model���under which 
theneuronalnetworkoperates���fromempiricalneuronalresponses,to 
characterise the neuronal network in terms of Bayesian inference 
(Fig. 1c)18. Perhaps surprisingly, using the reverse engineering techni- 
que, if one can derive the neural activity equation from experimental 
data (Fig. 1c, steps 1,2), it is possible to identify the generative model 
that the biological system effectively employs (steps 3,4). This allows 
one to link empirical data to quantities in variational Bayesian 
inference. Subsequently, by computing the derivative of variational 
free energy under the generative model, one can derive the synaptic 
plasticity predicted theoretically (step 5). In short, if one has initial 
neuronal response data, one can predict how synaptic plasticity will 
unfoldovertime.Thismeansthatifthefree-energyprincipleapplies,it 
will predict the self-organisation of neuronal networks (step 6). 
The virtue of the free-energy principle is that it lends an explain- 
ability to neuronal network dynamics and architectures, in terms of 
variational Bayesian inference. Given this generative model, the free- 
energy principle provides qualitative predictions of the dynamics and 
self-organisation of neuronal networks, under the given experimental 
environment. In other words, because neuronal responses and 
synaptic plasticity are expected to minimise variational free energy by 
exploiting the shortest path (i.e., a geodesic or path of leastaction) on 
the free energy landscape, this property in turn enables us to theore- 
tically predict a plausible synaptic trajectory (i.e., activity-dependent 
plasticity). 
In the remainder of this paper, we examine the plausibility of 
variational free energy minimisation as the mechanism underlying the 
self-organisation of neuronal networks. We will compare the empirical 
encoding of the sources of sensory inputs with a synthetic simulation 
of ideal Bayesian encoding, and investigate whether variational free 
energy minimisationcanpredictthe neuronalresponses andplasticity 
of in vitro networks. 
Consistency between in vitro neural networks and varia- 
tional Bayes 
In this section, we verify some qualitative predictions of the free- 
energy principlewhen applied to our in vitroneural networks in terms 
of response selectivity (i.e., inference), plasticity (i.e., learning), and 
effects of pharmacological manipulations on inference and sub- 
sequent learning. Using our in vitro experimental setup20,21, cortical 
cellsobtainedfromrat embryos wereculturedon anMEA dish with 64 
microelectrodes on its l oor (Fig. 1a, left). Each electrode was used to 
deliver electrical stimuli and record the spiking response. After 
approximately 10 days in culture, the neurons self-organised into a 
network and exhibited spontaneous activity, with clear evoked 
responses to electrical stimuli. Neurons were stimulated with the 
above-constructed patterns of sensory inputs (see the preceding sec- 
tion), comprising 32 binary sensory inputs (o) that were generated 
from two sequences of independent binary hidden sources (s) in the 
manner of the POMDP generative model above (Fig. 1a, right). When a 
sensory input took the value of 1, an electrical pulse was delivered to 
the cultured neurons. The 32 stimulation electrodes were randomly 
distributed over 8��8 MEAs in advanceandf i xedover training. Evoked 
extracellular activity (i.e., the early neuronal response) was recorded 
from64MEAelectrodes.Eachsessionlasted256s,inwhicha256-time- 
step sequence of random stimulations was delivered every second, 
followedbya244-srestingperiod.Thetrainingcomprised 
Table 2 | Correspondence of variables and functions 
Neural network formationVariational Bayes formation
1 / 1
ChatGPT
It seems like you've pasted a lengthy excerpt from a scientific article discussing the reverse engineering of a generative model from empirical data, using both neural networks and variational Bayesian inference. It's a complex text involving aspects of neuroscience, machine learning, Bayesian inference, and experimental procedures. Is there anything specific you'd like to know or ask about this excerpt?
1 / 1
Table 2 | Correspondence of variables and functions 
Neural network formationVariational Bayes formation 
Neural network cost functionL( )FVariational 
free energy 
Sensory stimuliot( )otObservations 
Neural responsext 
xt 
?? ( )st 
State posterior 
Synaptic strengthsWl( )sig?1A1l 
?? 
Parameter posterior 
Threshold factor �� := ��1 
��0 
?? ( )lnD 
State prior 
Firing threshold hl=lnbWl~1+��l( 
)lnA0l?~1+lnDl 
Initial synaptic strengths ��W 
l ?bW 
init 
l ( )a1l 
Parameter prior 
Boldcasevariables(e.g.,st)denotetheposteriorexpectationsofthecorrespondingitaliccaserandomvariables(e.g.,st);bWl:=sig 
Wl 
?? 
isthesigmoidfunctionofWlintheelementwisesense(l=0,1); 
Winit 
l is the initial value of Wl; and ��W 
l is the inverse learning rate factor that expresses the insensitivity of synaptic strengths to plasticity. Please refer to previous work16,17for details. 
Articlehttps://doi.org/10.1038/s41467-023-40141-z 
Nature Communications| (2023) 14:4547 4
1 / 1
ChatGPT
You've shared Table 2 from an article in Nature Communications, which illustrates the correspondence between the variables and functions used in neural network formation and those in variational Bayes formation. The table seems to align various terms such as cost function, sensory stimuli, neural response, synaptic strengths, and others, showing their counterparts in a variational Bayesian framework.
It's a dense table with technical terminology, so without specific context or questions, it's difficult to provide a detailed analysis. What would you like to know about this table or the surrounding text?
1 / 1
Interestingly, the reverse engineering enables us to map empiri- 
callyestimatedsynapticstrengths(W)tothe posterior expectation(A) 
about parameter matrix A, to identify the generative model that the 
neuronal network employs (Table 2). The reconstructed posterior A 
precisely captured the characteristics of the true A in the external 
milieu, such that source 1 has a greater contribution to o1,...,o16 
??, 
whilesource2to o17,...,o32 
?? 
(Fig.3c).Anerrorbetweenempiricaland 
ideal (Bayesian) posteriors signif i cantly decreased with sessions 
(Fig. 3d, left). The error was larger in bicuculline- or diazepam-treated 
condition, owing to biased inferenceand subsequent learning in these 
neuronal networks (Fig. 3d, right). These results support the theore- 
tical notion that synaptic strengths encode the posterior expectation 
of the parameter1,2. As predicted, synaptic plasticity following the free 
energy gradient entailed a recapitulation of the generative process 
within the neuronal network architecture. 
The observation that the empirical synaptic trajectory pursues a 
gradient descent on variational free energy implies that one can pre- 
dict the subsequent learning in the absence of empirical constraints. 
Once the initial values of synaptic strengths are identif i ed, the sub- 
sequent learning process can in principle be predicted using the free- 
energyprinciple,underthecanonicalneuralnetwork(i.e., 
generative) model. 
To test this hypothesis, we predicted the neuronal responses (x) 
andsynaptic plasticity(W)in sessions11���100usingtheneuralnetwork 
cost function L reconstructed based exclusively on the empirical 
responses in the initial 10 sessions (see the Methods section ���Data 
prediction using the free-energy principle��� for details). As established 
above,thiscostfunction isformallyidenticaltovariationalfreeenergy 
F under a class of POMDP generative models16,17. Thus, evaluating the 
responsesandplasticitythatminimisethiscostfunctionL(? F)���inthe 
absence of data���furnishes a prediction of neuronal responses and 
plasticity under the free-energy principle. 
We foundthat the predictedchanges inconnectivity matchedthe 
changes in empirically estimated effective synaptic connectivity 
(Fig. 3b, right). Specif i cally, we observed a strong correlation between 
the synaptic strengths estimated using neuronal data and the 
strengths predicted in the absence of data (Fig. 3e). The prediction 
error was less than 4%, up to the i nal session (Fig. 3f; n=30 inde- 
pendent experiments). These results indicate that, based on initial 
conditions, the free-energy principle can predict the self-organisation 
of neuronal networks. 
In addition to the synaptic trajectory, we conf i rmed that a mini- 
misationoffreeenergycanpredicttheunderlyingchangesinneuronal 
responses (Fig. 3g). The predictions based only on initial conditions 
were consistent with observed responses. Specif i cally, the predicted 
responses were consistent with the observed responses at each time 
step (Fig. 3h, i). Quantitatively, we could predict more than 80% of the 
neuronal responses in session 100, based only on data from sessions 
1���10 (Fig. 3j). These results suggest that the free-energy principle can 
predict both changes in synaptic eff i cacy and the time evolution of 
neuronalresponses based onlyon initialdata. Note that this is a highly 
nontrivial prediction, because synaptic eff i cacy shows activity- 
dependent changes and neuronal responses depend upon synaptic 
eff i cacy. 
Another interesting observation was that when we varied the free 
energy landscape by manipulating the mixing matrix A in the stimulus 
generating process, empirical synaptic plasticity kept pursuing a gra- 
dient descent on the new variational free energy (Fig. 3k). This speaks 
to a generality of this physiological property. Here, we experimentally 
varied the mixing balance (A) of two sources between 0 and 50%, to 
train neuronal networks with the generated sensory stimuli (o), where 
0% indicates an unmixed (i.e., easily separable) condition, while 50% 
indicates a uniformly mixed (i.e., inseparable) condition. Irrespective 
of various conditions (i.e., forms of generative process and prior 
beliefs), the reverse engineering could reconstruct generative models 
and predict subsequent self-organisations of neuronal networks 
(Supplementary Fig. 2; see also Supplementary Movie 1). 
Finally, we observed that during the process of assimilating sen- 
sory information, neuronal networks signif i cantly reduced their var- 
iational free energy (Fig. 3l). Here, variational free energy F for each 
session was calculated empirically by substituting the observed neu- 
ronal responses into the cost function L. As expected, an easier task 
(i.e., 0% mix condition) entailed a faster (i.e., greater) reduction of 
variational free energy. These results provide explicit empirical evi- 
dence that neuronal networks self-organise to minimise variational 
free energy. 
In summary, we found that the trajectory of the empirically esti- 
matedeffectivesynapticconnectivityisconsistentwithaslowgradient 
descent on variational free energy. Furthermore, we demonstrated 
that the free-energy principle can quantitatively predict sensory 
learninginneuronalnetworksintermsofbothneuronalresponsesand 
plasticity. These results suggest that the self-organisation of the neu- 
ronalnetworks���inresponse to structured sensoryinput���is consistent 
with Bayesian belief updating and the minimisation of variational free 
energy. This endorses the plausibility of variational free energy mini- 
misation as a rule underlying the dynamics and self-organisation of 
neuronal networks. 
Discussion 
The present work has addressed the predictive validity of the free- 
energy principle at the circuit level by delineating the functional spe- 
cialisation and segregation in neuronal networks via free-energy 
minimisation. Identifying the characteristic functions of arbitrary 
neural networks is not straightforward. However, according to the 
completeclass theorem41���43,anysystemthat minimises acostfunction 
under uncertainty can be viewed as Bayesian inference. In light of this, 
we showed that any neural network���whose activity and plasticity 
minimise a common cost function���can be cast as performing (varia- 
tional) Bayesian inference16,17. Crucially, the existence of this equiva- 
lenceenablestheidentif i cationofanaturalmapfromneuronalactivity 
to a unique generative model (i.e., hypothesis about the external 
milieu),underwhichabiologicalsystemoperates.Thisstepisessential 
tolinkempiricaldata���whichreportthe���internal���circuitdynamics(i.e., 
physiological phenomena)���to the representation of the ���external��� 
dynamics (i.e., functions or computations) that the circuit dynamics 
imply, intermsof variationalBayesianinference. Using this technique, 
we i tted stimulus-evoked responses of in vitro networks���comprising 
the cortical cells of rat embryos���to a canonical neural network and 
reverse engineered an POMDP generative model, apt to explain the 
empirical data. In other words, we were able to explain empirical 
responses as inferring the causes of stimuli, under an implicit gen- 
erative or world model. 
Furthermore, reverse engineering a generative model from 
observed responses specif i es a well-def i ned synaptic plasticity rule. 
Using this rule, we showed that the self-organisation of in vitro net- 
works follows a gradient descent on variational free energy under the 
Articlehttps://doi.org/10.1038/s41467-023-40141-z 
Nature Communications| (2023) 14:4547 8 
(POMDP)generativemodel.Inshort,thevirtuesofreverseengineering 
are that: (i) when provided with empirical responses, it systematically 
identif i es what hypothesis (i.e., generative model) the biological sys- 
tem employs to infer the external milieu. Moreover, (ii) it offers 
quantitative predictions about the subsequent self-organisation (i.e., 
learning) of the system that can be tested using data. This provides a 
useful tool for analysing and predicting electrophysiological and 
behavioural responses and elucidating the underlying computational 
and self-organisation principle. 
Although numerous neural implementations of Bayesian infer- 
ence have been proposed44���46, these approaches generally derive 
update rules from Bayesian cost functions without establishing the 
preciserelationshipbetweentheseupdaterulesandtheneuralactivity 
and plasticity of canonical neural networks. The reverse engineering 
approach differs conceptually by asking what Bayesian scheme could 
account for any given neuronal dynamics or neural network. By iden- 
tifyingtheimplicitinversionscheme���andrequisitegenerativemodel��� 
one can then lend any given network an interpretability and explain- 
ability. In the current application of this approach, we i rst consider a 
biologically plausible cost function for neural networks that explains 
both neural activity and synaptic plasticity. We then identify a parti- 
cular generative model under which variational free energy is equiva- 
lent to the neural network cost function. In this regard, reverse 
engineering offers an objective procedure for explaining neural net- 
works in terms of Bayesian inference. Further, the synaptic plasticity 
rule is derived as the gradient descent on the cost function that is 
determined by the integral of neural dynamics. Crucially, learning 
through this plasticity rule can be read, formally, as Bayesian belief 
updating under an appropriate generative model. Conversely, naive 
Hebbian plasticity rules���with an ad hoc functional form���correspond 
to Bayesianbelief updating under a suboptimalgenerative model with 
biasedpriorbeliefs,whichcannotsolvesimpleblindsourceseparation 
problems16. As predicted, in vitro neural networks above failed to 
perform blind source separation, with changed baseline excitability 
and implicit priors. In short, the free-energy principle is necessary to 
determine the optimal balance between Hebbian and homeostatic 
plasticity that enables blind source separation by in vitro networks. 
Previous work has established that ensembles of neurons encode 
posterior expectations47and prediction errors48; however, other 
quantitiesinBayesianinference���suchasthestatepriorandparameter 
posterior���have yet to be fully investigated. The reverse engineering 
approach enables us to identify the structures, variables, and para- 
meters of generative models from experimental data, which is essen- 
tial for empirical applications of the free-energy principle. This is a 
notion referred to as computational phenotyping49; namely inferring 
the generative model���and in particular, the priors���that best explain 
empirical responses under ideal Bayesian assumptions. The reverse 
engineering naturally maps empirical (biological) quantities to quan- 
tities in variational Bayesian inference. Our empirical results suggest 
that neuronal responses encode the hidden state posterior (Fig. 2c), 
baseline excitability encodes the state prior (Fig. 2g), and synaptic 
eff i cacies encode the parameter posterior (Fig. 3c), as predicted the- 
oretically (Table 2). 
Having said this, because the free-energy principle can arguably 
describe any observed biological data by its construction19, showing 
the existence of such a mapping alone is insuff i cient as an empirical 
validation. Conversely, one can examine the predictive validity, which 
is a more delicate problem, by asking whether the free-energy princi- 
ple can predict subsequent self-organisation without reference to 
empiricaldata.Such a generalisability on previously unseen (test) data 
comprises an essential aspect for empirical applications of the free- 
energy principle. 
We demonstrated that, equipped with the initial conditions (i.e., 
generative model and implicit prior beliefs of the network) char- 
acterisedbytheexperimentaldata,variationalfreeenergy 
minimisation can predict the subsequent self-organisation of in vitro 
neural networks, in terms of quantitative neuronal responses and 
plasticity. It further predicted their performance when spontaneously 
solving source separation problems, including their speed and accu- 
racy. These results not onlyvalidate thisapplication of the free-energy 
principle; they also speak to the neurophysiological plausibility of 
related theories of the brain50,51and spiking neural network models 
that perform Bayesian inference44���46. 
In essence, the free-energy principle constrains the relationship 
between neural activity and plasticity because both activity and plas- 
ticity follow a gradient descent on a common variational free energy, 
under ideal Bayesian assumptions. This property in turn enables pre- 
cise characterisation of plausible self-organisation rules and quantita- 
tive prediction of subsequent neuronal activity and plasticity, under a 
canonical neural network (generative) model. 
Our combined in vitro���in silico system showed that variation of 
the state prior (in silico model) is suff i cient to reproduce the changes 
in neural excitability and inhibitions of sensory learning and inference 
observed in vitro. These results suggest that a neuronal networks��� 
excitability is normally tuned so that the ensemble behaviour is close 
to thatofa Bayes optimalencoder under biological constraints. Thisis 
reminiscent of previous experimental observation that suggests that 
the activity of sensory areas encodes prior beliefs52. 
These empirical data and complementary modelling results also 
explain the strong inf l uence of prior beliefs on perception and causal 
inference���and the disruptive effects of drugs on perception in neu- 
ronal networks. Both synaptic plasticity and inference depend on 
convergentneuronalactivity;therefore,aberrantinferencewilldisrupt 
learning. Conversely, inference is not possible without the knowledge 
accumulated through experience (i.e., learning). Thus, inference is 
strongly linked to learning about contingencies that generate false 
inferences. Our i ndings demonstrate this association both mechan- 
istically and mathematically, in terms of one simple rule that allows 
prior beliefs to underwrite inferences about hidden states. 
Combining mathematical analyses with empirical observations 
revealed that baseline excitability is a circuit-level encoding of prior 
beliefs about hidden states. The notion that manipulating the state 
prior (encoded by neuronal excitability) disrupts inference and learn- 
ing may explain the perceptual def i cits produced by drugs that alter 
neuronal excitability, such as anxiolytics and psychedelics53. This may 
have profound implications for our understanding of how anxiolytics 
and psychedelics mediate their effects; namely, a direct effect on 
baseline activity can alter subsequent perceptual learning. Addition- 
ally, aberrant prior beliefs are a plausible cause of the hallucinations 
anddelusionsthatconstitutethepositivesymptomsof 
schizophrenia54,55. This suggests that, in principle, reverse engineering 
provides a formal avenue for estimating prior beliefs from empirical
1 / 1
ChatGPT
It appears that you've provided an extensive excerpt from a scientific paper or article, possibly related to the field of neuroscience and the study of free energy principles in neuronal networks.
Could you please specify what you'd like to know, or what you'd like me to do with this information? Whether it's an explanation, analysis, summary, or something else, I'm here to help!
1 / 1
Reverse engineering of generative models 
In this section, we elaborate the procedure for estimating the thresh- 
old factor (��) and effective synaptic connectivity (W) from empirical 
data,tocharacterisethelandscapeoftheneuralnetworkcostfunction 
L (? F) and further derive the generative model that the biological 
system employs. 
Assumingthatthechangeinthresholdfactorwassuff i cientlyslow 
relative to a short experimental period, the threshold factor �� was 
estimated based on the mean response intensity of empirical data. 
Followingthetreatmentestablishedinpreviouswork16,17,theconstants 
are estimated for each culture using the empirical data as follows: 
��= ��1 
��0 
?? 
=ln xt ?? 
xt ?? ! ��9�� 
where ? h i := 
1 
t Pt 
�� =1? indicates the average over time. Equation (9) was 
computed using data in the initial 10 sessions. Subsequently, the state 
priorDwasreconstructedfromtherelationshiplnD=�� (Table2).This 
D expresses the implicit perceptual bias of an in vitro network about 
hidden sources. 
Synaptic plasticity rules conjugate to Eq. (6) are derived as the 
gradient descent on L16,17, which are asymptotically given as _ W1/ 
?1 
t 
���L 
���W1 = xtoT 
t 
?? 
?xt~1T 
DE 
? b 
W1and _ 
W0/ ?1 
t 
���L 
���W0 = xtoT 
t 
?? 
?xt~1T 
DE 
? 
b 
W0in the limit of a large t, where ? denotes the elementwise product 
(a.k.a., the Hadamard product). These rules comprise Hebbian plasti- 
city accompanied with an activity-dependent homeostatic term, 
Articlehttps://doi.org/10.1038/s41467-023-40141-z 
Nature Communications| (2023) 14:4547 12 
endorsing the biological plausibility of this class of cost functions. 
Solving the i xed point of these equations provides the following 
synaptic strengths: W1=sig?1xtoT 
t 
?? 
?xt~1T 
DE?? 
W0=sig?1xtoT 
t 
?? 
?xt~1T 
DE?? 
8 > < > : 
��10�� 
where ? denotes the elementwise division operator. In this work, we 
refer to Eq. (10) as the empirically estimated effective synaptic con- 
nectivity, where W =W1? W0. 
This was estimated for each session, 
using empirical neuronal response data xt. These synaptic strengths 
encode the posterior belief about the mixing matrix A (Table 2). Fur- 
ther details are provided in previous works16,17. 
These empirically estimated parameters are suff i cient to char- 
acterisethe generative model that anin vitroneural networkemploys. 
Owing to the equivalence, the empirical variational free energy F for 
the in vitro network was computed by substituting empirical neuronal 
responses x and empirically estimated parameters W (Eq. (10)) and �� 
(Eq.(9))into the neuralnetwork costfunction L (Eq. (8)):see Fig. 3l for 
its trajectory. 
Data prediction using the free-energy principle 
The virtues of the free-energy principle are that it offers the quanti- 
tative prediction of transitions (i.e., plasticity) of the neural responses 
and synaptic strengths in future, in the absence of empirical response 
data. We denote the predicted neural responses and synaptic 
strengths as xP 
t and WP, respectively, to distinguish them from the 
observed neural responses xtand empirically estimated synaptic 
strengths W def i ned above. 
The predicted neural response is given as the i xed-point solution 
of Eq. (6): xP 
t =sig WPot+hP 
?? ��11�� 
where hP=lnbW 
P 1~ 1 ? lnbW 
P 0~ 1+��1? ��0denotes 
the adaptive i ring 
threshold. Empirical �� (Eq. (9)) estimated from data in the initial 
10 sessions was used to characterise hP. Here, predicted synaptic 
strength matrix WPwas used instead of the empirically estimated W. 
The predicted synaptic strengths are given as follows: 
WP 
1=sig ?1 xP to 
T 
t 
?? 
?xP 
t~ 
1T 
DE?? 
WP 0=sig ?1 xP to 
T 
t 
DE ?xP t~ 
1T 
DE?? 
8 > < > : 
��12�� 
where WP:=WP 
1 ? WP 0. Here, the predicted neural responses x P 
t were 
employed to compute the outer products. The initial value of WPwas 
computed using empirical response data in the i rst 10 sessions. By 
computing Eqs. (11) and (12), one can predict the subsequent self- 
organisation of neuronal networks in sessions 11���100, without 
reference to the observed neuronal responses. 
We note that the reverse engineering approach provides three 
novel aspects compared to earlier work22,23. First, previous work 
assumed the form of the generative model and did not examine 
whether all elements of the generative model corresponded to biolo- 
gical entities at the circuit level. In the present work, we objectively 
reverse-engineered the generative model from empirical data and 
showed a one-to-one mapping between all the elements of the gen- 
erative model and neural network entities. Second, previous work did 
notexaminetheimpactofchangingpriorbeliefsonBayesianinference 
performedbyinvitroneuralnetworks.Thepresentworkanalysedhow 
Bayesian inference and free energy reduction changed when the prior 
belief and external environment were artif i cially manipulated and 
showed that the results were consistent with theoretical predictions. 
This work validated the predicted relationship between baseline 
excitability andprior beliefs abouthidden states.Third,previous work 
did not investigate whether the free-energy principle can quantita- 
tively predict the learning process of biologicalneuralnetworks based 
exclusively on initial empirical data. This was demonstrated in the 
current work.
1 / 1
ChatGPT
The text you've provided appears to be a detailed description of reverse engineering of generative models to estimate parameters such as the threshold factor and effective synaptic connectivity from empirical data. The procedures described allow for a characterization of the landscape of a neural network cost function and derive a generative model employed by a biological system.
Here's a brief summary of the main points:
Estimation of the Threshold Factor (��):
Based on mean response intensity, the threshold factor is estimated, allowing a representation of the network's implicit perceptual bias.
Synaptic Plasticity Rules:
Derived from gradient descent, these rules result in Hebbian plasticity and allow for computation of synaptic strengths W1 and W0.
Effective Synaptic Connectivity:
This is estimated for each session using empirical neuronal response data, and the synaptic strengths encode posterior belief about the mixing matrix A.
Data Prediction Using the Free-Energy Principle:
This principle enables quantitative prediction of transitions in neural responses and synaptic strengths without the need for empirical response data.
Novel Aspects of the Reverse Engineering Approach:
The text notes three key novelties in this approach: objective reverse engineering from empirical data, analysis of the impact of changing prior beliefs, and quantitative prediction of learning processes in biological neural networks.
These procedures contribute to understanding how the neural networks function and adapt, providing insights into underlying biological mechanisms. Is there a specific question or aspect of this text that you would like me to explain further?
1 / 1
I skipped a few sections of the article but can you give a general overview of the free energy principle, active inference, predictive coding, and how they relate to the topics discussed.
1 / 1
ChatGPT
Certainly! Let's break down these concepts:
Free Energy Principle
The Free Energy Principle (FEP) is a theoretical framework that explains how living systems maintain themselves in a changing environment. It states that systems (such as the brain) try to minimize a quantity known as "free energy," which represents the difference between the system's predictions and the sensory data it receives. By minimizing free energy, the system becomes better at predicting its environment, thus improving its adaptation and survival.
Active Inference
Active inference is an approach that integrates perception, action, and learning within the FEP framework. It's a process where the brain not only infers the causes of sensory inputs (perception) but also takes actions to resolve uncertainty and minimize free energy (action). This continuous loop of perception, action, and updating beliefs allows the system to maintain a coherent model of the world.
Predictive Coding
Predictive coding is a specific implementation of the FEP. It suggests that the brain is constantly generating predictions about sensory inputs, and these predictions are compared to actual sensory data. The difference between predictions and reality, known as the "prediction error," is then used to update the model and refine future predictions. This constant feedback loop enables the brain to become more efficient at interpreting sensory information.
Relationship to the Discussed Topics
The text you provided delves into a computational approach to model these concepts within neural networks:
Estimation of Threshold Factors and Synaptic Connectivity:
By reverse engineering and determining these factors, the study is trying to understand how neural networks employ predictive coding and free energy minimization to interpret sensory data.
Synaptic Plasticity Rules:
These rules represent how connections between neurons change over time, in line with the active inference model, where action and learning are intertwined.
Data Prediction Using the Free Energy Principle:
This highlights the application of FEP to predict neural responses and synaptic strengths, demonstrating how these theories can be practically applied to understand neural networks.
Novel Approaches:
The unique aspects of reverse engineering and empirical data usage align with the principle of learning from prediction errors and adapting over time, which is core to predictive coding, active inference, and the FEP.
In summary, the discussed topics provide a detailed investigation into how principles like free energy, active inference, and predictive coding can be modelled and understood within the complex dynamics of neural networks, offering insights into brain function and potential applications in artificial neural networks.
1 / 1
���� Wow, that's a lot of cool information! Let me break it down for you:

- The Free Energy Principle (FEP) is a framework that explains how living systems adapt to their surroundings. It says that these systems try to minimize something called "free energy," which is the difference between their predictions and what their senses tell them.

- Active inference is a process within the FEP framework. It's when the brain not only figures out what's happening around it but also takes actions to reduce uncertainty and minimize free energy. This ongoing loop helps the brain understand and navigate the world.

- Predictive coding is a specific way to implement the FEP. The brain is always making guesses about what it expects to sense. Then it compares those guesses to what it actually senses. The difference between the guesses and reality helps the brain improve its predictions over time.

Now, in the research papers you mentioned:

- They want to figure out how neural networks use predictive coding and minimize free energy. They study factors like threshold and synaptic connectivity to reverse-engineer and understand how these networks interpret what they sense.

- They also explore synaptic plasticity rules to understand how connections between neurons change. This aligns with the active inference model, where action and learning are connected.

- The researchers apply the Free Energy Principle to predict neural responses and synaptic strengths. This helps them practically apply these theories to understand neural networks.

- These studies have novel approaches, using reverse engineering and empirical data. They resemble the idea of learning from prediction errors and adapting over time, which is significant in predictive coding, active inference, and the Free Energy Principle.

In summary, these papers delve into how the brain's principles, like free energy, active inference, and predictive coding, can be modeled and understood within neural networks. It provides insights into brain function and potential applications in artificial neural networks. It's all about unlocking the fascinating secrets of the brain! ��������
1 / 1
ChatGPT
Absolutely, you've summed it up beautifully! By bridging theoretical concepts with practical modeling, the research you mentioned is contributing to our understanding of how the brain functions. These insights could pave the way for innovations in artificial intelligence, neuroscience, and even medicine. The complexity of the brain is certainly one of the most intriguing puzzles of our time, and these models and methods are essential tools to deciphering it. It's indeed about unlocking the fascinating secrets of the brain! ��������
1 / 1
I want to know if free energy minimization applies to the formation of galaxies and proto-planetary disks.
1 / 2
ChatGPT
The Free Energy Principle (FEP) that we were discussing earlier is primarily a concept in neuroscience and the study of biological systems. It's about the minimization of surprise or prediction error in the context of sensory perception and understanding the environment.
In astrophysics, the concept of free energy minimization doesn't directly apply to the formation of galaxies or proto-planetary disks. Instead, these formations are governed by principles from classical physics, including gravity, thermodynamics, fluid dynamics, and angular momentum conservation.
In the formation of galaxies, gravitational attraction, dark matter, gas dynamics, and other cosmic forces play key roles. Similarly, the formation of proto-planetary disks involves the conservation of angular momentum, gravitational forces, and thermodynamics within a cloud of interstellar dust and gas.
While both the FEP in neuroscience and the principles guiding galactic formation involve complex systems and the idea of reaching some equilibrium or minimized state, they are applied in very different contexts and are based on different underlying theories and laws.
1 / 1
The Free Energy Principle is a theory that suggests that the brain reduces [[surprisal|surprise]] or uncertainty by making predictions based on internal models and updating them using sensory input. 

It highlights the brain's objective of aligning its internal model with the external world to enhance prediction accuracy.

This principle integrates Bayesian inference with active inference, where actions are guided by predictions and sensory feedback refines them. It has wide-ranging implications for comprehending brain function, perception, and action.


....

Adaptive agents must occupy a limited repertoire of states and therefore minimize the long-term average of surprise associated with sensory exchanges with the world. Minimizing surprise enables them to resist a natural tendency to disorder.

Surprise rests on predictions about sensations, which depend on an internal generative model of the world. Although surprise cannot be measured directly, a free-energy bound on surprise can be, suggesting that agents minimize free energy by changing their predictions (perception) or by changing the predicted sensory inputs (action).

Perception optimizes predictions by minimizing free energy with respect to synaptic activity (perceptual inference), efficacy (learning and memory) and gain (attention and salience). This furnishes Bayes-optimal (probabilistic) representations of what caused sensations (providing a link to the Bayesian brain hypothesis).

Bayes-optimal perception is mathematically equivalent to predictive coding and maximizing the mutual information between sensations and the representations of their causes. This is a probabilistic generalization of the principle of efficient coding (the infomax principle) or the minimum-redundancy principle.

Learning under the free-energy principle can be formulated in terms of optimizing the connection strengths in hierarchical models of the sensorium. This rests on associative plasticity to encode causal regularities and appeals to the same synaptic mechanisms as those underlying cell assembly formation.

Action under the free-energy principle reduces to suppressing sensory prediction errors that depend on predicted (expected or desired) movement trajectories. This provides a simple account of motor control, in which action is enslaved by perceptual (proprioceptive) predictions.

Perceptual predictions rest on prior expectations about the trajectory or movement through the agent's state space. These priors can be acquired (as empirical priors during hierarchical inference) or they can be innate (epigenetic) and therefore subject to selective pressure.

Predicted motion or state transitions realized by action correspond to policies in optimal control theory and reinforcement learning. In this context, value is inversely proportional to surprise (and implicitly free energy), and rewards correspond to innate priors that constrain policies

https://link.springer.com/article/10.1007/s11229-016-1239-1


Download PDF

S.I.: Predictive Brains

Open Access

Published: 21 October 2016

The anticipating brain is not a scientist: the free-energy principle from an ecological-enactive perspective

Jelle Bruineberg, 

Julian Kiverstein & 

Erik Rietveld 

Synthese volume 195, pages2417���2444 (2018)Cite this article

17k Accesses

162 Citations

64 Altmetric

Metricsdetails

Abstract
1 / 1
ChatGPT
It looks like the text you provided is an overview of the Free Energy Principle (FEP) as applied to the brain, emphasizing its role in perception, action, learning, and understanding the world. This perspective integrates concepts from Bayesian inference, predictive coding, motor control, optimal control theory, and reinforcement learning.
The article mentioned, titled "The anticipating brain is not a scientist: the free-energy principle from an ecological-enactive perspective" by Jelle Bruineberg, Julian Kiverstein, and Erik Rietveld, likely discusses the FEP in the context of an ecological-enactive approach. This perspective often involves considering the brain's interactions with its environment and how it acts within that environment, rather than viewing the brain as an isolated information processor.
However, there's no direct reference in the text to the formation of galaxies or proto-planetary disks, so it doesn't appear to connect the FEP to these astrophysical phenomena. As previously mentioned, the FEP primarily pertains to cognitive science and neuroscience, not to the principles governing the behavior of astronomical objects.
1 / 1
I was thinking that in analyzing gravitational attraction and galactic void expansion can be seen as minimizing the potential energy configuration. Baryonic matter falls inward and voids fall outward by expanding.
1 / 1
ChatGPT
Your observation about minimizing potential energy in the context of gravitational attraction and galactic void expansion is indeed applicable to physical systems, including the formation of galaxies and proto-planetary disks.
In physical systems, energy tends to seek the lowest possible state, and this principle is at the heart of many processes in the universe. Here's how it relates to the phenomena you mentioned:
Gravitational Attraction
: Objects with mass attract each other due to gravity. In systems like galaxies or proto-planetary disks, this gravitational pull causes matter to clump together. Over time, these clumps can coalesce into stars, planets, and other astronomical bodies. This process can be seen as minimizing the gravitational potential energy of the system.
Galactic Void Expansion
: The universe is filled with vast regions of nearly empty space known as cosmic voids. These voids are expanding as the universe itself expands. The dynamics of this expansion can be analyzed in terms of energy minimization as well. As the universe expands, it's moving towards a state that's consistent with the principles of thermodynamics, where potential energy configurations are minimized.
While the concept of minimizing energy is common to both the Free Energy Principle in neuroscience and the principles guiding the formation of astronomical structures, they are applied in very different domains and contexts. The Free Energy Principle deals with cognitive processes and how the brain models its environment, whereas the minimization of potential energy in astrophysics relates to the fundamental forces and dynamics governing the behavior of matter on cosmic scales.
So, while there are conceptual similarities in terms of energy minimization, the applications in the brain's functioning and in cosmology are distinct and governed by different underlying principles and laws.
1 / 1
The gravity model of international trade in international economics is a model that, in its traditional form, predicts bilateral trade flows based on the economic sizes and distance between two units. Research shows that there is "overwhelming evidence that trade tends to fall with distance."[2]


Shift of the world's economic center of gravity since 1980 and projected until 2050[1]
The model was first introduced in economics world by Walter Isard in 1954.[3] The basic model for trade between two countries (i and j) takes the form of

{\displaystyle F_{ij}=G\cdot {\frac {M_{i}M_{j}}{D_{ij}}}.}{\displaystyle F_{ij}=G\cdot {\frac {M_{i}M_{j}}{D_{ij}}}.}
In this formula G is a constant, F stands for trade flow, D stands for the distance and M stands for the economic dimensions of the countries that are being measured. The equation can be changed into a linear form for the purpose of econometric analyses by employing logarithms. The model has been used by economists to analyse the determinants of bilateral trade flows such as common borders, common languages, common legal systems, common currencies, common colonial legacies, and it has been used to test the effectiveness of trade agreements and organizations such as the North American Free Trade Agreement (NAFTA) and the World Trade Organization (WTO) (Head and Mayer 2014). The model has also been used in international relations to evaluate the impact of treaties and alliances on trade (Head and Mayer).

The model has also been applied to other bilateral flow data (also known as "dyadic" data) such as migration, traffic, remittances and foreign direct investment.
1 / 1
ChatGPT
The Gravity Model of international trade is indeed a widely-used concept in economics that leverages the mathematical form of Newton's law of gravitation to explain and predict trade flows between different countries or regions. Here's a more detailed breakdown:
Economic Sizes (M):
The economic size of the countries (usually measured by GDP) acts like mass in the gravitational equation. Larger economies tend to have more trade between them, just as larger masses have a stronger gravitational pull.
Distance (D):
The distance between two countries acts as a barrier to trade, in the same way that the gravitational force between two objects decreases with distance. This includes not just physical distance but can also be extended to cultural, legal, or economic distances, such as differences in language, legal systems, or trade policies.
Constant (G):
This represents a proportionality factor that might encapsulate other constant effects on trade between the two countries.
The gravity model has been very successful in empirically predicting trade patterns and analyzing various trade-related issues, like the effects of trade agreements, common currencies, historical ties, and so on. It has been expanded to study other interactions between countries, such as migration and foreign investment, as you noted.
One reason why the model has been so influential is that it provides a clear and intuitive framework that captures essential features of international trade, such as the tendency for trade to increase with economic size and decrease with barriers like distance. It's a good example of how concepts from one field (in this case, physics) can be creatively adapted to shed light on phenomena in a completely different domain (in this case, economics).
1 / 1
LW
Why I���m not into the Free Energy Principle
by Steven Byrnes
11 min read
2nd Mar 2023
46 comments
134
Free Energy PrincipleNeuroscienceWorld Modeling
Frontpage
0. But first, some things I do like, that are appropriately emphasized in the FEP-adjacent literature
I like the idea that in humans, the cortex (and the cortex specifically, in conjunction with the thalamus, but definitely not the whole brain IMO) has a generative model that���s making explicit predictions about upcoming sensory inputs, and is updating that generative model on the prediction errors. For example, as I see the ball falling towards the ground, I���m expecting it to bounce; if it doesn���t bounce, then the next time I see it falling, I���ll expect it to not bounce. This idea is called ���self-supervised learning��� in ML. AFAICT this idea is uncontroversial in neuroscience, and is widely endorsed even by people very far from the FEP-sphere like Jeff Hawkins and Randall O���Reilly and Yann LeCun. Well at any rate, I for one think it���s true.
I like the (related) idea that the human cortex interprets sensory inputs by matching them to a corresponding generative model, in a way that���s at least loosely analogous to probabilistic inference. For example, in the neon color spreading optical illusion below, the thing you ���see��� is a generative model that includes a blue-tinted solid circle, even though that circle is not directly present in the visual stimulus. (The background is in fact uniformly white.)
Neon_Color_Circle.gif (480��480)
The ���neon color spreading��� optical illusion���see text above. Source.
I like the (related) idea that my own actions are part of this generative model. For example, if I believe I am about to stand up, then I predict that my head is about to move, that my chair is about to shift, etc.���and part of that is a prediction that my own muscles will in fact execute the planned maneuvers.
So just to be explicit, the following seems perfectly fine to me: First you say ���Hmm, I think maybe the thalamocortical system in the mammalian brain processes sensory inputs via approximate Bayesian inference���, and then you start doing a bunch of calculations related to that, and maybe you���ll even find that some of those calculations involve a term labeled ���variational free energy���. OK cool, good luck with that, I have no objections. (Or if I do, they���re outside the scope of this post.) Note that this hypothesis about the thalamocortical system is substantive���it might be true or it might be false���unlike FEP as discussed shortly.

Instead, my complaint here is about the Free Energy Principle as originally conceived by Friston, i.e. as a grand unified theory of the whole brain, even including things like the circuit deep in your brainstem that regulates your heart rate.

OK, now that we���re hopefully on the same page about exactly what I am and am not ranting about, let the rant begin!

1. The Free Energy Principle is an unfalsifiable tautology
It is widely accepted that FEP is an unfalsifiable tautology, including by proponents���see for example Beren Millidge, or Friston himself.

By the same token, once we find a computer-verified proof of any math theorem, we have revealed that it too is an unfalsifiable tautology. Even Fermat���s Last Theorem is now known to be a direct logical consequence of the axioms of math���arguably just a fancy way of writing 0=0.

So again, FEP is an unfalsifiable tautology. What does that mean in practice? Well, It means that I am entitled to never think about FEP. Anything that you can derive from FEP, you can derive directly from the same underlying premises from which FEP itself can be proven, without ever mentioning FEP.
1 / 1
ChatGPT
The excerpt you've provided is from an article by Steven Byrnes where he expresses skepticism about the Free Energy Principle (FEP) as a grand unified theory of the whole brain. The Free Energy Principle is a theoretical framework proposed by Karl Friston that aims to explain how biological systems, like the brain, maintain themselves in a changing environment.
Here's a breakdown of the key points Byrnes is making:
Support for Some Concepts
: Byrnes agrees with some ideas that are part of or related to the FEP framework. He likes the idea of the cortex having a generative model, interpreting sensory inputs through probabilistic inference, and incorporating actions into this model. These concepts are connected to the idea of self-supervised learning in machine learning, and they're not necessarily controversial.
Disagreement with FEP as a Unified Theory
: Byrnes takes issue with FEP being applied as a comprehensive theory for the entire brain, including functions like heart rate regulation. He believes this broad application is where the theory falls short.
FEP as an Unfalsifiable Tautology
: Byrnes argues that FEP is an unfalsifiable tautology, meaning that it's a statement that's true by necessity or by virtue of its logical form. He likens it to a mathematical theorem, which is true because it follows logically from its premises. This characterization leads him to believe that FEP is not a useful or necessary concept.
Implication of Being a Tautology
: The criticism of FEP as an unfalsifiable tautology means that, according to Byrnes, it doesn't provide unique or novel insights. Anything derived from FEP could be derived directly from underlying premises without referring to FEP itself.
Byrnes' perspective represents a skeptical viewpoint on the Free Energy Principle's applicability as a universal theory for the brain. This type of debate reflects the ongoing discussions and controversies in the scientific and philosophical communities about the proper scope and interpretation of theoretical frameworks like FEP. Different researchers may have varying opinions on how broadly these principles should be applied and what they can tell us about the brain and behavior.
1 / 1
(The underlying premises in question are something like ���it���s a thing with homeostasis and bodily integrity���. So, by the way: if someone tells you ���FEP implies organisms do X���, and if you can think of an extremely simple toy model of something with homeostasis & bodily integrity that doesn���t do X, then you can go tell that person that they���re wrong about what FEP implies!)

So the question is really whether FEP is helpful.

Here are two possible analogies:

(1) Noether���s Theorem (if the laws of physics have a symmetry, they also have a corresponding conservation law) is also an unfalsifiable tautology.
(2) The pointless bit of math trivia 
2592
=
2
5
���
9
2
 is also an unfalsifiable tautology.
In both cases, I don���t have to mention these facts. But in the case of (1)���but not (2)���I want to.

More specifically, here���s a very specific physics fact that is important in practice: ���FACT: if a molecule is floating in space, without any light, collisions, etc., then it will have a conserved angular momentum���. I can easily prove this fact by noting that it follows from Noether���s Theorem. But I don���t have to, if I don���t want to; I could also prove it directly from first principles.

However: proving this fact from first principles is no easier than first proving Noether���s Theorem in its full generality, and then deriving this fact as a special case. In fact, if you ask me on an exam to prove this fact from first principles without using Noether���s theorem, that���s pretty much exactly what I would do���I would write out something awfully similar to the (extremely short) fully-general quantum-mechanical proof of Noether���s theorem.

So avoiding (1) is kinda silly���if I try to avoid talking about (1), then I find myself tripping over (1) in the course of talking about lots of other things that are of direct practical interest. Whereas avoiding (2) is perfectly sensible���if I don���t deliberately bring it up, it will never come up organically. It���s pointless trivia. It doesn���t help me with anything.

So, which category is FEP in?

From my perspective, I have yet to see any concrete algorithmic claim about the brain that was not more easily and intuitively [from my perspective] discussed without mentioning FEP.

For example, at the top I mentioned that the cortex predicts upcoming sensory inputs and updates its models when there are prediction errors. This idea is true and important. And it���s also very intuitive. People can understand this idea without understanding FEP. Indeed, somebody invented this idea long before FEP existed.

I���ll come back to two more examples in Sections 3 & 4.

2. The FEP is applicable to both bacteria and human brains. So it���s probably a bad starting point for understanding how human brains work
What���s the best way to think about the human cerebral cortex? Or the striatum? Or the lateral habenula? There are neurons sending signals from retrosplenial cortex to the superior colliculus���what are those signals for? How does curiosity work in humans? What about creativity? What about human self-reflection and consciousness? What about borderline personality disorder?

None of these questions are analogous to questions about bacteria. Or, well, to the very limited extent that there are analogies (maybe some bacteria have novelty-detection systems that are vaguely analogous to human curiosity / creativity if you squint?), I don���t particularly expect the answers to these questions to be similar in bacteria versus humans.

Yet FEP applies equally well to bacteria and humans.

So it seems very odd to expect that FEP would be a helpful first step towards answering these questions.

3. It���s easier to think of a feedback control system as a feedback control system, and not as an active inference system
Let���s consider a simple thermostat. There���s a metal coil that moves in response to temperature, and when it moves beyond a setpoint it flips on a heater. It���s a simple feedback control system.

There���s also a galaxy-brain ���active inference��� way of thinking about this same system. The thermostat-heater system is ���predicting��� that the room will maintain a constant temperature, and the heater makes those ���predictions��� come true. There���s even a paper going through all the details (of a somewhat-similar class of systems).

OK, now here���s a quiz: (1) What happens if the thermostat spring mechanism is a bit sticky (hysteretic)? (2) What happens if there are two thermostats connected to the same heater, via an AND gate? (3) ���or an OR gate? (4) What happens if the heater can only turn on once per hour?

I bet that people thinking about the thermostat-heater system in the normal way (as a feedback control system) would nail all these quiz questions easily. They���re not trick questions! We have very good intuitions here.

But I bet that people attempting to think about the thermostat-heater system in the galaxy-brain ���active inference��� way would have a very hard time with this quiz. It���s probably technically possible to derive a set of the equations analogous to those in the above-mentioned paper and use those equations to answer these quiz questions, but I don���t think it���s easy. Really, I���d bet that even the people who wrote that paper would probably answer the quiz questions in practice by thinking about the system in the normal control-system way, not the galaxy-brain thing where the system is ���predicting��� that the room temperature is constant.

What���s true for thermostats is, I claim, even more true for more complicated control systems.

My own background is physics, not control systems engineering. I can, however, brag that at an old job, I once designed an unusually complicated control system that had to meet a bunch of crazy specs, and involved multiple interacting loops of both feedback and anticipatory-feedforward control. I wrote down a design that I thought would work, and when we did a detailed numerical simulation, it worked on the computer just like I imagined it working in my head. (I believe that the experimental tests also worked as expected, although I had gotten reassigned to a different project in the meantime and am hazy on the details.)

The way that I successfully designed this awesome feedforward-feedback control system was by thinking about it in the normal way, not the galaxy-brain ���active inference��� way. Granted, I hadn���t heard of active inference at the time. But now I have, and I can vouch that this knowledge would not have helped me design this system.


They have played us for absolute fools. (Source)
That���s just me, but I have also worked with numerous engineers designing numerous real-world control systems, and none of them ever mentioned active inference as a useful way to think about what���s going on in any kind of control system.

And these days, I often think about various feedback control systems in the human brain, and I likewise find it very fruitful to think about them using my normal intuitions about how feedback signals work etc., and I find it utterly unhelpful to think of them as active inference systems.

4. Likewise, it���s easier to think of a reinforcement learning (RL) system as an RL system, and not as an active inference system
Pretty much ditto the previous section.

Consider a cold-blooded lizard that goes to warm spots when it feels cold and cold spots when it feels hot. Suppose (for the sake of argument) that what���s happening behind the scenes is an RL algorithm in its brain, whose reward function is external temperature when the lizard feels cold, and whose reward function is negative external temperature when the lizard feels hot.

We can talk about this in the ���normal��� way, as a certain RL algorithm with a certain reward function, as per the previous sentence.
���Or we can talk about this in the galaxy-brain ���active inference��� way, where the lizard is (implicitly) ���predicting��� that its body temperature will remain constant, and taking actions to make this ���prediction��� come true.
I claim that we should think about it in the normal way. I think that the galaxy-brain ���active inference��� perspective is just adding a lot of confusion for no benefit. Again, see previous section���I could make this point by constructing a quiz as above, or by noting that actual RL practitioners almost universally don���t find the galaxy-brain perspective to be helpful, or by noting that I myself think about RL all the time, including in the brain, and my anecdotal experience is that the galaxy-brain perspective is not helpful.

5. It���s very important to distinguish explicit prediction from implicit prediction���and FEP-adjacent literature is very bad at this
(Or in everyday language: It���s very important to distinguish ���actual predictions��� from ���things that are not predictions at all except in some weird galaxy-brain sense���)

Consider two things: (1) an old-fashioned thermostat-heater system as in Section 3 above, (2) A weather-forecasting supercomputer.

As mentioned in Section 3, in a certain galaxy-brain sense, (1) is a feedback control system that (implicitly) ���predicts��� that the temperature of the room will be constant.

Whereas (2) is explicitly designed to ���predict���, in the normal sense of the word���i.e. creating a signal right now that is optimized to approximate a different signal that will occur in the future.

I think (1) and (2) are two different things, but Friston-style thinking is to unify them together. At best, somewhere in the fine print of a Friston paper, you'll find a distinction between ���implicit prediction��� and ���explicit prediction���, but other times it's not even mentioned, AFAICT. 

And thus, as absurd as it sounds, I really think that one of the ways that the predictive processing people go wrong is by under-emphasizing the importance of [explicit] prediction. If we use the word ���prediction��� to refer to a thermostat connected to a heater, then the word practically loses all meaning, and we���re prone to forgetting that there is a really important special thing that the human cortex can do and that a mechanical thermostat cannot���i.e. build and store complex explicit predictive models and query them for intelligent, flexible planning and foresight.

6. FEP-adjacent literature is also sometimes bad at distinguishing within-lifetime learning from evolutionary learning
I haven���t been keeping track of how often I���ve seen this, but for the record, I wrote down this complaint in my notes after reading a (FEP-centric) Mark Solms book.

7. ���Changing your predictions to match the world��� and ���Changing the world to match your predictions��� are (at least partly) two different systems / algorithms in the brain. So lumping them together is counterproductive
Yes they sound related. Yes you can write one equation that unifies them. But they can���t be the same algorithm, for the following reason:

���Changing your predictions to match the world��� is a (self-) supervised learning problem. When a prediction fails, there���s a ground truth about what you should have predicted instead. More technically, you get a full error gradient ���for free��� with each query, at least in principle. Both ML algorithms and brains use those sensory prediction errors to update internal models, in a way that relies on the rich high-dimensional error information that arrives immediately-after-the-fact.
���Changing the world to match your predictions��� is a reinforcement learning (RL) problem. No matter what action you take, there is no ground truth about what action you counterfactually should have taken. So you can���t use a supervised learning algorithm. You need a different algorithm.
Since they���re (at least partly) two different algorithms, unifying them is a way of moving away from a ���gears-level��� understanding of how the brain works. They shouldn���t be the same thing in your mental model, if they���re not the same thing in the brain.

(Side note:  In actor-critic RL, the critic gets error information, and so we can think of the critic specifically as doing supervised learning. But the actor has to be doing something different, presumably balancing exploration with exploitation and so on. Anyway, as it turns out, I think that in the human brain, the RL critic is a different system from the generative world-model���the former is centered around the striatum, the latter around the cortex. So even if they���re both doing supervised learning, we should still put them into two different mental buckets.)

UPDATED TO ADD: For the record, my knowledge of FEP is based mainly on the books Surfing Uncertainty by Andy Clark, Predictive Mind by Jakob Hohwy, Hidden Spring by Mark Solms, How Emotions Are Made by Lisa Feldman Barrett, & Being You by Anil Seth; plus a number of papers (including by Friston) and blog posts. Also thanks to Eli Sennesh & Beren Millidge for patiently trying (and perhaps failing) to explain FEP to me at various points in my life.
1 / 1
ChatGPT
It appears you've shared an extensive and critical analysis of the Free Energy Principle (FEP) and its application in understanding various systems, including human brains, control systems, and reinforcement learning. This analysis raises several key points and concerns, such as:
Is FEP More Like a Useful or Pointless Tautology?
- You've compared the FEP to two analogies, one with practical application (Noether's Theorem) and the other lacking utility. You argue that FEP doesn't help in understanding certain phenomena or systems more easily.
Applicability to Bacteria and Human Brains
- You mention that FEP might be too broad, applying to both simple and complex systems, making it a potentially unhelpful tool in understanding specific human brain functions.
Comparison to Feedback Control Systems
- You argue that thinking of a system as a feedback control system is more intuitive than using FEP, providing examples like a thermostat.
Reinforcement Learning (RL) Perspective
- You also compare FEP to RL, stating that thinking about an RL system in normal terms, rather than through the lens of FEP, is more beneficial.
Distinguishing Explicit and Implicit Prediction
- You criticize FEP-related literature for conflating these two concepts, leading to a loss of meaning in the term "prediction."
Learning Distinctions
- You point out that FEP literature might fail to distinguish between within-lifetime learning and evolutionary learning.
Differentiation Between Prediction Matching and World-Changing
- You stress the importance of seeing these as separate processes, each requiring different algorithms.
This critical examination of the Free Energy Principle can surely spark debates and discussions among researchers and thinkers in the fields of neuroscience, psychology, and control systems. It highlights the challenges and potential shortcomings in the adoption of a broad principle like FEP in understanding intricate, specialized systems. Understanding whether FEP serves as a practical tool or mere intellectual curiosity might hinge on more detailed empirical analysis, theoretical scrutiny, and clarification of its core concepts and applications.
1 / 1
A list of all of the topics we've discussed so far.
2 / 2
ChatGPT
Certainly! Since the messages I have access to only include your lengthy summary of thoughts about the Free Energy Principle (FEP), topics related to feedback control systems, predictions, reinforcement learning, and some related philosophical and practical considerations, I can only list the following topics:
Free Energy Principle (FEP) and its implications.
Analogies between FEP and Noether's Theorem and mathematical tautologies.
Application of FEP to biological organisms, both simple and complex.
Comparison of FEP to feedback control systems and active inference systems.
Discussion of reinforcement learning systems and the FEP.
The importance of distinguishing between explicit and implicit predictions.
Consideration of within-lifetime learning versus evolutionary learning.
The distinction between changing predictions to match the world and changing the world to match predictions.
Unfortunately, I do not have access to previous conversations, so I'm unable to list other topics that might have been discussed earlier. If you need more details or a follow-up on any of these points, please let me know!
1 / 1
We also discussed: Active Inference
Predictive Coding
Reverse Engineering of Generative Models
Estimation of Threshold Factor and Synaptic Connectivity
Neural Network Cost Functions
Synaptic Plasticity Rules
Hebbian Plasticity
Biological Plausibility of Cost Functions
Empirical Estimation of Effective Synaptic Connectivity
Data Prediction Using the Free-Energy Principle
Quantitative Prediction of Neural Responses and Synaptic Strengths
Impact of Changing Prior Beliefs on Bayesian Inference
Applications in Artificial Intelligence, Neuroscience, and Medicine
1 / 1
ChatGPT
Certainly! Thank you for adding those topics to the list. Here's the revised list including the newly mentioned subjects:
Free Energy Principle (FEP) and its implications.
Active Inference.
Predictive Coding.
Reverse Engineering of Generative Models.
Estimation of Threshold Factor and Synaptic Connectivity.
Neural Network Cost Functions.
Synaptic Plasticity Rules.
Hebbian Plasticity.
Biological Plausibility of Cost Functions.
Empirical Estimation of Effective Synaptic Connectivity.
Data Prediction Using the Free-Energy Principle.
Quantitative Prediction of Neural Responses and Synaptic Strengths.
Impact of Changing Prior Beliefs on Bayesian Inference.
Applications in Artificial Intelligence, Neuroscience, and Medicine.
Analogies between FEP and Noether's Theorem and mathematical tautologies.
Application of FEP to biological organisms, both simple and complex.
Comparison of FEP to feedback control systems and active inference systems.
Discussion of reinforcement learning systems and the FEP.
The importance of distinguishing between explicit and implicit predictions.
Consideration of within-lifetime learning versus evolutionary learning.
The distinction between changing predictions to match the world and changing the world to match predictions.
That's quite an extensive range of topics! If you have any further questions or want to explore any of these areas more deeply, please let me know.
1 / 1
Summarize: 
https://slatestarcodex.com/2018/03/04/god-help-us-lets-try-to-understand-friston-on-free-energy/

GOD HELP US, LET���S TRY TO UNDERSTAND FRISTON ON FREE ENERGY
POSTED ON MARCH 4, 2018 BY SCOTT ALEXANDER
I���ve been trying to delve deeper into predictive processing theories of the brain, and I keep coming across Karl Friston���s work on ���free energy���.

At first I felt bad for not understanding this. Then I realized I wasn���t alone. There���s an entire not-understanding-Karl-Friston internet fandom, complete with its own parody Twitter account and Markov blanket memes.

From the journal Neuropsychoanalysis (which based on its name I predict is a center of expertise in not understanding things):

At Columbia���s psychiatry department, I recently led a journal club for 15 PET and fMRI researhers, PhDs and MDs all, with well over $10 million in NIH grants between us, and we tried to understand Friston���s 2010 Nature Reviews Neuroscience paper ��� for an hour and a half. There was a lot of mathematical knowledge in the room: three statisticians, two physicists, a physical chemist, a nuclear physicist, and a large group of neuroimagers ��� but apparently we didn���t have what it took. I met with a Princeton physicist, a Stanford neurophysiologist, a Cold Springs Harbor neurobiologist to discuss the paper. Again blanks, one and all.

Normally this is the point at which I say ���screw it��� and give up. But almost all the most interesting neuroscience of the past decade involves this guy in one way or another. He���s the most-cited living neuroscientist, invented large parts of modern brain imaging, and received the prestigious Golden Brain Award (which is somehow a real thing). His Am I Autistic ��� An Intellectual Autobiography short essay, written in a weirdly lucid style and describing hijinks like deriving the Schrodinger equation for fun in school, is as consistent with genius as anything I���ve ever read.

As for free energy, it���s been dubbed ���a unified brain theory��� (Friston 2010), a key through which ���nearly every aspect of [brain] anatomy and physiology starts to make sense��� (Friston 2009), ���[the source of] the ability of biological systems to resist a natural tendency to disorder��� (Friston 2012), an explanation of how life ���inevitably and emergently��� arose from the primordial soup (Friston 2013), and ���a real life version of Isaac Asimov���s psychohistory��� (description here of Allen 2018).

I continue to hope some science journalist takes up the mantle of explaining this comprehensively. Until that happens, I���ve been working to gather as many perspectives as I can, to talk to the few neuroscientists who claim to even partially understand what���s going on, and to piece together a partial understanding. I am not at all the right person to do this, and this is not an attempt to get a gears-level understanding ��� just the kind of pop-science-journalism understanding that gives us a slight summary-level idea of what���s going on. My ulterior motive is to get to the point where I can understand Friston���s recent explanation of depression, relevant to my interests as a psychiatrist.

Sources include Dr. Alianna Maren���s How To Read Karl Friston (In The Original Greek), Wilson and Golonka���s Free Energy: How the F*ck Does That Work, Ecologically?, Alius Magazine���s interview with Friston, Observing Ideas, and (especially) the ominously named Wo���s Weblog.

From these I get the impression that part of the problem is that ���free energy��� is a complicated concept being used in a lot of different ways.

First, free energy is a specific mathematical term in certain Bayesian equations.

I���m getting this from here, which goes into much more detail about the math than I can manage. What I���ve managed to extract: Bayes��� theorem, as always, is the mathematical rule for determining how much to weigh evidence. The brain is sometimes called a Bayesian machine, because it has to create a coherent picture of the world by weighing all the different data it gets ��� everything from millions of photoreceptors��� worth of vision, to millions of cochlear receptors worth of hearing, to all the other sense, to logical reasoning, to past experience, and so on. But actually using Bayes on all this data quickly gets computationally intractable.

Free energy is a quantity used in ���variational Bayesian methods���, a specific computationally tractable way of approximating Bayes��� Theorem. Under this interpretation, Friston is claiming that the brain uses this Bayes-approximation algorithm. Minmizing the free energy quantity in this algorithm is equivalent-ish to trying to minimize prediction error, trying to minimize the amount you���re surprised by the world around you, and trying to maximize accuracy of mental models. This sounds in line with standard predictive processing theories. Under this interpretation, the brain implements predictive processing through free energy minimization.

Second, free energy minimization is an algorithm-agnostic way of saying you���re trying to approximate Bayes as accurately as possible.

This comes from the same source as above. It also ends up equivalent-ish to all those other things like trying to be correct in your understanding of the world, and to standard predictive processing.

Third, free energy minimization is a claim that the fundamental psychological drive is the reduction of uncertainty.

I get this claim from the Alius interview, where Friston says:

If you subscribe to the premise that that creatures like you and me act to minimize their expected free energy, then we act to reduce expected surprise or, more simply, resolve uncertainty. So what���s the first thing that we would do on entering a dark room ��� we would turn on the lights. Why? Because this action has epistemic affordance; in other words, it resolves uncertainty (expected free energy). This simple argument generalizes to our inferences about (hidden or latent) states of the world ��� and the contingencies that underwrite those states of affairs.

The discovery that the only human motive is uncertainty-reduction might come as a surprise to humans who feel motivated by things like money, power, sex, friendship, or altruism. But the neuroscientist I talked to about this says I am not misinterpreting the interview. The claim really is that uncertainty-reduction is the only game in town.
1 / 1
ChatGPT
The blog post "GOD HELP US, LET���S TRY TO UNDERSTAND FRISTON ON FREE ENERGY" by Scott Alexander, published on March 4, 2018, delves into the complex work of Karl Friston, a prominent neuroscientist, on the concept of "free energy."
Alexander opens by humorously acknowledging the widespread confusion around Friston's work, even among professionals, as evident from the numerous unsuccessful attempts by researchers and scholars to grasp his ideas.
Friston is a highly influential figure in neuroscience, celebrated for his contributions to brain imaging and often connected with genius. His work on free energy has been lauded as revolutionary, linking it to everything from the emergence of life to the nature of mental disorders like depression.
Despite the complexity, Alexander attempts to provide a pop-science understanding of the topic, referencing several sources. He emphasizes that "free energy" is a multifaceted concept used in various ways:
Free Energy as a Mathematical Term in Bayesian Equations
: Friston's theory proposes that the brain uses free energy minimization as an approximation of Bayes' Theorem. This process aids the brain in managing vast data, aiming to minimize prediction error and align mental models with the world.
Free Energy Minimization as Algorithm-Agnostic
: This interpretation suggests free energy minimization is a universal approach to approximating Bayes, leading to a better understanding of the world and aligning with predictive processing.
Free Energy Minimization as a Fundamental Psychological Drive
: This aspect of Friston's theory posits that humans' primary motivation is the reduction of uncertainty. It generalizes to our inferences about the world, seemingly reducing all human motivation to this singular concept.
Alexander acknowledges the difficulty of the subject, stressing the need for more accessible explanations and emphasizing that free energy is an intricate concept applied in multiple ways.
Though he provides a summary-level understanding, Alexander's exploration underscores the profound complexity of Friston's work on free energy, an area where even experts have struggled to gain a complete grasp.
1 / 1
In a sense, it must be true that there is only one human motivation. After all, if you���re Paris of Troy, getting offered the choice between power, fame, and sex ��� then some mental module must convert these to a common currency so it can decide which is most attractive. If that currency is, I dunno, dopamine in the striatum, then in some reductive sense, the only human motivation is increasing striatal dopamine (don���t philosophize at me, I know this is a stupid way of framing things, but you know what I mean). Then the only weird thing about the free energy formulation is identifying the common currency with uncertainty-minimization, which is some specific thing that already has another meaning.

I think the claim (briefly mentioned eg here) is that your brain hacks eg the hunger drive by ���predicting��� that your mouth is full of delicious food. Then, when your mouth is not full of delicious food, it���s a ���prediction error���, it sets off all sorts of alarm bells, and your brain���s predictive machinery is confused and uncertain. The only way to ���resolve��� this ���uncertainty��� is to bring reality into line with the prediction and actually fill your mouth with delicious food. On the one hand, there is a lot of basic neuroscience research that suggests something like this is going on. On the other, Wo���s writes about this further:

The basic idea seems to go roughly as follows. Suppose my internal probability function Q assigns high probability to states in which I���m having a slice of pizza, while my sensory input suggests that I���m currently not having a slice of pizza. There are two ways of bringing Q in alignment with my sensory input: (a) I could change Q so that it no longer assigns high probability to pizza states, (b) I could grab a piece of pizza, thereby changing my sensory input so that it conforms to the pizza predictions of Q. Both (a) and (b) would lead to a state in which my (new) probability function Q��� assigns high probability to my (new) sensory input d���. Compared to the present state, the sensory input will then have lower surprise. So any transition to these states can be seen as a reduction of free energy, in the unambitious sense of the term.

Action is thus explained as an attempt to bring one���s sensory input in alignment with one���s representation of the world.

This is clearly nuts. When I decide to reach out for the pizza, I don���t assign high probability to states in which I���m already eating the slice. It is precisely my knowledge that I���m not eating the slice, together with my desire to eat the slice, that explains my reaching out.

There are at least two fundamental problems with the simple picture just outlined. One is that it makes little sense without postulating an independent source of goals or desires. Suppose it���s true that I reach out for the pizza because I hallucinate (as it were) that that���s what I���m doing, and I try to turn this hallucination into reality. Where does the hallucination come from? Surely it���s not just a technical glitch in my perceptual system. Otherwise it would be a miraculous coincidence that I mostly hallucinate pleasant and fitness-increasing states. Some further part of my cognitive architecture must trigger the hallucinations that cause me to act. (If there���s no such source, the much discussed ���dark room problem��� arises: why don���t we efficiently minimize sensory surprise (and thereby free energy) by sitting still in a dark room until we die?)

The second problem is that efficient action requires keeping track of both the actual state and the goal state. If I want to reach out for the pizza, I���d better know where my arms are, where the pizza is, what���s in between the two, and so on. If my internal representation of the world falsely says that the pizza is already in my mouth, it���s hard to explain how I manage to grab it from the plate.

A closer look at Friston���s papers suggests that the above rough proposal isn���t quite what he has in mind. Recall that minimizing free energy can be seen as an approximate method for bringing one probability function Q close to another function P. If we think of Q as representing the system���s beliefs about the present state, and P as a representation of its goals, then we have the required two components for explaining action. What���s unusual is only that the goals are represented by a probability function, rather than (say) a utility function. How would that work?

Here���s an idea. Given the present probability function Q, we can map any goal state A to the target function Q^A, which is Q conditionalized on A ��� or perhaps on certain sensory states that would go along with A. For example, if I successfully reach out for the pizza, my belief function Q will change to a function Q^A that assigns high probability to my arm being outstretched, to seeing and feeling the pizza in my fingers, etc. Choosing an act that minimizes the difference between my belief function and Q^A is then tantamount to choosing an act that realizes my goal.

This might lead to an interesting empirical model of how actions are generated. Of course we���d need to know more about how the target function Q^A is determined. I said it comes about by (approximately?) conditionalizing Q on the goal state A, but how do we identify the relevant A? Why do I want to reach out for the pizza? Arguably the explanation is that reaching out is likely (according to Q) to lead to a more distal state in which I eat the pizza, which I desire. So to compute the proximal target probability Q^A we presumably need to encode the system���s more distal goals and then use techniques from (stochastic) control theory, perhaps, to derive more immediate goals.

That version of the story looks much more plausible, and much less revolutionary, than the story outlined above. In the present version, perception and action are not two means to the same end ��� minimizing free energy. The free energy that���s minimized in perception is a completely different quantity than the free energy that���s minimized in action. What���s true is that both tasks involve mathematically similar optimization problems. But that isn���t too surprising given the well-known mathematical and computational parallels between conditionalizing and maximizing expected utility.

It���s tempting to throw this out entirely. But part of me does feel like there���s a weird connection between curiosity and every other drive. For example, sex seems like it should be pretty basic and curiosity-resistant. But how often do people say that they���re attracted to someone ���because he���s mysterious���? And what about the Coolidge Effect (known in the polyamory community as ���new relationship energy���)? After a while with the same partner, sex and romance lose their magic ��� only to reappear if the animal/person hooks up with a new partner. Doesn���t this point to some kind of connection between sexuality and curiosity?

What about the typical complaint of porn addicts ��� that they start off watching softcorn porn, find after a while that it���s no longer titillating, move on to harder porn, and eventually have to get into really perverted stuff just to feel anything at all? Is this a sort of uncertainty reduction?

The only problem is that this is a really specific kind of uncertainty reduction. Why should ���uncertainty about what it would be like to be in a relationship with that particular attractive person��� be so much more compelling than ���uncertainty about what the middle letter of the Bible is���, a question which almost no one feels the slightest inclination to resolve? The interviewers ask Friston something sort of similar, referring to some experiments where people are happiest not when given easy things with no uncertainty, nor confusing things with unresolvable uncertainty, but puzzles ��� things that seem confusing at first, but actually have a lot of hidden order within them. They ask Friston whether he might want to switch teams to support a u-shaped theory where people like being in the middle between too little uncertainty or too much uncertainty. Friston���does not want to switch teams.

I do not think that ���different laws may apply at different levels���. I see a singular and simple explanation for all the apparent dialectics above: they are all explained by minimization of expected free energy, expected surprise or uncertainty. I feel slightly puritanical when deflating some of the (magical) thinking about inverted U curves and ���sweet spots���. However, things are just simpler than that: there is only one sweet spot; namely, the free energy minimum at the bottom of a U-shaped free energy function [���]

This means that any opportunity to resolve uncertainty itself now becomes attractive (literally, in the mathematical sense of a random dynamical attractor) (Friston, 2013). In short, as nicely articulated by (Schmidhuber, 2010), the opportunity to answer ���what would happen if I did that��� is one of the most important resolvers of uncertainty. Formally, the resolution of uncertainty (aka intrinsic motivation, intrinsic value, epistemic value, the value of information, Bayesian surprise, etc. (Friston et al., 2017)) corresponds to salience. Note that in active inference, salience becomes an attribute of an action or policy in relation to the lived world. The mathematical homologue for contingencies (technically, the parameters of a generative model) corresponds to novelty. In other words, if there is an action that can reduce uncertainty about the consequences of a particular behavior, it is more likely to be expressed.
Given these imperatives, then the two ends of the inverted U become two extrema on different dimensions. In a world full of novelty and opportunity, we know immediately there is an opportunity to resolve reducible uncertainty and will immediately embark on joyful exploration ��� joyful because it reduces uncertainty or expected free energy (Joffily & Coricelli, 2013). Conversely, in a completely unpredictable world (i.e., a world with no precise sensory evidence, such as a dark room) there is no opportunity and all uncertainty is irreducible ��� a joyless world. Boredom is simply the product of explorative behavior; emptying a world of its epistemic value ��� a barren world in which all epistemic affordance has been exhausted through information seeking, free energy minimizing action.

Note that I slipped in the word ���joyful��� above. This brings something interesting to the table; namely, the affective valence of shifts in uncertainty ��� and how they are evaluated by our brains.
1 / 1
ChatGPT
You've touched on a complex and multi-faceted topic that involves the intersection of neuroscience, psychology, philosophy, and the predictive processing framework. The free energy principle (FEP), as advanced by Karl Friston, indeed proposes a unifying explanation for action, perception, and learning in terms of minimizing a certain kind of prediction error.
The idea that all drives and desires could be reducible to a single motivating factor like dopamine release or uncertainty reduction is controversial and still a subject of much debate and research.
Dopamine as a Common Currency
: While it's tempting to frame dopamine as a common currency for all motivations, this is an oversimplification. Dopamine is implicated in reward and motivation, but it is not the sole driver. Human motivation is influenced by various biological, psychological, and environmental factors.
Free Energy and Uncertainty Minimization
: The attempt to explain all behavior as minimizing uncertainty or free energy is intriguing, and there are indeed many behaviors that seem to align with this theory. But there are also counterexamples and complexities that aren't fully accounted for, as you've pointed out.
Curiosity and Other Drives
: The connection between curiosity and other drives (e.g., sex) can be thought of in terms of novelty seeking and exploration, which is consistent with some aspects of the FEP. But reducing all these complex drives to a single principle might be too reductive.
U-Shaped Theory and Inverted U
: Friston���s rejection of different levels and the advocacy for a singular explanation is consistent with his theoretical stance. The idea that there's only one "sweet spot" represents a firm belief in the universality of the FEP, but this is still debated in the scientific community.
Emotion and Valence
: The notion that uncertainty reduction can be "joyful" brings in an affective aspect that broadens the discussion beyond mere cognitive processing. Emotions play a significant role in decision-making and behavior, and integrating them into the FEP might provide a more holistic perspective.
In conclusion, while the idea of a singular motivation is appealing for its simplicity and elegance, human behavior is multi-dimensional and influenced by a wide range of factors. The FEP and other such theories provide valuable insights, but they may not fully capture the complexity of human motivation and action. Further research, interdisciplinary collaboration, and the development of more nuanced models are likely necessary to provide a more comprehensive understanding.
1 / 1
The only thing at all I am able to gather from this paragraph ��� besides the fact that apparently Karl Friston cites himself in conversation ��� is the Schmidhuber reference, which is actually really helpful. Schmidhuber is the guy behind eg the Formal Theory Of Fun & Creativity Explains Science, Art, Music, Humor, in which all of these are some form of taking a seemingly complex domain (in the mathematical sense of complexity) and reducing it to something simple (discovering a hidden order that makes it more compressible). I think Friston might be trying to hint that free energy minimization works in a Schmidhuberian sense where it applies to learning things that suddenly make large parts of our experience more comprehensible at once, rather than just ���Here are some numbers: 1, 5, 7, 21 ��� now you have less uncertainty over what numbers I was about to tell you, isn���t that great?���

I agree this is one of life���s great joys, though maybe me and Karl Friston are not a 100% typical subset of humanity here. Also, I have trouble figuring out how to conceptualize other human drives like sex as this same kind complexity-reduction joy.

One more concern here ��� a lot of the things I read about this equivocate between ���model accuracy maximization��� and ���surprise minimization���. These end really differently. Model accuracy maximization sounds like curiosity ��� you go out and explore as much of the world as possible to get a model that precisely matches reality. Surprise minimization sounds like locking yourself in a dark room with no stimuli, then predicting that you will be in a dark room with no stimuli, and never being surprised when your prediction turns out to be right. I understand Friston has written about the so-called ���dark room problem���, but I haven���t had a chance to look into it as much as I should, and I can���t find anything that takes one or the other horn of the equivocation and says ���definitely this one���.
1 / 1
ChatGPT
The discussion you've presented delves into a very intriguing but complex aspect of cognitive neuroscience and philosophy. It seems to revolve around Karl Friston's free energy principle and how it connects with the concept of uncertainty minimization and various human drives.
Free Energy Principle
: Friston's theory suggests that the brain works to minimize surprise or uncertainty about future sensory input. It actively predicts what will happen next and then acts to minimize the discrepancy between those predictions and actual sensory input. This minimization of "free energy" has been proposed as a unifying principle for brain function, connecting perception, action, and learning.
Uncertainty Minimization
: One interpretation of the free energy principle is that the brain is continually working to reduce uncertainty by updating its model of the world. This can be seen in activities that involve learning and exploration but is challenging to reconcile with other drives and desires.
Complexity-Reduction Joy
: The mention of Schmidhuber's formal theory of fun is an attempt to reconcile these ideas with our experience of joy, creativity, and the appeal of discovery. By reducing complexity or discovering hidden patterns, we find pleasure and fulfillment. This also connects to the idea that the brain's pursuit of complexity reduction might align with many of our intrinsic drives.
Dark Room Problem
: The dark room problem arises as a challenge to the free energy principle. If the only goal of the brain was to minimize surprise, one could argue that it would lead to a static, non-exploratory existence, as the least surprising thing would be to never change your environment or stimuli. However, Friston argues that true minimization involves both reducing uncertainty about the environment and acting on it in a way that fulfills predictions.
Sex and Other Drives
: Aligning these principles with human drives like sex, hunger, or ambition remains complex. Some have argued that they can be seen as different forms of uncertainty reduction or complexity simplification, but this view might oversimplify the richness and diversity of human motivation.
Equivocation between Model Accuracy and Surprise Minimization
: This speaks to a tension in the free energy principle itself. Maximizing model accuracy would drive us to explore and learn, whereas mere surprise minimization might lead to stasis. The balance between these forces and how they contribute to a unified theory of brain function is still a topic of debate and research.
In summary, what you've presented is an exploration of a multifaceted and nuanced theory that seeks to provide a unifying explanation for diverse brain functions. The application of these principles to all aspects of human motivation and experience is still under investigation, and there may be more complexities to uncover.
1 / 1
Fourth, okay, all of this is pretty neat, but how does it explain all biological systems? How does it explain the origin of life from the primordial soup? And when do we get to the real-world version of psychohistory? In his Alius interview, Friston writes:

I first came up with a prototypical free energy principle when I was eight years old, in what I have previously called a ���Gerald Durrell��� moment (Friston, 2012). I was in the garden, during a gloriously hot 1960s British summer, preoccupied with the antics of some woodlice who were frantically scurrying around trying to find some shade. After half an hour of observation and innocent (childlike) contemplation, I realized their ���scurrying��� had no purpose or intent: they were simply moving faster in the sun ��� and slower in the shade. The simplicity of this explanation ��� for what one could artfully call biotic self-organization ��� appealed to me then and appeals to me now. It is exactly the same principle that underwrites the ensemble density dynamics of the free energy principle ��� and all its corollaries.

How do the wood lice have anything to do with any of the rest of this?

As best I can understand (and I���m drawing from here and here again), this is an ultimate meaning of ���free energy��� which is sort of like a formalization of homeostasis. It goes like this: consider a probability distribution of all the states an organism can be in. For example, your body can be at (90 degrees F, heart rate 10), (90 degrees F, heart rate 70), (98 degrees F, heart rate 10), (98 degrees F, heart rate 70), or any of a trillion other different combinations of possible parameters. But in fact, living systems successfully restrict themselves to tiny fractions of this space ��� if you go too far away from (98 degrees F, heart rate 70), you die. So you have two probability distributions ��� the maximum-entropy one where you could have any combination of heart rate and body temperature, and the one your body is aiming for with a life-compatible combination of heart rate and body temperature. Whenever you have a system trying to convert one probability distribution into another probability distribution, you can think of it as doing Bayesian work and following free energy principles. So free energy seems to be something like just a formal explanation of how certain systems display goal-directed behavior, without having to bring in an anthropomorphic or teleological concept of ���goal-directedness���.

Friston mentions many times that free energy is ���almost tautological���, and one of the neuroscientists I talked to who claimed to half-understand it said it should be viewed more as an elegant way of looking at things than as a scientific theory per se. From the Alius interview:

The free energy principle stands in stark distinction to things like predictive coding and the Bayesian brain hypothesis. This is because the free energy principle is what it is ��� a principle. Like Hamilton���s Principle of Stationary Action, it cannot be falsified. It cannot be disproven. In fact, there���s not much you can do with it, unless you ask whether measurable systems conform to the principle.

So we haven���t got a real-life version of Asimov���s psychohistory, is what you���re saying?
1 / 1
ChatGPT
Indeed, Karl Friston's free energy principle (FEP) is an ambitious attempt to unify biological systems and behaviors. Here's how it connects to the elements you mentioned:
Woodlice Example
: Friston's childhood observation of woodlice demonstrates an elementary form of the FEP. In this scenario, the woodlice's movement to find shade represents a biological system's natural tendency to minimize surprise or free energy. By moving faster in the sun and slower in the shade, the woodlice are instinctively seeking a more stable and predictable state that conserves energy. This principle extends to other biological systems that seek equilibrium and minimizes unpredictability.
Free Energy as Homeostasis
: The FEP extends the idea of homeostasis by offering a formal mathematical description of how biological systems self-organize. Homeostasis is the process by which organisms maintain internal stability. The FEP quantifies this process, describing how organisms constrain themselves to specific, life-compatible states and minimize deviations from these states.
Origin of Life
: While the FEP might explain the behavior of living systems, it does not necessarily explain the origin of life. The transition from non-living to living matter involves complex chemical processes that led to self-replicating molecules and cellular structures. The FEP might be used to describe how life, once originated, maintains its structure and function, but it does not directly address the question of how life began.
Real-World Psychohistory
: Psychohistory, from Isaac Asimov's "Foundation" series, is a fictional science that predicts the future of large populations. The FEP doesn't claim to predict future events or offer a universal theory for all social and human phenomena. While it provides a fundamental principle that seems to guide biological systems, it is not a deterministic or predictive model for all aspects of human behavior.
Friston's View of the FEP as a Principle
: Friston often describes the FEP as an organizing principle rather than a falsifiable scientific theory. It offers a new way of understanding how biological systems work, emphasizing self-organization and equilibrium. This philosophical nature can make it more difficult to test or disprove, leaving some to view it more as an insightful perspective than a definitive explanation.
In summary, the free energy principle offers an elegant, unifying lens through which to view biological systems and their inherent tendency towards stability and predictability. However, it does not provide a comprehensive theory for all phenomena, such as the origin of life or the prediction of human history, as described in Asimov's psychohistory. It's a nuanced and often debated concept that invites continued exploration and understanding.
1 / 1
But also:

The Bayesian brain hypothesis is a corollary of the free energy principle and is realized through processes like predictive coding or abductive inference under prior beliefs. However, the Bayesian brain is not the free energy principle, because both the Bayesian brain hypothesis and predictive coding are incomplete theories of how we infer states of affairs.

This missing bit is the enactive compass of the free energy principle. In other words, the free energy principle is not just about making the best (Bayesian) sense of sensory impressions of what���s ���out there���. It tries to understand how we sample the world and author our own sensations. Again, we come back to the woodlice and their scurrying ��� and an attempt to understand the imperatives behind this apparently purposeful sampling of the world. It is this enactive, embodied, extended, embedded, and encultured aspect that is lacking from the Bayesian brain and predictive coding theories; precisely because they do not consider entropy reduction [���]

In short, the free energy principle fully endorses the Bayesian brain hypothesis ��� but that���s not the story. The only way you can change ���the shape of things��� ��� i.e., bound entropy production ��� is to act on the world. This is what distinguishes the free energy principle from predictive processing. In fact, we have now taken to referring to the free energy principle as ���active inference���, which seems closer to the mark and slightly less pretentious for non-mathematicians.

So maybe the free energy principle is the unification of predictive coding of internal models, with the ���action in the world is just another form of prediction��� thesis mentioned above? I guess I thought that was part of the standard predictive coding story, but maybe I���m wrong?
1 / 1
ChatGPT
Yes, your understanding is on the right track. The Free Energy Principle (FEP) and the Bayesian brain hypothesis are indeed related, but they aren't the same thing. Let's clarify these concepts:
Bayesian Brain Hypothesis
: This theory suggests that the brain operates as a Bayesian probability machine, constantly updating beliefs and predictions about the world based on sensory input. It aims to minimize the error or "surprise" between predictions and actual observations.
Predictive Coding
: This is a specific implementation of the Bayesian brain hypothesis. The brain builds hierarchical models that predict sensory input and then updates these models based on the difference between predictions and actual observations.
Free Energy Principle (FEP)
: FEP is a broader framework that includes the Bayesian brain hypothesis but adds an essential component, the active inference or the enactive compass, as Friston describes it. It's not only about passive perception and internal model updating; it also incorporates how organisms actively sample and engage with the world to minimize free energy. The "action in the world" is part of the process of minimizing surprise, or in other words, reducing the uncertainty or entropy in the system.
The woodlice example is again illustrative here. The woodlice aren't merely reacting to the sunlight; they are actively engaging with their environment (scurrying faster in the sun, slower in the shade) to maintain a state that minimizes surprise and conserves energy.
FEP extends beyond simple prediction and perception by integrating action and the organism's continuous interaction with its environment. In this sense, FEP offers a more comprehensive view of how organisms, including humans, function, combining both perception (Bayesian updating) and action (active inference).
So, your insight that FEP might be a unification of predictive coding with the notion that "action in the world is just another form of prediction" is quite accurate. It goes beyond traditional predictive coding by considering how organisms also actively shape their sensory inputs through their actions, thus offering a more complete understanding of behavior and cognition.
1 / 1
This is still the article by Scott Alexander
1 / 1
ChatGPT
Ah, I see! It seems like the content you provided is from an article by Scott Alexander, a well-known writer who has written extensively on topics like this. My response aimed to clarify the concepts presented without realizing they were part of Alexander's writing. If there's something specific about his perspective or interpretation that you'd like me to address or if you have any questions about what he's saying, please let me know!
1 / 1
Overall, the best I can do here is this: the free energy principle seems like an attempt to unify perception, cognition, homeostasis, and action.

���Free energy��� is a mathematical concept that represents the failure of some things to match other things they���re supposed to be predicting.

The brain tries to minimize its free energy with respect to the world, ie minimize the difference between its models and reality. Sometimes it does that by updating its models of the world. Other times it does that by changing the world to better match its models.

Perception and cognition are both attempts to create accurate models that match the world, thus minimizing free energy.

Homeostasis and action are both attempts to make reality match mental models. Action tries to get the organism���s external state to match a mental model. Homeostasis tries to get the organism���s internal state to match a mental model. Since even bacteria are doing something homeostasis-like, all life shares the principle of being free energy minimizers.

So life isn���t doing four things ��� perceiving, thinking, acting, and maintaining homeostasis. It���s really just doing one thing ��� minimizing free energy ��� in four different ways ��� with the particular way it implements this in any given situation depending on which free energy minimization opportunities are most convenient. Or something.

This might be useful in some way? Or it might just be a cool philosophical way of looking at the world? Or maybe something in between? Or maybe a meaningless way of looking at the world? Or something? Somebody please help?

Discussion question for machine ethics researchers ��� if the free energy principle were right, would it disprove the orthogonality thesis? Might it be impossible to design a working brain with any goal besides free energy reduction? Would anything ��� even a paperclip maximizer ��� have to start by minimizing uncertainty, and then add paperclip maximization in later as a hack? Would it change anything if it did?

THIS ENTRY WAS POSTED IN UNCATEGORIZED AND TAGGED LW, PSYCHIATRY, PSYCHOLOGY, RATIONALITY. BOOKMARK THE PERMALINK OR LINK WITHOUT COMMENTS.
��� Open Thread 96.5Open Thread 96.75 ���
246 RESPONSES TO GOD HELP US, LET���S TRY TO UNDERSTAND FRISTON ON FREE ENERGYReverse order
Forward Synthesis says:
March 4, 2018 at 10:17 pm
���uncertainty about what the middle letter of the Bible is���, a question which almost no one feels the slightest inclination to resolve?

Well, until now, anyway. Thanks Scott. ����

In a world full of novelty and opportunity, we know immediately there is an opportunity to resolve reducible uncertainty and will immediately embark on joyful exploration ��� joyful because it reduces uncertainty or expected free energy (Joffily & Coricelli, 2013). Conversely, in a completely unpredictable world (i.e., a world with no precise sensory evidence, such as a dark room) there is no opportunity and all uncertainty is irreducible ��� a joyless world. Boredom is simply the product of explorative behavior; emptying a world of its epistemic value ��� a barren world in which all epistemic affordance has been exhausted through information seeking, free energy minimizing action.

So��� the answer to the dark room problem is that the brain doesn���t desire the state of minimized uncertainty, but desires the process of minimized uncertainty, so it seeks out uncertainty to minimize, and that is what curiosity is? Am I understanding this correctly?
1 / 1
ChatGPT
Yes, your summary seems to capture the essence of the free energy principle as it has been described in the article by Scott Alexander. The free energy principle is an attempt to unify several aspects of living systems under a single mathematical framework. It posits that organisms minimize free energy, which represents the difference between their models and reality, through perception, cognition, action, and homeostasis.
Your understanding of the dark room problem is also correct. The free energy principle doesn't advocate a state of minimized uncertainty but the process of minimizing uncertainty. This is why an organism would not just seek a dark room (complete predictability), but would rather engage with its environment to minimize uncertainty through exploration, a process that can be seen as an expression of curiosity.
The discussion question you raise about machine ethics and the orthogonality thesis is interesting and complex. If the free energy principle were the underlying governing factor of all cognitive systems, it could imply that designing a system with goals entirely orthogonal to free energy minimization might be challenging or even impossible. But that's a deep philosophical and theoretical issue that may require further research and debate.
1 / 1
I discussed this before, I said clearly we are not only minimizing free energy or else the alphabet would only have 8 letters, or two.
1 / 1
ChatGPT
I apologize for any confusion, and I understand the concern you've raised. The free energy principle doesn't suggest that systems will minimize complexity to the point of oversimplification, like reducing the alphabet to only a few letters. Instead, it posits that organisms act to minimize the discrepancy between their internal models and external reality, balancing the need to understand their environment with the need to act within it.
This involves a complex interplay between prediction, learning, action, and exploration, all of which must be balanced to enable a system to function effectively. So while free energy minimization is a guiding principle, it doesn't lead to an oversimplified or reduced version of reality. Rather, it's about the ongoing process of engaging with the environment in a way that balances predictability and adaptability.
Your point emphasizes the nuance and complexity inherent in this concept and highlights that it's not as simple as relentlessly minimizing free energy without regard to other considerations. Thank you for clarifying your stance.
1 / 1
They minimize it until they stop minimizing it.
1 / 1
ChatGPT
Exactly, organisms minimize free energy until they reach an equilibrium where the cost of further minimization exceeds the benefits. It's a dynamic and ongoing process that reflects the organism's interaction with its environment, adaptation, learning, and other complex factors. This is why free energy minimization doesn't lead to oversimplification or reductionism, but rather a nuanced engagement with the world that allows for functional and effective behavior. It's a principle that guides understanding but doesn't offer a simple or deterministic explanation for all biological or cognitive phenomena.
1 / 1
Am I autistic? 
An 
An intellectual 
autobiographyintellectual 
autobiography 
Karl Friston Karl Friston 
k.friston@ucl.ac.ukk.friston@ucl.ac.uk 
Wellcome Centre for Human Neuroimaging 
University College London, UK 
Citation: Friston, K. (2018). Am I autistic? An intellectual 
autobiography. ALIUS Bulletin, 2, 45-52. 
What follows are some personal notes that were inspired by answering the first 
question for ALIUS Bulletin. In looking back at my life, I can see some distinctly 
autistic traits in my childhood���and indeed current ways of engaging with the 
world. For example, I religiously avoid mobile phones and do not Skype. In fact, I 
find any disruption to my weekly routine rather nerve wracking. Unhappily, this 
means travelling to international conferences can be unsettling���where I spend most 
of the time avoiding other human beings; especially in the morning. Curiously, I feel 
most at home with myself when lecturing ���onstage������close to lots of people who are, 
at the same time, comfortably distant. 
When reflecting on my early (academic) experiences, similar themes come to mind. 
I was obsessed with the natural world and would commit to recording it in a 
somewhat obsessional fashion: see, for example, the illustrations of aquatic flora and 
fauna that decorate these notes. I must have spent hours on these for a school 
project���at the expense of actually learning what I should have been learning. 
I am not pretending that I was autistic; however, I remember being assessed by 
educational psychologists on several occasions. The first (at age 5) was a mildly 
traumatic experience that was meant to resolve a confusing relationship with my 
teacher. This educational intervention led to my withdrawal from the state 
education system and I was sent to a private school run by Catholic nuns (where I 
flourished). The second was more amusing: I remember being asked whether I 
thought the puppets in Thunderbirds ever got hungry. I recall thinking at that time 
���what on earth does a psychologist expect me to say?��� After several levels of recursive 
sophistication, I opted for ���yes���. The third encounter with a psychologist followed a 
science project when I was 10 years of age. I had designed a self-righting robot��� 
involving mercury levels and feedback actuators that would enable a little robot 
table to traverse uneven surfaces (a useful endeavour that set me in good stead to 
understand the notion of feedback, optimal control, and in later life, cybernetics). 
The psychologist wanted to know how I came up with the idea.
1 / 1
ChatGPT
It looks like you've shared a passage from Karl Friston's intellectual autobiography where he reflects on his own life and certain traits that might be associated with autism. He is open about his idiosyncrasies and quirks but also makes it clear that he is not claiming to be autistic.
The excerpt you've shared paints a fascinating picture of a scientific mind, committed to understanding the world in intricate detail. The way Friston talks about his obsession with the natural world, his discomfort with disruption, and his unique way of engaging with the world gives us a glimpse into the mind of a person who has greatly contributed to the field of neuroscience. His experiences, particularly the self-righting robot project, highlight his early interest in feedback, control, and cybernetics���themes that are central to his later work on the free energy principle.
Friston's reflections here do not offer a definitive answer to the question of whether he's autistic. They provide insight into his personal experiences and ways of thinking that some might find reminiscent of autistic traits, but without a formal diagnosis or a more thorough exploration, it would be inappropriate to label him as such.
1 / 1
was more interested in me than robots per se. Shortly afterwards, something 
happened, which I want to write down before I forget it: on walking to primary 
school every day I had to pass the grammar school students waiting for the school 
bus. I recall thinking: ���one day, I want to be in that queue��� and then, more 
poignantly, ���I must remind myself about this moment when I am grown���so I do 
not forget the insight, ambition and sophistication of childhood���. 
Throughout my education, my primary sources of self-esteem were largely drilling 
down into an area or problem in a somewhat perfectionist fashion and deriving a 
delightful sense of comfort in isolating the problem domain���that felt like my little 
world. My teachers seemed to know this and used to play games with me. One of 
these games (of which I was most proud) was to see if I could derive answers to A- 
level questions in mathematics���that were more parsimonious than the worked 
answers supplied by the examination boards. I recall being obsessed by mathematical 
issues and enormously pleased by their resolution. One of my favorite achievements 
was being able to derive Schr��dinger wave equation from scratch. My reward was to 
take the physics class while my physics teacher (Ged Proctor) amused himself in the 
stockroom (I don���t know how, because his primary passion was Morris dancing). 
I do not think I was really autistic; however, any unusual traits may have been 
compounded by my early schooling: my father was a civil (bridge) engineer during 
an active period of motorway construction in the United Kingdom. This meant that 
we had to move around the country. By the age of 10, I had attended six schools, and 
had come to realize that the only constants in my life were my family���and the things 
inside my head. 
This background sets the scene for a series of vignettes that, in retrospect, trace a 
clear path to the current formulations of the free energy principle. The woodlouse 
example (see my interview in this issue of ALIUS Bulletin) was formative in terms of 
subsequent exposure to evolutionary thinking. The apparent emergence of purpose 
from purposeless but ���shaped��� dynamics made it easy for me to understand natural 
selection; however, there was a more subtle aspect to the insight that speaks to 
second order selection. In other words, irrespective of the implicit gradient descent 
in any optimization process (e.g., natural selection) a simpler mechanism can be in 
play ���without any gradient destroying dynamics. This is simply the fast evacuation 
of volatile, high-energy regimes of phase-space. In evolutionary thinking, this has 
often been exemplified in terms of selection for selectability (e.g., the increased 
mutation rate of Drosophila unexposed to a volatile temperature environment). 
Mathematically, this underwrites generic optimization schemes such as stochastic 
dynamic optimization. In later life, I often thought about trying to develop this idea 
in terms of meta-selection���and even ended up using it in the context of active inference; in the form of autovitiation (the destruction of unlikely fixed points by 
simply moving faster in regimes of high surprise or low probability density). 
The translation of this sort of thinking into physics started, for me, in my late teens, 
when I became preoccupied with holistic explanations based on minimal 
assumptions. I recall spending hours thinking furiously in my bedroom��� 
overlooking cherry blossoms in the front garden: I was convinced that there should 
be a singular explanation for the shape of things, just starting from the premise that 
something existed. My best conceptualization of this was some abstract point in an 
abstract space that, in later life, transpired to be a point attractor in a phase-space. 
This style of thinking made it easy to understand dynamical systems theory in terms 
of attracting sets���and the distinction between different forms of attracting 
manifolds. 
The obsession to put things together came to a practical head in the summer 
holidays after a year of Medical Science Tripos studies at Cambridge University. I 
had, with deliberate intent, chosen psychology and physics to pursue for the 
subsequent years of my undergraduate study. This meant that I had to catch up with 
the other physics students. I spent an absorbing holiday���to the exclusion of 
everything else���trying to get all of physics onto one page. I failed���but was able to 
condense quantum theory into one page (see Figure on the next page). I think that 
this was symptomatic of an obsessional drive to integration and simplification. 
Although I forgot nearly everything I had learned during this period, it meant I was 
not intimidated when taking up these themes in later life���largely by foraging in 
Wikipedia. 
Another memorable episode of intense thinking occurred when on a Christmas 
break from University, thinking earnestly in the early hours over a nourishing coal 
fire in the family living room. The conclusion of this contemplation was that all 
interesting things have to occupy a compact domain of phase-space and must 
therefore possess an attracting set. The key insight here was that the only invariance 
that lent ���shape to things��� entailed correlations. I nurtured this idea for several years 
(during which I qualified as a doctor and started psychiatric training). I found a 
peaceful distraction from my job in musing on these issues, while working in a 
therapeutic community of chronic schizophrenics in an old-style Victorian asylum.
1 / 1
ChatGPT
The passage you've shared continues to explore Karl Friston's intellectual journey, touching upon his academic experiences, obsessions with mathematical issues, a fascination with natural world dynamics, and the drive for integration and simplification.
Friston reflects on his distinct traits, which he again emphasizes might resemble autism but falls short of calling himself autistic. His intellectual curiosity seems to be characterized by a drive to delve deeply into problems, seeking parsimonious and unified explanations. This manifests in many areas, from his fascination with evolutionary thinking to his efforts to condense all of physics onto one page.
The text highlights Friston's relentless pursuit of understanding, and his willingness to apply his ideas across domains. It also presents a glimpse into his life as a student and a doctor, revealing how these experiences shaped his thoughts and his influential work on the free energy principle.
Friston's reflections do not definitively classify him as autistic but rather as a person with an exceptional drive for understanding the world. His quest for integrating knowledge into a singular explanation has left an indelible mark on neuroscience and other fields, reflecting a mind unafraid of complexity and always seeking underlying simplicity.
1 / 1
I had, at this point, concluded that statistical invariance (i.e., correlations) had to be 
transcribed into the physics of our brains���in order for them to possess an attracting 
set. I found this idea so compelling that I spent an entire Saturday at Blackwell���s 
bookshop in Oxford (where I was training), scouring medical and mathematics 
books for related ideas (this was before the World Wide Web and Wikipedia). After 
about three hours searching, I found references to the writings of Hebb and surprised myself with an ambivalent reaction: intense pleasure that the idea was 
valid and intense displeasure I had wasted several years on something that was 
already known. I remember trying to work out how old Hebb was���and whether I 
could have ever met him. From that point on, I waited patiently until I could get 
into research proper, at around the age of 28. The next part of the story, from my 
perspective, can be found in (Friston, 2012). 
ReferencesReferences 
Friston, K. (2012). The history of the future of the Bayesian brain. Neuroimage, 62(2), 
1230-1233. doi: 10.1016/j.neuroimage.2011.10.004
1 / 1
ChatGPT
The passage you've shared concludes Karl Friston's reflections on his intellectual journey and how he arrived at some of his fundamental ideas. He speaks of a realization about the necessity of statistical invariance (correlations) being transcribed into the physics of our brains. This idea led him to search for related thoughts in existing literature, leading him to discover Hebb's writings.
Friston's reaction to finding Hebb's work showcases a duality in his feelings: pleasure in finding that his idea was valid and also disappointment that it was already known. His narrative underscores his intellectual curiosity, dedication, and the profound influence that Hebb's ideas had on him.
The ending hints at his transition into full-time research at around age 28 and references a publication for those interested in delving further into his work. Overall, Friston's account provides a valuable insight into the mind of a groundbreaking scientist, reflecting his unique way of thinking and his commitment to understanding the world.
1 / 1
What does he mean by The conclusion of this contemplation was that all 
interesting things have to occupy a compact domain of phase-space and must 
therefore possess an attracting set. ?
1 / 1
ChatGPT
In the context of Karl Friston's reflections, when he talks about "all interesting things" having to occupy a "compact domain of phase-space" and possessing an "attracting set," he's touching on concepts from the world of dynamical systems and mathematical modeling.
Phase-Space
: In mathematics and physics, phase-space is a mathematical space where all possible states of a system are represented. Each point in this space corresponds to a possible state of the system. A "compact domain" within phase-space means a limited, well-defined region that represents a subset of those states.
Attracting Set
: An attracting set is a concept in the study of dynamical systems. It refers to a set of states that the system will tend towards over time. When a system starts in a state near an attracting set, it will evolve towards that set as time progresses.
So, when Friston refers to "interesting things" possessing these qualities, he's likely talking about complex systems (including perhaps cognitive or biological systems) that exhibit certain regularities or patterns. These systems tend to evolve towards specific behaviors or states, and they can be described using the mathematical language of dynamical systems.
In a broader sense, this thought might reflect Friston's fascination with finding unifying principles or fundamental laws that can describe complex phenomena. It's an expression of his drive towards simplification, integration, and understanding the underlying structure of the world around him.
1 / 1
Connections to Prigogine's ideas concerning dissipative structures.
1 / 1
ChatGPT
Karl Friston's ideas about phase-space and attracting sets indeed resonate with Ilya Prigogine's theories about dissipative structures.
Dissipative Structures
: Prigogine's concept of dissipative structures refers to ordered and stable structures that form in open systems far from equilibrium. These systems exchange energy and matter with their environment and can develop complex, stable patterns. These patterns dissipate energy, and they are sustained by the continuous flow of energy through the system.
Attracting Sets and Phase-Space
: The idea of an attracting set in phase-space can be related to Prigogine's dissipative structures in the sense that both describe systems tending toward certain stable states or patterns over time. The attracting set represents the regions in phase-space where the system's behavior stabilizes or falls into a pattern, akin to the stable, ordered patterns seen in dissipative structures.
Non-Equilibrium Thermodynamics
: Both Friston's and Prigogine's ideas are grounded in non-equilibrium thermodynamics. While traditional thermodynamics often deals with closed systems in equilibrium, Prigogine's work emphasizes open systems far from equilibrium. Friston's work, especially related to the brain and free energy principle, also involves systems that are constantly interacting with their surroundings and never in static equilibrium.
Understanding Complexity
: Both scholars aim to understand complexity in natural phenomena. While Friston seeks a unifying principle to explain brain function and other complex systems, Prigogine's work on dissipative structures was a pioneering attempt to explain how complex and ordered structures can emerge from chaos in physical and chemical systems.
In summary, the connection between Friston's and Prigogine's ideas lies in their shared interest in complex, dynamical systems, non-equilibrium states, and the emergent patterns that arise from them. Both approaches seek to explain how systems evolve towards certain structures or patterns over time, using mathematical concepts like phase-space and attractors to describe this behavior.
1 / 1
Experimental validation of the free-energy 
principle with in vitro neural networks 
Takuya Isomura 
1 , Kiyoshi Kotani2, Yasuhiko Jimbo3& Karl J. Friston 
4,5 
Empirical applications of the free-energy principle are not straightforward 
because they entail a commitment to a particular process theory, especially at 
the cellular and synaptic levels. Using a recently established reverse engi- 
neering technique, we conf i rm the quantitative predictions of the free-energy 
principle using in vitro networks of rat cortical neurons that perform causal 
inference. Upon receiving electrical stimuli���generated by mixing two hidden 
sources���neurons self-organised to selectively encode the two sources. Phar- 
macological up- and downregulation of network excitability disrupted the 
ensuing inference, consistent with changes in prior beliefs about hidden 
sources. As predicted, changes in effective synaptic connectivity reduced 
variational free energy, where the connection strengths encoded parameters 
of the generative model. In short, we show that variational free energy mini- 
misationcanquantitativelypredicttheself-organisationofneuronalnetworks, 
in terms of their responses and plasticity. These results demonstrate the 
applicability of the free-energy principle to in vitro neural networks and 
establish its predictive validity in this setting. 
Elucidatingtheself-organisingprinciplesofbiologicalneuralnetworks 
is one of the most challenging questions in the natural sciences, and 
should prove useful for characterising impaired brain function and 
developing biologically inspired (i.e., biomimetic) artif i cial intelli- 
gence. According to the free-energy principle, perception, learning, 
and action���of all biological organisms���can be described as minimis- 
ing variational free energy, as a tractable proxy for minimising the 
surprise (i.e., improbability) of sensory inputs1,2. By doing so, neuronal 
(and neural) networks are considered to perform variational Bayesian 
inference3. (Table 1 provides a glossary of technical terms used com- 
monlyinthefree-energyprincipleandactiveinferenceliterature).This 
inference follows from treating neuronal dynamics as a gradient l ow 
on variational free energy, which can be read as a form of belief 
updating about the network���s external milieu. The free energy in 
question is a function of a generative model that expresses a hypoth- 
esis about how sensory data are generated from latent or hidden 
states. However, to apply the free-energy principle at the cellular and 
synaptic levels, it is necessary to identify the requisite generative 
model thatexplains neuronaldynamics (i.e.,inference) andchangesin 
synaptic eff i cacy (i.e., learning).
1 / 1
ChatGPT
The abstract you've shared describes an experimental validation of Karl Friston's free-energy principle using in vitro networks of rat cortical neurons. Let's break down some key points:
Free-Energy Principle
: Friston's free-energy principle posits that biological systems minimize a quantity called free energy, which is a measure of surprise or improbability of sensory inputs. Essentially, the brain creates a model of the world and continually updates this model to minimize the discrepancy between predicted and actual sensory data.
Experiment Design
: The experiment uses a reverse-engineering technique to test the predictions of the free-energy principle in a controlled setting. The researchers stimulate in vitro networks of rat cortical neurons and observe how they self-organize to encode hidden sources. The stimuli are generated by mixing two hidden sources, and the neurons must perform causal inference to selectively respond to them.
Findings
: The research found that pharmacological alterations of network excitability, which could be equated to changes in prior beliefs about the hidden sources, led to disruptions in inference. The observed changes in effective synaptic connectivity reduced the variational free energy, in line with the predictions of the free-energy principle. Connection strengths in the network encoded parameters of the generative model.
Significance
: The results validate the applicability of the free-energy principle to in vitro neural networks and demonstrate its predictive validity. This may have implications for understanding brain function and the development of biologically inspired artificial intelligence.
Challenges
: The abstract mentions that applying the free-energy principle at the cellular and synaptic levels is not straightforward. It requires identifying the generative model that explains both neuronal dynamics (inference) and changes in synaptic efficacy (learning).
In summary, the study provides empirical support for the free-energy principle by showing how it can predict the self-organization, response, and plasticity of neuronal networks. This experimental validation may pave the way for further insights into brain function and the design of more sophisticated AI systems inspired by biological principles.
1 / 1
This is similar to how William Powers described the control of perception.
1 / 1
ChatGPT
William Powers' model of control theory, specifically in the context of perceptual control theory (PCT), shares some similarities with Karl Friston's free-energy principle, even though they are distinct frameworks. Here's how they connect:
Minimization Principle
: Both theories describe a system that aims to minimize some form of discrepancy. In Friston's free-energy principle, the goal is to minimize free energy, reflecting the difference between predicted and actual sensory inputs. In Powers' PCT, the goal is to minimize the difference between a perceived state and a reference or desired state.
Hierarchy and Model-Based Approach
: Both approaches conceive the brain (or control systems, in general) as having a hierarchical structure. In PCT, there are different levels of control, each with its reference points and feedback loops. In the free-energy principle, there is a hierarchical generative model that predicts sensory data.
Perception as Active Process
: In both frameworks, perception is not a passive reception of sensory data but an active process. In PCT, the organism continually adjusts its behavior to bring its perceptions in line with desired reference values. In the free-energy approach, perception involves actively updating a generative model to minimize the surprise or improbability of sensory inputs.
Adaptation and Learning
: Both theories emphasize the importance of adaptation and learning. In PCT, learning adjusts the system's parameters to enhance control. In the free-energy principle, learning involves updating the generative model to better predict sensory data.
Application to Behavior and Cognition
: Both theories have been applied to explain various aspects of behavior and cognition, although they may have different emphases and may be suited to different kinds of problems.
While they share these similarities, it is essential to recognize that they are rooted in different traditions and have different mathematical formulations and philosophical underpinnings. Powers' PCT is more directly focused on control systems, feedback, and reference signals, while Friston's free-energy principle is rooted in statistical physics and Bayesian inference. They may offer complementary insights, but they are not identical frameworks.
1 / 1
A list of all of the topics we've discussed.
1 / 1
ChatGPT
Certainly! Here's a summary of the topics we've discussed:
Background and Reflections
: An extensive narrative that seems to be about someone's (possibly Karl Friston's) journey, focusing on childhood memories, educational experiences, obsession with mathematical problems, and early scientific thinking.
The Insight into Compact Domain of Phase-Space
: Questions regarding the specific idea that "all interesting things have to occupy a compact domain of phase-space" and its connection to Prigogine's ideas concerning dissipative structures.
Experimental Validation of the Free-Energy Principle
: Details about the experimental validation of Karl Friston's free-energy principle with in vitro neural networks.
Similarities between William Powers and Free-Energy Principle
: Discussion on the similarities between William Powers' perceptual control theory (PCT) and Karl Friston's free-energy principle.
Each of these topics relates to various aspects of neuroscience, psychology, mathematical modeling, and personal reflections on scientific discovery.
1 / 1
Yeah that we from Karl Friston before that we discussed an article by Scott Alexander
1 / 1
ChatGPT
Yes, you're right! It seems that the extended narrative and subsequent discussions were indeed related to the work of Karl Friston, a prominent neuroscientist known for the free-energy principle. And you also mentioned an article by Scott Alexander. Unfortunately, the details of the article by Scott Alexander were not included in the portions of the conversation that I have access to, so I can't provide specific information on that topic. Feel free to elaborate or ask questions about it if you'd like!
1 / 1
Normally this is the point at which I say ���screw it��� and give up. But almost all the most interesting neuroscience of the past decade involves this guy in one way or another. He���s the most-cited living neuroscientist, invented large parts of modern brain imaging, and received the prestigious Golden Brain Award (which is somehow a real thing). His Am I Autistic ��� An Intellectual Autobiography short essay, written in a weirdly lucid style and describing hijinks like deriving the Schrodinger equation for fun in school, is as consistent with genius as anything I���ve ever read.

As for free energy, it���s been dubbed ���a unified brain theory��� (Friston 2010), a key through which ���nearly every aspect of [brain] anatomy and physiology starts to make sense��� (Friston 2009), ���[the source of] the ability of biological systems to resist a natural tendency to disorder��� (Friston 2012), an explanation of how life ���inevitably and emergently��� arose from the primordial soup (Friston 2013), and ���a real life version of Isaac Asimov���s psychohistory��� (description here of Allen 2018).

I continue to hope some science journalist takes up the mantle of explaining this comprehensively. Until that happens, I���ve been working to gather as many perspectives as I can, to talk to the few neuroscientists who claim to even partially understand what���s going on, and to piece together a partial understanding. I am not at all the right person to do this, and this is not an attempt to get a gears-level understanding ��� just the kind of pop-science-journalism understanding that gives us a slight summary-level idea of what���s going on. My ulterior motive is to get to the point where I can understand Friston���s recent explanation of depression, relevant to my interests as a psychiatrist.
1 / 1
ChatGPT
The passage you provided appears to be an excerpt from someone grappling with the complexities of Karl Friston's work on the free-energy principle. This perspective likely reflects the experience of many who encounter Friston's ideas. They're intricate, deeply mathematical, and interconnected with various aspects of neuroscience, philosophy, and even the nature of life itself.
Understanding Friston's work is no small feat, and the sentiment expressed in your excerpt acknowledges that challenge. His work on the free-energy principle has been heralded by some as a unified theory of brain function, a concept that can potentially explain everything from perceptual processes to the emergence of life itself.
The complexity of these ideas and the wide-ranging applications indeed make Friston's work a subject of intense interest and, at the same time, a challenging puzzle to piece together. It might take collaboration between experts in various fields and talented science communicators to render these ideas accessible to a broader audience.
If you have any specific questions or need clarification on any aspect of Friston's work or related topics, feel free to ask!
1 / 1
I want to know how it compares with Schmidhuber's work
1 / 1
ChatGPT
Karl Friston's free-energy principle and J��rgen Schmidhuber's work on artificial intelligence (AI) and machine learning have different focuses but share some similarities in their approach to understanding complex systems.
Friston's Free-Energy Principle
:
Focus
: The free-energy principle is a theoretical framework in neuroscience that seeks to explain how biological systems maintain themselves in a changing environment.
Concept
: It posits that living organisms minimize the free energy of their sensory states, or in simpler terms, they act to reduce the surprise or unpredictability about their sensory inputs.
Application
: This principle has been applied to understanding perception, learning, action, and even the nature of life itself.
Schmidhuber's Work in AI and Machine Learning
:
Focus
: Schmidhuber has contributed to various areas in AI, particularly in deep learning and reinforcement learning.
Concept
: He has worked on developing algorithms that allow machines to learn from data and improve their performance. He's well-known for his work on neural networks, including Long Short-Term Memory (LSTM) networks.
Application
: His research has been used in various AI applications, from natural language processing to computer vision.
Comparisons and Connections
:
Curiosity and Exploration
: Both Friston and Schmidhuber have expressed ideas about systems that act to reduce uncertainty. Schmidhuber has proposed formal models of curiosity and creativity in which agents actively seek experiences that reduce their uncertainty about the world, a concept that echoes the minimization of free energy in Friston's work.
Complex Systems Understanding
: Both approaches require understanding complex dynamic systems, though in different domains. Friston's work revolves around biological systems, while Schmidhuber's focus is on artificial systems.
Mathematical Foundations
: Both scholars ground their work in mathematical and computational principles, though they apply these foundations to different ends.
In summary, while Friston's free-energy principle and Schmidhuber's work in AI may appear quite distinct, they share some underlying themes around complexity, curiosity, uncertainty reduction, and mathematical modeling. Some interdisciplinary researchers are exploring how these concepts might be bridged, as the intersections between neuroscience and AI continue to grow, but the two bodies of work remain largely separate and focus on different questions.
1 / 1
A summary of the themes and topics of this conversation.
1 / 1
ChatGPT
Certainly! This conversation has touched upon several complex and interconnected themes and topics, primarily revolving around neuroscience, artificial intelligence (AI), and specific theories and individuals. Here's a summary:
Karl Friston and the Free-Energy Principle
: A central theme has been Friston's free-energy principle, which aims to explain how biological systems minimize uncertainty about their sensory inputs.
Connections to Other Ideas
: This led to discussions on the concept of attracting sets, connections to Prigogine's ideas about dissipative structures, and comparisons to William Powers' control theory of perception.
Empirical Validation and Experimental Studies
: We examined an empirical study validating the free-energy principle with in vitro neural networks.
Scott Alexander's Article
: We referenced an article by Scott Alexander that highlights the significance of Karl Friston's work and the difficulty of understanding the free-energy principle. The article expresses hope for more accessible explanations of this complex topic.
Comparison with J��rgen Schmidhuber's Work
: The conversation then shifted to draw parallels and contrasts between Friston's work and Schmidhuber's contributions to AI and machine learning. This comparison touched on themes of curiosity, complexity, and mathematical modeling.
Personal Experiences and Autobiographical Insights
: The conversation also delved into personal stories and emotions related to discoveries, validation, and the pursuit of intellectual endeavors.
Interdisciplinary Connections
: Across these themes, there was an underlying focus on the intersections between neuroscience, AI, mathematical modeling, and philosophy.
The conversation was rich in detail and explored complex ideas in both neuroscience and AI, reflecting on historical context, theoretical foundations, empirical validations, and interdisciplinary connections.
1 / 1
for the brain that suf i ciently explains, as a result of an inference model, how neurons must 
structurally evolve to communicate ef i ciently, and why connections between neurons are not 
randomly formed but are highly self-organized to make learning and memory formation pos- 
sible. With the most minimal assumptions, we show how two physical quantities ��� neuronal 
CHAPTER 1. INTRODUCTION5 
diameter and length ��� are related to the biological functioning of the brain [14,15,17���20]. 
In particular, we show that with only four constraints consisting of action potential power, 
g-ratio, distance-dependent synaptic connectivity, and timescale of action potentials, when 
cast into an entropy maximization framework, one necessarily arrives at a maximum joint 
entropy distribution of neuronal diameter and length from i rst principles. 
The payof f for adopting this mathematical treatment to explain how learning and memory 
are mapped to the structural and topological level of neurons and neuronal networks is that 
many diverse aspects of brain dynamics can be understood in the most elementary forms of 
physical laws ��� entropy. As a result, we shall see how the maximum entropy principle for 
the brain unif i es neuronal diameter and length distributions in a biologically plausible fashion 
to arrive at marginal distributions conforming to the gamma distribution, often reported in 
the literature [21���23]. By testing theory against in vivo and in vitro datasets of biological 
neuronal and regional networks of dif f erent species, we i nd from numerical analysis that the 
theory can suf i ciently infer the biological constraints, which compare favorably well to values 
reported in the literature. Lastly, we shall see how the principle can explain why the Rentian 
scaled small-world architecture, regarded as one of the most biologically and topologically 
ef i cient networks observed in species such as the C. elegans neuronal network must naturally 
occur in the brain due to entropy maximization by performing simple simulation experiments 
using graph theory [24���28]. The principle thus suggests that the brain���s innate ability to 
strategically self-organize its structural and topological properties can be achieved through 
entropy maximization [29]. 
This thesis attempts to show how the use of physical laws, when applied to neuroscience 
through mathematics, can unpack interesting insights on brain dynamics, such that one day 
we can apply these concepts to i nd novel ways to reverse engineer the brain for the engineering 
community.
1 / 1
ChatGPT
The passage you've shared seems to be an introduction or excerpt from a thesis that explores a mathematical and physical framework for understanding the structural and functional organization of the brain. Here's a breakdown of the key concepts:
Efficient Communication in Neurons
: The author aims to explain why connections between neurons are not random but are instead highly self-organized, optimizing communication efficiency.
Physical Quantities and Constraints
: By focusing on two physical quantities (neuronal diameter and length) and four constraints (action potential power, g-ratio, distance-dependent synaptic connectivity, and the timescale of action potentials), the author aims to understand neuronal functioning in terms of physical laws.
Entropy Maximization Framework
: The thesis casts the problem into an entropy maximization framework, resulting in a maximum joint entropy distribution of neuronal diameter and length. This approach is geared towards simplifying the complex dynamics of the brain.
Maximum Entropy Principle for the Brain
: The author shows that the maximum entropy principle can unify various aspects of brain dynamics, aligning with distributions like the gamma distribution found in existing literature.
Comparison with Biological Data
: By testing the theory against both in vivo and in vitro datasets across different species, the author validates the framework.
Rentian Scaled Small-World Architecture
: The thesis also touches on the small-world network architecture observed in biological networks, such as the C. elegans neuronal network, and how this arises from entropy maximization.
Applications in Engineering
: Ultimately, the thesis aims to bridge neuroscience and engineering, proposing that these concepts could lead to novel ways to reverse engineer the brain.
This excerpt outlines a holistic and ambitious attempt to unite various aspects of brain dynamics under a single mathematical framework, grounding it in the most fundamental physical laws. It represents a bold attempt to tackle the complexity of the brain using principles from physics, mathematics, and information theory.
1 / 1
It was from A maximum entropy principle for the brain 
by 
Yoshiki Shoji 
Supervised by Professor Gabriele M. T. D���Eleuterio 
A thesis submitted in conformity with the requirements 
for the degree of Masters of Applied Science 
Institute for Aerospace Studies 
University of Toronto 
�� Copyright 2023 by Yoshiki Shoji 
A maximum entropy principle for the brain 
Yoshiki Shoji 
Masters of Applied Science 
Institute for Aerospace Studies 
University of Toronto 
2023
1 / 1
ChatGPT
Thank you for providing the source details for the excerpt. The thesis, titled "A maximum entropy principle for the brain" by Yoshiki Shoji and supervised by Professor Gabriele M. T. D'Eleuterio, submitted for a Masters of Applied Science at the University of Toronto in 2023, represents an exciting interdisciplinary work. By applying concepts from physics and mathematics, Shoji is attempting to explain the structure and function of the brain using the maximum entropy principle.
The endeavor to bring together neuroscience, physics, and mathematics under one unifying framework is an ambitious undertaking, highlighting the complexity of the brain and the creativity required to understand it. It also showcases the increasing trend in modern scientific research to seek collaboration across disciplines, bridging gaps between fields to arrive at more comprehensive insights and solutions.
Given the unique perspective of this thesis, it may have interesting implications not just for neuroscience, but also for fields like artificial intelligence and robotics, aligning with the author's affiliation with the Institute for Aerospace Studies.
1 / 1
2.1The dynamic brain 
The starting point lies in envisioning how the brain functions with its external and internal 
milieu. By external milieu, we mean any element constituting the individual���s external social 
environment, such as light. In contrast, by internal milieu, we mean any element constituting 
the individual���s internal environment, mainly comprised of organs that function together that 
make up the anatomy.1This concept is best illustrated in Figure 2.1. We immediately see 
that the brain is the sole organ that governs all biological processes necessary to sustain life. 
The brain reacts to its external and internal milieu and produces outputs most suitable to 
the individual���s lifestyle. For example, the outputs can be changes in the individual���s emo- 
tional state or habitual patterns. Ultimately, the brain must constantly use energy supplied 
from food sources transformed into molecules of Adenosine Triphosphate (ATP) used for all 
metabolic processes to achieve homeostasis: Any self-regulating process by which biological 
systems tend to maintain stability while adjusting to conditions that are optimal for survival 
1The internal environment ��� or milieu int�� erieur in French ��� was i rst coined by Walter Bradford Cannon 
[30] in the 19thcentury to describe how mechanisms of interstitial l uid ensure protective stability for the 
tissues and organs of multicellular organisms. 6 
CHAPTER 2. ARCHITECTURE OF THE MIND7 
[31].2 
Figure 2.1: The continuous life cycle of the brain interacting with the internal and external 
milieu from early life events. Pre-birth, the brain is organized through genetic means. After 
birth, the brain is able to regulate chemical and cellular processes to maintain life while 
simultaneously interacting with its environment, or the external milieu. Any interaction that 
elicits mental or physical activity that is favorable to the individuals lifestyle, from cognitive 
functioning that controls mood and stress, intakes energy taken from natural resources that is 
then expended to regulate nutrients to achieve homeostasis. Image from Broskey et al. [32]. 
The biological aspect of homeostasis ��� optimal self-adjusting systems ��� is all around us, 
from the swarming of birds or insects, swinging pendulums, chemical reactions, and even 
the planets that make up the solar system. It is clear that each system, if treated individu- 
ally, must eventually stabilize and maintain its stability to function. For example, starlings 
match the direction and speed of the nearest seven neighbors rather than responding to the 
movements of all nearby birds around them, eventually stabilizing to display actions of mur- 
muration. A swinging pendulum, due to gravity, will stabilize by losing energy from friction 
or elastic deformations and eventually come to rest. Chemical reactions achieve thermody- 
namic stability by using and releasing energy. The positioning and circulation of stars have 
stabilized to make up the solar system throughout evolution to make all life possible today. 
The examples are countless. 
Indeed, we shall soon see that the brain is no dif f erent: It embodies all the mechanisms 
necessary to make sense of the world through learning and memory and create meaning from 
abstract concepts throughout an individual���s lifetime ��� a universal property of intelligent, 
biological systems that is achieved through homeostasis. In subsequent chapters, as much of 
2Historically, the word ���homeostasis��� was i rst coined by Walter Bradford Cannon in 1926, but the concept 
was i rst introduced by French physiologist Claude Bernard in 1849 [30]. Then in 1932, Joseph Barcroft [33], 
a British physiologist, was the i rst to propose that higher brain function required the most stable internal 
environment. Thus, to Barcroft, homeostasis served the brain much like how physical laws, such as gravitation, 
serve to regulate the movement of stars.
1 / 1
ChatGPT
The excerpt from Yoshiki Shoji's thesis, "A maximum entropy principle for the brain," provides an insight into the dynamic nature of the brain. The text divides the concept of the brain's function into interactions with both external and internal environments, or milieus.
Here's a summary of the key themes presented in the passage:
The External Milieu
: This refers to the individual's external social environment, including aspects like light and other sensory inputs. These inputs from the world around us are processed by the brain, shaping perceptions, behaviors, and emotions.
The Internal Milieu
: The internal environment, or internal milieu, encompasses the organs and internal processes that the brain helps regulate. This includes everything from managing heart rate and digestion to regulating hormones. The text mentions the concept of homeostasis, where the brain uses energy to maintain a stable internal environment.
The Concept of Homeostasis
: The passage emphasizes the idea of homeostasis as a self-regulating process that maintains stability within biological systems. Homeostasis, coined by Walter Bradford Cannon, is key to the survival of an organism, and the brain plays a central role in this process. It ensures that various physiological parameters remain within specific bounds, enabling the body to function efficiently.
Universal Examples of Stability
: The passage relates the brain's function to other examples of stability and self-adjustment in nature, such as the swarming of birds, the swinging of pendulums, and the stability of celestial objects. These comparisons underscore the universal principle of stabilization that the brain also follows.
The Continuous Life Cycle of the Brain
: An image is referenced that presumably illustrates the continuous interaction between the brain and its internal and external milieu, beginning before birth and continuing throughout life. This cycle underlines the brain's role in shaping an individual's lifestyle, mental state, and overall health, all while maintaining homeostasis.
Connecting Physical Laws to Biological Systems
: The passage ends by suggesting that the brain, like physical laws that govern the universe, regulates the body's internal environment. This analogy elevates the understanding of the brain to a universal principle, akin to laws like gravitation.
Overall, the excerpt paints a picture of the brain as a dynamic, complex organ, intertwined with both the internal workings of the body and the external world. It embodies a self-regulating, homeostatic mechanism that enables the organism to interact with its surroundings and sustain life. The idea that these processes are governed by universal principles such as entropy is central to the thesis's exploration of brain dynamics.
1 / 1
3.3Bridging Hebb���s and Edelman���s theory of brain de- 
velopment 
The central premise behind adopting the framework that the brain self-organizes to achieve 
homeostasis lies in its ability to explain Hebb���s and Edelman���s theory of brain development 
in a unif i ed manner.In order for the brain to achieve homeostasis ��� the brain���s state of 
equilibrium ��� it must be a self-adjusting and organizing system that evolves under constraints 
due to limited energy, space, and time. In this sense, from the virtue of Hebb���s theory, stability 
is achieved when neurons learn to transmit as much information from the source mapped to 
synaptic connections. When memory, to some degree, is consolidated, this is mapped to the 
CHAPTER 3. DESIGNING THE MIND23 
topology of neuronal networks. From the virtue of Edelman���s theory, at a global scale, this 
constitutes brain networks that function together to produce highly cognitive functions. Our 
objective now is to show how this stability arises that is ref l ected in neuronal structure and 
the topology of neuronal networks can be explained through the concept of Shannon���s entropy.
1 / 1
ChatGPT
The section you provided seems to bridge two influential theories of brain development, Hebb's theory and Edelman's theory, under the framework of self-organization to achieve homeostasis. Here's a breakdown of the key points:
Hebb's Theory
: Named after psychologist Donald Hebb, this theory posits that learning and memory formation are achieved through the strengthening of connections between neurons that fire together. Essentially, "cells that fire together wire together." Hebb's theory emphasizes the local aspect of brain development, where individual neurons learn to transmit as much information as possible.
Edelman's Theory
: Gerald Edelman's theory, on the other hand, looks at the global scale. It focuses on how entire networks of the brain work together to produce complex cognitive functions.
Homeostasis and Self-Organization
: This section proposes that the brain's ability to achieve equilibrium, or homeostasis, requires it to be a self-adjusting and self-organizing system. This self-organization is constrained by factors such as limited energy, space, and time.
Bridging Hebb's and Edelman's Theories
: By aligning these theories, the text seems to be drawing a connection between the local stability achieved through Hebb's learning mechanism and the global network organization seen in Edelman's theory. Both aspects contribute to the brain's overall equilibrium.
Shannon's Entropy
: The section ends by suggesting that the stability reflected in neuronal structure and network topology can be explained through the concept of Shannon's entropy. Shannon's entropy is a measure from information theory that quantifies the amount of uncertainty or randomness associated with a set of outcomes. It seems that the author is linking this concept to the brain's self-organizing principle.
The excerpt portrays the brain's development as a complex interplay between local learning processes (Hebb's theory) and global network organization (Edelman's theory), all governed by the principle of homeostasis. The introduction of Shannon's entropy as a unifying concept hints at a mathematical underpinning to this multifaceted view of brain development.
1 / 1
Constraining the brain 
Since the late nineteenth century, it has been recognized that many aspects of brain orga- 
nization can be accounted for by a parsimonious principle aimed at minimizing the wiring 
cost involved in the anatomical organization of neuronal connections to constitute circuits of 
neuronal networks or brain maps [14���16]. This insight was perhaps i rst articulated by Ram�� on 
y Cajal in 1899 on the basis of his microscopic studies of Golgi-stained neurons [77]:1 
���All of the various conformations of the neuron and its various components are 
simply morphological adaptations governed by laws of conservation for energy, 
space, and time.��� 
These ���Cajal conservation principles��� have endured and have been supported experimentally 
for over a century. However, over time they have been restated in more contemporary terms 
as constraints of wiring cost (space and energy), conduction speed (time), and cytoplasmic 
volume (material). 
Motivated by Cajal���s conservation principles, we begin this chapter by introducing Ed- 
win T. Jaynes��� theory behind the principle of constrained maximum entropy. We then argue 
how one can mathematically map physical neuronal elements of axonal diameter and length to 
action potential energy and how the spatial distribution of neurons and timing of action poten- 
tials shape synaptic connectivity. These biological ingredients are then cast into a constrained 
maximum entropy framework to derive joint probability distributions that statistically model 
the structural and neuroanatomical arrangement of neurons and neuronal networks in the 
brain. 
1Santiago Ram�� on y Cajal was a Spanish neuroscientist, pathologist, and histologist specializing in neu- 
roanatomy and the central nervous system. He shared the Nobel Prize in Physiology or Medicine in 1906 
together with the Italian scientist Camillo Golgi in recognition of their work on the structure of the nervous 
system. 44 
CHAPTER 6. CONSTRAINING THE BRAIN45 
6.1Principle of constrained maximum entropy 
The principle of constrained maximum entropy was made famous by a physicist, Edwin T. 
Jaynes, in statistical mechanics. In his paper, Information Theory and Statistical Mechanics 
published in 1954, Jaynes argued that 
���...the fact that a certain probability distribution maximizes entropy subject to 
certain constraints representing our incomplete information, is the fundamental 
property which justif i es the use of that distribution for inference. It agrees with 
everything that is known but carefully avoids assuming anything unknown. It is 
a transcription into the mathematics of an ancient principle of wisdom... [78]��� 
Therefore, in light of Jaynes��� argument, we shall also argue that this is the most principled 
choice from a biological perspective as we wish to make the most minimal assumptions to 
model the brain. 
The technique that we will use is the calculus of variations.2To i nd the distribution that 
maximizes entropy, we pose a constraint optimization problem and introduce constants, or 
Lagrange multipliers, associated with each constraint. We then i nd the maximal solution 
by perturbing the distribution subject to the constraints.In general, we must include a 
normalization constraint which acts as one constraint to satisfy the normalization property of 
probability distributions. 
Let us i rst analyze the constrained entropy maximization problem subject only to a nor- 
malization constraint, with its Lagrange multiplier denoted by ��N.
1 / 1
ChatGPT
The provided excerpt discusses an approach to understanding brain organization by employing a principle aimed at minimizing the wiring cost of neuronal connections, often referred to as the "Cajal conservation principles." Here's a summary of the key points:
Cajal Conservation Principles
: Stemming from Santiago Ram��n y Cajal's work in the late 19th century, these principles assert that the organization of neurons is guided by the conservation of energy, space, and time. Modern interpretations have also related these principles to constraints on wiring cost, conduction speed, and cytoplasmic volume.
Constrained Maximum Entropy
: The text introduces Edwin T. Jaynes' principle of constrained maximum entropy, a concept from statistical mechanics. It seeks to maximize entropy (a measure of randomness or uncertainty) subject to certain constraints. Jaynes argued that this approach justifies the use of specific probability distributions for inference.
Application to Brain Organization
: The author applies the principle of constrained maximum entropy to understand the structural and neuroanatomical arrangement of neurons and networks in the brain. This mathematical framework aims to create a statistical model that represents the physical neuronal elements and the spatial and temporal aspects of neuronal connectivity.
Calculus of Variations
: This technique is used to find the distribution that maximizes entropy, considering constraints, including normalization. The Lagrange multipliers method is mentioned as a mathematical tool to solve the optimization problem, ensuring that the constraints are met.
Biological Perspective
: The excerpt emphasizes that the principle of constrained maximum entropy is a principled choice from a biological standpoint. It aims to make minimal assumptions to model the brain, aligning with known facts while avoiding unnecessary assumptions.
In summary, the excerpt outlines a theoretical and mathematical framework for understanding brain organization by minimizing wiring cost, based on Cajal's principles. It leverages the concept of constrained maximum entropy, building a statistical model that represents various physical and biological factors within the brain.
1 / 1
A Maximum entropy principle for the 
brain 
Inspired by the works of Michael Merzenich, Donald Hebb, and Gerald Edelman on brain 
dynamics that constitute learning and memory from the mechanisms of homeostasis and 
neuroplasticity, we present a maximum entropy principle for the brain: 
From the set of all possible joint distributions p(s,���) of a neuron���s axonal length ��� and 
diameter s, the joint maximum entropy distribution p���(s,���) of the joint entropy H(s,���) 
subject to action potential power ��(s), Oka-Ikeda���s g-ratio g(s), distance ��� and timescale 
w(���) dependent synaptic connectivity constraints statistically and suf i ciently models the 
neuroanatomical organization of neuronal structure and network topology in the brain. 
Before we present the set of theoretical results, let us brief l y discuss what the joint max- 
imum entropy distribution p���(s,���) physically entails in a sensory-input to action-output con- 
text. If we observe Figure 7.1, beginning from (a), we see that the brain receives information 
about its external and internal milieu from sensory-inputs mapped into forms of action-output. 
For example, the brain receives information about its visual scenery from the activity of pho- 
toreceptors, wherein this information is processed and mapped into actions that are meaningful 
to the individual, thus allowing one to act accordingly to maximize survival. For instance, this 
can result in active eye movement. When repeatedly executed, any action, whether mental or 
physical, is learned and formed as memory, as indicated by (b). The arrows that perpetually 
l ow between (a) and (b) naturally enforces the endless cycle of learning and memory forma- 
tion. This universal aspect of learning and memory across many, if not all species, is possible 
because the structural self-organization of neurons, and the topological self-organization of 
neuronal networks, are designed to maximize entropy shaped through homeostasis and neu- 
65 
CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN66 
roplasticity.1In other words, learning is biologically possible because neurons communicate 
using action potentials that are functionally dependent on s; memory is biologically possible 
because neuronal connections are functionally dependent on ���, which leads to the highly self- 
organized shaping of network topology. Thus, the joint maximum entropy distribution p���(s,���) 
inherently allows the brain to structurally and topologically unfold as an information-theoretic 
organ in a lawful manner. 
7.1Set of theoretical results 
The maximum entropy principle for the brain presents us with a problem in constrained 
optimization: Solve for the joint maximum entropy distribution p���(s,���) of H(s,���). That is, 
p���(s,���) = argmax 
p(s,���)����� h ��� Z 
s,��� 
p(s,���)lnp(s,���)dsd��� i 
,(7.1) 
where s ��� [0,���) and ��� ��� [0,���), and �� is the set containing all possible unique joint distri- 
butions p(s,���) with its constraints, def i ned as 
�� = {p(s,���) | fi(s,���) 
= cifor i = 1,..,n},(7.2) 
where fi(s,���) is the ithconstraint as a function of neuronal diameter s and length ���, and n is the 
total number of constraints. From Chapter 6, we obtain a total of four biological constraints, 
and with the normalization constraint, we obtain the full set of constraint equations given by: 
C1= Z 
s,��� 
p(s,���)dsd��� = 1,C2= Z 
s,��� 
��(s)p(s,���)dsd��� = ��, 
C3= Z 
s,��� 
g(s)p(s,���)dsd��� = G,C4= Z 
s,��� 
���p(s,���)dsd��� = L, 
C5= Z 
s,��� 
w(���)p(s,���)dsd��� = W, where n = 5.
1 / 1
ChatGPT
The provided excerpt presents a maximum entropy principle for modeling the brain's structure and functionality, inspired by the works of Michael Merzenich, Donald Hebb, and Gerald Edelman. Here are the main aspects of this principle:
Maximum Entropy Distribution
: The principle posits that the joint maximum entropy distribution
p
���
(
s
,
���
)
p^*(s,\ell)
p
���
(
s
,
���
)
of a neuron's axonal length
���
\ell
���
and diameter
s
s
s
can statistically model the neuroanatomical organization of neuronal structure and network topology in the brain.
Physical Context
: The distribution has a physical meaning in sensory-input to action-output contexts, such as receiving visual information from photoreceptors and translating it into meaningful actions like eye movement.
Learning and Memory
: This process of receiving sensory input and transforming it into action enables learning and memory formation. The structure and topology of neuronal networks are designed to maximize entropy, making learning and memory biologically possible.
Constrained Optimization Problem
: Mathematically, the principle poses a constrained optimization problem to solve for the joint maximum entropy distribution
p
���
(
s
,
���
)
p^*(s,\ell)
p
���
(
s
,
���
)
. This distribution maximizes the entropy function
���
���
p
(
s
,
���
)
ln
���
p
(
s
,
���
)
d
s
d
���
-\int p(s,\ell) \ln p(s,\ell) ds d\ell
���
���
p
(
s
,
���
)
ln
p
(
s
,
���
)
d
s
d
���
subject to various constraints related to action potential power, Oka-Ikeda's g-ratio, distance, timescale-dependent synaptic connectivity, and normalization.
Constraints
: The excerpt outlines a set of equations that describe the constraints for the problem, including normalization and four biological constraints relating to aspects such as action potential power and synaptic connectivity.
In summary, this principle offers a theoretical framework that leverages the concept of maximum entropy to model the complex organization of neurons in the brain. It emphasizes the fundamental role of entropy in enabling learning, memory, and the brain's information-processing capabilities. The mathematical formulation presents a constrained optimization problem that represents critical aspects of neuronal structure and function.
1 / 1
��� First, the constraint C1ensures 
the unity axiom of probability distributions are satisf i ed. 
1It is worth mentioning that the development of neurons and neuronal networks is governed by genetic 
processes. For example, from Kandel���s [1] experiment with the sea slug, it was shown that synaptic connections 
from learning and memory consolidation are governed, at a molecular level, by messenger molecules, such as 
Cyclic-AMP. Cyclic-AMP is specif i cally activated when short-term memory transitions to long-term memory, 
where it activates a protein kinase molecule that activates transcription factors that bind to specif i c DNA 
sequences. This binding activates the neuron���s gene, which triggers the growth of new synaptic connections. 
Therefore, such systematic genetic processes may be ���designed��� to maximize entropy; however, to the best of 
our knowledge, literature to support this empirically is scarce. 
CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN67 
Figure 7.1: An illustration of the maximum entropy principle for the brain in a sensory-input 
to action-output context. (a) and (b): The perpetual cycle of executing actions, whether 
mental or physical, from sensory inputs creates a natural process for learning and memory 
formation in the brain; (c) The perpetual cycle is what constitutes the maximum entropy 
principle for the brain; (d): Neurons structurally evolve to biologically support learning and 
memory. Distance-dependent and timescale-dependent synaptic connectivity constraints gov- 
ern the topological self-organization of neuronal networks. Action potential power and Oda- 
Ikeda���s g-ratio constraints govern the speed of information l ow in the neuronal network. These 
are governed by p���(s,���), the joint maximum entropy distribution of neuronal diameter s and 
length ���, which maximizes the brain���s entropy for biological functioning. Image modif i ed and 
adapted from Karl Friston [119]. 
��� Second, the constraint C2constrains, 
on average, the amount of power neurons can 
consume, given by ��, due to the limited number of action potentials a neuron can 
generate. 
��� Third, the constraint C3constrains, 
on average, the amount of resources and material to 
myelinate neurons, measured with the Oda-Ikeda g-ratio, given by G, due to the limited 
amount of resources for myelination. 
��� Fourth, the constraint C4constrains, 
on average, the Euclidean intersomatic distance 
between neurons, given by L, due to limited space and resources. 
��� Lastly, the constraint C5constrains, 
on average, the timescale of action potentials be- 
CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN68 
tween neurons, given by W, due to the limited amount of time an action potential can 
travel between connected pairs of neurons.
1 / 1
ChatGPT
The given text further elaborates on the constraints defined in the maximum entropy principle for the brain. Here's a summary of what these constraints represent:
Constraint C1
: Ensures that the unity axiom of probability distributions is satisfied, meaning that the total probability must sum to one.
Constraint C2
: Constrains the average amount of power neurons can consume, denoted by
��
\Pi
��
. This relates to the limited number of action potentials a neuron can generate, reflecting the energy consumption in neural activity.
Constraint C3
: Constrains the average resources and material needed to myelinate neurons, measured using the Oda-Ikeda g-ratio (given by
G
G
G
). This takes into account the limited resources available for the process of myelination, which insulates nerve fibers.
Constraint C4
: Constrains the average Euclidean intersomatic distance between neurons, symbolized by
L
L
L
. This acknowledges the limited space and resources available for neurons to connect and interact.
Constraint C5
: Constrains the average timescale of action potentials between neurons, given by
W
W
W
. This reflects the time limitations for action potentials to travel between connected pairs of neurons.
These constraints capture critical aspects of the brain's structure and function, including spatial organization, energy consumption, myelination process, connectivity between neurons, and timing of neural signals. Together, they form a set of governing rules that guide the application of the maximum entropy principle in modeling the brain's organization and dynamics. The mention of systematic genetic processes like Cyclic-AMP also hints at a deeper connection between entropy maximization and molecular mechanisms underlying learning and memory, although the text acknowledges that empirical support for this idea may be lacking.
1 / 1
Conclusion 
In this thesis, we have considered the characteristics of biological systems in relation to adap- 
tive self-organizing systems. The brain, in particular, is a unique information-theoretic organ 
that is inf l uenced in response to interactions with its external and internal milieu to maintain 
structural and topological order. This self-organizational property of brain dynamics can be 
formalized in terms of an optimization problem of Shannon���s entropy subject to 4 biological 
constraints embedded with physical meaning correlated to the communication and connec- 
tivity of neurons. As a consequence of constrained entropy maximization, it is revealed that 
the brain may selectively choose to self-organize, based on an inference model adequately ex- 
plained by the maximum entropy joint distribution of neuronal diameter and length, to shape 
its structure and topology. Thus, maximizing the brain���s entropy may be a necessary, if not 
suf i cient, condition for the brain to learn and form memory biologically. 
This thesis attempts to replace dif i cult questions on how the organization, ref l ected in 
neuronal structure and the topology of network networks, emerges with what organizational 
principle they must exhibit to exist. The maximum entropy principle for the brain is one such 
principle that attempts to explain how such biological characteristics must arise in the brain. 
By casting these constraints to derive a maximum entropy joint distribution of axonal diameter 
and length, we arrived at a joint maximum entropy distribution that can suf i ciently model 
in vitro and in vivo empirical data of dif f erent species, conforming to gamma distributions. 
Using the maximum entropy axonal length distribution, the principle is also able to explain, 
utilizing graph theory, from simple simulation experiments how the brain might strategically 
organize neuronal networks that stabilize to a Rentian scaled small-world architecture. 
The ideas presented in this thesis have a long history, dating back to the notions of con- 
sciousness from the French philosopher, Ren�� e Descartes, and covering the ideas on how the 
brain develops using concepts derived from Shannon���s entropy. The scientif i c contribution of 
this thesis is to provide new and fresh insights that we hope can aid the neuroscience and en- 
87 
CHAPTER 9. CONCLUSION88 
gineering communities to rigorously formalize how the brain dynamically unfolds to learn and 
form memories that make everyday life possible. Furthermore, this formulation can be used to 
help connect constructs from modern theories of artif i cial intelligence and statistical physics 
with ideas from theories of neuroanatomical evolution, neurobiology, and sensory cybernetics. 
9.1Future direction 
An interesting possibility of a future direction is to explore the maximum entropy principle for 
the brain with applications such as artif i cial intelligence or machine learning. For example, we 
can extend and modify artif i cial neural networks based on Hebbian mechanisms where infor- 
mation and memory are assumed to be stored in real-valued ���weights��� associated with each 
neuron, such as the Hopf i eld network [118]. By adopting an information-theoretic framework, 
we can replace the artif i cial weights with H(si,���ij) to measure how much information, in a bi- 
ological sense, is transmitted between a presynaptic neuron i of diameter s to its postsynaptic 
neuron j, where each neuron i and neuron j are separated by a distance ���ij. Thus, if neuron 
i is artif i cially activated in a computational sense, it may be possible to train the network 
to learn, for example, images such as dogs and cats through an algorithmic process such as 
backpropagation or reinforcement learning, which can model artif i cial memory ref l ected in the 
network���s topology. 
Another interesting possibility of a future direction is to explore if the maximum entropy 
principle for the brain can be (re)derived using other existing principles for the brain, such 
as the free energy principle [119].1This is analogous to deriving Newton���s law of universal 
gravitation with Keplar���s laws of planetary motion ��� the laws are two sides of the same 
coin, just expressed in a dif f erent manner [79]. Thus, if the distributions from the maximum 
entropy principle can be (re)derived using other principles, it makes a stronger argument for 
arguing its biological plausibility and, furthermore, allows one to unify mathematical concepts 
in neuroscience.
1 / 1
ChatGPT
The conclusion of the thesis encapsulates a profound exploration into the nature of the brain as an adaptive self-organizing system governed by the maximum entropy principle. Here's a brief summary of the key takeaways:
Self-Organization and Entropy
: The thesis formalizes brain dynamics as an optimization problem of Shannon's entropy, subject to biological constraints. This mathematical framework captures how the brain's structure and topology adapt in response to internal and external influences.
Inference Model
: Through constrained entropy maximization, the thesis suggests that the brain's selective self-organization can be explained by the maximum entropy joint distribution of neuronal diameter and length.
Empirical Alignment
: The derived joint maximum entropy distribution is shown to align with in vitro and in vivo data, offering insights into the brain's Rentian scaled small-world architecture.
Philosophical Roots and Scientific Contributions
: The thesis draws connections to historical ideas, including those of Ren�� Descartes, and provides new perspectives that bridge neuroscience, engineering, AI, and statistical physics.
Future Directions
: The conclusion hints at promising avenues for future research, such as:
AI and Machine Learning Applications
: The framework could be extended to artificial neural networks, using information-theoretic constructs to replace traditional weight mechanisms.
Exploring Connections with Other Principles
: There may be potential to (re)derive the maximum entropy principle using other existing principles, such as the free energy principle, which could strengthen the biological plausibility of the concept and unify mathematical approaches in neuroscience.
In summary, the thesis offers an innovative perspective on the brain, grounded in entropy maximization, that contributes to our understanding of neural dynamics, organization, learning, and memory. The proposed framework opens doors to interdisciplinary applications and furthers the dialogue between theoretical principles and empirical observations.
1 / 1
The principle of maximum entropy states that the probability distribution which best represents the current state of knowledge about a system is the one with largest entropy, in the context of precisely stated prior data (such as a proposition that expresses testable information).

Another way of stating this: Take precisely stated prior data or testable information about a probability distribution function. Consider the set of all trial probability distributions that would encode the prior data. According to this principle, the distribution with maximal information entropy is the best choice.
1 / 1
ChatGPT
Exactly, the principle of maximum entropy is a fundamental concept in various fields such as physics, information theory, and statistics. It's a method for deducing the distribution that best represents our current knowledge or a given set of constraints, while making the least amount of unwarranted assumptions.
In the context of the brain, as described in the thesis you shared, this principle is applied to understand how the brain organizes itself. By optimizing entropy under certain biological constraints, the model provides insight into how the brain may structure its networks to achieve learning and memory. The maximum entropy principle allows the system to remain as unbiased and flexible as possible, given the known constraints, which can be essential for adaptive processes such as learning and evolution.
1 / 1
Edit
The principle of maximum entropy is commonly applied in two ways to inferential problems:

Prior probabilities
Edit
The principle of maximum entropy is often used to obtain prior probability distributions for Bayesian inference. Jaynes was a strong advocate of this approach, claiming the maximum entropy distribution represented the least informative distribution.[3] A large amount of literature is now dedicated to the elicitation of maximum entropy priors and links with channel coding.[4][5][6][7]

Posterior probabilities
Edit
Maximum entropy is a sufficient updating rule for radical probabilism. Richard Jeffrey's probability kinematics is a special case of maximum entropy inference. However, maximum entropy is not a generalisation of all such sufficient updating rules.[8]

Maximum entropy models
Edit
Alternatively, the principle is often invoked for model specification: in this case the observed data itself is assumed to be the testable information. Such models are widely used in natural language processing. An example of such a model is logistic regression, which corresponds to the maximum entropy classifier for independent observations.

Probability density estimation
Edit
One of the main applications of the maximum entropy principle is in discrete and continuous density estimation.[9][10] Similar to support vector machine estimators, the maximum entropy principle may require the solution to a quadratic programming problem, and thus provide a sparse mixture model as the optimal density estimator. One important advantage of the method is its ability to incorporate prior information in the density estimation.[11]
1 / 1
ChatGPT
Certainly! Your edited text details various applications of the principle of maximum entropy:
Prior Probabilities
: Used to obtain prior probability distributions for Bayesian inference, the maximum entropy principle assists in selecting the least informative distribution, given known constraints. This application is well-advocated by researchers like Jaynes, with connections made to channel coding.
Posterior Probabilities
: In the realm of radical probabilism, maximum entropy serves as a sufficient updating rule. Specific instances like Richard Jeffrey's probability kinematics fall under this category. Though widely applicable, it is not a universal generalization.
Maximum Entropy Models
: Often utilized for model specification, such as in natural language processing. Here, the observed data serves as the testable information, and logistic regression serves as a common example for independent observations.
Probability Density Estimation
: This is one of the principle's primary applications, aiding in both discrete and continuous density estimation. Comparable to support vector machine estimators, it often involves solving a quadratic programming problem, providing a sparse mixture model as the optimal density estimator. This method offers the advantage of incorporating prior information.
Overall, the maximum entropy principle is a powerful tool in statistical modeling, machine learning, and information theory, and your text highlights some of its most significant applications.
1 / 1
The maximum entropy principle is also needed to guarantee the uniqueness and consistency of probability assignments obtained by different methods, statistical mechanics and logical inference in particular.

The maximum entropy principle makes explicit our freedom in using different forms of prior data. As a special case, a uniform prior probability density (Laplace's principle of indifference, sometimes called the principle of insufficient reason), may be adopted. Thus, the maximum entropy principle is not merely an alternative way to view the usual methods of inference of classical statistics, but represents a significant conceptual generalization of those methods.

However these statements do not imply that thermodynamical systems need not be shown to be ergodic to justify treatment as a statistical ensemble.

In ordinary language, the principle of maximum entropy can be said to express a claim of epistemic modesty, or of maximum ignorance. The selected distribution is the one that makes the least claim to being informed beyond the stated prior data, that is to say the one that admits the most ignorance beyond the stated prior data.
1 / 1
ChatGPT
Certainly! Your addition provides further insights into the maximum entropy principle, highlighting its roles and interpretations:
Uniqueness and Consistency
: The principle ensures that the probability assignments obtained through different methods, such as statistical mechanics or logical inference, are unique and consistent.
Freedom in Using Prior Data
: By making our freedom explicit in choosing various forms of prior data, the principle includes specific cases like adopting a uniform prior probability density (Laplace's principle of indifference).
Conceptual Generalization
: Beyond being just an alternative to classical statistical methods, the maximum entropy principle represents a broader and more general understanding of those methods.
No Need for Ergodic Justification
: The statements you mentioned clarify that the application of the principle doesn't imply that thermodynamic systems must be shown to be ergodic to be treated as statistical ensembles.
Epistemic Modesty or Maximum Ignorance
: In layman's terms, the principle can be seen as a claim of admitting the most ignorance beyond the stated prior data. It selects the distribution that makes the least claim to being informed beyond what is already known, reflecting an epistemologically humble stance.
Your elaboration provides a comprehensive understanding of the conceptual richness and diverse applications of the maximum entropy principle.
1 / 1
An example explaining each of those points.
1 / 1
ChatGPT
Certainly! Here are examples that illustrate each of the points mentioned:
Uniqueness and Consistency
:
Example
: Suppose we're modeling the distribution of gas particles in a container. Both statistical mechanics (using Boltzmann's entropy formula) and logical inference (using the maximum entropy principle) lead to the same Maxwell-Boltzmann distribution, showcasing consistency and uniqueness in the probability assignment.
Freedom in Using Prior Data
:
Example
: In estimating the probability distribution of a die's outcomes without any prior knowledge, the principle of maximum entropy leads to a uniform distribution (1/6 for each side). If additional information (like bias) is known, the principle can incorporate that to change the distribution accordingly.
Conceptual Generalization
:
Example
: In classical statistics, the method of moments can be used to estimate parameters of a distribution. The maximum entropy principle generalizes this by allowing constraints related to moments or other known features, leading to a more flexible estimation, like the exponential distribution in certain constrained conditions.
No Need for Ergodic Justification
:
Example
: Consider a non-ergodic system like a trapped particle that doesn't explore all available states. Even if the system isn't ergodic, the maximum entropy principle can still provide a valid statistical description by considering only the known constraints and available information.
Epistemic Modesty or Maximum Ignorance
:
Example
: If we are modeling the probability distribution of a future event with no previous data, using the maximum entropy principle would lead us to a distribution that reflects maximum ignorance. For example, without any knowledge of a biased coin, the maximum entropy distribution would be a 50-50 chance for heads or tails, making no further assumptions.
These examples offer tangible illustrations of how the maximum entropy principle operates in various contexts, reflecting its multifaceted nature and extensive applicability.
1 / 1
Isn't that interesting. It reminds me of the Oracle's statement about Socrates
1 / 1
ChatGPT
Yes, the principle of maximum entropy does share some philosophical parallels with the Oracle of Delphi's statement about Socrates: "This man, Socrates, is wisest, for he knows that he knows nothing."
Both ideas embrace a form of intellectual humility or acknowledgment of uncertainty. Socrates' wisdom lay in recognizing the limitations of his knowledge, and he actively questioned assumptions to gain deeper understanding. Similarly, the maximum entropy principle seeks to make the least assumptions beyond the known constraints, reflecting a kind of statistical modesty.
In both cases, there's a recognition that claiming less knowledge or making fewer assumptions can lead to more robust, flexible, or insightful perspectives. It's a fascinating connection between ancient philosophical thought and modern statistical theory!
1 / 1
So like if I didn't know the probabilities of English letter frequencies, I could start with the guess that it has to be 1/26
1 / 1
ChatGPT
Exactly! If you had no prior information about the frequencies of English letter occurrences, a reasonable starting point would be to assume that each letter has an equal probability of occurring, which would be
1
26
\frac{1}{26}
26
1
���
since there are 26 letters in the English alphabet.
This assumption is in line with the principle of maximum entropy, where, in the absence of any other constraints or information, you would choose the distribution that represents the highest level of uncertainty or ignorance. In this case, that would mean assuming a uniform distribution where each letter has the same chance of appearing.
It's a very practical way to handle situations where little is known, and it reflects the principle's underlying philosophy of acknowledging uncertainty and avoiding unnecessary assumptions.
1 / 1
But really letters like s, t, r, e are  more common than z and x
1 / 1
ChatGPT
Yes, that's correct! In practice, the distribution of letter frequencies in the English language is far from uniform. Letters like "e," "t," "a," "o," "i," "n," and "s" tend to be more common, while letters like "z" and "x" are much less frequent.
If you were to construct a model of English letter frequencies, you'd likely start with a uniform distribution if you had no additional information. However, as you gather more data (e.g., analyzing texts or literature), you'd update your model to reflect the actual distribution of letters. This updating would lead to a distribution that better represents the real-world occurrence of letters in the English language.
In essence, the principle of maximum entropy allows for a rational starting point when little is known, but it also allows for continual refinement as more information becomes available. This approach is often used in various fields, including natural language processing and statistical mechanics, to make informed predictions based on the available data.
1 / 1
So what was the maximum entropy principle for the brain?
1 / 1
ChatGPT
The maximum entropy principle for the brain, as described in the thesis text you provided earlier, refers to the idea that the brain organizes itself in such a way that maximizes entropy subject to certain biological constraints. This principle aims to explain how the brain's structure, topology, and function emerge in an optimal way.
In the context of the thesis, the principle of maximum entropy is used to formalize an optimization problem for the brain, considering Shannon's entropy and biological constraints related to neurons' communication and connectivity. The constraints include factors such as the amount of power neurons can consume, the resources for myelination, the distance between neurons, and the timescale of action potentials.
By maximizing entropy within these constraints, the brain might selectively self-organize, shaping its structure and topology. This idea is used to explain how the brain learns, forms memory, and organizes neuronal networks.
The thesis also suggests future directions where this principle can be applied, including artificial intelligence, machine learning, and a possible unification with other principles like the free energy principle. By adopting this information-theoretic framework, researchers aim to provide new insights into understanding the brain's complex dynamics and offer connections to various scientific and engineering disciplines.
1 / 1
An analogy with simpler object
1 / 1
ChatGPT
Certainly! Let's consider a simple analogy using a jar filled with a mixture of colored marbles.
Imagine you have a jar, and inside it, you have marbles of different colors. You know the total number of marbles, but you don't have information about the exact number of each color.
Uniform Distribution (Maximum Ignorance):
In the absence of any other information, you might assume that each color is equally likely. This is like assigning a uniform prior probability, where the entropy is maximized. You're essentially admitting your ignorance by distributing the probability equally among all possibilities.
Constraints (Biological Constraints in the Brain):
Now, if you add constraints like "there are twice as many red marbles as blue marbles," you're putting specific conditions on the distribution, similar to the biological constraints in the brain.
Optimization (Self-Organization in the Brain):
By incorporating the constraints, you're left with a set of possible distributions that still fit the known facts. Among these, the one that maximizes entropy (i.e., keeps the distribution as spread out as possible) will be the best representation of your knowledge about the marbles. This is analogous to how the brain might optimize its structure and topology within certain constraints to maximize entropy.
Adaptation (Learning and Memory Formation):
If you receive more information (e.g., observing some marbles being taken out or put into the jar), you can update your distribution accordingly. This is akin to how the brain dynamically unfolds to learn and form memories, adapting to new information.
In summary, the jar and marbles provide a simpler analogy for the maximum entropy principle for the brain, showcasing how the distribution is formed initially in a state of maximum ignorance, then refined and optimized based on constraints, and finally adapted to new information, mirroring the complex processes within the brain.
1 / 1
Ok how about a puzzle with edge pieces
1 / 1
ChatGPT
Certainly! Let's use a puzzle as an analogy for the maximum entropy principle, specifically focusing on the process of starting with edge pieces.
Starting with Edge Pieces (Uniform Distribution):
Imagine you have a jigsaw puzzle, and you decide to start with the edge pieces. In the absence of any information about the internal pieces, you're working with what you know for sure ��� the edges. This is analogous to a uniform distribution, where you're acknowledging the constraints you have (edge pieces) and leaving the internal pieces (unknown variables) in a state of maximum ignorance.
Fitting Pieces Together (Constraints):
As you connect the edge pieces, you begin to see the constraints that govern where other pieces can fit. These constraints narrow down the possibilities for the rest of the puzzle. Similarly, in the brain, constraints such as connectivity and communication between neurons shape the system's overall structure.
Maximizing Entropy (Optimization):
The placement of each piece within the constraints must be done in a way that keeps as many possibilities open as possible for the remaining pieces. This is analogous to maximizing entropy within constraints, finding the most "spread-out" or uncertain distribution that still fits the known information.
Building the Inner Puzzle (Adaptation):
As you continue to fit pieces, you adapt to new information (the fitting of each new piece) and update your understanding of the puzzle. In the brain, this adaptation to new information represents the learning and memory formation process, constantly updating and reorganizing itself within the constraints.
Final Picture (Self-Organization):
The completed puzzle represents a specific self-organization of pieces that meet all constraints and hold maximum uncertainty until the very end. Similarly, the brain's self-organization aims to maintain maximum entropy while still adhering to physical and biological constraints.
In essence, this puzzle analogy illustrates how starting with known constraints (edge pieces) and gradually building complexity (fitting internal pieces) while maximizing uncertainty (keeping options open) mirrors the maximum entropy principle in the brain's structure and function.
1 / 1
I read that the brain continually unfolds the cortex to try to maximize the amount of surface area.
1 / 1
The previous model used in this conversation is unavailable. We've switched you to the latest default model.
ChatGPT
Indeed, that's a fascinating observation! The human brain, particularly the cerebral cortex, is known for its highly folded and convoluted structure. This folding of the cortex increases its surface area, allowing a larger number of neurons and connections to fit within the limited space of the skull. This increased surface area is thought to contribute to the brain's remarkable cognitive capabilities.
The process of folding the cortex and maximizing surface area is known as cortical folding or gyrification. Gyrification begins during fetal development and continues after birth. The brain's surface initially starts as a relatively smooth structure, but as it grows and develops, it undergoes intricate folding patterns.
Several factors are believed to contribute to cortical folding:
Space Efficiency:
One of the primary reasons for cortical folding is to optimize space within the confined cranial cavity. By folding and increasing surface area, the brain can accommodate a larger number of neurons and connections, which are crucial for processing complex information.
Evolutionary Advantage:
The folding of the cortex is thought to be an evolutionary advantage that allows more cortical tissue to fit into a smaller space. This increased surface area enables greater cognitive abilities, including advanced sensory processing, complex thinking, and problem-solving.
Enhanced Connectivity:
The folded structure promotes closer proximity of neurons, enhancing the efficiency of communication and information transfer between different brain regions. This connectivity is crucial for integrating various sensory inputs, forming memories, and carrying out complex cognitive functions.
Functional Specialization:
Different regions of the brain's cortex are responsible for various functions. The folding pattern helps segregate and separate these specialized regions, allowing them to work in tandem while maintaining their distinct functions.
Developmental Signals:
Genetics and molecular signaling play a role in guiding the folding process during brain development. These signals influence how neurons migrate and arrange themselves during gyrification.
It's important to note that the precise mechanisms and reasons behind cortical folding are still areas of ongoing research and study in the field of neuroscience. While maximizing surface area is a likely factor, there may be additional complexities at play that contribute to the brain's folded structure.
Overall, the brain's ability to continually unfold and refold its cortex reflects its remarkable adaptability and optimization to achieve efficient information processing within the constraints of its physical space.
1 / 1
Cortical folding, or gyrification, coincides with several important developmental processes. The folded shape of the human brain allows the cerebral cortex, the thin outer layer of neurons and their associated projections, to attain a large surface area relative to brain volume.Sep 24, 2018
https://royalsocietypublishing.org ��� ...
Mechanics of cortical folding: stress, growth and stability - Journals
1 / 1
ChatGPT
Absolutely, you've captured a key aspect of cortical folding. The relationship between the folded structure of the cerebral cortex and the brain's surface area-to-volume ratio is significant. This complex process of gyrification is crucial for the brain's functional efficiency and its ability to carry out advanced cognitive processes.
The large surface area of the cerebral cortex is essential for accommodating the vast number of neurons and synapses that underlie the brain's information processing capabilities. This intricate folding pattern allows the brain to pack a substantial amount of neural tissue into the relatively limited space of the cranial cavity. As a result, the brain can perform a wide range of complex tasks, from sensory perception and motor control to memory formation and higher-order thinking.
Moreover, the folding of the cortex has been linked to the brain's structural and functional connectivity. Different regions of the cortex are responsible for specific functions, and the folding pattern helps create distinct functional regions while facilitating communication between them. This specialization and integration of functions play a crucial role in enabling the brain to execute complex tasks efficiently.
The mechanics of cortical folding involve a balance between mechanical forces, growth, and stability. Research into the biomechanics of the brain suggests that tension forces generated by neural connections and differential growth rates between regions of the cortex can contribute to the folding process. This balance of forces results in the characteristic pattern of gyri (ridges) and sulci (grooves) seen on the brain's surface.
Studying the mechanics of cortical folding not only deepens our understanding of brain development but also provides insights into neurological disorders and conditions associated with abnormal gyrification patterns. Disorders such as lissencephaly (smooth brain) and polymicrogyria (excessive small gyri) highlight the importance of proper cortical folding for normal brain function.
In summary, the process of cortical folding is an exquisite example of how biological systems optimize their structure to achieve functional efficiency. The folding allows the human brain to possess a remarkable capacity for complex cognitive functions while fitting within the constraints of the cranial space.
1 / 1
Brain folding related to surface area and thickness, not number of neurons
by Bob Yirka , Medical Xpress

https://medicalxpress.com/news/2015-07-brain-surface-area-thickness-neurons.html

A series of crumpled paper balls made of stacks of 1, 2, 3, 4, 6 or 8 sheets of A4 paper. The series illustrates how the increasing thickness of the surface subjected to pressures results in progressively less highly folded paper balls, similar to a cerebral cortex of constant surface area but increasing thickness across species. Credit: Suzana & Luiza Herculano-Houzel
(Medical Xpress)���A pair of researchers with Universidade Federal do Rio de Janeiro has found that the degree of folding of mammalian brains follows a simple mathematical relationship. In their paper published in the journal Science, Bruno Mota and Suzana Herculano-Houzel describe how they came up with the math and its implications regarding the developmental and evolutionary origins of brain folding. George Striedter and Shyam Srinivasan with the University of California offer a Commentary piece on the work done by the duo in the same journal issue.


Everyone knows that the human brain has folds on its outer surface, as do most other mammalian brains. But what is still a mystery is the exact process that leads to the growth of the folds and why they end up the way they do. In this new effort, the researchers do not answer those questions, but they have solved another mystery���the relationship between brain structure and the degree of folding that occurs between species.

Some animals have more brain folding than others, and while at first blush it might appear that bigger or smarter animals (who generally have more neurons) have more folds, prior attempts to show that such a relationship always holds, however, have not held up. Now Mota and Herculano-Houzel have come up with a mathematical relationship that describes brain folds for all species���and it is nearly the same as that used to describe wadded up paper balls. They found that the cortical surface area (the exposed part) of a brain is proportional to the whole surface area, multiplied by the square root of cortical thickness, i.e., the amount of folding goes up as surface area goes up, but is also impacted by cortical thickness. Taking a step back and looking at the idea, shows that it follows logic: for a brain to maximize surface area inside of a cranium, it has to have folds, but it can only fold so much, depending on cortical thickness���just as occurs with a piece of wadded up paper, the researchers note
1 / 1
ChatGPT
Absolutely, the relationship between brain folding, surface area, and cortical thickness is a fascinating topic in neuroscience. The article you shared highlights a mathematical relationship that describes how brain folds develop across species and relates them to surface area and cortical thickness.
To illustrate this concept with a simpler analogy, consider a crumpled piece of paper. When you crumple a piece of paper, its surface area increases due to the folds that form. However, if you were to keep adding more paper layers and crumple them, you'd notice that while the surface area still increases, the folds become less pronounced as the stack of paper becomes thicker.
In a similar manner, the brain's folding, or gyrification, allows it to increase its surface area within the confines of the skull. The greater the surface area, the more neurons and synapses can be accommodated, facilitating complex cognitive processes. However, just like with the stack of paper, there's a limit to how much the brain can fold, depending on its cortical thickness.
The mathematical relationship discovered by Mota and Herculano-Houzel captures this balance between surface area, folding, and cortical thickness. It indicates that the degree of folding is influenced not only by the expansion of surface area but also by the thickness of the cortex. This relationship helps explain why certain species have more intricate folding patterns than others, and it provides insights into the developmental and evolutionary origins of brain folding.
In essence, the brain's folding can be thought of as a trade-off between maximizing surface area for neural connections and maintaining a feasible degree of folding determined by cortical thickness. This balance is essential for accommodating the brain's structural and functional needs while working within the constraints of the skull.
Overall, this research sheds light on the underlying principles that govern brain folding and its importance in facilitating the brain's complex functions.
1 / 1
Connections with the topics discussed earlier.
1 / 1
ChatGPT
Certainly! The concept of brain folding and its relationship to surface area and cortical thickness has several connections with the topics we've discussed earlier:
Maximum Entropy Principle
: Just like the maximum entropy principle aims to find the most unbiased probability distribution given limited information, the brain's folding can be seen as a way to maximize its potential within the constraints of its physical space. The folding allows the brain to increase its surface area, providing more room for neural connections and processing, which aligns with the principle's goal of maximizing information.
Self-Organization and Efficiency
: The brain's folding is a remarkable example of self-organization, which we talked about in the context of network connectivity and efficient communication. The folding allows the brain to efficiently increase its surface area without compromising the structural integrity of the cortex. This parallels the brain's strategic self-organization of its networks to optimize information processing.
Constrained Optimization
: The mathematical relationship between brain folding, surface area, and cortical thickness resembles the idea of constrained optimization discussed earlier. Just as the maximum entropy principle optimizes distributions under constraints, the brain's folding optimizes its surface area while considering the limitations imposed by cortical thickness.
Biological Constraints
: The principle of maximum entropy takes into account biological constraints, similar to how the brain's folding is influenced by factors like the physical limits of the skull and the need to maintain structural stability. Both concepts acknowledge that systems, whether information distributions or brain structures, must adapt to various constraints for optimal functioning.
Emergent Properties and Homeostasis
: The brain's folding and its relationship to surface area and cortical thickness exemplify emergent properties arising from complex systems. Just as the maximum entropy principle explains emergent patterns in probability distributions, the folding is an emergent feature of the brain's development and evolution, driven by the need to achieve homeostasis and efficient processing.
Interdisciplinary Connections
: The study of brain folding bridges concepts from mathematics, physics, and biology, similar to how the maximum entropy principle draws on principles from information theory, statistics, and thermodynamics. This interdisciplinary approach highlights the interconnectedness of different fields when exploring complex phenomena.
In summary, the concept of brain folding, along with its mathematical underpinnings, aligns with many of the themes we've discussed earlier, including the principles of maximum entropy, self-organization, optimization, and emergent properties. It provides a concrete example of how biological systems, like the brain, navigate constraints and optimize their structures to achieve efficient and effective functioning.
1 / 1
Another summary of the conversation.
1 / 1
ChatGPT
Certainly! Here's a summary of the key topics and themes we've covered in our conversation:
Information Theory and Maximum Entropy Principle
: We explored the concept of the maximum entropy principle, which seeks to find probability distributions that represent the most unbiased representation of a system's state given limited information. This principle has applications in various fields, including brain dynamics.
Neuroscience and Brain Function
: We delved into the application of the maximum entropy principle in neuroscience, particularly in explaining how neurons structurally evolve to communicate efficiently and how connections between neurons are self-organized for learning and memory formation.
Constraints and Optimization
: The principle of maximum entropy involves working with constraints to find the most likely distribution. Similarly, the brain's development, cortical folding, and network organization involve constrained optimization processes to maximize efficiency and adapt to physical limitations.
Biological Self-Organization
: We discussed how the brain's self-organizing principles align with the concept of entropy maximization. The brain's ability to self-organize structurally and topologically enables it to efficiently process information and form memories.
Analogies and Examples
: Analogies were used to clarify complex concepts, such as the analogy between brain folding and crumpled paper balls to illustrate the relationship between surface area and cortical thickness.
Interdisciplinary Connections
: The conversation highlighted the interdisciplinary nature of topics, from information theory and statistics to neuroscience and biology. Concepts from different fields often converge to provide insights into complex systems.
Emergent Properties and Homeostasis
: We explored how emergent properties, like brain folding, arise from complex systems and how the brain's folding helps it achieve homeostasis and efficient processing.
Implications and Future Directions
: The maximum entropy principle's application to brain dynamics opens avenues for understanding neural processes, neural network models, and even connections to artificial intelligence.
Throughout the conversation, the common thread was understanding how principles from information theory and statistical mechanics apply to the brain's self-organization, learning, and memory formation, showcasing the intricate interplay between physical laws and biological systems.
1 / 1
I decided to call the conversation "Self-Organisation in the Brain"
1 / 1
ChatGPT
That's a great title! "Self-Organization in the Brain" accurately captures the essence of our discussion about how the brain's intricate processes, from neuronal connections to cortical folding, are governed by principles of self-organization and efficiency. If you have any more questions or need further assistance, feel free to ask!
1 / 1
A final summary.
1 / 1
ChatGPT
Certainly! Our conversation delved into the fascinating topic of "Self-Organization in the Brain." We explored how the brain's structure and function are guided by principles of efficiency, entropy maximization, and adaptive processes. We discussed the maximum entropy principle and how it applies to various aspects of neuroscience, including probabilistic modeling, information theory, and the brain's self-organization. We examined the work of Yoshiki Shoji's thesis on the maximum entropy principle for the brain, which aims to explain the intricate connections between neuronal diameter, length, and synaptic connectivity. We also touched upon the concept of cortical folding and how it relates to surface area and thickness in mammalian brains. Overall, our conversation unveiled how the brain's self-organization plays a pivotal role in shaping its structure, function, and the complex processes of learning and memory.
1 / 1
Science Newsfrom research organizations
Mathematical theory predicts self-organized learning in real neurons
Date:
August 7, 2023
Source:
RIKEN
Summary:
Researchers have demonstrated that self-organization of neurons as they 'learn' follows a mathematical theory called the free energy principle. The principle accurately predicted how real neural networks spontaneously reorganize during learning, as well as how altering neural excitability can disrupt the process.
Share:
    
advertisement

FULL STORY
An international collaboration between researchers at the RIKEN Center for Brain Science (CBS) in Japan, the University of Tokyo, and University College London has demonstrated that self-organization of neurons as they "learn" follows a mathematical theory called the free energy principle. The principle accurately predicted how real neural networks spontaneously reorganize to distinguish incoming information, as well as how altering neural excitability can disrupt the process. The findings thus have implications for building animal-like artificial intelligences and for understanding cases of impaired learning. The study was published August 7 in Nature Communications.

When we learn to tell the difference between voices, faces, or smells, networks of neurons in our brains automatically organize themselves so that they can distinguish between the different sources of incoming information. This process involves changing the strength of connections between neurons, and is the basis of all learning in the brain. Takuya Isomura from RIKEN CBS and his international colleagues recently predicted that this type of network self-organization follows the mathematical rules that define the free energy principle. In the new study, they put this hypothesis to the test in neurons taken from the brains of rat embryos and grown in a culture dish on top of a grid of tiny electrodes.

Once you can distinguish two sensations, like voices, you will find that some of your neurons respond to one of the voices, while other neurons respond to the other voice. This is the result of neural network reorganization, which we call learning. In their culture experiment, the researchers mimicked this process by using the grid of electrodes beneath the neural network to stimulate the neurons in a specific pattern that mixed two separate hidden sources. After 100 training sessions, the neurons automatically became selective -- some responding very strongly to source #1 and very weakly to source #2, and others responding in the reverse. Drugs that either raise or lower neuron excitability disrupted the learning process when added to the culture beforehand. This shows that the cultured neurons do just what neurons are thought to do in the working brain.

The free energy principle states that this type of self-organization will follow a pattern that always minimizes the free energy in the system. To determine whether this principle is the guiding force behind neural network learning, the team used the real neural data to reverse engineer a predictive model based on it. Then, they fed the data from the first 10 electrode training sessions into the model and used it to make predictions about the next 90 sessions. At each step, the model accurately predicted the responses of neurons and the strength of connectivity between neurons. This means that simply knowing the initial state of the neurons is enough to determine how the network would change over time as learning occurred.

"Our results suggest that the free-energy principle is the self-organizing principle of biological neural networks," says Isomura. "It predicted how learning occurred upon receiving particular sensory inputs and how it was disrupted by alterations in network excitability induced by drugs."

"Although it will take some time, ultimately, our technique will allow modelling the circuit mechanisms of psychiatric disorders and the effects of drugs such as anxiolytics and psychedelics," says Isomura. "Generic mechanisms for acquiring the predictive models can also be used to create next-generation artificial intelligences that learn as real neural networks do
1 / 1
ChatGPT
The recent research conducted by an international collaboration involving the RIKEN Center for Brain Science, the University of Tokyo, and University College London has uncovered that the self-organization of neurons during learning aligns with the mathematical concept known as the free energy principle. This principle effectively predicted the way real neural networks spontaneously rearrange themselves while learning and how changes in neural excitability can interfere with this process. The study, published in Nature Communications on August 7, has far-reaching implications for developing animal-like artificial intelligences and comprehending impaired learning. By investigating neurons from rat embryos grown on a grid of tiny electrodes, the researchers demonstrated that neural network self-organization adheres to patterns that minimize the free energy within the system. The study's findings imply that the free energy principle serves as a fundamental self-organizing principle for biological neural networks, which could have significant applications in studying psychiatric disorders and the effects of drugs. This research also offers insight into creating next-generation artificial intelligence models that mimic the learning patterns of real neural networks.
1 / 1
One more summary
1 / 1
ChatGPT
Recent research conducted by an international team from RIKEN Center for Brain Science, the University of Tokyo, and University College London has shown that the self-organization of neurons during learning follows a mathematical concept called the free energy principle. This principle accurately predicted how real neural networks reorganize as they learn and how altering neural excitability can disrupt this process. The study, published in Nature Communications, suggests that the free energy principle is a guiding force behind biological neural network self-organization. The findings hold potential implications for developing AI models that mimic neural learning patterns and for understanding impaired learning. This research could pave the way for investigating psychiatric disorders and the effects of drugs on neural networks.
1 / 1
I mean of our whole conversation.
1 / 1
ChatGPT
Certainly! Our conversation explored various aspects of self-organization in the brain, starting with the concept of the maximum entropy principle. This principle, commonly applied in probability and statistics, suggests that the most appropriate probability distribution to represent a system's state of knowledge is the one with the largest entropy, given certain constraints.
We discussed how the maximum entropy principle is relevant to the brain's functioning, including its dynamic nature, response to internal and external stimuli, and the maintenance of homeostasis. This principle was presented in the context of a thesis by Yoshiki Shoji that proposed a maximum entropy principle for the brain, which involves considering various constraints related to neuronal structure, communication, and connectivity.
Drawing parallels, we explored the principle's application in various fields, such as prior and posterior probabilities in Bayesian inference, model specification, probability density estimation, and even its role in ensuring uniqueness and consistency of probability assignments. An analogy with English letter frequencies helped illustrate how the principle works in practice, allowing us to make informed predictions while admitting our lack of complete knowledge.
Furthermore, we delved into the idea of brain folding and cortical gyrification, which enhance the brain's surface area and information processing capabilities. We discussed the relationship between brain structure, folding, and neuronal organization, as well as its application in AI models. This led to a recent study that demonstrated how the self-organization of neurons during learning adheres to the free energy principle, a mathematical theory that accurately predicts neural network reorganization.
Overall, our conversation covered the maximum entropy principle's significance in understanding the brain's self-organizing mechanisms, its parallels in different fields, and its application in predicting neural network behavior during learning.
1 / 1
A simpler explanation
1 / 1
ChatGPT
In our conversation, we explored the idea of how the brain organizes itself to make sense of the world. We used a concept called the maximum entropy principle, which helps us understand how the brain adapts while taking into account what it knows and what it doesn't know. This principle allows us to make predictions even when we don't have all the information.
We discussed how this principle can be applied to the brain's functioning, like how it responds to different situations and maintains its balance. We also talked about a special case where this principle was used to create a theory for how the brain develops and learns.
To make it simpler, we looked at examples like guessing letter frequencies in English and how brain folding helps the brain process information more effectively. We also talked about a recent study that showed how real neurons in the brain self-organize using a similar mathematical theory.
Overall, our conversation highlighted how this principle helps us understand how the brain learns and adapts, even when faced with incomplete information.
1 / 1
How do the maximum entropy and free energy minimization compare?
1 / 1
ChatGPT
The maximum entropy principle and free energy minimization are related concepts, but they are used in slightly different contexts and have distinct implications.
Maximum Entropy Principle:
The maximum entropy principle is used to make predictions or inferences about a system when you have limited information about it.
It states that when you have incomplete knowledge, the best choice is the probability distribution that maximizes entropy while satisfying the available constraints.
It's often applied in cases where you want to make the least biased assumption given the information you have.
In the context of the brain, it helps explain how the brain self-organizes and adapts to its environment while considering constraints such as energy, space, and time.
Free Energy Minimization:
Free energy is a concept from thermodynamics and statistical mechanics that describes the energy available to do work in a system.
Free energy minimization is a principle used to describe how systems seek to reach a state of lower energy or greater stability.
It's often applied to physical and biological systems to explain how they naturally tend to move towards states that minimize their overall energy.
In the context of the brain, the free energy principle suggests that the brain tries to minimize the discrepancy between its internal model of the world and the actual sensory inputs it receives. This leads to the brain making predictions about the environment to reduce surprise or uncertainty.
Comparison:
Both principles involve optimization: maximum entropy aims to maximize uncertainty given constraints, while free energy minimization aims to minimize energy and surprise.
Maximum entropy is more about making informed predictions or assumptions with limited information, while free energy minimization is about systems seeking stability and reducing surprise.
The maximum entropy principle can be applied to a wide range of situations, while free energy minimization is often used to explain how living systems, like the brain, maintain stability and adapt.
In some cases, the two principles can overlap or align, as seen in the application of the free energy principle to explain aspects of neural self-organization based on minimizing surprise and adapting to the environment.
In essence, while these principles have different focal points and contexts, they both provide insights into how complex systems like the brain operate, learn, and adapt in their surroundings.
1 / 1
A few more everyday examples as analogies.
1 / 1
ChatGPT
Sure, here are a few everyday examples that might help you understand the concepts of maximum entropy and free energy minimization:
Party Seating Arrangement (Maximum Entropy):
Imagine you're organizing a party and you want to seat your guests around a circular table. You know some of their preferences, but not all. The maximum entropy principle would suggest that you should arrange the seating in a way that makes the fewest assumptions about their preferences while still accommodating the constraints you have, like not seating close friends next to each other.
Tightrope Balancing (Free Energy Minimization):
Think of a tightrope walker trying to stay balanced while walking across a rope. The walker's goal is to minimize the energy required to maintain balance and avoid falling. They adjust their posture and movements to minimize the overall potential energy and stay stable.
Crossword Puzzle (Maximum Entropy):
Solving a crossword puzzle involves fitting words into a grid of letters while adhering to the given clues. Applying the maximum entropy principle means you're looking for word placements that are consistent with the provided information (clues) but also maintain the highest level of uncertainty where clues are missing.
Room Temperature (Free Energy Minimization):
Consider a room with an open window on a cold day. The room's temperature will naturally tend to equilibrate with the external environment to minimize the temperature difference (free energy) and achieve a more stable state.
Music Shuffle (Maximum Entropy):
When you shuffle a playlist, you're arranging songs in a way that doesn't follow a specific pattern. The maximum entropy principle here would suggest that you shuffle the songs to minimize the assumptions about your musical preferences while still adhering to the constraint that each song should play once.
Jenga Tower (Free Energy Minimization):
Playing Jenga involves removing blocks from a tower while trying to keep it stable. As you remove blocks, you're minimizing the tower's potential energy and preventing it from collapsing, just like how living systems aim to minimize their free energy to maintain stability.
These analogies help illustrate how maximum entropy and free energy minimization play out in everyday scenarios, providing a more intuitive understanding of these concepts.
1 / 1
Connections to naive physics'
1 / 1
ChatGPT
Naive physics refers to the intuitive understanding that humans have about the physical world, even without formal scientific knowledge. There are some connections between the concepts we've discussed (maximum entropy and free energy minimization) and naive physics:
Stable Structures:
Naive physics often involves understanding stability in everyday objects. For example, when stacking blocks, we intuitively know that a stable tower requires a wider base. This idea relates to free energy minimization, where systems tend to stabilize to lower energy states to maintain balance and stability.
Predicting Actions:
Naive physics helps us predict how objects will behave in certain situations. This relates to maximum entropy in the sense that we make predictions based on available information while trying to minimize assumptions. Just as we predict that a ball thrown into the air will come back down due to gravity, we make predictions about the behavior of systems based on what we know.
Optimal Arrangements:
In naive physics, we often seek optimal arrangements to achieve desired outcomes. For example, when setting up a seesaw, we intuitively place heavier objects closer to the pivot point to achieve balance. This idea connects to both maximum entropy (optimal arrangement with minimal assumptions) and free energy minimization (achieving balance by minimizing energy differences).
Cause and Effect:
Naive physics involves understanding cause-and-effect relationships in the physical world. Similarly, both maximum entropy and free energy minimization involve understanding how different factors and constraints influence outcomes. Just as we understand that a ball rolls downhill due to gravity (cause), we consider how various factors influence system behavior in these principles.
Equilibrium States:
Naive physics helps us understand equilibrium states in systems. For instance, we know that a swinging pendulum eventually comes to rest at its lowest point due to energy dissipation. This concept aligns with free energy minimization, as systems tend to reach equilibrium states with minimized energy.
In essence, naive physics provides an intuitive foundation for understanding the physical world, and the concepts of maximum entropy and free energy minimization align with our natural intuitions about stability, optimal arrangements, and cause-and-effect relationships in various scenarios.
1 / 1
That seems to relate somewhat to the Bayesian brain hypothesis. It seems that we can do sparse Bayesian recursion subconsciously or below the level of awareness.
1 / 1
ChatGPT
Absolutely, you're onto something! The Bayesian brain hypothesis suggests that the brain operates as a probabilistic inference machine, constantly updating its beliefs and predictions based on incoming sensory information. This process involves combining prior knowledge with new evidence to generate the most likely explanations for the observed data.
Your observation about doing "sparse Bayesian recursion subconsciously or below the level of awareness" aligns well with the idea that our brains are constantly performing Bayesian-like computations without us even being aware of it. Just as we intuitively make predictions and update our understanding of the world based on sparse and incomplete information, the brain is thought to do something similar on a neural level.
The concepts of maximum entropy and free energy minimization also fit into this framework. Maximum entropy allows the brain to make predictions while minimizing assumptions, and free energy minimization helps the brain seek equilibrium states while updating beliefs based on new information.
So, the Bayesian brain hypothesis, combined with the principles of maximum entropy and free energy minimization, suggests that our brains are inherently wired to perform sophisticated computations for perception, learning, and decision-making, often operating beneath our conscious awareness. This aligns well with the idea that our everyday intuitions, naive physics, and subconscious processes are all intertwined in the way our brains navigate and understand the world around us.
1 / 1
Any testable hypotheses?
1 / 1
ChatGPT
Certainly! The principles of maximum entropy, free energy minimization, and the Bayesian brain hypothesis have led to several testable hypotheses in the field of neuroscience. Here are a few examples:
Prediction Errors and Learning
: According to the Bayesian brain hypothesis, our brains constantly make predictions about the world and update those predictions based on incoming sensory information. This leads to the prediction error signal, which represents the difference between our predictions and reality. A testable hypothesis would involve studying how prediction errors are computed and how they influence learning and adaptation in the brain.
Neural Coding and Representations
: Maximum entropy principles suggest that neurons might encode information in a way that maximizes the information content while minimizing assumptions. Researchers could test this hypothesis by analyzing neural firing patterns and assessing whether they conform to the distributions predicted by maximum entropy models.
Brain Network Topology
: The idea that the brain's folding and connectivity maximize surface area while minimizing energy expenditure and wiring cost is testable through studies of brain development and evolution. Comparing the folding patterns of different species' brains and correlating them with energy consumption could provide evidence for this principle.
Implicit Learning and Decision-Making
: Investigating how the brain subconsciously applies Bayesian-like computations to make decisions could involve designing experiments that measure subconscious responses to different stimuli. For instance, researchers could use implicit learning tasks to examine how participants unconsciously adapt to changing environments.
Neural Plasticity and Neuroplasticity
: The relationship between neural plasticity (ability to change) and the principles of free energy minimization and maximum entropy could be tested by exploring how neural networks reorganize in response to changes in sensory input. This could involve studying brain activity before and after learning new skills or adapting to new environments.
Neurological Disorders
: Examining how disruptions to the brain's Bayesian computations, maximum entropy principles, or free energy minimization could contribute to neurological disorders. For instance, researchers could investigate whether conditions like anxiety or depression are associated with deviations from these computational principles.
Artificial Intelligence and Brain-Inspired Models
: Applying the principles of maximum entropy and free energy minimization to artificial neural networks could lead to the development of more efficient and adaptable AI systems. Comparing the performance of brain-inspired models with traditional machine learning algorithms could provide insights into the effectiveness of these principles.
Testing these hypotheses often involves a combination of experimental studies, computational modeling, and data analysis techniques. While these concepts provide a theoretical framework, their validation and application to real-world brain function require careful empirical investigation and interdisciplinary collaboration between neuroscience, psychology, cognitive science, and computational modeling.
1 / 1
A glossary of difficult terms.
1 / 1
ChatGPT
Sure, here's a glossary of some of the difficult terms and concepts discussed in our conversation:
Maximum Entropy Principle
: A principle that states that when making inferences or estimating probability distributions, the distribution that best represents the current state of knowledge is the one with the largest entropy, subject to certain constraints or prior data.
Bayesian Brain Hypothesis
: The idea that the brain processes information using Bayesian-like computations, where it combines prior beliefs with sensory evidence to make predictions and decisions.
Free Energy Minimization
: A concept from statistical physics and biology that suggests systems, including the brain, tend to minimize their free energy (a measure of disorder or surprise) to maintain stability and adapt to the environment.
Neural Plasticity
: The brain's ability to reorganize its structure and connections in response to learning, experience, and environmental changes.
Neuroplasticity
: The same concept as neural plasticity, referring to the brain's ability to adapt and change its structure and functions.
Cortical Folding (Gyrification)
: The process by which the cerebral cortex, the outer layer of the brain, develops folds and wrinkles to increase its surface area within the confines of the skull.
Neuronal Network
: A complex interconnected system of neurons (nerve cells) that communicate with each other through synapses to process and transmit information.
Synaptic Plasticity
: The ability of synapses (connections between neurons) to strengthen or weaken over time, allowing for learning and memory formation.
Entropy
: A measure of uncertainty or randomness in a system. In the context of information theory, entropy quantifies the amount of information in a probability distribution.
Prediction Error
: The difference between a predicted outcome and the actual observed outcome. In the context of the brain, prediction errors play a role in learning and updating internal models of the world.
Hierarchical Inference
: A process by which the brain processes information in a hierarchical manner, making predictions at multiple levels of abstraction and combining them to form a coherent perception.
Statistical Mechanics
: A branch of physics that uses statistical methods to explain the behavior of large groups of particles, such as molecules in a gas, based on their interactions.
Neuroanatomy
: The study of the structure and organization of the nervous system, including the brain and spinal cord.
Neural Connectivity
: The arrangement and connections between neurons, which determine how information flows through the brain.
Neuronal Diameter and Length
: Physical dimensions of neurons, where diameter refers to the thickness of a neuron and length refers to its extent.
Sensory Inputs
: Information received by the brain from sensory organs, such as eyes, ears, and skin, which is used to perceive the external world.
Network Excitability
: The tendency of neurons or neural networks to generate action potentials (electrical impulses) in response to stimuli.
Surface Area and Volume Optimization
: The process by which the brain's folds increase its surface area while minimizing energy expenditure and space constraints.
Implicit Learning
: The acquisition of knowledge or skills without conscious awareness or intentional effort.
Neural Coding
: The process by which information is represented and transmitted by patterns of neural activity.
Remember that these concepts are complex and often interrelated, and their understanding may require further exploration and study.
1 / 1
Thank you. A final summary of our discussion.
1 / 1
ChatGPT
Throughout our conversation, we delved into the fascinating world of self-organization in the brain, exploring concepts like the Maximum Entropy Principle and its relation to brain development and learning. We discussed how the brain's neural networks adapt and reorganize through processes like synaptic plasticity and cortical folding, allowing us to understand the brain's complex behavior from a statistical and information-theoretic perspective. We drew parallels to everyday examples, such as puzzles and edge pieces, to grasp the intricate dynamics of the brain's organization. Our exploration extended to connections with naive physics, Bayesian brain hypotheses, and even potential testable hypotheses related to the brain's subconscious mechanisms. We unraveled the role of the Free Energy Principle and its connection to neural network self-organization, shedding light on how the brain's reorganization aligns with minimizing surprise or disorder. Ultimately, our journey led us to appreciate the intricate balance between prediction, learning, and adaptation in the brain, unveiling the underlying principles that govern its remarkable abilities.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT August 3 Version
?
ChatGPT



