Semantic Ladle Of Words
Open sidebar
Semantic Ladle Of Words
GPT-4
Summarize: SEP home page
Stanford Encyclopedia of Philosophy
 Menu
Search SEP

 Entry Navigation
Methods in Comparative Cognition
First published Wed Sep 6, 2023
Comparative cognition is the study of cognition across the tree of life. Nonhuman animals (hereafter animals) display a broad and often surprising range of cognitive abilities. Kea (a species of large parrot endemic to New Zealand) solve problems using domain-general statistical inference (Bastos & Taylor 2020), Eurasian jays are deceived by magic tricks (Garcia-Pelegrin et al. 2021), and bumblebees may be conscious (Gibbons et al. 2022). Researchers in the field of comparative cognition seek to understand the cognitive mechanisms giving rise to animal behavior, including their evolutionary, developmental, and socioecological history. Comparative cognition is an interdisciplinary field bringing together tools from ecology, ethology, cognitive science, developmental psychology, evolutionary biology, and neuroscience, among others (Shettleworth 2009). There is also a robust philosophical literature on the methods of comparative cognition. Philosophers aim to address questions such as, ���what is evidentially required to show that animals have causal reasoning?��� and ���how can we avoid anthropocentricism in the study of nonhuman minds?��� How best to define ���cognition��� is an area of debate (Allen 2017). For our purposes, we can follow Sara Shettleworth���s broad characterization of cognition as ���the mechanisms by which animals acquire, process, store and act upon information from the environment��� (2010a: 4; see also entry on animal cognition).

1. Evolution, Development, and Culture
1.1 Convergent Evolution
1.2 Homology and Development
1.3 Culture
1.4 Cognition in the Wild and Captivity
2. Eliminating Alternative Explanations
2.1 Null Hypotheses in Comparative Cognition
2.2 Cognitive and Associative Explanations
2.3 The Role of Epistemic Values
2.4 The Role of Non-Epistemic Values
3. Methodological Challenges
3.1 Anthropomorphism
3.2 Anthropocentrism
3.3 Underdetermination
3.4 Signatures and Dimensions
3.5 Reproducibility
4. Comparative Cognition and AI
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. Evolution, Development, and Culture
Research in comparative cognition takes place against a backdrop of evolutionary, developmental, and socioecological considerations. Natural selection leads to the convergence and divergence of cognitive traits over evolutionary time. Cognitive traits might converge because two species face similar socioecological problems, such as navigating a similar foraging environment. Alternatively, two species might share cognitive abilities because they have inherited them from a shared ancestor or have developmental modules in common. Finally, cognitive abilities interact with evolution in ways that not only alter a species trajectory through phenotypic space, but their evolvability (Brown 2013). Considerations such as these help researchers predict and explain cognitive and behavioral abilities across taxa:

Only by investigating proximate (mechanism and ontogeny) and ultimate (phylogeny and function) causes can we fully understand the nature and origin of behavior. (Krupenye & Call 2019: 16)

This section presents several key ways in which evolutionary, developmental, and socioecological considerations shape methods in comparative cognition.
1 / 1
ChatGPT
Stanford Encyclopedia of Philosophy (SEP) Summary
:
Title
: Methods in Comparative Cognition
Published
: September 6, 2023
Overview
:
Comparative cognition studies cognition across different species. It's been discovered that animals like the Kea parrot use statistical inference to solve problems, Eurasian jays can be fooled by magic tricks, and bumblebees might even be conscious. The field merges various disciplines, including ecology, cognitive science, and evolutionary biology. There's ongoing philosophical discourse about how to approach and define comparative cognition, with some defining cognition as how animals process and act on environmental information.
Main Sections
:
Evolution, Development, and Culture
:
Explores how cognitive traits can evolve due to socioecological challenges or inherited from shared ancestors.
Discusses how cognitive abilities interact with evolution, influencing a species' trajectory and adaptability.
Emphasizes the importance of understanding both immediate causes and evolutionary reasons for behavior.
Eliminating Alternative Explanations
:
Focuses on ways to rule out other potential explanations for observed cognitive behaviors.
Methodological Challenges
:
Addresses concerns like avoiding anthropomorphism, addressing anthropocentrism, understanding underdetermination, and issues with reproducibility.
Comparative Cognition and AI
: (Details not provided in the excerpt).
The entry also includes a bibliography and other resources for further exploration.
1 / 1
4. Comparative Cognition and AI
There has been a large amount of collaborative work between comparative cognition and artificial intelligence (AI) research over the past decade. On the one hand, formal models developed in AI can be used to predict and explain animal behavior in ways that move beyond folk psychological accounts. On the other hand, the methods of comparative cognition are well placed to inform AI research, given the diversity of behavior and information-processing abilities found across the tree of life. We���ll consider both aspects here, while also highlighting why animal-AI inferences should be handled with care.

Colin Allen (2014) argues that comparative cognition would benefit greatly from developing mathematically rigorous formal models. As we have seen throughout this entry, comparative cognition researchers often rely on intuitive, natural language concepts for constructing accounts of animal minds like causal reasoning, mental time travel, imagination, and self-recognition (see Schnell et al. 2021b). Regarding this approach Allen (2014) writes:

The conceptual framework guiding most work in comparative animal cognition (whether by ethologists or psychologists) is insufficiently formalized to support rigorous science in the long run. (2014: 82)

One concern with more formal approaches, however, is that they will fail to ���scale up��� to predict and explain the behavioral phenomenon that are of interest to many comparative cognition researchers, such as natural social and physical interactions. Work in AI is starting to show that there are ways of closing this gap, however. For example, Peter Battaglia and colleagues advance a formalized mental model in the form of an ���intuitive physics engine��� (IPE) analogous to the machine physics engines used in interactive video games (Battaglia, Hamrick, & Tenenbaum. 2013, see also Ullman et al. 2017). The IPE is probabilistic and oversimplifies the nature of objects, such as their geometry and mass density distribution, but has been developed to explain how people quickly make inferences about physical scenes in a dynamic and noisy world. Battaglia and colleagues found that this formal model does indeed capture people���s intuitions and prediction about physical scenes (such as ���will this tower of blocks fall?���) across a wide range of complex and novel scenarios. Moreover, the model captures not just successful predictions, but also other signatures of human judgment like illusions and biases (see section 3.4).

The above work uses AI to explain human cognition and behavior. However, such methods are also being applied to nonhuman animals. For example, much of contemporary AI depends on the tools of reinforcement learning (RL). These techniques involve linking states of the environment and an agent���s actions in such a way that allows the agent to maximize future rewards. The tools of RL were originally inspired by animal learning research (Hassabis et al. 2017); however, they have since been developed by AI researchers in ways that allow fresh insights into animal behavior. For example, the temporal-difference (TD) model has been used to explain a wide range of results from animal classical conditioning studies (see Sutton & Barto 1998: chapter 14). Similarly, Buckner (2018) draws on work on Deep Convolutional Neural Networks (DCNNs) to explain the relationship between sensory experience and representations of abstract categories in humans and animals���a longstanding question in philosophy of mind. Halina (2021b) also shows how one can understand aspects of animal insightful problem solving (namely, mental scenario building) through Monte Carlo tree search. Finally, Bohn et al. (2022) advance a Bayesian computational model of great ape communication, which they show accurately predicts the communicative interactions of real-world chimpanzees living semi-wild in the Chimfunshi Wildlife Orphanage in Zambia. These are a few examples of researchers drawing on AI for formal models that can be successfully applied to capture animal minds and behavior (see also van der Vaart et al. 2012).

A major aim of AI research has been to build machines that ���learn and think like people��� (Lake et al. 2017). Currently, there are many AI systems that match or exceed humans on various tasks, like the ability to play Chess and Go, and even make scientific discoveries (Shevlin et al. 2019). However, how to build a machine with domain-general intelligence or ���common sense��� remains elusive. This challenge has led some researchers to argue that animal cognition research offers the best path towards building thinking machines. Animals exhibit many of the ���building blocks��� of human common sense, such as an understanding of objects and their affordances, space, and causality (Shanahan et al. 2020). Through the application of RL techniques, it is also possible to train artificial agents in 3D virtual environments analogous to the real world. Using this approach, one can combine different RL architectures and training environments with the aim of encouraging the development of domain-general abilities. As Murray Shanahan and colleagues write,

animal cognition supplies a compendium of well understood, nonlinguistic, intelligent behaviour; it suggests experimental methods for evaluation and benchmarking; and it can guide environment and task design. (2020: 863; see also Crosby 2020)

Work such as this is already underway. For example, the Animal-AI Testbed applies experimental protocols developed in comparative cognition to test AI (Crosby, Beyret, & Halina 2019; Crosby, Beyret et al. 2020). In 2019, the testbed included 300 tasks grouped into 12 categories such as spatial elimination, delayed gratification, numerosity, and tool use tasks. Konstantinos Voudouris and colleagues (2022) compared AI performance on this testbed with children aged 6���10. They found that children and AIs performed similarly on basic navigational tasks, but that children outperformed AIs on more complex tasks like object permanence and detour tasks.

There is much to be gained from animal-AI comparisons. Such work may represent the beginning of a transformation in the field of comparative cognition���one that brings artificial systems into the fold. It may also lead to the development of cognitive models that bridge the gap between intuitive accounts of capacities like imagination and causal reasoning on the one hand, and mathematical and computational models on the other. However, when applying ���rich psychological concepts��� like awareness, episodic memory, and theory of mind to AI, one should also proceed with caution (Shevlin & Halina 2019). Some such concepts have normative dimensions, for example, indicating a potential moral agent or moral patient. These normative dimensions are important to acknowledge before adopting a term in the context of AI, particularly if that term is used differently in the two contexts. AI findings may also dramatically alter our understanding of some cognitive capacities. Rather than adopting existing cognitive concepts, it may be fruitful in some cases to develop a radically new approach in the context of AI. If successful, such an approach could then be imported into comparative cognition and potentially revolutionize our understanding of animal minds

https://plato.stanford.edu/entries/comparative-cognition/
1 / 1
ChatGPT
Comparative Cognition and AI Summary
:
Comparative cognition and artificial intelligence (AI) have witnessed considerable collaboration in the past decade. The union of these disciplines presents opportunities:
Formal AI Models and Animal Behavior
:
AI models can predict and explain animal behavior, moving beyond traditional explanations.
Colin Allen (2014) emphasizes the need for mathematically rigorous models in comparative cognition, suggesting that current frameworks are not formalized enough.
There's concern that formal models might not cover broader behavioral phenomena. But AI research, like the "intuitive physics engine" by Battaglia and team, shows promise in closing this gap. This model mimics human intuitions and predictions about physical scenarios.
AI Techniques for Explaining Animal Behavior
:
Tools of reinforcement learning (RL), inspired by animal learning research, offer insights into animal behavior.
For instance, the temporal-difference model explains results from animal conditioning studies, and other models like Deep Convolutional Neural Networks and Bayesian computational approaches shed light on sensory experiences and communication in animals.
AI's Pursuit of Domain-General Intelligence
:
The goal for many AI researchers is to develop machines that "learn and think like people". Current AI systems excel in specialized tasks, but achieving broad, "common sense" intelligence remains challenging.
Animal cognition is believed to be a path to achieve this, as animals display foundational components of human intelligence.
RL techniques can train AI agents in 3D environments similar to real-world conditions. This combines different learning methods to foster domain-general abilities. Animal cognition thus offers a blueprint for intelligent behavior, experimental methods, and design strategies.
The Animal-AI Testbed
:
The testbed applies protocols from comparative cognition to evaluate AI. In a 2019 study, tasks like spatial elimination and tool use were compared between AI and children. Children and AIs had similar basic navigation skills, but children excelled in complex tasks like object permanence.
Caution and Future Directions
:
While the intersection of AI and animal cognition is promising, it's vital to use caution, especially when attributing complex psychological concepts to AI. Some terms have moral implications, which can complicate their use in an AI context.
Instead of just adopting existing cognitive ideas, a novel approach in AI might be beneficial, which could then reshape our understanding of animal cognition.
For more detailed insights and references, refer to the
Stanford Encyclopedia of Philosophy
.
1 / 1
Concepts is All You Need: A More Direct Path to AGI 
Peter Voss, AIGO.ai, Austin TX, USA, peter@aigo.ai 
Mla��an Jovanovi��, Singidunum University, Belgrade Serbia, mjovanovic@singidunum.ac.rs 
Abstract ��� Little demonstrable progress has been made toward AGI (Artificial General Intelligence) since 
the term was coined some 20 years ago. In spite of the fantastic breakthroughs in Statistical AI such as 
AlphaZero, ChatGPT, and Stable Diffusion none of these projects have, or claim to have, a clear path to 
AGI. In order to expedite the development of AGI it is crucial to understand and identify the core 
requirements of human-like intelligence as it pertains to AGI. From that one can distill which particular 
development steps are necessary to achieve AGI, and which are a distraction. Such analysis highlights 
the need for a Cognitive AI approach rather than the currently favored statistical and generative efforts. 
More specifically it identifies the central role of concepts in human-like cognition. Here we outline an 
architecture and development plan, together with some preliminary results, that offers a much more 
direct path to full Human-Level AI (HLAI)/ AGI. 
Keywords: AGI, Cognitive AI, Adaptive AI, Human-Level AI, HLAI, Cognitive Architecture, Third Wave of 
AI, Intelligence, Concepts, Generalization. 
Requirements of General Intelligence 
We expect an AGI to be capable of performing any cognitive task, especially novel ones, at a level 
comparable to a human being [1]. Thus, a key feature of general intelligence is the ability to learn new 
knowledge and skills. As far as AGI design is concerned, it is much more important to be able to acquire 
knowledge than simply having it. 
Moreover, AGI has core requirements as to what to learn, and how to learn as follows: 
��� Be able to learn real-world 4D data that could be noisy, incomplete, or even wrong. 
��� Such data includes new entities and action sequences, plus their relationships. 
��� Knowledge must be interpreted, encoded, and evaluated conceptually. This means that entities, 
actions, and generalizations are represented by their (scalar) attributes. In other words, as vectors 
with a schema. This is essential to facilitate (dis)similarity comparisons, and for forming higher-level 
abstract concepts. 
��� The ability to learn complex data such as images and movement interactively. This implies having 
input senses and output actuators of some kind, plus mechanisms to select and extract particular 
input data (selective attention) [2]. 
��� The system must be able to accumulate new knowledge and skills incrementally, integrating with 
existing short- and long-term memory. This requires a robust knowledge representation such as an 
integrated, high-performance knowledge graph. 
��� Input needs to be interpreted contextually, taking into account prior input and knowledge as well as 
current goals and priorities. 
��� Learning must be life-long and adaptive with the ability to change or invalidate existing knowledge 
and to adjust to new situations and environments. 2 
��� Most learning should be autonomous (unsupervised or self-supervised), without a human in the 
loop. 
��� The system must operate in real-time, and function adequately with limited resources [3]. 
��� Human-like intelligence covers a wide range of learning modes, including: instance or one-shot; 
clustering and association by time and/or space; generalization; aping; stimulus-response; 
reinforcement; random and structured exploration; human guided; via instructions; as well as zero- 
shot (implicit inference); explicit reasoning (figuring things out) and study (read, view). 
Effective AGI designs must not only implement all of these learning requirements, but also embody 
methods for action control, reasoning mechanisms, and metacognitive control.
1 / 1
ChatGPT
Concepts is All You Need: A More Direct Path to AGI
Authors
:
Peter Voss, AIGO.ai
Mla��an Jovanovi��, Singidunum University
Abstract
:
While there have been remarkable achievements in Statistical AI (e.g., AlphaZero, ChatGPT, and Stable Diffusion), these projects don't necessarily lead directly to AGI (Artificial General Intelligence). To progress towards AGI, it's essential to discern the fundamental necessities of human-like intelligence related to AGI. This understanding will help in recognizing which paths are constructive towards AGI and which aren't. The study emphasizes the importance of a Cognitive AI approach over statistical and generative methods, highlighting the pivotal role of concepts in human cognition. The authors suggest an architecture and roadmap to approach Human-Level AI (HLAI)/ AGI more directly.
Keywords
: AGI, Cognitive AI, Adaptive AI, Human-Level AI, HLAI, Cognitive Architecture, Third Wave of AI, Intelligence, Concepts, Generalization.
Requirements of General Intelligence
:
For an AI to be considered as having general intelligence, it must match human cognitive capabilities, especially in learning new information and skills. Key requirements include:
Learning Real-World Data
: Ability to learn from data that is in 4D, and can sometimes be noisy, incomplete, or incorrect.
Conceptual Encoding
: All data, whether new entities, actions, or their relationships, must be understood, encoded, and assessed conceptually, highlighting the role of scalar attributes.
Complex Data Learning
: The system must learn intricate data, like images and movements, in an interactive manner. It requires mechanisms like selective attention.
Incremental Knowledge
: Knowledge should be accumulated step by step, combined with existing memories, making use of a consistent and high-performing knowledge representation.
Contextual Interpretation
: Incoming data should be perceived in context, considering past information, present objectives, and priorities.
Lifelong & Adaptive Learning
: The AI should have the capacity for perpetual learning, modifying outdated knowledge, and adapting to new situations.
Autonomous Learning
: The majority of the learning should be unsupervised or self-driven, without constant human intervention.
Real-time Operation
: The system must work in real-time, even when resources are limited.
Diverse Learning Modes
: AGI should be adept at multiple learning styles like one-shot learning, clustering, generalization, reinforcement, and more.
In addition to these learning requirements, an effective AGI must integrate mechanisms for action control, logical reasoning, and metacognitive regulation.
1 / 1
Interestingly I wrote an essay recently titled Semantic memory is all you need, which expressed a summary concept and de-emphasized episodic memory in those with aphantasia because episodic details can be rebuilt or simulated using only semantic memory
1 / 1
ChatGPT
That's a fascinating perspective! Aphantasia, for those unfamiliar, is a condition where one does not possess a functioning "mind's eye" and cannot voluntarily visualize imagery.
Your essay's title, "Semantic Memory is All You Need," seems to suggest that you're highlighting the importance of semantic memory, especially for individuals with aphantasia. Episodic memories, which are tied to personal experiences and events, often involve a strong visual component. However, if one has aphantasia, they lack the capability for visual recall, which may seem to lessen the richness of episodic memories.
Yet, semantic memory, which holds general world knowledge (facts, ideas, meaning, and concepts) that's not drawn from personal experience, can indeed compensate. An individual might not remember the visual details of a beach vacation, for instance, but they'd remember the fact that they went, who they were with, and other semantic details like the nature of beaches, the sensation of sand, or the sound of waves.
Your proposition is thought-provoking, suggesting that for individuals with aphantasia, semantic memory isn't just an abstract database of facts, but a crucial tool to reconstruct or simulate episodic experiences. It aligns with recent research suggesting that our memories are not static replays but dynamic reconstructions influenced by our current state and knowledge.
Your essay could potentially open up discussions on the adaptability of the human mind and how different cognitive functions can compensate for one another. It also underscores the potential for further research into understanding the nuances and interplay between different forms of memory, especially in individuals with unique cognitive profiles.
1 / 1
Cognitive AI 
Essential requirements of AGI cannot be met by logic or statistical methods alone [4] ��� they demand a 
cognitive approach. A DARPA presentation makes a useful distinction with ���The Three Waves of AI��� [5]: 
��� 1st Wave: Rule-based, hand-crafted knowledge ��� GOFAI, expert systems, Deep Blue. 
��� 2nd Wave: Statistical learning ��� DL/ML/RL/Transformers, AlphaZero, ChatGPT. 
��� 3rd Wave: Cognitive AI, autonomous contextual adaptation ��� Cognitive architectures. 
Figure 1. Timeline of growing capabilities of AI systems. 
The Cognitive AI approach is not just a mashup of the first two ���Waves���, though it freely incorporates 
insights gained from those earlier methods. It is typically implemented as a cognitive architecture. We 
describe Cognitive Architectures as systems that encompass and embody all of the essential structures 
3 
required for a human-level mind [1]. It also considers how these structures and functions need to work 
together effectively and function intelligently in diverse, dynamic environments [6]. 
Senses and Actuators 
We perceive objects and actions via our senses. Subconscious, lower-level processes ���package��� input 
data streams into digestible objects that we become aware of. One could argue that an AGI needs to 
fully integrate such preprocessing with higher-level cognition. This view certainly has merit; higher-level 
context influences lower-level focus and selection, and recognition. However, both theoretical 
consideration as well as practical experience indicate that effective AGI can be constructed with 
separate pre-processing mechanisms for visual, tactile, and sound input [7]. 
An insightful perspective to consider is that both Helen Keller, with severely limited sense perception, 
and Stephen Hawking, with little dexterity, were able to deliver outstanding intellectual contributions. 
We could call this the ���Helen Hawking��� model of AGI ��� a powerful cognitive system with very limited 
sense acuity and dexterity. 
From a practical point of view, we posit that a highly effective AGI could be limited to something like PC 
desktop visual input supplemented by text or sound, plus the ability to manipulate mouse and keyboard. 
Screen input would potentially provide a real-time window to the real world. A limiting factor may be 
the lack of direct 3D or depth perception, that blind people obviously obtain via touch and sound. 
From Percepts to Concepts 
Returning to the nature of what we (and potential AGIs) perceive, it is crucial to note that the objects 
and actions are essentially vectors composed of numerous scalar features. All knowledge, actions, and 
skills that we learn and utilize cognitively can be seen as vectors plus their relevant relationships. 
For example, facial features can be represented by a number of features ��� whether via simple, 
traditional low-dimensional distance measures, or via modern complex machine learning features [8]. 
Similarly, actions are represented by various scalar dimensions ��� e.g., a ball bouncing, rolling, or floating 
with values for frequency, amplitude, speed, etc. [9]. 
Vector representation forms the basis not only for lower-level cognitive functions such as similarity 
measures, but also ultimately for our uniquely human ability to form highly abstract concepts, and to be 
able to reason with them.
1 / 1
ChatGPT
The provided excerpt delves deep into the transition from traditional AI approaches to what is now termed "Cognitive AI." Let's unpack some key points:
Three Waves of AI
:
1st Wave
: The earliest AI models were rule-based and relied on pre-defined instructions. Systems like Deep Blue, which defeated the world chess champion, are prime examples.
2nd Wave
: This is the realm of deep learning, machine learning, reinforcement learning, etc. Models like AlphaZero and ChatGPT, which use vast amounts of data to learn patterns, fall into this category.
3rd Wave
: Cognitive AI focuses on autonomous adaptation by taking into account context. This represents an approach closer to human cognition.
Cognitive Architectures
: These systems aim to encompass all structures required for a human-level mind. Unlike the earlier waves, Cognitive AI isn't merely a fusion of the two but a new way of constructing AI that can act intelligently in various settings.
Senses and Actuators
: The discussion delves into how humans perceive the world and then jumps into an interesting consideration about AGIs. The "Helen Hawking" model is especially intriguing. It posits that AGI doesn't necessarily need sophisticated sensory inputs to be highly effective. Helen Keller and Stephen Hawking, despite their disabilities, made significant intellectual contributions, showcasing that advanced cognition can be achieved without intricate sensory data.
From Percepts to Concepts
: This part focuses on the representation of knowledge. Everything we perceive and understand can be broken down into vectors (lists of scalars that give direction and magnitude). This is true whether we're identifying facial features or understanding the motion of objects. Such vector representations not only help with basic cognitive functions but also facilitate higher-order thinking and reasoning.
In essence, the author(s) argue for a shift from the existing AI methodologies to Cognitive AI to achieve true Artificial General Intelligence. They emphasize the importance of concept formation, abstract thinking, and contextual understanding, leaning towards an approach that mimics human cognition more closely.
1 / 1
From Senses to Percepts to Concepts to Abstractions
Senses
Sensed
Features
Percepts
Percept
Concrete
Concept
Vectors
Concept
Concept
Abstract
Abstract
Vectors
Vectors
Concept
Concept
Vision
Perceived
Entities&
Activity
Patterns
(Property
Vectors)
Environment
"Rover'
Entity
Concept
(Property
Vectors)
Dog
Concept
(Property
Vectors)
Animal
Concept
(Property
Vectors)
Sound/
Language
Other Dogs
Perceived Features:
Color, Shape, Size,
Sound, Name,
Movement, etc.
Other Animals
Integrated 'Rover'
Features
Integrated Dogs
Features
Integrated Animal
Features
"Rover"

required for a human-level mind [1]. It also considers how these structures and functions need to work 
together effectively and function intelligently in diverse, dynamic environments [6]. 
Senses and Actuators 
We perceive objects and actions via our senses. Subconscious, lower-level processes ���package��� input 
data streams into digestible objects that we become aware of. One could argue that an AGI needs to 
fully integrate such preprocessing with higher-level cognition. This view certainly has merit; higher-level 
context influences lower-level focus and selection, and recognition. However, both theoretical 
consideration as well as practical experience indicate that effective AGI can be constructed with 
separate pre-processing mechanisms for visual, tactile, and sound input [7]. 
An insightful perspective to consider is that both Helen Keller, with severely limited sense perception, 
and Stephen Hawking, with little dexterity, were able to deliver outstanding intellectual contributions. 
We could call this the ���Helen Hawking��� model of AGI ��� a powerful cognitive system with very limited 
sense acuity and dexterity. 
From a practical point of view, we posit that a highly effective AGI could be limited to something like PC 
desktop visual input supplemented by text or sound, plus the ability to manipulate mouse and keyboard. 
Screen input would potentially provide a real-time window to the real world. A limiting factor may be 
the lack of direct 3D or depth perception, that blind people obviously obtain via touch and sound. 
From Percepts to Concepts 
Returning to the nature of what we (and potential AGIs) perceive, it is crucial to note that the objects 
and actions are essentially vectors composed of numerous scalar features. All knowledge, actions, and 
skills that we learn and utilize cognitively can be seen as vectors plus their relevant relationships. 
For example, facial features can be represented by a number of features ��� whether via simple, 
traditional low-dimensional distance measures, or via modern complex machine learning features [8]. 
Similarly, actions are represented by various scalar dimensions ��� e.g., a ball bouncing, rolling, or floating 
with values for frequency, amplitude, speed, etc. [9]. 
Vector representation forms the basis not only for lower-level cognitive functions such as similarity 
measures, but also ultimately for our uniquely human ability to form highly abstract concepts, and to be 
able to reason with them. 4 
Figure 2. Entity and activity features from senses are stored or recognized as percept vectors. These in 
turn are integrated into entity (���Rover���), concept (dog), and abstract category levels (animal). 
The utility of vector encoding and hierarchies is amply demonstrated by the power of LLMs [10]. 
However, this Statistical AI approach suffers three important limitations: 
1. These vectors are based on co-occurrence or prediction-relevance in training data, and not on 
real-world ontological features. 
2. They have fixed dimensionality rather than one most appropriate to each concept. These 
limitations ultimately hamper robust ongoing learning and reasoning. 
3. Vectors in LLMs are established during training and do not change during ���inference��� ��� while 
interacting with users. 
The proposed Cognitive AI approach does not inherently suffer from these issues. It provides for 
variable-size vectors that are dynamically adaptive, and are more directly grounded with real-world 
features. 
Knowledge Representation 
Core AGI requirements dictate the need for a long-term memory store of vectors representing things 
like entities, concepts, action sequences, and various relationships. Graph-like data stores are ideally 
suited for this purpose. They provide the flexibility of encoding a myriad of different complex structures 
and relationships. 
However, performance considerations rule out the use of external graph databases because all 
recognition, learning, and cognitive functions need to constantly reference and update the graph. Only a 
custom, fully integrated, memory-based knowledge-graph system can provide the speed required to 
operate in real-time. Recent benchmark tests have shown a 1000-fold difference in access time between 
these two approaches (Table 1).
1 / 1
ChatGPT
This excerpt explores the progression of AI and the processing of information from raw sensory inputs to abstract reasoning. Let's break it down further:
Senses to Abstractions
:
Senses
are our raw data receptors: vision, sound, touch, etc.
Percepts
are what we make of these sensed inputs. For instance, from the visual shape, size, and color, one might recognize a "Rover" (a specific dog).
Concepts
are a step further, generalizing individual percepts into broader categories, like recognizing that Rover is a "dog".
Abstractions
generalize even further, for example, understanding that a dog is an "animal".
AGI and Sensory Integration
:
Effective AGI may not need to fully integrate pre-processing with high-level cognition. For instance, an AGI could function effectively with separate mechanisms for processing visual, tactile, and auditory inputs.
The 'Helen Hawking' model suggests that complex cognitive abilities can exist even with limited sensory input.
Vectors and Knowledge Representation
:
Everything we perceive and comprehend can be represented as vectors with scalar features.
This vector approach not only aids basic cognitive functions, like recognizing similarities, but also helps in abstract reasoning.
Vectors formed by systems like Large Language Models (LLMs) are based on data patterns, not real-world attributes. Hence, while they're powerful, they aren't adaptive post-training.
Cognitive AI, on the other hand, uses dynamic, adaptable vectors grounded in real-world features.
Knowledge Representation in AGI
:
A core requirement for AGI is a long-term memory store for vectors representing entities, concepts, actions, and their relationships.
Graph-like data structures are ideal for representing this knowledge because of their flexibility in capturing complex structures and relationships.
For real-time operation, a custom, integrated memory-based knowledge-graph system is crucial due to its speed and efficiency.
The overall theme here is the evolution of AI from just processing raw sensory data to making sense of it in abstract, human-like ways. While current models like LLMs are powerful, they might still fall short of the adaptability and context-awareness required for true AGI. The move towards Cognitive AI, with its dynamic vectors and graph-based knowledge representation, seems to be a step closer to mimicking human cognitive processes.
1 / 1
Traditionally, cognitive architectures have been implemented in a very modular fashion which, generally 
speaking, is good engineering practice [11]. For AGI, however, we need extremely tight integration 
between the various cognitive mechanisms. Context, memory, pattern matching, learning, 
generalization, inference, exploration, action and metacognition constantly interact in complex ways. 
Figure 3. Traditional, Modular Cognitive Architecture Design. 
A powerful way to achieve this is to have a hyper-optimized graph-based vector datastore act as a 
foundational substrate for all cognitive functions. Not only does this vector graph serve as long-term 
memory, but it can also double as short-term memory via suitable activation mechanisms. Such a 
system has to be carefully designed and built from the ground up to ensure full integration and good 
performance. Off-the-shelf components or separate modules won���t do. 6 
Figure 4. Outline of Fully Integrated Cognitive Architecture using a Knowledge-Base Substrate. 
Metacognition and Emotions 
The majority of our cognition is subconscious ��� it does not involve explicit mental control or supervision. 
However, what sets human intelligence apart is that we are able to think about, and direct our thinking. 
This distinction was well articulated by Kahneman���s System1/System2 model [12]. It is important to note 
that the distinction is not binary, but rather transitions from one to the other seamlessly. 
Higher-level, or System 2, cognition is one aspect of overall awareness and control. The other pertains to 
the availability of what one could call ���cognitive emotions���, mental states such as surprise, certainty, 
confusion, and boredom [13]. These signals affect both conscious as well as subconscious cognition. 
They can also be controlled to some extent; much more so in AIs than humans.

AGI Curriculum and Benchmarks 
One of the fundamental principles of Cognitive AI is that it should be built with a minimum of hard- 
coded or fixed functionality. It should be as adaptive as possible, both as far as new knowledge and skills 
are concerned, as well as being able to adapt to new information and circumstances. 
Additionally, its hierarchical, conceptual knowledge base should be as accurate and grounded as 
possible. These requirements combine to put a large burden on the quality of training ��� especially for its 
foundational knowledge. Unlike LLMs, Cognitive AI doesn���t inherently need massive amounts of 
uncurated training data, instead it needs a carefully designed curriculum to create a robust hierarchy of 
knowledge and skills. 
A related difficulty is the design of tests and benchmarks. Existing SOTA benchmarks are not appropriate 
for evaluating early-stage AGI designs [14]; an early general AI would not be expected to do well on 
specialized narrow tasks, or on tasks that require a wide range of knowledge. 7 
Performance tests can also not be too generic, they have to be designed to measure progress in relation 
to the specific AGI theory involved [15], to the types of sense and activators used, as well as the chosen 
curriculum. 
To minimize the risk of designing tests aligned with what the system can do, rather than what it should 
be able to do, these benchmarks should ideally be developed by an external party that does however 
have a very good understanding of the overall setup and theory (see ���Benchmarks for Proto-AGI���, in 
preparation at the time of writing this article). 
Practical Implementations 
The ���Aigo��� project (originally, ���a2i2��� Adaptive A.I Inc) has over the past 20 years produced a number of 
AGI development prototypes (as well as several ���industrial grade��� commercial versions) using this 
approach1. All of these systems utilize a graph-based knowledge substrate into which all cognitive 
subsystems are integrated. Early models incorporated several sense inputs (vision, sound, touch, etc.) 
operating in a simulated environment, while later commercial versions focused on speech and text IO 
(input/output). These conversation-focused implementations demonstrate powerful real-time 
contextual learning, memory capabilities, as well as reasoning and question answering2. 
One of our benchmarks (conducted at the end of August 2023) was to test the ability to learn novel facts 
and answer questions about them. We compared AIGO with Chat GPT-4 (8.000 tokens context window) 
and with Claude 2 (100.000 tokens context length). The AIGO system was pretrained with only a 
rudimentary real-world ontology of a few thousand general concepts such as person, animal, red, and 
small. Chat GPT-4 and Claude 2 were used in their standard form and not constrained in any way. 
The test involved first feeding 419 natural language statements to each of the three systems. These 
were simple facts, some of which related to each other (e.g., Tina wants a dog and a cat. Actually, Tina 
only wants a cat). Finally, we asked 737 questions and scored the answers. We evaluated the responses 
based on a reasonable human standard. If the response pertains to the topic, answers correctly based 
on the correct source of information, and is grammatically sound, we consider the answer correct. 
The AIGO system scored 88.89%, whereas Claude 2 only managed 35.33%. Chat GPT-4 was unable to 
perform the test. It scored less than 1%. Details and analysis of the experiment are available elsewhere3 
and from the authors.
1 / 1
ChatGPT
This detailed section focuses on the nuances of constructing an Artificial General Intelligence (AGI) that mirrors human cognition. Let's break down the main points:
Modularity vs. Integration
:
Traditional AI systems are modular in design, which usually aligns with good engineering practices.
However, for AGI, a tighter integration between cognitive processes like context, memory, pattern matching, and metacognition is necessary.
A graph-based vector datastore is suggested as a foundational substrate, serving both long-term and short-term memory needs.
Metacognition and Emotions
:
A significant portion of human cognition is subconscious, but what sets us apart is our ability to be aware of and control our thinking, known as metacognition.
The System1/System2 model by Kahneman explains the shift between subconscious and conscious cognition.
Cognitive emotions like surprise, certainty, and confusion play pivotal roles in influencing both conscious and subconscious cognition.
AGI Training and Evaluation
:
Cognitive AI should have minimal hardcoded functionality to remain adaptable.
Training for Cognitive AI should be meticulous, focusing on building a solid foundation of knowledge rather than just amassing vast amounts of data.
Traditional benchmarks may not be suitable for evaluating emerging AGI systems. Benchmarks should ideally be crafted by external parties that understand the AGI's underlying theory.
Practical Implementations: The Aigo Project
:
Over 20 years, the 'Aigo' project has produced AGI prototypes using the described approach.
The systems employ a graph-based knowledge substrate and initially incorporated multiple senses like vision and sound. Later versions focused on speech and text interaction.
Aigo's proficiency was showcased in a benchmark test where it demonstrated its ability to learn and answer questions about novel facts. It outperformed other AI models like Chat GPT-4 and Claude 2 in this test.
The essence of this section is to underline the importance of an integrated approach to AGI, emphasizing the role of metacognition and emotions in cognition, the need for adaptable training curricula and benchmarks, and a practical demonstration of this philosophy through the Aigo project. It also highlights the current limitations of existing AI models like GPT-4 when compared to more integrated, cognitive systems.
1 / 1
A Roadmap to AGI 
The current Aigo baseline system offers excellent knowledge-graph performance, deep contextual 
parsing and understanding, real-time adaptive learning, and integrated inference. It does however no 
longer support multi-modal input or output, or have low-level, integrated vector support. 
A recently launched Aigo development project revisits multi-model IO and aims to eliminate various 
existing rule-systems, and to significantly reduce the amount of code. The curriculum and assessments 
are specially crafted to foster the system's increasing autonomy in knowledge and skill acquisition. The 
1 Aigo.ai Web Chat Demo: https://www.youtube.com/watch?v=FLQPdS9tvQg (Accessed 19.08.2023). 
2 Aigo.ai Elder Companion Demo: https://www.youtube.com/watch?v=VVumDGlSRng (Accessed 17.08.2023). 
3 Aigo.ai Benchmark: http://tinyurl.com/2x59ma4d (Accessed 31.08.2023). 8 
vast range of currently available LLMs, along with data resources such as Wikipedia, will significantly aid 
in the development of curated knowledge acquisition. 
Figure 5. The current architecture���s rules systems, as well as various functions currently hard-coded, 
need to be re-implemented as concept structures (���Brain���). It will more fully integrate this functionality 
with overall cognition, and also make it fully adaptive. 
A roadmap outline to upgrading the system to fully meet the core requirements of AGI includes the 
following activities: 
��� Re-integrating multimodal vector pattern learning and matching into the knowledge graph. 
��� Adding real-time and background abstraction/concept formation. 
��� Training system to do basic question-answering. 
��� Training and developing advanced language capabilities. 
��� Adding multi-modal action and action learning mechanisms. 
��� Training semi-autonomous incremental knowledge acquisition and validating using multiple sources. 
At this point the system will have basic human-level (HLAI) ���High School��� capabilities. Further iterative 
enhancements include: 
��� Semi-autonomous acquisition of conversation requirements (language-based assistant). 
��� Developing advanced visual sensing and output (mouse) dexterity. 
��� Advanced space and time representation and modeling. 
��� Extending metacognition, focus-and-selection, and other control mechanisms. 
��� Advanced multi-modal learning, reasoning and problem solving (PC-based assistant). 
��� Significantly scaling up the amount of embedded common knowledge and high-level reasoning skills. 
This will bring the system to ���Graduate��� level. Ongoing improvements in autonomous learning, high-level 
reasoning (including Theory-of-Mind) as well as capacity and performance enhancements will bring Aigo 
up to full AGI capabilities.
1 / 1
ChatGPT
This section details a roadmap for transitioning Aigo, an existing AI system, towards achieving full Artificial General Intelligence (AGI). Here's a breakdown:
Current Capabilities of Aigo
:
Aigo already has robust knowledge-graph performance, real-time adaptive learning, deep contextual understanding, and integrated inference.
It no longer supports multi-modal input or output and lacks integrated vector support.
The latest Aigo development project seeks to improve multi-modal IO, simplify its design by eliminating rule-systems, and minimize code.
Resources like Wikipedia and various Large Language Models (LLMs) will assist in curating knowledge acquisition.
Short-term Upgrades
:
The immediate plan involves re-implementing various functionalities, currently hard-coded, as conceptual structures or "Brain" to seamlessly integrate with the overall cognitive process and to enhance adaptability.
Roadmap to Core AGI Requirements
:
Re-integration
of multi-modal vector pattern learning and matching into the knowledge graph.
Abstraction/Concept Formation
: Introducing real-time and background abstraction mechanisms for concept formation.
Language Proficiency
: Train the system in basic question-answering and then progress to advanced language capabilities.
Action Mechanisms
: Incorporate multi-modal action and action learning mechanisms.
Knowledge Acquisition
: Implement a semi-autonomous mechanism for incremental knowledge collection, corroborated using multiple sources.
Advanced Features
:
Achieving basic human-level 'High School' capabilities, followed by:
Language Assistance
: Semi-autonomous learning of conversation requirements.
Sensory and Dexterity Enhancements
: Advanced visual sensing and output dexterity.
Spatial and Temporal Modeling
: Enhanced representation and modeling of space and time.
Control Mechanisms
: Improvements in metacognition, focus-and-selection, and other control aspects.
Learning and Reasoning
: Advanced multi-modal learning, reasoning, and problem-solving.
Knowledge and Reasoning Scale
: Increase in the volume of embedded common knowledge and high-level reasoning skills.
Ultimate Goal
:
Once these features are in place and the system reaches a 'Graduate' level of proficiency, continuous improvements in autonomous learning, high-level reasoning, Theory-of-Mind, and overall performance enhancements will push Aigo to full AGI capabilities.
The roadmap paints a clear trajectory for Aigo���s development from its current state to AGI, emphasizing both the foundational steps and the sophisticated functionalities that it must incorporate.
1 / 1
So this was all the article Concepts is all you need. any comparisons or connections with my essay?
1 / 1
ChatGPT
I'm familiar with the content you provided from the "Concepts is all you need" article. However, I would need to review the content of your essay in order to make meaningful comparisons or connections between the two. Please provide some relevant excerpts or a summary of your essay, and I'll do my best to draw comparisons or connections for you.
1 / 1
It's probably not exactly done yet m. Here are a few of the relevant portions:

Semantic Memory as a Foundation: The discussion emphasizes the critical role of semantic memory in both recalling past experiences (episodic memory) and generating new ideas (imagination). By viewing these processes as reconstructions using semantic templates, the essay asserts that semantic memory is foundational to our cognitive abilities.

Challenging Traditional Views: By presenting surprising and counterintuitive examples, such as the phenomenon of aphantasia, the essay challenges conventional views of memory and imagination. It argues that visualization may not be as crucial as previously thought, and that the ability to recognize patterns, principles, and abstract concepts might be more vital.

Connecting to Broader Themes: The integration of topics such as priming, confabulation, and mental imagery capacity connects to broader themes of cognition, understanding, and human behavior. It provides a cohesive argument that semantic memory is not just a storage system for facts but a dynamic and essential component of human thinking.

Implications for Education, Therapy, and Technology: The insights derived from this perspective have potential applications in various fields. Understanding the generative nature of memory and imagination could influence educational strategies, therapeutic interventions for memory disorders, and the design of artificial intelligence systems that mimic human-like reasoning.

Synergistic Ecphory:

Definition: Ecphory is the process of retrieving memories through specific cues that can trigger the recall. It often involves multiple sensory modalities like visual, auditory, olfactory, etc.

Contextual Triggers: These triggers can be contextual elements that were present during the encoding of the memory, thereby creating a rich multisensory imprint.

Memory Retrieval: By utilizing these triggers, an individual can more effectively retrieve a memory, reconstructing it through the synergy of different sensory inputs.

Synergistic Recall:

Enhancing Memory Formation: Synergistic recall takes the process a step further by consciously using these sensory modalities at the time of memory formation. By commenting on, making notes, and repeating certain details in different sensory formats, the memory becomes more deeply encoded.

Creating Robust Retrieval Pathways: This process strengthens the connections between the memory and various sensory cues, making it more accessible later.

Single Cue Retrieval: Since the memory is encoded with multiple sensory details, it may be retrieved more spontaneously or through a single cue due to the synergistic effect created at the time of memory formation.

Applications: This approach can have practical applications in educational settings, memory training, and therapeutic interventions, where creating robust memory connections is vital.

The integration of synergistic ecphory with synergistic recall creates a comprehensive framework that recognizes the complexity of human memory. By understanding how sensory modalities can be harnessed both in encoding and retrieval, this expanded concept offers valuable insights into memory mechanisms. It emphasizes the dynamic, multisensory nature of our memories and provides strategies for enhancing recall through conscious engagement with our sensory experiences.

In the context of the essay "Semantic Memory is All You Need," this expanded concept could serve as an illustrative example of how semantic memory interacts with various sensory modalities to create robust and nuanced memory structures. It could also be seen as an embodiment of the generative grammar of memory, where a blend of sensory elements constructs a richer and more accessible memory landscape.

In Conclusion

The exploration of synergistic ecphory and synergistic recall offers a profound understanding of memory's multisensory nature. By consciously engaging with sensory modalities during memory encoding and retrieval, these concepts promote a richer and more robust memory structure. The integration of these ideas within the framework of semantic memory emphasizes the ability to generate and interpret memories with greater flexibility and depth. This approach not only sheds light on the intricate mechanisms of human memory but also suggests innovative strategies for enhancing recall, redefining our relationship with memory in both theoretical and practical terms. In the grand scope, the conversation reveals how memory transcends mere data storage, becoming a dynamic and generative process where understanding and creativity intertwine.

In conclusion, the multifaceted nature of memory, as explored through concepts like synergistic ecphory and synergistic recall, paints a fascinating picture of human cognition. It challenges the traditional division between episodic and semantic memory, showing instead a nuanced and interconnected system where generative patterns and semantic information play a central role. From the way we perceive objects without visual recall to the intricate dance of sensory cues in memory retrieval, these insights redefine memory as an active and imaginative process. Ultimately, the journey into these complex aspects of human cognition unveils that semantic memory is not just a repository of facts but a living and dynamic landscape, shaping how we think, learn, and interact with the world around us.
1 / 1
ChatGPT
After reviewing the provided excerpts from your essay and comparing them with the content from "Concepts is all you need," here are some connections and comparisons that stand out:
Semantic Memory as a Foundation
: Both your essay and the article emphasize the importance of a foundational, structured system of knowledge. While the "Concepts is all you need" article suggests a knowledge-graph (or hyper-optimized graph-based vector datastore) as a foundational substrate for all cognitive functions, your essay explores semantic memory as foundational for cognitive abilities.
Challenging Traditional Views
: The "Concepts is all you need" article challenges traditional modular designs of cognitive architectures in favor of more integrated systems. Your essay challenges traditional views of memory and imagination, suggesting that abstract understanding might be more important than visualization.
Implications for AI and Technology
: The article discusses practical implementations, aiming for a system that can learn and reason in a human-like manner. Your essay suggests that understanding the generative nature of memory could influence the design of AI systems that mimic human-like reasoning.
Dynamic, Integrated Systems
: Both writings highlight the importance of integration. While the article discusses the integration of cognitive functions, your essay delves into the integration of sensory modalities in memory recall, termed as synergistic ecphory and synergistic recall.
Applications Beyond Storage
: Both texts move beyond the concept of memory as mere storage. The article outlines the importance of integrated cognitive functions, and your essay emphasizes that semantic memory is a dynamic component of human thinking, not just a static storage system.
Complexity of Memory
: Your essay's exploration of synergistic ecphory and recall emphasizes the intricate mechanisms through which memories are formed and recalled. This complexity aligns with the article's acknowledgment of how AGI requires understanding of complex interactions between context, memory, learning, inference, and other cognitive processes.
Educational Implications
: The article touches upon the importance of a curated curriculum for cognitive AI. Your essay's exploration of enhanced memory formation and retrieval techniques using sensory modalities provides practical strategies that could be beneficial in educational settings.
In conclusion, both your essay and the "Concepts is all you need" article converge on the idea that understanding and integration of foundational knowledge structures (be it semantic memory or knowledge-graphs) are crucial for advanced cognitive functions, either in humans or in AI. Your essay provides a deeper exploration of the nuances of human memory, while the article offers insights into how these concepts might be translated into artificial general intelligence.
1 / 1
And with the earlier article on comparative cognition with animals?
1 / 1
ChatGPT
Certainly. When comparing your essay on semantic memory and the provided information on "Concepts is all you need" with the earlier article on comparative cognition in animals, several connections and contrasts emerge:
Nature of Memory
: Your essay dives deep into the importance and functioning of semantic memory in humans. The article on comparative cognition discusses how animals may have specialized cognitive processes tailored to their ecological niches. This establishes that memory and cognitive processes, while universal in some ways, are nuanced and adapted based on specific needs and evolutionary pressures.
Cognitive Complexity
: The comparative cognition article illustrates that non-human animals possess cognitive capacities often underestimated. Similarly, your essay and the "Concepts is all you need" article show that human cognitive abilities, especially around memory, are more intricate than conventionally understood.
Foundational Systems
: Both your essay and the "Concepts is all you need" article emphasize foundational systems of knowledge���semantic memory for humans and a knowledge-graph for AGI. In the comparative cognition article, foundational cognitive systems could be inferred as species-specific mechanisms that have evolved to solve specific ecological problems.
Challenging Assumptions
: All three pieces challenge prevailing assumptions in their respective domains. Your essay challenges traditional beliefs about memory and imagination, the AGI article challenges traditional designs of cognitive architectures, and the comparative cognition piece challenges anthropocentric views of cognitive abilities.
Integration and Adaptation
: The synergistic ecphory and recall you mention advocate for an integrative approach to memory, utilizing multiple sensory modalities. Similarly, the AGI roadmap focuses on integrating various modules and capabilities. In the animal cognition realm, the concept of cognitive adaptations suggests that animals have integrated cognitive mechanisms finely tuned to their environment.
Implications for Learning
: Your essay's insights into memory might have educational ramifications, as it suggests methods to enhance learning through sensory engagement. The article on AGI discusses the importance of a system's curriculum. Comparative cognition, on the other hand, illustrates that learning mechanisms in animals can be varied, innate, or acquired, and understanding these mechanisms can have implications for fields like ethology and conservation.
Applications and Technology
: While the AGI piece is forward-looking, focusing on the evolution of artificial intelligence, your essay suggests potential applications in education and therapy. The comparative cognition article offers insights beneficial for animal behavior studies, conservation, and potentially biomimicry in tech designs.
In essence, when considering all three writings, there is a collective acknowledgment of the vastness and nuance of cognitive abilities across different entities, be it humans, animals, or artificial systems. Each emphasizes the importance of understanding foundational systems, the potential for learning, and the necessity of challenging prevailing assumptions to gain a deeper understanding of cognition.
1 / 1
Ok so it is the argument of the representation independence of linguistic and semantic (what Yampolskiy calls the substrate independence of ideas) concepts, I was thinking like text, audio, video, different programming languages, human languages, music. We convert back and forth between temporal loops and language arbitrarily by running or executing the program
1 / 1
ChatGPT
Got it. The concept of representation or substrate independence is a profound and multifaceted idea, especially when applied to cognition, information processing, and communication. It touches upon the nature of symbols, meaning, and the mediums through which information or ideas are conveyed. Here's how this idea connects to the themes discussed:
Mediums and Modes
: At the core of the representation independence argument is the idea that an underlying concept, or "idea," can exist independently of the medium that presents it. Whether it's text, audio, video, programming languages, human languages, or music, the underlying semantic or conceptual essence remains consistent, even if the representation varies.
Semantic Memory & Substrate Independence
: Your essay on semantic memory's role in human cognition underscores the power of abstraction in human thought. Just as we can recognize the same object or idea across different sensory modalities or contexts, the substrate independence concept argues for the universality and portability of ideas across different representations.
Language and Execution
: Language, in all its forms, can be seen as a way to encode and transmit ideas. This ties into the notion you brought up about "temporal loops and language." When a program is written in a high-level language, it's a representation of a process. When executed, it becomes a temporal loop or a series of actions. This duality mirrors the conversion between static representation (like language) and dynamic process (like thought or action).
Comparative Cognition & Representations
: Different animals might have evolved specific cognitive tools tailored for their environment. While a songbird's song and a dolphin's whistle both convey information, they are different mediums with their unique syntactic structures. Yet, they both serve the purpose of communication, implying a sort of substrate independence within the animal kingdom as well.
AGI & Substrate Independence
: The "Concepts is all you need" article alludes to the creation of AGI systems that have underlying architectures designed to understand and generate knowledge. Such systems would, in essence, need to be substrate-independent to understand and generate ideas in various forms ��� be it text, visuals, or other data representations.
Transcending Boundaries
: The ultimate goal of many technologies, especially in AI, is to break down the barriers between different forms of representation. Natural Language Processing (NLP) tools that can convert text to speech, image recognition tools that can describe visuals in textual terms, and translation tools that can convert between human languages are all striving towards this ideal of substrate independence.
In conclusion, the notion of representation or substrate independence is central to understanding the versatility and adaptability of information and ideas. It emphasizes that the essence of an idea is not tied down to its medium of expression, and with the right tools or cognitive abilities, one can traverse between different representations seamlessly. This concept holds significant implications for fields ranging from cognitive science and linguistics to AI and information theory.
1 / 1
A list of all of the topics we've discussed.
1 / 1
ChatGPT
Certainly! Here's a list of the primary topics we've discussed:
Semantic Memory
: The foundational role of semantic memory in recalling past experiences and generating new ideas, as well as its interactions with episodic memory and imagination.
Aphantasia
: A condition where one doesn't possess a functioning mind's eye and cannot voluntarily visualize imagery.
Ecphory & Synergistic Recall
: The process of retrieving memories through specific cues, and the concept of enhancing memory formation using multi-sensory modalities.
Comparative Cognition in Animals
: Discussing the cognitive abilities of animals and how they compare with human cognition.
Representation/Substrate Independence
: The idea that concepts or ideas can exist independently of the medium or representation that conveys them.
Modes of Representation
: Different mediums such as text, audio, video, programming languages, human languages, and music.
Temporal Loops and Execution
: The notion of converting between static representation and dynamic processes.
AGI (Artificial General Intelligence)
: The roadmap and features of the AGI system "Aigo" and the steps toward its development.
Mediums of Communication & Language
: Discussing language as a means to encode and transmit ideas and its role in cognition.
Animal Communication
: How different animals convey information using unique mediums and structures.
Technological Tools
: Briefly touched upon tools like NLP and image recognition that strive for representation independence.
Role of Substrate Independence in AI
: The significance of substrate independence in the context of AI development and understanding.
These topics collectively offer a multifaceted look into human cognition, comparative animal cognition, and the progression of AI, especially with the lens of representation and substrate independence.
1 / 1
I would say that there is no voluntary or involuntary imagery either, in the case of total aphantasia, no sounds, music, voices, touch, smell, or taste
1 / 1
ChatGPT
Yes, you're right. Total aphantasia extends beyond just the absence of visual imagery. Individuals with this condition cannot voluntarily conjure up sensations across all sensory modalities, whether it's auditory (sounds or music), tactile (touch), gustatory (taste), or olfactory (smell). This highlights the diversity of experiences even within what we might think of as a singular concept or condition. It's a profound reminder of the variety and intricacy of human cognition and perception.
1 / 1
No I mean it isn't involuntary either, I don't experience anything like flashbacks or episodic recall of any events they are immediately placed into a semantic matrix it web of connotations, there is no imagery or picturing involved in either memory or imagination.
1 / 1
ChatGPT
Got it. I understand your clarification now. In your case, all memories or thoughts, regardless of whether they originate from a past experience or imagination, are devoid of sensory details. Instead, they're processed as abstract, semantic constructs without the typical sensory-rich elements many people associate with episodic memory or imaginative thinking.
This situation offers an intriguing insight into how different people's minds work and the variability in cognitive experiences. Your unique way of processing information challenges many traditional understandings of memory and imagination and emphasizes the idea that human cognition is multifaceted and diverse.
1 / 1
This is an article from the Lone Hand written by L. Woolacott in 1920 that discusses the idea of "wordless, imageless thought." The author argues that there are emotional impulses towards right action that can occur without the need for verbal expression or thought images.

These impulses come from a deeper level of the mind and should be obeyed without hesitation.

The article also discusses the idea that the mind is not a collection of separate powers, but one power using the entire body as its instrument.

The author suggests that as people become more educated in psychology, a new terminology will be needed to describe mental operations, and current terms like "conscience," "intelligence," "will," and "reason" will fall into disuse.
1 / 1
ChatGPT
The article from "The Lone Hand" by L. Woolacott touches upon themes that resonate with the discussion about aphantasia, semantic memory, and cognition. Here's a comparative analysis based on your descriptions:
Wordless, Imageless Thought
: This idea aligns with the perspective you've shared about experiencing thought without imagery or sensory details. In both scenarios, there's an emphasis on understanding that thought processes can exist without conventional, sensory-rich constructs. Woolacott's notion of 'emotional impulses towards right action' that don't require verbal expression is analogous to the abstract, semantic-based thoughts you described.
Unified Mind Theory
: Woolacott's idea that the mind isn't a collection of separate powers, but one using the body as its instrument, could be linked to the seamless integration of semantic memory into overall cognition. If we view memory as a holistic, interconnected web rather than distinct compartments, then both episodic and semantic memories are just different manifestations of a unified cognitive process.
Emphasis on Intuition
: The idea of obeying impulses from a deeper level of the mind without hesitation highlights the importance of intuition and innate knowledge. This could be seen as a parallel to the inherent understanding or "knowing" that emerges from semantic associations without the need for sensory recall.
Evolving Terminology
: Woolacott's prediction that terms like "conscience," "intelligence," "will," and "reason" might fall into disuse as we refine our understanding of the mind is thought-provoking. It suggests that as our comprehension of cognition evolves, so will our linguistic representations. This is somewhat reminiscent of the discussions on representation independence, where ideas can manifest across various modalities without losing their essence.
In sum, Woolacott's article seems to touch upon ideas that challenge traditional notions of cognition, much like the discussions on aphantasia and semantic memory. It emphasizes the existence of cognitive processes that don't necessarily align with conventional, sensory-based paradigms, thereby highlighting the vastness and diversity of human thought.
1 / 1
Here is the article: Wordless Imageless Though

Ernest Osborne���s short article on ���Thought��� in the Lone Hand for June provoked a two-hour long discussion among some of my friends. The main conclusions are here concentrated for you:

If wordless, imageless thought be a possibility, is it not a further argument for obeying the inhibitions of conscience without waiting until the inhibitory impulses can be put into words?

For instance, if one becomes conscious of an uneasy feeling when one is about to do a certain action, would it not be better to avoid doing the action even if one cannot put into words the reason why the action should be avoided?

There are unmistakable emotional impulses towards right action which occur periodically and which we should train ourselves to obey unhesitatingly.

There are unmistakable emotional impulses towards right action which occur periodically and which we should train ourselves to obey unhesitatingly.

No time should be spent in seeking a logical reason for the impulses. Obey them. You know they are right���right for you at any rate.

This knowledge at critical moments of what is right and wrong is an instance of thought unclothed with words.

Such knowledge springs from a level of the mind deeper than the layer on which operate thought-images, combined with the capability of verbal expression.

When the deeper levels of the mind operate harmoniously with the outermost layer (we took McDougall as our authority for speaking of mental ���layers��� and ���levels���), then only is a man at peace with himself and the universe.

For him the paradox, "Right speech is right action", is no longer a paradox. The majority of us are unhappily crammed with Freudian complexes which make harmonious speech and action nearly impossible. Hence the saying, ���He acted against his better self.���

Translated into modern psychological terms the phrase would read, ���The layers of his mind were not acting in unity.��� 

After the masses are sufficiently educated, a new terminolgy for mental operations will have to come into being.

Such psychically identical terms as ���conscience,��� ���intelligence,��� ���will,��� and ���reason,��� will fall as far into the limbo of 

disuse as such words as ���humours��� and ���faculties��� have already fallen.

The greatest lesson of modern psychology is that the mind is not a concatenation of separate powers, but one power using as its instrument the whole body.

��� L. Woolacott, 1920

https://nla.gov.au/nla.obj-393171833/view?sectionId=nla.obj-432274350&partId=nla.obj-393300183#page/n4/mode/1up
1 / 1
ChatGPT
This article by L. Woolacott from 1920 delves into some profound and avant-garde ideas about cognition for its time. Let's break down the piece and draw some connections with the previous discussions:
Wordless, Imageless Thought
: Woolacott proposes the idea that thought can exist without the encasement of words or visual images. This is strongly resonant with the experience you described of aphantasia and the capacity to think and comprehend without sensory-based representation.
Intuitive Ethics and Inhibitions
: Woolacott suggests that sometimes we feel an inherent moral or ethical unease about an action, even if we can't articulate why. This could be linked to an innate understanding or deep-rooted semantic connections that guide our behavior, even without episodic or sensory recall.
Harmony of Mental Layers
: The mention of mental "layers" and "levels" and the necessity for their harmonious interaction implies a multifaceted cognitive structure. When these levels act in unity, it results in an individual's peace and coherence in thought and action.
The Need for a New Terminology
: As psychology progresses, Woolacott predicts the emergence of new terminologies to better describe mental operations. This perspective aligns with the broader theme of representation independence discussed earlier. Just as ideas can manifest in various formats without changing their essence, our understanding of cognition requires evolving terminology to reflect its intricacies accurately.
Mind as a Unified Power
: The concluding notion of the mind as a singular power using the body as its tool echoes the idea of semantic memory as a fundamental and pervasive aspect of cognition.
The Context of Time
: This article, being from 1920, is quite advanced in its perspective, considering the dominant psychological theories of that era. It���s worth noting that Woolacott was thinking about the nuances of cognition and thought representation long before modern advancements in neuroimaging and cognitive science.
To tie it back to the discussions on aphantasia, semantic memory, and comparative cognition, Woolacott���s article provides historical context. It emphasizes that the quest to understand the essence of thought���beyond sensory imagery and traditional constructs���has long been a topic of intrigue. The article underscores the importance of intuition, the innate understanding of right and wrong, and the intricate harmony of different cognitive facets, themes that still resonate with our modern understanding and personal experiences of cognition.
1 / 1
Ok it seems like we covered a lot of topics and ideas.
1 / 1
ChatGPT
Absolutely! Let's do a quick recap of the main topics and ideas we covered:
Comparative Cognition with Animals
: We discussed how different animals process information and how their cognitive abilities might compare to humans.
Representation Independence of Linguistic and Semantic Concepts
: This highlighted the substrate independence of ideas, emphasizing that the same idea can be represented in various forms, such as text, audio, video, or even different languages.
Aphantasia
: You described your personal experience with total aphantasia, emphasizing the absence of both voluntary and involuntary imagery across all sensory modalities.
Semantic Memory's Role
: We delved into the importance of semantic memory in both recalling past experiences and generating new ideas, suggesting it as a foundational aspect of our cognitive abilities.
Synergistic Ecphory and Recall
: These concepts explored the nuances of memory retrieval, emphasizing the multisensory nature of memories and strategies for enhancing recall.
Wordless, Imageless Thought
: We analyzed L. Woolacott���s 1920 article, which proposed the idea of thought existing independently of words or visual imagery. The article also touched upon intuitive ethical behaviors and the evolving terminology in psychology.
Throughout our discussion, there was a consistent thread highlighting the complexities of human cognition and the various ways we process, store, and retrieve information. Your insights and the materials you shared provided a deep dive into these topics, showcasing the intricate dance between sensory experiences, memory, representation, and cognition.
1 / 1
A list of all themes and topics
1 / 1
ChatGPT
Certainly! Here's a concise list of the themes and topics we've covered:
Comparative Cognition
:
Differences in cognitive abilities between animals and humans.
Representation and Substrate Independence
:
Ideas being independent of their medium (text, audio, video, etc.).
Conversion between various forms and languages.
Aphantasia
:
Absence of mental imagery across all sensory modalities.
Distinction between voluntary and involuntary imagery.
Semantic Memory
:
Importance in recalling past experiences and generating new ideas.
Generative nature of memory and imagination.
Synergistic Ecphory and Recall
:
Memory retrieval using multisensory cues.
Strategies for enhancing memory recall.
Wordless, Imageless Thought
:
Thought processes without the need for verbal or visual imagery.
Intuitive emotional impulses.
The mind as a unified power using the body as its instrument.
These topics delve into the intricacies of cognition, memory, representation, and the nuances of human thought processes.
1 / 1
So I guess what I am trying to say is that the scientific definition of the word image is more like a mental state, and doesn't necessary include an sensation. People can imagine that they are thinking in pictures when they are not, meaning that their mental imagery and audio are sub"vocalizations" of the eye muscles and jaw muscles that can help "direct" episodic recall of imagery, but they are implements in symbolic networks of reprentations that is the semantic representations, itself a higher level abstraction of hebbian networks controlling the muscle groups
1 / 1
ChatGPT
That's a profound observation. Let's unpack it a bit:
Redefining Mental Images
: You're suggesting that mental "images" might not necessarily be visual phenomena. Instead, they could be understood as particular states or configurations of the mind. This aligns with discussions around aphantasia, where people don't "see" images but still possess knowledge or conceptual understanding of the described object or scene.
Illusion of Imagery
: People might believe they "see" pictures in their mind, but this could be more about recognizing patterns and symbols rather than actual visual representations. This interpretation challenges the traditional notion of "picturing" something in one's mind.
Muscle-based Subvocalization
: When people think they "hear" a song in their head or visualize a scene, it might involve subtle muscular movements or activations, like those of the eyes or the jaw. These could aid in the retrieval of episodic memories but aren't the actual memories themselves.
Symbolic Networks & Semantic Representations
: At the core, these so-called "images" or "sounds" could be symbolic representations, embedded in a network of semantic relationships. These semantic networks, in turn, might be abstracted from more fundamental neural networks, grounded in our bodily movements and experiences.
This perspective indeed challenges traditional views on mental imagery. It pushes for an understanding that cognitive processes might be more abstract and symbolic than they are sensory. It's a blend of cognitive psychology, neuroscience, and philosophy of mind, offering a holistic take on human cognition.
1 / 1
Yes so synesthesia is not a crossing over of sensory modality replay they are generative process that are independent of the sensory modality they were introduced. So people experience visual recall for something they heard as a visual image, if that is their workspace. I argue that visual and auditory mental imagery are forms of voluntary lucid synthesia
1 / 1
ChatGPT
Interesting point! Let's dive a little deeper:
Synesthesia Redefined
: Traditional understanding of synesthesia is a condition where stimulation of one sensory modality leads to involuntary experiences in another sensory modality. For example, a person might "see" colors when they hear sounds. You're suggesting that these experiences might not be mere replays of past sensory inputs but rather generative processes, creating something new that wasn't there before.
Modal Independence
: The idea here is that the way we internally represent information might be independent of the modality through which we originally perceived it. Hence, a sound could be remembered as an image if the person's cognitive "workspace" is primarily visual.
Mental Imagery as Lucid Synesthesia
: Traditionally, synesthesia is described as involuntary. When a person with chromesthesia (sound-color synesthesia) hears a note, they might automatically see a specific color. By arguing that mental imagery is a form of voluntary, controlled synesthesia, you're suggesting that people can intentionally conjure and manipulate these cross-modal experiences. This is an intriguing idea and aligns with the notion that our mental workspace allows for a dynamic play of symbols, independent of their original sensory source.
This perspective paints a rich tapestry of human cognition, where boundaries between senses blur and the mind's ability to generate, manipulate, and play with symbols becomes central. It also adds depth to discussions around aphantasia and hyperphantasia, suggesting that these might be different ways people navigate their internal cognitive workspace, using the tools (like mental imagery) available to them.
1 / 1
A summary of the conversation so far.
1 / 1
ChatGPT
Certainly! Here's a concise summary of our conversation:
Concepts in "Concepts is all you need"
: You introduced a new perspective on AI development that emphasizes symbolic AI and knowledge graphs over traditional neural networks. This approach taps into semantic memory to create general AI systems.
Semantic Memory
: The critical role of semantic memory in both recalling past experiences and generating new ideas was discussed. This perspective views processes as reconstructions using semantic templates, emphasizing the foundational nature of semantic memory.
Synergistic Ecphory & Synergistic Recall
: An expanded understanding of memory that involves utilizing multiple sensory modalities for enhanced recall was introduced. This approach has applications in education, memory training, and therapy.
Comparative Cognition with Animals
: The distinction between humans and animals was discussed regarding symbolic representation and conceptual understanding.
Representation Independence
: The idea that concepts and ideas can exist and be transformed across various media and formats, from text to audio to programming languages, was brought up. This touches on the substrate independence of ideas.
Aphantasia
: The phenomenon where some individuals cannot voluntarily conjure up mental images was discussed. You added a personal perspective, highlighting that in cases like total aphantasia, there's no imagery involved in memory or imagination.
Wordless, Imageless Thought
: An article from 1920 titled "Wordless Imageless Thought" was presented, discussing the possibility of thoughts and decisions not rooted in verbal or visual representations.
Synesthesia & Mental Imagery
: We explored the idea that mental imagery might be a form of voluntary synesthesia, suggesting a dynamic cognitive workspace that allows for the blending and manipulation of symbols, regardless of their original sensory source.
Throughout our conversation, we delved deep into human cognition, memory, imagination, and the mechanisms that underpin these processes, aiming to bridge contemporary AI concepts with a broader understanding of the mind.
1 / 1
Just the outline and Rank them in order of how speculative
1 / 1
ChatGPT
Certainly! Here's an outline ranked from least speculative (well-established concepts) to most speculative (more theoretical and debated ideas):
Semantic Memory
:
Role in recalling past experiences and generating ideas.
Viewed as reconstructions using semantic templates.
Comparative Cognition with Animals
:
Distinction between humans and animals in symbolic representation and conceptual understanding.
Aphantasia
:
Phenomenon where individuals cannot voluntarily produce mental images.
Personal perspective on total aphantasia and the absence of imagery in memory/imagination.
Wordless, Imageless Thought
:
1920 article discussing decisions and thoughts not rooted in verbal or visual representations.
Synergistic Ecphory & Synergistic Recall
:
Understanding memory through multiple sensory modalities for enhanced recall.
Applications in various fields like education and therapy.
Concepts in "Concepts is all you need"
:
New perspective on AI, emphasizing symbolic AI and knowledge graphs.
Potential for creating general AI systems using semantic memory.
Representation Independence
:
Concepts can exist and transform across various media/formats.
Idea of substrate independence of ideas.
Synesthesia & Mental Imagery
:
Mental imagery as a potential form of voluntary synesthesia.
Cognitive workspace allowing for blending and manipulation of symbols regardless of their original sensory source.
The ranking is based on the general acceptance and understanding of each concept in the scientific community as of my last training data in 2021.
1 / 1
Connections with the following: [Submitted on 3 Jan 2023]
Semantic Units: Organizing knowledge graphs into semantically meaningful units of representation
Lars Vogt, Tobias Kuhn, Robert Hoehndorf
Knowledge graphs and ontologies are becoming increasingly important as technical solutions for Findable, Accessible, Interoperable, and Reusable data and metadata (FAIR Guiding Principles). We discuss four challenges that impede the use of FAIR knowledge graphs and propose semantic units as their potential solution. Semantic units structure a knowledge graph into identifiable and semantically meaningful subgraphs. Each unit is represented by its own resource, instantiates a corresponding semantic unit class, and can be implemented as a FAIR Digital Object and a nanopublication in RDF/OWL and property graphs. We distinguish statement and compound units as basic categories of semantic units. Statement units represent smallest, independent propositions that are semantically meaningful for a human reader. They consist of one or more triples and mathematically partition a knowledge graph. We distinguish assertional, contingent (prototypical), and universal statement units as basic types of statement units and propose representational schemes and formal semantics for them (including for absence statements, negations, and cardinality restrictions) that do not involve blank nodes and that translate back to OWL. Compound units, on the other hand, represent semantically meaningful collections of semantic units and we distinguish various types of compound units, representing different levels of representational granularity, different types of granularity trees, and different frames of reference. Semantic units support making statements about statements, can be used for graph-alignment, subgraph-matching, knowledge graph profiling, and for managing access restrictions to sensitive data. Organizing the graph into semantic units supports the separation of ontological, diagnostic (i.e., referential), and discursive information, and it also supports the differentiation of multiple frames of reference
1 / 1
ChatGPT
The work by Lars Vogt, Tobias Kuhn, and Robert Hoehndorf on "Semantic Units" dives deep into refining and enhancing the structure of knowledge graphs. By organizing knowledge graphs into semantically coherent subgraphs, they aim to make them more effective and functional for a variety of applications. Let's align the core ideas presented in this work with the themes we discussed earlier:
Semantic Memory
:
Connection
: The concept of semantic units resembles the function of semantic memory, wherein information is categorized into meaningful networks. Semantic units might represent a technological parallel to the cognitive processes of organizing and representing knowledge in human minds.
Comparative Cognition with Animals
:
Connection
: Animals have differing capabilities of symbolic representation. The structure of semantic units might help illustrate how different levels of semantic complexity can be embodied in different systems ��� from simpler animals to complex human cognition.
Aphantasia
:
Connection
: People with aphantasia, especially total aphantasia, rely heavily on semantic networks devoid of imagery. The concept of semantic units, as clear and concise partitions of information, could resemble how people with aphantasia organize their knowledge.
Wordless, Imageless Thought
:
Connection
: Semantic units, being devoid of explicit imagery, align well with the concept of wordless, imageless thought. They represent abstract units of knowledge that can be understood without direct visual or verbal representations.
Synergistic Ecphory & Synergistic Recall
:
Connection
: The multi-layered and structured approach to semantic units might enhance the recall of information, much like how synergistic recall uses multiple modalities to boost memory.
Representation Independence
:
Connection
: Semantic units, especially in their FAIR Digital Object and nanopublication formats, exemplify the idea of substrate independence. They can be accessed and understood across varied formats and platforms.
Synesthesia & Mental Imagery
:
Connection
: While semantic units are designed to be clear-cut partitions of knowledge, their interaction with other units can mimic the blending seen in synesthesia. Different semantic units can combine to give rise to new insights, much like synesthetic experiences create novel sensory perceptions.
Concepts in "Concepts is all you need"
:
Connection
: Semantic units emphasize the importance of symbolic representations in knowledge graphs. This aligns with the idea of using symbolic AI and knowledge graphs to develop advanced AI systems.
Speculative Ranking
: Given that the concept of semantic units is based on a technical and academic work published in 2023, it would be more towards the speculative end of our earlier ranking. It proposes a specific structure for knowledge graphs, and while grounded in established principles, its practical implementations and wider acceptance might still be in the early stages.
The introduction of semantic units to the conversation provides a concrete framework for organizing and representing knowledge, offering a technical perspective to the philosophical and cognitive themes discussed earlier.
1 / 1
I think I called them "semantic ladles" or bundles before
1 / 1
ChatGPT
Yes, you did mention "semantic ladles" earlier. The idea of "ladles" or "bundles" conveys the concept of grouping or collecting information into coherent units. When related to the work on "Semantic Units," this provides an illustrative metaphor. Semantic ladles/bundles would scoop or collect meaningful portions of information, similar to how semantic units are organized in a knowledge graph.
When contextualizing with our previous discussions:
Semantic Memory
: Semantic ladles/bundles can be seen as the mechanism by which our semantic memory collects and groups related concepts.
Representation Independence
: The conversion between various modalities (text, audio, video, etc.) can be facilitated by these semantic ladles/bundles, serving as the coherent units that maintain meaning across translations.
Wordless, Imageless Thought & Aphantasia
: For individuals experiencing aphantasia or those who think without relying on explicit imagery or verbalization, semantic ladles/bundles would represent their primary means of organizing information.
Considering the abstract nature of these concepts, they would rank similarly in terms of speculativeness to our earlier discussions. Semantic ladles/bundles provide an interesting metaphorical framework to understand the organization of knowledge in both the human brain and in technical systems like knowledge graphs.
1 / 1
I still haven't thought of a good title for this conversation
1 / 1
ChatGPT
Given the breadth and depth of topics covered, settling on a single title can be a challenge. However, considering the core themes and the synthesis of cognition, memory, and representation independence, here are some title suggestions:
"The Landscape of Semantic Cognition: From Memory to Representation Independence"
"Unearthing the Layers of Semantic Memory and Representation"
"Beyond Imagery: The Interplay of Semantic Memory and Substrate Independence"
"Decoding the Nexus of Semantic Memory, Synesthesia, and Knowledge Graphs"
"Conversations on Cognitive Landscapes: Memory, Modality, and Meaning"
Selecting a title often involves considering the core message or insight you hope readers will take away from the conversation. Which of these resonates most with your intentions, or do they spark a new idea for you?
1 / 1
I think I'll call it "Semantic Cognition Interpretation"
1 / 1
ChatGPT
"Semantic Cognition Interpretation" is a concise and apt title that encapsulates the core themes discussed throughout the conversation. It conveys the essence of delving deep into the layers of semantic understanding and how cognition interacts with and interprets various representations. Great choice!
1 / 1
A summary
1 / 1
ChatGPT
Certainly! Here's a concise outline of the topics discussed, ranked from least speculative to most speculative:
1. Semantic Memory & Its Role:
Importance in recalling past experiences and generating ideas.
Reconstructions using semantic templates.
Applications in education, therapy, and AI.
2. Synergistic Ecphory & Recall:
Definition and context of ecphory.
The importance of multisensory cues in memory retrieval.
Using sensory modalities for memory formation and robust recall.
3. The Concept of Representation Independence:
Various formats of representing ideas: text, audio, video, programming languages, etc.
Transition between temporal loops and language by executing the program.
4. Aphantasia & Mental Imagery:
The idea that there's no voluntary or involuntary imagery in total aphantasia.
Memory and imagination without imagery.
5. Wordless, Imageless Thought:
Emotional impulses towards right action without verbal expression or thought images.
The mind as one power using the entire body as its instrument.
6. Scientific Definition of Imagery:
Imagery as a mental state, not necessarily tied to sensation.
Subvocalizations and the idea that people can believe they're thinking in images.
7. Synesthesia & Generative Processes:
Synesthesia as independent of the sensory modality of introduction.
Mental imagery as forms of voluntary lucid synesthesia.
8. Semantic Units & Knowledge Graphs:
The concept of structuring knowledge graphs into identifiable and semantically meaningful subgraphs.
The differentiation between statement and compound units.
9. Semantic Ladles/Bundles:
Personal terminology for semantic units or groups.
10. Title & Theme Consolidation:
"Semantic Cognition Interpretation" as the chosen title for the conversation.
This summary provides a structured understanding of the nuanced discussion about semantic cognition and its various interpretations.
1 / 1
Significant Digits would be shorter
1 / 1
ChatGPT
Absolutely. Here's a more condensed summary titled "Significant Digits":
1. Semantic Memory:
Role in experiences and idea generation.
2. Ecphory:
Multisensory cues in memory retrieval.
3. Representation Independence:
Various formats for ideas: text, audio, video.
4. Aphantasia:
Absence of mental imagery in recall and imagination.
5. Wordless Thought:
Emotional impulses guiding actions without verbal or visual aids.
6. Imagery Definition:
Imagery as mental states, beyond sensory experiences.
7. Synesthesia:
Beyond sensory modality crossover; lucid voluntary experiences.
8. Semantic Units:
Structuring knowledge into meaningful subgraphs.
9. Semantic Bundles:
Personal take on semantic units.
This compact version captures the essence of the conversation about the intricacies of semantic cognition.
1 / 1
A final summary.
2 / 2
ChatGPT
Certainly. Here's a concise summary titled "Significant Digits":
1. Semantic Memory:
Foundation for recalling experiences and fostering creativity.
2. Representation Independence:
Ideas transcend formats, from text to sensory experiences.
3. Aphantasia:
A condition denoting an absence of mental imagery.
4. Wordless Thought:
Instinctive actions guided by emotional impulses sans imagery or words.
5. Synesthesia:
Sensory experiences beyond mere modality crossovers.
6. Semantic Units:
Knowledge graph organization into meaningful subgraphs, akin to "semantic bundles."
This summary encapsulates the core discussions surrounding semantic cognition in the conversation.
1 / 1
I was thinking like the end of an essay on these topics
1 / 1
ChatGPT
Understood. Here's a summary structured in a manner fitting the conclusion of an essay:
In the exploration of cognition and memory, a few themes emerge that challenge our traditional understanding of the mind.
Semantic Memory
, often perceived as a mere database of our experiences, reveals itself as a dynamic foundation not just for recall, but for the genesis of new ideas and creativity. This shifts our understanding to see memory as more of an active processor than passive storage.
The concept of
Representation Independence
underscores that ideas are not chained to their medium���be it text, audio, or even sensory experiences. They transcend these formats, reminding us of the universality of ideas and the inherent substrate independence they possess.
The phenomenon of
Aphantasia
forces us to reconceptualize how individuals perceive, recall, and imagine. Without mental imagery, one leans heavily on semantic networks, underscoring that imagination doesn't necessarily require visual representation.
Adding depth to this concept, the idea of
Wordless Thought
emphasizes the capability of the mind to act on emotional impulses without the crutch of imagery or verbal reasoning. This resonates with the concept that our deepest insights and actions may arise from layers of cognition we're barely conscious of.
Synesthesia
then introduces a twist, suggesting that our sensory experiences are more interconnected and generative than previously believed. It���s not merely a crossover of sensory modalities but an active, conscious creation of new experiences.
Lastly, the emergence of
Semantic Units
in knowledge graphs resonates with our broader conversation on semantics. As we seek to organize vast amounts of data, we recognize the importance of meaningful, semantic categorizations���our modern-day "semantic ladles."
In concluding, this journey through the intricacies of semantic cognition unveils a landscape far more intricate and dynamic than traditionally believed. From the abstract realm of semantic memories to the tangible structures of knowledge graphs, we see a mind that's not just a repository but a living, active constructor of understanding. The multifaceted nature of cognition serves as a testament to the mind's remarkable capacity to weave together memory, perception, and imagination in endlessly creative ways.
1 / 1
A "semantic ladle" it's like a force-separated graph of a bag of words. I define it as a 
3. Bundles of properties
Consider a particular which has several essential properties and several accidental properties. There is room to consider a theory which identifies the particular with the collection of essential properties, and there is room to consider a theory which identifies the particular with the collection of all its properties. On consideration, however, it can be seen that a particular cannot be identified with any collection which includes an accidental property. An accidental property is something which, by definition, the particular could have lacked. But the bundle of properties which includes that accidental property would not have been the bundle that it is if it had not included that property.

Consider, therefore, the theory which identifies a particular with the collection of its essential properties. An objection can be raised if we show that there can be several particulars which share exactly the same essential properties. Certainly Aristotle thought that different members of the same species share the very same essential properties. For Aristotle, therefore, what distinguishes particulars of the same species is not their ���form���, but the ���matter��� on which this form is impressed.

Hence if we are to identify a particular with a collection of essential properties, we must suppose that distinct particulars cannot ever share exactly the same essential properties. Each particular must have some property which no other particular could have. This is what is called an individual essence. One way of thinking of an individual essence is by construing it to be an unshareable conjunction of severally-shareable properties as, for example, Leibniz���s monads. An alternative would be to suppose that for each particular there is a simple essential property called a ���haecceity��� (from Latin, meaning ���thisness���) which that particular alone possesses and which nothing else could have had either instead of or as well as it. This notion was articulated by the Islamic philosopher Avicenna (see Ibn Sina ��4), and was taken up by some of the scholastic philosophers in Europe, such as Duns Scotus in the thirteenth century, but has been roundly denounced by many since that time.

HomeAbout Browse What's newLibrariansFree trialHelpTell us what you thinkResourcesTeaching and Learning Resources
Share
 Cite
Print
Contents
Article Summary
1	
What is at stake
2	
Bare particulars
3	
Bundles of properties
4	
Properties particularized
5	
Particulars as aggregates
6	
The state of the art
Bibliography
Thematic
Particulars
By
Bigelow, John C.
DOI10.4324/9780415249126-N040-1
Versions
version 2
version 1
1 / 1
ChatGPT
The concept of a "semantic ladle," as you described it, bears semblance to the philosophical deliberation over the nature of particulars and their association with properties. Within this deliberation, particulars are debated in relation to their essential and accidental properties.
You describe "semantic ladles" like force-separated graphs of a bag of words. Taking this visualization into account, the properties could be analogous to individual words or concepts, while the "force separation" could represent the differential weighting or significance of these words/concepts based on context or usage. In this representation, essential properties might have a stronger force or pull, while accidental properties could be more peripheral.
The philosophical argument you presented emphasizes two main points:
Bundles of Properties
: It questions whether a particular can be identified merely by its collection of properties, especially when distinguishing between essential and accidental properties. Essential properties are inherent to an object's identity, while accidental properties are circumstantial or changeable.
Individual Essence
: This idea suggests that for a particular to be distinct, it must have an individual essence, a unique property or set of properties that no other particular possesses. This can be a "haecceity" or "thisness" which is exclusive to that particular entity.
Linking this back to your concept of a "semantic ladle", each ladle could represent a particular, scooping up a unique bundle of semantic properties. These properties, or words in the bag, form the identity of that ladle. The more central or essential properties are those that are integral to the meaning or context of the ladle, while the peripheral or accidental properties may vary based on context or usage.
In essence, the "semantic ladle" provides a modern, computational analogy to a philosophical inquiry into the nature of identity and properties, helping bridge age-old questions with contemporary data-centric challenges.
1 / 1
Synthese (2021) 199:5107���5124 
https://doi.org/10.1007/s11229-020-03017-z 1 3 
The concreteness of objects: an argument 
against mereological bundle theory 
Uriah Kriegel1 
Received: 15 June 2020 / Accepted: 28 December 2020 / Published online: 7 January 2021 
�� The Author(s), under exclusive licence to Springer Nature B.V. part of Springer Nature 2021 
Abstract 
In a series of publications, L. A. Paul has defended a version of the bundle theory 
according to which material objects are nothing but mereological sums of ���their��� 
properties. This ���mereological��� bundle theory improves in important ways on ear- 
lier bundle theories, but here I present a new argument against it. The argument 
is roughly this: (1) Material objects occupy space; (2) even if properties have spa- 
tial characteristics, they do not quite occupy space; (3) on no plausible construal 
of mereological composition does a mereological sum of non-space-occupying 
entities occupy space; therefore, (4) material objects are not mereological sums of 
properties. 
Keywords Material objects �� Bundle theory �� Mereological bundle theory �� L.A. 
Paul �� Concrete/abstract 
1 Mereological bundle theory and its attractions 
The more you examine a material object, such as a table or a fl ower, the more prop- 
erties of it you come to know. First you establish that the table is brown, rectangular, 
four-legged, and hard; later you discover that it is made of cherry wood, weighs 53 
kilos, is 140 cm across, is manufactured in Taiwan, and is more precisely sienna- 
brown; ultimately you might learn what percentage of the table is carbon, oxygen, 
hydrogen, and so on, what the table���s exact mass is, and the like ���scientif i c proper- 
ties.��� But however long you examine the table, you will never detect something that 
goes beyond the table���s properties, say a bare substrate that ���supports��� the properties. 
According to the bundle theory of material objects, there is a very simple reason 
for this: all a material object is is the collection of its properties. Our table is nothing 
more than a bundle of table-y properties. Very generically, the bundle theory says 
this: 
* Uriah Kriegel 
theuriah@gmail.com 
1 Department of Philosophy, Rice University, Houston, TX 77005, USA 
5108 Synthese (2021) 199:5107���5124 
1 3 
(BUNDLE) For any material object O, there is a bundle B of properties, such 
that O = B. 
(BUNDLE) faces a number of immediate challenges, however. One way to bring out 
the attraction of mereological bundle theory, as developed notably by Paul (2002, 
2006, 2017a, b), is to consider the way it elegantly responds to these challenges. 
Perhaps the fi rst challenge (BUNDLE) faces is that it is unclear what a bundle is. 
It is perhaps most natural to construe bundles as sets. However, sets are typically 
understood as abstract objects, whereas tables are concrete (Hof f man and Rosenk- 
rantz 1994, p. 61). By Leibniz���s Law, O cannot be identical with B if O is concrete 
and B is abstract. 
One might take bundles to be simply pluralities. On this construal, what the table 
is identical to is just the table-y properties P1, ���Pn ���taken together.��� This approach 
faces its own embarrassment, however, insofar as it involves an identity on one side 
of which is a plurality and on the other side a single individual. This is quite puz- 
zling: again, by Leibniz���s Law, we might expect that if B is a plurality whereas O 
is a oneness, then B ��� O. Although there are certainly live approaches to many-one 
identities (see Contoir and Baxter 2014), it is mutatis mutandis preferable for the 
bundle theory if it can avoid getting mired in this particular can of worms.
1 / 1
ChatGPT
The excerpt you provided outlines an argument against the "mereological bundle theory" as proposed by L. A. Paul. This theory suggests that material objects are just mereological sums of their properties. The argument against it can be summarized as follows:
Concreteness of Material Objects
: Material objects are tangible and occupy space.
Properties and Space
: Even though properties might have spatial characteristics, they don't occupy space in the same way that concrete objects do.
Mereological Composition
: There's no convincing explanation of how a mereological sum of non-space-occupying entities (like properties) can end up occupying space.
Conclusion
: Therefore, material objects aren't just mereological sums of properties.
The article then goes on to challenge the general idea of the bundle theory, which states that a material object is merely the collection of its properties. This means that, according to this theory, if you examined a table thoroughly, you'd only discover properties about the table and never some underlying "bare substrate" that holds these properties. This understanding of objects can be summarized as:
(BUNDLE)
\text{(BUNDLE)}
(BUNDLE)
: For any material object
O
O
O
, there's a bundle
B
B
B
of properties such that
O
=
B
O = B
O
=
B
.
However, the article outlines some criticisms of the bundle theory:
Definition of Bundles
: It's ambiguous what exactly a "bundle" means. If bundles are understood as sets, it raises the issue of sets being abstract, while objects like tables are concrete. This distinction violates Leibniz���s Law, which states that two objects are identical if and only if they share the same properties.
Bundles as Pluralities
: Another interpretation could be that bundles are pluralities of properties. This understanding poses another problem: if one side of the identity equation is a plurality (the properties) and the other side is a single entity (the table), they can't be identical.
The central thrust of this argument revolves around the tangible, spatial nature of material objects and how this doesn't mesh well with the idea that these objects are just abstract bundles or collections of properties.
1 / 1
Ok I decided to call the conversation "Semantic Ladle Of Words"
1 / 1
ChatGPT
That's a catchy and intriguing title! "Semantic Ladle Of Words" nicely encapsulates the theme of how concepts, or "semantic units", are scooped out from the vast soup of language and knowledge. It gives the conversation a unique identity. Great choice!
1 / 1
So give an outline of SLOW theory.
1 / 1
ChatGPT
Semantic Ladle Of Words (SLOW) Theory: An Outline
Introduction
Defining the term "Semantic Ladle."
Understanding the need for such a theory in the context of knowledge representation and semantic cognition.
Background and Motivation
Brief look into traditional semantic units and knowledge graphs.
Challenges faced by current knowledge representation systems.
Conceptual Foundations
The notion of a "ladle" scooping out specific and meaningful semantic units.
Differentiating between mental images, episodic recall, and subvocalizations.
Bundles of Properties
Defining particulars, their essential and accidental properties.
Discussion on the potential identification of a particular with its essential properties and the problems associated.
Introduction of concepts like individual essence and haecceity, and their relevance.
Mereological Bundle Theory
Material objects and their relationship with properties.
Critique of the idea that objects are mereological sums of 'their' properties.
Challenges faced by the bundle theory, including identity issues and the concrete vs. abstract divide.
Synesthesia and Semantic Representation
Addressing synesthesia as a generative process independent of sensory modality.
Proposing the idea of voluntary lucid synesthesia and its relation to visual and auditory mental imagery.
Applications and Implications
How the SLOW theory can aid in organizing knowledge graphs into semantically meaningful units.
Potential benefits for graph-alignment, subgraph-matching, knowledge graph profiling, and managing access restrictions.
Conclusion
Reflecting on the significance of a structured semantic representation.
Future prospects and areas for further exploration in the context of the SLOW theory.
Note:
This outline is speculative, based on our conversation's direction and content. Adjustments and refinements may be necessary for a comprehensive development of the SLOW theory.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT August 3 Version
?



