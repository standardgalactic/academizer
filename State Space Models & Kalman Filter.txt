State Space Models & Kalman Filter
Open sidebar
State Space Models & Kalman Filter
GPT-4
summarize: The discovery and development of state space models and the Kalman filter have
their roots in the dynamical and control systems research communities. The Kalman
filter was proposed initially as an alternative to the Wiener-Kolmogorov estimation
theory after Kalman applied state variables to the filtering problem. Soon after its
conception, the Kalman filter was associated with significant real-data application
such as the Apollo project at the Ames Research Centre at NASA. The Kalman
filter was soon discovered by the statistics and econometrics research communities,
which were able to exploit the flexibility of the state space formulation in the quest to
describe dynamic systems and to use the filter as a powerful forecasting framework.
Bayesian inference and forecasting were key areas of development in the 1980s
and 1990s. By that time, the state space models and the Kalman filter were found
to be extremely popular in a wide range of applied science, including statistics,
engineering, economics, environmetrics and biology, to name but a few. Partly due
to the availability of computer advancement, over the last 20 years, there has been
an increasing interest in multivariate linear Gaussian, non-linear and non-Gaussian
modelling and related state space methods. This is facilitated by deploying Bayesian
computation, in particular sequential Monte Carlo and Markov chain Monte Carlo
methods, but also by other estimation procedures such as the unscented Kalman
filter and related algorithms.
The principle idea of this book is to bring together the above models with their
statistical inference and make them available to a broad audience. Teaching time
series and state space modelling for over 15 years at the University of Sheffield
has motivated me to take up this book project. During these years, I have met and
collaborated with a number of applied scientists sharing a keen interest in state space
models. Some of these models can be generated by a natural phenomenon such
as met in engineering or environmetrics and some can be generated by a socioeconomic structure such as in finance and its applications. The book is written
from a statistician���s perspective, and it uses a number of data sets to illustrate
the methods from a wide range of disciplines. The first six chapters discuss state
space methods and Bayesian inference for general use; the last two chapters of the
book focus on finance and dynamical systems. On one hand, economics and finance
1 / 1
ChatGPT
Summary:
State space models and the Kalman filter originated from dynamical and control systems research. Kalman developed this filter as an alternative to the Wiener-Kolmogorov estimation theory. Quickly, it became integral to significant projects like NASA's Apollo project. The statistics and econometrics communities soon adopted the filter for its versatility, using it to describe dynamic systems and for forecasting.
By the 1980s and 1990s, the models were being applied in numerous fields like statistics, engineering, and biology, with Bayesian inference becoming a focal point. Computer advancements in the past two decades have bolstered interest in diverse modeling and related state space methods, with Bayesian computation, sequential Monte Carlo, Markov chain Monte Carlo methods, and the unscented Kalman filter becoming increasingly vital.
The book aims to compile these models and their statistical inferences for a wider readership. The author's teaching experience at the University of Sheffield and interactions with various scientists have shaped this project. The models cater to natural phenomena in fields like engineering and socio-economic structures in finance. Written from a statistician's view, the book uses multiple data sets across disciplines. It broadly covers state space methods and Bayesian inference, while the latter part zooms in on finance and dynamical systems.
1 / 1
have been a steady flow of motivation and development of state space methods,
and on the other hand, dynamical systems is the key subject area where the story
of the Kalman filter began. Furthermore, the text aims to widespread state space
methods by developing suitable software to enable the reader to apply the algorithms
using the data sets of the book, but also using their own data sets. We have created
the package BTSA (Bayesian Time Series Analysis), available via the contributed
package CRAN website within the environment for statistical computing R (https://
www.r-project.org). The package includes most functions and data sets used in
Chaps. 1���6; moreover, R commands incorporated in the text is believed to help
understanding and implementing the algorithms once the BTSA package is installed.
The book assumes a basic technical background of linear algebra, probability,
and statistics. This is about second year university level and is reviewed in Chap. 2.
The textbook can be used as a one-semester course on linear Gaussian state space
methods by covering Chaps. 1���4, perhaps with some inclusion of multivariate state
space models in Chap. 5. Alternatively, the book can cover the basic theory of linear
models in Chap. 3 and then move on to non-linear and non-Gaussian models in
Chap. 6, perhaps by including some parts of Chaps. 7 and 8. The textbook is aimed
at students at the higher end of undergraduate or graduate level and it is also aimed
at scientists and doctoral students for self-study.
Sheffield, UK Kostas Triantafyllopoulos
June 202

Bayesian 
Inference 
of State Space 
Models
Kalman Filtering and Beyond
1 / 1
ChatGPT
Summary:
State space methods have found motivation and development primarily from economics, finance, and dynamical systems, the latter being the genesis of the Kalman filter. The book endeavors to make these methods more accessible by providing relevant software tools. A package named BTSA (Bayesian Time Series Analysis) has been created and is available on the CRAN website within the R statistical computing environment. This package incorporates functions and datasets utilized in the initial chapters of the book. R commands embedded in the text are intended to aid readers in understanding and implementing the algorithms, especially after installing the BTSA package.
Readers are expected to have a foundational understanding of linear algebra, probability, and statistics, typically at a second-year university level, which is also recapped in Chapter 2. The textbook can serve as material for a one-semester course focusing on linear Gaussian state space methods (covering Chapters 1-4) or by emphasizing the basic theory of linear models and transitioning to non-linear models, including portions of later chapters. This book targets upper undergraduate and graduate students, along with researchers and doctoral candidates for independent study.
Title Suggestion:
"Bayesian Inference of State Space Models: Kalman Filtering and Beyond" by Kostas Triantafyllopoulos, Sheffield, UK.
1 / 1
A brief explanation of each: AR Autoregressive (model, parameters)
ARIMA Autoregressive integrated moving average (model)
c.d.f. Cumulative distribution function
DGLM Dynamic generalised linear model
EKF Extended Kalman filter
EM Expectation maximisation (algorithm)
FFBS Forward filtering backward sampling (algorithm)
i.i.d. Independent and identically distributed (random variables)
GARCH Generalised autoregressive conditional heteroskedastic models
GLM Generalised linear model
MCMC Markov chain Monte Carlo
MAD Mean absolute deviation
MGARCH Multivariate generalised autoregressive conditional heteroskedastic
models
1 / 1
ChatGPT
Certainly! Here's a brief explanation of each term:
AR (Autoregressive)
: A model that expresses a variable in terms of its previous values. Parameters refer to the number of past values (lags) used.
Example:
An AR(1) model would be
X
t
=
c
+
��
X
t
���
1
+
��
t
X_t = c + ��X_{t-1} + ��_t
X
t
���
=
c
+
��
X
t
���
1
���
+
��
t
���
.
ARIMA (Autoregressive Integrated Moving Average)
: A model that combines autoregressive (AR) and moving average (MA) approaches and includes differencing to make a time series stationary.
c.d.f. (Cumulative Distribution Function)
: It describes the probability that a random variable takes on a value less than or equal to x.
DGLM (Dynamic Generalised Linear Model)
: An extension of the general linear model that allows for observations to depend on an underlying state that evolves over time.
EKF (Extended Kalman Filter)
: An extension of the Kalman filter that linearizes about an estimate of the current mean and covariance to handle nonlinearities.
EM (Expectation Maximisation)
: An algorithm used to find the maximum likelihood estimates of parameters when there's missing data or latent variables.
FFBS (Forward Filtering Backward Sampling)
: An algorithm used in time series analysis, particularly with state space models, for smoothing and obtaining posterior distributions of states.
i.i.d. (Independent and Identically Distributed)
: A collection of random variables that have the same probability distribution and are independent of each other.
GARCH (Generalised Autoregressive Conditional Heteroskedastic Models)
: A time series model that accounts for changing variances over time, commonly used in financial data.
GLM (Generalised Linear Model)
: A flexible generalization of the linear regression that allows for response variables that have error distribution models other than a normal distribution.
MCMC (Markov Chain Monte Carlo)
: A class of algorithms for sampling from a probability distribution based on constructing a Markov chain that has the desired distribution as its equilibrium distribution.
MAD (Mean Absolute Deviation)
: A measure of dispersion in a dataset, calculated by taking the average of the absolute differences between each data point and the mean.
MGARCH (Multivariate Generalised Autoregressive Conditional Heteroskedastic Models)
: An extension of the GARCH model that considers multiple time series and accounts for changing variances and covariances over time.
Each of these terms and models offers a unique approach or insight into statistical modeling and analysis, particularly in the domain of time series forecasting and analysis.
1 / 1
MIMO Multiple input multiple output (dynamic system)
MSE Mean squared error
MSSE Mean squared standardised error
MSOP Multivariate scaled observation precision model
OLS Ordinary least squares
p.d.f. Probability density function
PID Proportional integral derivative (controller)
PF-I Particle filter algorithm I (standard particle filter)
PF-II Particle filter algorithm II (Liu and West particle filter)
p.m.f. Probability mass function
RLS Recursive least squares
SISO Single input single output (dynamic system)
SOP Scaled observational precision model
TRMS Twin rotor multi-input multi-output system
UKF Unscented Kalman filter
WAR Whishart autoregressive process
WN White noise (process)
1 / 1
ChatGPT
Sure, let's delve into a brief explanation for each of these terms:
MIMO (Multiple Input Multiple Output)
: Refers to systems with multiple inputs and multiple outputs, often used in control systems and communication systems to describe devices or processes that manage multiple simultaneous inputs to produce multiple outputs.
MSE (Mean Squared Error)
: A measure of the average squared differences between the estimated values and the true value. It's a common metric for the accuracy of estimators or predictors.
MSSE (Mean Squared Standardised Error)
: The mean of the squared differences between predicted values and observed values, normalized by some standard.
MSOP (Multivariate Scaled Observation Precision Model)
: A model that incorporates multiple observations and scales them based on their precision.
OLS (Ordinary Least Squares)
: A method used in linear regression to estimate the parameters of a linear model by minimizing the sum of the squared residuals.
p.d.f. (Probability Density Function)
: For continuous random variables, it represents the likelihood of a particular outcome.
PID (Proportional Integral Derivative)
: A type of controller used in control systems to regulate processes. It combines three control actions: proportional, integral, and derivative.
PF-I (Particle Filter Algorithm I)
: The standard particle filter, an algorithm for implementing a recursive Bayesian filter by Monte Carlo simulations.
PF-II (Particle Filter Algorithm II)
: Also known as the Liu and West particle filter, an enhanced version of the standard particle filter.
p.m.f. (Probability Mass Function)
: For discrete random variables, it gives the probability that a discrete random variable is exactly equal to some value.
RLS (Recursive Least Squares)
: A method used for recursively updating the coefficients of a linear model to minimize the sum of squared residuals.
SISO (Single Input Single Output)
: Refers to systems with one input and one output.
SOP (Scaled Observational Precision Model)
: A model that scales observations based on their precision.
TRMS (Twin Rotor Multi-Input Multi-Output System)
: A system involving two rotors and functioning as a MIMO dynamic system.
UKF (Unscented Kalman Filter)
: An approach to the nonlinear estimation problem that avoids the need to compute the Jacobian, used to handle the nonlinearities present in the problem.
WAR (Whishart Autoregressive Process)
: A type of stochastic process that can model multivariate time-varying volatilities.
WN (White Noise)
: A random signal or process with a flat spectral density, meaning it has the same intensity at different frequencies.
Each of these terms and models provides specific insights or techniques in the domain of control systems, statistical modeling, and time series analysis.
1 / 1
Chapter 1
State Space Models
This chapter introduces time series, the state space model (although a more formal
treatment is given in Chap. 3) and Kalman filtering. We start by defining and giving
some examples of time series data. Section 1.2 discusses a data driven problem from
hydro-dynamics, which motivates our first encounter with the state space model.
To appreciate the wealth of applications that the state space model holds, Sect. 1.3
provides several examples from environmetrics, navigation, economics and physics.
Section 1.4 gives a historical account of the Kalman filter and the chapter concludes
by giving a brief content description.
1.1 Introduction
1.1.1 Time Series
In many subject areas, such as engineering, economics, biology, environmetrics,
data collected are frequently collected over time. Such data, known as time series,
may arise as the result of the data collection process (we may collect data in a
daily, or hourly frequency) and interest is focused in understanding the dynamics
of such data as well as forecasting future time series values. Examples of time
series include: daily prices of financial assets, monthly marriage figures, quarterly
product sales, daily temperatures in a particular city, annual precipitation levels of a
lake and so forth. In all these examples, the time in which the data are collected is
important, as it introduces a particular correlation or dependence structure between
measurements or observations. In order to understand such data, it is necessary
to consider statistical models that take into account time in the aforementioned
dependence structure. The study of such models is known as time series analysis
and has been discussed in many textbooks, see e.g. Brockwell and Davis (1991),
Shumway and Stoffer (2017) and Lindsey (2004).

To establish notation, we refer to time as t and to the time series observation at t
as yt or as y(t) (see below). In most situations t will belong to a discrete set (such as
the natural numberst = 1, 2, 3 ...) and in this respect the collection of observations
yt , for all t = 1, 2,..., denoted by {yt, t = 1, 2,...} or simply {yt} defines a
discrete-time time series. For example, t may represent days, months or years (as
in examples above). In some cases t belongs to a continuous set (e.g. the closed
interval [0, 1]); then the time series at t is denoted by y(t) (to make explicit that t is
continuous) and so we may write {y(t), t ��� [0, 1]} or {y(t)} for a continuous-time
time series. In this book we will primarily study discrete-time time series, unless
otherwise stated. The objectives of time series analysis are
1. to build statistical models (known as time series models) that describe and
understand the dynamics of observed time series data,
2. based on an observed collection of data, to forecast future values of the time
series.
Both (1) and (2) adopt a time series model, but while (1) aims at finding a model
that describes a collection of data, (2) adopts the model in order to forecast future
data.
A general class of time series models and one that this book is focused on, known
as state space models, suggests that at each time t the observations yt are related
to the states at time t, which in turn are related to the states at t ��� 1. Thus, the
observation is a function of the states, and the way in which the states move in their
space, hence the name state space (time series) models.
1 / 1
ChatGPT
Chapter 1: State Space Models Summary
Main Topic
: Introduction to the concept and application of state space models in time series analysis.
Time Series Data
: This refers to a set of data points gathered over specific intervals of time. The primary characteristic of time series data is that the sequence matters since the timing and order of the data points introduce a correlation or dependence structure. The study of models that account for this time-based structure is called time series analysis. Notable references in this area include works by Brockwell and Davis (1991), Shumway and Stoffer (2017), and Lindsey (2004).
Notation
: The chapter establishes a notation system wherein time is represented by
t
t
t
and observations at time
t
t
t
are represented as
y
t
yt
y
t
or
y
(
t
)
y(t)
y
(
t
)
. The book mainly focuses on discrete-time series where time belongs to a specific set (like natural numbers). However, continuous-time series, where time spans a continuous range, are also mentioned.
Objectives of Time Series Analysis
:
Develop statistical models, termed as time series models, to interpret the dynamics of observed time series data.
Utilize these models to predict future values in the series.
State Space Models
: A unique class of time series models wherein observations
y
t
yt
y
t
at each time
t
t
t
are related to the states at the same time. These states at time
t
t
t
are also linked to states at time
t
���
1
t ��� 1
t
���
1
. This implies that an observation is determined by the states and the manner in which these states evolve over time, hence the term "state space."
Chapter Structure
:
Introduction to Time Series
: Defines what time series data is and emphasizes its importance across various fields such as engineering, economics, biology, and environmetrics. It also highlights the need for models that take time into account due to the inherent correlation between data points.
Historical Perspective of Kalman Filter
: Touches upon the historical significance of the Kalman filter in state space models.
Examples from Various Domains
: Discusses real-world applications of state space models in areas like environmetrics, navigation, economics, and physics, showing the model's versatility.
Introduction to State Space Models
: Introduces the concept of state space models as a significant type of time series model, emphasizing how observations and states interrelate over time.
The chapter serves as a foundation for understanding state space models and their importance in studying and predicting time series data.
1 / 1
1.1.2 Examples of Time Series Data
Time series data typically comprise trend, seasonal components and their combination. This section describes three examples of time series data, which are revisited
later in Chap. 4. ��� Trend (Aluminium prices). Figure 1.1 depicts spot prices of aluminium over
the time period 4 January 2005 to 31 October 2005. Aluminium, which is a
non-ferrous metal, trades daily at the London metal exchange, for information of
which the reader is referred to http://www.lme.com/. The data of Fig. 1.1, which
exclude bank holidays and weekends, show initially some random fluctuation,
followed by an upward linear trend (March���April), followed by a linear fall
(May���June), followed by some random fluctuation (June���July), followed by
some increasing and then decreasing trend (August���September), and finally
followed by a linear trend (October).
��� Seasonal (Quarter temperatures at Sheffield).
Figure 1.2 shows averaged temperatures collected for each quarter at Weston
Park, Sheffield, UK, for unspecified years. This data set shows clear evidence of
seasonality (or cyclic variation), as the values of the 1st Quarter of each year are
similar (lower values in the figure) and of course they are such due to the effect
of the winter months in the first quarter. Likewise, the third quarter of each year
is responsible for the higher temperature values, being influenced by the summer
months..
1 / 1
ChatGPT
1.1.2 Examples of Time Series Data
Main Topic
: Illustrating the typical characteristics of time series data: trend, seasonal components, and their combination.
Examples
:
Trend (Aluminium prices)
:
Source of Data: Spot prices of aluminium from 4 January 2005 to 31 October 2005, recorded daily at the London metal exchange. More details can be found at the official website:
http://www.lme.com/
.
Observation: The data, which excludes weekends and bank holidays, reveals various patterns:
Initial random fluctuations.
An upward linear trend observed from March to April.
A linear decline from May to June.
Random fluctuations again from June to July.
A trend showing an increase followed by a decrease from August to September.
Another upward linear trend in October.
The presented graph (Figure 1.1) helps visualize these patterns.
Seasonal (Quarter temperatures at Sheffield)
:
Source of Data: Averaged temperatures recorded for each quarter at Weston Park, Sheffield, UK, over unspecified years.
Observation: The data demonstrates a pronounced seasonality:
The 1st Quarter of each year has consistently lower temperatures, reflecting the influence of winter months.
Conversely, the 3rd Quarter of each year exhibits higher temperatures, indicative of the summer months.
This seasonality or cyclic variation is evident in the graph (Figure 1.2).
Summary
:
The section presents two distinct examples of time series data, emphasizing the characteristics typical of such datasets. The first demonstrates how trends manifest, as observed in the fluctuating aluminium prices over a specific period. The second exemplifies seasonality, as seen in the quarter temperatures at Sheffield, which follow a predictable pattern influenced by the seasons of the year. Both examples underscore the importance of understanding the inherent structures within time series data.
1 / 1
1.2 Water Tank Dynamics and the State Space Model
In this section we describe a mechanism that generates a linear state space model.
We consider a simple experiment used to measure the level of water in a tank.
Figure 1.3 shows a water tank, which allows a constant flow of water entering the
tank from the left side with constant flow rate 6 litres per min and leaving the tank on
the bottom right side at flow rate 5 litres per min. The objective of the experiment
is to measure the level L of the water in the course of time. The first observation
we make is that the level is not constant as the water coming to the tank creates
disturbance affecting the level of the water. Secondly, the water leaving the tank has
lower flow rate than the flow rate entering the tank. Assuming water mass per litre is
constant, this means that in the long run we expect the level to increase by 1 litre per
min. If there was no disturbance due to water entering the tank, the volume in the
tank at time t is Lt = L0+t, where  is the length of the base of the tank and L0 is
the initial level of the water (assumed to be higher than the higher point of the right
leave point of the tank). The above equation can be written as Lt = Lt���1 + 1,
starting from L1 = L0 + 1. With the disturbance generated by the water falling
into the tank we postulate that Lt ��� Lt���1 +1. This in words says that the volume 
of the tank at time t (in min) is close to the volume of the tank at time t ��� 1 plus
1 litre. This can be modelled by introducing a sequence of random variables ��t , so
that
Lt = Lt���1 + 1 + ��t, (1.1)
where ��t is a i.i.d. sequential of random variables with zero mean and some variance
Z. For this model we have E(Lt) = E(Lt���1) + 1/ and Var(Lt) ��� Var(Lt���1).
Consider now that an observer is measuring the level Lt . This may be achieved
automatically by placing a float in the tank. This will create an extra source of
uncertainty on the level of the water. A possible model for the observed level yt
suggests that yt is expected to be equal to the actual (unobserved) level Lt inflated
by noise  t , caused by the float. Hence the measurement equation is
yt = Lt +  t, (1.2)
where  t is an i.i.d. sequence of random variables with zero mean and variance ��2.
Initially a value for L0 (the level as time t = 0 should be set); alternatively it
is possible to consider that L0 is a random variable, if we wish to specify an initial
distribution for it (this specification will be a useful consideration, if the engineer
is not certain about the initial value L0). Measurement model (1.2) together the
evolution model (1.1) and the initial specification of L0 define a state space model.
The unobserved signal Lt is the state at time t and the observation yt is a linear
function of Lt . Again collecting water float measurement data y1,...,yn we can
estimate the unknown water tank float at each time Lt .

Before we proceed with the definition of the general state space model, we
need to establish some notation. Suppose that x represents a p-dimensional column
vector, i.e.
x = ��������������� x1 x2...xp ��������������� ,
where xi is the ith element of the vector, i = 1, 2,...,p. With  denoting
transposition, we write x = [x1, x2,...,xp] for a row vector; note that with
this notation x can be compactly written as x = [x1, x2,...,xp] . A p �� p
matrix X is a tabular display, which places p column vectors [x11, x21,...,xp1] , [x12, x22,...,xp2] , ..., [x1p, x2p,...,xpp] one after the other, i.e. assigning the
element xij at position (i, j ). As is evident from the above, we use boldface to
distinguish a matrix from a scalar or a vector. In a probabilistic setting, we deal with
random variables (for univariate variables) and random vectors (for multivariate
variables), more information on which can be found in Chap. 2. For a p-dimensional 
column vector y, the notation y ��� N(��, V) implies that y follows the multivariate
Gaussian distribution with mean vector �� and with covariance matrix V. More
details about matrix algebra and statistics relevant to the contents of this book are
provided in Chap. 2.
In general, if the p-dimensional state column vector at time t is denoted by ��t ,
then a linear state space model may be described by equations
yt = xt ��t +  t and ��t = Ft��t���1 + ��t, (1.3)
where xt is a p-dimensional column design vector, Ft is a p��p transition matrix and
the error sequences  t and ��t may be assumed to be independent, with zero mean; in
many applications xt = x and Ft = F are time-invariant, but the general case allows
for more flexibility. It is assumed that the sequences { t} and {��t} are independent
(i.e.  t is independent of  s and ��t is independent of ��s, for any t  = s) and that

t and ��t are independent of ��0, for any t. The model is completely determined if
distributions for the innovations  t and ��t as well as distribution of the initial state
��0 are specified
1 / 1
ChatGPT
1.2 Water Tank Dynamics and the State Space Model
Objective
: This section explains the state space model by using the dynamics of a water tank as a simple, illustrative experiment.
Water Tank Experiment
:
Setup
:
A water tank, as depicted in Figure 1.3.
Water enters the tank from the left at a constant rate of 6 litres/min.
Water exits the tank from the bottom right at a rate of 5 litres/min.
Objective
: Measure the changing water level
L
L
L
over time.
Disturbance is observed due to incoming water.
The outflow rate is less than the inflow rate. Therefore, in the absence of any disturbance, the level would increase by 1 litre/min.
Model without Disturbance
:
If
��
��
��
represents the base area of the tank and
L
0
L_0
L
0
���
is the initial water level, then in the absence of disturbance, the water volume
��
L
t
��L_t
��
L
t
���
at any time
t
t
t
would be
��
L
0
+
t
��L_0 + t
��
L
0
���
+
t
.
Rewritten, it becomes:
��
L
t
=
��
L
t
���
1
+
1
��L_t = ��L_{t���1} + 1
��
L
t
���
=
��
L
t
���
1
���
+
1
, starting with
��
L
1
=
��
L
0
+
1
��L_1 = ��L_0 + 1
��
L
1
���
=
��
L
0
���
+
1
.
Model with Disturbance
:
The disturbance from incoming water results in the following model:
L
t
=
L
t
���
1
+
1
��
+
��
t
L_t = L_{t���1} + 1�� + ��_t
L
t
���
=
L
t
���
1
���
+
1��
+
��
t
���
��
t
��_t
��
t
���
represents a sequence of random variables, indicating disturbances with zero mean and variance
Z
Z
Z
.
Measurement with Float
:
A float is used to measure water level, adding uncertainty due to its movement.
Model for observed level
y
t
y_t
y
t
���
is given by:
y
t
=
L
t
+
��
t
y_t = L_t + ��_t
y
t
���
=
L
t
���
+
��
t
���
��
t
��_t
��
t
���
is an i.i.d. sequence of random variables with zero mean and variance
��
2
��^2
��
2
.
State Space Model Definition
:
This is defined by combining the evolution model (1.1) with the measurement model (1.2) and the initial specification of
L
0
L_0
L
0
���
.
L
t
L_t
L
t
���
is the state, and
y
t
y_t
y
t
���
is a linear function of
L
t
L_t
L
t
���
.
Notation Introduction
:
x
x
x
represents a column vector with
p
p
p
dimensions.
X
X
X
is a
p
��
p
p \times p
p
��
p
matrix.
Boldface denotes a matrix.
A
p
p
p
-dimensional column vector
y
y
y
with Gaussian distribution is represented as
y
���
N
(
��
,
V
)
y ��� N(��, V)
y
���
N
(
��
,
V
)
.
General State Space Model
:
For a
p
p
p
-dimensional state column vector
��
t
��_t
��
t
���
at time
t
t
t
, the linear state space model is represented by:
y
t
=
x
t
T
��
t
+
��
t
y_t = x_t^T ��_t + ��_t
y
t
���
=
x
t
T
���
��
t
���
+
��
t
���
��
t
=
F
t
��
t
���
1
+
��
t
��_t = F_t ��_{t���1} + ��_t
��
t
���
=
F
t
���
��
t
���
1
���
+
��
t
���
Where:
x
t
x_t
x
t
���
is a
p
p
p
-dimensional column design vector.
F
t
F_t
F
t
���
is a
p
��
p
p��p
p
��
p
transition matrix.
��
t
��_t
��
t
���
and
��
t
��_t
��
t
���
are independent error sequences with zero mean.
Summary
:
The section uses the example of a water tank's dynamics to illustrate the concepts and structures behind the state space model. By observing how the water level changes with the inflow, outflow, and disturbances, we can derive a mathematical representation. This model allows for the understanding of state dynamics and measurements, two key components in state space modeling.
1 / 1
If Gaussian distributions are assumed for  t , ��t and for ��0, model (1.3) is known
as Gaussian linear state space model, and it can be described by
yt | ��t ��� N(xt ��t, ��2) and ��t | ��t���1 ��� N(Ft��t���1,Z), (1.4)
where yt | ��t denotes the conditional distribution of yt given ��t (a formal definition
is given in Chap. 2), ��2 is the variance of  t and Z is the covariance matrix of ��t .
Expression (1.4) allows us to extend the Gaussian linear state space model (1.4)
to non-linear and non-Gaussian state space models. Indeed, we will say that the
time series {yt} is generated by a general (including linear Gaussian and nonlinear and non-Gaussian) state space model, if yt can be described by the following
distributions
p(yt | ��t), p(��t | ��t���1) and p(��0). (1.5)
This, very general, model setting assumes a distribution of yt , given some states,
a distribution of ��t , given the previous state ��t���1 and an initial state distribution
p(��0). It is implicitly assumed that given ��t , yt is conditionally independent of
past observations and states yt���1, yt���2,... and of ��t���1, ��t���2,..., but also of future
observations and states yt+1, yt+2,... and ��t+1, ��t+2,...; in other words, the
present state ��t holds all information from past and future data and states relevant
to the understanding and knowledge of yt . Likewise, given ��t���1, ��t is conditionally
independent of ��t���2, ��t���3,.... Simply put, we say that given the present (state at
time t), the past and the future are conditionally independent. More information
about this independence structure can be found in West and Harrison (1997). It is
worth noting that the above description fits the purposes of state space models for
discrete and roughly equally spaced observed data. An example of a continuoustime state space model is given in Sect. 1.3.4 and further discussed in the context of dynamical systems in Sect. 8.4.
1 / 1
ChatGPT
Gaussian Linear State Space Model and General State Space Model
1. Gaussian Linear State Space Model
:
If the error terms
��
t
��_t
��
t
���
,
��
t
��_t
��
t
���
and the initial state
��
0
��_0
��
0
���
are all assumed to follow Gaussian distributions, then the model as expressed in equation (1.3) is termed the Gaussian linear state space model. It can be mathematically defined by the expressions:
y
t
���
��
t
���
N
(
x
t
T
��
t
,
��
2
)
y_t | ��_t \sim N(x_t^T ��_t, ��^2)
y
t
���
���
��
t
���
���
N
(
x
t
T
���
��
t
���
,
��
2
)
��
t
���
��
t
���
1
���
N
(
F
t
��
t
���
1
,
Z
)
��_t | ��_{t���1} \sim N(F_t ��_{t���1},Z)
��
t
���
���
��
t
���
1
���
���
N
(
F
t
���
��
t
���
1
���
,
Z
)
In this context,
y
t
���
��
t
y_t | ��_t
y
t
���
���
��
t
���
represents the conditional distribution of
y
t
y_t
y
t
���
given the state
��
t
��_t
��
t
���
.
��
2
��^2
��
2
stands for the variance of
��
t
��_t
��
t
���
.
Z
Z
Z
is the covariance matrix for
��
t
��_t
��
t
���
.
2. Extension to General State Space Models
:
Expression (1.4) can be adapted to describe non-linear or non-Gaussian state space models. In general terms, a time series {
y
t
y_t
y
t
���
} is said to be generated by a state space model if it can be characterized by the distributions:
p
(
y
t
���
��
t
)
p(y_t | ��_t)
p
(
y
t
���
���
��
t
���
)
p
(
��
t
���
��
t
���
1
)
p(��_t | ��_{t���1})
p
(
��
t
���
���
��
t
���
1
���
)
p
(
��
0
)
p(��_0)
p
(
��
0
���
)
This model is extremely broad and assumes:
A distribution for
y
t
y_t
y
t
���
given certain states.
A distribution of
��
t
��_t
��
t
���
based on the preceding state
��
t
���
1
��_{t���1}
��
t
���
1
���
.
An initial state distribution
p
(
��
0
)
p(��_0)
p
(
��
0
���
)
.
3. Conditional Independence
:
A key feature of this model is its conditional independence structure:
Given the present state
��
t
��_t
��
t
���
,
y
t
y_t
y
t
���
is conditionally independent of prior observations and states (like
y
t
���
1
y_{t���1}
y
t
���
1
���
,
y
t
���
2
y_{t���2}
y
t
���
2
���
, etc.) and of future observations and states (like
y
t
+
1
y_{t+1}
y
t
+
1
���
,
y
t
+
2
y_{t+2}
y
t
+
2
���
, etc.).
Similarly, when considering
��
t
���
1
��_{t���1}
��
t
���
1
���
,
��
t
��_t
��
t
���
is conditionally independent of
��
t
���
2
��_{t���2}
��
t
���
2
���
,
��
t
���
3
��_{t���3}
��
t
���
3
���
, and so forth.
This reflects the idea that the present state captures all relevant information from past and future data, making past and future data conditionally independent when considering the current state.
4. More Insights
:
The conditional independence structure, as described, aligns with the objectives of state space models for data that are discrete and approximately equidistant in their observations. However, there are more advanced models for continuous-time data. Examples and discussions on these models can be found in various sources, with one such model detailed in Section 1.3.4 and further explored in the context of dynamical systems in Section 8.4.
Reference
: West and Harrison (1997) provide more in-depth understanding about the conditional independence structure in state space models.
Summary
:
The Gaussian Linear State Space Model, as its name suggests, employs Gaussian distributions for its error terms and initial state. This model can be broadened to accommodate non-linear and non-Gaussian variations, leading to the general state space model. A fundamental aspect of these models is the principle of conditional independence, where the present state encapsulates all the necessary information, making past and future data conditionally independent of the present.
1 / 1
1.3 Examples of State Space Models
This section describes some situations motivated by real-life problems, which can
be modelled with a state space model. It illustrates some of the many subject areas
that state space models find application.
1.3.1 Forecasting Air-Pollution Levels
Air pollution consists of the introduction of chemicals, particulate matter and
biological materials into the atmosphere, causing severe damage to the environment.
Many of the main air pollutants are contributing to the greenhouse effect, which is
considered to be the main human made factor that affects climate change.
Nitric oxide (NO), one of the most prominent air pollutants, is emitted from
high temperature combustion, and also produced naturally during thunderstorms by
electrical discharge. Figure 1.4 shows NO levels (in mg/m3) together with levels
of % humidity, mean daily temperature (in ���C), and wind speed (in m/s); the
measurements of these variables are collected daily covering January to December
2001 and they are provided by one of the sensors sites of the air-pollution networks
of Athens.
One of the objectives is to be able to use the covariates (here denoted by x1t���
humidity, x2t���temperature and x3t���wind speed) in order to forecast future values
of the NO levels (denoted by yt). Such information may be vital in issuing warning
messages to the community, should the pollution levels be expected to rise, e.g.
by preventing old people, and in particular those with respiratory related health
problems, access particular areas of the city. Another objective may be to establish
pollution trends and dynamics, so as to assess whether anti-pollution measures work
and assist policy makers.
A first model is a simple regression model of x1t, x2t, x3t on the response variable
yt , given by
yt = ��0 + ��1x1t + ��2x2t + ��3x3t +  t, (1.6)
where  t is an independent sequence, following a Gaussian distribution with zero
mean and some variance ��2, i.e.  t ��� N(0, ��2). The coefficient ��0 is the intercept
and ��1, ��2, ��3 are the coefficients of the covariates x1t, x2t, x3t . We can fit this
model by using standard regression methods, see e.g. Bingham and Fry (2010).
1 / 1
ChatGPT
State Space Models: An Example on Forecasting Air-Pollution Levels
Background
:
State space models are versatile statistical tools that can be applied to a variety of real-world problems. This section details an application in the domain of environmental science, particularly in forecasting air-pollution levels.
Air-Pollution
:
Air pollution results from the infusion of harmful chemicals, biological materials, and particulate matter into the atmosphere, leading to environmental degradation. Many key pollutants, including Nitric oxide (NO), play a role in augmenting the greenhouse effect, which in turn is a significant driver of human-induced climate change.
Data Overview
:
The data depicted in Figure 1.4 comprises daily measurements of:
NO levels in mg/m��.
Humidity percentage.
Mean daily temperature in ��C.
Wind speed in m/s.
These measurements, spanning January to December 2001, have been sourced from one of Athens' air-pollution network sensors.
Objective
:
The primary aim is to harness the covariates (humidity denoted by
x
1
t
x1_t
x
1
t
���
, temperature by
x
2
t
x2_t
x
2
t
���
, and wind speed by
x
3
t
x3_t
x
3
t
���
) to project future NO levels, represented by
y
t
y_t
y
t
���
. Anticipating NO levels is crucial for:
Issuing alerts to the public. For instance, elderly individuals, especially those with respiratory conditions, might be cautioned against visiting certain city areas when pollution is expected to surge.
Understanding pollution trends and dynamics to evaluate the efficacy of anti-pollution measures, thereby supporting policy decision-making.
Initial Model - Simple Regression
:
A preliminary modeling approach is to use a simple regression model with
x
1
t
x1_t
x
1
t
���
,
x
2
t
x2_t
x
2
t
���
, and
x
3
t
x3_t
x
3
t
���
as predictor variables and
y
t
y_t
y
t
���
as the dependent variable. The model can be represented as:
y
t
=
��
0
+
��
1
x
1
t
+
��
2
x
2
t
+
��
3
x
3
t
+
��
t
y_t = ��_0 + ��_1x1_t + ��_2x2_t + ��_3x3_t + ��_t
y
t
���
=
��
0
���
+
��
1
���
x
1
t
���
+
��
2
���
x
2
t
���
+
��
3
���
x
3
t
���
+
��
t
���
In this equation:
��
t
��_t
��
t
���
is an independent sequence with a Gaussian distribution having a mean of zero and variance
��
2
��^2
��
2
, i.e.,
��
t
���
N
(
0
,
��
2
)
��_t \sim N(0, ��^2)
��
t
���
���
N
(
0
,
��
2
)
.
��
0
��_0
��
0
���
represents the intercept.
��
1
��_1
��
1
���
,
��
2
��_2
��
2
���
, and
��
3
��_3
��
3
���
are coefficients corresponding to the covariates
x
1
t
x1_t
x
1
t
���
,
x
2
t
x2_t
x
2
t
���
, and
x
3
t
x3_t
x
3
t
���
, respectively.
This model can be fitted using standard regression techniques, as mentioned in resources like Bingham and Fry (2010).
Conclusion
:
State space models' applicability in predicting air pollution exemplifies their potential in tackling real-world issues. By incorporating environmental variables as covariates, such models can offer invaluable insights, facilitating timely interventions and informed policy-making.
1 / 1
If we define the state vector
��t = ������������ ��0 ��1 ��2 ��3 ������������ ,
then model (1.6) can be put in state space form by writing
yt = [1, x1t, x2t, x3t] ������������ ��0 ��1 ��2 ��3 ������������ +  t = xt ��t +  t, (1.7)
and
��t = ��t���1, (1.8)
for all t, with probability 1, i.e. ��t = ��t���1 =������= ��1 = ��
1 / 1
ChatGPT
State Space Representation of the Regression Model
:
State Vector Definition
:
Given a regression model, the state vector can be defined as:
��
t
=
[
��
0
��
1
��
2
��
3
]
\beta_t = \begin{bmatrix}
\beta_0 \\
\beta_1 \\
\beta_2 \\
\beta_3
\end{bmatrix}
��
t
���
=
���
���
���
��
0
���
��
1
���
��
2
���
��
3
���
���
���
���
���
This vector houses all the coefficients of our regression model, including the intercept.
State Space Form
:
Model (1.6) can be restructured into a state space format as:
y
t
=
[
1
x
1
t
x
2
t
x
3
t
]
[
��
0
��
1
��
2
��
3
]
+
��
t
=
x
t
T
��
t
+
��
t
y_t = \begin{bmatrix}
1 & x1_t & x2_t & x3_t
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\beta_2 \\
\beta_3
\end{bmatrix}
+ \delta_t = x_t^T \beta_t + \delta_t
y
t
���
=
[
1
���
x
1
t
���
���
x
2
t
���
���
x
3
t
���
���
]
���
���
���
��
0
���
��
1
���
��
2
���
��
3
���
���
���
���
���
+
��
t
���
=
x
t
T
���
��
t
���
+
��
t
���
Here,
x
t
T
x_t^T
x
t
T
���
refers to the transpose of the matrix formed by appending a 1 to the covariates
x
1
t
x1_t
x
1
t
���
,
x
2
t
x2_t
x
2
t
���
, and
x
3
t
x3_t
x
3
t
���
. Essentially, the observation
y
t
y_t
y
t
���
at time
t
t
t
is a linear combination of the state vector
��
t
\beta_t
��
t
���
and the covariates from the matrix
x
t
T
x_t^T
x
t
T
���
with an added noise term
��
t
\delta_t
��
t
���
.
State Transition
:
The state transition model is given by:
��
t
=
��
t
���
1
\beta_t = \beta_{t-1}
��
t
���
=
��
t
���
1
���
This equation implies that the state vector
��
t
\beta_t
��
t
���
does not evolve over time; instead, it remains constant. In other words, the coefficients
��
0
\beta_0
��
0
���
,
��
1
\beta_1
��
1
���
,
��
2
\beta_2
��
2
���
, and
��
3
\beta_3
��
3
���
are static across all time points.
So, equation (1.8) asserts that for any time point
t
t
t
, with absolute certainty (probability = 1), the state
��
t
\beta_t
��
t
���
is equal to its previous state
��
t
���
1
\beta_{t-1}
��
t
���
1
���
, which is again equal to its prior state
��
t
���
2
\beta_{t-2}
��
t
���
2
���
, and so on. This unchanging nature continues until
��
1
\beta_1
��
1
���
, which is itself equivalent to
��
\beta
��
.
Conclusion
:
In the state space formulation, the regression model is represented in terms of a state vector and an observation equation. The constant state transition model indicates that the coefficients in the regression are fixed and do not change over time. This setup is typical for a simple linear regression scenario where the relationship between the covariates and the response variable remains unchanged across observations.
1 / 1
It can be argued that model (1.6) is insufficient, because although the response
variable and covariate are time-varying, the ��i coefficients are time-invariant (for
i = 0, 1, 2, 3). Sometimes such a model is referred to as static regression model,
because its coefficients do not depend on time. However, as it is evidenced by
Fig. 1.4, the humidity and temperature covariates (x1t and x2t) are changing over
time and thus the coefficients ��i should be time-varying.
A simple regression model with time-varying coefficients, known also as
dynamic regression model, is to adopt (1.7), but to replace (1.8) by
��t = ��t���1 + ��t . (1.9)
where ��t is an independent sequence and ��t follows a four-dimensional Gaussian
distribution with zero mean vector and some covariance matrix. Equation (1.9)
implies that ��t ��� ��t���1, but the shock ��t allows for some local variation in the
��t coefficients. Equations (1.7) and (1.9) define a Gaussian linear state space model
(assuming that a Gaussian distribution is set for ��0)
1 / 1
ChatGPT
Dynamic Regression Model with Time-Varying Coefficients
:
The critique of model (1.6) is valid, especially when considering real-world phenomena where relationships between variables may evolve over time. In many real-world applications, particularly those involving environmental, economic, or social variables, static models (with time-invariant coefficients) may not capture the complexities and dynamics of the processes at hand.
To account for this time-varying nature of relationships, we introduce dynamic regression models. Let's break down the dynamic regression model presented:
Observation Equation
:
The observation equation remains the same as in the static model:
y
t
=
x
t
T
��
t
+
��
t
y_t = x_t^T \beta_t + \delta_t
y
t
���
=
x
t
T
���
��
t
���
+
��
t
���
This means that the observed value
y
t
y_t
y
t
���
is still a linear combination of the covariates and the coefficients, but now the coefficients (
��
t
\beta_t
��
t
���
) are allowed to change over time.
State Transition with Random Walk
:
In place of the static state transition, we now have:
��
t
=
��
t
���
1
+
��
t
\beta_t = \beta_{t-1} + \zeta_t
��
t
���
=
��
t
���
1
���
+
��
t
���
This suggests that the state at time
t
t
t
,
��
t
\beta_t
��
t
���
, is a continuation of the state at time
t
���
1
t-1
t
���
1
,
��
t
���
1
\beta_{t-1}
��
t
���
1
���
, with an added shock or noise,
��
t
\zeta_t
��
t
���
. This shock represents the local changes or variations in the coefficients.
Nature of the Shock
:
��
t
\zeta_t
��
t
���
is assumed to be an independent sequence. It follows a four-dimensional Gaussian distribution, representing variations in all four coefficients. It has a zero mean vector, which suggests that, on average, there's no systematic trend in the changes to the coefficients. However, the covariance matrix allows for variability in these changes, possibly even accounting for correlations in how the coefficients change with respect to one another.
Conclusion
:
Equations (1.7) and (1.9) together present a Gaussian linear state space model with the key characteristic of having time-varying coefficients. Such a model is crucial when working with processes where the relationship between the response and predictor variables changes over time. This dynamic regression model can adapt to the changing conditions, making it a more flexible and often more accurate representation of real-world processes compared to its static counterpart.
1 / 1
2.4 Statistics
2.4.1 Principle Set-Up and Objectives
Statistics is concerned with quantifying and managing uncertainty in observational
studies, may these be controlled experiments, or socio-economic or physical
phenomena. With observational study broadly we mean studies based on observed
outcomes, which are uncertain. A good introductory treatment of Statistics can be
found in Trosset (2009).
Uncertainty arises in all walks of life. In climate change, for example, the
potential increase of the global temperature is hugely uncertain, as is the extent
to this increase attributed to human-made actions. In a physical system the output
signal may be uncertain due to measurement error and in economics fluctuations of
asset prices are uncertain due to market and investors��� movements.
Considering a vector x = [x1, x2,...,xn] of n observed or recorded mea���surements we can postulate that uncertainty around the values of x is generated
by x being a particular realisation of a random vector X = [
Thus, it is natural to think that the probability distribution of
X1, X2,...,Xn] . X will summarise the
uncertainty around x and thus it may be used to describe the generating process of
x and to forecast future values of x. This distribution will typically depend upon
some parameter vector ��, which is responsible for the shape of the distribution of
X. We write p(x | �� ) to indicate the p.d.f. of X (if X is continuous) or the p.m.f.
of X (if X is discrete). Statistical inference is concerned about estimating ��, based
on the observed data x1, x2,...,xn and hence provide forecasts of future values of
x, based on this observed data. Within the above model-based framework two main
estimation approaches may be deployed
1. Maximum likelihood inference (frequentist statistics); and
2. Posterior inference (Bayesian statistics).
In (1) we consider that �� is a fixed, but known quantity and estimation procedures
largely involve maximum likelihood analysis, see e.g. Sect. 2.4.2 below. In (2)
�� is assumed to be random and estimation procedures involve the derivation of
the conditional distribution of ��, given the data x; Sect. 2.4.3 discusses Bayesian
inference and gives two examples for illustration purposes.
2.4 Statistics 49
2.4.2 Maximum Likelihood Estimation: The EM Algorithm
The likelihood function has a central role on the development of estimators in
statistical inference. The likelihood function, a function of the unknown param���eter or parameter vector ��, is just the joint distribution of the random sample
X1, X2,...,Xn, given ��, i.e.
L(��; x) = p(x1, x2,...,xn | �� ),
where x = [x1, x2,...,xn] . The likelihood function is a (deterministic) function
of ��, which gives a measure of how likely is �� for a given sample x1, x2,...,xn. If
�� is not very likely then L(��; x) should be small, while if it is likely the value of
L(��; x) should be large. Thus, say for two values ��1 and ��2 of �� the inequality
L(��1; x) > L(��2; x)
will favour ��1 as being more likely than ��2, for this sample. This naturally leads us
to choose the value �� that maximises the likelihood function, hence the maximum
likelihood principle. Usually, for computational efficiency, we choose to maximise
the logarithm of the likelihood, known as log-likelihood function, written as
(��; x) = logL(��; x).
In many situations it is hard to find the maximum of the likelihood function.
The expectation maximisation (EM) algorithm, originally developed in Dempster
et al. (1977) and further discussed in many textbooks, see e.g. Fahrmeir and Tutz
(2001), is a popular choice of an indirect maximisation algorithm of the likelihood
L(��; x). The EM algorithm is an iterative algorithm, which consists of two steps:
in the E-step the conditional expectation of the log-likelihood function is computed,
given the past sample values and the current estimate of ��, and in the M-step a new
estimate of �� is computed that maximises the expected log-likelihood function from
the E-step. Below we provide description and the foundations of the EM algorithm,
which is then used in Sect. 4.3.1 to derive the EM algorithm for state space models.
Our aim is to maximise L(��; x) with respect to ��. Consider an unobserved
discrete random vector Z and denote with Rz the domain of the p.m.f. of Z. We
can express L(��; x) in terms of Z as
L(��; x) = p(x | �� ) =  z���Rz
p(x, z | �� ).
50 2 Matrix Algebra, Probability and Statistics
Notice that this is the marginal distribution of X, after we sum out Z. Then the EM
algorithm is
1. Initialise ����(0);
2. E-step: calculate the conditional expectation
Q(�� | ����(k)) = E[logL(��; x, z) | x, ����(k)];
3. M-step: find the maximum
����(k+1) = arg max�� Q(�� | ����(k));
4. Update k ��� k + 1 and repeat steps (2)-(3) until convergence (see below).
As k ��� ���, ����(k) converges to the maximum likelihood estimate ���� of L(��; x). In
practice the algorithm terminates when ����(k+1) and ����(k) are close to each other, hence
convergence is assumed. The rule to check for convergence is if the Euclidean norm
of ����(k+1) ��� ����(k) is smaller to a pre specified tolerance, i.e.


����(k+1) ��� ����(k) 
 < Tol.
Usually we set Tol = 0.001 or smaller.
Before we prove the correctness of the algorithm we give the Gibbs inequality.
For any two discrete distributions with p.m.f.���s p(x) and q(x), respectively, we have
x���Rx
p(x)log p(x) ��� x���Rx
p(x)log q(x), (2.18)
with equality if and only if p(x) = q(x), for all x ��� Rx , where Rx is the domain of
p(x).
To prove this we use the well known inequality log x ��� x ��� 1, for any x > 0.
x���Rx
p(x)log q(x)
p(x) ��� x���Rx
p(x) 
 q(x)
p(x) ��� 1 =  x���Rx
q(x) ��� x���Rx
p(x)
=  x���Rx
q(x) ��� 1 ��� 0
and so  x���Rx p(x)log p(x) ���  x���Rx p(x)log q(x).
2.4 Statistics 51
Now we prove the correctness of the EM algorithm. From the definition of the
joint distribution p(x, z | �� ) = p(z | x, �� )p(x | �� ) we have
p(x | �� ) = p(x, z | �� )
p(z | x,��)
and so
log p(x | �� ) = log p(x, z | �� ) ��� logp(z | x,��)
=  z���Rz
p(z | x, ����(k))log p(x, z | �� )




expectation of logp(x,z|�� )
��� z���Rz
p(z | x, ����(k))log p(z | x,��)




expectation of logp(z|x,�� )
= Q(�� | ����(k)) + G(�� | ����(k)).
Then
log p(x | �� ) ��� log p(x | ����(k)) = Q(�� | ����(k)) ��� Q(����(k) | ����(k)) +G(�� | ����(k)) ��� G(����(k) | ����(k)).
Now applying the Gibbs inequality (2.18) with p(x) = p(z | x, ����(k)) and q(x) =
p(z | x,��), we obtain
G(�� | ����(k)) ��� G(����(k) | ����(k)).
Hence
log p(x | �� ) ��� log p(x | ����(k)) ��� Q(�� | ����(k)) ��� Q(����(k) | ����(k)).
From this inequality, an improvement in Q (Q(�� | ����(k)) ��� Q(����(k) | ����(k))) results in
an improvement in L(��; x) = log p(x | �� ) (logp(x | �� ) ��� p(x | ����(k))).
As we obtain in the next iteration ����(k+1 as the maximum of Q(�� | ����(k)), an
improvement in L(��; x) is achieved. As a result, as k ��� ���, ����(k) converges to the
maximum likelihood estimate ����.
1 / 1
ChatGPT
The section you provided is a concise introduction to statistical inference, specifically focusing on the Maximum Likelihood Estimation (MLE) method, and the Expectation-Maximization (EM) algorithm, which is an iterative approach to find MLE.
Let's break down the concepts:
2.4.1 Principle Set-Up and Objectives
Statistics
deals with managing uncertainty in observational studies. Uncertainties arise from various sources, such as measurement errors, environmental fluctuations, and the unpredictable nature of events.
Observational studies are based on observed outcomes, which are uncertain. Any set of observed outcomes is considered a realization of some random process.
The uncertainty can be captured by a probability distribution, which is typically parameterized by a vector
��
\theta
��
.
The goal in statistics is to estimate this parameter vector
��
\theta
��
based on observed data.
Two primary estimation approaches are:
Maximum likelihood inference (from the frequentist perspective)
Posterior inference (from the Bayesian perspective)
2.4.2 Maximum Likelihood Estimation: The EM Algorithm
Likelihood Function
: Represents how likely a set of observed outcomes is given a parameter
��
\theta
��
.
Maximizing the Likelihood Function
: The aim is to find the parameter
��
\theta
��
that maximizes the likelihood, as this would be the most probable parameter value given the observed data.
Log-Likelihood
: It's often more computationally feasible to maximize the log of the likelihood instead of the likelihood itself.
EM Algorithm
: In cases where directly maximizing the likelihood is complex, the EM algorithm provides an iterative approach to estimate the maximum likelihood.
E-step (Expectation)
: Calculate the expected log-likelihood given the current parameter estimate.
M-step (Maximization)
: Update the parameter estimate to maximize the expected log-likelihood.
The algorithm iteratively refines the parameter estimate until convergence.
The subsequent details delve into the mathematical properties of the EM algorithm, including its foundation and proof of its convergence. The Gibbs inequality is used as a critical tool in establishing these properties.
In summary, this section provides foundational concepts on the importance of statistical inference and introduces the EM algorithm as a powerful tool for maximum likelihood estimation in situations where direct maximization is challenging.
1 / 1
2.4.3 Bayesian Inference
Bayesian statistics has been developed extensively over the past three decades, in
particular the advance of computationally intensive estimation methods have made
the Bayesian paradigm a very attractive estimation approach. Excellent expositions
of Bayesian methods can be found in O���Hagan and Forster (2004), Leonard and Hsu
(1999), Gamerman and Lopes (2006) and Robert (2007), among others.
52 2 Matrix Algebra, Probability and Statistics
In Bayesian inference unknown parameters are assumed to form a random
vector ��. The distribution p(�� ) of �� prior to observing data is known as the prior
distribution of �� and reflects the prior belief we may have before observing the
data. Apart from this prior belief, we are going to adopt the model formulation
of Sect. 2.4.1, i.e. that the data generating process is described by the distribution
p(x | �� ). In other words the conditional distribution p(x | �� ) is a model statement
which asserts that if we know the parameter vector ��, then we know the distribution
of the data p(x | �� ) = p(x1,...,xn | �� ). In our notation, p(x | �� ) = L(��; x) is just
the likelihood function of ��. The principle building block in Bayesian inference is
the Bayes theorem, which states that the conditional distribution of �� given the data
x is given by
p(�� | x) = p(x | �� )p(�� )
p(x) ,
or simply
p(�� | x) ��� L(��; x)p(�� ), (2.19)
where 1/p(x) is known as the proportionality constant. The term p(�� | x) is the
posterior distribution of ��, because it is the distribution of �� after (a posteriori)
the data x is observed. Sometimes p(�� | x) is referred to as the updated belief
or posterior belief and the likelihood L(��; x) referred to as the evidence the data
provides. The marginal distribution p(x) of X is the forecast distribution of X, i.e.
p(x) = "  p(x, �� ) d�� = "  p(x | �� )p(�� ) d�� ,
where  is the domain of �� (if X is discrete the integral above is replaced by
a relevant sum). In many situations the computation of p(x) is not available in
closed form, since integration of high dimensional integrals becomes very quickly
intractable. In such cases simulation-based inference is usually adopted, in particular
sequential Monte Carlo and Markov chain Monte Carlo methods; the former
is discussed in this book in Sect. 6.7 and the latter is discussed in Sect. 5.7
(introduction to MCMC and Gibbs sampling) and in Sect. 6.8 (Metropolis-Hastings
algorithm). Book-length treatment of MCMC methods can be found in Gamerman
and Lopes (2006) and Robert (2007). Below two examples are provided to illustrate
the utility and application of Bayesian analysis.
Example 2.1 (Bayesian Regression) Consider the linear model
yi = xi �� +  i,
where yi denotes a scaler response variable, xi is a p-dimensional vector containing
p covariates or explanatory variables and  i denotes an i.i.d. random variable,
usually assumed to follow the normal distribution N(0, ��2), for some variance
2.4 Statistics 53
��2 and for i = 1,...,n. This model is revisited in Sect. 3.1, where regression
is discussed from a least squares and maximum likelihood standpoints. A detailed
discussion of Bayesian analysis for the linear model is given in Press (1989, Chapter
5) and in O���Hagan and Forster (2004, Chapter 11). This model is usually cast in
matrix form as
y = X�� + ,
where y = [y1, y2,...,yn] ,  = [ 1, 2,...,n] and
X = ��������������� x1 x2... xn ��������������� .
Thus, conditionally on ��, y follows a normal distribution
y | �� ��� N(X��, ��2I). (2.20)
Let us consider that the prior distribution of �� is normal, given by
�� ��� N( ���� , R), (2.21)
where the prior expectation ���� and the prior covariance matrix R of �� are assumed
known.
From (2.20) and (2.21) by applying Bayes theorem (2.19) the posterior distribu���tion of �� is
p(�� | y) ��� p(y | ��)p(��)
��� exp ( ���21 %
(y ��� X��) (y ��� X��)/��2 + (�� ��� ����) R���1(�� ��� ����)& )
��� exp 
 ���21
(�� ��� ����) P���1(�� ��� ����) ,
where
���� = P(X y/��2 + R���1 ����) and P���1 = R���1 + X X/��2. (2.22)
Hence the posterior distribution of �� is �� | y ��� N( ����, P). Therefore, credible
intervals and other a posteriori features can be extracted from this distribution.
We note that if R���1 = 0, then P = ��2(X X)���1 (assuming that X is of full
rank p) and so the posterior mean of �� is equal to ���� = (X X)���1X y, which is the
least squares and maximum likelihood estimates of ��; see the relevant discussion in
54 2 Matrix Algebra, Probability and Statistics
Sect. 3.1. In this case (R���1 = 0) the elements of R converge to infinity and prior
(2.21) is an improper uniform distribution; for a related discussion see O���Hagan
and Forster (2004, Chapter 11). In practice we may set a large covariance matrix,
say R = 1000I, so that R���1 ��� 0. This is known as weakly informative prior
specification and is discussed in Sect. 4.5 and in O���Hagan and Forster (2004) and
Robert (2007).
By writing R���1 = P���1 ���X X/��2 from (2.22) and substituting it in ���� we obtain
���� = ���� +
PX
��2 (y ��� X ����), (2.23)
or in words that the posterior mean ���� of �� is equal to the prior mean ���� plus a gain
factor K = PX /��2 times the residual e = y ��� X ����. Here X ���� is the prediction of
y (hence their difference is the residual e). Equation (2.23) is important, as we will
see in Sect. 3.2 it is generalised to provide the celebrated Kalman filter within the
context of state space and time series modelling.
Example 2.2 (Beta-Binomial Model) Consider that �� = �� denotes a probability of
success of independent trails, such that
X | �� ��� Binom(n, �� )
follows a binomial distribution with probability of success �� and size n. Suppose
that a prior distribution for �� is the beta distribution
�� ��� Beta(2, 3).
By applying Bayes rule (2.19) we have that the posterior distribution of �� given
X = x is proportional to
p(�� | X = x) ��� p(x | �� )p(�� )
��� ��x+2���1(1 ��� �� )n+3���x���1,
which is proportional to a beta distribution with parameters x +2 and n+3���x, i.e.
�� | X = x ��� Beta(x + 2, n + 3 ��� x).
For example, if n = 5 and x is observed to be equal to 4, then
E(�� | X = 4) = 6
10.
In this case we observe that the posterior mean of �� is larger than the prior mean of
��, which is E(�� ) = 2/5.
2.5 Exercises 55
The forecast distribution of X can be computed as
p(x) = " 01
p(x | �� )p(�� ) d��
= (5)
(2)(3) nx	 " 01 ��x+2���1(1 ��� �� )n+3���x���1 d��
= 10 nx	
(x + 2)(n + 3 ��� x)
(n + 5) = 10(x + 1)(x + 2)(n ��� x + 1)(n ��� x + 2)(n ��� x + 3)
(n + 1)(n + 2)(n + 3)(n + 3)(n + 4)(n + 5) ,
where we have used (x) = x(x ��� 1) = x!, for x integer. Also from the posterior
beta distribution �� | X = x ��� Beta(x + 2, n + +3 ��� x), with * 01 p(�� | x) d�� = 1
or
"
01 (x + 2 + n + 3 ��� x)
(x + 2)(n + 3 ��� x)
��x+2���1(1 ��� �� )n+3���x���1 d�� = 1,
it follows that
"
01 ��x+2���1(1 ��� �� )n+3���x���1 d�� = (x + 2)(n + 3 ��� x)
(n + 5) .
As it is evident, in this example, it is harder to compute p(x) than it is to compute
the posterior p(�� | x). The above two examples illustrate the use of conjugate prior
distributions, having the property that the posterior distribution has the same form
as the prior, only differing on their respective parameters (e.g. in Example 2.1 both
the prior and the posterior of �� are normal distributions and in Example 2.2 both
the prior and the posterior are beta distributions). The conjugate prior distributions
have been criticised as being limited, see e.g. Robert (2007, Chapter 3), but they are
certainly a worthy consideration in recursive estimation of time series, because they
facilitate a sequential prior to posterior updating over time.
1 / 1
ChatGPT
Bayesian inference is a fundamental approach in statistical analysis and modeling that relies on the concept of probability to describe uncertainty. The text you provided gives a broad overview and explanation of Bayesian inference, focusing on its theoretical foundation and a few applied examples. Here's a summarized breakdown:
1. Core Concept
Bayesian statistics view unknown parameters as random variables with distributions.
Before seeing data, we have a prior distribution representing our beliefs about the parameters.
Once we observe the data, we update our beliefs to obtain the posterior distribution.
The process of updating from prior to posterior relies on Bayes' theorem.
2. Bayes' Theorem
:
p
(
��
���
x
)
���
L
(
��
;
x
)
p
(
��
)
p(\theta | x) \propto L(\theta; x) p(\theta)
p
(
��
���
x
)
���
L
(
��
;
x
)
p
(
��
)
Where:
p
(
��
���
x
)
p(\theta | x)
p
(
��
���
x
)
: Posterior distribution, our updated belief after seeing the data.
L
(
��
;
x
)
L(\theta; x)
L
(
��
;
x
)
: Likelihood function, showing how the data behaves given the parameters.
p
(
��
)
p(\theta)
p
(
��
)
: Prior distribution, our initial belief before seeing the data.
The proportionality (���) arises because we're often not interested in the exact probability but a quantity that's proportional to it.
3. Computational Methods
Computation of the posterior can be challenging, especially in high dimensions.
Methods such as Sequential Monte Carlo, Markov Chain Monte Carlo (MCMC), and Gibbs sampling can be used to estimate the posterior distribution.
4. Examples
:
Bayesian Regression
:
A linear model is expressed as:
y
i
=
x
i
T
��
+
��
i
y_i = x_i^T \beta + \epsilon_i
y
i
���
=
x
i
T
���
��
+
��
i
���
.
By setting certain prior distributions and using the Bayes theorem, we can derive the posterior distribution for the coefficients,
��
\beta
��
.
This framework can easily be extended to more advanced topics like the Kalman filter for state space and time series modeling.
Beta-Binomial Model
:
Here, we're interested in estimating a probability of success,
��
\pi
��
, in a binomial experiment.
If we have a Beta prior for
��
\pi
��
, the resulting posterior, after observing some data, is also a Beta distribution but with updated parameters.
This demonstrates the property of conjugacy: when the prior and posterior distributions are of the same family.
5. Conjugate Priors
:
These are priors that, when combined with a likelihood function, result in a posterior distribution of the same form as the prior.
They're mathematically convenient but may not always be the most appropriate for a given problem.
6. Criticisms and Advancements
:
Conjugate priors have faced criticism for being too limited or restrictive.
However, they are practical in some scenarios, especially in recursive estimation tasks where updating beliefs over time is essential.
In conclusion, Bayesian inference provides a robust framework for understanding data and making predictions. The approach is unique in that it combines prior beliefs with observed data to provide a comprehensive understanding of underlying phenomena. While computational challenges exist, especially with complex models, modern techniques offer solutions that make Bayesian methods practical and widely applicable in numerous fields.
1 / 1
1. Show that for any non-singular n �� n matrices A and B the following is true
(A + B)���1 = B���1(A���1 + B���1)���1A���1.
2. If I is the n �� n identity matrix, show that trace(cI) = cn. Hence show that
trace(0) = 0.
1 / 1
ChatGPT
Problem 1:
Given:
(
A
+
B
)
���
1
(A + B)^{-1}
(
A
+
B
)
���
1
To prove:
(
A
+
B
)
���
1
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
(A + B)^{-1} = B^{-1}(A^{-1} + B^{-1})^{-1}A^{-1}
(
A
+
B
)
���
1
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
Proof:
To prove this, let's begin by multiplying both sides of the desired equation by the matrix
(
A
+
B
)
(A + B)
(
A
+
B
)
:
I
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
(
A
+
B
)
I = B^{-1}(A^{-1} + B^{-1})^{-1}A^{-1}(A + B)
I
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
(
A
+
B
)
Using the distributive property, we can expand the right side:
I
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
A
+
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
B
I = B^{-1}(A^{-1} + B^{-1})^{-1}A^{-1}A + B^{-1}(A^{-1} + B^{-1})^{-1}A^{-1}B
I
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
A
+
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
B
This simplifies to:
I
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
+
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
B
I = B^{-1}(A^{-1} + B^{-1})^{-1} + B^{-1}(A^{-1} + B^{-1})^{-1}A^{-1}B
I
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
+
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
B
Now, let's use the identity
I
=
A
A
���
1
I = AA^{-1}
I
=
A
A
���
1
:
I
=
B
���
1
+
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
B
I = B^{-1} + B^{-1}(A^{-1} + B^{-1})^{-1}A^{-1}B
I
=
B
���
1
+
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
B
If we multiply both sides of the initial equation
(
A
+
B
)
���
1
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
(A + B)^{-1} = B^{-1}(A^{-1} + B^{-1})^{-1}A^{-1}
(
A
+
B
)
���
1
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
by
A
���
1
B
A^{-1}B
A
���
1
B
, we will have:
A
���
1
B
(
A
+
B
)
���
1
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
A
���
1
B
A^{-1}B(A + B)^{-1} = B^{-1}(A^{-1} + B^{-1})^{-1}A^{-1}A^{-1}B
A
���
1
B
(
A
+
B
)
���
1
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
A
���
1
B
On the left side,
A
���
1
B
(
A
+
B
)
���
1
A^{-1}B(A + B)^{-1}
A
���
1
B
(
A
+
B
)
���
1
is equivalent to
A
���
1
+
B
���
1
A^{-1} + B^{-1}
A
���
1
+
B
���
1
. This is based on the matrix inversion lemma, which provides a formula for the inverse of a sum of two matrices. The matrix inversion lemma states:
(
A
+
B
)
���
1
=
A
���
1
���
A
���
1
B
(
A
���
1
+
B
���
1
)
���
1
A
���
1
(A + B)^{-1} = A^{-1} - A^{-1}B(A^{-1} + B^{-1})^{-1}A^{-1}
(
A
+
B
)
���
1
=
A
���
1
���
A
���
1
B
(
A
���
1
+
B
���
1
)
���
1
A
���
1
Using this lemma, it's clear that:
(
A
+
B
)
���
1
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
(A + B)^{-1} = B^{-1}(A^{-1} + B^{-1})^{-1}A^{-1}
(
A
+
B
)
���
1
=
B
���
1
(
A
���
1
+
B
���
1
)
���
1
A
���
1
Thus, the given statement is proved.
Problem 2:
Given:
I
I
I
is the
n
��
n
n \times n
n
��
n
identity matrix
To prove:
t
r
a
c
e
(
c
I
)
=
c
n
trace(cI) = cn
t
r
a
ce
(
c
I
)
=
c
n
Proof:
The trace of a matrix is the sum of the elements on its diagonal. For the identity matrix
I
I
I
, all diagonal elements are 1, and all off-diagonal elements are 0. When this matrix is multiplied by a scalar
c
c
c
, all diagonal elements become
c
c
c
, and all off-diagonal elements remain 0. Thus, the trace of
c
I
cI
c
I
is:
t
r
a
c
e
(
c
I
)
=
c
+
c
+
c
+
.
.
.
+
c
trace(cI) = c + c + c + ... + c
t
r
a
ce
(
c
I
)
=
c
+
c
+
c
+
...
+
c
(n times)
This sums up to:
t
r
a
c
e
(
c
I
)
=
c
n
trace(cI) = cn
t
r
a
ce
(
c
I
)
=
c
n
To prove:
t
r
a
c
e
(
0
)
=
0
trace(0) = 0
t
r
a
ce
(
0
)
=
0
Proof:
A matrix with all elements equal to 0 has a trace of 0 since the sum of its diagonal elements is 0. Hence:
t
r
a
c
e
(
0
)
=
0
trace(0) = 0
t
r
a
ce
(
0
)
=
0
1 / 1
3. Show that trace(ABC) = trace(CAB) = trace(BCA).
4. Let X be a symmetric matrix of variables. Evaluate the partial derivatives
���trace(AXkB) ���X , ��� log |AXkB| ���X
and
���trace(AX���1B) ���X ,
where k is a positive integer and A,B are any matrices with constants.
5. For a n �� n matrix A and for any non-zero n-dimensional vector x show that


A 
= |x Ax|,
is a matrix norm, where |��| denotes modulus.
If limk������ Ak = 0, use the above formula to show
���k=0 Ak = (I ��� A)���1.
6. The random variable X follows the geometric distribution, if its p.m.f. is
p(x) = P (X = x) = (1 ��� �� )x��, x = 0, 1, 2,...
This distribution is generated as the number of failures until the first success in
independent Bernoulli trials each having probability of success ��.
Show that, for integer x, the c.d.f. of X is
F (x) = 1 ��� (1 ��� �� )x+1.
Show that the expectation and the variance of X are
E(X) = 1 ��� �� ��
and Var(X) = 1 ��� �� ��2 .
Hint: for E(X): differentiate both sides of
���x=0(1 ��� �� )x�� = 1,
with respect to ��. A similar argument can be applied for the variance.
7. For any n, x > 0 show
(n + x)
x!(n) =  n + x ��� 1 x
1 / 1
ChatGPT
Let's solve each part one by one.
3. Trace properties
Given three matrices A, B, and C, we need to show:
trace
(
A
B
C
)
=
trace
(
C
A
B
)
=
trace
(
B
C
A
)
\text{trace}(ABC) = \text{trace}(CAB) = \text{trace}(BCA)
trace
(
A
BC
)
=
trace
(
C
A
B
)
=
trace
(
BC
A
)
Proof:
The trace of a matrix is the sum of its diagonal elements. A crucial property of trace is:
trace
(
A
B
)
=
trace
(
B
A
)
\text{trace}(AB) = \text{trace}(BA)
trace
(
A
B
)
=
trace
(
B
A
)
Using the above property, we get:
trace
(
A
B
C
)
=
trace
(
C
A
B
)
\text{trace}(ABC) = \text{trace}(CAB)
trace
(
A
BC
)
=
trace
(
C
A
B
)
trace
(
C
A
B
)
=
trace
(
B
C
A
)
\text{trace}(CAB) = \text{trace}(BCA)
trace
(
C
A
B
)
=
trace
(
BC
A
)
Thus, we can say:
trace
(
A
B
C
)
=
trace
(
C
A
B
)
=
trace
(
B
C
A
)
\text{trace}(ABC) = \text{trace}(CAB) = \text{trace}(BCA)
trace
(
A
BC
)
=
trace
(
C
A
B
)
=
trace
(
BC
A
)
4. Partial derivatives of matrix functions
Given
X
X
X
is a symmetric matrix of variables, and A, B are matrices with constants.
i) The derivative with respect to X of
trace
(
A
X
k
B
)
\text{trace}(AX^kB)
trace
(
A
X
k
B
)
:
Using the cyclic property of trace:
trace
(
A
X
k
B
)
=
trace
(
X
k
B
A
)
\text{trace}(AX^kB) = \text{trace}(X^kBA)
trace
(
A
X
k
B
)
=
trace
(
X
k
B
A
)
Differentiating with respect to X, we get (using the chain rule and properties of traces):
���
trace
(
X
k
B
A
)
���
X
=
k
B
X
k
���
1
B
A
\frac{\partial \text{trace}(X^kBA)}{\partial X} = kB X^{k-1}BA
���
X
���
trace
(
X
k
B
A
)
���
=
k
B
X
k
���
1
B
A
ii) The derivative with respect to X of
trace
(
A
X
���
1
B
)
\text{trace}(AX^{-1}B)
trace
(
A
X
���
1
B
)
:
Using properties of matrix derivatives:
���
trace
(
A
X
���
1
B
)
���
X
=
���
A
X
���
1
B
X
���
1
\frac{\partial \text{trace}(AX^{-1}B)}{\partial X} = -AX^{-1}BX^{-1}
���
X
���
trace
(
A
X
���
1
B
)
���
=
���
A
X
���
1
B
X
���
1
iii) The derivative with respect to X of
log
���
���
A
X
k
B
���
\log|AX^kB|
lo
g
���
A
X
k
B
���
:
This requires more extensive computation, and can be derived from properties of determinants and matrix derivatives.
5. Matrix Norm
Given:
���
A
���
=
���
x
T
A
x
���
���
x
���
\|A\| = \frac{|x^TAx|}{|x|}
���
A
���
=
���
x
���
���
x
T
A
x
���
���
To show: This is a matrix norm, where
���
.
���
|.|
���.���
denotes modulus.
This involves showing that the definition satisfies the properties of a norm. The properties include:
a)
���
A
���
���
0
\|A\| \geq 0
���
A
���
���
0
and
���
A
���
=
0
\|A\| = 0
���
A
���
=
0
if and only if
A
=
0
A = 0
A
=
0
.
b)
���
A
+
B
���
���
���
A
���
+
���
B
���
\|A + B\| \leq \|A\| + \|B\|
���
A
+
B
���
���
���
A
���
+
���
B
���
(Triangle inequality)
c)
���
��
A
���
=
���
��
���
���
A
���
\|\alpha A\| = |\alpha| \|A\|
���
��
A
���
=
���
��
������
A
���
for any scalar
��
\alpha
��
.
Each of these properties can be shown using the definition.
For the second part of the question: If
lim
���
k
���
���
A
k
=
0
\lim_{k \to \infty} A^k = 0
lim
k
���
���
���
A
k
=
0
, then:
���
k
=
0
���
A
k
=
(
I
���
A
)
���
1
\sum_{k=0}^{\infty} A^k = (I - A)^{-1}
���
k
=
0
���
���
A
k
=
(
I
���
A
)
���
1
This is the result of the geometric series for matrices.
6. Geometric Distribution
To find the c.d.f.:
F
(
x
)
=
P
(
X
���
x
)
=
���
i
=
0
x
(
1
���
��
)
i
��
F(x) = P(X \leq x) = \sum_{i=0}^{x} (1-\pi)^i \pi
F
(
x
)
=
P
(
X
���
x
)
=
���
i
=
0
x
���
(
1
���
��
)
i
��
=
��
+
(
1
���
��
)
��
+
(
1
���
��
)
2
��
+
.
.
.
+
(
1
���
��
)
x
��
= \pi + (1-\pi)\pi + (1-\pi)^2\pi + ... + (1-\pi)^x\pi
=
��
+
(
1
���
��
)
��
+
(
1
���
��
)
2
��
+
...
+
(
1
���
��
)
x
��
This is a geometric series. Using the formula for the sum of a geometric series, we get:
F
(
x
)
=
1
���
(
1
���
��
)
x
+
1
F(x) = 1 - (1-\pi)^{x+1}
F
(
x
)
=
1
���
(
1
���
��
)
x
+
1
For
E
(
X
)
E(X)
E
(
X
)
:
Differentiate both sides of:
���
x
=
0
���
(
1
���
��
)
x
��
=
1
\sum_{x=0}^{\infty} (1-\pi)^x\pi = 1
���
x
=
0
���
���
(
1
���
��
)
x
��
=
1
With respect to
��
\pi
��
, and using the hint provided, we can derive
E
(
X
)
=
1
���
��
��
E(X) = \frac{1-\pi}{\pi}
E
(
X
)
=
��
1
���
��
���
.
For variance, a similar differentiation approach can be applied.
7. Combinatorial Identity
The provided expression appears to involve factorials and combinations. The equation seems to represent a combinatorial identity, but it's not presented clearly. If you could provide a clearer representation or specify the notations, I would be able to assist further!
1 / 1
8. Let X be a random variable that follows the negative binomial distribution X ���
NegBinom(��, �� ), for some known �� > 0 and probability ��. Show that

�� + x ��� 1 x 	 =  x + �� ��� 1 �� ��� 1 	
hence the p.m.f. of X can be written as
p(x) = P (X = x) =  �� + x ��� 1 x 	 (1 ��� �� )����x, x = 0, 1, 2,...
9. The random variable X follows the Laplace distribution, if its p.d.f. is given by
p(x) = 21b exp ���|x ��� ��| b 	 , x ��� R,
where �� is a location parameter and b > 0 is a scale parameter. Show that the
c.d.f. of X is
F (x) =  12 exp  x�����b  , x<��
1 ��� 12 exp  ���x�����b  , x ��� ��
1 / 1
ChatGPT
8. Negative Binomial Distribution:
Let's first derive the combinatorial identity. The binomial coefficient can be written as:
(
n
k
)
=
n
!
k
!
(
n
���
k
)
!
{n \choose k} = \frac{n!}{k!(n-k)!}
(
k
n
���
)
=
k
!
(
n
���
k
)!
n
!
���
Let's start with the given expression:
(
��
+
x
���
1
x
)
{�� + x - 1 \choose x}
(
x
��
+
x
���
1
���
)
Using the binomial coefficient formula, this can be written as:
(
��
+
x
���
1
)
!
x
!
(
��
���
1
)
!
\frac{(�� + x - 1)!}{x!(�� - 1)!}
x
!
(
��
���
1
)!
(
��
+
x
���
1
)!
���
The other side of the equation is:
(
x
+
��
���
1
��
���
1
)
{x + �� - 1 \choose �� - 1}
(
��
���
1
x
+
��
���
1
���
)
This can be written as:
(
x
+
��
���
1
)
!
(
��
���
1
)
!
x
!
\frac{(x + �� - 1)!}{(�� - 1)!x!}
(
��
���
1
)!
x
!
(
x
+
��
���
1
)!
���
Clearly, the two expressions are identical, and hence, the combinatorial identity holds.
Given this, the p.m.f. for the negative binomial distribution can be written as:
p
(
x
)
=
P
(
X
=
x
)
=
(
��
+
x
���
1
x
)
(
1
���
��
)
��
��
x
,
p(x) = P(X = x) = {�� + x - 1 \choose x} (1-��)^����^x,
p
(
x
)
=
P
(
X
=
x
)
=
(
x
��
+
x
���
1
���
)
(
1
���
��
)
��
��
x
,
for
x
=
0
,
1
,
2
,
.
.
.
x = 0, 1, 2, ...
x
=
0
,
1
,
2
,
...
9. Laplace Distribution:
To find the c.d.f
F
(
x
)
F(x)
F
(
x
)
, we need to integrate the p.d.f.
p
(
x
)
p(x)
p
(
x
)
.
Given:
p
(
x
)
=
1
2
b
e
���
���
x
���
��
���
b
p(x) = \frac{1}{2b} e^{-\frac{|x - ��|}{b}}
p
(
x
)
=
2
b
1
���
e
���
b
���
x
���
��
���
���
When
x
<
��
x < ��
x
<
��
:
F
(
x
)
=
���
���
���
x
1
2
b
e
x
���
��
b
d
x
F(x) = \int_{-\infty}^{x} \frac{1}{2b} e^{\frac{x - ��}{b}} dx
F
(
x
)
=
���
���
���
x
���
2
b
1
���
e
b
x
���
��
���
d
x
=
1
2
(
e
x
���
��
b
)
���
���
���
x
= \frac{1}{2} \left( e^{\frac{x - ��}{b}} \right) \bigg|_{-\infty}^{x}
=
2
1
���
(
e
b
x
���
��
���
)
���
���
���
���
���
x
���
=
1
2
(
e
x
���
��
b
���
0
)
= \frac{1}{2} \left( e^{\frac{x - ��}{b}} - 0 \right)
=
2
1
���
(
e
b
x
���
��
���
���
0
)
=
1
2
e
x
���
��
b
= \frac{1}{2} e^{\frac{x - ��}{b}}
=
2
1
���
e
b
x
���
��
���
When
x
���
��
x \geq ��
x
���
��
:
F
(
x
)
=
1
���
���
x
���
1
2
b
e
���
x
���
��
b
d
x
F(x) = 1 - \int_{x}^{\infty} \frac{1}{2b} e^{-\frac{x - ��}{b}} dx
F
(
x
)
=
1
���
���
x
���
���
2
b
1
���
e
���
b
x
���
��
���
d
x
=
1
���
1
2
(
e
���
x
���
��
b
)
���
x
���
= 1 - \frac{1}{2} \left( e^{-\frac{x - ��}{b}} \right) \bigg|_{x}^{\infty}
=
1
���
2
1
���
(
e
���
b
x
���
��
���
)
���
���
���
x
���
���
=
1
���
1
2
(
0
���
e
���
x
���
��
b
)
= 1 - \frac{1}{2} \left( 0 - e^{-\frac{x - ��}{b}} \right)
=
1
���
2
1
���
(
0
���
e
���
b
x
���
��
���
)
=
1
���
1
2
e
���
x
���
��
b
= 1 - \frac{1}{2} e^{-\frac{x - ��}{b}}
=
1
���
2
1
���
e
���
b
x
���
��
���
Thus, the c.d.f. of
X
X
X
is:
\frac{1}{2} e^{\frac{x - ��}{b}} & \text{if } x < �� \\
1 - \frac{1}{2} e^{-\frac{x - ��}{b}} & \text{if } x \geq ��
\end{cases} \]
1 / 1
10. The random variable X follows the Pareto distribution with shape �� > 0 and
scale �� > 0, if its p.d.f. is
p(x) = 
������ x��+1 , x ��� �� 0, x<��
Show that the c.d.f. of X is
F (x) = ���������1 ���  ��x  ��
, x ��� ��
Show that the expectation of X is
0, x<��
E(X) =  ���, �� ��� 1
����
�����1 , ��> 1
11. Let p(x) be the p.d.f. of the normal distribution N(0, 1) and q��(x) be the p.d.f.
of the Student t distribution with �� degrees of freedom t (��, 0, 1). Using the
limit
lim
n������
(n + ��)
(n)n�� = 1,
58 2 Matrix Algebra, Probability and Statistics
for any �� > 0, show that
lim
�������� q��(x) = p(x),
i.e. the Student t p.d.f. converges to the N(0, 1) p.d.f. as �� ��� ���.
Hint: Make use of the well known limit
lim
n������  1 + ��n  n = exp(��),
for any �� ��� R.
12. Let X and Y be any continuous random vectors. Show
Cov(X, Y ) = E(XY  ) ��� E(X)E(Y ) .
1 / 1
ChatGPT
10. Pareto Distribution:
Given the p.d.f for the Pareto distribution:
\frac{\alpha \beta^\alpha}{x^{\alpha + 1}} & x \geq \beta \\
0 & x < \beta
\end{cases} \]
To find the c.d.f \( F(x) \):
\[ F(x) = \int_{\beta}^{x} \frac{\alpha \beta^\alpha}{t^{\alpha + 1}} dt \]
\[ = \alpha \beta^\alpha \int_{\beta}^{x} t^{-\alpha -1} dt \]
\[ = \alpha \beta^\alpha [-t^{-\alpha}]_{\beta}^{x} \]
\[ = \alpha \beta^\alpha [-x^{-\alpha} + \beta^{-\alpha}] \]
\[ = 1 - \left(\frac{\beta}{x}\right)^\alpha \]
For the expectation \( E(X) \):
If \( \alpha \leq 1 \), the expectation is infinite because the tail of the distribution is too heavy.
If \( \alpha > 1 \):
\[ E(X) = \int_{\beta}^{\infty} x \frac{\alpha \beta^\alpha}{x^{\alpha + 1}} dx \]
\[ = \alpha \beta^\alpha \int_{\beta}^{\infty} x^{-\alpha} dx \]
\[ = \alpha \beta^\alpha [\frac{-x^{-\alpha+1}}{\alpha-1}]_{\beta}^{\infty} \]
\[ = \frac{\alpha \beta}{\alpha - 1} \]
**11. Convergence of Student's t-distribution to Normal distribution as �� ��� ���:**
This is a well-known property of the t-distribution. As the degrees of freedom increase, the t-distribution approaches the standard normal distribution.
However, a rigorous proof requires expressing the p.d.f of the Student's t-distribution, expressing its terms in a form that demonstrates convergence to the p.d.f of the standard normal distribution, and utilizing the provided limits to show that the terms involving the degrees of freedom approach the corresponding terms of the normal p.d.f.
Given the hint and the known limits, this property can be demonstrated. But it involves quite a bit of detailed mathematical steps, which would be too lengthy for this format.
**12. Covariance of X and Y:**
By definition:
\[ \text{Cov}(X,Y) = E(XY) - E(X)E(Y) \]
Proof:
Using the linearity of expectation, the expectation of the product minus the product of expectations is:
\[ E(XY) - E(X)E(Y) \]
\[ = E(XY) - E(X)E(Y) \]
This is the definition of covariance. Thus,
\[ \text{Cov}(X,Y) = E(XY) - E(X)E(Y) \]
This result shows that covariance represents the expected product of deviations of two random variables from their individual expected values.
2 / 2
The formatting was messed up
1 / 1
ChatGPT
Apologies for the formatting confusion. Let's go through the relevant problems again with clearer formatting.
10. Pareto Distribution:
Given the p.d.f for the Pareto distribution:
\frac{\alpha \beta^\alpha}{x^{\alpha + 1}} & \mbox{for } x \geq \beta \\
0 & \mbox{for } x < \beta
\end{array}
\right. \]
*To find the c.d.f \( F(x) \):*
\[ F(x) = \int_{\beta}^{x} \frac{\alpha \beta^\alpha}{t^{\alpha + 1}} dt \]
\[ = \alpha \beta^\alpha [-t^{-\alpha}]_{\beta}^{x} \]
\[ = 1 - \left(\frac{\beta}{x}\right)^\alpha \]
For the expectation \( E(X) \):
If \( \alpha \leq 1 \), the expectation is infinite.
If \( \alpha > 1 \):
\[ E(X) = \frac{\alpha \beta}{\alpha - 1} \]
**11. Convergence of Student's t-distribution to Normal distribution as \( \nu \to \infty \):**
This problem requires some intricate steps and detailed explanations. The main idea is to express the p.d.f of the Student's t-distribution and use the given limits to show the convergence to the normal distribution.
**12. Covariance of X and Y:**
By definition, the covariance between X and Y is:
\[ \text{Cov}(X,Y) = E[(X - E[X])(Y - E[Y])] \]
Expanding this out:
\[ \text{Cov}(X,Y) = E[XY - XE[Y] - E[X]Y + E[X]E[Y]] \]
\[ = E[XY] - E[X]E[Y] - E[X]E[Y] + E[X]E[Y] \]
\[ = E[XY] - E[X]E[Y] \]
Thus,
\[ \text{Cov}(X,Y) = E(XY) - E(X)E(Y) \]
This result confirms that covariance represents the expected product of deviations of two random variables from their individual expected values.
1 / 1
Let X, Y and Z be any continuous random vectors. Show
Cov(X, Y ) = E[Cov(X, Y | Z)] + Cov[E(X | Z), E(Y | Z)].
14. Suppose that the random variables X and Y follow a joint Gaussian distribution


XY  ��� N  
 ��x ��y  , ��2x ��xy
��xy ��2y
!+ ,
where ��x is the expectation of X, ��y is the expectation of Y , ��x2 is the variance
of X, ��y2 is the variance of Y and ��xy is the covariance of X and Y .
Show that the joint p.d.f. of X and Y can be written as
pXY (x, y) = 1 2����x��y' 1 ��� ��2 �� exp �����y2(x ��� ��x )2 ��� 2����x��y(x ��� ��x )(y ��� ��y) + ��x2(y ��� ��y)2 2��2x ��2y (1 ��� ��2) ! .
Show that the marginal distributions of X and Y are
X ��� N(��x , ��2) and Y ��� N(��x , ��2).
Show that if X and Y are independent random variables, then Cov(X, Y ) = 0.
The converse claim is not generally true. However, if X, Y are jointly normally
distributed, then this is true. Prove this claim, i.e. if the joint distribution of
X, Y is Gaussian as above, then Cov(X, Y ) = 0 implies that X and Y are
independent.
2.5 Exercises 59
15. Suppose that the random vector X = [X1, X2,...,Xk ] follows the multinomial distribution with size n =  ki=1 Xi and probability vector �� = [��1, ��2,...,��k] , i.e.
X ��� Multin(n, �� ).
Show that the marginal distribution of X1 is the binomial distribution
X1 ��� Binom(n, ��1)
and the conditional distribution of the random vector [X2,...,Xk ] , given
X1 = x1 is
[X2,...,Xk] | X1 = x1 ��� Multin n ��� x1, 
 p2 1 ��� p1
,..., pk 1 ��� p1    .
1 / 1
ChatGPT
Let's address these step by step:
13. Covariance involving Conditional Expectation:
By definition of conditional expectation:
E
[
C
o
v
(
X
,
Y
���
Z
)
]
=
E
[
E
[
(
X
���
E
[
X
���
Z
]
)
(
Y
���
E
[
Y
���
Z
]
)
���
Z
]
]
E[Cov(X,Y|Z)] = E[E[(X - E[X|Z])(Y - E[Y|Z])|Z]]
E
[
C
o
v
(
X
,
Y
���
Z
)]
=
E
[
E
[(
X
���
E
[
X
���
Z
])
(
Y
���
E
[
Y
���
Z
])
���
Z
]]
C
o
v
[
E
(
X
���
Z
)
,
E
(
Y
���
Z
)
]
=
E
[
E
[
X
���
Z
]
E
[
Y
���
Z
]
]
���
E
[
E
[
X
���
Z
]
]
E
[
E
[
Y
���
Z
]
]
Cov[E(X|Z),E(Y|Z)] = E[E[X|Z]E[Y|Z]] - E[E[X|Z]]E[E[Y|Z]]
C
o
v
[
E
(
X
���
Z
)
,
E
(
Y
���
Z
)]
=
E
[
E
[
X
���
Z
]
E
[
Y
���
Z
]]
���
E
[
E
[
X
���
Z
]]
E
[
E
[
Y
���
Z
]]
Adding them together:
E
[
C
o
v
(
X
,
Y
���
Z
)
]
+
C
o
v
[
E
(
X
���
Z
)
,
E
(
Y
���
Z
)
]
=
E
[
X
Y
]
���
E
[
X
]
E
[
Y
]
E[Cov(X,Y|Z)] + Cov[E(X|Z),E(Y|Z)] = E[XY] - E[X]E[Y]
E
[
C
o
v
(
X
,
Y
���
Z
)]
+
C
o
v
[
E
(
X
���
Z
)
,
E
(
Y
���
Z
)]
=
E
[
X
Y
]
���
E
[
X
]
E
[
Y
]
=
C
o
v
(
X
,
Y
)
= Cov(X,Y)
=
C
o
v
(
X
,
Y
)
14. Joint Gaussian Distribution:
Given that X and Y are jointly Gaussian distributed, the joint p.d.f is given by a formula that depends on their means, variances, and covariance. If
��
\rho
��
is the correlation coefficient between X and Y, it's given by:
��
=
��
x
y
��
x
��
y
\rho = \frac{\sigma_{xy}}{\sigma_x \sigma_y}
��
=
��
x
���
��
y
���
��
x
y
���
���
The formula for the joint p.d.f as mentioned in your question is derived by expanding the exponent of the joint Gaussian distribution. Proving this involves algebraic manipulations.
For the marginals:
Using properties of joint Gaussian distributions, we can infer that the marginals are Gaussian. This can be deduced directly from the given covariance matrix.
Independence:
In general,
C
o
v
(
X
,
Y
)
=
0
Cov(X, Y) = 0
C
o
v
(
X
,
Y
)
=
0
does not imply independence. But for jointly normal random variables, zero covariance implies independence.
15. Multinomial Distribution:
For a multinomial distribution with parameters
n
n
n
(number of trials) and
��
=
[
��
1
,
��
2
,
.
.
.
,
��
k
]
\pi = [\pi_1, \pi_2, ..., \pi_k]
��
=
[
��
1
���
,
��
2
���
,
...
,
��
k
���
]
(probabilities of categories), the marginal distribution of
X
1
X_1
X
1
���
is the number of times category 1 occurs in
n
n
n
trials. This is binomially distributed with parameters
n
n
n
and
��
1
\pi_1
��
1
���
.
For the conditional distribution:
Given
X
1
=
x
1
X_1 = x_1
X
1
���
=
x
1
���
, there are
n
���
x
1
n - x_1
n
���
x
1
���
trials left to be distributed among the remaining
k
���
1
k-1
k
���
1
categories. The conditional probabilities are adjusted as given in the question, reflecting that the trials for category 1 are fixed at
x
1
x_1
x
1
���
.
To fully prove these, you would use combinatorial arguments and the properties and definitions of the Binomial and Multinomial distributions.
1 / 1
16. Three random variables have joint p.d.f.
pXYZ(x, y, z) =  c
xy exp(���yz), 1 < x,y < 2, z> 0 0, otherwise
a. Show that the constant c is c = 2
log 2 .
b. Find the marginal joint p.d.f. of [X, Y ] , and the marginal p.d.f.���s of X and
Y .
Show that X and Y are independent, but X, Y and Z are not independent.
c. Calculate the mean and variance of X and Y . Also calculate the mean vector
of W = [X, Y ] and the covariance matrix of W.
d. For 1 < x,y < 2, find the joint distribution function FXY (x, y) of [X, Y ]
and calculate the probability P (X ��� 3/2, Y ��� 4/3).
17. Consider an independent random sample X1, X2,...,Xn, where Xi is gener���ated from a Poisson distribution, with rate ��, i.e. Xi ��� Pois(��). Show that the
maximum likelihood estimate of �� is
���� = n1 ni=1 xi,
where x1, x2,...,xn are the observed values of X1, X2,...,Xn.
18. Consider an independent random sample X1, X2,...,Xn, where Xi is gener���ated from the binomial distribution Xi ��� Binom(m, �� ), for some m. Show that
60 2 Matrix Algebra, Probability and Statistics
the maximum likelihood estimate of �� is
���� = 1
mn
ni=1 xi,
where x1, x2,...,xn are the observed values of X1, X2,...,Xn.
19. Consider an independent random sample X1, X2,...,Xn, where Xi is generated from the geometric distribution with probability of success �� (see Exercise
2.7). Show that the maximum likelihood estimate of �� is
���� = n + nni=1 xi ,
where x1, x2,...,xn are the observed values of X1, X2,...,Xn.
20. Consider an independent random sample X1, X2,...,Xn, where Xi is generated from the inverse Gaussian distribution, with p.d.f.
pXi(xi) = , �� 2��x3i
exp ����� (xi ��� ��)2 2��2xi 	
, xi > 0, ��, �� > 0.
Assuming that �� is known, show that the maximum likelihood estimate of �� is
���� = n��2  ni=1(xi ��� ��)2x���1 i ,
where x1, x2,...,xn are the observed values of X1, X2,...,Xn.
1 / 1
ChatGPT
Let's address each problem step by step:
16. Three random variables with joint p.d.f.:
a. To find
c
c
c
, integrate the given p.d.f. over the entire space to get 1:
���
1
2
���
1
2
���
0
���
c
x
y
e
���
y
z
���
d
z
���
d
y
���
d
x
=
1
\int_1^2 \int_1^2 \int_0^\infty cxye^{-yz} \, dz \, dy \, dx = 1
���
1
2
���
���
1
2
���
���
0
���
���
c
x
y
e
���
yz
d
z
d
y
d
x
=
1
Solving this will give
c
=
2
log
���
2
c = \frac{2}{\log 2}
c
=
l
o
g
2
2
���
.
b. The marginal p.d.f.s can be obtained by integrating out the other variables:
p
X
Y
(
x
,
y
)
=
���
0
���
p
X
Y
Z
(
x
,
y
,
z
)
���
d
z
p_{XY}(x,y) = \int_0^\infty p_{XYZ}(x,y,z) \, dz
p
X
Y
���
(
x
,
y
)
=
���
0
���
���
p
X
Y
Z
���
(
x
,
y
,
z
)
d
z
p
X
(
x
)
=
���
1
2
���
0
���
p
X
Y
Z
(
x
,
y
,
z
)
���
d
z
���
d
y
p_X(x) = \int_1^2 \int_0^\infty p_{XYZ}(x,y,z) \, dz \, dy
p
X
���
(
x
)
=
���
1
2
���
���
0
���
���
p
X
Y
Z
���
(
x
,
y
,
z
)
d
z
d
y
p
Y
(
y
)
=
���
1
2
���
0
���
p
X
Y
Z
(
x
,
y
,
z
)
���
d
z
���
d
x
p_Y(y) = \int_1^2 \int_0^\infty p_{XYZ}(x,y,z) \, dz \, dx
p
Y
���
(
y
)
=
���
1
2
���
���
0
���
���
p
X
Y
Z
���
(
x
,
y
,
z
)
d
z
d
x
c. Mean and variance of X and Y can be found using the definitions:
E
[
X
]
=
���
1
2
x
p
X
(
x
)
���
d
x
E[X] = \int_1^2 x p_X(x) \, dx
E
[
X
]
=
���
1
2
���
x
p
X
���
(
x
)
d
x
Similarly for
E
[
Y
]
E[Y]
E
[
Y
]
,
V
a
r
[
X
]
Var[X]
Va
r
[
X
]
, and
V
a
r
[
Y
]
Var[Y]
Va
r
[
Y
]
.
d. The joint distribution function is:
F
X
Y
(
x
,
y
)
=
���
1
x
���
1
y
p
X
Y
(
u
,
v
)
���
d
v
���
d
u
F_{XY}(x,y) = \int_1^x \int_1^y p_{XY}(u,v) \, dv \, du
F
X
Y
���
(
x
,
y
)
=
���
1
x
���
���
1
y
���
p
X
Y
���
(
u
,
v
)
d
v
d
u
Plug in the given values to find the required probability.
17. Poisson MLE:
The likelihood function is:
L
(
��
)
=
���
i
=
1
n
e
���
��
��
x
i
x
i
!
L(\lambda) = \prod_{i=1}^n e^{-\lambda} \frac{\lambda^{x_i}}{x_i!}
L
(
��
)
=
���
i
=
1
n
���
e
���
��
x
i
���
!
��
x
i
���
���
Taking log, differentiating w.r.t.
��
\lambda
��
, setting to zero, and solving will give the MLE.
18. Binomial MLE:
The likelihood function is:
L
(
��
)
=
���
i
=
1
n
(
m
x
i
)
��
x
i
(
1
���
��
)
m
���
x
i
L(\pi) = \prod_{i=1}^n \binom{m}{x_i} \pi^{x_i} (1-\pi)^{m-x_i}
L
(
��
)
=
���
i
=
1
n
���
(
x
i
���
m
���
)
��
x
i
���
(
1
���
��
)
m
���
x
i
���
Taking log, differentiating w.r.t.
��
\pi
��
, setting to zero, and solving will give the MLE.
19. Geometric MLE:
The likelihood function is:
L
(
��
)
=
���
i
=
1
n
(
1
���
��
)
x
i
��
L(\pi) = \prod_{i=1}^n (1-\pi)^{x_i} \pi
L
(
��
)
=
���
i
=
1
n
���
(
1
���
��
)
x
i
���
��
Taking log, differentiating w.r.t.
��
\pi
��
, setting to zero, and solving will give the MLE.
20. Inverse Gaussian MLE:
The likelihood function is:
L
(
��
)
=
���
i
=
1
n
��
2
��
x
i
3
exp
���
(
���
��
(
x
i
���
��
)
2
2
��
2
x
i
)
L(\theta) = \prod_{i=1}^n \frac{\theta}{2\pi x_i^3} \exp \left( -\frac{\theta(x_i-\mu)^2}{2\mu^2 x_i} \right)
L
(
��
)
=
���
i
=
1
n
���
2
��
x
i
3
���
��
���
exp
(
���
2
��
2
x
i
���
��
(
x
i
���
���
��
)
2
���
)
Taking log, differentiating w.r.t.
��
\theta
��
, setting to zero, and solving will give the MLE.
For each of these, you'd have to perform the actual differentiations and algebraic manipulations to arrive at the result.
1 / 1
The distribution of data X, given parameter �� > 0, is Poisson
X | �� ��� Pois(��).
If, for some �� and ��, the prior of �� is gamma
�� ��� G(��, ��),
then
a. show that the posterior distribution of �� is gamma, i.e.
�� | X = x ��� G(�� + x,�� + 1),
where x is the observed value of X;
b. show that the forecast distribution of X is negative binomial
X ��� NegBinom ��,
1 �� + 1	 .
2.5 Exercises 61
22. Suppose that, given probability of success ��, the distribution of data X is the
geometric distribution of Exercise 2.7. If the prior of �� is beta
�� ��� Beta(��, ��),
for some �� and ��, then
a. show that the posterior distribution of �� is beta
�� | X = x ��� Beta(�� + 1, �� + x),
where x is the observed value of X;
b. show that the forecast distribution of X is
p(x) = ����(�� + 1)������(�� + x)
(�� + ��)(�� + �� + 1)������(�� + �� + x + 1).
23. Given �� > 0, the data X follows the exponential distribution with p.d.f.
p(x | ��) =  �� exp(�����x), x ��� 0 0, x< 0
If the prior of �� is gamma
�� ��� G(��, ��),
for some �� and ��, then
a. show that the posterior distribution of �� is gamma
�� | X = x ��� G(�� + 1, �� + x),
where x is the observed value of X;
b. show that the forecast distribution of X is
p(x) = 
������
(��+x)��+1 , x ��� 0 0, x< 0
1 / 1
ChatGPT
Alright, let's go step by step for these problems:
21. Poisson-Gamma conjugacy:
Given the Poisson likelihood and Gamma prior, let's derive the posterior:
a.
p
(
X
���
��
)
=
e
���
��
��
x
x
!
p(X | \lambda) = e^{-\lambda} \frac{\lambda^x}{x!}
p
(
X
���
��
)
=
e
���
��
x
!
��
x
���
p
(
��
)
=
��
��
��
(
��
)
��
��
���
1
e
���
��
��
p(\lambda) = \frac{\beta^\alpha}{\Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta\lambda}
p
(
��
)
=
��
(
��
)
��
��
���
��
��
���
1
e
���
��
��
Using Bayes' theorem, the posterior is proportional to the product of the likelihood and the prior.
p
(
��
���
X
)
���
��
x
e
���
��
��
��
���
1
e
���
��
��
p(\lambda | X) \propto \lambda^x e^{-\lambda} \lambda^{\alpha-1} e^{-\beta\lambda}
p
(
��
���
X
)
���
��
x
e
���
��
��
��
���
1
e
���
��
��
������
���
������
��
x
+
��
���
1
e
���
(
��
+
��
)
��
\implies \lambda^{x+\alpha-1} e^{-(\lambda+\beta)\lambda}
���
��
x
+
��
���
1
e
���
(
��
+
��
)
��
This is a gamma distribution
G
(
��
+
x
,
��
+
1
)
G(\alpha+x, \beta+1)
G
(
��
+
x
,
��
+
1
)
.
b. The predictive distribution for a new X, given the observed data, is the negative binomial distribution when combined with a Gamma prior. This can be derived by marginalizing out
��
\lambda
��
from the joint distribution of
��
\lambda
��
and the new
X
X
X
. The resulting distribution is a negative binomial.
22. Geometric-Beta conjugacy:
Given the geometric likelihood and Beta prior:
a.
p
(
X
���
��
)
=
(
1
���
��
)
x
��
p(X | \pi) = (1-\pi)^x \pi
p
(
X
���
��
)
=
(
1
���
��
)
x
��
p
(
��
)
=
��
��
���
1
(
1
���
��
)
��
���
1
B
(
��
,
��
)
p(\pi) = \frac{\pi^{\alpha-1} (1-\pi)^{\beta-1}}{B(\alpha, \beta)}
p
(
��
)
=
B
(
��
,
��
)
��
��
���
1
(
1
���
��
)
��
���
1
���
The posterior is proportional to the product of the likelihood and the prior.
p
(
��
���
X
)
���
(
1
���
��
)
x
��
��
��
���
1
(
1
���
��
)
��
���
1
p(\pi | X) \propto (1-\pi)^x \pi \pi^{\alpha-1} (1-\pi)^{\beta-1}
p
(
��
���
X
)
���
(
1
���
��
)
x
��
��
��
���
1
(
1
���
��
)
��
���
1
������
���
������
��
��
(
1
���
��
)
x
+
��
���
1
\implies \pi^{\alpha} (1-\pi)^{x+\beta-1}
���
��
��
(
1
���
��
)
x
+
��
���
1
This is a beta distribution
B
e
t
a
(
��
+
1
,
��
+
x
)
Beta(\alpha+1, \beta+x)
B
e
t
a
(
��
+
1
,
��
+
x
)
.
b. The forecast distribution can be derived similarly by marginalizing out
��
\pi
��
from the joint distribution of
��
\pi
��
and the new
X
X
X
. This will give you the stated distribution for
p
(
x
)
p(x)
p
(
x
)
.
23. Exponential-Gamma conjugacy:
Given the exponential likelihood and Gamma prior:
a.
p
(
X
���
��
)
=
��
e
���
��
x
p(X | \lambda) = \lambda e^{-\lambda x}
p
(
X
���
��
)
=
��
e
���
��
x
p
(
��
)
=
��
��
��
(
��
)
��
��
���
1
e
���
��
��
p(\lambda) = \frac{\beta^\alpha}{\Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta\lambda}
p
(
��
)
=
��
(
��
)
��
��
���
��
��
���
1
e
���
��
��
The posterior is proportional to the product of the likelihood and the prior.
p
(
��
���
X
)
���
��
e
���
��
x
��
��
���
1
e
���
��
��
p(\lambda | X) \propto \lambda e^{-\lambda x} \lambda^{\alpha-1} e^{-\beta\lambda}
p
(
��
���
X
)
���
��
e
���
��
x
��
��
���
1
e
���
��
��
������
���
������
��
��
e
���
(
x
+
��
)
��
\implies \lambda^{\alpha} e^{-(x+\beta)\lambda}
���
��
��
e
���
(
x
+
��
)
��
This is a gamma distribution
G
(
��
+
1
,
��
+
x
)
G(\alpha+1, \beta+x)
G
(
��
+
1
,
��
+
x
)
.
b. The forecast distribution for a new X can be derived similarly, by marginalizing out
��
\lambda
��
from the joint distribution of
��
\lambda
��
and the new
X
X
X
. This will give you the stated distribution for
p
(
x
)
p(x)
p
(
x
)
.
For each of these derivations, you'd need to perform the actual algebraic manipulations to arrive at the result.
1 / 1
Here are the solutions:

1a) Given:
X | �� ~ Pois(��)
�� ~ G(��, ��)

Posterior of ��: By Bayes' theorem,
p(�� | x) ��� p(x | ��)p(��)
��� ��^x e^-�� / x! * ��^(��-1)e^-���� / ��(��)
��� ��^(��+x-1)e^-(��(��+1)) / ��(��+x)
= G(�� + x, �� + 1)

Therefore, the posterior distribution of �� is G(�� + x, �� + 1).

1b) Given:
X | �� ~ Pois(��)
�� ~ G(��, ��)

Forecast distribution of X:
X ~ NegBinom(��, p) where p = 1/(�� + 1)

2a) Given:\
X | �� ~ Geo(��)
�� ~ Beta(��, ��)

Posterior of ��:
p(�� | x) ��� p(x | ��)p(��)
��� ��(1-��)^x * ��^(��-1)(1-��)^(��-1)
��� ��^(��+(1-��)^(��+x-1)
= Beta(�� + 1, �� + x)

Therefore, the posterior of �� is Beta(�� + 1, �� + x).

2b) Given the posterior of �� is Beta(�� + 1, �� + x), the forecast distribution of X is the geometric distribution:
p(x) = (��+1)����(�� + 1)...(�� + x) / (�� + ��)(�� + �� + 1)...(�� + �� + x + 1)
1 / 1
ChatGPT
Your solutions are correct and concise. To recap:
1a.
You've shown that combining the Poisson likelihood with the Gamma prior yields a Gamma posterior for
��
\lambda
��
. This is a commonly known conjugate prior relationship in Bayesian statistics.
1b.
You mentioned that the forecast distribution of
X
X
X
(given previous observations) is the negative binomial distribution with parameters
��
\alpha
��
and
p
=
1
��
+
1
p = \frac{1}{\beta + 1}
p
=
��
+
1
1
���
. This makes sense given the conjugacy between the Poisson and Gamma distributions.
2a.
Given a geometric likelihood and a Beta prior for
��
\pi
��
, you correctly derived that the posterior for
��
\pi
��
is also Beta, but its parameters have been updated to
��
+
1
\alpha + 1
��
+
1
and
��
+
x
\beta + x
��
+
x
.
2b.
Finally, using the updated Beta distribution, you have provided the forecast distribution for
X
X
X
. This represents the likelihood of observing a future value
X
X
X
, given the data observed so far. The provided formula correctly incorporates the influence of both the prior and the data.
Your solutions are well-structured and they clearly demonstrate the process of Bayesian updating. This is central to the concept of Bayesian inference, where one updates their beliefs (the prior distribution) in light of new data (the likelihood), to get a refined belief (the posterior distribution). Well done!
1 / 1
Chapter 3
The Kalman Filter
This chapter introduces the linear state space model and discusses filtering,
smoothing and forecasting. Section 3.1 motivates the state space model as a natural
extension of the usual multiple regression model, which adopts ordinary least
squares and maximum likelihood estimation methods. In Sect. 3.1.1, we give a brief
review of these estimation methods, and for completeness purposes we provide the
full derivations. These derivations provide technical motivation for the following.
Section 3.1.2 discusses recursive estimation of regression with the emphasis placed
on local estimation, leading to recursive least squares. The definition of the state
space model follows in Sect. 3.1.3. Filtering is discussed in Sect. 3.2, where two
derivations of the Kalman filter are given. Smoothing and forecasting are discussed
in the next two sections, and the chapter concludes with coverage of observability
and the steady state of linear time-invariant state space models.
3.1 From Regression to the State Space Model
3.1.1 Ordinary Least Squares
In this section we briefly describe regression methods for linear models, a detailed
account of which is given in Bingham and Fry (2010); see also Sect. 2.4.3. Suppose
that observations y1, y2,...,yn become available over time t = 1, 2,...,n, for
some positive integer n. In some situations, the time index t may represent a finite
discrete set {a1,...,an}, which is equivalent to {1, 2,...,n}, i.e. there is a one���to-one mapping from elements of {a1,...,an} to {1, 2,...,n}. For example, ai
may represent years, or quarters, or any other, suitably defined discrete objects
(not necessarily representing time). It is further assumed that {a1,...,an} is, at
least approximately, an equally spaced set, i.e. that at ��� at���1 is the same for all
�� The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0_3
63
64 3 The Kalman Filter
t = 2, 3,...,n. For convenience, in what follows we will work with a time index
{1, 2,...,n}, but the above discussion motivates the more general case.
In the context of regression, suppose that we have p variables (also indexed by
time), xit (i = 1, . . . , p), which form a column vector xt = (x1t,...,xpt) , where

denotes transposition. We wish to express a relationship between yt and xt , and
thus we form the linear regression model
yt = x1t��1 +������+ xpt��p +  t = xt �� +  t, (3.1)
where �� = (��1,...,��p) denotes a p-variate vector of regression coefficients and

t is the error or innovation term of the above model, accounting for the distance
between yt and xt ��. According to the Gauss���Markov conditions (Bingham &
Fry, 2010), { t} is a sequence of independent random variables ( t is independent
of  s, for any t  = s) with zero mean and common variance ��2; { t} is referred
to as a white noise process, see e.g. Brockwell and Davis (1991), and we write

t ��� WN(0, ��2). The purpose of regression is to estimate ��, based on a realised
collection of observations y1:n = {y1,...,yn}. This estimation can be carried out
in several equivalent ways (in Sect. 2.4.3, we describe the Bayesian estimation), but
the standard one is by minimising the sum of squares
S(��) = nt=1
(yt ��� xt ��)2. (3.2)
To facilitate the calculations, it is useful to write model (3.1) in matrix form as
y = ��������������� y1 y2...yn ��������������� = ��������������� x1 x2... xn ��������������� �� + ���������������  12...n ��������������� = X�� + .
Then, assuming that X is of full rank, the well known solution that minimises S(��)
gives the estimator of �� as
���� = (X X)���1X y =  nt=1 xtxt  ���1 nt=1 xtyt . (3.3)
For completeness purposes, we give the proof next. We wish to minimise
S(��) =    = (y ��� X��) (y ��� X��) = y y ��� 2�� X y + �� X X��.
3.1 From Regression to the State Space Model 65
Using (2.3) and (2.5), the first partial derivative of S(��) with respect to �� is
���S(��)
����� = ���2X y + 2X X��,
which for �� = ���� satisfies the equation
���S( ����)
��� ���� = 0 ��� ���� = (X X)���1X y,
given that X is of full rank, so that the inverse of X X exists.
Thus ���� is a stationary vector, and we can use Eq. (2.5) to verify that its second
partial derivative is a positive definite matrix, i.e.
���2S(��)
����������T = 2X X.
Thus, the sum of squares S(��) is minimised at ����.
1 / 1
ChatGPT
This excerpt is an introduction to the Kalman Filter through the lens of linear regression. Here's a brief overview:
Chapter 3 - The Kalman Filter
Introduction
: The Kalman Filter, a recursive solution to the linear state-space estimation problem, is discussed in the context of filtering, smoothing, and forecasting.
Section 3.1
: This section presents the state space model as an extension of the typical multiple regression model. Multiple regression generally uses methods such as ordinary least squares (OLS) and maximum likelihood estimation, which are reviewed here.
3.1.1 Ordinary Least Squares
: Regression methods for linear models are detailed here, especially the OLS method. Given a time-series of observations,
y
1
,
y
2
,
.
.
.
,
y
n
y_1, y_2,...,y_n
y
1
���
,
y
2
���
,
...
,
y
n
���
, and associated covariates,
x
i
t
x_{it}
x
i
t
���
, the goal of regression is to model the relationship between the observations and the covariates using the equation
y
t
=
x
t
T
��
+
��
t
y_t = x_t^T \beta + \epsilon_t
y
t
���
=
x
t
T
���
��
+
��
t
���
, where
x
t
T
x_t^T
x
t
T
���
denotes the transpose of the vector
x
t
x_t
x
t
���
and
��
\beta
��
is a vector of coefficients. The error term,
��
t
\epsilon_t
��
t
���
, accounts for discrepancies between the predicted and observed values. To estimate
��
\beta
��
, the sum of squared errors,
S
(
��
)
S(\beta)
S
(
��
)
, is minimized. When this model is expressed in matrix notation, the estimator for
��
\beta
��
that minimizes the sum of squared errors is
��
^
=
(
X
T
X
)
���
1
X
T
y
\hat{\beta} = (X^T X)^{-1}X^T y
��
^
���
=
(
X
T
X
)
���
1
X
T
y
.
3.1.2
and
3.1.3
: These sections likely continue the discussion, moving from standard linear regression to recursive estimation and defining the state space model, respectively.
Section 3.2
: This section will discuss filtering, specifically the Kalman Filter, which is used to estimate the internal states of a linear dynamic system.
The remaining sections probably delve deeper into the applications of the Kalman Filter, discussing smoothing and forecasting, and touching on specific characteristics of the model like observability and steady states.
The overall purpose of this chapter seems to be to build an understanding of the Kalman Filter starting from foundational statistical concepts, moving from simple linear regression to more complex state-space models. This foundational approach ensures the reader appreciates the evolution and logic behind the introduction of the Kalman Filter in the context of dynamic linear models.
1 / 1
Here are the key points about the Kalman filter from the passage:

- Chapter 3 introduces the linear state space model and discusses filtering, smoothing and forecasting using the Kalman filter.

- Section 3.1 motivates the state space model as a natural extension of the standard multiple linear regression model. Ordinary least squares and maximum likelihood estimation for regression are briefly reviewed.

- Section 3.1.1 reviews ordinary least squares estimation for linear regression. The estimator ��^ is derived by minimizing the sum of squared errors.

- Section 3.1.2 discusses recursive estimation of regression with an emphasis on local estimation, leading to recursive least squares.

- Section 3.1.3 defines the state space model, which forms the basis for the Kalman filter.

- Section 3.2 derives the Kalman filter using two approaches - one based on multivariate distribution theory and one minimizing the error covariance matrix.

- Sections 3.3 and 3.4 cover smoothing and forecasting using the Kalman filter.

- The chapter concludes by discussing observability and the steady state of linear time-invariant state space models.

So in summary, the chapter introduces the state space modeling framework and derives the Kalman filter, covering its application to filtering, smoothing and forecasting of linear dynamic systems.
1 / 1
ChatGPT
That's a concise summary of the key points about the Kalman filter from the passage provided. This gives a clear overview of the chapter's structure and main themes, from the foundational concepts in regression to the more complex state-space models, and the derivation and applications of the Kalman filter. If you need any further elaboration on specific topics or any other assistance, please let me know!
1 / 1
So far, no assumption has been made about the distribution of the sequence { t}.
If one is prepared to accept that, additionally to the white noise assumption of { t},  t (t = 1, . . . , n) follows a normal distribution with zero mean and variance ��2, i.e.

t ��� N(0, ��2), then the maximum likelihood estimation of �� and ��2 is available and
given as follows. From the model definition (3.1) and the white noise assumption

t ��2���
as
N(0, ��2), we can write down the distribution of yt given the parameters �� and
yt | ��, ��2 ��� N(xt ��, ��2).
Since { t} is a white noise, it follows that, given �� and ��2, y1,...,yn are
independent.
The likelihood function of �� and ��2 is the joint distribution of y1,...,yn, given
these parameters, which by using the above two facts is
L(��, ��2; y1:n) = p(y1,...,yn | ��, ��2) = n-t=1
p(yt | ��, ��2) (from the independence of y1,...,yn) = n-t=1 ���21
����
exp 
 ���(yt ��� xt ��)2 2��2  = 1 (2�� )n/2�� n exp ���2��1 2 nt=1
(yt ��� xt ��)2! ,
66 3 The Kalman Filter
and the log-likelihood function of �� and ��2 is
(��, ��2; y1:n) = logL(��, ��2; y1:n)
= ���n log ���2�� ��� n2 log ��2 ��� 2��1 2 nt=1
(yt ��� xt ��)2. (3.4)
In order to find ���� and ����2 that maximise (3.4), first we maximise it with respect to ��
and then with respect to ��2.
The partial first derivative of (��) with respect to �� is
���(��, ��2; y1:n)
����� = ��12 nt=1 xt(yt ��� xt ��),
from which by equating it to zero, we obtain ���� exactly as in (3.3).
For ��2, we have
���(��, ��2; y1:n)
�����2 = ��� n2��2 + 2��1 4 nt=1
(yt ��� xt ��)2,
which after evaluating it at �� = ����, and solving the equation ���( ����, ����2; y1:n)/��� ����2 =
0, yields
����2 = n1 nt=1
(yt ��� xt ����)2. (3.5)
It is of some interest to express the estimator (3.5) in terms of X and y only. By
expanding (3.5) and recalling the definitions of y and X above, we can readily see
that
����2 = n���1  nt=1 yt2 ��� nt=1 ytxt ���� ��� ���� nt=1 xtyt + ���� nt=1 xtxt ���� = n���1(y y ��� y X ���� ��� ����X y + ���� X X ����)
= n���1y (I ��� X(X X)���1X )y, (3.6)
after using ����
estimators
= (X X)���1X y. We note that in the above maximum likelihood
����2, it is usual to replace n by n ��� p, which makes ����2 an unbiased
estimator.
3.1 From Regression to the State Space Model 67
The above notion of the estimation of �� is known as ordinary least squares
(OLS), because all observations y1,...,yn have on average the same contribution
on ����. This means that for large n, distant observations (such as y1 or y2) have the
same weight on ���� as the more recent observations (such as yn or yn���1). This is
usually not desirable when the data exhibit a time-dependence structure or when a
localised estimation of �� is required. For example, considering share prices of the
stock market as yt , the estimate of the price of today is likely to depend more on the
related price of yesterday, but not as much on the price of last month. Thus, we wish
to put more weight at more recent observations in the estimation of ����
1 / 1
ChatGPT
The given passage primarily focuses on the assumptions about the distribution of the sequence
��
t
{\delta_t}
��
t
���
and the implications of these assumptions for regression analysis using ordinary least squares (OLS). Here are the main takeaways:
Distribution Assumption
: The passage assumes that in addition to the white noise property, the sequence
��
t
{\delta_t}
��
t
���
is normally distributed with mean 0 and variance
��
2
��^2
��
2
.
Likelihood Function
:
Given the above assumptions, the distribution of
y
t
y_t
y
t
���
is defined as
y
t
���
��
,
��
2
���
N
(
x
t
T
��
,
��
2
)
y_t | ��, ��^2 ��� N(x_t^T ��, ��^2)
y
t
���
���
��
,
��
2
���
N
(
x
t
T
���
��
,
��
2
)
.
The observations
y
1
,
.
.
.
,
y
n
y_1,...,y_n
y
1
���
,
...
,
y
n
���
are independent given the parameters
��
��
��
and
��
2
��^2
��
2
.
The likelihood function of
��
��
��
and
��
2
��^2
��
2
, given the observations, is derived.
Log-Likelihood Function
: The log-likelihood function
l
(
��
,
��
2
;
y
1
:
n
)
l(��, ��^2; y_1:n)
l
(
��
,
��
2
;
y
1
���
:
n
)
is expressed as a function of
��
��
��
and
��
2
��^2
��
2
. This function is to be maximized to obtain the maximum likelihood estimates (MLEs) for
��
��
��
and
��
2
��^2
��
2
.
Derivation of Estimators
:
The maximum likelihood estimator (MLE) for
��
��
��
,
��
^
\hat{��}
��
^
���
, is derived to be identical to the one obtained by minimizing the sum of squared residuals in OLS.
The MLE for
��
2
��^2
��
2
,
��
2
^
\hat{��^2}
��
2
^
, is expressed in terms of the observed data and
��
^
\hat{��}
��
^
���
. It is also mentioned that for this estimator, it's common to replace
n
n
n
with
n
���
p
n - p
n
���
p
to get an unbiased estimator for
��
2
��^2
��
2
.
Ordinary Least Squares (OLS)
:
The method discussed for the estimation of
��
��
��
is referred to as OLS.
One significant limitation of OLS is highlighted: all observations, regardless of when they occurred, have equal weight in estimating
��
��
��
. This is not ideal when data exhibits time dependence or when local estimation is needed.
For instance, in a time series context, like share prices, recent observations (e.g., today's price) might be more relevant than older ones (e.g., last month's price).
In summary, the passage explains the assumptions and derivations involved in regression analysis using ordinary least squares when considering normal distribution assumptions for errors. It further emphasizes the limitations of OLS in scenarios where data points have varying levels of relevance based on their timing.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT August 3 Version
?
ChatGPT





