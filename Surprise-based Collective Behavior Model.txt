Surprise-based Collective Behavior Model
Open sidebar
Surprise-based Collective Behavior Model
GPT-4
Summarize: Collective behavior from surprise minimization 
Conor Heins���1,2,3,4, Beren Millidge5, Lancelot Da Costa4,6,7, 
Richard P. Mann8, Karl Friston4,7, and Iain D. Couzin1,2,3 
1Department of Collective Behaviour, Max Planck Institute of Animal Behavior, 
2Centre for the Advanced Study of Collective Behaviour, and 
3Department of Biology, University of Konstanz, Konstanz D-78457, Germany 
4VERSES AI Research Lab, Los Angeles, CA 90016, USA 
5MRC Brain Networks Dynamics Unit, University of Oxford, Oxford OX1 3TH, UK 
6Department of Mathematics, Imperial College London, London SW7 2AZ, UK 
7Wellcome Centre for Human Neuroimaging, University College London, London, WC1N 3AR, UK 
8Department of Statistics, School of Mathematics, University of Leeds, Leeds, LS2 9JT, UK 
Abstract 
Collective motion is ubiquitous in nature; groups of animals, such as i sh, birds, 
and ungulates appear to move as a whole, exhibiting a rich behavioral repertoire that 
ranges from directed movement to milling to disordered swarming.Typically, such 
macroscopic patterns arise from decentralized, local interactions among constituent 
components (e.g., individual i sh in a school). Preeminent models of this process de- 
scribe individuals as self-propelled particles, subject to self-generated motion and ���social 
forces��� such as short-range repulsion and long-range attraction or alignment. However, 
organisms are not particles; they are probabilistic decision-makers. Here, we introduce 
an approach to modelling collective behavior based on active inference. This cognitive 
framework casts behavior as the consequence of a single imperative: to minimize sur- 
prise. We demonstrate that many empirically-observed collective phenomena, including 
cohesion, milling and directed motion, emerge naturally when considering behavior as 
driven by active Bayesian inference ��� without explicitly building behavioral rules or 
goals into individual agents. Furthermore, we show that active inference can recover 
and generalize the classical notion of social forces as agents attempt to suppress predic- 
tion errors that conf l ict with their expectations. By exploring the parameter space of 
the belief-based model, we reveal non-trivial relationships between the individual be- 
liefs and group properties like polarization and the tendency to visit dif f erent collective 
states. We also explore how individual beliefs about uncertainty determine collective 
decision-making accuracy. Finally, we show how agents can update their generative 
model over time, resulting in groups that are collectively more sensitive to external 
l uctuations and encode information more robustly.
1 / 1
ChatGPT
ChatGPT
The paper titled "Collective behavior from surprise minimization" by Conor Heins et al. introduces a new approach to modeling collective behavior in groups of animals like fish, birds, and ungulates. Instead of describing individual animals as self-propelled particles subject to social forces, this research adopts a cognitive framework called active inference. This approach views behavior as a consequence of minimizing surprise, casting organisms as probabilistic decision-makers. The authors demonstrate that observed collective phenomena like cohesion, milling, and directed motion emerge naturally within this framework without defining specific behavioral rules. Active inference also allows the classical notion of social forces to be recovered and generalized, reflecting agents' efforts to suppress prediction errors. The paper explores the complex relationships between individual beliefs and group properties, such as polarization, and investigates how individual beliefs about uncertainty affect collective decision-making. Finally, the paper shows that agents can update their generative model over time, leading to groups that are more sensitive to external fluctuations and can encode information more robustly.
1 / 1
Introduction 
The principles underlying coordinated group behaviors in animals have inspired research in 
disciplines ranging from zoology to engineering to physics [1���3]. Collective motion in partic- 
ular has been a popular phenomenon to study, due in part to its striking visual manifestation 
and ubiquity (e.g., swarming locusts, schooling i sh, l ocking birds and herding ungulates), 
and in part to the simplicity of models that can reproduce many of its qualitative features; 
like cohesive, directed movement [4���7]. Because of this, collective motion is often cited as a 
canonical example of a self-organizing complex system, wherein collective properties emerge 
from simple interactions among distributed components. 
Popular theoretical models cast collective motion as groups composed of self-propelled 
particles (SPPs) that inf l uence one another via simple ���social forces.��� Early models like the 
Vicsek model [6] consider only a simple alignment interaction, where each particle aligns 
its direction of travel with the average heading of its neighbors.While oversimplifying 
the biological mechanisms in play, SPP models ��� like the Vicsek model ��� are useful for 
their amenability to formal understanding, e.g., the computation of universal quantities and 
relations through hydrodynamic and mean-f i eld limits [8���11]. 
Recent research has shifted towards more biologically-motivated, agent-based approaches 
that aim to model the specif i c behavioral circuits and decision-rules that govern individual 
behaviors [12���14]. While these models are less analytically-tractable than SPP models, they 
are more appealing to domain specialists like biologists, as they can generate predictions 
about sensory features in an individual���s environment that are necessary and suf i cient for 
evoking behavior. Furthermore, these predictions can be tested experimentally [14, 15]. This 
data-driven approach can thus provide mechanistic insights into the biological and cognitive 
origins of decision-making [13, 16]. 
In this work, we propose a model class that blends the i rst-principles, theoretical ap- 
proaches of physical models with biological-plausibility, resulting in an ecologically-valid but 
theoretically-grounded agent-based model of collective behavior. Our model class is based 
on active inference, a framework for designing and describing adaptive systems where all 
aspects of cognition ��� learning, planning, perception, and action ��� are viewed as a process 
of inference [17���19]. Active inference originated in theoretical neuroscience as a normative 
account of self-organizing, biological systems as constantly engaged in predictive exchanges 
with their sensory environments [20���22].
1 / 1
ChatGPT
ChatGPT
The introduction of the paper highlights the fascination with and significance of coordinated group behaviors in animals, inspiring research in fields like zoology, engineering, and physics. Collective motion, such as swarming locusts or schooling fish, has been a major area of study due to its visual appeal and the relatively simple models that can reproduce its features, such as cohesive, directed movement.
Historically, theoretical models have approached collective motion by treating groups as composed of self-propelled particles (SPPs) influenced by simple "social forces." These models, including the well-known Vicsek model, have offered insights through simplified alignment interactions but tend to oversimplify biological mechanisms.
Recent research has shifted towards more complex, biologically-motivated, agent-based models, aiming to understand the specific behavioral rules governing individual actions. These models, while less easily analyzed, are more relevant to biologists and can offer more accurate predictions about sensory features and individual behavior.
The authors introduce a new class of model that blends the simplicity and theoretical strength of physical models with the biological plausibility of agent-based approaches. Their approach is based on active inference, a framework that views all aspects of cognition, including learning, planning, perception, and action, as processes of inference. Originating in theoretical neuroscience, active inference provides a normative view of biological systems, emphasizing their constant predictive engagement with their sensory environments. This results in a theoretically grounded and ecologically valid model for collective behavior.
1 / 1
Collective motion models: from self-propelled particles to 
Bayesian agents 
In popular self-propelled particle models, an individual���s movement is described as driven 
by a combination of social and environmental forces.These forces are often treated as 
vectors that capture various tendencies seen in biological collective motion, such as repulsion, 
attraction (to neighbors or external targets), and alignment.These forces can then be 
combined with various nonlinearities and weights to capture mechanisms of interaction. 
2 
In contrast, the active inference approach forgoes specifying explicit vectorial forces, and 
instead starts by modelling all behavior as the solution to an inference problem, namely the 
problem of inferring the latent causes of sensations. Perception and action are updated to 
ensure that the agent better predicts its sensory inputs, using an internal model of its world 
(see Figure 1A). By equipping this internal model with expectations about the environment���s 
underlying tendencies, ���social forces��� can emerge naturally as agents attempt to suppress 
sensory data that are mismatched with their expectations. This perspective-shift of f ers a 
unifying modelling ontology for describing adaptive behavior, while also resonating with 
cybernetic principles like homeostatic regulation and process theories of neural function like 
predictive coding [20, 23, 24]. 
Active inference blends the construct validity of cognitivist approaches with the i rst- 
principles elegance of physics-based approaches by invoking minimization of a single, all- 
encompassing objective function that explains behavior: surprise, or, under certain assump- 
tions, prediction error. As an example of this perspective shift, in this work we investigate 
a specif i c class of generative models that can be used to account for the types of collective 
behaviors exhibited by animal groups. In doing so, we hope to showcase the benef i ts of 
the framework, while also proposing a testable model class for use in studies of biological 
collective motion. 
Active inference and generative models of behavior 
A common pipeline in the quantitative study of animal behavior involves selecting a can- 
didate behavioral algorithm or decision rule that may explain a given behavior, and then 
i tting the parameters of the candidate model to experimental or observational data [15, 25]. 
While these approaches often yield strong quantitative i ts to data, the explanatory power of 
the models reduces to the interpretation of hard-coded parameters, which often have opaque 
relationships to real biological mechanisms or constructs [26]. 
In the active inference framework we rather ask: what is the minimal model an organism 
might have of its environment that is suf i cient to explain its behavior? Behavior is then 
cast as the process by which the agent minimizes surprise or prediction error, with respect 
to this model of the world [20, 27]. The principle of prediction-error minimization enjoys 
empirical support in neuroscience [23, 28] and a theoretical basis in the form of the Free 
Energy Principle [20, 21], an account of all self-organizing systems that casts them as implicit 
models of their environments, ultimately in the service of minimizing the surprise (a.k.a., 
self-information) associated with sensory states [29���31]. 
What states-of-af f airs count as surprising hinges on a generative model that can assign 
a likelihood to sensory data. When it comes to modelling behavior driven by this principle, 
the challenge then becomes specifying a generative or world model, whereby a particular 
pattern of behavior simply emerges by minimizing surprise. 
According to active inference, agents minimize surprise by changing their beliefs about 
the world (changing which observations are considered surprising) or by acting on the world 
to avoid surprising sensory data. The former strategy is thought to correspond to passive processes such as perception and learning, whereas the latter corresponds to processes like 
active sensing and movement. Action is thus motivated by the desire to generate sensations 
that are as least surprising as possible. 
In this paper, we describe the motion of mobile, mutually-sensing agents as emerging 
from a process of collective active inference, whereby agents both estimate the hidden causes 
of their sensations, while also actively changing their position in space in order to minimize 
prediction error. In contrast to models that use pre-specif i ed behavioral rules for generat- 
ing behavior, generative models entail collective behavior by appealing to a probabilistic 
representation of how an organism���s sensory inputs are generated.
1 / 1
ChatGPT
ChatGPT
This section of the paper contrasts traditional self-propelled particle (SPP) models with the active inference approach in understanding collective motion in biological entities.
In SPP models, movement is driven by social and environmental forces that are treated as vectors to capture tendencies like repulsion, attraction, and alignment. They can be manipulated with nonlinearities and weights to represent different interaction mechanisms.
On the other hand, the active inference approach avoids defining explicit forces and instead models all behavior as a solution to an inference problem: the problem of inferring the latent causes of sensations. Here, "social forces" emerge naturally as agents try to suppress sensory data conflicting with their expectations. This perspective offers a unifying way to describe adaptive behavior and aligns with principles like homeostatic regulation and theories like predictive coding.
The strength of active inference lies in blending the validity of cognitive models with the elegance of physics-based ones by focusing on minimizing a single objective function: surprise or prediction error. This work investigates specific generative models to account for collective behaviors, highlighting the advantages of this framework and proposing testable models for studying biological collective motion.
In contrast to traditional quantitative studies that fit candidate behavioral algorithms to data, the active inference framework asks for the minimal model that can explain an organism's behavior. Behavior is then seen as a process of minimizing surprise or prediction error concerning this world model. This principle is supported empirically in neuroscience and theoretically through the Free Energy Principle, viewing all self-organizing systems as implicit models of their environments to minimize surprise.
The active inference approach sees agents as minimizing surprise by changing their beliefs about the world or by acting to avoid surprising sensory data. This leads to a distinction between passive processes like perception and learning and active processes like sensing and movement.
The paper describes the motion of mobile, mutually-sensing agents as emerging from collective active inference, contrasting with traditional models that use predefined behavioral rules. By using generative models, collective behavior is explained through a probabilistic representation of how an organism's sensory inputs are generated, thus providing a richer, more nuanced understanding of collective behavior.
1 / 1
Figure 1: A: Schematic illustrating the Bayesian perspective in the context of our single 
agents, where the hidden states of the environment are segregated from a focal agent by 
means of sensory data yt(right panel of A). This contrasts with classic self-propelled particle 
models (left panel of A), where environmental or social information manifests in terms 
of social forces on the focal individual, who emits its own actions based on hand-crafted 
decision-rules (e.g., changes to heading direction). B: Schematic illustration of the sector- 
specif i c distance tracking.The left panel shows a Bayesian network representation of a 
Markovian state space model, that captures time-evolution of a latent variable x1,...,Tand 
simultaneous observations y1,...T. Note that in practice we represent instantaneous paths of 
x using generalized coordinates of motion �� xt= (xt,x���t,x������ t,...). The middle panel of B shows 
how each component of the vectorial hidden state x = (xh,1,...,xh,L) is computed as the 
average nearest-neighbor distance for the neighbors within each visual sector. Observations 
are generated as noisy, Gaussian samples centered on the sector-wise distance hidden state 
(right panel of B). This requires the agent to estimate the true hidden state xtby performing 
inference with respect to a generative model of how sensory data are generated p(�� y, �� x).
1 / 1
ChatGPT
ChatGPT
Figure 1 in the paper illustrates the differences between the Bayesian perspective used in the active inference approach and classic self-propelled particle (SPP) models.
Panel A compares these two perspectives. On the right, the Bayesian perspective is shown, where hidden states of the environment are separated from an agent through sensory data
y
t
y_t
y
t
���
. The agent's understanding of the environment is mediated through this data. On the left, the classic SPP model is depicted, where environmental or social information influences the individual directly through social forces, leading the individual to emit actions based on predefined decision rules.
Panel B provides a schematic illustration of sector-specific distance tracking. The left part of this panel illustrates a Bayesian network representation of a Markovian state space model. This captures the time evolution of a latent variable
x
1
,
.
.
.
,
T
x_1,...,T
x
1
���
,
...
,
T
and simultaneous observations
y
1
,
.
.
.
,
T
y_1,...,T
y
1
���
,
...
,
T
, where the instantaneous paths of
x
x
x
are represented using generalized coordinates of motion
x
~
t
=
(
x
t
,
x
t
���
,
x
t
���
���
,
.
.
.
)
\tilde{x}_t = (x_t,x'_t,x''_t,...)
x
~
t
���
=
(
x
t
���
,
x
t
���
���
,
x
t
������
���
,
...
)
. The middle part of Panel B demonstrates how each component of the vectorial hidden state
x
=
(
x
h
,
1
,
.
.
.
,
x
h
,
L
)
x = (x_{h,1},...,x_{h,L})
x
=
(
x
h
,
1
���
,
...
,
x
h
,
L
���
)
is computed as the average nearest-neighbor distance within each visual sector. The right panel of B explains that observations are generated as noisy, Gaussian samples centered on the sector-wise distance hidden state, requiring the agent to estimate the true hidden state
x
t
x_t
x
t
���
by performing inference with respect to a generative model of how sensory data are generated
p
(
y
~
,
x
~
)
p(\tilde{y}, \tilde{x})
p
(
y
~
���
,
x
~
)
.
In essence, Figure 1 contrasts the mechanistic and hand-crafted rules of SPP models with the probabilistic and inference-driven approach of active inference, highlighting how sensory data and Bayesian principles guide the agents in understanding their environment.
1 / 1
A generative model for a (social) particle 
We now consider a suf i cient generative model for an individual in a moving group. We equip 
this individual, hereafter referred as the focal agent, with a representation of a simple random 
variable: the local distance x between itself and its neighbors. For generality, we can expand 
this into a multivariate random variable to describe a set of distances x = (x1,x2,...,xL) 
that track the distance between the focal agent and its neighbors within L dif f erent sensory 
sectors (see Figure 1B). We analogize these L sectors to adjacent visual i elds of an agent���s 
i eld of view [32, 33]. 
The focal agent possesses a model of the distance(s) x and its sensations thereof y. 
In particular, our focal agent represents the dynamics of x using a stochastic dif f erential 
equation (a.k.a., a state-space model) def i ned by a drift f and some stochastic forcing �� ��� 
we refer to this component of the generative model as the dynamics model. The stochastic 
term �� captures the agent���s uncertainty about paths of x over time. The agent also believes 
it can sense x via observations y, mediated by a sensory map, which we call the observation 
model. This is def i ned by some function g with additive noise z. The agent���s generative 
model is then fully described by a pair of equations that detail 1) the time-evolution of the 
distance and 2) the simultaneous generation of sensory samples of the distance: 
D�� x =��f + �� ���� y = �� g + �� z(1) 
All random variables are described using generalized coordinates of motion with the 
convention �� q = {q,q���,q������,...}. Generalized coordinates allow us to represent the trajectory 
of a random variable using a vector of local time derivatives (position, velocity, acceleration, 
etc.).The matrix D is a generalized shift operator that moves a vector of generalized 
coordinates up one order of motion D(x,x���,x������,...)���= (x���,x������,x���������,...)���.The generalized 
functions �� 
f and �� g therefore operate on vectors of generalized coordinates (see Appendix A 
for details on generalized i ltering).
1 / 1
ChatGPT
ChatGPT
The passage outlines a generative model for an individual within a moving group, referred to as the focal agent. This model is used to understand the agent's perception and interaction with its environment, specifically regarding the distance between itself and its neighbors within different sensory sectors.
Here's a breakdown of the model:
Random Variable
: The local distance
x
x
x
between the agent and its neighbors is represented as a random variable. This is further expanded into a multivariate random variable
x
=
(
x
1
,
x
2
,
.
.
.
,
x
L
)
x = (x_1, x_2, ..., x_L)
x
=
(
x
1
���
,
x
2
���
,
...
,
x
L
���
)
, allowing tracking of the distance across
L
L
L
different sensory sectors.
Dynamics Model
: The dynamics of
x
x
x
are represented using a stochastic differential equation, defined by a drift
f
f
f
and stochastic forcing
��
\omega
��
. This captures how the agent perceives the change in distances over time and how uncertainty is incorporated into this perception.
Observation Model
: The observation model deals with how the agent senses
x
x
x
through observations
y
y
y
, mediated by a sensory map defined by some function
g
g
g
with additive noise
z
z
z
. This connects the internal representation with the sensations received by the agent.
Equations
: The complete generative model is given by the equations:
D
x
~
=
f
~
+
��
~
y
~
=
g
~
+
z
~
\begin{align*}
D\tilde{x} &= \tilde{f} + \tilde{\omega} \\
\tilde{y} &= \tilde{g} + \tilde{z}
\end{align*}
D
x
~
y
~
���
���
=
f
~
���
+
��
~
=
g
~
���
+
z
~
���
where all random variables are described using generalized coordinates of motion, denoted with the convention
q
~
=
{
q
,
q
���
,
q
���
���
,
.
.
.
}
\tilde{q} = \{q,q',q'',...\}
q
~
���
=
{
q
,
q
���
,
q
������
,
...
}
. The matrix
D
D
D
is a generalized shift operator that represents the trajectory of a random variable in terms of local time derivatives (such as position, velocity, acceleration, etc.).
Generalized Coordinates
: The use of generalized coordinates allows for a complex representation of the dynamics, involving various derivatives of the random variable.
L Sectors
: The model can be visualized in terms of
L
L
L
sectors corresponding to adjacent fields of view within the agent's perception, as shown in Figure 1B.
This model provides a comprehensive mathematical framework to study how an individual in a group perceives its local environment, especially the distances to its neighbors, and how this perception influences its behavior. The use of stochastic equations adds complexity and realism to the modeling, allowing for uncertainty and noise in the agent's perception and actions.
1 / 1
Generalized i ltering and active inference 
An agent equipped with this dynamic generative model then performs active inference by 
updating its beliefs (state estimation, or i ltering) and control states (action) to minimize 
5 
surprise. 
Inference entails updating a probabilistic belief over hidden states �� x in the face of sen- 
sory data �� y. Our agents solve this i ltering problem using generalized i ltering [34, 35], an 
approximate algorithm for Bayesian inference and parameter estimation on dynamic state- 
space models. This is achieved by minimizing the variational free energy F, a tractable 
upper bound on surprise (i.e., negative log evidence or marginal likelihood).The agent 
minimizes the free energy with respect to a belief distribution q(�� x) with parameters ��; this 
approximates the true posterior q��(�� x) ��� p(�� x|�� y), which is the optimal solution in the context 
of Bayesian inference. The true posterior p(�� x|�� y) is dif i cult to compute for many generative 
models due to the dif i cult calculation of the marginal (log) likelihood lnp(�� y). Variational 
methods circumvent this intractable marginalization problem by replacing it with a tractable 
optimization problem: namely, adjusting an approximate posterior to match the true poste- 
rior by minimizing F with respect to its (variational) parameters ��. 
We parameterize q(�� x) as a Gaussian with mean-vector �� ��; according to generalized i lter- 
ing, �� �� is updated using a weighted sum of prediction errors: 
d�� �� 
dt ��� �������� 
��F(�� ��, �� y) 
��� 
�� ��z��������� 
where �� 
��z= �� ��z(�� y ��� �� g(�� ��)) 
�� 
����= �� ����(D�� �� �����f(�� ��))(2) 
The ensuing evidence accumulation can also be regarded as a generalisation of predictive 
coding [23, 36], where beliefs are updating using a running integration of prediction errors 
�� 
��z,������. 
While inference entails changing the approximate posterior means �� �� to account for sen- 
sory data, action entails changing the data itself to better match the data to one���s current 
beliefs. Similar to the update scheme in (2), actions are also updated by minimizing free 
energy: da 
dt = ������aF(�� 
��, �� y(a)) 
= �������� yF(�� ��, �� y(a))���a�� 
y(a) 
= ������� 
��� z���a�� 
y(a) (3) 
Actions thus are updated using a product of precision-weighted prediction errors and 
�� ��zand a ���sensorimotor contingency��� ���a�� y(a) or ref l ex arc. This sort of ���ref l exive action��� ��� 
where control is simply targeted at minimizing sensory prediction errors ��� underlies active 
inference accounts of motor control [22, 24], and can be formally related to proportional- 
integral-derivative (PID) control [37]. In the presence of precise prior beliefs (i.e., �� ������� 
�� 
��z), 
these prediction errors measure how far an agent���s observations are from its expectations; the 
6 
agent then acts using (3) to minimize this deviation. Active inference agents are thus driven 
to act in a way that aligns with their (biased) expectations about the world [38]. In the next 
section, we will see how building a particular type of bias into each agent���s generative model 
leads to the appearance of social forces-like terms in (3).
1 / 1
ChatGPT
ChatGPT
This passage explains how an agent equipped with a dynamic generative model (explained earlier) performs active inference. Here���s a breakdown of the concepts involved:
Active Inference
: The agent updates its beliefs and actions to minimize surprise, based on sensory data.
Generalized Filtering
: This is an approximate algorithm for Bayesian inference and parameter estimation on dynamic state-space models. It's used to solve the filtering problem, or updating beliefs over hidden states
x
~
\tilde{x}
x
~
, given sensory data
y
~
\tilde{y}
y
~
���
.
Minimization of Free Energy
: The agent minimizes the variational free energy
F
F
F
, an upper bound on surprise. It uses a Gaussian parameterization for
q
(
x
~
)
q(\tilde{x})
q
(
x
~
)
, and the mean vector
��
~
\tilde{\mu}
��
~
���
is updated using a weighted sum of prediction errors. The equations involved are:
d
��
~
d
t
���
���
���
��
~
F
(
��
~
,
y
~
)
���
��
~
z
���
��
~
��
��
~
z
=
��
~
z
(
y
~
���
g
~
(
��
~
)
)
��
~
��
=
��
~
��
(
D
��
~
���
f
~
(
��
~
)
)
\begin{align*}
\frac{d\tilde{\mu}}{dt} &\propto -\nabla\tilde{\mu}F(\tilde{\mu}, \tilde{y}) \propto \tilde{\xi}z - \tilde{\xi}\omega \\
\tilde{\xi}z & = \tilde{\Pi}z(\tilde{y} - \tilde{g}(\tilde{\mu})) \\
\tilde{\xi}\omega & = \tilde{\Pi}\omega(D\tilde{\mu} -\tilde{f}(\tilde{\mu}))
\end{align*}
d
t
d
��
~
���
���
��
~
���
z
��
~
���
��
���
���
���
���
��
~
���
F
(
��
~
���
,
y
~
���
)
���
��
~
���
z
���
��
~
���
��
=
��
~
z
(
y
~
���
���
g
~
���
(
��
~
���
))
=
��
~
��
(
D
��
~
���
���
f
~
���
(
��
~
���
))
���
Evidence Accumulation
: This process is a generalization of predictive coding, updating beliefs using running integration of prediction errors.
Actions and Motor Control
: While inference changes the approximate posterior means, action entails changing the data to better match current beliefs. Actions are updated by minimizing free energy, expressed by:
d
a
d
t
=
���
���
y
~
F
(
��
~
,
y
~
(
a
)
)
���
a
y
~
(
a
)
=
���
��
~
���
z
���
a
y
~
(
a
)
\frac{da}{dt} = -\nabla\tilde{y}F(\tilde{\mu}, \tilde{y}(a))\nabla a\tilde{y}(a) = -\tilde{\xi}^{\top}z\nabla a\tilde{y}(a)
d
t
d
a
���
=
���
���
y
~
���
F
(
��
~
���
,
y
~
���
(
a
))
���
a
y
~
���
(
a
)
=
���
��
~
���
���
z
���
a
y
~
���
(
a
)
Here, control is targeted at minimizing sensory prediction errors, forming the basis of active inference accounts of motor control, and it can be related to proportional-integral-derivative (PID) control.
Alignment with Expectations
: The agent's actions aim to minimize deviation from expectations. Precise prior beliefs can measure how far observations are from expectations, driving the agent to act in alignment with biased expectations.
Implication for Social Behavior
: The passage hints at how biases in an agent's generative model can lead to the appearance of social forces-like terms in the equation governing actions.
In summary, the agent's beliefs and actions are updated through generalized filtering and active inference by minimizing the free energy associated with sensory surprises. This mechanism provides a theoretical framework for understanding how an agent interprets and reacts to its environment, including its social context.
1 / 1
Social forces as a consequence of predictive control 
In particular, we take the agent���s action to be its heading direction a = v, and examine 
the case where the agent observes the distance to its neighbors within a single sensory 
sector, i.e., L = 1, x = (x1). We distinguish the agent���s representation of the distance x 
from the actual distance using the subscript h. Therefore xh= (xh,1,xh,2,...,xh,L) denotes 
the average distances (and corresponding sensory samplesyh) calculated using the actual 
positions of other agents. For the case of L = 1, and assuming the agent observes both the 
distance and its rate of change y��� h,1, this is: 
xh,1= 
1 
K X 
j���Nin ���rj��� r���yh,1= xh,1+ zh,1 
x���h,1= 
dxh,1 
dt 
y��� 
h,1 = x���h,1+ z��� h,1 (4) 
Ninis the set of neighbors within the agent���s single sensory sector, K is the size of this 
set, r is the focal agent���s position vector, and rjis the position vectors of neighbor j. The 
sensory observation of the generalized distance �� yh= (yh,1,y��� h,1) is a sample of the hidden 
state, perturbed by some additive noises �� z = (zh,1,z��� h,1). By expanding the active inference 
control rule in (3), we arrive at the following dif f erential equation for the heading vector: 
dv 
dt 
= ����� z����� r 
����� r = 
1 
K X 
j���Nin 
���rj 
������rj���,���rj 
= rj��� r(5) 
The average vector ����� r is exactly the (negative) ���sensorimotor contingency��� term ���a�� 
y(a) 
from (3) (see Appendix A for detailed derivations): 
���v�� y(v) = ���ry 
= 
1 
K X 
j���Nin 
r ��� rj 
���r ��� rj��� = �������� r(6) 
The simple action update in (5) means that the focal agent moves along a vector point- 
ing towards the average position of its neighbors. Whether this movement is attractive or 
repulsive is determined by the sign of the sensory prediction error ����� z, and its magnitude 
7 
depends on the scale of the prediction error, i.e., how much observations deviate from the 
agent���s predictions. 
The presence of both attractive and repulsive forces depends on the agent���s model of the 
distance dynamics, captured by the functional form of �� 
f. In particular, consider forms of �� 
f 
that relax x to some attracting i xed point �� > 0. Equipped with such a stationary model of 
the local distance, inference dynamics (c.f., (2)) will constantly bias its predictions �� accord- 
ing to the prior belief that the distance is pulled to ��. Given this biased dynamics model 
and the action update in (3), such an agent will move to ensure that distance observations 
�� yhare consistent with the i xed point ��. 
This action update shows immediate resemblance to the attractive and repulsive vectors 
common to social force-based models [4, 5, 7], which often share the following general form: 
Fattr��� X 
j���ZA 
rij 
���rij��� 
Frepul��� ��� 
1 
K X 
j���ZR 
rij 
���rij��� (7) 
where ZA,ZRrefer to distance-def i ned zones of attraction or repulsion, respectively. In 
the active inference framework, these social forces emerge as the derivative of the observations 
with respect to action ���a�� y, where the sign and magnitude of the sensory prediction error 
����� z determines whether the vector is attractive (towards neighbors) or repulsive (away from 
neighbors). The transition point between attraction and repulsion is therefore given by ��, 
the point at which prediction errors switch sign. 
An important consequence of this formulation is that, unlike the action rule used in social 
force-based models, the ���steady-state��� solution occurs when all social forces disappear (when 
prediction errors vanish). In this case, the agent ceases to change its heading direction and 
adopts its previous velocity. This occurs when the agent���s sensations align with its (biased) 
predictions yh,1��� ��. In classic SPP models, this is equivalent to the dif f erent social force 
vectors exactly cancelling each other.
1 / 1
ChatGPT
ChatGPT
This section delves into how social forces can arise as a consequence of predictive control within the active inference framework. It looks at how an agent, taking into account its direction and the distance to its neighbors, responds with actions that can be understood as attractive or repulsive forces. Here's an overview:
Agent's Action and Observations
: The action is represented as the heading direction
a
=
v
a = v
a
=
v
, and the agent observes the distance to its neighbors. The representation of the distance, including the actual distance and its rate of change, is given by equations in the passage.
Differential Equation for Heading Vector
: The change in the agent's heading direction over time is given by
d
v
d
t
=
��
���
z
��
r
^
\frac{dv}{dt} = \xi' z \Delta\hat{r}
d
t
d
v
���
=
��
���
z
��
r
^
where
��
r
^
\Delta\hat{r}
��
r
^
is the average vector pointing towards the average position of the neighbors.
Attractive or Repulsive Forces
: Whether the movement is attractive (towards neighbors) or repulsive (away from neighbors) depends on the sign of the sensory prediction error
��
���
z
\xi' z
��
���
z
and its magnitude.
Model of Distance Dynamics
: The presence of both attractive and repulsive forces depends on the agent's model of distance dynamics. If the agent has a stationary model of local distance that attracts to a fixed point
��
\eta
��
, it will move to ensure distance observations are consistent with
��
\eta
��
.
Similarity to Social Force-Based Models
: The action update has resemblance to attractive and repulsive vectors common in social force-based models:
F
attr
\proportionalto
���
j
���
Z
A
r
i
j
���
r
i
j
���
,
������
F
repul
\proportionalto
���
1
K
���
j
���
Z
R
r
i
j
���
r
i
j
���
.
F_{\text{attr}} \proportionalto \sum_{j\in ZA} \frac{r_{ij}}{\|r_{ij}\|},\; F_{\text{repul}} \proportionalto -\frac{1}{K} \sum_{j\in ZR} \frac{r_{ij}}{\|r_{ij}\|}.
F
attr
���
\proportionalto
j
���
Z
A
���
���
���
r
ij
���
���
r
ij
���
���
,
F
repul
���
\proportionalto
���
K
1
���
j
���
ZR
���
���
���
r
ij
���
���
r
ij
���
���
.
Here,
Z
A
ZA
Z
A
and
Z
R
ZR
ZR
refer to distance-defined zones of attraction or repulsion.
Transition Point
: The point
��
\eta
��
at which prediction errors switch sign determines the transition between attraction and repulsion.
Steady-State Solution
: Unlike classic social force models, in this active inference framework, the steady-state solution occurs when all social forces disappear (prediction errors vanish). The agent then ceases to change its direction and maintains its previous velocity.
The concepts here present an advanced understanding of how predictive control, within the active inference framework, can lead to behaviors that are similar to those modeled by social forces. By modeling the agent's relationship with its neighbors in terms of prediction errors and control rules, the passage explains how social dynamics such as attraction and repulsion can emerge naturally from the active inference process.
1 / 1
We can therefore interpret social force-based models as limiting cases of distance-inferring 
active inference agents, because one can conceive of social forces as just those forces induced 
by free energy gradients; namely, the forces that drive belief-updating. In the case of our 
active inference agents, attractive and repulsive forces emerge naturally when we assume A) 
agents model the local distance dynamics as an attractor with some positive-valued i xed 
point ��; B) agents can act by changing their heading direction and C) agents observe at least 
the i rst time derivative of their observations (e.g., y��� h,1, but see Appendix A for detailed 
derivations). 
It is worth highlighting the absence of an explicit alignment force in this model, consistent 
with experimental i ndings in several species of i sh [16]. The heading vectors of neighbors 
nevertheless implicitly incorporated into the calculation of i rst-order prediction errors ����� 
z 
(c.f., (A.40) in Appendix A). However, alignment forces as seen in the Vicsek model [6] 
8 
and Couzin model [7] can also be recovered if we assume agents have a generative model 
of the average angle between their heading vector and those of their neighbors (see B for 
derivations). 
Multivariate sensorimotor control 
Having recovered social forces as free energy gradients in the case of a single sensory sector 
(L = 1), we now revisit the general formulation of the generative model���s state-space, where 
the hidden variable x is treated as an L-dimensional vector state: x = (x1,x2,...,xL), with 
correspondingly L-dimensional observations y = (y1,y2,...,yL). 
Specif i cally, we consider each xlto represent the average distance-to-neighbors within 
one of a subset of adjacent sensory sectors, where each sector is of f set from the next by 
a i xed inter-sector angle (see Figure 1B for a schematic of the multi-sector set-up). The 
rest of the generative model is identical; the agents estimate these distances (and their 
temporal derivatives x���l,x������ l,...) while changing their heading direction to minimize free energy. 
Following the same steps as in the case of a single sector, the resulting update rule for v is 
a weighted sum of ���sector-vectors���, where generalized observations from each sector-specif i c 
modality �� ylare used to compute the prediction errors that scale the corresponding sector- 
vector. This generalizes the scalar-vector product in (3) to a matrix-vector product: 
dv 
dt 
= �� 
�� ��� 
z��� �� 
R 
�����R = ��� ��� ��� ��� ��� ��� 
���v�� y1 
���v�� 
y2 
. . . 
���v�� 
yL 
��� ��� ��� ��� ��� 
(8) 
where now the (negative) sensorimotor contingency ������a�� 
y = �����R is a matrix whose rows 
contain the partial derivatives ���v�� yl(i.e. the ���sector-vectors���). Each sector-vector is a vector 
pointing towards the average neighbor position within sector l.
1 / 1
ChatGPT
ChatGPT
This segment of text further develops the connection between social force-based models and active inference agents, emphasizing the emergence of attractive and repulsive forces. It also introduces multivariate sensorimotor control. Here���s the breakdown:
Social Force-Based Models as Limiting Cases
: Social force-based models can be seen as specific cases of distance-inferring active inference agents. The forces in these models can be thought of as those induced by free energy gradients, driving belief-updating.
Conditions for Attractive and Repulsive Forces
: For attractive and repulsive forces to emerge, three assumptions are made:
A) Agents model local distance dynamics with a positive-valued fixed point
��
\eta
��
.
B) Agents act by changing their heading direction.
C) Agents observe at least the first time derivative of their observations.
Absence of Alignment Force
: Unlike some other models, this formulation doesn���t include an explicit alignment force. However, the heading vectors of neighbors are still implicitly incorporated into the calculations. Alignment forces can be included if agents model the average angle between their heading and that of their neighbors.
Multivariate Sensorimotor Control
: The general case is considered where the hidden variable
x
x
x
is an
L
L
L
-dimensional vector state, representing distances to neighbors within different sensory sectors. The update rule for the heading vector
v
v
v
now becomes a weighted sum of ���sector-vectors���, leading to a matrix-vector product:
d
v
d
t
=
��
~
���
z
��
R
^
,
������
��
R
^
=
���
[
���
v
y
~
1
���
v
y
~
2
���
���
v
y
~
L
]
\frac{dv}{dt} = \tilde{\xi}^{\top} z\Delta\hat{R},\; \Delta\hat{R} = -\begin{bmatrix} \nabla v\tilde{y}_1 \\ \nabla v\tilde{y}_2 \\ \vdots \\ \nabla v\tilde{y}_L \end{bmatrix}
d
t
d
v
���
=
��
~
���
���
z
��
R
^
,
��
R
^
=
���
���
���
���
���
v
y
~
���
1
���
���
v
y
~
���
2
���
���
���
v
y
~
���
L
���
���
���
���
���
Here,
��
R
^
\Delta\hat{R}
��
R
^
is a matrix whose rows contain the partial derivatives
���
v
y
~
l
\nabla v\tilde{y}_l
���
v
y
~
���
l
���
, representing vectors pointing towards the average neighbor position within each sector
l
l
l
.
This segment encapsulates how distance-inferring active inference agents can be used to model social forces by focusing on the free energy gradients that drive belief updating. It also extends the formulation to accommodate a more complex sensory space by allowing for multiple sensory sectors, introducing a richer and more nuanced control mechanism. This multivariate approach permits a more detailed and realistic modeling of how agents perceive and respond to their surroundings, which may have applications in understanding collective behaviors in groups of animals or even in robotic swarms.
1 / 1
Numerical results 
Given a group of active inference agents ��� equipped with the generative models described 
in previous sections ��� it is straightforward to generate trajectories of collective motion by 
integrating each agent���s heading vector over time: �� ri= vi,i ��� {1,2,...,N} where N is the 
number of agents. We update all heading directions {vi}N 
i=1 and beliefs {�� ��i}N 
i=1 in parallel 
via a joint gradient descent on their respective free energies: 
9 
A 
B log��z log��z 
��z��z 
PolarizationMilling probability 
PolarizedMillingDisordered 
Figure 2: A: Example snapshots of dif f erent collective states in schools of N = 50 active 
inference agents. Each line represents the trajectory of one individual, and color gradient 
represents time, from earliest (light blue) to latest (purple). The polarized regime in the 
left panel was simulated with the default parameters listed in Table E.1 in Appendix E. The 
milling regime (middle panel) was achieved by increasing the variance of velocity l uctuations 
(encoded in ��2 z���,h) from 0.01 to 0.05 (relative to the default conf i guration) and increasing ��z 
from 1.0 to 1.2. The disordered regime was achieved by increasing the sensory smoothness 
parameter to 2.0 and decreasing �� from 1.0 to 0.5 and �� from 0.5 to 0.1 (relative to the 
default conf i guration). B: Average polarization (left) and milling probability (right) shown 
as a function of the two factorized components of the sensory precision, ��z(log-transformed) 
and ��z. For each combination of precision parameters, we ran 500 independent trials of ���free 
schooling,��� and then averaged the quantities of interest across trials. Each ���free schooling��� 
trial lasted 15 seconds (1500 time steps with dt = 0.01s); the time-averaged metrics (polar- 
ization and milling probability, respectively, were computed from the last 10 seconds of the 
trial.

�� v 1= ������v1F(�� ��1, �� y1) �� 
�� ��1= �������� ��1F(�� ��1, �� y1) 
�� v 2= ������v2F(�� ��2, �� y2) �� 
�� ��2= �������� ��2F(�� ��2, �� y2) 
. . . . . . 
�� v N= ������vNF(�� ��N, �� yN) �� 
�� ��N= �������� ��NF(�� ��N, �� yN)(9) 
For the simulation results shown here, each agent tracks the average distance xlwithin 
a total of L = 4 sensory sectors that each subtend 60���(starting at ���120���and 
ending 
at +120���, relative to the focal agent���s heading direction) and observe the sector-specif i c 
distances calculated using all neighbors lying within 5.0 units of the focal agent���s position. 
Each agent represents the vector of local distances as a generalized state with 3 orders of 
motion: �� x = {x,x���,x������}, �� �� = {��,�����,��������}. Agents can observe the i rst and second orders 
of the distance �� y = {y,y���}, i.e. the distance itself and its instantaneous rate-of-change. In 
the numerical results to follow, we use active inference to study the relationship between the 
properties of individual cognition (e.g., the parameters of agent-level generative models) and 
collective phenomenology. 
Collective regimes 
Simulated groups of these distance-inferring agents display robust, cohesive collective motion 
(see Figure 2A and Supplemental Movies 1-5). Figure 2A displays examples of dif f erent 
types of group phenomena exhibited in groups of active inference agents, whose diversity 
and types resemble those observed in animal groups [39, 40] and in other collective motion 
models [6, 7, 41]. These range from directed, coherent movement with strong inter-agent 
velocity correlations (���polarized motion���) to group rotational patterns, like milling, which 
features high angular momentum around the group���s center-of-mass.
1 / 1
ChatGPT
ChatGPT
The text you provided focuses on the numerical simulation of a group of active inference agents based on the models described earlier, analyzing the collective motion patterns that arise from these agents' behaviors. Here's a summary:
Simulation Setup
: The simulation generates trajectories of collective motion by integrating the heading vector of each agent over time, updating both heading directions and beliefs simultaneously via joint gradient descent on free energies. This is described by the equation:
v
��
i
=
���
���
v
i
F
(
��
~
i
,
y
~
i
)
,
������
��
~
��
i
=
���
���
��
~
i
F
(
��
~
i
,
y
~
i
)
\dot{v}_i = -\nabla v_i F(\tilde{\mu}_i, \tilde{y}_i),\; \dot{\tilde{\mu}}_i = -\nabla \tilde{\mu}_i F(\tilde{\mu}_i, \tilde{y}_i)
v
��
i
���
=
���
���
v
i
���
F
(
��
~
���
i
���
,
y
~
���
i
���
)
,
��
~
���
��
���
i
���
=
���
���
��
~
���
i
���
F
(
��
~
���
i
���
,
y
~
���
i
���
)
where
i
i
i
is the agent index and
N
N
N
is the number of agents.
Sensory Setup
: Each agent tracks the average distance within four sensory sectors spanning 60�� each, observing both the distance and its instantaneous rate of change. Agents are equipped to observe the first and second orders of distance and its derivatives.
Collective Regimes
: Simulated agents exhibit robust, cohesive collective motion, displaying group phenomena that resemble those seen in animal groups and other models of collective motion. Figure 2A illustrates various types of group behaviors:
Polarized Motion
: Directed, coherent movement with strong inter-agent velocity correlations.
Milling
: Group rotational patterns with high angular momentum around the group's center of mass.
Parameter Variation
: Different regimes of collective motion (polarized, milling, disordered) were achieved by adjusting parameters like velocity fluctuation variance, sensory smoothness, and the fixed point of the attractor.
Study of Cognition and Collective Phenomenology
: The simulations were leveraged to study the relationship between individual cognition, specifically agent-level generative model parameters, and collective phenomena.
Overall, the numerical results provide insights into how individual-level behaviors (e.g., modeling local distance dynamics, sensory observations) can give rise to complex and diverse group behaviors. By tweaking the parameters of the generative model, various collective patterns can be reproduced, making this approach applicable for studying collective behavior in both natural systems (like schools of fish) and artificial systems (like swarms of robots).
1 / 1
Relating individual beliefs to collective outcomes 
In all but the most carefully constructed systems [26, 42], the relationship between individ- 
ual and collective representations is often opaque. In particular, the relationship between 
individual level uncertainty or ���risk��� and collective behavior is an open area of research. For 
instance, increased risk-sensitivity at the level of the individual may lead to to decreased 
risk-encoding at the collective level [43]. Inspired by these observations, we use active in- 
ference to examine the quantitative relationship between uncertainty at the individual level 
and collective phenomenology. We begin by examining common metrics of group motion 
like polarization and angular momentum [7]. In Figure 2B we explore how polarization and 
angular momentum are af f ected by two components of agent-level sensory uncertainty (i.e., 
inverse sensory precision): 1) the absolute precision that agents associate to sensory noise, 
encoded in the parameter ��zand; 2) the autocorrelation or ���smoothness��� of that noise, en- 
coded in the parameter ��z. Intuitively, ��zencodes the variance or amplitude that the agent 
11 
associates with the noise in each of its L sensory sectors yl, and ��zis a how ���smooth��� the 
agent believes the noise i [35, 44]. A higher value of ��zimplies that the agent believes sen- 
sory noise are more serially-correlated (e.g., random l uctuations in optical signals caused by 
smooth variations in refraction due to turbulence in water). We refer the reader to Appendix 
C for details on how these two parameters ��zand ��zjointly the parameterize the precision 
matrix of the agent���s observation model. 
Figure 2B shows how the dif f erent components (amplitude and autocorrelation) of the 
agent���s sensory uncertainty determine group behavior, as quantif i ed by average polarization 
and milling probability.Average polarization is def i ned here as the time average of the 
polarization of the group, where the polarization at a given time p(t) measures the alignment 
of velocities of agents comprising the group [7, 39]: 
�� p = 
1 
T 
T X 
t=1 
p(t)p(t) = 
1 
N ��� 
N X 
i=1 vi(t)���(10) 
High average polarization indicates directed, coherent group movement. The left panel 
of Figure 2B shows how ��zand ��zcontribute to the average polarization of the group. 
An increase in either parameter causes polarization to decrease and angular momentum to 
increase, ref l ecting the transition from directed motion to a milling regime, where the group 
rotates around its center of mass. We calculate the milling probability (c.f. right panel of 
Figure 2B) as the proportion of trials where the time-averaged angular momentum surpassed 
0.5. The average angular momentum can be used to quantify the degree of rotational motion, 
and is calculated as the time- and group-average of the individual angular momenta around 
the groups��� center of mass c: 
�� m = 
1 
T 
T X 
t=1 
m(t)m(t) = 
1 
N ��� 
N X 
i=1 ric(t) �� vi(t)���(11) 
where ricis a relative position vector for agent i, def i ned as the vector pointing from the 
group center c to agent i���s position: ri��� c. 
These collective changes can be understood in light of the magnitude of action updates, 
which depend on the how the scale of i rst-order prediction errors �����zis tuned by ��zand ��z: 
�����z��� ��z��2 
z (12) 
In practice, this means that as the group believes in more predictable (less rough) i rst- 
order sensory information y��� z, the group as a whole is more likely to enter rotational, milling- 
like regimes. However, the enhancing ef f ect of these i rst-order prediction errors �����zon rota- 
tional motion is bounded; if prediction errors are over-weighted (e.g. high ��zand/or ��z), the 
group becomes more polarized again and likely to fragment. This fragmentation probability 
occurs at both low and high levels of ��zand ��z, implying that there is an optimal range 
of individual-level sensory precision where cohesive group behavior (whether polarized or Figure 3: A: Collective accuracy as a function of proportion informed or pinffor dif f ering 
values of the sensory precision assigned to social observations ��z���Social. Average accuracy 
for each condition (combination of pinf,��zSocial,��z���Target) was computed as the proportion of 
successful hits across 500 trials. Here, the average accuracy is further averaged across all the 
values of the ��z���Targetparameter, meaning each accuracy here is computed as the average of 
15000 total trials (500 trials per condition �� 30 dif f erent values of ��z���Target). B: Collective 
accuracy as a function of both the social and target precisions (��z���Social,��z���Target, shown 
in log-scale) averaged across values of pinfranging from pinf= 0.15 to pinf= 0.40. Each 
condition���s accuracy was computed as the proportion of accurate decisions from 500 trials. 
milling) is stable. Thus, our model predicts that maintaining beliefs about reliable informa- 
tion is neither required, or in fact even desirable, for animals in order to facilitate collective 
motion. 
We have seen how one can use active inference to relate features of individual-level beliefs 
(in this case, beliefs about sensory precision) to collective patterns, focusing in the present 
case on common metrics for studying collective motion like polarization and the tendency 
to mill. 
In the following sections, we move from looking at group-level patterns that occur during 
free movement, to studying the consequences of individual-level uncertainty for collective 
information-processing. We begin by investigating how collective information transfer de- 
pends on individual-level beliefs about the relative precisions associated with dif f erent types 
of sensory information.
1 / 1
ChatGPT
ChatGPT
The section you provided delves into the relationship between individual-level beliefs and collective behaviors in the context of active inference. Here���s a breakdown:
Complex Relationship Between Individual and Collective Behaviors
: The interplay between individual uncertainty (or ���risk���) and collective behavior is complex, and understanding this relationship is an ongoing area of research.
Examining Sensory Uncertainty
: The study looks at two components of agent-level sensory uncertainty:
��z
: Encodes the variance or amplitude that an agent associates with the noise in its sensory sectors.
��z
: Represents how ���smooth��� the agent believes the noise is, with higher values meaning more serially-correlated noise.
Polarization and Angular Momentum
: These metrics of group motion are explored in relation to sensory uncertainty.
Average Polarization
: Defined as the time-average of the alignment of velocities of agents, indicating directed, coherent group movement. An increase in either ��z or ��z leads to decreased polarization and increased angular momentum, reflecting a shift from directed motion to a milling regime.
Milling Probability
: Calculated as the proportion of trials where the time-averaged angular momentum surpassed a threshold. This and the average angular momentum quantify the degree of rotational motion.
Magnitude of Action Updates
: This refers to how the scale of first-order prediction errors is tuned by ��z and ��z, influencing the group's tendency to enter rotational regimes or to become more polarized and potentially fragment.
Optimal Range for Cohesiveness
: The model reveals an optimal range of individual-level sensory precision for stable cohesive group behavior, where beliefs about reliable information are neither necessary nor desirable.
Collective Information Processing
: The text also hints at upcoming exploration into how collective information transfer depends on individual-level beliefs about the relative precisions associated with different types of sensory information.
In summary, this excerpt from a scientific paper is focused on examining how individual beliefs, specifically those related to sensory uncertainty, influence collective outcomes like polarization and angular momentum. It provides an analytical and mathematical exploration of the transitions between different group behaviors and offers insight into how complex collective phenomena emerge from individual-level uncertainties. It also sets the stage for a broader investigation into collective information processing.
1 / 1
Collective information transfer 
In this section, we take inspiration from the collective leadership and decision-making liter- 
ature to investigate how individuals in animal groups can collectively navigate to a distant 
target [45���48]. This phenomenon is an example of ef f ective leadership through collective 
information transfer and is remarkable for a number of reasons; one that speaks to its emer- 
gent nature, is the fact that these collective decisions are possible despite ��� and indeed even 
because of ��� the presence of uninformed individuals in the group [46]. Figure 3A shows 
that active inference agents engaged in this task reproduce a result from earlier work [45] on 
the relationship between the proportion of uninformed individuals and collective accuracy. 
Namely, as the proportion of informed individuals increases, so does the accuracy of reaching 
the majority-preferred target. In the same vein as earlier sections, we also investigated the 
dependence of this ef f ect, as well as the average target-reaching accuracy, on individual-level 
beliefs. 
We operationalize the notion of an agent being ���informed��� (about an external target) by 
introducing a new latent variable to its generative model; this variable xtargetrepresents the 
distance between the informed agent���s position r and a point-mass-like target with position 
vector T = [T1,T2].We thus def i ne this new hidden state and observation as follows: 
xtarget= ���T ��� r���, ytarget= xtarget+ ztarget. Just like the ���social��� distance observations yh, 
this target distance observation ytargetrepresents a (potentially-noisy) observation of the 
true distance xtarget. As before, the agent s represent both the target distance xtargetand 
its observations ytargetusing generalized coordinates of motion. Each informed agent has 
a dynamics model of �� xtarget, whereby they assume the target-distance is driven by some 
drift function ftarget(xtarget) = �����txtargetwhich relaxes to 0. As with the social distances, 
we truncate the agent���s generalized coordinates embedding of the target distance to three 
orders of motion and the generalized observations to two orders of motion. 
Each informed agent maintains a full posterior belief �� �� = (�� ��1, �� ��2,..., �� ��L, �� ��target) about 
the local distances �� x1, �� x2,..., �� xLas well as the target distance �� xtarget. 
Using identical reasoning to arrive at the action updates in (5) and (8), one can augment 
the matrix-vector product in (8) with an extra sensorimotor contingency and prediction error 
that represents target-relevant information: 
dv 
dt 
= �� 
�� ��� 
z ?��� 
�� 
R 
���T ? 
���T = ������v�� ytarget= T ��� r 
���T ��� r��� 
(13) 
This matrix-vector product can then be seen as a weighted combination of social and 
target vectors, with the weights af f orded to each equal to their respective precision-weighted 
prediction errors: 14 
dv 
dt 
= ��social�����R 
|{z} 
Social vector 
+ ��target���T 
|{z} 
Target vector 
(14) 
This expression is analogous to the velocity update in Equation (3) of Ref. [45], where 
a ���preferred direction��� vector is integrated into the agent���s action update with some pre- 
determined weight. This weight is described as controlling the relative strengths of non- 
social vs. social information. For active inference agents, the weighting of target-relevant 
information emerges naturally as a precision-weighted prediction error (here represented as 
��target), and the target-vector itself is equivalent to a sensorimotor ref l ex arc, that represents 
the agent���s assumptions about how the local l ow of the target distance y��� target changes as a 
function of the agent���s heading direction v. An important consequence of this construction, 
is that, unlike in previous models where this weight is ���baked-in��� as a i xed parameter, the 
weight assigned to the target vector is dynamic, and l uctuates according to how much the 
agent���s expectations about the target distance �� ��targetpredict the sensed target distance ytarget.
1 / 1
ChatGPT
ChatGPT
This section of the text focuses on the concept of collective information transfer within the context of animal groups, specifically how they can collectively navigate to a distant target. Here's a brief summary of the key points:
Emergent Nature of Collective Decisions
: The phenomenon being studied here is particularly remarkable as collective decisions can occur even with the presence of uninformed individuals within the group.
Informed vs Uninformed Agents
: In the model, an agent is defined as ���informed��� if it knows the distance to a specific target. As the proportion of informed individuals increases, the accuracy of reaching the target also increases.
Modeling Target Distance
: The model introduces a latent variable to represent the distance between the informed agent's position and the target. The agent's belief about this distance, along with local distances, plays a key role in driving its behavior.
Weighted Combination of Social and Target Vectors
: The velocity update of each agent can be viewed as a combination of social and target vectors. The weighting of these vectors is not fixed but fluctuates according to precision-weighted prediction errors (represented as ��_target).
Dynamic Nature of Weighting
: Unlike previous models where the weight between social and non-social information is a fixed parameter, this construction allows the weight assigned to the target vector to be dynamic. It changes based on how well the agent's expectations about the target distance predict the sensed target distance.
Collective Navigation Through Active Inference
: By applying the principles of active inference, the model can reproduce results from earlier work regarding collective navigation and provides a more nuanced understanding of how individual-level beliefs about sensory information can affect collective behavior.
In summary, this section provides insights into how collective navigation to a distant target can be achieved within animal groups. It emphasizes the roles of informed and uninformed individuals, and illustrates how individual-level beliefs and their dynamic interactions contribute to the overall ability of the group to reach its target. The incorporation of active inference in this analysis offers a more flexible and responsive understanding of the complex interplay between individual and collective decision-making.
1 / 1
Using this new construction, we can simulate a group of active inference agents, in which 
some proportion pinfof agents represent this extra set of target-related variables as described 
above. To generate �� ytargetobservations for these informed individuals, we placed a spatial 
target at a i xed distance away from the group���s center-of-mass and then allowed the informed 
individuals to observe the generalized target distance �� ytarget= (ytarget,y��� target). We then 
integrated the collective dynamics over time and measured the accuracy with which the group 
was able to navigate to the target (see Materials and Methods for details). By performing 
hundreds of these trials for dif f erent values of pinf, we reproduced the results of Ref. [45] in 
Figure 3. We see that as the number of informed individuals increases, collective accuracy 
increases.However, this performance gain depends on the agents��� beliefs about sensory 
precision, which we now dissociate into two components: ��z-Social( the precision assigned 
to the social distance observations) and ��z-Target(the precision assigned to target distance 
observations). By varying these two precisions independently, which respectively scale ��social 
and ��targetin (14), we can investigate the dependence of collective accuracy on the beliefs of 
individual agents about the uncertainty attributed to dif f erent sources of information. 
Figure 3A shows the average collective accuracy as a function of pinf, for dif f erent levels 
of the social distance precision ��zSocial. The pattern that emerges is that the social preci- 
sion, that optimizes collective decision-making, sits within a bounded range. The general 
ef f ect of social precision is to essentially balance the amplif i cation of target-relevant infor- 
mation throughout the school, with the need for the group to maintain cohesion. When 
social precision is too high, agents over-attend to social information and are not sensitive 
to the information provided by informed individuals; when it is too low, the group is likely 
to fragment and will not accurately share target-relevant information; meaning only the in- 
formed individuals will successfully reach the target. Figure 3B shows that a similar optimal 
precision-balance exists for ��zTarget. Here, we show average collective accuracy (averaged 
across values of pinfas a function of social- and target-precision.Maximizing collective 
accuracy appears to rely on agents balancing the sensory precision they assign to dif f erent 
15 
sources of information; under the active inference model proposed here, this balancing act 
can be exactly formulated in terms of the variances (inverse precisions) af f orded to dif f erent 
types of sensory cues. 
Online plasticity through parameter learning 
The ability of groups to tune their response to changing environmental contexts, such as 
rapid perturbations or informational changes, is a key feature of natural collective behavior 
[43, 49]. However, many self-propelled particle models lack a generic way to incorporate this 
behavioral sensitivity [45] and exhibit damped, ���averaging���-like responses to external inputs 
[50]. This results from classical models usually equipping individuals with i xed interaction 
rules and constant weights for integrating dif f erent information sources. While online weight- 
updating rules and evolutionary algorithms have been used to adaptively tune single-agent 
parameters in some cases [45, 48, 51], these approaches are often not theoretically principled 
(with some exceptions [52, 53]) and driven by specif i c use-cases. 
Active inference of f ers an account of tune-able sensitivity, using the same principle used 
to derive action and belief-updating in previous sections: minimizing surprise. In practice, 
this sensitivity emerges when we allow agents to update their generative models in real- 
time. Updating generative model parameters over time is often referred to as "learning" 
in the active inference literature [54], since it invokes the notion of updating beliefs about 
parameters rather than states, where parameters and states distinguish themselves by the 
fast and slow timescales of updating, respectively. We leverage this idea to allow agents to 
adapt their generative models and thus adapt their behavioral rules, referring to this process 
as plasticity, in-line with the notion of short-term plasticity in neural circuits [55]. To enable 
agents to update generative model parameters, we can simply augment the coupled gradient 
descent in (9) with an additional dynamical equation, this time by minimizing free energy 
with respect to model parameters, which we subsume into a set ��: 
�� �� = ��������F(�� 
��, �� y,��)(15) 
The generative model parameters �� represent the statistical contingencies or regularities 
agents believes govern their sensory world; this includes the various precisions associated 
with sensory and process noises �� 
��z,������and the parameters of the dynamics and observation 
models, �� 
f, �� g. Since the free energy is a smooth function of all the generative model parame- 
ters, in theory learning can be done with respect to any parameter using procedure entailed 
by (15).
1 / 1
ChatGPT
ChatGPT
This continuation of the text delves into how active inference agents in a group can collectively navigate to a target and explores how the group can tune its behavior to adapt to different contexts. Below are the key insights from this passage:
Simulation of Active Inference Agents
: A simulation was carried out using a proportion of informed agents, and they observed a target distance variable. By doing this, they were able to reproduce previous results that showed increased collective accuracy with a higher number of informed individuals.
Precision of Sensory Beliefs
: Two types of precision are considered - ��z-Social (precision for social distance) and ��z-Target (precision for target distance). These precisions scale the weights for social and target vectors in the model. By varying them, the researchers investigated how collective accuracy depended on individual beliefs about uncertainty in different information sources.
Balance of Social Precision
: An optimal range of social precision exists that balances the amplification of target information with the need for group cohesion. Too much social precision leads to over-attention to social cues, while too little can cause fragmentation.
Optimal Precision for Target Information
: A similar balance is needed for target precision. Maximizing accuracy relies on agents balancing sensory precision for different cues, and this can be precisely formulated in the active inference model.
Online Plasticity through Parameter Learning
: The active inference framework allows for adaptable sensitivity, which is critical for natural collective behavior. Unlike traditional models with fixed interaction rules, active inference enables real-time updating of generative models, referred to as "learning." This adaptive approach aligns with short-term plasticity in neural circuits.
Updating Generative Model Parameters
: Agents are enabled to update their generative models using a coupled gradient descent with an additional dynamic equation. These generative model parameters represent the statistical rules that agents believe govern their world, and in theory, learning can be applied to any parameter.
In summary, this text delves into the complex dynamics of collective decision-making, revealing how active inference can capture the interplay between individual and group-level behaviors. It highlights the importance of precision balancing, adaptability, and the potential for real-time learning, providing a rich understanding of collective navigation and the plasticity inherent in group dynamics. It's an example of a sophisticated model that attempts to bridge the gap between the often simple rules found in classical models and the more complex behaviors observed in nature.
1 / 1
In practice, combining parameter-learning with active inference usually implies a separa- 
tion of timescales, whereby learning or plasticity occurs concurrently to state inference and 
action but at a slower update rate. In all the results shown here, agents update parameters 
an order of magnitude more slowly than they update beliefs or actions. To furnish a inter- 
pretable example of plasticity, in the simulations described here, we enabled agents to update 
their beliefs about the sensory smoothness parameter ��z. We chose sensory smoothness due 
16 
y2 y3 
y4 
y1 
��1 
��2 
��3 
��4 
Stimulated 
agent 
Pseudo-motion 
stimulus Stimulus-evoked neural activity 
y1y2y3y4 y2 y3 
y4 
y1 ��1 
��2 
��3 
��4 
Stimulated 
agent 
Pseudo-motion 
stimulus Stimulus-evoked 
neural activity 
y1y2y3y4 
`` 
AB 
C 
Stimulus 
time 
+1 
-1 
0 
Figure 4: A: Schematic of the sensory perturbation protocol. The ���pseudo-motion��� stim- 
ulus consists of repetitively perturbing the agent���s sensory sectors with a moving wave of 
prediction errors in the agent���s velocity-observation modality y��� h. The top panel shows stim- 
ulus pattern as a heatmap over (amplitude over time) with two repetitions, starting from 
negative (red, sectors 1 and 2) and transitioning to positive (blue, sectors 3 and 4) prediction 
errors. The sign-switch in the stimulus (from negative to positive) mimics a moving object 
that i rst moves towards focal individual and then moves away. The temporal order of the 
stimulus across the sectors can be used to selectively emulate a right-moving vs. left-moving 
object, relative to the focal individual���s heading-direction. The bottom panel shows how the 
stimulated agent���s beliefs about the distance hidden state �� changes over the course of the 
motion stimulus. B: Response magnitude to a perturbation in presence or absence of pa- 
rameter learning. Left panel: example pair of 2-D trajectories of active inference agents with 
matched pre-perturbation histories, in response to an individual perturbation. The ability to 
perform parameter-learning is left on in one stochastic realization (green) and turned of f in 
the other (blue), following the perturbation. Right panel: initialization-averaged collective 
responses (group turning angle) to perturbation of active inference agents when learning is 
enabled or disabled. The perturbation response of a 2-zone self-propelled particle model 
(purple line) based on [45] is also shown for reference. C: Collective response as a function 
of the number of perturbed individuals, comparing simulations where parameter-learning 
is enabled to those where it���s disabled. Shown is the mean response with highest density 
regions (HDRs) of integrated turning magnitude (left) and response probability (right) com- 
puted from Ni= 200 independent initializations of each condition. For each initialization, 
the average metric is computed across Nr= 50 independent realizations that were run for- 
ward from the same point in time, following a sensory prediction error perturbation (to a 
randomly-chosen set of perturbed agents). Response probability is computed as the propor- 
tion of independent realizations, per initialization, where the group turning rate exceeded �� 
radians within the i rst 10 seconds of the perturbation. 
17 
to its straightforward relationship to the magnitude of sensory prediction errors (c.f. the 
relation in (12) and Appendix C). As agents tune ��zto minimize free energy, belief updating 
and action will at the same time become quadratically more or less responsive to sensory information. One example of where behavioral plasticity is crucial for collective information processing 
is a group���s ability to rapidly amplify behaviorally-relevant information, e.g., detecting the 
presence of a predator [43, 56, 57]. To study the ef f ect of behavioral plasticity on collec- 
tive responsiveness, we perturbed single agents in groups of active inference agents while 
enabling or disabling online plasticity. We perturbed groups by inducing transient ���phan- 
tom��� prediction errors in random subsets of agents and measuring the resulting turning 
response of the group (see Materials and Methods for details). These prediction errors were 
structured (see Figure 4A) to mimic a transient visual stimulus, e.g., a loom stimulus or 
approaching predator [58], which reliably induces a sustained turning response in the chosen 
individual [50]. Figure 4 shows the ef f ect of enabling plasticity on the size and sensitivity of 
collective responses to these perturbations. Not only do plasticity-enabled groups respond 
more strongly to perturbations of single-agents, compared to their plasticity-disabled coun- 
terparts (4B), but the magnitude of the collective response is also more sensitive to the size 
of the perturbation (4C). As has been measured in biological collectives [59], the plasticity- 
enabled groups collectively encode the size of perturbations with higher dynamic range than 
plasticity-disabled controls. This can be interpreted as an enhanced ability to collectively 
discriminate between inputs of dif f erent magnitude 
By updating generative models over time, the active inference framework provides a 
l exible and theoretically-principled approach to modeling adaptive, collective behavior with 
tuneable sensitivity, that eschews ad-hoc update rules or expensive simulations driven by 
evolutionary algorithms. Recall that the plasticity mechanism proposed here is not limited 
to updating beliefs about sensory smoothness: it can be extended to update beliefs about 
any model parameter in a similar manner. The ability to adapt generative model parameters, 
and hence individual-level behavioral rules, in real-time represents a promising avenue for 
future research in active inference and collective behavior, and may lead to more biologically- 
plausible hypotheses about the mechanisms underlying collective behavior in the natural 
world. 
Discussion 
In this work, we proposed active inference as a l exible, cognitively-inspired model class that 
can both be used in the theoretical study of collective motion, and in an empirical setting as 
an individual-level model of collective animal behaviors. By framing behavior as the conse- 
quence of prediction-error minimization ��� with respect to an individual���s world model ��� we 
of f er examples of how naturalistic collective motion emerges in, where individual behavior is 
driven by the imperative to minimize the surprisal associated with sensory signals. Under 
mild distributional assumptions, this surprise is scored by an interpretable proxy; namely, 
prediction error. In the particular case of collective motion, we equipped a group of active in- 
18 
ference agents with a simple generative model of local social information, operationalized as 
the average distance-to-neighbors and its rates-of-change. Using this individual-level model, 
we recovered and generalized the social forces that have been the core mechanism in classical 
SPP models of collective motion. The active inference framework also provides a probabilis- 
tic interpretation of ad-hoc ���weight��� parameters that are often used in these models, in terms 
of the precisions that agents associate to dif f erent types of sensory information. 
We have also shown how the active inference framework can be used to characterize 
the relationship between generative model parameters and emergent information-processing 
capacities, as measured by collective information transfer and responsiveness to external 
perturbations. Active inference���s generality allows us to relax the typically-static behavioral 
rules of SPP models, by enabling agents to l exibly tune their sensitivity to prediction errors. 
This is achieved via principled processes like parameter learning (i.e., ���plasticity���), and can 
be used to model naturalistic features of collective behavior, such as the tendency to amplify 
salient (i.e., precise) information, that have largely evaded modelling in the SPP paradigm, 
except in cases where adaptation rules are explicitly introduced [45, 48]. However, when 
we simply allow agents to update parameters, in addition to beliefs and agents, using the 
principle of surprise-minimization, many hallmarks of these naturalistic behaviors can be easily obtained.
1 / 1
ChatGPT
ChatGPT
The text you provided presents an in-depth look at a specific modeling approach for simulating collective behavior among a group of agents. This approach is based on active inference, a framework grounded in the principle of minimizing surprise or prediction error.
Here's a summary of the key points:
Modeling Collective Behavior
: Using active inference, the model represents groups of agents where some are "informed" about a target. The dynamics of the collective are integrated over time, and the accuracy of navigation to the target is measured.
Effect of Precision
: The performance depends on beliefs about sensory precision, with two components: social distance observations and target distance observations. The optimal balance of these precisions results in better collective accuracy.
Online Plasticity and Parameter Learning
: The model allows agents to adapt to changing contexts and incorporates behavioral sensitivity. Agents can update their generative models in real-time, referred to as "learning" or "plasticity," which includes various precisions and parameters of dynamics and observation models.
Incorporating Behavioral Plasticity
: The text discusses the effect of plasticity on collective responsiveness to perturbations (e.g., mimicking an approaching predator). Enabling plasticity enhances the collective's ability to respond more strongly and discriminately to varying stimuli.
Towards More Realistic Models
: By updating generative models, the active inference framework offers a flexible and theoretically-sound method for modeling adaptive collective behavior. This approach has the potential to lead to more biologically plausible hypotheses regarding the mechanisms of collective behavior in nature.
Comparison with Traditional Models
: Active inference is presented as an alternative to traditional self-propelled particle (SPP) models, overcoming some limitations by providing probabilistic interpretations and allowing for dynamic adjustment of behavioral rules.
Potential Applications
: The principles of surprise-minimization in the model can lead to naturalistic behaviors in collective motion, making it a valuable tool for studying animal behaviors and potentially other complex systems where collective decision-making plays a role.
This research contributes to the understanding of how individual-level behavior can give rise to collective phenomena. By focusing on the interaction between individual beliefs, precision balancing, and online plasticity, it offers a rich and flexible framework for modeling and exploring complex collective dynamics.
1 / 1
By providing a l exible modeling approach that casts perception, action, and learning as 
manifestations of the single drive to minimize surprise, we have highlighted active inference as 
a novel toolbox for studying collective behavior in natural systems. Future work in this area 
could explore how the framework can be used to investigate other forms of collective behavior 
(not just collective motion), like multi-choice decision-making and social communication [60]. 
The results shown in the current work serve primarily as a proof of concept: we started 
by writing down a specif i c, hypothetical active inference model of agents engaged in group 
movement, and then generated naturalistic behaviors by integrating the resulting equations of 
motion for this particular model. Taking inspiration from i elds like computational psychiatry 
[61, 62], we emphasize the ability to move from simple forward modelling of behavior to 
data-driven model inversion, whereby one hopes to infers the values of parameters that 
best explain empirical data (of e.g. behavioral movement data). Both the selection of model 
structure and the i tting of model parameters can be performed through methods of Bayesian 
model inversion and system identif i cation methods like Bayesian model selection, averaging 
or reduction. 
Materials and Methods 
For all simulations, we randomly initialized the positions and (unit-magnitude) velocities of 
N particles, and integrated the equations of motion for active inference and generalized i l- 
tering using a forwards Euler-Maruyama scheme with an integration window of ���t = 0.01s. 
Group size N the length of the simulation T (in seconds) varied based on the experiment. 
At any timestep �� of a simulation, we integrate the active inference equations for percep- 
tion (f i ltering) and control (action) for one timestep each before using the updated ve- 
19 
locity to displacement the positions of all particles using the following discrete equation: 
r(�� +���t) = r(��)+���tv(��)+zawhere zais normally-distributed ���action noise��� with statistics 
za��� N(za;0,��2 a���t), where �� 
2 
a = 0.01 unless stated otherwise. Detailed background on gen- 
eralized i ltering, active inference, and derivations specif i c to the generative model we used 
for collective motion can be found in Appendix A. All other parameters used for simulations, 
unless stated otherwise, are listed in Table E.1 of Appendix E. The code (written in JAX 
and Julia) used to perform simulations can be found in the following open-source repository: 
https://github.com/conorheins/collective_motion_actinf. 
Collective information transfer experiments 
For each trial of collective target-navigation, we initialized a group of N = 30 agents with 
random positions and velocities (centered on the origin) and augmented the generative mod- 
els of a i xed proportion pinfof the total number of agents, where pinfranged from 0.05 
to 1.0, with an extra sensory modality and hidden state that represents the distance to the 
target with position vector T, where distance of the target was always 10 units from the 
origin. We measured collective accuracy as follows: we count a given trial as successful if the 
group is able to navigate to within 0.25 units of the target without losing cohesion within 
T = 15 seconds (the length of each trial). The accuracy for a given experimental condition 
was then computed as the proportion of successes observed in 500 total trials. 
Perturbation experiments 
For the perturbation experiments, we simulated Ni= 200 independent runs of N = 50 
agents, which we term independent initializations. Each initialization is distinguished by 
the agents��� random starting positions, velocities, and seeds used to sample trajectories of 
action and observation noise. For each initialization, we integrated the collective dynamics 
until a steady state dynamic was reached (the pre-perturbation period) We chose this to be 
T = 100 seconds, a point at which metrics like average polarization, angular momentum, and 
median nearest-neighbor distance were highly likely to have stopped changing and l uctuate 
around a stationary value. At the end of each initialization���s pre-perturbation period, we 
then split each initialization into two further sets of Nr= 50 parallel runs, each of which we 
deem a realization. Each realization is distinguished from the others based on the random 
seed used to A) generate the noises on the actions and noises for that realization; and B) 
select the candidate agent(s) for perturbation. Note that the splitting of seeds at the end of 
the pre-perturbation period means that each realization has an identical history up for its 
i rst 100 seconds. In the i rst set of Nr= 50 realizations, we enabled plasticity (parameter 
learning of ��z), and in the second set, we left it disabled. After enabling learning in one set of 
realizations, we included an additional ���burn-in��� period of 12 seconds of continued dynamics, 
to account for any transient group ef f ects introduced by enabling learning per se. After 
the burn-in period ended, we perturbed random subsets of agents in both learning-enabled 
and -disabled realizations (2%- 50% of the group, i.e., 1 to 25 agents). We added to the 
ongoing zeroth-order prediction errors �����zof the perturbed individuals, two sequential waves of negative (���1) to positive values (+1), each lasting 0.8s and moving from left to right, 
relative to the perturbed agent���s heading vector. We tracked the group turning angle, relative 
to its initial heading direction at the beginning of the perturbation for 20s to generate the 
plots in Figure 4B and C.
1 / 1
ChatGPT
ChatGPT
It seems like you've provided a detailed description of an approach that uses active inference for modeling collective behavior in natural systems, focusing on things like multi-choice decision-making and social communication. The text also outlines the methods and simulations used in this study, including the specific equations and parameters for movement and information transfer.
Do you have a specific question or need clarification on a particular aspect of this text?
1 / 1
A summary of the whole article
1 / 1
ChatGPT
ChatGPT
Certainly! The article outlines a study that uses active inference to examine collective behavior in natural systems. This method models perception, action, and learning as manifestations of minimizing surprise. Here's a summary of key elements:
Objective
: The primary goal is to present a flexible model for understanding collective behavior, not just in terms of motion but also in areas like decision-making and social communication. The results serve as proof of concept for the specific model applied to group movement.
Methods
: The study uses active inference equations and integrates them through the Euler-Maruyama scheme. Simulations involve random initializations of positions and velocities of particles, with specific parameters for integration and noise.
Collective Information Transfer Experiments
: In these trials, agents are initialized with random positions and velocities, and the generative models are augmented with extra sensory modalities. Success is measured by the group's ability to navigate to a specific target, with accuracy computed from multiple trials.
Perturbation Experiments
: This part involves independent runs with agents having random starting positions, velocities, and noise. After reaching a steady state, realizations are created with various perturbations to study specific effects.
Code Availability
: The code used for simulations, written in JAX and Julia, is openly available at the provided GitHub repository.
Future Work
: The article hints at the potential of extending this framework to explore other forms of collective behavior and the integration with other fields like computational psychiatry.
In summary, the article offers a comprehensive look at using active inference to model and understand collective behavior, including movement, decision-making, and social communication, with extensive details on the methods and experiments used to validate the approach.
1 / 1
Connections with perceptual control theory, active inference, and free energy minimization.
1 / 1
ChatGPT
ChatGPT
Certainly! Perceptual Control Theory (PCT), Active Inference, and Free Energy Minimization are interconnected concepts in understanding cognitive processes and behavior. Here's a brief connection among them:
Perceptual Control Theory (PCT)
:
Definition
: PCT posits that behavior is the control of perception rather than reactions to stimuli. It emphasizes that organisms act to keep their perceptions of the world consistent with their expectations or reference values.
Connection to Active Inference
: Active inference extends ideas from PCT by emphasizing that organisms not only act to minimize the error between perceived and desired states but also engage in a predictive model that includes minimizing surprise or uncertainty about future states.
Active Inference
:
Definition
: Active inference is a framework that unites perception, action, and learning within a single principle: minimizing surprise or, equivalently, maximizing model evidence.
Connection to Free Energy Minimization
: Active inference employs the Free Energy Principle (FEP) to achieve its goal. The FEP is a way of explaining how self-organizing systems maintain themselves in the face of a changing environment. Active inference thus aims to minimize free energy, which is mathematically equivalent to minimizing surprise.
Free Energy Minimization
:
Definition
: In the context of cognitive science, free energy minimization is the idea that the brain maintains itself and its perceptions of the world by minimizing a free energy bound on surprise.
Connection to PCT
: While not directly correlated, free energy minimization can be seen as a mathematical expression of some of the concepts in PCT. Both involve minimizing discrepancies between expected and actual sensory inputs, though the free energy framework extends this with a statistical and thermodynamic perspective.
In summary, these three concepts are linked in their focus on the minimization of discrepancies between expected and perceived states. PCT lays the groundwork by emphasizing the control of perception. Active inference builds on this by incorporating predictive modeling and surprise minimization, and the Free Energy Principle provides a unifying mathematical framework that relates to the concepts of surprise and uncertainty minimization. Together, they form an interconnected network of ideas to explain how cognitive systems perceive, act, and learn.
1 / 1
A list of all of the topics we've discussed.
1 / 1
ChatGPT
ChatGPT
Certainly! Here's a list of the topics we have discussed:
Active Inference
Perceptual Control Theory (PCT)
Free Energy Minimization
Collective Behavior in Natural Systems
Multi-choice Decision-making
Social Communication
Computational Psychiatry
Bayesian Model Inversion and System Identification
Forward Modeling of Behavior
Simulations and Methods in Studying Collective Motion
Collective Information Transfer Experiments
Perturbation Experiments
These topics collectively cover a complex network of ideas related to cognition, behavior, statistical modeling, and experimental design.
1 / 1
A glossary of difficult terms.
1 / 1
ChatGPT
ChatGPT
Certainly! Here's a glossary of some potentially difficult terms from the topics discussed:
Active Inference
: A framework that treats perception, action, and learning as processes that minimize surprise, aligning with a predictive model of the environment.
Perceptual Control Theory (PCT)
: A theory that explains behavior as a control of perception rather than stimuli, aiming to maintain essential variables within desired bounds.
Free Energy Minimization
: A principle where the brain tries to minimize discrepancies between predicted and actual sensory inputs, called free energy, leading to improved perception and learning.
Bayesian Model Inversion
: A statistical method to infer the hidden parameters of a model based on observed data, incorporating prior knowledge.
Bayesian Model Selection
: A method of model comparison based on the probability that a model is true, given observed data.
Generalized Filtering
: An advanced statistical filtering technique used to estimate hidden states in dynamical systems.
Euler-Maruyama Scheme
: A numerical method for solving stochastic differential equations.
Computational Psychiatry
: An interdisciplinary field using mathematical models and simulations to understand psychiatric disorders.
Multi-choice Decision-making
: A scenario where individuals or systems must choose between multiple options, often studied using game theory or decision theory.
Perturbation Experiments
: Experiments where a system is intentionally disturbed or perturbed to study its response or stability.
Collective Motion
: Movement that emerges from the local interactions of individuals within a group, often studied in flocks, schools, or herds.
���� (Variance)
: A statistical measure of the dispersion or spread in a set of values.
Angular Momentum
: A measure of the rotational motion of a system.
Zeroth-order Prediction Errors
: Errors in predicting basic or primary characteristics, such as location or magnitude, in a system.
Plasticity (Neural or System)
: The ability of the nervous system or any system to change its connections and behavior in response to new information or stimuli.
These terms represent a blend of concepts from neuroscience, psychology, mathematics, and physics, applied in the context of collective behavior and modeling.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT July 20 Version
ChatGPT



