Welcome to the Future of Life Institute podcast. My name is Gus Docker and I'm here with Susie
Sheppard. Susie, you're welcome to the podcast.
Thanks for having me.
You are the winner of the grand prize in our superintelligence imagined contest. And this prize
was for a short film called Riding Doom. Maybe you tell us a bit about yourself and your film.
Yeah, so I make films. I'm mostly a video editor freelance and been doing that for a while now.
I mostly do kind of factual documentary-ish stuff most of the time. I did some fiction stuff
a while back during uni and kind of haven't doubled since, but have been kind of wanting
to get back into it. Riding Doom is set in a TV show writer's room. Yeah, like writer's rooms,
people like hash out the stories, like the overarching stories of the season of a TV show.
And so the idea is that they're writing kind of a speculative fiction from the idea is the show
is set in 20 years time. So one of the execs is like, okay, what else is going to happen in the
next 20 years? Oh, this weird thing, ASI, maybe that's going to happen. Let's make that the bad
guy seems great. So these writers get tasked with job of making artificial superintelligence the
bad guy for the next season of their show. And they have to just hash out how that would work
and what that would mean. And just by complete coincidence, they've just been joined by a
machine learning PhD guy who is definitely not based on Newt Kowsky or anything like that.
Even though he does write fan fiction technically. But that's just a way to get him in and to get
him like, you know, in conflict with the character with the other characters from the off. And also
because we just obviously just like need a voice of like, knowing the field and stuff. So yeah,
that's the best idea. And they like sit around and talk about how would this work? And what would
this mean for the ASI to be the kind of the bad guy? And like, yeah, like that kind of springs
a bunch of like discussion and stuff. But they're always trying to get back to like, oh, what are
our heroes doing? And like, how does this work as a story? Yeah, and that is actually one of the
first funny moments in the film, where they're discussing whether an artificial superintelligence
would be a good villain. Is there something does this fit into kind of a normal narrative arc
where you have the heroes and you have the villains? And is this entertaining to look at?
So you end up having the whole film happen within this writer's room. What was that decision like?
And and how do you how do you think about keeping people's attention when you're not showing anything
very action oriented on screen? Yeah, it was, I knew I wouldn't be able to kind of
further together anything super complicated in the time that I had like between finding out about
the contestants. So when I came up with that idea, I was like, Oh, great, like, we can just do it and
like, you know, in one room and like have these characters, like the story within a story is always
kind of fun thing to play with. Like anyway, in terms of keeping it interesting, like there's
there is like an interesting film history of like, you know, films that are just people talking
about a table or like, I think I saw a film once, it was just like a guy in a car the whole time,
or like, actually a guy in a coffin one kind of time who'd been buried alive. You know,
there is this way of doing a story that is like, where you just kind of use the audience's minds
to like fill out, you know, the rest of the big showpieces or something, like, you don't have to
always like show them exactly what's going on or what you're talking about. Obviously, like,
we watched 12 angry men to prepare and like this, there's also maybe remind our audience was what
12 angry men is about.
Oh, gosh, 12 angry men is, it's like, it's like a set in a jury room. And there's one person
of the 12 who thinks that the accused is innocent and everyone else is completely convinced that
he's guilty. And yeah, it just kind of, it's just set in that one room as they discuss as they
figure out, like, you know, break down their kind of prejudices and why they came to certain
conclusions. And it just seems like an open shut case. And then, you know, it's not because
actually what's going on is so human, like everyone has come to that trial and has brought
all of their own baggage with them. So it's kind of breaking down everybody's baggage, which is
like, all stories ever do anyway.
I was also reminded of of margin call from 2011, which is a movie about the financial crisis that
happens not in not in one room, but almost, it's extremely kind of driven by dialogue and happens
almost entirely in one room, where they simply talking about events happening in the world.
And you're completely right that this is just engaging for people because people love to hear
other people talking, I think.
Yeah. And I think also, it's so much easier to get into any kind of story by, like, having a very,
like, narrow, like, like, like, seeing a very tiny piece of a bigger story and then using the
tiny piece to kind of like, flesh out, like the rest, like, like this video does is set in,
like, this tiny, like, window of two weeks, but it's about this 10 year old, right? And you're
going backwards and forwards, and you're kind of building out the story in a way that you,
like, feels much more grounded in by just picking like a tiny, tiny piece of it.
So yeah. And another film that I watched, rewatched was called Mass, which is a fantastic film,
which is just for people sat around a table, like, discussing like a really, really heavy topic.
But yeah, would would would highly recommend that one to people as well, because it's a
fantastic, like, yeah, it shows you how how fascinating interpersonal dynamics can be,
like, when they are when there is nothing else going on, it's just those interpersonal dynamics,
like, they can't they couldn't depend on the industry, anything else happening. And yeah,
it's wonderful. It's wonderful. So in the film, you handle a bunch of very complex topics, like
instrumental convergence, artificial superintelligence system. It's the main idea, of course,
agency in in artificial agents. Do you think these topics or these ideas are especially
difficult to convey? If you if you had to convey them kind of in a traditional film format,
it would end up looking like something like Transformers. And do you think do you think
having your short film be dialogue driven is a way to avoid that?
Yeah, I think there is this constant tension when you're talking about something like AI,
where it's like, it is like this, the first thing you think of is Terminator. And you always kind
of risk sounding a little bit crazy. Like, if you talk about the world ending, like, of course,
you're going to sound a little bit nuts, like, you know, having a big movie with a big set piece,
and it's kind of just like adding to that. And like, all of the things that have made me scared
about AI, and not like, watching any big show piece, it's always been like, smart people
getting so drawn into the arguments that they start to be like, wait a second, this is,
I can't see a way out of this problem. I can't see a way out of this, like,
situation. Like, if this is not, there's not an easy, like, logical kind of, like, oh,
this is the reason that we would be fine. Like, and that could be really chilling. It can be
really chilling when someone who's like, very smart and put together starts to kind of shiver a
little bit. It was trying to like replicate that. And also, you know, one of the things that has
made me the most worried, I think you'd cast you went on like a podcast a couple of years ago that
went around. And it was just like, it was really scary because he was scared, because he's very
smart. And like, that like, I think I actually pulled like a quote or two from that, from that
podcast as well, just like shamelessly ripped off random bits from here and there, from Ted Talks,
and from actually from, from the contest web page as well. But yeah, so it's kind of, I was just
like trying to put in front of other people what would be affecting for me. And I think another
element of that to kind of try to make it affecting for people is also to like, make sure that there's
someone in the room who like, at least kind of, they can relate to in some way. Like, I think a
lot of like slow budget films, they often lean on like student actors. And then you get like kind of,
you know, three to five people in a room who kind of are from the same kind of, you know,
background, the same age, you know, and that kind of thing. And I kind of like, I wanted to
make this room have like people of different ages and people coming from very different like
angles and perspectives and like, so that hopefully when people are like, wait, but this thing,
I can put that in the mouths of somebody at that table and it will feel like relatable to,
you know, that particular part of the audience or something.
And you also, if I'm correct here, you also use that to kind of generate some humor with
differences between generations and the kind of gentsy woman talking about being on a phone a
lot and then say the older guy being very skeptical and kind of trying to puncture some hype or what
he perceives as hype throughout the film. And that works very well, I think. So why use humor
that much? Because it's such a, maybe precisely because it's such a bleak topic. Is that the reason?
The humor is about like, you know, trying to make it relatable, trying to make these people not
seem like, oh, I'm like, I've gone to a lecture to sit down and like, absorb like, you know,
information about this thing so that I can do this other thing, like a random person that I talk to,
like, my mom, like, is not going to be like, engaging in that in a way of being like, please
inform me about like, you know, what could be going on in the world. Like, it's real people
talking to other real people that like, is more convincing than the thing else or like, it's more
makes people more open to these ideas. And they're kind of bringing up object objections
that will be in the minds of different parts of the target audience. How have you talked to your
kind of relatives and friends about about AI before and then you wrote to us that that some
of the motivation for making this short film comes from having conversations where maybe you feel
like you weren't really getting through to people on on the risk from AI. Yeah, I, I feel like I'm
a bit nuts when I talk to like, someone who like, doesn't live in Oxford, and like, has never like,
interacted with this stuff before, like, and actually, I really experienced this when I was
like, sending the script out to the actors, I almost wanted to like, put a caveat on the email
being like, I know this sounds a bit weird, I know, like, it's kind of, I think maybe like,
unreasonably shy about talking to people about it. And like, I think when I have tried, like,
people have been very like, Oh, okay, yeah, okay, sure. Like, what do you want for lunch? Like,
so yeah, I really wanted to make something that would be like rewarding for people to watch,
even if they came away, like with still as little interest in AI afterwards as they had before,
right? They've kind of gone on with some kind of story, they've like, you know, you know,
met these characters, they hopefully kind of like and that kind of thing. So it was kind of,
I think, I think the thing about like, any kind of factual content, even like documentary, which
is obviously very story based still is like, you sit down and you know that the thing that you're
supposed to take away from it is like, understanding information, I think fiction is like, can be a
bit more sneaky in that way, where like, you can just like, kind of integrate it in, but like,
in a way that's like, well, you know, actually, if this stuff doesn't matter to you, then you
still had like a nice time, or you've still kind of like, experienced a story, which is like,
fundamentally like, talk having conversation with the world or something.
Yeah. Or maybe you've learned something about human nature or human relationships that are
perhaps too dry or too complex to convey in nonfiction, by watching a film or reading a novel.
At least that's what I often find that you can convey something in fiction that's probably
difficult to convey in nonfiction, while keeping people's attention.
Yeah. And I think it's like, it's very tricky as well, because like, I'm very conscious that you
can make as good a film from a bad intellectual position as from a good intellectual position,
right? Often you can make better films from bad intellectual positions, like it would be way easier
to like, make a film about how like, the US government elicit people than it would to like,
make a film about like, how, you know, they're a mixture of complex personalities and like,
some people are selfish and some people are trying really hard. And you know what I mean,
it's like, just because the true explanation is complex, and therefore boring, or what's the
general kind of phenomena behind that? I guess my impression is that like, people want the world
to work in stories and have like, heroes and that kind of thing. And like, this is, I mean,
this is one of the things that the film talks about. But it makes me cautious of in general,
making any kind of fiction film that has like, a message, because it just feels like propaganda,
not because I don't believe the things I'm saying, or things that I'm trying to manipulate people,
but because I know that I could, I could make another film that was about like, how AI risk
is like, not important at all. And I know I could make that film. And so like, making this one
still feels a bit weird and a bit like, ethically dubious or something or not quite that much.
But you know, it's something that I kind of feel like, yeah, like fiction can convey ideas,
but we've got to be like really careful about like, what we then decide to use fiction for.
I mean, I think if you watch your short film, and then go to the arguments, there is actually
a bunch, we have a bunch of good arguments for AI risk being an important thing to think about.
And so I think there's some substance behind the fiction in this case.
Yeah, yeah, I just worry that like, because there is another version of this film that is
intellectually dishonest, it's kind of, you know what I mean? Like,
there's you always have to engage in fiction in a slightly like, a careful way or something. But
yeah, like, yeah, it's, it's of course, like very, very, this particular one is very backed up,
I hope. So sometimes you're, you're conveying a complex topic in one sentence, maybe even,
even kind of like a very short sentence. For example, when you, when you want to discuss
the idea that it's, it's difficult to predict how a, an agent that's smarter than you would
outsmart you or win over you in kind of any game of, of power seeking in the world, you discuss
it by talking about, well, if you sit in front of a chess engine, like stockfish, it's easy to
understand that you would lose, but it's not easy to understand why you would lose exactly.
Because if you could predict moves that it would make, you would kind of be able to win over it.
Those kinds of lines you have a, you have a bunch of in the film. How do you kind of make
sure to capture all of the complexity of, of an idea in one line?
I do it by stealing things that other people have said. That was directly from, I think,
a TED talk. Maybe you'd cast these TED talk. So yeah, I really can't claim credit for that. I
think somewhere in there, there is a like a really lovely line that like came straight from like a
comment on a forum somewhere that I've now lost track of and can't thank the person whose words
it was, but I can presume that people who are engaged enough to like come up with like, you know,
good statements about this stuff, like, wouldn't mind be borrowing their, their words. In general,
I learned really heavily on other people's understanding. I don't keep on top of all
developments in AI. I have like, you know, I have very much like a layman's understanding of it.
The reason I was able to write what I wrote was because I was having a lot of conversations with
friends who do spend all of their time in that world and, you know, are like very, very engaged in
it. And that was like, great. And also because like, you know, I read Superintelligence back in
like 2018. And then I was like, great, I understand AI now, great. And then I came to sit down to
write this. And I was like, had one of the characters be like, Oh, we can just turn it off.
And I was like, maybe we can just turn it off. And like, you know what I mean? I was just like,
I suddenly realized that I couldn't, I didn't have as good a grasp on all of the basics as I
thought I did. And I had just like hadn't engaged really deeply with it for quite a while, because
I had been around people who actually weren't talking about the basics, they were talking about
like, you know, the latest model that had just come out or whatever, and or had all the basics
kind of assumed. And then I was like, okay, well, actually, this is a great exercise for me to kind
of, you know, get back into a deep level of understanding, because every time I didn't
understand something, like when you were when you're like sat in like a electoral conversation,
you kind of think I think it's quite human to be like, not understand a thing, but just like
pretend that you do or like pretend to yourself that you do. But I was finding it's very easy to
like, put the thing that I don't understand into the mouths of one of the other characters and be
like, yeah, but surely that's just that sounds really contrived or like, that sounds really
silly. And I would do that and then be like, okay, what's the next line? And then be like,
great, I've got to go off and like read a bunch of stuff again. So yeah, it was it was a really fun
way of like reengaging with that stuff. And I think people talk about this in terms of like, you
know, blog posts and stuff like you really want to understand the topic or just read about it,
like write about it and like engage or teach it to people. So it was definitely much more up to
date with stuff by the end of writing the script.
It seems like such a valuable exercise to do to kind of try to explain it to yourself or explain
it well enough that you can convey it simply, because that's not not always easy to do. I mean,
it's often easier to give a 20 minute rambling explanation than to give a concise two minute
explanation. Yeah, and I think this is the other thing when I look back at being that fact that
I wasn't very good at talking to friends and family about this, I'm like, well, of course,
because I like couldn't remember the basic arguments, like, and they would have been like,
why do we just turn it off? And I'd have been like, well, I think it's like something like this
or but not like gone through this list of like, you know, or like gone into like, just turn or
like all the reasons why unplugability is a thing. It was a yeah, it was a really fun exercise. Like,
like, I feel like I've now done that exercise and I can like present this film to people and just
be like, here we go. Here's the conversation I should have been having with you the whole time,
but like, you know, in an entertaining way also, perhaps, and then not just kind of like in a
factual way where you're trying to almost kind of inform people, perhaps there's a resistance
and perhaps it's a healthy resistance to being kind of presented at a topic by another person
where that person is trying to inform you. Because, you know, a bunch of people are trying to tell
you a bunch of things all the time and you have to have some kind of filter. But with fiction,
it seems like it kind of disarms people a little bit and you can you can maybe it's an it's a
gateway to learning something. Yeah, and I also think we're like, you know, stories are a way of
like sharing information, but they're just a little bit more like encoded than, you know,
like very like literal stuff. But I feel like it's a much more like natural kind of
brain field to be kind of like told a story about, I don't know, a hero who does this and you kind of
learn something a bit more abstract about the world, maybe, but you're still kind of,
you're still kind of building your picture of what the world is and how the world will respond
to certain like actions and like, you know, what the shape of it is. And so I imagine that like
stories we use to kind of like convey information like much more in like human history than they are
now. But I think they can be like a really amazing tool.
What kind of feedback did you get? Did you did you send out the script or did you send out that
you screen the film or how did you how did you collect feedback? I like wrote the first draft
in a massive rush and then sent it to a friend who's, you know, an AI safety researcher and like
he went through it with a fine tooth comb and kind of picked out, you know, all these things I
needed to change but was generally like, yeah, thumbs up. And I made the terrible mistake of
being like, great, it's done. It's all accurate and perfect. And also, AI safety is a monolithic
field and everyone agrees about everything. And I got so busy with the casting and the
organizing and everything else that I then didn't kind of go to anybody else until about a week
before we were due to shoot. And I was kind of like, I should probably get someone at least
one of you know, just in case this first person has like missed anything. And they took a look
through it and they were like, I mean, this is great. It's great. But like, you know, I think
you've missed the main point. And I think with without this extra point, like everything you've
talked about is kind of interesting, but doesn't really worry me. And what was that point? Point
was like treacherous turn, which you might notice if you are paying a lot of attention is a little
bit more shoehorned into the script than the rest of the stuff like the exclamation about,
you know, like small child inherits billion dollar company, that whole analogy, which is
apparently the kind of typical analogy to go to when we're talking about kind of treacherous
turn stuff. That's one of like, the longer monologues, I think, which is kind of, you know,
earlier on, I put quite a lot of effort into kind of making sure that it wasn't, well, I mean,
it is still a little bit of a lecture from the machine learning guy, I've got to be honest. But
like, I was trying to as much as possible have him like, introduce an idea and then have everybody
else around the table play with the idea, like, extend the analogy, like, you know, like take
like, understand it quite quickly, and then start like making inferences of their own and then
like arguing about that and stuff like that. So it wasn't just like, you know, one person like
telling everybody else in the room, what's what. Yeah, so that was like a super useful to get like
another round of feedback just in time. But I think also that comes from a little bit like,
my first draft focus frame was very much kind of drawing on this kind of very classic review of
like the kind of, you know, 2014 super intelligence, like all of those kind of old ideas. And then
this other person was coming from a very much like modern headspace and like, you know, reacting to
like LMS and how we, you know, how we see the field has like shifted quite a lot. But like,
obviously, these two things are still integrated. And I think the first person who looked through
it was very much like, these are the foundational ideas, even if the kinds of things we talk about
now are a little bit different or something. So yeah, I think there is like a little bit of
smooching of those two kind of frameworks together. But like, you know, they are, you know,
they are the same field. But what I found really interesting as well with the second person who
looked through it was that, you know, he picked out a lot of things that the first person had said
were great. And it was like, not really sure. And one of the things that they picked out was
a line that I had explicitly copied and pasted from the super intelligence imagined contest
web page that was like, a summary of why FLI is worried about AI. And I was just like,
I mean, take it up with FLI, dude. What am I going to do? I'm going to leave it in there. Like,
they think this is like, it's just, it made it really, really clear to me that like, people
really just agree on this stuff, obviously, but like also just like the way of expressing things.
And, and there was also, you know, a certain amount of like, they were picking out things that
that were like, you know, technically inaccurate, but sounded much more like something that somebody
would actually say. And at some point, and they were suggesting like, you know, rewordings that
were a little bit more like scientifically accurate. And I'm like, Yeah, this is starting to sound like
a philosophy paper. And we don't, you know, we have to at some point just, you know, for the
character and often for the sake of the jokes, let people say something that is like, you know,
not really quite the thing, but also like, it would make sense for the character to
maybe say something along those lines, and they're getting the gist of the meaning, even if they're
not like, you know, starting to talk like a machine learning PhD kind of thing. So, you know,
just little details like, you know, chat, GPT wants to be helpful. Like, that was picked up and being
like, I don't not sure that's really a good way of describing it. And like, yeah, but it's not the
machine learning guy who's saying that. Although he thinks he does agree with us. You know what I
mean, there's always going to be this trade off between like, technical language, and like, you
know, conversational language. And I kind of leaned very hard into the conversational language, I
think. And there's like, yeah, there's that the sometimes the like, technical accuracy suffers
because of that. But I think it's kind of okay. I think that's a good choice. I mean, there is
this tension about precision, or accuracy on one on one side, and then kind of entertainment value,
or how quickly you can say something is often also, if you make things very complex to make them
very precise and accurate, it will take a while to say something. And that's you probably lose
people and you, you maybe you don't even get to convey the idea that you originally wanted to convey
because you simply just lose people in the process of explaining something. I think
imprecision can be a good tool, especially coming from sake, say coming from characters that are
not the machine learning expert, it works well, I think. What was the character that you thought
about including but ended up not including? Oh, man, I think I wanted, I just wanted like,
somebody from every, like decade of age, like right up from like, when I was first like conceiving
of the idea, I kind of had this idea of like, okay, well, there's going to be like the person who
knows a bunch about this, there's going to be the kind of the authority figure in the room who
is the main holdout. And then there has to be some other characters, like,
against whom like, these two main characters have their conflict, right, like kind of all of these
are like, I don't want to call them intermediate characters, because they're quite because they're
obviously like very central to like what's going on. But like, they, the three other characters
are the battleground on, on which like, the head writer and the machine learning guy are like,
having their back and forth, which allows like, the head writer character doesn't really have
a crazy, like he has much fewer lines than the rest of them. And like, you know, I mean, it's
kind of like, they don't have to be exactly at dagger heads all the time. When I was like trying
to think of what are these, you know, where to come from with the other characters, I was just
like, Oh, we should do like, the different generations, like one for Gen Z, one millennial,
one like, you know, kind of middle aged person, like maybe older than that. But also like, you
know, I would have loved to have like, you know, what's the, you know, the difference between like,
you know, how a millennial guy and a millennial girl, like interacts with these ideas is going
to be a bit different. And like, and also like their interests, like I have to lump together,
like, okay, it's like, it made sense to lump together, like Gen Z is interested in like
social justice stuff, sure. But then like, you've got like, what about the millennials who are
super into tech, you have to just like, throw as many bits in there for people to cling onto
as possible, that there's something in there for people. And I think, yeah, the other like
intention behind those three characters was how can I try and speak in the language of the audience?
Like, so like how like, what makes somebody who's really into social justice more able to
understand AI risk than someone who's not like, is there a particular part of AI risk they are
likely to get much quicker than somebody who's not into that. And then same again, with like,
you know, a sensible person who like, you know, is very kind of like, like very mature and grown
up and isn't into kind of like, you know, these crazy things, like, as different, you know,
differently to Gen Z, who's like, of course, the world's gonna end. And then someone who's like,
you know, like, and then you, you end up with this effect of like, you can rely on that character's
backstory to give them kind of a leg up in the understanding, right. So for the character who's
really into music, that is his framing on AI. And, you know, he's done a bunch of thinking in the
past about how music is kind of this like weird arbitrary thing that we love, but we like is not
straightforwardly like, good for our survival or something, or like, you know, there are kind of
ways that's connected to that. But like, fundamentally, art and music, you know, is kind of,
we value them for their own sake. And like, he's done a bunch of thinking about that in person,
he's like, see the little connection to AI, and then he suddenly jumps forward in his understanding,
and I was trying to find find that for all of the characters. And that makes a lot of sense to me,
like thinking about what people already know, and then building on that. Yeah, that's hard work that
requires a lot of empathy, I think it's not always obvious what people care about and what people
know about. Did you did you thought about including an elderly person or child? I'm not sure how this
would fit into a writer's room, but there are just there are many elderly people there, many
children, and they might have interesting perspectives or interesting comments, or
you know, I could see a child giving his or her perspective, and then kind of exposing that
perhaps the adults haven't fully thought through what they kind of confidently claim to believe,
something like that. Yeah, have you thought about including characters like that?
Well, I mean, never work with children and animals, right? We had a lot to make work about
this, and that would have been extraordinarily difficult. But like you say, it would have been
great. Next time when I have more money, hopefully to put into it, that would be a really interesting
perspective. And you could probably play with something there around the child inheriting
the billion dollar company. But also, they're not the audience I'm mostly trying to talk to,
right? It feels less important to get inside the mind of a child, although they're kind of
interesting perspectives they might have. And then, yeah, elderly, I guess, the head writer
character was a little bit older, but not like elderly. Although the head writer strikes me as
kind of a different archetype than what I was thinking about with the elderly person. The
head writer is kind of competent and knows about the world and is kind of not interested in new
ideas, or at least has some counterarguments for why things might continue to be as they've been
throughout his life. Whereas the elderly character could be more scared of change and perhaps kind
of overwhelmed by what's happening. But again, I have no idea how he would incorporate something
like that. But I think it would be interesting to have something to show to my grandfather,
for example, so that he could learn about these ideas. Yeah, for sure. And my grandfather is in
exactly this position of feeling very out of control and very scared about things that are
happening. And there's a really interesting angle in this where it's like he knows that he's never
going to get the answers. He's not going to find out whether we make it. You know what I mean?
And I think that's like such a, I don't know if you've seen the Francis Ford Coppola's latest
film. Yeah, I haven't seen it because the reviews weren't that great. But it's a crazy film. It's
completely, but I was like looking up to be at a talk with the director like a couple, like a week
before I saw it. And this is exactly what he was talking about. He was being like, you know,
he's 85. He's really scared about the way the world is going and how things are going to kind
of pan out. And he knows he has to accept that he's never going to know. And all he can do is like
try to talk to the people who are younger than him about trying to find some future to aim for,
right? And so you get kind of like, similar vibes from like the boy in the heron just like
Miyazaki's latest film where he's like, I can't find, you know, an air or I can't find some light.
And I'm really worried about how things are going. And like, you know, kids, it's up to you. It's up
to you now. I'm not going to like be here at the end of the story. And yeah, I find that like really
kind of fascinating and scary to like, yeah, be in that position, I guess.
Yeah, I think lack of kind of continuity in the future is something that that all the people
tend to care a lot about and thinking about whether what you've built in your family and perhaps in
businesses or culturally or something, whether that persists over time, whether there's a legacy
there, whether people are maybe remembering you in 50 years or something. And if the world is
changing so quickly, perhaps the world is under threat of extinction, well, then there's uncertainty
about whether any of that is going to happen. And that is something that worries my grandfather,
for example, and some of his friends. Yeah, so those those perspectives you could have included.
And I think, I think it's probably good you didn't because it would have made it too complex.
So last character idea maybe is having a skeptic who is also a machine learning expert.
Probably good. Do you think it would have made them the film too complex again, because you
could easily see if these two characters are discussing something, you could easily see
adventuring into just a complex discussion where the other characters are kind of left behind?
Although you could play with the interesting dynamic of that kind of both trying to get the
room around to their perspective and like, both kind of tempted to go and to like techno babble
to do that. And they end up actually just talking to each other at loggerheads. But then they're
kind of like remembering that they have to simplify in order to kind of get the people around them on
their side and stuff like that. But yeah, that like, I don't know, I think, I think, again, it's a kind
of like, it's like a space thing of like, you know, you can only put so many elements in the room
and and also kind of like a, I mean, I don't know what proportion of machine learning people
are scared about this. I get the impression it's quite a few, but like, maybe not majority.
It's difficult to get exact numbers here. And it's difficult to know exactly what it is that
people say yes to when they cross off on a questionnaire that they worry about extinction
risk from AI. But you do have a bunch of prestigious and kind of accomplished academics
and industry people worrying about this. Yeah, yeah. I think it would be very tempting to like,
you know, have a lot of counter arguments in there that like, I think, like, aren't strong enough
or something, just to kind of balance it out. And then for people to come around being like,
actually, I agreed with the other guy more, which is like, obviously, like, in some ways,
very intellectually honest. But I don't know, doesn't like, like, I think there's a lot of
voices being like, this is fine, everyone's making a big deal of nothing. And like, you know,
in order to like, explore the thing that I wanted to say, you kind of have to like, yeah,
choose an avenue and kind of, and like, actually, one of the things that came up in the feedback
as well was like, maybe you should like, nuance this a bit, like, you know, this guy is has to
doubt himself also. Yeah. And now we're talking about the machine learning expert, right? Because
he does kind of doubt himself. He's, he's somewhat depressed. And he's, he's talking about whether
he, you know, whether maybe this is all wrong, but I don't see how it could be wrong. And that's
kind of his headspace in the end, not at the very end, but towards the end. Yeah.
And yeah, I think there's like, there's a line where he's the kind of like, you know, the arguments
are kind of fuzzy. And like, this is something I was like, directly told to put in, because it's
just like, you know, like, we don't know what we're talking about. Like, this is kind of like
abstract and like, this is we don't know, and all this kind of stuff. So yeah, I think, I think
people who are scared of this are not like, this is 100% going to happen. And that like,
you know, the people who are saying like, it's 99% certain are the outliers. But like, you don't
have to be very worried about it to think that there should be way, way more like resources being
put into like, like looking into this just in case. I think people who are like, think that
there's like a 10% probability of this happening are some of the people who are like the most
engaged with like, you know, like AI safety stuff, because like, they're just like, those odds are
just like, not good. Like, considering what's at stake relative to like what we're doing and
relative to how bad it would be if it happened, like we are kind of way, way under arresting.
When you think of a movie like Terminator 2, I mean, it's 30 years old, but it's still something
that people reach for when they want to have something tangible in their minds to discuss AI
risk around. Do you think, do you think a short film like yours can help people get other ideas
in their minds or another starting point for, for discussing these ideas?
I think, I think one big problem is that people don't really watch short films. This is like,
this is like this kind of really weird thing that's going on in like the filmmaking scene,
where like, everyone in their mums is like trying to make a short film, and then they just like,
go onto YouTube and then they just, most of the time, they just disappear, right? Like,
this is, this is the thing. Oh, they go to festivals and they get a big stir at festivals,
but nobody like, people don't, like, I mean, when was the last time you were like, oh,
what's a great short film the other day? Like, you know what I mean? So I think that's just like
part of why it's so hard to use fiction and use film to like, talk about this stuff. And like,
you do have this handful of like, important stories that have like, changed, changed policy
and changed the world. Like, you've got like threads for nuclear stuff. And you, yeah. And,
and also just like, you know, even if you're creating a story that is kind of like exaggerating
something or making it slightly ridiculous, it's still, it is still creates the idea. Like,
I can imagine that, you know, people hadn't come across the even the concept of artificial intelligence
before watching Terminator back 30 years ago. So there's something to that. Although obviously,
you have to be like, kind of careful, you know, get stuck on this particular kind of
images and stuff. But, but yeah, it's kind of, I would, I would love there to be like, like a
feature version, or just like, I would love to have something like this in a form that is like,
something that people typically watch, whatever that means. And if that means like, you know,
a 30 second TikTok film, but that's not really gonna work. But I think, I think there's an
interesting kind of interesting phenomena happening where you have entertainment either being very
short or very long form. So either it's like a three hour podcast or a, say a 10 hour TV show,
or it's a 10 second kind of short clip. And I think for something like, I mean, your short film
could easily be expanded into something much longer, I think not easily, it would be hard work,
of course. But there's what I mean is that there's a lot, a lot of material to work with. And you
could have something like a almost like a courtroom drama, but around arguments, foreign
against AI risk, and fold that out into a TV show, or perhaps a feature film.
I mean, if anybody listening wants to fund that, I'm, I'm game. I'd love to adapt it. But I think,
yeah, I think you're right that there is this like, strange middle ground where like those,
and you know, it's a shame because like short films can be really powerful. You know, I've seen,
like, you know, like, I'm, I'm like at film school right now, and I'm seeing a lot of short films,
and I'm making a lot of short films, and they can like do things that long form and very,
very short form can't do. You know, I mean, like, you can, like, there was one that I saw
recently, that's just like, you know, you spend time with a couple, like an elderly couple,
and one of them has dementia, and like, you just like experience their story. And it's not a story
that's like, worth telling over an hour and a half. And it's not a story that you can tell in
like a minute. But it's this beautiful 20 minute piece that like, you know, made me just like,
cry buckets, you know, and it's like, these things are beautiful, but you just, we just don't have
like, I don't know, there's not like, an actual space for them to sit. So I think often what they
are doing in practice in the industry is they are proof of concept for, you know, turning that idea
into something else. So yeah, so is it you, it's the other thing about like, making short films,
you always come to kind of go in with that like, background knowledge, I think that's also partly
why I've made so few of them. Because I watched when I was like making films on the side of my
undergrad course, I watched a bunch of people make really interesting short films, and put them on
YouTube, and they get like 12 views. And it's like, you know, all of this ever. And like, you know,
people should make art, like, that's great. But like, I really need some kind of demand in order
to like, throw myself into something that hard. And it's so hard to make film is so, so hard,
like, like, trying to make it all come together, like, you know, the number of different elements
all have to like, cohere and like, is ridiculous. And like, yeah, the film I made before, I just
knew there would be like a huge fan base for and huge demand for. And then this one, I'm like,
okay, well, someone's going to like, someone's got a contest, they want they want this, like,
and I'm like willing to put my own money into it, because I, you know, I, I'm willing to like,
gamble on myself. And like, you know, there are these prizes available and stuff. So it's kind of,
yeah, it's this is like, making short fiction films is like, really weird. And it can be like,
really demoralizing to like, you know, given that there's not like a natural like feedback
loop. And so yeah, that's kind of a difficulty.
It's simply because people don't want to go to the movie theater or rent for their TVA is something
that's only 20 minutes long or something. Is it, is it, is it something as simple as that? Or is
there something? Is there kind of a deeper explanation there?
I think I've heard something like that might be complete nonsense. There's like, you know,
like a sleep cycle is like an hour and a half. And this is like a natural kind of like stopping
point for films. And you kind of go on this like, you know, it's like a natural like length of time
for our brains to kind of like, you know, do a full like cycle of something might be complete
nonsense. Don't quote me on that. But yeah, and, and yeah, but honestly, I don't know, I feel like
my guess would have been that there would be just this like spectrum of like, you know, we watch
short films and we watch media and that things will be watched on films. And it's just like not
how it pans out. And I think you can get all of these like weird artifacts in the way that people
behave based on like particular histories of particular mediums and stuff. Again, to go back
to classics, sorry. Like one of the most interesting things about like the other in the Odyssey is
they are just so much, they are like orders of magnitude longer than any other stories that we
even have record of, like not even that we have, but that we that we know existed. Like we know
that there were some that were like 1000 lines long. And then you like, you wonder like what was
going on when people were going around these like festivals and presumably hearing bards like tell
stories. And you've got the one barred over here who's telling like 10 minute story and another
barred over there is telling like a 14 hour story. And you're like, what like, how does that change
how people are behaving? How does that change? You know, is there also a person who's telling an
hour and a half story? Like, are they trying to make sure that like, if somebody walks in halfway
through that they still kind of get it? Or are they not like, you know what I mean? It's kind of,
I can imagine like the whole like, you know, two hours for a film and then like 10 seconds for
TikTok is is is just like this kind of slightly arbitrary thing that we've got because the two
places that we consume media are like, go out to the cinema and do this big thing and like scroll
on your phone for like, you know, five minutes or anything. But then there's like, I don't know,
there's like video essays that have converged on like 12 minutes. There's like a really, really
good amount of time. So who knows, it's a mystery. We just have to keep rolling with it and see what
we can do. Yeah, it's interesting to what extent it's kind of a natural versus a cultural phenomenon.
Because if I mean, what is the Odyssey? Is it 14 hours long? I think Ian McKellen's audio book
of the Odyssey is something like that 14 hours long. We should look it up. Yeah, that's a real
investment to get into. And especially if we're imagining people kind of whatever 1000 years
ago listening to it and a person kind of speaking it out loud. One guess is that this is just drawing
from personal experience. Whenever I've gone YouTube and I find some some very good short
films, I can I can watch say five of them in the span of a normal movie. And afterwards I feel
almost kind of oversaturated or kind of I have too many ideas because I can't really remember
what happened in the first one when I get to the last one. And there's something nicer about having
this kind of hour and a half storyline. And you feel like you can you can kind of get into that
and and stay on one topic for a little bit longer. So I've heard people talk about like,
like factual books as being much less about having a book's worth of information to convey
and much more about like having one central idea and just needing to come at it from 20 directions
because there are 20 different types of brain that will come at it from 20 different directions.
And like you just need time to like, gradually absorb that idea and all of the ways that it kind
of seeps into the world. Yeah, maybe you need to repeat that yet for for for it to get stuck in
people's minds. Or maybe it's more cynical and publishers need a certain length for it to become
a real book or something like that. Maybe maybe there's this thing about like, you know, when
people write news articles, there's like the format of news articles is like, say the whole
story in one sentence, then say the whole story in two sentences, then do it in a paragraph,
then you know what I mean? It's like, you're not just like starting a linear like kind of exploration
that's at the depth that whoever's writing it has decided is the right one, like you are having
this thing where like, you know, you can, in theory, tune out any point in news article and have
got on the basic ideas. How did you approach that for your own film for writing Doom? Like
because I am I'm imagining you want people to kind of get what's what's happening very quickly so
that they have some some kind of knowledge that they then take with them for the rest of the film.
Yeah, I guess this is like mostly done just in terms of like the the characters. So like,
you need to know very early on that like, the machine learning guy is like,
kind of scared and that the like, head writer is kind of skeptical, very skeptical. Yeah. And
you just like, I think that there's like a line where they kind of interrupt each other and it's
like, yeah, this doesn't work as a bad guy is, it's like, too easy to defeat. No, it's impossible
to defeat. Yeah. Yeah, that was funny. Yeah, this is I guess, this is like, the main gist of the
thing is like, Oh, you are currently in the, you know, probably as a viewer, you're probably in
the camp of that would be super easy to defeat, we would just turn it off. And oh, there's this
thing, there's this other person coming in who's like, in this other camp, and this is how far
in the other direction it goes. There are some people who think we have no way out, this is just
happening. I guess the rest of the thing is just kind of breaking that down and kind of like playing
with that, but also given that the kind of point is more to kind of make people aware that there
are these arguments as opposed to like, you know, necessarily like, getting them to absorb all the
arguments, like, yeah, that line is, is just like setting the stage. I have to ask you this,
did you use AI generated kind of assets in the film? I think the poster for the TV show,
the writing was seen a little bit AI generated to me. Oh, yeah, it was totally yeah. AI and Canva,
unfortunately, because I was doing all the production design myself on top of everything else.
So it wasn't there. And what else? Oh, there's like one line where I like typed into like,
Claude, like, okay, what would a Gen Z person say to be like, yeah, you go girl, but like in one,
like one word, and it was like a sleigh. And like, great. And then I like sat down with Mimi,
who was like, plays that character. And she was just like, Oh, my God, I read this line. I was
like, that is exactly what I would say. That's exactly what I would say. And I'm like, great.
But I think that was maybe the only like, you know, I think that was the only time
although actually, I think maybe I also had a some, I don't even notice now how often I like,
Oh, there's a thing that I like don't quite understand. I'll just go like chat to Claude
or chat about it. Like, you know what I mean, it's so integrated now into like, Oh, this is a
fantastic way to learn really fast, like roughly what's going on in this like field and what's
kind of, you know, and obviously, like, it's a bit risky because there are, you know, but like,
being able to just like, ask exactly the question of the thing I'm not quite getting,
and then be introduced to like, you know, off the cuff to like, Oh, and here's another thing
you could probably be thinking about, like, like, these tools are amazing. Like,
much, much more useful than going to Google and then getting some article that's been optimized
for kind of SEO reasons. And it's, it's difficult to find exactly the piece of information you're
looking at. If the stakes are high, you have to check what the information you're getting. But
it is just a useful tool to have. Do you think you'll use AI more in your production process
going forward? Something that's really, really changed video editing. Certainly for me, in the
last couple of years, it's all just like all of the AI transcription stuff, like I now can't edit
without having like subtitles on like every interview that I edit. And then I find need to
find a thing I could just read the thing. And like, this is so obvious, but I used to spend so long
kind of going back through old interviews being like, I know somewhere they said this really
cool thing. And like, you know, and then like, making sure to like, you know, label it all
as well as I could. And then, but yeah, so it's, I mean, when that came into like, as an auto
feature in Premiere, I think I sped up by like 25% or something on all of my edits, which is kind
of crazy. So yeah, so there's like, there's like, yeah, I think it's like, seeping into various
filmmaking-y things. What about kind of the creative process? What about generating, say,
a monster in a film or generating some sci-fi creature? How far do you think AI is or how
close is it to kind of generating the imagery you're seeing? As far as I can tell, it doesn't
write very good stories yet. There's one view on this where like, I was listening to a podcast
where some like screenwriters, very like old established screenwriters who've very excellent
at their job, were talking about AI and AI tools and AI like generated content and all this kind
of stuff. And they were like extremely skeptical. They were just like, haha, look at this like
story that it's written, it's like bad in these particular ways or like, look at this dialogue
scene that is written like, you know, that doesn't quite sound like a human. And my first reaction
was like, oh my God, like, it's gotten to the stage of being able to write a bad script,
like from zero, like that you're like seeing this like tiny little margin between like,
you know, like, you know, subpar script and professional script and like,
there being no script, right? I mean, you have to notice the rate of improvement,
not just kind of the absolute performance, because I mean, a cup just in 2020 or in 2018,
you couldn't get anything coherent out of large language models. And now you can
basically have a conversation with them.
Yeah. And I don't think anybody has predicted that right. I think even the most like,
like optimistic people have been like, out by a way in terms of like how fast how much progress
we would make and how much time I will say, Guern, the kind of anonymous essay writer has
that has a great great post called the scaling hypothesis, where he's very early on predicting
some of these things. But yeah, I agree that there are no very obvious of experts predictions
that this is the way things would go.
Yeah, I think there's also the other side of that thing as well, where like,
it might be just like way easier to make progress from zero to bad script than it is to make progress
from bad scripts to good script, like there might just be there's something inherent in that,
that like space or something that's like much more work than anything else.
Kind of like it's, it's somebody, again, it's not easy, but it's, you can get to,
to pretty good self-driving, but there will be educations that are difficult to handle.
And so you never really get or it takes a long time to get permission and kind of get fully
integrated. So you have actual self-driving on the road. And it might be the same who knows
with writing tasks or with programming or with math or with anything else.
And we're kind of approaching expert human performance, but we're not quite there.
Yeah. And I think like, I think the way that it will impact like storytelling and fiction won't be
like you directly asking it to write a story, right? Like it just, there are a bunch of ways
that it can like, you know, make a writer's life easier, even if they're still the ones
fundamentally doing the writing, right? So it's kind of like, there must be a lot of
these like indirect effects. And even if it's just like, tell me about this concept,
like I don't want to read the Wikipedia page, because I want to understand this very specific
element of this thing. I think that's what's happening now. And I mean, let's hope it stays
that way. I think it's, it's, it's kind of depressing future if the future is just a very
large, very general model, getting a vague input from a human, you know, give me a lot of the rings
for and then outputting something, something kind of a finished product without human involvement.
I think it's a, it's a, it's a happier future if we have more tools and we have kind of enhanced
productivity, perhaps we cut out some of the boring parts of, of creating something and you
are more, you're kind of like a vessel for, for a, for a vision to come to life. And then you
have all of these helpers trying to make that happen. Yeah, that would be, that would be,
that would be the dream, I guess. And it seems like there's so much that can go wrong now,
because like, it feels like it's automating a way or more of the good stuff than the bad stuff or
like, is that your, is that your feeling at this point that, that may, because something like
transcription, for example, is not really the most interesting part of, of a process or a creative
process? I guess this like partly comes from like me being like, Oh, like, to like make art
physically is just wonderful. And, you know, I love the images that get created with AI,
but it has had a huge like impact on like, now fewer people do that nice thing. And like,
sure, there's like a bunch of caveats to that. And like, hopefully things will shift around.
And like, hopefully people can just do art anyway, with the extra time that they get and stuff. But
there does sometimes seem like, Oh, it's like, much more easily kind of automating the stuff that
is like, in like, inherently like, like feels good to do or something. But maybe that's wrong. I
think also like, you know, human interaction feels amazing. And like, that's something that is not
going to easily replace or something, although maybe like chatbots and stuff. But you know, it's
it's yeah, the order of automation is something I've discussed with a bunch of experts, economists
and so on. There is, as you mentioned, with kind of the capability gains from scaling and how great
these large language models would become, few people foresaw that. And the same same is true of
kind of the order of automation. I am not sure saying 2010 people would have have predicted
that you would get kind of very creative AI. People maybe thought that you would get some
an AI that's great at accounting before an AI that's great at generating art. Although maybe one
way of sunshine is that whenever I see some AI art, that is just looks amazing to me. It's often
some very nerdy person that's been crafting prompts and experimenting with different models
gone through a process. So it's it's kind of a maybe the process is, is it's still iterative,
but it's less like it's it doesn't take as long and you can maybe you generate 100 images and then
you you slowly focus in on something that's that looks great. Yeah, yeah. And the thing that like
feels intuitively terrifying to me about that is like, even though it's great, and even though I
love the results and stuff is like, everyone I know right now is being like, Well, I kind of
like my job, but I really don't like having a life where I just sit down at laptop for like
eight hours a day. And like, I mean, this is like a very naive point, but it just feel like
everyone's job is becoming that and everyone kind of hates it. And like, we don't really know what
to do about it other than like, maybe become a digital nomad and then like go to the beach when
you don't have to be on your laptop or whatever. But like, it's, yeah, I don't know, there's
something like that there are errors of my life where I still have a very like hands on physical
kind of interaction with the world. And those parts of my life feel very like important and
fulfilling. And they feel like they're getting kind of harder to do. There is an argument to
be made that the order of automation is going to be something like roughly creative tasks first,
then kind of white collar office work, and then last something like care work, where you're caring
for the sick or the elderly and you are, you know, taking care of children, more physical,
physical tasks, being an electrician, being a plumber or something like that. And so, you know,
perhaps, perhaps the population as a whole returns to doing something more physical at one
point. Although, I mean, I don't know if you've seen progress in humanoid robots, but that's also
going pretty well. And perhaps we can kind of adopt the lessons from large language models to
teach these robots how to navigate the world in a flexible way and, you know,
walk around in new environments and solve new tasks and so on. So
Yeah, I mean, at that point, what's left? Like, what do we actually do? Like, I'm sure there are
like a lot of philosophy books on this, like what happens after work ends. Yes. I mean, that would
be Nick Bostrom's new book, Deep Utopia, where he discusses that I don't, what do you, what do you
think we will do? Just what's your intuition here?
Scroll on TikTok. Yeah, I don't know. It feels very, it feels very scary to me. I, I can imagine
lots of like fun scenarios. And it feels like those feel much less likely than like the hundreds
and hundreds of like slightly dystopian ones where we like slowly, slowly lose contact with
all of the kind of like, like restorative things that humans need to do in order to like feel
good about being in the world. But I feel like I'm getting slightly outside of my area of knowledge
here. No, this is, this is great. What, what do you, what would be examples of restorative
activities, literally touching grass or, or kind of being with family or?
Yeah, I think just like hanging out, looking at a fire, seeing the stars, like, like,
like moving a heavy thing that needs to be moved.
Because you feel such a sense of accomplishment once you've moved it.
Yeah, I, yeah, like a friend's boat got in some trouble a few weekends ago, and we spent all
afternoon like using a winch to like, like against the tree, like to like pull it like,
maybe like 30 feet further up the river to get it into a slightly better mooring spot. And
it was great. It was, but it was, it was, it was stressful because it was like,
oh my goodness, the boat might sink if we don't like do this right. And so like,
in some level, you're like moment to moment experience is like, wow, this is like,
important and stressful. And then the other part of you is like, oh, wow, like, I'm actually like,
look, it's moving. And I did that, like, I did that with my winch, like this is a 10 ton boat,
and I just moved it. And like, it's important that I do that. No one else going to do it for me.
Like, so like, I kind of, yeah, I had that day. And I was like, wow, like, I didn't know how often
people get to experience that kind of, like deep satisfaction of like, doing something that is
hard and physical, but also that just like absolutely needs to be done. And that you can
see progress and you like the progress is like meaningful or something.
Sounds a bit like we perhaps what maybe the Amish have this right that they kind of get
together as a community, build a barn together, see the progress over time. But I mean,
we have to somehow integrate these, these desires into a modern world. So it's not
obvious how we do that. Yeah. And it feels like when you're doing, when you know that the physical
task you're doing is something that you're doing in order to be doing a physical task, it kind of
Yeah, now it feels fake, suddenly, right? Something breaks, like it's really,
if you tell me, you know, move this stone, just for the fun of it, I'm not really inclined to
actually move this, this heavy stone. I was like really struck last time I spent time with my grandparents
when they were talking about how in the fifties, my granny would like to make like these huge vats
of chutney. And then she would like put them in jars and then like, you know, give them out to the
whole street. And she just loved doing it. And, you know, that was a situation where like, if she
hadn't made chutney, there wouldn't be chutney, right? Whereas now like, okay, it's cool that we
bake bread at home and stuff. But like, it feels a little bit harder to like get into the joy of
that when you know that there would be bread, whether or not you make bread. And so I'm like
applying this like chutney framing to everything. Because now it's like, she doesn't make chutney
anymore, because she can just go buy chutney and it's perfectly good. And like, you know, I think,
yeah, I think she misses that a lot.
If this is an instance of our lives becoming too good, then because us becoming too comfortable
and there's no risk. And you know, if you don't make the chutney, you just go you order the chutney
and it arrives at your door in no time. And there's no there's never any real risk. But then again,
do you really want to create risk for yourself? I mean, we kind of are our ancestors have worked
very hard to to de risk the world for us to make us rich and so on.
Right. And I'm sure like, also the like on the ground experience of like the people on that
street were like, Well, this is great. I love this jar of chutney, but I gotta make it last three
months because I can't go to the shop and get one. And they would be like, wouldn't it be great
if we could just go to the shop and get one? Like, it's, it's such a weird, like contradiction.
Like, I don't know what the answer is, or maybe like, have a great time.
Do you plan on working more on AI related topics? What what are your future plans for your for your
films? I mean, I would love to. I like like I said, I kind of I need like some kind of demand,
you know what I mean? Like some like intuition that like, I mean, for both this one and the other
like, big student film I made, like, I had this really strong intuition that if I didn't make it,
nobody would make it. And again, it comes back to this thing we were talking about, right? Like,
it's like, I, yeah, I felt like it would kind of actually do something. But then as a result of
that, I've made, you know, there's been a seven year gap between the last fiction film I made
in this one, like, it's like pinning other stuff in the meantime. But like, you know, it's, and I
also distinctly remember like, you know, getting very reading a lot about AI stuff back in like,
2017, 2018, like first really becoming immersed in it and being like, cool, like, what can I
offer to this like field? Like, okay, maybe I should be making like films by AI.
As a last question, perhaps we could talk a little bit about kind of how you're navigating
the changes we see with with AI in the future. You've you've mentioned you've been thinking
about this for, say, since 2017. And you've made this movie, this film. So you, you know,
I know that you that you know these concepts. And how are you, how are you, how are you navigating
all that? Yeah, I think, I think my like, worry about it is like quite compartmentalized or something.
Like, you know, when I listened to that podcast a few years ago, the one round, the Yuckaski one,
like, I got like very like viscerally afraid. And that lasted like a couple of days. And then I was
like, kind of fine again. I mean, it's kind of like, you can, you can maintain this kind of
background, like, you know, intellectual worry. But you, but like, I don't feel like I personally
can kind of like experience that in a bodily way for very long. So it's, I don't know, I'm, I like,
I'm worried about it in some sense. And in other sense, I'm just like, I'm just like,
going to just go do stuff. And it's kind of fine. And like, although it's interesting,
like one of the, one thing that made me much, much more scared about autonomous weapons was
FLI's slaughterbots film, which is again, like a fiction thing, and just made it real, and made
it visceral in a way that like, and I was like, okay, well, if I read something that says like,
oh, this is much, actually much less of a problem than like engineered pandemics or something,
I would still feel more afraid of autonomous weapons than like, pandemic. So it's kind of like,
I, I'm like, I think my actual like experience of like worry is not not like really, really
strongly connected to, you know, what I think is going to happen or like, you know, what,
where I'm coming from from an intellectual position and, but also I'm also not as much
of a doomer as the guy in the film is to be clear, like, I mean, I haven't like figured out exactly
what percentage chance I put on this, but like, you know, I'm not, I'm not at the stage where I'm
like, oh, it's 100% likely to happen. And we should just like all go and have parties for
like the next couple of years. And then like, you know, everyone should like max out their
credit cards or anything like that. Like, I, yeah, I, I have a lot of doubt and a lot of uncertainty
about like how I should be thinking about this or like what, you know, how likely it is or whatever.
So like, I think, I think that creates a lot of distance as well. So I kind of, I'm doing fine.
Makes sense to me. Susie, thanks for chatting with me. It's been great.
Oh, it's been really lovely to chat. Thanks for having me on.
