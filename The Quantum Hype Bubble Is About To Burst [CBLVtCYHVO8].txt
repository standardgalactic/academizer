Quantum technology currently attracts a lot of attention and money,
which might explain why they're missing on my end.
But it's not just governments who think quantum everything is where your taxes should go.
Business investors and companies are willing to put in big money too.
This has had a dramatic impact on quantum physics research in the past decade.
It's also created a lot of hype, especially around quantum computing.
But if so much of quantum computing is hype,
then why are companies like Google and IBM pouring so much money into it?
What will happen when the investment bubble bursts?
What's the quantum winter?
And what does it mean for all of us?
That's what we'll talk about today.
There are several different quantum technologies and, as a rule of thumb,
the fewer headlines they make, the more promising they are.
Take, for example, quantum metrology.
That's not a mispronunciation of meteorology.
That's making better measurements with quantum effects.
You basically never read anything about this.
But it's really promising and already being used by scientists to improve their own experiments.
You can learn more about this in my earlier video.
On the other hand, you have those quantum things that you read about a lot,
but that no one needs at once, like the quantum internet.
And then there is quantum computing, which, according to countless headlines,
is going to revolutionize the world.
Quantum computers are promising technology, yes,
but the same can be said about nuclear fusion.
And look how that worked out.
A lot of physicists, me included, have warned that quantum computing is being oversold.
It's not going to change the world.
It'll have some niche applications at best.
And it's going to take much longer than many startups want you to believe.
Though I admire the optimism of the quantum computing believers,
and also the vocabulary.
For example, there's a startup called Multiverse
that is working with customers in more than 10 verticals.
I'd be afraid some of them don't find the way back from the bathroom.
Or here's one called Universal Quantum,
which has a fault-tolerant team that embraces entanglement
and helps everyone find a superposition.
If you look at them, do they collapse?
This company also recently published a blog post titled
Six Reasons List Trust Needs a Quantum Computer,
which explains, for example,
quantum computers are suited to modeling complex systems,
making them better at forecasting both near-term weather patterns
and the long-term effects of climate change.
Last time I looked, no one had any idea how to do a weather forecast on a quantum computer.
It's not just that no one has done it, no one knows if it's even possible,
because weather is a non-linear system, whereas quantum mechanics is a linear theory.
Here's an example of some recent quantum hype from a website called Investors Chronicle
in an article titled Quantum Computing, a New Industrial Revolution.
After creating a lot of fog about superpositions and interference,
they explained that quantum computers are close to showing quantum advantage
and that quantum advantage therefore can be interpreted as being when problem-solving power
can be applied to real-world issues, which makes it much more interesting for investors.
That's just wrong. Quantum advantage has indeed been demonstrated for some quantum computers,
but that just means the quantum computer did something faster than a conventional computer,
not that this was of any use for real-world issues.
They just produced a random distribution that'd take a really long time to calculate by any other means.
It's like this guy stapling five M&Ms.
That's a world record. Hooray! What are you going to do with it?
Problem is, a lot of CEOs in industry and the financial sector can't tell a bra from a cat
and believe that quantum computing is actually going to be relevant for their business
and that it's going to be relevant soon.
For example, at a recent quantum computing conference in London,
the managing director of research at Bank of America
said that quantum computing will be bigger than fire.
The only way I can see this coming too is that it'll produce more carbon emissions.
This bubble of inflated promises will eventually burst. It's just a matter of time.
This will cause a sudden decline in investment in quantum tech overall
and be the start of a difficult time for research and development.
This scenario has been dubbed the Quantum Winter.
And winter is coming.
But before we get to the Quantum Winter,
let me briefly summarize how quantum computers work and what their problems are.
A conventional computer works with bits that take on one of two discrete values.
A quantum computer instead uses cube bits that can be in arbitrary superpositions of two states.
A quantum computer then works by entangling the cube bits
and shifting this entanglement around.
Entanglement is a type of correlation,
but it has no analogy in conventional computers.
This is why quantum computers can do things that standard computers can't do.
For some mathematical problems,
a quantum computer can give you an answer much faster
than any conventional computer possibly could.
This is called quantum advantage.
Those problems include things like factoring large numbers into primes,
but also calculating properties of molecules and materials
without having to chemically synthesize them first.
Putting these questions on a quantum computer
could speed up material design and drug discovery.
Quantum computers can also solve certain logistic problems
or optimize financial systems.
This is why if you're Bank of America,
you think it's bigger than fire.
And like fire, quantum computing is not magic.
It's an application of standard quantum mechanics.
There is no speculative new physics involved.
It's rather, to the contrary,
claims that quantum computers will not work
rest on speculative new physics.
But it's one thing to say if you could build them,
they'd be useful.
It's another thing entirely to actually build them.
So what does it take to build a quantum computer?
First of all, you need qubits.
Then you have to find a way of entangling many of those qubits.
And like a conventional computer,
a quantum computer needs an algorithm
that tells it how to move the entanglement around.
Eventually, you make a measurement
which collapses the wave function
and you read out the final state.
This final state should be one that answers your question correctly
with high probability.
This means, most importantly,
a quantum computer isn't a standalone device.
It needs other devices for the programming and the readout.
The quantum part is really just a small piece of the whole thing.
Now let's talk about the problems.
First, there's the qubits.
Producing them is not the problem.
Indeed, there are many different ways to produce qubits.
I went through the advantages and disadvantages
of each approach in an earlier video,
so check this out if you want to know more.
But a general problem with qubits is decoherence,
which means they lose their quantum properties quickly.
The currently most widely developed systems
are superconducting qubits and ion traps.
Superconducting qubits are used, for example,
by IBM and Google.
For them to work,
they have to be cooled to 10 to 20 millikelvin.
That's colder than outer space.
Even so, they decoher with the intense of microseconds.
Ion traps are used, for example, by INQ and Honeywell.
They must only be cooled to a few kelvin above absolute zero.
They have much longer coherence times, up to some minutes,
but they're also much slower to react to operations,
so it's not a priori clear which approach is better.
I'd say they're both equally bad.
The cooling isn't only expensive and energy intensive.
It requires a lot of equipment,
and it's difficult to scale to larger quantum computers.
It seems that IBM is trying to do it by breaking world records
in building large cryogenic containers.
I guess if the thing with the quantum computing doesn't work out,
they can rent them out for people to have their heads frozen.
There are some qubits that operate at room temperature.
The most promising ones of those
are currently nitrogen vacancy systems
and photonics on a chip.
However, for both of those,
no working quantum computer exists to date,
and it's unclear even what the challenges may be,
let alone how to overcome them.
The next biggest problem is combining these qubits.
Again, the issue is that quantum effects are fragile,
so the quantum computer is extremely sensitive to noise.
The noise brings in errors.
You can correct for those to some extent,
but this error correction requires more qubits.
More qubits bring problems by themselves.
For example, they tend to be not as independent as they should be,
an issue known as crosstalk.
It's kind of like if you're trying to write
while moving your feet in circles.
It gets really difficult.
The qubit states are also drifting if you leave them unattended.
Indeed, it's somewhat of a mystery at the moment
what a quantum computer does if you don't calculate with it.
It's like it's difficult to calculate
what a big quantum system does.
Maybe we can put it on a quantum computer?
And finally, there's the issue of the algorithms.
Few algorithms for quantum computers are known,
an issue that goes off non-mentioned
because everyone is focused on the technology.
Wikipedia hopefully has a list of quantum algorithms.
It's short.
Several of those algorithms don't compute anything
of practical use, and for some it's not known
if they lead to any speedup.
As this brief summary makes clear, the challenges are enormous.
But how far along is the technology?
The largest current quantum computers
have somewhere between 50 and 100 qubits,
though IBM has a roadmap saying
they want to make it to a thousand next year.
Two different approaches have demonstrated a quantum advantage,
that is, they have performed the calculation faster
than the currently fastest conventional computer could have done.
However, in those demonstrations of quantum advantage,
the devices were executing algorithms
that did not calculate anything of use.
The record-breaking, useful calculation for quantum computers
is the prime number factorization of 21.
That's the number, not the number of digits.
Yes, the answer is three times seven,
but if you do it on a quantum computer,
you can publish it in Nature.
In case you are impressed by this achievement,
please allow me to clarify that doing this calculation
with the standard algorithm and error correction
is way beyond the capacity of current quantum computers.
They actually used a simplified algorithm
that works for this number in particular.
To be fair, there have been some cute applications
of quantum algorithms for simple examples
in quantum chemistry and machine learning,
but none of this is anywhere even close
to being commercially interesting.
How many qubits do you need for a quantum computer
to do something commercially interesting?
Current estimates say it's several hundred thousand
to a few millions of qubits,
depending on what you want to calculate
and how large your tolerance for errors is.
A lot of quantum computing enthusiasts
claim that we'll get there quickly because of Moore's law.
Unfortunately, I have to inform you
that Moore's law isn't a law of nature.
It worked for conventional computers
because those could be miniaturized.
However, you can't miniaturize ions
or the quantum wavelength of electrons.
They're already as small as it gets.
Nature's a bitch sometimes.
In the past years, there's been some noise
around noisy intermediate-scale quantum computers
or NISCs for short.
Those are small quantum computers
in which you just accept the noise,
kind of like YouTube comment sections,
but no one seems to have found anything useful to do with them
and the hype around them has noticeably died down recently.
I guess you understand now why I'm extremely skeptical
that we're anywhere close
to commercially relevant applications of quantum computers.
But let's hear what some other people say.
There is, for example, Mikhail Diakonov,
a physics professor who has worked on quantum things
much longer than I have.
He's written a book that was published in 2020
under the title Will We Ever Have a Quantum Computer?
It is only 49 pages,
which is what happens if you agree to write a book,
but notice how through you'd rather do something else.
He finishes by answering his own question.
No, we will never have a quantum computer.
Instead, we might have some special task
and outrageously expensive quantum devices
operating at milli-carbon temperatures.
The saga of quantum computing
is waiting for profound sociological analysis
and some lessons for the future
should be learned from this fascinating adventure.
The brevity of Diakonov's book is balanced by another book,
Law and Policy for the Quantum Age,
by Chris Hoofnagel and Simpson Garfinkel,
who make it to a whopping 602 pages.
Their book was just published earlier this year,
it's freely available online,
and it has an adorable cat-pick on the cover,
so definitely go check it out.
Hoofnagel is a professor of law
and Garfinkel is a data scientist,
but their book has been heavily informed
by people who work in quantum computing.
They look at the possible future scenarios.
The most likely scenario they say is the quantum winter,
which they describe as follows.
In this scenario, call it quantum winter.
Quantum computing devices remain noisy
and never scale to a meaningful quantum advantage.
After a tremendous amount of public and private money
are spent pursuing quantum technologies,
businesses in the field are limited to research applications
or simply fail and career paths wither.
If that happens, funding eventually dries up
for quantum computing.
Academics and scientists in the field
either retool and shift or simply appear irrelevant,
even embarrassing.
Then there is Viktor Galitski,
professor at the Joint Quantum Institute
at the University of Maryland,
who wrote in a 2021 post on LinkedIn.
The number of known quantum algorithms,
which promise advantage over classical computation,
is just a few and none of them will solve global warming for sure.
More importantly, exactly zero such algorithms
have been demonstrated and practiced so far
and the gap between what's needed to realize them
and the currently available hardware is huge
and it's not just a question of numbers.
There are qualitative challenges with scaling up,
which will likely take decades to resolve, if ever.
Most recently, there was an opinion piece
by Nikita Guranoff in the Financial Times.
Nikita works on computational quantum physics
at the University of Oxford.
He writes,
As more money flowed into quantum computing,
the field grew and it became progressively
more tempting for scientists to oversell their results.
After a few years of this,
a highly exaggerated perspective
on the promise of quantum computing
reached the mainstream,
leading to the formation of a classical bubble.
He then points out that no quantum computing company
is currently making profit
and that the little revenue they generate
mostly comes from consulting missions
aimed at teaching other companies
about how quantum computers will help their business.
I have to disagree on the final point
because big companies have another way
to make money from quantum computing,
namely by renting them out to universities.
And since governments are pouring money into research,
that's quite a promising way
to funnel tax money into your business.
Imagine the LHC was owned by Google
and particle physicists had to pay to use it.
That's how I think it'll go with quantum computing.
First, all the smaller startups will falter
because they don't reach their milestones,
venture capital will evaporate,
and all the overeducated quantum computerists in academia
will use grant money to pay a few large companies
who own the only workable devices.
And while those devices are interesting research objects,
they'll not be useful for commercial applications.
I might be totally wrong, of course.
Maybe one of those startups will actually come up
with a scalable quantum platform.
I don't know, I'm guessing as much as everyone else.
But if quantum winter is coming,
what does it mean for you and me?
Well, some people will lose a lot of money,
but that just means they had too much of it to begin with,
so I can't say it bothers me all that much.
There'll also be fewer headlines
about how quantum computing is supposedly
going to revolutionize something or other,
which I'd say is a good development.
And we'll see many people who worked in quantum computing
going into other professions.
Chances are, in 10 years,
you can have a nice chat about the finer details
of multiparticle entanglement with your taxi driver.
I don't know about you,
but I'm looking forward to quantum winter.
Okay, let me guess,
you didn't quite understand how quantum computers work.
Don't despair, our sponsor Brilliant can help you with this.
Brilliant is an amazing tool for learning.
They have courses on a large variety of topics
in science and mathematics,
and they're adding new ones each month.
All their courses come with interactive visualizations
and will challenge you with questions,
so you can check your understanding right away.
For this video, for example,
I suggest you check out their course on quantum computing.
That's the best introduction to the topic I've come across.
I myself find Brilliant really useful to look up
something I never fully understood,
like some of the puzzles you find in probability theory,
or something I must once have known but have forgotten,
like, for example,
how you prove that the real numbers aren't countable.
I now even have my own course on Brilliant,
which accompanies my videos on quantum mechanics.
You don't need to be an expert to take this course.
I've worked together with Brilliant
so that you can start from the very basics.
My course gives you an introduction to interference,
superpositions and entanglement,
the uncertainty principle, and Bell's theorem.
I had a lot of fun working with Brilliant's team on this,
and I hope you'll enjoy it too.
To support this channel and learn more about Brilliant,
go to brilliant.org slash Sabine and sign up for free.
The first 200 subscribers using this link
will get 20% off the annual premium subscription.
Thanks for watching. See you next week.
