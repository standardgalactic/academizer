Pro-civilization forces have an inherent advantage
because we can actually write good stories.
And our futures are exciting.
Money is a measure of fucks given.
Measure of fucks given.
What is the purpose of my existence?
What do I give a fuck about?
What gives meaning to my life?
You hear these absurd phrases like humans are a cancer on the planet.
They're not talking about themselves.
Exactly.
They're saying all you other people are a cancer on the planet.
We need to cut the population of you guys.
Tax the rich.
We need to steal more from the rich as if that's an ethical claim.
If we institutionalize stealing, we can't have nice things.
No one can have nice things because no one will make nice things.
They're using the ethics to destroy the ethics.
Yes, it's an inversion.
How do we have a society with two different types of rational animals?
Especially what one of them is immortal.
Wow.
One possible solution is...
The farm at Okefenokee is a revolutionary new regenerative agricultural community.
It features an 8,000 tree olive orchard which they use to make their own olive oil as well as a very large pecan orchard.
All the animals on the farm are heritage animals with some varieties over 100 years old and others thousands of years old.
Fresh eggs are produced daily by the farm's chickens.
Also, there are over 1,000 beehives that pollinate the over 200 heirloom fruits and vegetables and provide honey to all the residents.
The farm makes its own molasses, unrefined sugar, herbs, and spices.
The farm also features an herbal apothecary and a commercial kitchen.
These are just a few reasons why the farm is the healthiest place on earth.
To learn more about the healthiest place on earth, go to okefarm.com and use discount code BREEDLOVE for $21,000 off custom cabin pricing.
Again, to learn more about the farm at Okefenokee, go to okefarm.com and be sure to tell them I sent you.
Some of the inspirations behind your work.
You talked about... you named a few science fiction authors before we started.
Yes.
And then the Greek creation myths sound like there are some themes woven in from that as well.
Can you just talk about some of your influences and inspirations?
Well, you know, a novel isn't one idea.
It's a bunch of ideas woven together into a story.
And I think this is something that a lot of people, particularly those high school English teachers who I don't know if they annoyed you as much as they annoyed me, but they've kind of got it backwards.
So people tend to think, oh, you know, someone wants to write a story with a theme they're going to write.
Oh, he's going to write a story with Christ imagery.
And let's make it about my dog dying where my dog is, you know, the symbol for Christ or whatever.
And that's really not how books get written.
What you do is you write a story.
And it starts out as a very simple story meant to entertain.
And you tie this rope to a bucket and you toss it into your subconscious and you dredge the bottom and you pour it out on the table.
And that's where you discover the themes.
So as I was writing this adventure story about, you know, a down on his luck criminal who gets blackmailed into a heist, a high stakes heist of alien technology,
I discovered, oh, you know, there's some Promethean stuff here and there's some stuff about how men and women relate to each other.
And there's some stuff about the future of technology and there's some AI stuff about what it means to be a human being.
So it all kind of emerges from your subconscious and then you start to look at it and you say, well, gee, I got that from Larry Niven.
I got that from Walter John Williams.
I got a little bit of this from watching the Bitcoin guys and thinking about what the future of the economy is going to look like.
And I got it from reading about the upside potential of asteroid mining.
And you get all these ideas that just sort of percolate in your head and they attach to your story as you write it.
So it's a very organic process.
It sounds almost like a Jungian type process that you're just digging into your own subconscious to see.
You're almost like bleeding on the page anyway, right?
Like, who are you?
What has constructed your worldview?
So when you set out, I'm trying to now, I guess, dredge up some advice for other aspiring science fiction authors.
When you set out to write this, then you didn't know the story necessarily.
You had kind of a skeleton.
And then you started to realize there were pieces from these other Greek myths, et cetera, that were attached to it.
Can you speak to how that process actually unfolds mechanically, I guess?
Some people plan a lot. Others plan very little.
I like to call them gardeners and architects.
Gardeners throw seeds in the ground and see what comes up and architects plan and then they build.
And I am very much an architect, so I planned the story.
But even if you have a plan, a plan tends to be a list of things that don't happen.
So when you plan and you start to implement that plan, you learn something and you go back and you're continuously revising it.
And, you know, if I could give any sort of advice to aspiring authors to take it back to your question,
I would say that no one can tell you how to write.
They can only tell you how they write.
And people tend to exist, pre-writers, embryonic writers, which is where I was,
tend to exist in this state where they're kind of pottering around, writing these little bits of things.
And it never really comes together into a full and complete novel length story.
And then what happens is you find your process.
You find the process that works for you.
And that's very individual.
And it can be difficult to do that because nobody can tell you.
You can pick up Stephen King's on writing and it won't tell you how to do that because that's just what worked for Stephen King.
Well, that and a lot of cocaine.
But what you what you can do is you can listen to a lot of different writers and you can sort of cherry pick the little bits that help you.
And then hopefully get to this point where something clicks.
And it's like, oh, I know how to get the thoughts out of my head in an organized way now.
And so did you go through that own developmental process for yourself, figuring out your own personal writing process?
And now I'm asking selfishly.
I'm not an aspiring science fiction writer,
but I am someone that struggles to incorporate a disciplined writing regiment into my life.
For me, it's I feel like I'm a one trick pony.
It's like I'm either podcasting or I'm writing like I can do like a laser beam.
I can do one thing at a time, but I have a hard time maintaining a daily balance of both writing and podcasting and other business activities.
So if you could just walk me through some of that journey and what what you discovered that worked for you individually and see if there's any nuggets in there that might be helpful.
Well, your others.
Well, for me, it was listening to a series of lectures recorded by Brandon Sanderson and bring them young university on writing fantasy and science fiction.
But when you talk about writing in general and only being able to do one thing.
What I would say is stop kicking yourself for having a human brain.
It's it's a neural network neural networks only do one thing at once.
Yeah, multitasking is a myth.
People who say that they multitask what they're doing is their tasks switching.
And so what I do is what I do is is that I, you know, I have a task and I'm focused on it and then I do the task and then I do another task.
And it can be very easy to, you know, oh, I wrote some stuff.
It's become popular or oh, I have a podcast.
It's become popular.
I have all these opportunities that I want to take advantage of.
And you can do anything, you know, you're a smart guy, you can probably do most anything, but you can't do everything.
You have to do one thing at once.
As I was telling you in the kitchen earlier, I think we're all very dumb in our own way.
Yeah, because we can only focus on one thing.
Yes.
What is the struggle here?
There's a lot of, I think Bitcoin gives you a lot of energy to want to like share and create.
But then it's figuring out which channel is the most productive and it just so happens.
But I'm an introvert by the way.
So podcasting does not come natural to me, but this is the one that caught fire, so to speak.
So it became a real business and I've been leading more into that.
However, the foundation of this was writing.
Like it started with me tweeting and writing.
Well, it really starts with reading, I guess, prior to that reading and then writing that even got me in front of the camera in the first place, appearing on other people's podcast.
So I'm trying to figure out almost a way to like keep running the business, but also have an established writing practice that I'm like daily writing because I've found the writing thing.
It's like you're in that mode or you're not like when I'm, as you mentioned of the subconscious, when I'm writing, if I spend an hour a day writing, which is what I try to do, then my subconscious is working on at the other 23 hours.
Right.
And so it's like things will just pop in and I'm dropping notes on my phone and then I'm incorporating that into the written piece the one hour day that I'm actually writing.
So I don't know that's been kind of my process up until this point, but I struggle to get the one hour a day of writing.
I find it to be very painful.
I have to almost force myself.
I bought an hourglass on my desk.
Like once I turn the hourglass over, like I don't let myself move from the desk until the sand has completely fallen.
And I don't know.
I still feel like I'm in that process of struggling to find my own writer's practice.
Yeah.
Well, you you definitely said some very interesting things there.
I love talking to smart people because you listen and you can think of six different directions.
You can take this.
You know, when you when you started talking about Bitcoin, I think a lot of people who who invested in Bitcoin early found themselves with a lot of like, OK, I have I have not just money now, but wealth.
Yeah.
And wealth isn't like, oh, I can buy a Lamborghini.
I mean, I suppose you whatever.
But wealth is is is not that it's it's I can I'm free to do what I want.
And you you you get that sea change from how do I build my career?
How do I pay my bills to what do I want to see in the world?
Yes.
What do I want to create?
How do I want to change the world?
Hopefully to make a better place.
And so it feels to me like when you talk about doing the podcast and writing, it's like you're free to explore your ideals because of your level of material success.
And it's like there's all these ideas I could be putting out there.
How do I how do I channel myself to be productive in that?
And you know, what strikes me is is that if you're struggling to find an hour a day to write.
I don't really think that human effort happens in ours.
I don't think that when we were banging the rocks together and chasing antelope around on the Serengeti or whatever,
that that we really was were like the sun has moved to 10 degrees.
That seems to be a reasonable block of time.
I think blocks of time for creativity are bigger than that.
You know, I work in blocks of four hours.
Four hours.
Yeah, if I if I get if I get if I make a public appearance, you know, on a podcast or whatever, hopefully over the Internet.
So I'm not traveling all over.
But that's that's like, OK, that's my morning.
But then in the afternoon, I have four hours to really get started because that first hour is just getting the creative juices flow.
Right.
And it feels to me like and, you know, I obviously can't inhabit your head or speak for you.
But it it kind of feels to me like if you're just writing for an hour, then you're just getting started and you have to stop.
You're just kind of like paying the switching costs.
Yeah, yeah.
So maybe the solution is to have, OK, this is my writing day.
Bigger blocks.
This is my writing day.
And and then you can forgive yourself for, OK, this other day is my podcast day or my marketing day or whatever you need to do.
Yeah, no, that's great feedback.
And we have actually started to tilt things that direction where I have more writing days.
You also there's you make you bring up a great point that you do have to just kind of listen to the creative brain sometimes because there's some days you wake up and I'm just flooded with ideas.
And it's a writing day, right?
I didn't choose it.
It shows me and you just need to sit down and get it out.
But then there's the other part where if you don't, if there's not some pressure, some deadline, some structure and like imposing itself on you, even though it's self-imposed, then I might procrastinate too much, basically.
So it's like I want I want to let nature have its room to run and have, you know, embrace those creative days when they come, even though you can't summon them.
But I also try to have this structure in place that keeps me moving forward.
And yeah, it's like gardening, I guess.
I guess that would be a good metaphor structure, but some chaos.
Yeah, and and, you know, the progress is made over the long run.
I think people who when you talk about writing for an hour a day, it sounds like these people who are watching their investments and they're refreshing the page every 15 minutes.
You know, your your your portfolio goes up in the long term.
Right.
But there's a lot of noise.
And if we if we try to make our refresh period or our work periods too short, I think maybe we can get lost in the noise.
Yeah.
So you said for you, Theft of Fire, you said nine months for a manuscript?
Nine months for a manuscript.
So walk me through the typical day while you were writing this book.
Well, it goes stepwise.
And because there's there's different phases of writing, you have to you have to first like, OK, this is the story I want to tell.
And this is the seed of the idea.
And for me, it actually started as a very simple writing prompt in an internet group devoted to writing prompts.
And I go, hmm, somebody wrote a princess kidnaps a pirate.
And I'm like, OK, that's backwards.
Interesting. OK.
Well, let's do this in space so it can't be literal royalty.
Let's make her some sort of corporate heiress.
So why would she kidnap?
Well, let's do blackmail.
Why would she blackmail somebody instead of hiring him?
And then you sort of explore these ramifications.
So for me, there's a there's a process.
And, you know, I went through this in the sequel as well.
And I'm in other stages, but of you're just kind of spitballing ideas.
And I think for some people who are very driven and who have a very good work ethic,
they kind of struggle with this almost guilt where it's like,
I'm just sitting around being bored thinking of ideas and not writing them down.
And I'm just spitballing stuff and I'm not working.
But the creative process, I think it almost requires a certain amount of idleness and boredom.
So I have that several month period of idleness and boredom.
And there's a tipping point where it's like, now I'm writing notes because I want to get this stuff down.
And then I'm writing outlines and then I'm writing summaries.
And then I'm breaking the summaries up into scenes and all the scenes and chapters have summaries.
And by the time I'm writing words that readers are actually going to read,
I have a complete summary of the scene I'm writing.
And all I have to do is pick specific descriptions and specific dialogue
because I already know everything that's going to happen.
So you're building that story in phases as if, think of it like building an arch.
An arch is a stable structure of stones where the gravity on each one of them wedges them into this stable format.
But if you have to lift them into place one at a time, if you think about it naively, you can't build an arch
because no part of the arch is stable.
But if you think, oh, well, I'm going to pile up stones where the doorway would be.
And then I'm going to set the stones of the arch on top of that.
When I set the keystone, I take that stuff away and now it's stable.
So you have to give yourself the breathing room to let your creative mind build that scaffolding.
And a lot of the time, you know, you seem to me to be a very, to have a lot of work ethic,
to be a very driven person, to be a very high agency person.
And sometimes that high agenciness that I must do at every second can get in the way a little bit
because we're at our most creative when we're not doing and we're simply being.
So true. That's a great metaphor then.
So you might perceive the idle time as nonproductive if you're very high agency or Taipei,
but you're actually building the scaffolding necessary to put something monumental in place.
Yes, you've understood me exactly.
You have to, you're doing, it sounds like you're doing this thing where it's like,
oh, here's my writing hour that I have wrestled from my busy schedule.
I should, I'm sorry to make this about me, by the way, I don't want to talk about you, but yeah.
Well, no, this is a very interesting thing about the writing process. I love this.
I definitely strive to get that one hour a day consistently because again,
I get that other 23 hours subconscious thing being applied to the written piece
and I find that's where the magic really happens.
But some days it does, I get more, right?
Sometimes there's gaps that I can write much more.
Some days it's flowing naturally.
So it's not just like I'm linearly doing one hour per day every day.
Some days they, there are more hours devoted to writing.
Let's go back to how we connected originally.
The writing process is very interesting.
I want to continue talking about it, but you have super fans, basically.
One of them, and I'm sorry I don't recall his name, but he contacted me on Twitter
and he basically harassed me and was like, you've got to talk to this guy.
This guy is so interesting, interesting tweets.
He kept sending me your tweets.
I think he sent me your book as well.
And we ultimately had a conversation on the show on Zoom,
which was a really good conversation.
And you had one of the most interesting answers to the question
that is the namesake of the show, which is what is money.
And your answer to that question.
It was money is a measure of fucks given.
Measure of fucks given.
Can you please, I know we talked about this last time,
but I think it's worth unpacking it one more time.
It's, if you think back to the origins of humanity,
you have these sort of hominid tribes and everybody has to contribute in some way.
And you're going to keep track of that.
You're going to keep track of it mentally.
You know, you don't.
And so what you've really got is this sort of mental spreadsheet
that human beings have of the value that others have contributed.
And you can get up to what we call Dunbar's number.
You know, you're probably familiar,
but for the audience Dunbar's number is this theoretical number of human beings
that you can sustain a mental model of.
Yeah.
Yeah, it's supposedly around 150.
We don't know.
But what's important is that there is a number.
Yeah.
And and beyond that number groups into fragment, right?
We kind of fork into different tribes.
Well, either they fragment or you need ways to formalize your relationship with them
so that you don't have to think about it as much.
Yeah.
You're limited in your mental resources.
Right.
So as we started to we had the agricultural revolution, we settled down.
Okay.
There's some things that we own now and we can use these as trade goods to keep
track of, you know, who has contributed value.
We can measure it in metal or in grain or whatever.
But ultimately what we are actually measuring is you did something that I give a fuck about.
So I am going to do something that you give a fuck about.
And if I were to, if I were to somehow be able to create a society, you know, the the
currency would be the fuck because it's, you know, that's what measures whether people
give a fuck or not.
It's about what people care about.
Yeah.
So this like ethereal spreadsheet in the sky that's tracking the favors people have
rendered to one another and are then in turn owed from one another.
Right.
Like I do.
I brought down the woolly mammoth and fed all 40 of you.
The 40 of you owe me something in the future.
Yes.
So when I, when I trip over a rock and break my foot, the tribe is going to take care
of me.
Right.
Because I have done something that they give a fuck about.
Yes.
And currency is basically a way of formalizing that relationship.
Right.
So that we, so that we can track it when there are so many human beings that we can't sustain
a mental model of it.
Right.
Very pleasing and amusing that the latest technological development in money goes
back to it being a spreadsheet.
I love that.
Yeah.
Yeah.
So it really, I mean just a mechanism for trading favors, but it's one that allows us
to offload the cognitive burden.
Right.
And we don't need to remember who, who did what for who within our little 150 person
circle, we can actually offload that to a mathematical system.
Basically a spreadsheet, I guess would be a mathematical framework of sorts.
And this allows us to increase the size of our circle.
Right.
And what that allows us to do is work on projects that require more than 150 people.
Right.
Like launching rockets into space.
Yes.
In some way this enables civilization.
Yes.
Yeah.
And over much longer periods of time too, right?
Because you can track, obviously there's intergenerational wealth, right?
People that have families that have created a lot of solutions to a lot of problems over
a long period of time through their business enterprises.
They, you can track that mathematically.
So we get this, it becomes linguistic too, because we now get the language of numeracy
to discuss, you know, we go from the domain of the qualitative, like what people have
actually done for us, but it's translated into the domain of the quantitative.
So you can see, you know, the hierarchies of wealth, right?
What is the net worth?
What is the enterprise value of the business?
Et cetera, et cetera.
So what is the, I guess, what are we doing here?
The loaded term is the fuck, right?
It's like, what I give a fuck about, what does that mean?
Is that what I care about?
Yeah.
Basically.
But it's being communicated in a way that's universally standardized, right?
That's what mathematics is.
So what is the linguistic, there's something linguistic here.
Like I'm trying to, this is something we wrestle with on the show a lot.
It's like one of the definitions of money, the language of value or the language of
human action.
So what is the linguistic quality of money?
What is it doing for us from like a communication standpoint?
Well, when I hear what you're saying here, I almost want to go back to Thomas Sowell.
And when he talks in his book, Basic Economics, he says that economics is the study of choice.
And it's the study of the allocation of scarce resources that have alternative uses.
So when we talk about somebody having done something that we give a fuck about, and
that being the basis of currency, what this helps us do is it helps us choose how we're
going to use our efforts and direct our resources because the monetary value of something essentially
measures what a lot of people give a lot of fucks about.
It's like if something has a high fuck value, what this really means is that we're this
big group of hominids and a large number of people care intensely about this.
So maybe this is where we direct some significant amount of effort.
Because if something has less of a less fucks given, then maybe it means that a lot of people
care about it less intensely, or maybe it means that a smaller amount of people care
about it intensely.
So as apes with tools, there's so many things that we can spend our day doing.
We can spend our day writing.
We can spend our day brewing coffee and serving it to other people.
We can spend our day running a nuclear reactor.
And we have to decide what is the most valuable thing that I can do.
And this currency is a language through which other humans can speak to us and tell us what they care about.
Now, that's wonderful.
The language of economists comes to mind where they would say that the pricing system is that through which consumers reveal their preferences.
So you're actually telling people what you want when you, for instance, buy a car.
Well, then you've taken a car off of the market, so you've reduced the supply, and therefore you put upward pressure on the price of that car,
which is signaling to all the producers of cars in the world.
Well, people give a fuck about transportation, I guess in this case.
Let's produce more of those.
And the opposite is obviously true as well.
When you sell something, it's putting downward pressure and then producers are producing less.
So language, like we connect to each other we're doing it right now.
Obviously, we almost are connecting the interior space of our minds to one another.
But that's not enough to reveal preferences in a way that's trustworthy.
But when you do it with money, it's more, there's more of like this human energy component, right?
So we have these phrases in our language like talk is cheap, for instance.
Could we say that money is something like an energy language?
Like it's telling us what we have done or what we should be doing based on the preferences of other people, something like that?
Yeah, well, with what you're getting at here, I think the way I would put it is that it sort of elides the process of lying to others and the process of lying to ourselves.
You know, when we say talk is cheap, it's literally true.
It's free to say something.
It's very, very low effort.
So we can express preferences that are performative.
Like I don't actually want to spend my day going to the Guggenheim and appreciating great art,
because maybe I actually find that boring and I would much rather watch science fiction movies.
But I want people to think of me as a sophisticated person.
So I'm going to lie about my preferences either to them or to myself.
But because currency requires effort, I'm going to direct my efforts towards the things that I actually care about.
So if other people, if money becomes a language of fucks given, then other people can look at my economic activity.
They can look at how I spend my money and they can discern my real preferences.
And so we can cut through this whole practice of deception and self-deception and social politics
and look at our actual priorities both as an individual and as a group of people living and working together.
And we can direct our efforts in ways that are actually relevant to what we care about
rather than just this sort of spin-off result of how we're trying to present ourselves.
How do you think about the distortion in the field of fucks given that occurs when money is monopolized and printed or counterfeited?
So if there's, I'm referring here specifically to the central bank, obviously,
if there's one organization that can print money or produce it without effort, as you said,
how does that create distortions in this field of fucks given in your view?
They're doing something that nobody cares about.
You know, nobody wakes up in the morning. You don't wake up in the morning. I don't wake up in the morning and say,
gosh, I wish somebody would spend 30 seconds writing a larger number in an imaginary column.
And that is worth $5 trillion to me. It's not.
But the problem, it's a hack in the system because if we have something else that's worth $5 trillion,
like a lot of this sort of wonderful Florida real estate that I drove to to come visit you,
that's also worth $5 trillion. We care a lot about that.
Because people actually give a fuck about living on the land, eating, getting shelter.
Yeah, living around nice trees and near water and being able to go out sailing.
And so what we have is a counterfeit fuck.
We have a fake expression of caring that nobody actually cares about.
So people are doing things that nobody wants.
And they've found a way to infect the system to make it appear as if people care a great deal.
And counterfeiting was like this.
And the only distinction between counterfeiting and currency manipulation
is whether you are the government and you can give yourself a permission slip to do it.
But anytime you have a system for measuring value,
anytime you have a system that motivates people to do things that you care about,
there's going to be incentives to game that system.
And so a society is healthy when it's harder to game the system than it is to participate in the system.
And sick when it's easier to game the system than participate in that.
That's awesome.
I think the driving motivation behind Bitcoin in particular, cryptocurrency in general,
and this idea that we need a new wave of money is that we want to live in a society
where it's easier to create than to cheat and steal
because we would rather be surrounded by creators than thieves.
Absolutely. That's wonderfully said.
And you want to then create a spectrum of rewards and punishments that reward productive activity
and punish anti-productive or non-productive activity, right?
So if someone steals from you, obviously they didn't create anything.
They stole something that you produced.
We want legal penalties in place to disincentivize that activity.
But we want the profit motive, for instance, to motivate producers to solve problems that people want solved.
And so if I hear you correctly, that's the game you're describing, right?
We were creating this economic, the economy, I guess, to use the broad term.
It is a game.
And we're wrestling with how to properly instantiate the rules such that we operate productively
and not self-destructively, I guess, in the case of stealing and killing.
Destructively toward the acting in ways that destroy value in order to get some of the value for ourselves.
Right.
So in game theory terms, to tilt it further towards a positive sum game
and further away from a zero sum game, right?
Yeah, well, this was actually something I played with in the fictional universe of Theft of Fire
and the Orbital Space series, is that one of the trends I see is the way to eliminate warfare
and the way that warfare is eliminated is a gradual move away from warfare being efficient.
So if you think about, and this will become relevant in a moment,
if you think about what people fight over, what has been the valuable resource has changed over time.
Under primitive conditions, it was land and it was physical resources.
And while things like land remain valuable, we now have a condition where like,
okay, technology and technological know-how are becoming a greater and greater source of value.
So you have, you can hope for and try to work for a world where the things that have the most value
are the things that it is not necessarily very efficient to steal.
Like if we start becoming a multi-planetary species and we colonize the solar system,
then all of a sudden, you know, here's these asteroids that are worth 60 quadrillion dollars on today's mineral market.
And of course, what happens is the bottom falls out of the value of some of these material resources.
So it makes less and less sense to fight over them.
So certainly you can set up rules where you punish people who steal.
And that's a thing that we want to do.
But I think as we've looked at the behavior of governments, we've also seen that those who we put in power to punish stealing,
the thieves are incentivized to take over that structure.
And I would say that's what we have going on with the United States federal government now.
We have a kleptocracy where a government run for the purpose of stealing.
But one of the things that technological progress can do for us is that it can move the greatest stores of value
to things that are harder and harder to steal, you know, designs, technological ideas,
and that technology can make the things that are easier to steal, material resources, land more and more plentiful.
So it becomes, you know, if you can colonize all of Mars,
then maybe land is less valuable.
If you can mine all these asteroids, gold is less valuable.
The store of value becomes more and more who has the best technological ideas,
who has the designs, who has the expert population that can design things.
You can't steal any of that.
So there is some hope here simply in technological trends.
But obviously we want to try to do everything we can voluntarily in our own lives to try to reward creators
and either punish thieves or simply make theft more trouble than it's worth.
Right, right, right. So yeah, this is an economics,
I guess the game boils down to the economics of stealing versus producing in a way, right?
Like everyone wants more of any, whatever the thing is.
Obviously there's a gradient, a value gradient on all this, the moreness.
However, to produce something requires work, to steal something also requires work in a way,
depending how safeguarded it is.
That's what I'm saying is you want to make the stealing take more work than the producing.
Yes, exactly.
And this, I guess the central pillar to this game dynamic is this institution of private property,
which we talk about a lot on this show, right?
The idea that each person that expends the energy to create something of value has the right in the responsibility,
the right to enjoy it and the responsibility to take care of it if they wish to continue to enjoy it.
Yeah, they have the right to control it.
To control it, exactly.
And when that social institution becomes violated, and I think what you said about the US government is a great example, right?
It's become a kleptocracy.
Well, what are they doing?
They're violating people's private property rights through taxation, through inflation, through lockdowns even, right?
Through other forms of fiat regulation where they say, do this or else you will suffer the consequences.
All of these are encroachments on individuals' control over their assets and thus their lives.
So how do we, how do you frame this up then?
Because I often, I go to Hoppe's definitions where he says socialism is aggression,
an institutionalized policy of aggression against private property,
and capitalism is an institutionalized policy of respect for private property.
Forget multivitamins and other supplements.
Animal organs are the most nutrient dense foods on the planet.
You can get 100 times more nutrients from organs than you can from muscle meats.
But the problem with eating organs is that they are difficult to find in stores, they are difficult to prepare,
and even when they are prepared well, they often don't taste great.
Thankfully, heart and soil supplements has made consuming organ meats so much easier by providing powderized organs in capsule form.
Organ meats include everything your body needs to thrive, vitamins, minerals, peptides, proteins, and growth factors.
This is why organ meats were the most prized foods for our ancestors.
Fortunately for us, heart and soil makes these treasured foods easily accessible.
So go to heartandsoil.co today and use discount code BREEDLOVE to get started on your journey to optimal health and vitality.
Again, that's heartandsoil.co discount code BREEDLOVE.
Have you ever wanted to start a business in the Bitcoin space?
If so, then the Wolf Startup Accelerator could be for you.
Wolf is the first startup accelerator dedicated exclusively to businesses developing in the Bitcoin Lightning Network.
Four times each year, Wolf brings teams from around the world to New York City to work with like-minded entrepreneurs,
pushing the boundaries of what's possible with Bitcoin and Lightning.
The program is designed to help early-stage companies achieve product market fit, develop their brand,
secure early-stage funding, and grow businesses that fuel the global adoption of Bitcoin.
Go to wolfnyc.com to learn more or apply today.
Again, that's wolf. W-O-L-F-N-Y-C.com.
I know you have some different views here, but I'd love to hear you elaborate on private property, socialism, and capitalism.
Oh, yeah, yeah, yeah. I'm absolutely twitching to get at this.
I like to frame it in a slightly different way.
I mean, obviously, I agree with you because what you're talking about implies a little bit of a moral angle.
It's like, if I create it, I have the right to control it.
And that is absolutely true.
But when we talk to people in moral language about private property, we are pushing against what they're used to.
We are pushing against this idea that they're used to paying a 30% tax on income or whatever,
and that's normal, and we're paying things with it.
Oh, you need to pay your fair share.
And there's a lot of this sort of distorted language used by thieves to pretend that it's selfish to keep what you made,
and it's somehow not selfish to steal what other people have made.
And I agree with all that, but I think there's another angle to look at this, which really provides additional clarity.
And that is that taking what somebody else has produced and removing their control of it is not simply morally wrong.
It's more importantly, an anti-civilizational force.
It tears down because what civilization is, what separates us from our bestial state of nature,
is that we have this massive pile of stuff, and we built that stuff with effort.
And that effort is invested by individual human beings in the hopes of controlling what they build and improving their lives.
And if you create an environment where someone can come along and take it from you,
whether it's a man with a gun or a man with a legal document or a man with powerful friends,
then there is no longer an incentive to expend that effort to build,
but we stop piling up that stuff, those resources, that infrastructure, that technology that separates us from chasing the antelopes with sharp sticks.
So this is how private property is not just a moral imperative, it's a survival imperative, it's a civilizational imperative.
If we institutionalize stealing, we can't have nice things.
No one can have nice things because no one will make nice things.
Now that's wonderful.
Yeah, the pile of stuff that separates us from being cavemen and women, basically.
I guess economists would call that the stock of goods, consumer goods and capital goods, all of this wealth that we've created across generations and accumulated.
We've accumulated all of these goods, again, consumer and capital goods.
And that is civilization in a way, right?
I mean, obviously there's other things that we get.
We get these norms, we get, obviously our language improves, we get social institutions, we have these other sort of intangible things that come along with that,
but the intangibles are made possible.
So we have the luxury to discover or produce the intangibles by virtue of having accumulated the tangible goods.
Yes.
So this is, so when you say to attack private property or to violate private property, it is literally a de-civilizing force.
It's almost like pulling that thread, right?
Because the general expectation amongst people in a civilized society is that, right?
Like whatever you earn, you get to keep and you can trade it with other people.
But if you start to pull that thread and all of a sudden you don't get to keep what you earn, whether it's 10%, 20%, 30%,
again, Hoppe makes this point is like, you start to unwind that process,
that pile of goods, capital and consumer goods is growing ever larger and further separating us from our animalistic ways.
There can reach a point where it starts to actually, we start to draw down that stock of goods and therefore we start regressing as a civilization.
Yeah.
And it's not impossible for that to happen, basically.
Yeah.
Oh yeah.
You're chipping away at the base of the pillar.
And you said something that I want to sort of repeat and emphasize because I think it's so important.
All of these intangibles that go with civilization are luxuries.
And I think you are 100% correct about that.
Yeah.
A lot of people think of history in terms of social progress.
And they say, oh, you know, well, we used to live in caves and eat each other.
And then somebody said, you know, oog, think it wrong to eat other people.
And everybody goes, wow, oog, brilliant.
And then we have progress.
And that's not how it works.
Justice is a luxury.
Notions of justice and ethics and social progress are luxuries.
And this is not that they're not important.
This is not that they're not necessary to a civilization.
But it's important to understand that they were purchased with material goods.
Right.
Because if you want to have something like the rule of law, if you want to have a justice system,
you need police officers and you need courts and you need lawyers.
And you need all these people who are spending their entire day doing something other than whacking at the dirt with a stick to feed themselves.
We have to have all these people employed in giving us this stuff.
So we need to have a material wealth enough to feed this system.
So all of the ethical progress we have had in civilization is simply a side effect of the material progress.
And if the material progress is taken away by people chipping at the base of the pillar,
then we will go back to bandit kingdoms and warlords and this sort of thing.
And so we need to understand this anti-property forces as not just being anti-civilizational
and not just being personally unethical, but as destroying the very thing that allows us to have an ethical and cooperative society.
That's so fucking good.
I'm seeing now the hypocrisy is becoming more emphasized of, say, a modern liberal, for instance, where they're saying tax the rich.
We need to steal more from the rich as if that's an ethical claim,
stealing from the rich and giving to the poor, presumably, which is not what they actually do,
that that is somehow an ethical action that needs to be taken.
But what you're describing is that's, again, it's hypocrisy, right?
If you're advocating for theft to steal from someone, you're actually reducing the incentives for anyone to be productive
and to add to that stock of goods and services, which is the substrate for all the ethicality and morality and all these other intangibles we have on top.
They're actually saying, let's draw down that material base, which draws down the intangible intangibles,
but they're asserting it as if it's an intangible good.
They're using the ethics to destroy the ethics.
Yes, it's an inversion.
And it's an inversion in another way as well, because who are the rich people?
The rich people are the rich people who got rich because somebody gave a lot of fucks about what they're doing.
So when you say, we want to take this measure of fucks away from the people who are doing the things that people give a fuck about
and give them to people who are doing things that people don't give a fuck about,
then we are essentially subverting the revealed preferences of our entire population.
We're saying, oh, we want to tax the people who are, we want to take the value away from the people who are doing things you care about
and give it to people who are doing things you don't care about.
And this is, my agent is over there in the corner waving her hands at me, reminding me to, this is something that I call a death morality.
Okay.
Have you heard me use that term?
No, please.
Okay.
A death morality is any morality that destroys the individuals or systems who embrace it.
Okay.
Like a nihilism of sorts.
Well, even more than a nihilism, because nihilism I would define as believing in no value system.
Okay.
This is belief in a value system.
Like an anti-value system.
That destroys you so that your ethics no longer exist.
Got it.
Like, I'm going to be too broad minded to take my own side.
I'm going to be anti-bigoted, anti-racist and prefer people from outside my culture to people in my culture.
And this is going to tear down my civilization.
And then my ethics will no longer exist because I no longer exist.
It's a self-swallowing morality.
Yes.
This is the self-destructiveness of evil too, right?
That quote came to mind.
I don't know if I can say this exactly right.
Maybe it's Mark Twain, that a fine as a tax for doing wrong and a tax is a fine for doing well or doing right.
And this idea of just eating the seed corn, right?
Where you're, you know, oh, people are hungry.
Feed them the seed corn, right?
It's this short termist sort of thinking that, is it just born of ignorance, I guess?
One of the hypotheses I have is that we're sort of emerging from the economic dark ages.
Largely think, thanks to Bitcoin eclipsing the central bank that we're going to wake up to these, the obvious reality in hindsight that political machinations cannot improve economic reality.
At all.
Actually, all political activity is anti-economic.
Is this, is this just a process of that that we're awakening to economic reality?
Well, if we, if we look at this from a different angle, if we take sort of a different slice through the apple, what occurs to me when you say this is.
There, there is a certain sort of bubble mentality.
Because when you create civilization, when you create value, you're creating a bubble.
You're creating an area, virtual or physical, where the, the ordinary condition of nature, which is poverty, disease and death does not apply.
Right.
So the garden again, right?
Yeah.
The garden and the garden has a wall.
Yeah.
And when you create the bubble and people live in the bubble long enough, they start to disbelieve in the existence of the bubble.
They start to think that the bubble is, is normal life.
Yeah.
And so what you get with these people who you describe as eating the seed corn or advocating eating the seed corn, their, their concern is with how do we share the resources?
Because they have lived in a bubble for so long that they on some level believe that they live in a post economic society.
Yeah.
And scarcity no longer exists.
They use that term to post scarcity.
The garden covers the world.
And now all we have to do is share.
So there's, there's this belief that the problem of generating wealth of advancing civilization of creating technology is already solved.
And nothing we do to redistribute is going to mess with that.
Yeah.
Because it's all sewn up already.
And I think that's the reason that you get super rich socialists in the jet set.
It's maybe some of its manipulative, but a lot of it is, is based on their reality.
They live in a bubble where scarcity doesn't exist and they mistake the conditions of their bubble for the place that the tech stack has brought the entire universe to.
This is a Schopenhauer is coming to mind here that every man takes the limits of his field of vision for the limits of reality.
Yes.
Right.
The people are just in the, as you said, the bubble or the garden and they are so well insulated from the poverty, disease, death of nature, entropy of nature that they forget that that's what's real.
What?
So, I mean, we talked about private property, but this other aspect of the planning, right?
So it's like, okay, well, to build a garden requires some planning.
How should we be thinking about who's doing the planning for the construction of this garden?
Like, is this something that needs to be done centrally?
Or is this something that needs to be done in a more decentralized fashion?
Well, so that's a bit of a leading question.
I mean, obviously, everyone who's listening knows the answer because they're smart enough to have at some point opened up a history book.
And they realize that every time someone has said, we're the smart people and we're going to make a plan to do it better, it always gets worse.
You know, sometimes worse to the point of mass graves, sometimes just measurably worse.
And so, you know, when we talk about a garden, you know, maybe that's not the best metaphor because a garden is something that's small enough that one person can plan it.
But a civilization isn't.
So maybe if we think about it as a bubble, we can say, okay, we're we're expanding this bubble of peace and prosperity by pushing the boundaries little by little out into the world.
But because our brains are limited by Dunbar's number, there is no human being, however intelligent whose mind can encompass the whole economy.
That's why we use this price as language to this is what a vast amount of people care a lot about.
Those are the components of the bubble.
Like if it's profitable to make air conditioners, that means that, okay, there's a lot of people living in hot climates and they want to be cool.
And that's part of that bubble of nice things that we get to have.
And if we start ignoring those price signals, then we don't even know what the bubble is.
We don't know what civilization is.
We don't know what the niceness that distinguishes the bubble from the chaos outside is.
Yeah, we don't know what we have nor what we want in a way, right?
Because those preferences are not being revealed adequately at least.
So how does in your book, then, you said you sort of looked into the possible future, I guess, for this bubble?
What does it look like?
Like what does government look like?
I don't want you to spoil the book at all, but I'm just curious like where we are today versus a better vision for the future.
Is that something that you paint in this book?
Yes, yes.
Well, this is definitely sort of your old school science fiction where you're going to talk about, you know, how can we become more powerful and in the future technologically and implement a society that is advanced over what we have today?
And I looked at this and I looked at sort of some of the things I see happening.
And one of the things that you see is that frontier societies tend to be tremendously libertarian and they tend to be tremendously productive.
And one of the things I thought about here because in this fictional setting, you know, orbital society that which exists outside Earth does not have a central government or large governments or perhaps anything that can be described as a government at all.
They have a lot of contracts.
They have some rules based on private property ownership where, you know, I own this station, I'm going to set up some rules for conduct on it.
But there's nothing that can be described as a government.
And where I saw this going is that if you look at frontier societies, if you look at the American West, it was or America at all, colonial America, it was very lightly governed.
And the reason was is that when you have a certain population average of high IQ and high agency pro social people, you maybe need a little bit of contract dispute settlement.
But they tend to cooperate.
They tend to use their words to settle things.
And so you really just need to get out of their way and let them get on with it.
So I envisioned space and the gravity well as being the next great filter where people who can't get their lives together aren't going to be able to get out of the gravity well into space.
So what does it look like when you have a society full of people with technical specialties whose average IQ is 115 or 120 or whatever it would be.
And it's like, okay, now you don't need a lot of governments.
Now you don't need a lot of regulations.
Now you can focus on cooperating to build your tech stack instead of using the legal process to wrangle over resources.
And I actually focused on three technologies that I thought would be very exciting in the future.
Space colonization, computer science in the sense of artificial intelligence, you know, both true artificial intelligence and developing better expert systems for doing tasks and biotech genetic manipulation.
And these all have very, very, very high, almost unimaginably high potential upsides.
But right now they're at risk from this sort of knee jerk possibility of regulation where the progress can be interrupted by government.
So I drew a future where the centralized regulatory role was occupied by Earth and the decentralized unregulated role was taking place in orbital space.
And, you know, my goal was not to create a utopia where this is good and this is bad and I'm going to preach to you.
It's let's explore the ramifications in both ways where you obviously have some unintended consequences of this sort of unregulated technology, but you have a vast expansion of wealth.
Whereas the centralized sort of planned economy governed societies tend to be held back.
But you have much more ability to sort of predict the future because you're controlling the future.
And I think that's that's a big appeal of regulation that statists go to.
It's like we want to know what's going to happen.
So we're going to create restrictions.
Right.
Yeah.
The visual for me is going back to that bubble actually because there is some, well, let's see.
You want the core of your bubble to be sort of stable and predictable and controlled.
Right.
But you want the edges to be able to adapt to changes in the environment.
The tendency towards centralization would tend to be stronger.
As you said, in your book, it's on earth.
Right.
So in the older civilization, there tends to be a larger tendency towards centralization.
Whereas in the frontier orbital space, it's much more libertarian.
Right.
So it's a it's a free for all.
Yeah.
Well, it's it's it's based on people sorting.
Yeah.
You have the risk averse people.
Yes.
Staying in the safe place.
Right.
And this this causes them to this causes a concentration of people that favor a risk averse policy.
Right.
Where they think a lot about potential downsides.
Yes.
And then you have the very risk tolerant.
High agency people who are going to go take the risks.
And then you have this other area where you have a high concentration of people who like risk because they think about the potential upside.
And obviously, since this this this show we're doing right now is very Bitcoin adjacent.
Obviously, we're talking in front of an audience of risk takers.
You know, people who said they're on this this this cryptocurrency stuff.
That's kind of interesting.
I'm going to put 10 $20,000 in that and see what happens.
Yeah.
Yeah.
People that are.
Yeah.
It's a good framing.
Right.
You're looking at risk in a way that you're seeing the upside, not just the downside.
But people that see it the other way would tend to almost retreat towards the center.
Right.
You're further away from the frontier.
So you've got a higher predictability, more stability, less risk, but also less reward.
Whereas people that are more attracted to risk taking will operate near the edges where there is less stability, less predictability, but therefore more potential upside and downside for that matter.
Yeah.
And that sorting function is a good thing.
Yeah.
Because it's revealed preference.
Right.
We would like to have people be able to to live in places or in in societies and conditions that match their preferences.
And we would like to not be ruled by people who don't have preferences that match ours.
Right.
And one of the things that we're experiencing right now is that we as a species, we don't have a lot of frontier territory right now.
So those of us who are very comfortable with risk and are very focused on the upside of risk are having to live alongside those who are not very comfortable with risk and having to share political units with them and having to have arguments about them about whether certain risks should be allowed.
And I think what space colonization does is it allows us to leave those people in a place where they can set a whole bunch of policy and mitigate the risks they're afraid of, or at least they think they are.
And socialism has its own risks, but try telling them that.
And like, okay, we can we can establish societies or social units or physical areas that are free to be populated just with more risk tolerant people where we can cooperate to say, okay, now we're going to build something.
And so, you know, that you get a lot of you get a lot of socialist types talking about, oh, you're you're trying to escape to space, you know, to escape the global warming.
What we're trying to escape is you. What we're trying to escape is is you, you know, risk averse central planning resource redistributors that are the reason that we can't have nice things.
Which is maybe part of that sorting function as well, right? Like maybe we need to be annoyed by them enough to want to go and conquer the the oceans and the stars and all of these things.
Yeah.
What so you mentioned AI space colonization and biotechnology slash gene manipulation. Are you able to talk about those themes?
Oh, sure.
How they manifest in the book without giving anything away like I'm just curious what type of sci fi is going on in this.
I actually I actually have three major characters and each one of them is tied in with one of those technological stacks.
There is there is a a failed asteroid miner whose business is circling the drain and he gets blackmailed and and and his his expertise his tech stack is all about space travel and asteroid mining and space exploration and doing physical stuff in space.
And then the second character the heiress who blackmails him is so gene manipulated that she is essentially post human.
Oh, wow.
So a lot of what her character presentation talks about the kinds of things that we can do and the kinds of things that people will do, you know, with ourselves the moment we have the capability.
You know, it's it's not all deep minded stuff. Some of its revealed preference rather than, you know, the the philosophical stuff people say they care, like, let's make ourselves smarter.
Okay, great. Yeah, there we're also going to try to make ourselves cuter.
Of course, you know, we're going to do it.
And then the third character who is revealed somewhat later so I won't say too much about her is a is a prototype artificial intelligence.
Okay.
And her character explores some of what does it mean when we create something that is essentially a person, but not a human.
And how do we deal with that as a species? And how does that new organism coexist with us?
And I had a lot of fun with that because every almost every science fiction treatment of true artificial intelligence, you know, where it's not just like the the ship says the oxygen levels are falling.
That's just a plot device.
If they always seem to fall into one of two tropes, they're either Pinocchio, and they want to be a real boy, or they're the terminator, and they want to exterminate the organic meat bags.
Yeah.
And I was like, neither of these things is going to happen.
Right.
Yeah, of all the things that are going to not happen, those two things are going to not happen the most.
So this is going to be something entirely new when we create software life.
It's going to be something new and maybe it will be resemble ourselves because we'll copy off ourselves and we'll create ourselves.
And you know, maybe we'll maybe we'll have some success in translating people into software so we can not die of old age, which would be nice.
But ultimately, this is going to be a new form of existence with its own rules and principles and those people, whether they were human or they're entirely new, are going to have to figure out their place in the universe.
And it's not going to be, gosh, I wish I were organic and can die in 100 years.
And it's not going to be, I want to mindlessly kill every organic thing so that we can have a fight plot.
It's going to be, what is the purpose of my existence?
What do I want?
What do I give a fuck about?
What gives meaning to my life?
And this character has to answer those questions.
Fascinating.
Don't give it away if it does, but I'm just curious.
I would imagine this gets into kind of the ethical status of this new form of life.
Is it human? Is it not human? How does it fit into our views of one another?
Imagine there's some tension there.
Oh, yeah.
Well, that was something that was first explored by William Gibson in Neuromancer, which I don't know if you've read.
I would highly recommend it.
It's probably one of the seminal science fiction works on AI.
He talks in this one scene about how the hardware and the database are the property of the corporation that made it,
but the AI is considered a citizen and somebody remarks,
gee, I own your brain and what you know, but your thoughts have Swiss citizenship.
Yeah, great deal.
Lots of luck AI.
And there's going to be some tension in the future there.
I mean, right now, what we create that we call artificial intelligences are basically just neural nets that serve a purpose and their tools,
and there's no real ethical consideration there.
But eventually we're going to reach a point where somebody is going to create something that is clearly understandable as being a person,
but the effort of having created them is going to represent a very large investment.
And this is a question that we have grappled with in ancient history because of what are the rights and responsibilities of parents with respect to children.
But this is going to be a whole new form of that and it's going to be unfamiliar.
So we're going to have to renegotiate that question at some point.
That's going to have repercussions on legal systems, ethical systems, moral, everything.
Yeah, yeah.
Right now we talk about human rights and that's absolutely a fair thing to do because we are humans and I don't think we should be too broad-minded to take our own side.
And I'll stop eating animals when you persuade them to stop eating each other or not going there.
But we can shape the discourse about rights and individuality and the ability to own property around humanity because right now all of our sentient members of society are human.
We're the only rational animal that we know of, but we introduce a new rational animal.
Yeah.
Then we have to say, okay, how do we have a society with two different types of rational animals?
Especially when one of them is immortal and can be connected to potentially unlimited amounts of processing power.
Wow.
So one possible solution is, well, if we have a superior way of being sentient, then maybe we try to become that.
Maybe we can, as a species, transcend our meat substrate.
And that's something that's been talked about recently and there's a lot of pushback on that because it feels sort of egg-heady.
It's the transhumanism thing.
Yeah.
People have objected to sort of the tech bro vibe of that.
But I think that in the long run, when we really develop the ability to control who and what we are, we won't be deciding these issues with,
well, that's unnatural or these sort of vibe judgments like that.
We'll be able to look at what it's actually like to be a software intelligence versus to be a biological human being.
So right now, we don't have that choice.
We don't have the choice about what to be.
We are what genetic accidents make us.
But I think that developing independent artificial intelligence is going to be a preview of the choices we have to make when we develop the ability to manipulate our own essential genetic nature.
It's funny you call that we are what genetic accidents make us.
I was curious about the line really between we use this term artificial intelligence.
But if we do it correctly, then it's basically we're probably reproducing natural intelligence in a way, right?
One emerges as a series of accidents, but then that series of accidents that led to the emergence of us then led to the emergence of this AI thing.
So maybe this is a philosophical question.
Where is the line between the artificial and the natural?
Is it just having gone through the hands of man?
That is that is a very astute question.
And a lot of people, they use the term natural very casually to mean, oh, you know, this, this swamp is natural.
And, you know, this, this Miami condo is not.
But what they really mean by that is this was built by a human.
And this wasn't because if you show them a termite mound or if you show them a bat colony, they will say this is natural.
And they will often use this term natural as sort of an intellectual bludgeon to advance an anti human agenda.
Like whenever a human being does something or builds something, that's not natural.
We need to cut down on that.
Whereas anything that else that happens in nature, oh, that's natural and that's good.
And, you know, it's like saying things are made out of chemicals.
Everything is made out of chemicals.
You know, everything is in some sense natural.
So often when people use this word natural, what it really is, is just an appeal to an appeal to the basic fact that we kind of like trees better than concrete, you know, they're prettier.
And I think that's important.
An aesthetic appeal.
That's important.
But we need to we need to understand that that's what we're saying.
Yeah.
We're not we're not saying, oh, the the actions of man upon the environment are morally bad.
Right.
What we're saying is I like trees.
I like to live around trees.
Let's not build concrete hives to live in because that is unpleasant.
Also like concrete, right?
I mean, it's I think revealed preference.
Yeah, revealed preference.
Right.
It's one of the most abundant things on earth.
I think maybe the most abundant man made thing on earth is close to it.
Well, again, this is this is a scale of revealed preference.
You know, my agent over there who helps me do all these shows.
You know, she loves Chicago.
If she had her way, she would live in Chicago, you know, in a walkable neighborhood in
Chicago and bike everywhere and get everything from little shops.
And this is this is a high preference for having a lot of your environment consists of humans
and human byproducts.
And if I had my way, I would live somewhere on a mountaintop by a lake with lots of trees
and, you know, a good internet connection.
But this is a high preference for living with relatively few with relatively little of your
environment shaped by humans and a lot of it shaped by nature.
And so again, just as as we like to have people be able to sort by risk tolerance preference,
we would like to have people be able to sort by population density preference.
So and I realize that I'm taking this question of what is natural in an aesthetic direction.
But I think I think there are some parallels because there are people who will not accept artificial
intelligences as natural life forms and there will not want they will not want to associate with them.
Yeah.
And some other people will want to marry them.
Right.
And it's like allow people to sort on their preference.
Right.
Yeah.
That's fantastic.
The the using it as an intellectual bludgeon to advance the anti human agenda.
Right.
You hear these absurd phrases like humans are cancer on the planet.
And it's a human espousing that opinion.
It just death.
It is a death morality and simultaneously, I think a performative contradiction.
I was like, you are a human sitting there articulating this opinion.
Yeah, they're not talking about themselves.
Exactly.
They're saying all you other people are a cancer on the planet.
We need to cut the population of you guys.
Yeah.
So that I can inhabit my utopia.
Right.
You know, people who talk about sustainability, ignoring the fact that that, you know, steady
state sustainable environments are never how human beings have done anything.
And they're not how we have succeeded.
We have always innovated our way into larger and larger worlds.
And there is infinite space in the universe to do so forever.
But people who talk about sustainability and how we need to cut down and cut back are never
volunteering to be the ones who cut down or the people who get cut back.
But this invalidates what they're saying, right?
Yeah.
It's like, if I hate to be so brutal about it, but if someone's saying that, the only
thing, if they actually meant it, the only way they could prove that they actually meant
it to me is like suicide on the spot.
It's like, if you actually thought that was a thing and you need it as a pathogen on the
planet.
And I think you're not being brutal enough.
I think it would be an excellent idea if they would do that and get out of the way of the
rest of us.
What?
How?
I mean, how does this particular mind virus penetrate people?
How is the performative contradiction not evident to others?
It seems so abundantly obvious to me.
I can't.
It's like the shining sun right in your eyes.
How does this work on other people's rationality?
What is this hijacking of the human rationality that's occurring when you get these death
moralities or performative contradictions that we're talking about?
I think we have to reexamine our, our assumption that objectivity is the default condition.
You know, when we talk about objectivity and we talk about philosophy, these are conversations
that are held throughout history between people who like to write things down in books and
have IQs of 130 and above.
And that is not your typical human being.
Yeah.
It is.
How small of a subset is the 130 and above is 10%, 5%?
Quite small.
Yeah.
5, 1.
Sorry to interrupt.
I was just curious.
I think, I think, I think maybe 125 is 1%.
Okay.
Sure.
Um, but the point is that a number exists.
The point is that a boundary exists.
And the comparing all of your beliefs for consistency is not a default human activity.
And having all your beliefs be consistent is not a default human state.
If you talk to a, a great number of people, you find things like they are unable to imagine
what they would do in a different emotional state than they are now in.
You know, there are a lot of people who have trouble with the breakfast test.
How would you feel if you had not had breakfast this morning?
So there are these basic, basic, basic cognitive tasks of objective thinking that are beyond
a lot of people.
And if you add to that the number of people who are smart, but their, their social and
material purposes are served by not being aware of something.
You know, the, the, the forebrain is a storytelling engine.
That's why we like stories.
You know, we, we invent stories to explain things.
And so a lot of the time we'll have something that we want.
And, you know, this frontal cortex will get busy writing a story about how it makes sense.
This is default human activity.
This is how we contend for social status and resources.
So when you ask how can people be completely unable to do this, what, what you're really looking
at is that this is a special capability, which only a small percentage of humanity has.
So small percentage of humanity can generate the story or ideology.
Large percentage can install it or adopt it, whatever the term is here.
What then is the motivation of the small percentage of people producing such anti-human ideologies?
Like what is to be gained?
Is it just control over people?
I don't necessarily always think that this is deliberate.
Because when you write a story, you know, when you write these just so stories,
you can be persuading other people, but you can also be persuading yourself.
And it is a great advantage to a con man to believe his own lies.
Right.
Okay.
So post hoc rationalization.
Yeah.
Yeah.
What I'm saying is that post hoc rationalizations, just so stories, you know, a priori reasoning,
all of these are the default mode of human functioning.
Right.
And so asking why people don't do this is like asking why people are poor.
Poverty is the default condition.
Ask why are people wealthy?
What creates wealth?
So what you, what you really want to ask is, is why are, why are some people able to assemble
a, a consistent set of beliefs that help them understand the universe?
Yeah.
I'm, I'm back.
And how can we have more of that?
So we get to this whole relationship between the material as the kind of the substrate for
the, you know, the intangibles, right?
The cerebral or the ethical.
And so it's, it's maybe cert, well, I guess through the accumulation of goods, right?
Capital goods, consumer goods that we gave people the freedom to sit around and philosophize.
And a few of those people happened to be 125 IQ plus whatever right place, right time wrote
it, had the right distribution that then becomes permeated into the, the, you know, what do
we call this accumulation of knowledge over time?
And then the other 99% of people that aren't capable of producing that then install that.
And so this is not only are we up, are we upgrading our physical capital, but we're upgrading
our non physical cognitive capital over time as well through this process.
It sounds like, so then are more people capable of, you can get bad installs like this anti
human ideology, but obviously, and if you look at the whole arch, like the whole arc
rather of human history, like it's overwhelmingly positive, right?
We've moved towards more abundance, more prosperity, more freedom, more population, all of these
things like we're, we're being fruitful and multiplying, but there's definitely if you
zoom in, you know, periods of progress, regress, et cetera.
So I think, I think I see a little bit where you're going with this.
I don't know where I'm going with this.
I hope you do.
Well, I'll, I'll have a stab at it.
One of one of the, I think one of the first and most powerful human inventions and it's
probably pre human in its basic origins is language.
Yeah.
And what language allows us to do is that humanity has, has like a very small percentage
of people who are innovators.
But since we have language, these sort of genius innovators, we can make a much larger
segment of our population, you know, like implementers or in imitators able to functionally
be that genius.
Like you don't have to be Tesla to plug in this microphone.
You just have to have somebody who understands what Tesla is talking about and can use that
to make microphones.
Yeah.
And so we have essentially a population that is able to, in some ways, function on the
level of our best geniuses, despite being nowhere near that.
And so naturally we, we sometimes develop some silly beliefs, but all of these sort of
ways of looking at the world and belief systems and thoughts about, you know, how to connect
membranes to electromagnets and ways to bang the rocks together can all be thought of a
little bit like investments in a capitalist market where you're trying economic experiments
or you're trying, you know, cognitive experiments and then everybody imitates the winners.
Right.
And these things are subject to evolution as well.
And the danger, of course, is that sometimes you generate ideas that are so pernicious
that they can wipe out the substrate that you have ideas in.
What I call death morality, communism.
Marxism.
Yeah.
Right.
Yeah.
It's like Marxism is a bad idea and in a free market of ideas, you would like to say, well,
you know, let's just let the Marxism die out.
But what the Marxism does is it tries to destroy the free market of ideas itself.
It tries to destroy everything.
So sometimes you have to take a more active role of intervention, you know, because we
can't just, we can't just let the socialists be wrong and let history prove the socialists
are wrong because we're unwilling to accept the mountain of corpses and the technological
and civilizational collapse that the process of failing on its own involves.
Right.
Right.
Yeah.
The term mutation came to mind, but it's as if, you know, Marxism, right?
From each according to their ability to each according to their need.
It sounds wonderful in a way.
If you just don't think about it too much.
Yeah.
It's like, oh, well, abilities needs match up.
We're all good.
Right.
But as soon as you apply some thinking, like, wait a minute, who determines what's the incentive
to produce their who determines need?
Who arbitrates this thing?
You're sort of you're implying centralized power.
Right.
Well, if you look at, if you look at the German and I'm not, I haven't done this in a while,
so I may not be completely correct here.
But if I'm remembering correctly, a better translation would be from each according to
his abilities to each according to his labor, except that is a dangerous idea in of itself
because private property basically is like, how did you know?
I don't know.
Well, I mean, it's the labor theory of value.
The labor value is very dangerous.
Okay, you're right.
It's got to be fucks given has to be attached to the labor.
It has to be attached.
You know, it has to be labor that people give a fuck.
Yeah.
Yeah.
It has to, fucks are given about results, not efforts.
Right.
Right.
Otherwise we could all just dig holes in the desert and fill them up with it.
Right.
Of course.
Yeah.
No, so that's great.
From each according to their abilities to each according to their labor that other people
give a fuck about.
Yeah.
That would be what we actually want, but that is not the abolition of private property.
Yeah.
That's the perfection of private property.
Yeah.
From each according to their abilities to each according to their results.
Yeah, results.
Right.
Yeah.
We want to reward, you know, a lot of people get stuck on this idea of, oh,
you know, in capitalist societies, you know, there are these people who get filthy rich
by barely working at all.
Well, good.
Good.
Because that means we are massively, we are massively rewarding somebody who figured
out how to, how to do something people give a fuck about without expending much effort.
Yes.
That's exactly what we want.
Right.
Yeah.
Yes.
We want, we want wealth inequality.
Wealth inequality is good because it means you are rewarding rare innovation events.
Yes.
Exactly.
Yeah.
The question is not, you know, what is, what is the gap between the rich and the poor?
It's, you know, what is the absolute measure of wealth inequality?
It's how much does the baseline person have?
Yes.
What is the absolute wealth of the baseline member of your society?
That's what you want to raise.
Yes, exactly.
Yeah.
Standard of living.
And it's almost immeasurable in a way because the qualitative dimension is very difficult
to account for, right?
Having access to refrigeration or antibiotics or whatever.
It's like that's hard to quantify in a way.
You have to quantify it through revealed preference.
Yeah, we do it.
Number of fucks given.
Yeah, we do it.
Yeah.
Like GDP, I guess would be kind of the thing, right?
More people living longer lives, producing more stuff.
And then we create this metric called GDP.
The qualitative lived experience is, we're back to that thing of civilization, right?
Like it's a whole nother world.
We've literally created, we're sitting in it right now, right?
It's surrounded by paintings and lights and cameras and microphones and all this specialization
that's accumulated and knowledge over time.
Like I don't know how to do any of this shit.
I can't make anything in this room.
No one does.
But we're benefiting from it.
No one does.
There is no single person alive that knows how to build everything that is in this one
room that we are sitting in.
Yeah.
It requires that cooperation.
Yeah.
The fantastic essay on this, I don't know if you ever read it, I Pencil.
It's a great economics essay.
Just talking about constructing a pencil and how much collaboration is involved.
Yeah.
It's really wonderful.
Do you want to give your kids a foundation of freedom and understanding of Bitcoin and
a healthy skepticism of government?
Then you should try Tuttle Twins.
Tuttle Twins is a cartoon about a grandma with a time traveling wheelchair who takes her
grandkids on hilarious adventures to learn about economics and freedom.
Think the education of magic school bus meets the comedy of The Simpsons.
With Tuttle Twins, your kids will learn about Bitcoin from Satoshi Nakamoto, civil disobedience
from Harriet Tubman, natural rights from John Locke and how to destroy the economy from
Karl Marx.
Today, Hollywood green lights a lot of woke content or mindless garbage.
Each episode of Tuttle Twins is parent funded, parent vetted and only released when it is
parent approved.
Because Tuttle Twins is fan funded, it was the world's first kids show to teach about
Bitcoin.
That episode alone has been seen by over 40 million people and was tweeted by Michael
Saylor.
You can watch episodes of Tuttle Twins for free right now and if you like what you see,
you can watch dozens of Tuttle Twins episodes when you subscribe to the Angel Studios app.
So go to angel.com slash breed love to discover Tuttle Twins today.
One of my highest health priorities is keeping my brain in top shape.
To take care of my brain power, I do many things such as striving to read, write, exercise
and meditate daily.
One of the latest tools in my brain power toolkit is MindLab Pro.
MindLab Pro is a new tropic supplement that is scientifically proven to enhance your brain
power.
When I take MindLab Pro, my mind feels like it has a better grip on the world, my thinking
is more lucid and the articulation of my speech is radically improved.
MindLab Pro has been tested in rigorous double blind placebo controlled human trials and
has been proven to enhance brain power for users in every age group.
MindLab Pro is an advanced formulation of 11 new tropic ingredients and is backed by
research from over 1400 human trials conducted over the past 32 years.
So if you're looking to enhance your brain power, MindLab Pro is an excellent solution.
Go to mindlabpro.com slash breed love to start enhancing your brain power today.
Again, that's mindlabpro.com slash breed love.
So innovation is inherently uncertain.
It's an uncertain process, right?
Well, it's disruptive.
Disruptive, yeah.
It disrupts the status quo.
I think that is maybe one of the main sources of anti-innovation because imagining that
which does not exist is a lot harder than imagining the loss of that which does exist.
So anytime you have some potential progress, it's very easy for people to say, well, the
buggy whip manufacturers, the horse whip manufacturers will be put out of business by this new, you
know, motor-velocipede thingy.
The horseless carriage.
And that is bad because it's easy to imagine the downside, and it's not easy to imagine
the upside, but also that which exists has people who benefit by it, and that which
does not yet exist only has people who hope to benefit by it.
So there's always this sort of inherent fearfulness on the part of certain parts of the population
where they think they're focusing on a specific negative change, but they would have that same
negative change focus for literally any change that looked like it was going to happen.
Yeah.
People fear what they do not understand.
Yeah.
The other thing that came to mind was the scene versus the unseen, right?
There's the scene, right?
The buggy whip and the buggy manufacturer and all the jobs and all the integration and food
on the tables and roofs over their heads that those jobs are providing people.
But then there's the unseen, which is just this possible future of doing things differently,
right?
Horseless carriages, right?
Automobiles rather than having the horse buggy whip.
Yeah.
Like that is a challenge of imagination, right?
It's unseen.
It's never been seen.
It started in whoever Henry Ford's imagination, and then that had to be produced for people
to, I guess, then actually engage with that new reality.
Yeah.
So there's this, there's an asymmetry there, I guess.
And then the last part you were saying too is those existing economic interests have,
they're entrenched, right?
They have, they will defend their turf.
Yeah.
They have a budget.
They have a budget.
They have, yes, exactly.
They have resources.
So how do we, is this another mind virus thing that we need to learn from history not to
fear innovation?
That, you know, although it can be destructive or disruptive to jobs in certain jobs, as
you were saying with the buggy whip manufacturer, in the broader scope of consideration, it
improves human productivity and standards of living.
So we should just embrace it rather than be scared of it.
And the current example, of course, would be AI, that everyone's scared that it's going
to destroy jobs.
Yeah.
Well, this is, this is what these kinds of cultural conversations are about.
And I think there's a couple of important points to understand here.
First of all, you don't, no one has ever been able to put tech innovation back in the bottle.
Right.
Because you don't, you may be able to set policy, but you can only set policy over a certain
percentage of humanity.
If you decide not to innovate and you make a policy that the percentage of humanity that
you can make policy over will not innovate in this way, then there will be some other
segment of humanity that will innovate in this way and they will become dominant over
you and their culture will prevail and yours will not.
So there is no option for the do not innovate button.
There is only the how do we steer our innovation button and the do not, the temptation of the
do not innovate button is always this huge threat precisely because the scene is easier
to understand than the unseen.
And I believe I mentioned this earlier, but if I may go off on a bit of a tangent, there
are asteroids out there that are worth 60 quadrillion dollars in today's money in minerals
and so forth.
Now obviously, if you mine these, you don't get 60 quadrillion dollars.
What happens is that the bottom drops out of the market for all of these rare substances.
They become less rare and more cheap.
You start making bullets out of gold, but what that does is it means that all of the
technological processes that have been bottlenecked behind the difficulty of extracting this
stuff on earth, now suddenly that blockage is cleared and you can do all sorts of things
and create all sorts of possibilities that you couldn't before.
So right now it's like, okay, you want to make electric cars, you need all this infrastructure,
you need all these batteries, you need to strip mine certain parts of the earth for
cobalt and so forth.
And what people don't necessarily understand is that earth is a gravity well.
And gravity well, you can literally imagine it as a well.
It's like it's a deep hole where the heavy stuff falls to the bottom.
So here on earth, most of the heavy stuff is at the bottom.
Most of the heavy elements are at earth's core where we can't get them.
We're just scrabbling around on the surface compared to some of the other parts out in
space where all these heavy elements are crushed up in little pebbles that are orbiting all
over the place and all of the neat stuff is really there available to grab.
Now right now with our current technology, we would go broke doing it.
Right now, if Fort Knox were sitting open on the moon, we would go broke trying to bring
the gold back.
But the whole point of the technological progress is to change that and enable further
technological progress.
So when you are able to lift your tool chain out of the gravity well and start doing your
mining and extraction, doing your manufacturing out in space, then you have a second industrial
revolution which eclipses the first industrial revolution.
And I tried to write about this, but I may well have underestimated it by many orders
of magnitude.
I don't think there's any way for us to really understand just how much that changes lives
for the better.
Any more than a 15th century agrarian farmer could have understood downtown Miami.
No, it's fantastic.
And again, back to that excellent point you made earlier of just the capital, the physical
capital stock supporting the ethical and moral.
It's like, who knows what we can discover or create or become or second order intangible
effects.
The civilization that we could be with, you know, unlocking the next step change in human
productivity.
It's unimaginable, but I guess it's imaginable, but we don't know, but it's so profound.
It's overwhelmingly profound.
Not only make war, you know, economically obsolete, but be able to exist in a condition
of such abundance that it would be ethically unthinkable as well.
Yes, exactly.
Yeah, it's fantastic to think about.
I actually saw a tweet, I actually, I put out a tweet.
This was a clip of Elon talking about robots.
He was saying that he thought that demand for robots was on the order of 10 billion units,
basically, because he said basically every person on earth would want one plus you need
some for production processes, et cetera.
And he goes and he was trying to figure out what the total addressable market was and
he figured, you know, 10 billion of these things, I guess the price point was $20,000
each.
I might be wrong on this, but the total addressable market equaled $200 trillion for these robots
if he sold 10 billion units.
That's twice global GDP, right?
So that's 2x what the world puts out every year.
And he was struggling to understand this.
He's like the money doesn't even make sense at that point.
Like how could the market be that large?
But I think it's one of these type of events you're describing because if you assume there's
5 billion productive people on the earth and we produce 10 billion robots that were 24x7,
well then we have at a minimum tripled human productivity just by producing those robots.
And they don't stay costing $20,000.
Exactly.
So the way I looked at this is like, well, that fits perfectly if he thought it was a
$300 trillion market because that means we, if you add that to existing global GDP, you'd
have a $300 trillion market while we tripled human productivity.
So from $100 to $300 trillion, that makes perfect sense.
How that would actually be expressed assuming we're on a sound money system.
Now if you have inflation, then a lot of these gains get stolen to inflation and all these
things.
But if you're on like a Bitcoin standard, then the price, general price level of goods
and services would go down 67%.
That would be the gain for everyone.
But it was just interesting to watch him go through the mental gymnastics of trying and
then being like overwhelmed with the outcome and say, how could that be?
That doesn't make any sense.
I'm like, no, actually, I think it makes perfect sense.
Yeah.
Well, we need to have the understanding that when we calculate economic impacts in this
fashion, we're only ever looking at the starting point.
We're only ever looking at the initial conditions of a self-reinforcing process.
Because if we really say, okay, maybe what we need to do is say, okay, how many robots
could we actually use?
Like assume we can build a robot that can do simple repetitive physical tasks as well
as a human.
How many of those could we put to use?
And then we start to think, well, okay, when we start building them, the first one is going
to cost $100 million.
The second one is going to cost $500,000.
And that's just with what we learn from building them.
And then we move to production and moving to production is very expensive, hundreds
of millions of dollars again.
But eventually we're using the robots to build the robots.
Right.
You're amortizing those fixed costs over more and more units, so they're getting cheaper
and cheaper.
Yeah.
So people always, always, always, always underestimate the value of learning to do something new.
The true value that Henry Ford achieved was how do we make automobiles on an assembly
line?
The true value of these technological innovations is the innovations themselves.
It's not just, oh, we built this product, now we have the product.
We built this product, now we know how to build the product and we build it cheaper.
And this was something that Tesla did very well because they made a very wise decision
to start with the roadster.
Like, okay, we cannot make this thing cheap because we're just figuring out how to do
it.
We're going to make $130,000 rich bands toy and we're going to make it sexy.
And then we're going to learn from that how to make a mass market product.
And when people look at this innovation, they're like, who the hell wants a $50,000 robot that
can do simple repetitive tasks in my kitchen?
Well, if you look at it that way, you're not really understanding what's being proposed
here.
You're not understanding that you're looking at a fundamental transformation in how we
do economy.
And this is why I write science fiction.
Because you have to make people understand or they'll regulate utopia out of existence.
It's almost like the change from animal powered tilling of the soil to industrial agriculture.
The whole energy, while the agent that's doing the work is a whole new agent, it's not even
human anymore.
We've now created an artificial robot to do the work that humans had to do, therefore
freeing up the human to do other things.
And the fear is always that the human won't have anything to do.
And we always find something to do.
And eventually, what we will find to do is, gosh, I'm going to go and play.
I'm going to create art.
I'm going to make podcasts where we have conversations about these things because we
don't have to whack at the dirt with a stick anymore.
Yeah, there's something kind of maybe this is a bad.
There's an implicit.
I'll use the word bad because I think it's bad.
I don't know if it's bad, but this idea that humans need to be employed in something otherwise
they'll do something wrong or be wasteful or destructive.
Whereas maybe we're back to this.
These life philosophy things, right?
I don't know if there's a death morality per se, but this would be the idea that humans
with more freedom are somehow dangerous.
But in fact, it's history tells us the opposite is true.
I think the fear is several fold.
First of all, there's the fears about economic distribution.
Like right now I do a thing and I get paid.
And that's how I put food on my table.
And I don't know how I'm going to survive if that task is automated away.
And it becomes very difficult to imagine how everything becomes cheaper and where before
I needed to earn the equivalent of say $60,000 a year driving a truck where now if the neural
network drives the truck and everything is cheaper and I need less to buy the things
I need so I can have another kind of job that affords me more leisure time and maybe I'm
being paid less in some sort of inflation adjusted dollars, but everything is cheaper.
And the second fear I think is more philosophical and it's something that's held by smarter
and more philosophically inclined people is what will the meaning of my life be if I don't
have productive work to do that one that strikes me is very strange.
Yeah, and I can I can see people that mostly want more freedom.
I can see your eyes rolling and I completely agree because we find when we are freed from
brute labor, we find things to do and those things feel more meaningful.
Yeah, yeah, I was for two decades, I was a software engineer, which was a vast improvement
on my previous careers.
But when I quit software engineering and started writing science fiction novels, it's something
that's maybe less necessary for our survival.
It's more of a luxury, but it felt so much more meaningful to me because I was creating
something out of my own mind with my own hands, you know, that this is something that people
with corporate jobs really, I don't know how to explain it, how it feels when you when
you make something, when you have an idea in your head, and you make something, whether
it's a book, or it's like a piece of handcrafted furniture where you're going to cut all the
lumber and fit all the corners and sand it down and varnish it so it's really nice.
And you can sell it, and it pays your bills.
And you don't have to be sitting in an office somewhere going to meetings where you have
to you have to say, oh, this is meaningful because people pay money for it.
And you get to substitute, no, this is meaningful because people come up to me and tell me that
they love it where you don't have to rely on that abstract fucks given signaling mechanism
of money, where people will just come up to you and say, I love this, you know what I'm
talking about.
Oh, yeah.
Dude, it's so funny.
Like, yeah, to see the fucks being given face to face is like magical, especially if you
get to do something that you give a fuck about, right, like you enjoy writing the book, right?
And then someone comes to you having read the book and said, thank you, this improved my
life.
Yeah, I love this.
You're aligning the fucks given so, yeah, and viscerally, yeah, and although you need
to do it abstractly, it reduces that signal distortion that we have in the modern money
system.
Right.
And maybe there will be less signal distortion if we're able to move to less gameable currencies.
But there's always some real value in just doing, making something that comes from you.
Yes.
And I feel like there is just a tremendous upside in moving human beings out more and
more out of the work that is out of the cubicles into the entrepreneurship.
Out of the work that is required to sustain life.
And into the work that is required to make life enjoyable and rich and fulfilling.
Yes.
You know, it's more satisfying to make people happy.
Yeah.
Yeah.
And, you know, it's maybe very fulfilling to be like, I'm a farmer, I grow food and
that keeps people alive.
But you know, if you're a farmer with a legion of robots and you're feeding a million people
instead of 2,000, maybe that's more meaningful too.
Yeah.
And to try to bring this into a modern setting, there is a lot of fear in the creative slash
professional occupations, right?
Let's say animators, attorneys, accountants, fear of AI, displacing their jobs.
But in reality, it's, it's liberally like that is the idea of technology automating
away drudgery.
Right.
Right.
I mean, I work with a few different attorneys is like, I don't think I love their job.
I mean, maybe there's some attorneys that are really good at what they do and they've
had a meaningful career and all of that.
But if you could do some of this stuff, it's you already see AI starting to impact the legal
profession.
If you could do some of that stuff without so much human touch, it would be better.
Obviously, if we could resolve disputes over private property through some kind of automated
mechanism, that would be a lot better than chains of emails and back.
The AI is coming up from the bottom.
It's coming up from the most basic and dull and boring human capabilities.
So when I look at AI as it exists right now, I'm not talking about the technological singularity
because that's by definition unpredictable.
But as AI exists right now, the parts of each task that it automates away are the dullest
and most boring parts.
Read this 900 page report and summarize it for me.
Yeah.
Yeah.
Yeah.
So it's embrace it, right?
There's nothing to be afraid of actually.
It's freeing people.
That's why I was rolling my eyes earlier because it's like, freedom is staring people in the
face and yet they're scared of it.
It's like, freedom is the same thing you're pursuing when you go to work, right?
You're pursuing money.
What do you want the money?
You want the money to be free?
Freedom is scary because freedom is responsibility.
If you are free and by freedom I mean that outcomes to you are determined by your choices,
that you have control over your life, then that is scary because people think, well,
what if I fail?
What if it's all up to me, then I might drop the ball.
It feels less scary to be in a system where you're insulated from the consequences of
your actions and the outcome is predictable.
We're back to that bubble, right, where people are hurting near the center.
What people don't understand, I think, and this has been such an overwhelmingly joyful
experience becoming an author and publishing my debut novel independently out of my home
in East Nowhere, Tennessee and just like one novel, and I can pay my mortgage off.
I mean, I'm not getting rich, but I'm paying the bills off one book that I wrote and imagine
what the future looks like.
People think, oh, God, that's so scary.
It's like, no, you don't understand.
You can get on the internet and sell something and people will actually pay you money and
you will survive.
It can be done.
It's not as hard as you think.
I have to ask you that, as you were saying that, we're back to that talk earlier, right,
where the sorting of people, right, the people that want more stability, more predictability,
go to the center of the bubble and the frontiersmen go to the exterior of the bubble.
People like us, if I may be so presumptuous, that have pro-life, pro-civilization,
let's say not pro-life, that term has been pro-progress, pro-humanity, pro-humanity,
pro-civilization, life philosophies and outlooks.
We're embroiled in this culture war thing now.
How can we win that war?
It seems like, especially in social media world, if it bleeds, it leads, has become amplified.
What we're saying here is sort of inherently optimistic.
How do we compete in this culture war and win on behalf of human civilization itself?
Well, to win the culture war, you have to fight it.
And I think that's what people think that that's incredibly difficult,
because Team Western civilization has not been fighting the culture war.
What Team Western civilization has been doing is saying, oh, those crazy artists over there,
they're just a bunch of commie lunatics.
I do real work because I'm a truck driver or a firefighter or, you know, I'm a farmer or whatever.
And that's great, but culture matters, because culture is upstream of everything.
And I think right now, we kind of have the pundits we deserve, sort of on the right,
where you get these guys who performatively try to describe themselves as being
hard-nosed realists who are interested in the practical and not in the fantastical.
And I had this realization when I was watching some right-wing conservative YouTube type,
and he says he doesn't read fiction. He mentions this in some kind of conversation.
He says he doesn't read fiction. And then he does this sort of mocking, satirical voice,
tell me a story, daddy, implying that people who read stories are essentially children and
they're frivolous and they're not doing serious stuff. But stories are the DNA of our culture.
And it's like you talk like this and you're complaining that you lose the culture war.
And, you know, we think, oh, we might be tempted to think, oh, you know, winning the culture war
for pro-civilization forces is so hard, because look at all the negativity and fear out there,
and this must be the way the terrain is slanted. No, absolutely not. Pro-civilization forces have
an inherent advantage, because we can actually write good stories and our futures are exciting.
Nobody is actually getting excited about the idea of living in a world where they can only
run their air conditioners two hours a day, because, you know, all the power plants are
shut off. And, you know, nobody is excited about ration chips. Nobody is excited about
putting solar panels on the roof of their grass hut. The reason they have to fight the culture
war so hard is that what they are selling is so unpalatable. The future that we offer is
exciting. We're the ones with the flying cars. We're the ones with the space exploration.
We're the ones with the robot butlers, you know, the Jetsons, that old cartoon. That's our vision
of the future, not theirs. The only reason they are winning is that we're not promoting
our stories. And that is why I write science fiction. That is why I wrote Theft of Fire.
That is why I'm writing the entire Orbital Space series. That is why I'm going to keep writing
stories until I die, because stories make people imagine worlds that are not. And we need to make
the unseen seen in our fiction so that people can lust for it in reality so that they can say,
I want my flying car. I want my robot butler. I want my... I want to colonize the western spiral
arm of the galaxy and have my own planet that I can terraform any way I want.
You know, I want to live in a world that is better. You have to show people the world that is better.
And so, you know, a lot of the... We have allowed the institutions that used to promote
this positive vision of the future in our art and in our stories. You know, Manhattan, traditional
publishing, and Hollywood, we've allowed them to be subverted by anti-civilizational Marxist forces.
And when I came to the point where, okay, I'm going to launch a career of telling a different
kind of story because I want a different kind of story to be told, I said, well, okay, I have to
bypass these people. But the wonderful thing is you can. I didn't need anybody's permission to
sit down and write. And because we have Amazon and we have print on demand and we have ebooks,
I didn't need anyone's permission to publish. And, you know, now I've taken the next step
with this first novel, as I'm working on the second, is I'm doing a full cast audio book,
which is the next sort of more accessible media where I found some voice actors and we're recording
it with different voices for all the different characters. And, you know, we're launching the
Kickstarter to fund it later this month, but it's accessible because you don't need a big studio,
you just need a hope to get a bunch of people together and just do it. And it's become cheap
enough that you can raise the money. And it doesn't stop there because the future of these AI tools,
of these better computer tools, is that in maybe five to 10 years, you're going to see
animation studio in a box where, like, now you don't need to,
you don't need to, oh, I'm being told that while this airs, the Kickstarter will be running.
So I've been, I've been tripped up by the temporal magic of prerecording.
We will link to it. But the next step is that, you know, these independent authors
is that now you have these better animation toolkits and so forth where 10 years from now
may be, in order to make a miniseries, in order to make a movie, you don't need to get
optioned by Hollywood where, you know, they're going to devote a $200 million animation budget
to make your movie and you have to grovel on your knees to these weirdos like Weinstein or
whatever. You know, have you seen Godzilla minus one? It is an excellent film. It is not just a
big stompy monster movie. It is just a great story with a plot that has a big stompy monster.
But the real, the important thing about it is that they made a Hollywood blockbuster quality
movie on a budget of, guess how much? I have no clue. $16 million. Wow. It's called Godzilla minus
one? Godzilla minus one. Yeah, it's a Japanese production. They made it for $16 million. They
absolutely did a better job than these $200 million, $300 million, $400 million, you know,
cape stuff, Hollywood, you know, slop. And so think what the technology is going to be like
in five or 10 years. Now it's like, oh, I just need some computers and to hire like
five or 10 animation guys. Now it's like, okay, I need two, three, four million dollars to do an
entire animated mini series of my book. Well, if you have a wildly successful novel, you can go to
some of these like, you know, people, investors, and you can say, hey, we're making a movie.
You know, do you want in? Look at how well the book sold. Yeah. There's an almost unlimited upside
for using these advances in technology to fight the culture war so that we can promote further
advances in technology. So, you know, we can use the technology to, you know, proselytize.
Like a positive feedback loop because the technology it's, well, they say science fiction
precedes science fact. Yeah. All right. So as we get the fact and we get better technology,
you use the technology to paint the picture of newer, future, better technology,
wash, rinse, repeat. You just have to get that spiral running. We have to tell the
stories that get people excited about the future instead of afraid of the future.
That's a beautiful place to bring it to a close, I think. Devin, thank you, man. This has been a
heck of a conversation. We covered a lot of ground. Yeah. Thank you for inviting me. It's been
wonderful to actually get to have the second conversation in person in your lovely studio.
Yes. It's so much richer in person. So thank you for inviting me.
Let's go have some dinner. Thank you again for doing this.
