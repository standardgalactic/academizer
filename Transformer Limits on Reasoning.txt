From: 
Snapshot-Content-Location: https://chat.openai.com/c/f8b09b73-f937-4ed7-a356-5aecf945492d
Subject: Transformer Limits on Reasoning
Date: Tue, 20 Jun 2023 01:01:52 -0000
MIME-Version: 1.0
Content-Type: multipart/related;
	type="text/html";
	boundary="----MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----"


------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: text/html
Content-ID: 
Content-Transfer-Encoding: binary
Content-Location: https://chat.openai.com/c/f8b09b73-f937-4ed7-a356-5aecf945492d

Transformer Limits on ReasoningOpen sidebarTransformer Limits on ReasoningModel: Default (GPT-3.5)Faith and Fate: 
Limits of Transformers on Compositionality 
Nouha Dziri1â, Ximing Lu1,2â, Melanie Sclar2â, Xiang Lorraine Li1â , Liwei Jiang1,2 â , 
Bill Yuchen Lin1, Peter West1,2, Chandra Bhagavatula1, Ronan Le Bras1, Jena D. Hwang1, 
Soumya Sanyal3, Sean Welleck1,2, Xiang Ren1,3, Allyson Ettinger1,4, 
Zaid Harchaoui1,2, Yejin Choi1,2 
1Allen Institute for Artif i cial Intelligence2University of Washington 
3University of Southern California4University of Chicago 
nouhad@allenai.org, ximinglu@allenai.org, msclar@cs.washington.edu 
Abstract 
Transformer large language models (LLMs) have sparked admiration for their 
exceptional performance on tasks that demand intricate multi-step reasoning. Yet, 
these models simultaneously show failures on surprisingly trivial problems. This 
begs the question: Are these errors incidental, or do they signal more substantial 
limitations? In an attempt to demystify Transformers, we investigate the limits of 
these models across three representative compositional tasksâmulti-digit multi- 
plication, logic grid puzzles, and a classic dynamic programming problem. These 
tasks require breaking problems down into sub-steps and synthesizing these steps 
into a precise answer. We formulate compositional tasks as computation graphs to 
systematically quantify the level of complexity, and break down reasoning steps 
into intermediate sub-procedures. Our empirical i ndings suggest that Transformers 
solve compositional tasks by reducing multi-step compositional reasoning into 
linearized subgraph matching, without necessarily developing systematic problem- 
solving skills. To round off our empirical study, we provide theoretical arguments 
on abstract multi-step reasoning problems that highlight how Transformersâ perfor- 
mance will rapidly decay with increased task complexity. 
1Introduction 
âIt was the epoch of belief, it was the epoch of incredulity.â â Charles Dickens, A Tale of Two Cities 
Large-scale Transformers such as ChatGPT [41] and GPT-4 [42] demonstrate unprecedented capa- 
bilities [41,57,9,12,66], even noted as âsparks of AGIâ [10]. In stark contrast, the same models 
sometimes struggle with simple, intuitive tasks [8,45,35]. For instance, humans can solve 3-digit 
by 3-digit multiplication arithmetic after learning basic calculation rules [19,29]. Yet, off-the-shelf 
ChatGPT and GPT4 achieve only 55% and 59% accuracies on this task, respectively (Â§3). 
The striking discrepancy between the impressive successes of Transformers on seemingly complex 
tasks and the astonishing failures on seemingly trivial tasks spark critical open questions about how 
to faithfully interpret their mixed capabilities. Under what conditions do Transformers succeed, fail, 
and why? What types of errors do they make? Can Transformers uncover implicit problem-solving 
rules or be taught to follow reasoning paths? 
â First co-authors. 
â  Second co-authors. 
Preprint. Under review. 
arXiv:2305.18654v2 
[cs.CL] 
1 
Jun 
2023 
Seeking thorough answers to these questions remains an open research challenge. However, we offer 
novel insights into the fundamental limits of Transformer LLMs, centered around compositional 
problems that require strict multi-hop reasoning to derive correct predictions. Applying step-by-step 
reasoning is fundamental to human intelligence [52,51]. These compositional problems present 
compelling challenges for AI systems as they require combining basic reasoning operations to 
follow computational paths that arrive at unique correct solutions. In particular, we study three 
straightforward and l exible representative compositional tasks: long-form multiplication, logic grid 
puzzles (i.e., Einsteinâs puzzle [44]), and a classic dynamic programming problem.1 / 1ChatGPTChatGPTThe paper you mentioned, "Faith and Fate: Limits of Transformers on Compositionality," aims to investigate the limitations of Transformer-based large language models (LLMs) like GPT-4 and ChatGPT when it comes to compositional tasks.Compositional tasks, in this context, are problems that require multi-step reasoning, breaking down a problem into several sub-problems and combining their solutions to arrive at the final answer. This is a critical aspect of human intelligence. Examples of such tasks include multi-digit multiplication, logic grid puzzles like Einstein's puzzle, and certain dynamic programming problems.The authors argue that despite the impressive capabilities demonstrated by these LLMs, they sometimes falter on tasks that humans find relatively simple once they learn the basic rules. For instance, humans can reliably perform 3-digit multiplication, but the tested models only achieve 55% and 59% accuracies on this task.The authors aim to explore this dichotomy, offering insights into the fundamental limitations of these models. They formulate the tasks as computation graphs to quantify their complexity and break down the reasoning into sub-procedures. Preliminary findings suggest that Transformers attempt to solve these problems by reducing them to linearized subgraph matching, rather than developing systematic problem-solving skills.The study implies that while LLMs can accomplish impressive feats, their ability to handle complex reasoning tasks has significant limitations. They are not yet able to replicate the depth of compositional reasoning that human intelligence can perform. This paper could inform future efforts to enhance the reasoning capabilities of AI models.1 / 1We propose two hypotheses. First, Transformers solve compositional tasks by reducing multi-step 
compositional reasoning into linearized path matching. This contrasts with the systematic multi-step 
reasoning approach that learns to apply underlying computational rules required for building correct 
answers [54,32,24]. Shortcut learning [26] via pattern-matching may yield fast correct answers 
when similar compositional patterns are available during training but does not allow for robust 
generalization to uncommon or complex examples. Second, due to error propagation, Transformers 
may have inherent limitations on solving high-complexity compositional tasks that exhibit novel 
patterns. Errors in the early stages of the computational process can lead to substantial compounding 
errors in subsequent steps, preventing models from i nding correct solutions. 
To investigate our hypotheses, we formulate compositional tasks as computation graphs. These graphs 
break down problem-solving into submodular functional steps, enabling structured measurements 
of complexity and verbalization of computational steps as input sequences to language models. 
Moreover, we leverage information gain to predict patterns that models are likely to learn based on 
the underlying task distribution without the need to perform full computations within the graph. 
Empirical results show that training on task-specif i c data leads to near-perfect performance on in- 
domain instances and under low compositional complexity, but fails drastically on instances outside 
of this region. This substantial gap suggests that systematic problem-solving capabilities do not 
emerge from maximum likelihood training [5] on input-output sequences, even when prompted or 
trained with human-like reasoning steps (i.e., a linearization of computation graphs; Â§3.1). Modelsâ 
success can be attributed, in part, to their exposure to training examples sub-graphs that involve 
the same computations required for solving test examples (see Section 3.2.2) In order to gain a 
deeper understanding of modelsâ failures, we conduct a comprehensive analysis by decomposing 
their computation graphs and examining different error types. We i nd that while models can 
memorize single-step operations, they fail to compose them into correct reasoning paths, suggesting 
that they mostly make predictions based on shallow, rote learning rather than a deep, holistic 
task understanding (Â§3.2.3). Importantly, we provide theoretical evidence of exponential error 
accumulation using abstract compositional tasks. All tasks analyzed empirically in this paper are 
instantiations of these abstractions (Â§4). We argue that Transformers could be inherently limited in 
solving compositionally complex tasks out-of-the-box. 
As Transformers continue to make tangible real-world impacts, it is pressing to interpret their 
remarkable performance critically. Our work takes a realistic look at the limitations of Transformers 
in the context of compositional tasks. To shed light on practical future steps, we identify directions 
for addressing these limitations, such as using Transformers for tasks that could be decomposed into 
few reasoning steps, tasks where evaluation may afford some leniency, and using Transformers in 
combination with planning modules or ref i nement methods to improve their generations. To advance 
language AI, fundamental innovations are required to address or complement these limitations. 
2Measuring Limitations of Transformers in Compositional Tasks 
Human problem-solving skills can be conceptualized as a graph structure, where each vertex repre- 
sents a partial solution and the edges represent operators that can be applied to modify these solutions. 
As we will outline next and illustrate in Figure 1, we use computation graphs and corresponding 
metrics to methodically evaluate Transformersâ reasoning abilities.1 / 1ChatGPTChatGPTIn the paper, the authors propose two hypotheses regarding Transformers and compositional tasks. The first hypothesis is that these models attempt to solve tasks by turning multi-step reasoning into linearized path matching, using a pattern-matching approach, rather than learning and applying the computational rules necessary to systematically solve problems. This might work for familiar problem patterns but can limit the model's ability to generalize to new or more complex examples.The second hypothesis posits that due to error propagation, Transformers may struggle with high-complexity tasks featuring novel patterns. Early errors in the computational process can lead to significant compounded mistakes in subsequent steps, hampering the model's ability to find the correct solution.To evaluate these hypotheses, the authors formulate the tasks as computation graphs, breaking down problem-solving into smaller, more manageable steps. They also use information gain to predict patterns that the models are likely to learn, based on the underlying task distribution.Empirical findings suggest that Transformers perform well on in-domain instances and tasks of low complexity. However, they fail significantly on instances outside of this scope. This gap implies that systematic problem-solving abilities don't emerge from maximum likelihood training on input-output sequences, even with human-like reasoning prompts. The models seem to succeed due to their exposure to training examples of sub-graphs involving similar computations required to solve test examples. But a comprehensive analysis shows that while the models can memorize single-step operations, they struggle to compose them into correct reasoning paths, suggesting a reliance on shallow learning rather than a deep understanding of the task.Furthermore, the authors provide theoretical evidence of exponential error accumulation using abstract compositional tasks. They argue that Transformers might inherently struggle to solve compositionally complex tasks out-of-the-box.Addressing these limitations may require using Transformers for tasks that can be broken down into fewer reasoning steps, allowing some leniency in evaluation, or combining Transformers with planning modules or refinement methods to enhance their outputs. However, overcoming these limitations will require fundamental innovations in language AI.For evaluation, the authors use computation graphs and corresponding metrics, which allow them to evaluate the reasoning abilities of the Transformers systematically and analytically.1 / 12.1Computation Graph Def i nition 
LetAbe a deterministic algorithm (function), and letFAbe 
a set of primitives (functions) the 
algorithm uses in its execution. Assuming the inputsxto algorithmAare given, we def i neA(x)âs 
2 
for 
A(x) 
x = [7,49] 
function multiply (x[1..p], y[1..q]): 
// multiply x for each y[i] 
for i = q to 1 
carry = 0 
for j = p to 1 
t = x[j] * y[i] 
t += carry 
carry = t // 10 
digits[j] = t mod 10 
summands[i] = digits 
// add partial results (computation not shown) 
product = 
return product 
âq i=1summands[q+1-i]â 10i-1A(x) 
multiply 
1-digit carryconcatmod 
10sum 
Color 
legend: 
7 
4 
9 
28 
63 
2 
6 
8 
14 
13 
4 3 
343 
Figure 1:Transformation of an algorithmAto its computational graphGA(x). The depicted example is of 
long-form multiplication algorithm A, for inputs x = [7,49] (i.e. computing 7 Ã 49). 
static computation graphGA(x).GA(x)= (V, E, s, op)is a directed acyclic graph. NodesV 
represent all variablesâ values duringAâs execution: each nodev â Vhas 
a values(v) â R 
associated. EdgesErepresent the function arguments involved in some computation: for each non- 
source nodev â V, letU = {u1,...,uj} â V 
j be its parent nodes. Then,s(v) = f(u1,...,uj) 
for somef â FA. 
Since each nodevis uniquely def i ned by the computation of a single primitivef, 
we def i ne op : V â FAas 
op(v) = f. 
LetS â Vbe 
the source nodes ofGA(x)and without loss of generality, leto â Vbe 
its sole leaf 
node. By def i nition, S â¡ x and A(x) = s(o), representing the input and output of A respectively. 
TobeabletotrainandevaluatealanguagemodelâsabilitytofollowalgorithmAwemustlinearizeGA(x). 
Since we only consider autoregressive models, this linearization must also be a topological ordering. 
2.2Quantifying Compositional Complexity using Graph Metrics 
AâsrepresentationasacomputationgraphGA(x)enablesmeasuringtaskcomplexityfrommanyangles. 
We def i ne a nodev â Vâs 
layer number as the length of the longest path from a source node tovin 
the directed acyclic graphGA(c). We then def i ne the reasoning depth as the largest layer number in 
the graph. In computation graphs, reasoning depth is a proxy for the maximum level of multi-hop 
reasoning required to solve the task. 
LetdS: V â N0be 
the shortest distance to any ofGâs source nodesS â V. 
We def i ne the 
reasoning width of a graph as the mode of{d(v) : v â V }. 
This metric aims to measure the 
maximum number of variables required to maintain in parallel during the computation. Relatedly, we 
also def i ne the average parallelism of a graph as the ratio between|V |and 
its reasoning depth. This 
aims to compute the average width in computation through the graph, and not just in its mode. 
2.3Predicting Surface Patterns through Relative Information Gain 
When evaluating model performance, we may observe partially correct answers even in an overall 
incorrect response. To understand model strategies in these partial successes, we use Relative 
InformationGaintopredictsurfacepatternsthatmodelsarelikelytorecognize. WerepresenttaskTas 
a distribution(X1,...,Xn,Y1,...,Ym)and measure the amount of (normalized) information gained 
about an output element Yjby observing a subset of input random variables X â {X1,...,Xn}: 
RelativeIG(Yj,X) = H(Yj) â H(Yj|X) 
H(Yj) â [0,1](1) 
RelativeIG may be used to analyze the inf l uence of any node in the computation graph (as def i ned in 
Â§2.1) with respect to a set of its ancestors; in particular, output nodes with respect to input nodes.1 / 1ChatGPTChatGPTSection 2.1 defines computation graphs, which are used to illustrate an algorithm's execution as a directed acyclic graph (DAG). Nodes in the graph represent variable values during the algorithm's execution, while edges signify function arguments involved in a computation. Each node has an associated function (primitive) that gives it its value, and each node is defined by the computation of a single primitive. This graph structure encapsulates the process and steps involved in the execution of an algorithm and allows for a more comprehensive evaluation of a Transformer model's reasoning abilities.In Section 2.2, the authors propose metrics to quantify the complexity of tasks represented as computation graphs. They define a node's layer number as the length of the longest path from a source node to it in the graph. The reasoning depth is the largest layer number in the graph and serves as a measure of the maximum level of multi-hop reasoning needed to solve a task. The reasoning width of a graph is defined as the mode of the shortest distances from all nodes to any source node, measuring the maximum number of variables required to maintain concurrently during the computation. Additionally, the average parallelism of a graph is defined as the ratio between the total number of nodes and its reasoning depth, providing a measure of the average width of computation through the graph.Section 2.3 introduces Relative Information Gain as a method to predict patterns that models are likely to recognize. By observing a subset of input random variables, the authors measure the normalized information gained about an output element. This can be used to analyze the influence of any node in the computation graph with respect to a set of its ancestors, particularly output nodes with respect to input nodes.1 / 12.4Exploring Three Representative Compositional Tasks: Def i nitions 
MultiplicationMulti-digit multiplication requires executing operations with numerical symbols 
based on procedural rules [29]. This task has multiple algorithmic solutions; in constructing computa- 
3 
051015 
Average parallelism 
0.5 
0.0 
0.5 
1.0 
1.5 
Accuracy 
GPT4 zero-shot (Multiplication) 
(b) 
Figure 2: (a)Zero-shot accuracy. Axes refer to problem sizes (number of digits in multiplication, number of 
houses and attributes in puzzle, and sequence length in the DP task). Transformersâ accuracy decreases to near 
zero as task complexity increases, measuring task complexity by the problem size. (b) Average parallelism 
negatively correlates with accuracy. 
tion graphs, we use the well-knownO(k1k2)long-form multiplication algorithm for computingx Â· y, 
wherexhask1â¤ 5digits andyhask2â¤ 5digits 
in base 10. See Â§A.1 for data construction details. 
To instantiateGA(x), letFA= {one-digit multiplication, sum, mod 10, carry over, concatenation}. 
Source nodesSare digits of input numbers, leaf nodeois the i nal output, and intermediate nodesv 
are partial results generated during execution of the long-form multiplication algorithm (see Figure 1). 
Einsteinâs PuzzleEinsteinâs puzzle is a well-known logic puzzle often used as a benchmark for 
solving constraint satisfaction problems [44]. It involves a list of houses with different attributes (e.g., 
ownerâs name, pets), and the goal is to determine which attributes belong to each house by combining 
a set of pre-def i ned natural language clues or constraints. The solution to the puzzle is a matrix of 
sizeK Ã M, 
whereKrepresents the number of houses andMthe number of attributes. AsKand 
Mincrease, synthesizing different partial solutions that satisfy individual constraints becomes highly 
compositionally complex. To construct the computation graph, we consider a greedy algorithm that 
iteratively eliminates possible solutions by i lling at least one cell each time. It deterministically i lls 
the cell(s) that requires the minimum number of clues among all current unf i lled cells. We refer to 
this as the elimination function. See Â§A.2 for examples, data construction, and algorithm details. 
To instantiateGA(x), letFA={elimination function}. 
The source nodes are the clues, all intermedi- 
ate nodes are partially-f i lled matrices, and the output node is a fully-f i lled solution matrix. 
Dynamic Programming ProblemDynamic programming (DP) recursively breaks down complex 
problems into simpler sub-problems, so problems solved using this technique are compositional. We 
analyze a classic relaxation of the NP-complete Maximum Weighted Independent Set problem [34]: 
Given a sequence of integers, i nd a subsequence with the highest sum, such that no two numbers in 
the subsequence are adjacent in the original sequence. This relaxation may be solved inO(n)time 
using DP. See the solution in Â§A.3. In the experiments, we restrict each integer to the [â5,5] range. 
To instantiateGA(x), letFA= {equals, and, not,indicator function, sum, max}. Source nodes are 
elements of the input list, and the output node is a list that for each element indicates whether it 
should be selected. We select anO(n)algorithm sinceGA(x)âs size is proportional toAâs complexity.1 / 1ChatGPTChatGPTSection 2.4 introduces three different compositional tasks that will be used to evaluate Transformer models' performance:Multiplication: This task involves multi-digit multiplication, requiring operations with numerical symbols based on procedural rules. The authors use the long-form multiplication algorithm in constructing computation graphs. The source nodes are the digits of the input numbers, the leaf node is the final output, and intermediate nodes are the partial results generated during the execution of the multiplication algorithm.Einstein's Puzzle: This is a well-known logic puzzle used as a benchmark for constraint satisfaction problems. It involves a list of houses with different attributes, and the goal is to determine which attributes belong to each house by combining predefined natural language clues or constraints. The computation graph construction uses a greedy algorithm that eliminates possible solutions by filling at least one cell each time. The source nodes are the clues, the intermediate nodes are partially filled matrices, and the output node is a fully-filled solution matrix.Dynamic Programming Problem: This involves a classic relaxation of the NP-complete Maximum Weighted Independent Set problem. Given a sequence of integers, the task is to find a subsequence with the highest sum, such that no two numbers in the subsequence are adjacent in the original sequence. This problem is solved using dynamic programming. In the computation graph, source nodes are elements of the input list, and the output node is a list that indicates whether each element should be selected.These tasks are used to investigate how Transformers perform on different types of compositional tasks and measure their reasoning abilities.1 / 13Testing the Limits of Transformers: Empirical Evidence 
ExperimentalSetupTounderstandthecapabilitiesofLLMs,weevaluateGPT3 
(text-davinci-003) [9], ChatGPT (GPT-3.5-turbo) [41] and GPT4 (gpt-4) [42] using zero- 
shot, few-shot, and i netuning techniques. To enable the generation of computation graphs beyond 
the i nal answers, we use the concept of scratchpads [40]. Scratchpads are a verbalization of the 
computation graphs (i.e., a linearized representation of a topological ordering ofGA(x)). Overall, we 
consider question-answer and question-scratchpad formats for few-shot and i netuning settings to 
gauge modelsâ capabilities for learning with and without explicit reasoning. See details of additional 
models and experimental conf i gurations in Â§B and examples of scratchpad in Â§A. 
4 
3.1Testing the Limits of Transformers with Zero-shot, Few-shot and Finetuning 
Limits of Transformers in zero- and few-shot settingsTo investigate the inherent problem-solving 
capabilities of LLMs, we begin by analyzing modelsâ zero-shot and few-shot performances on our 
compositional tasks. As shown in Figure 2, task performances deteriorate signif i cantly from near 
perfection to zero with increasing complexity when measured by either problem size (Figure 2(a))or 
average parallelism (Figure 2(b)).The trend remains the same for few-shot prompting (see Â§B.2). 
These results indicate that pre-training is in fact not suff i cient to teach models how to combine basic 
operations to solve compositional problems, especially as problems grow more complex. 
Limits of Transformers with question-answer trainingThe limited performance of models 
may be attributed to the lack of task-specif i c data during pre-training. To fully bring out modelsâ 
potentials in solving these tasks, we next exhaustively i netune GPT3 with question-answer pairs. In 
multiplication and DP, we i netune models with all enumerations of questions up to the maximum 
problem size3within reasonable training budget, leaving out 10% for validation and 10% for testing. 
In puzzles, we train on a subset of all instances up to(K,M) â¤ (4,4)due 
to combinatorial explosion. 
We separately i netune GPT3 models onâ¼1.8M 
multiplication pairs,â¼142K 
DP pairs, andâ¼41K 
puzzle pairs (see details in Â§B.3). Additionally, to examine problems of different complexity, we 
consider different training splits based on the depth and width of computation graphs. 
Figure 3:GPT3 i netuned exhaustively on task- 
specif i c data up to a certain problem size. The blue 
region represents the in-distribution examples and 
the red region refers to OOD examples. The same 
trend is observed for the puzzle task (See Â§B.2) 
Figure 3 and Figure 4a show high accuracy for exam- 
ples with splits seen during training, i.e., in-domain. 
However, the performance sharply declines when 
evaluating unseen splits during training, i.e., out-of- 
domain (OOD). Similar trends hold in all tasks (see 
Â§ B.3), suggesting that systematic problem-solving 
capabilities do not emerge via exhaustive training on 
task-specif i c data. 
Limits of Transformers with explicit scratchpad 
trainingNext, we test whether we can explicitly 
teach models the required computational operations 
via scratchpads. To do so, we i netune GPT3 with 
question-scratchpadpairsforalltasks. Weconsidered 
the same distribution splits as before. The results, pre- 
sented in Figure 4b, show that once again GPT3 achieves near-perfect performance on in-distribution, 
but fails entirely in generalizing to OOD casesâin particular, wider or deeper computation graphs. 
These results indicate that even when training directly with guidance on the computation steps, 
models still fail to learn component operations in a generalizable manner. This observation holds 
for all tasks (See details in Â§ B.4). These i ndings suggest that the autoregressive characteristic of 
Transformers, which forces them to tackle problems sequentially, presents a fundamental challenge 
that cannot be resolved by instructing the model to generate a step-by-step solution. Instead, models 
face the fundamental challenge of simply depending on a greedy process of producing the next word 
to make predictions without a rigorous global understanding of the task. 
3.2Breaking Down Successes and Failures of Transformers 
3.2.1Information Gain Explains Where Transformers Partially Excel 
At times Transformers predict partially correct answers even when the overall response is incorrect. 
We speculate that this may be due to particularities in the task distribution that allow for guessing 
partial answers without performing the full multi-step reasoning that the task requires. 
Using relative information gain (def i ned in Â§2.3), we can predict surface patterns that a model is 
likely to learn and contrast them empirically. For multiplication, relative information gain shows that 
the i rst digit (two digits) of the output highly correlates with the i rst digit (two digits) of each input 
number (see Â§C.1). Hence, this spurious pattern is likely to be learned by a model. Similarly, the 
prediction of the last digit (or two digits) of the output is observed to solely rely on the last digit (or 
3We consider all k1-by-k2digit multiplications with1 â¤ k1,k2â¤ 4andk1Â· k2â¤ 9; and all DP problems 
up to 5 elements. We selected sizes based on budget constraints for GPT3 i netuning, see Â§B.3 for cost details.

(a) Results on question-answer pairs.(b) Results on question-scratchpad pairs. 
Figure 4:GPT3 i netuning and prompting accuracy on different data splits. Although the in-distribution 
performance is almost perfect, GPT3 exhibits poor generalization with increasing graph depth and width. Refer 
to Â§B.3 and Â§B.4 for results on the puzzle and DP tasks. 
two digits) of each input number. This pattern holds true due to the principles of modulo arithmetic, 
which ensures the validity of this relationship in all cases. Empirically, we verify that models indeed 
learn the patterns we predicted and other patterns as well (e.g., order of magnitude of the answer, 
number of trailing zeros for multiplication) in all the settings with and without scratchpad. See details 
for multiplication, plus dynamic programming task analysis in Â§C. 
These experiments suggest that if an output element heavily relies on a single or a small set of input 
features, Transformers are likely to recognize such correlation during training and directly map these 
input features to predict the output element in testing, without going through the rigorous multi-hop 
reasoning and giving a false illusion of performing compositional reasoning. 
3.2.2Transformers Reduce Multi-Step Compositional Reasoning into Linearized Subgraph 
Matching 
We now explore whether modelsâ correct predictions on unseen test data are due to learning the un- 
derlying algorithm or, instead, explainable by exposure to similar training examples. We hypothesize 
that, beyond simple memorization, Transformers largely rely on pattern matching for solving these 
tasks. To test this, we calculate the average frequency with which partial computations needed to 
solve an instance appear in the training data, for both correctly and wrongly predicted examples. 
Given a model-generated computation graph b 
GA(x)we analyze how often the full computation of 
each nodev â b 
Vis seen in training. We def i nevâs full computation as the subgraph induced by all 
ancestors ofvincludingv, denotedFCb 
GA(x)(v). We say thatFCbGA(x)(v)is 
seen during training if 
FCb 
GA(x)(v) â¡ FCGA(xâ²)(w)for 
some computation graphGA(xâ²) in training, and for somew â V. 
We characterize complexity of a full computation subgraph by its depth, as def i ned in Â§2.1. 
Figure 5 shows that full computation subgraphs appear signif i cantly more frequently in the training 
data for correctly predicted test examples than for incorrectly predicted ones, for both the multi- 
plication and DP task (both frequencies tend to zero for large depths since we ensured a disjoint 
train/test split). This high correlation suggests that pattern matchingâand not general reasoning 
capabilitiesâmay be the cause behind correct model outputs. This type of learning could be largely 
effective when the compositional complexity of tasks is low but it becomes less eff i cient when tasks 
are increasingly complex. This may elucidate the observed performance gain in low-complexity and 
in-domain cases and the striking performance drop in OOD and highly complex cases.1 / 1ChatGPTChatGPTSection 3 of the paper investigates the performance of large language models (LLMs), specifically GPT-3, ChatGPT (GPT-3.5-turbo), and GPT-4, on the three compositional tasks previously defined: Multiplication, Einstein's Puzzle, and the Dynamic Programming Problem.The authors carry out experiments using zero-shot, few-shot, and fine-tuning techniques. Additionally, the authors use the concept of scratchpads, which are a verbalization of the computation graphs, enabling generation beyond final answers.Limits of Transformers in zero- and few-shot settings: The models' performance on the compositional tasks deteriorates significantly as task complexity increases. This suggests that pre-training is not enough to teach models how to combine basic operations to solve complex problems.Limits of Transformers with question-answer training: Even with exhaustive fine-tuning on task-specific data, models struggle to generalize problem-solving capabilities to unseen examples (out-of-domain cases). Their performance drops sharply when tested on problems they were not trained on.Limits of Transformers with explicit scratchpad training: Even when models are trained directly on computation steps, they still struggle to generalize to cases not seen during training. This points to a fundamental challenge of the autoregressive nature of Transformers, which leads them to depend on a greedy process for next-word prediction rather than having a more holistic understanding of tasks.Further analysis reveals some insights:Information Gain Explains Where Transformers Partially Excel: The Transformers sometimes predict partially correct answers. This is because they can recognize correlations between input features and output elements during training and use them to guess answers, giving the illusion of compositional reasoning.Transformers Reduce Multi-Step Compositional Reasoning into Linearized Subgraph Matching: Correct predictions seem to be linked to pattern matching rather than learning the underlying algorithm of tasks. Correctly predicted examples have a significantly higher frequency of partial computations seen during training. This pattern matching approach is only effective for less complex tasks and fails for out-of-domain or highly complex cases.In summary, despite their impressive performance on a variety of tasks, Transformers struggle with compositional tasks, especially as complexity increases. Their limitations stem from a fundamental characteristic of their design, relying on pattern matching rather than developing a more comprehensive understanding of tasks.1 / 13.2.3What Types of Errors do Transformers Make at Different Reasoning Depths? 
For clearer understanding of where Transformers fall short, we analyze the types of errors that 
transformers make for nodes at different layers in the computation graph. For every inputx, we 
compare the ground truth computation graphGA(x)with the (possibly incorrect) model-generated 
computation graph b 
GA(x). We consider a nodevas having a correct value if and only ifs(v) = b s(v).4. 
We consider a nodevto be derived from a correct computation if given thatU = {u1,...,uk}are 
the immediate predecessors ofvin b 
GA(x)and thatb op(v) = f, 
we have thatf(u1,...,uk) = b s(v). 
4If a node v does not appear in the ground truth graph G, we consider it to have an incorrect value. 
6 
avg. 
freq. 
in training 
data 
Fine-tuned GPT3- Multiplication 
avg. 
freq. 
in training 
data 
(log) 
Fine-tuned GPT3- Dynamic Prog. 
Correct Final AnswerIncorrect Final Answer 
Fine-tuned GPT3- DP 
Figure 5:Average frequency in 
which test examplesâ full computa- 
tions subgraph appear in the train- 
ing data w.r.t.the subgraph depth, 
grouped by i nal answer. 
Fully CorrectLocal ErrorPropagation ErrorRestoration Error 
Five-shot GPT4 â DP 
Fine-tuned GPT3 â DP 
Five-shot GPT4 â MultiplicationFive-shot GPT4 â Puzzle 
Figure 6:Ratio of nodes in each of the four correct/error categories 
for each layer in computation graph. Results shown are for few-shot 
prompting and i ne-tuning with scratchpad. 
Note that the notion ofcorrect computationis independent ofG, and that a nodevderived from a 
correct computation may not have the correct value if an error occurred in some of its ancestors. 
We classify each nodev â b 
Vinto one of four categories. Nodevis fully correct ifvand its ancestors 
have correct values and are derived from correct computations. If a nodevis not fully correct, its 
error can be of the following types:vhas a local error if its parent nodes have correct values butvis 
derived from an incorrect computation (i.e., a one-hop reasoning error);vhas a propagation error if 
vis derived from a correct computation but some of its parent nodes have incorrect values;vhas a 
restoration error if it has a correct value but is derived from an incorrect computation. 
Figure 6 shows results for few-shot GPT4 and i ne-tuned GPT3 with scratchpad, with respect to 
graph layer number for each node. In all settings, the ratio of fully correct nodes is almost perfect 
but sharply decreases toward zero with increasing graph layers. Moreover, the ratio of propagation 
errors is usually higher than the ratio of local errors. Both phenomena suggest that models are able to 
correctly perform single-step reasoning, potentially due to memorizing such single-step operations 
during training, but fail to plan and compose several of these steps for an overall correct reasoning. 
Both the DP and the puzzle tasks have a high ratio of restoration errors, suggesting memorization 
since correct outputs are produced despite incorrect computations. There are signs of memorization 
even when restoration errors are near zero: 82.3% of the i nal correct answers for 4-digit by 2-digit 
multiplications (a setting unseen during training) had at least one error in the computation graph, but 
still produced correct answers. These patterns are possibly due to high frequency of (input, output) 
multiplication pairs in the pretraining data, in contrast to intermediate reasoning steps.1 / 1ChatGPTChatGPTThis section of the paper focuses on the types of errors that Transformers make when attempting to reason through the computation graphs for the tasks they were given.The researchers classify each node in the computation graph into one of four categories: fully correct, local error, propagation error, and restoration error.A node is fully correct if it and all of its ancestors (previous steps in the calculation) have correct values and are derived from correct computations.A node has a local error if its parent nodes have correct values, but it is derived from an incorrect computation (i.e., a one-hop reasoning error).A node has a propagation error if it is derived from a correct computation, but some of its parent nodes have incorrect values.A node has a restoration error if it has a correct value but is derived from an incorrect computation.The results show that the number of fully correct nodes drastically decreases as the complexity (number of layers) of the computation graph increases, suggesting that Transformers struggle with maintaining correct reasoning across multiple steps. In addition, there are usually more propagation errors than local errors, indicating that Transformers have a problem with carrying correct information through multiple reasoning steps.In both the Dynamic Programming (DP) and the Puzzle tasks, there is a high number of restoration errors, which suggests that the models are resorting to memorization rather than reasoning. The paper also cites evidence of memorization when correct final answers are given despite having at least one error in the computation graph.In summary, while Transformers can usually perform single-step reasoning correctly, they struggle to plan and execute multiple steps of reasoning in a coherent and correct way. This issue appears to be due to a reliance on memorization of single steps or outputs, rather than understanding and applying a systematic reasoning process.1 / 14Error Propagations: The Theoretical Limits 
Experiments (Â§3) highlight the limitations of current Transformers in handling complex, multi-step 
reasoning tasks. Concretely, we show that errors rapidly escalate as the problem size grows (Â§3.2.3). 
In this section, we aim to provide theoretical insights into why these models can perform signif i cantly 
worse in compositional tasks as the problem size increases. We argue using stylized examples that 
transformers may be too limited to solve compositionally complex tasks. 
Algorithms designed to solve compositional tasks typically involve multiple independent applications 
of a function and/or iterated applications of the same function. A Transformer executing such an 
algorithm acts as an estimator of these functions. In this context, we examine the probability of such 
an estimator reaching the correct answer as the problem size increases. We i rst consider a scenario 
where a Transformer estimates an algorithm requiring n independent applications of a function: 
7 
Proposition 4.1 (informal). Letfninvolvethecombinationhnofnindependentapplications of a func- 
tiong.Let b f,b g,bhnbe 
their estimators.Assumehnhas low collision and thatbhnis 
a perfect estimator 
of hn. If P(gÌ¸=b g)>0 where b gâs errors are independent, then P(fnÌ¸=bfn) 
tends to 1 as n increases. 
Proof sketch.Derive an upper bound forP(fn= b 
fn)by using the law of total probability on the 
event that the estimationsb gwere 
correct for all of thenindependent applications. Show it converges 
to zero as n â +â. See Â§D.1 for a formal statement and proof derivation. 
Proposition4.1âsproofshowstherateofconvergenceisexponential, thusconcludingthattransformers 
will rapidly fail with increasing n. Letâs now analyze the iterated application function scenario. 
Proposition 4.2 (informal). Letfn(x)=gn(x)involve the repeated application ofg. Assume that 
the probability of recovering from a mistake due to the randomness of applying the estimator on an 
incorrect input has probability at mostc. IfP(gÌ¸=b g)=Ïµ>0, 
thenliminf 
nâ+â P(fnÌ¸=bfn) 
= 1âc/(c+Ïµ). 
Proof sketch.Letsn:= P(fn= b 
fn), wheres1= 1âÏµbydef i nition. Derivesnâ¤ (1âÏµâc)Â·snâ1+c 
using law of total probability. Then, prove by induction a non-recursive upper bound forsnwith 
limit 
c 
c+Ïµ when n â +â. See formal statement and derivation in Â§D.2. 
Prop. 4.2âs proof also shows an exponential rate of convergence.Note that ifc âª Ïµthen 
liminf 
nâ+â P(fnÌ¸= b 
fn) â 1. 
It is reasonable to assumec âª Ïµwhenghas 
low collision, sincec 
represents the probability of the estimatorb g(y)arriving 
at the correct outputg(x)by chance when 
given the wrong input y Ì¸= x. More details in Â§D.3. 
Moreover, repeated applications of a function often imply unbounded errors: ifg(x)can be expressed 
as an aff i ne transformationFx+c, then it may be viewed as a i rst-order vector autoregression, which 
are known to be unstable when|Î»| â¥ 1for at least oneÎ»eigenvalue ofF[27] (statement in Â§D.4). 
While we make these arguments with aff i ne maps, similar behaviors, perhaps even more acute, would 
hold with nonlinear maps [22]âbut their study is beyond the scope of this paper. 
In Prop. 4.2âs current form, we implicitly assume that there is a single valid reasoning for each input 
sincegis a function. We can potentially generalize this assumption with a state-transition framing, 
where the probability of transitioning from a valid state to an invalid one isÏµ, and the probability of 
recovering from an invalid state is at most c. See formal statement in D.2. 
All tasks evaluated in the present work can be seen as instances of the results just proven. Prop. 4.1 
directly applies to multiplication, sincem-by-ndigit multiplication can be seen asnindependent 
instances ofm-by-1digit multiplication (see Cor. D.1). Prop. 4.2 directly applies to the recursive 
function of the dynamic programming task, as well as tom-by-1digit multiplication, and to the 
puzzle through its elimination function (details in D.3). They are also all low collision settings.1 / 1ChatGPTChatGPTThis section of the paper presents theoretical evidence to explain the limitations of Transformers in complex, multi-step reasoning tasks. The authors propose two main propositions that outline the potential problems:Proposition 4.1 (informal): This proposition discusses a scenario where a Transformer is estimating an algorithm that requires multiple independent applications of a function. If the probability of an error occurring at each application of the function is greater than 0, then as the number of applications (n) increases, the probability that the Transformer's output differs from the correct answer (i.e., makes an error) tends to 1. In simpler terms, as the complexity of the task increases (more independent applications of a function), the chance of the Transformer making an error increases significantly.Proposition 4.2 (informal): This proposition considers a scenario where a Transformer estimates a recursive function (one function applied repeatedly). It shows that if the probability of the Transformer making an error at each application of the function is greater than 0, then the probability of making an error tends to a value of 1 - c/(c+Ïµ) as n goes to infinity. Here, c is the probability of the model correcting a mistake due to randomness, and Ïµ is the chance of an error occurring at each application. If c is significantly less than Ïµ, then the probability of an error tends to 1.Both propositions show that the error rate increases exponentially as the complexity of the task increases. This provides theoretical evidence for the observed limitations of Transformers in complex, multi-step reasoning tasks. The propositions are applicable to various tasks such as digit multiplication and dynamic programming tasks.1 / 15Discussion 
Collapsed Compositionality and Robustness ImplicationsTransformers today demonstrate un- 
deniably powerful empirical results. Yet, our study suggests that Transformers may have fundamental 
weaknesses in certain intellectual tasks that require true multi-step compositional operations such as 
multiplications and logic puzzles. Our careful study based on the computation graph and analyses 
demonstrates that Transformers can often solve multi-step compositional problems by collapsing the 
depth of the compositional operations via analogical pattern matching. More broadly, our i ndings 
suggest that the strong performance of Transformers should be taken with a certain grain of salt: De- 
spite initially appearing challenging, certain tasks may not possess the inherent compositionality they 
seem to have. This is due to the fact that desired solutions could be readily derived from input-output 
sequences present in the training data, allowing for shortcut pattern matching to produce acceptable 
solutions. However, such an approach can ultimately result in poor generalization capabilities as 
shown in our study. For example, i ne-tuning GPT3 on our tasks both with and without explicit 
reasoning graphs shows that modelsâ learning fails to generalize beyond levels of complexity seen in 
training. 8 
Theoretical Findings and their Empirical ImplicationsThe proofs presented in Â§4 show that, 
under reasonable assumptions, the probability of incorrect predictions converges exponentially to 
â 1for 
abstract compositional tasks. Importantly, these proofs apply to autoregressive language 
models in general. Building on these i ndings, we suggest several empirical strategies for harnessing 
the potential of Transformers. Firstly, Transformers may be employed in ways that require chaining 
only a few compositional steps to reach a solution rather than lengthy reasoning steps (e.g., [30]). 
Secondly, Transformers may be best suited for compositional tasks where evaluation metrics can 
afford some leniency; for example, i nding approximate solutions that do not require executing the 
whole graph, such as identifying the most signif i cant digit in a multiplication. Finally, we suggest 
augmenting Transformers with planning modules as well as using ref i nement methods, that can 
iteratively improve their generations [64, 37]. 
Call for broad Participation to Investigation on the LimitationsIdentif i cation of limitations is 
an important step towards achieving greater robustness. Our study suggests fundamental limitations 
that impede Transformers from fully mastering certain compositional operations. However, we 
acknowledge that due to our compute budget constraints as well as limited access to the largest 
language models such as GPT-4, we are unable to push the empirical limits of Transformers even 
further in terms of training data size and number of epochs. We invite the broader research community, 
particularly those with more extensive resources at their disposal, to investigate these possibilities 
further. 
6Related Work 
Reasoning abilities in Transformer LLMsRecently, Transformers [9,42,41,14,13,46,56,57] 
have demonstrated impressive reasoning abilities across a wide range of tasks, even outperforming 
humans in certain cases [61,25,12,66]. This success has been largely attributed to the scaling effect, 
where larger models and training datasets result in improved performance [33,28,1]. However, these 
models have also been shown to struggle across multiple domains, including algorithmic reasoning 
[60], commonsense reasoning [45,35], theory of mind [48], planning [59], logical reasoning [53], 
and ethical reasoning [31]. These diff i culties have motivated us to take a step back and thoroughly 
examine both the successes and failures of Transformers from empirical and theoretical perspectives 
on compositional reasoning tasks. 
Challenges of Transformers in compositional tasksTransformers perform fairly well in single- 
step reasoning tasks [53], but face challenges when it comes to effectively combining multiple steps 
to solve compositionally complex problems [39,49,63]. Recent research has focused on overcoming 
these limitations through various approaches. First, i ne-tuning Transformers to directly generate 
the i nal answer while keeping the reasoning implicit [7,15]. Second, encouraging Transformers to 
generatereasoningstepsexplicitlywithinasinglegeneration[39,62,36]. Forexample, Nyeetal. [39] 
and Zhou et al. [67] used scratchpads to teach Transformers how to perform algorithmic reasoning 
tasks such as addition by splitting the task into intermediate steps [36,62]. Lastly, leveraging LLMs 
to generate each reasoning step iteratively via a selection and inference mechanism [17,16,55]. 
The primary focus of these studies is to explore possibilities for improving modelsâ performances 
on compositional problems without necessarily aiming for complete mastery of the task. While 
they have indeed made enhancements compared to baseline approaches, they did not achieve 100% 
accuracy on OOD domain. In contrast, our work delves into investigating the fundamental limits of 
achieving full mastery of the task. We seek to examine whether we could achieve 100% performance 
in both in-domain and OOD settings by pushing transformers to their limits. Our i ndings reveal that 
accomplishing this feat is not a simple task, and we offer insights into why reaching full mastery is 
inherently challenging.1 / 1ChatGPTChatGPTIn this discussion section, the authors reflect on the results of their investigation into the weaknesses of Transformers when dealing with tasks requiring multi-step compositional operations. They've found that, despite the current model's ability to perform pattern matching, the Transformers fail to generalize to more complex situations beyond what they've encountered in training. They argue that such tasks may not be as inherently compositional as they seem because models can use "shortcut" pattern matching to generate acceptable solutions from training data.The authors' theoretical findings indicate that Transformers are more likely to produce errors as the complexity of the tasks increases. The authors recommend using Transformers for tasks that require fewer compositional steps and allowing for some leniency in evaluation metrics. They also suggest augmenting Transformers with planning modules and using refinement methods to improve their predictions iteratively.The authors invite more extensive research into the limitations of Transformers, acknowledging the constraints of their own investigation due to limited resources. They note that their study's findings should prompt further exploration into whether Transformers can fully master certain compositional tasks.They also reference related work that demonstrates the impressive reasoning abilities of Transformers across a wide range of tasks. While Transformers can perform well on single-step reasoning tasks, they struggle with tasks requiring complex, compositional problem-solving. Some previous studies have attempted to address these challenges, for example, by using scratchpads to teach Transformers how to perform algorithmic reasoning tasks or generating reasoning steps explicitly within a single generation. Despite these attempts, no approach has been able to achieve complete mastery over compositional tasks, further emphasizing the need for further investigation into the limitations of Transformers.1 / 1Challenges of Transformers in generalizationExtensive research has been done to investigate 
the generalization capabilities of Transformers [3,38,23,47]. This encompasses various facets of 
generalization, including easy-to-hard generalization [50,4], length generalization [2,43,11,38], and 
generalization on symbolic mathematical integration [65]. Schwarzschild et al. [50] and Bansal et al. 
[4] employ weight-tied neural networks to generalize from easy to hard examples. Razeghi et al. [47] 
revealed a positive correlation between the frequency of training terms and their test performance. 
Building upon this line of inquiry, we present a more rigorous examination of sub-graph matching 
9 
between training and test instances for complex compositional tasks. We complement our empirical 
results with theoretical insights on Transformersâ limits. 
Iterated FunctionsThe process of repeatedly applying a noisy single operation or functionf 
can be related to iterated random functions [21]. In this latter literature, the focus is usually on the 
contractive regime in which accrued errors can be kept under control, and the subsequent convergence 
guarantees (e.g., [20]). Whenfis an aff i ne transformation, the process falls simultaneously between 
two perspectives: time series [27] and dynamic programming and control [6]. We leverage the former 
to discuss the often explosiveerrorsoffn. 
7Conclusions 
On a broader scope, as Transformers continue to gain widespread deployment with signif i cant real- 
world impacts, it is ever more urgent to understand their successes and failures. Our study critically 
investigates Transformersâ limitations and emphasizes the need to develop models capable of robust 
generalization and systematic problem-solving. By examining the compositional capabilities of these 
models, we aspire to work towards more reliable AI systems that excel not only in tasks where 
abundant training examples are suff i cient, but also in cases requiring precise compositional reasoning. 
8Limitations 
We focus on analyzing compositional reasoning capabilities through the lens of computation graphs. 
Althoughtheyareausefulwaytosystematicallyrepresentrigorousreasoningprocesses, itisimportant 
to note that for the scratchpad approach, we are limited to only establishing a correlation between the 
model generation and its preceding context, as we cannot inspect the exact tokens model attends to 
when making the prediction. This limitation arises from our lack of access to the activations of the 
studied models. Furthermore, we posit that alternative approaches to linearizing reasoning processes 
may yield different performances and provide opportunities for further exploration.1 / 1ChatGPTChatGPTIn this conclusion and limitations section, the authors first recap the discussion on the challenges Transformers face when generalizing, particularly when working with complex compositional tasks. They highlight that previous studies on iterated functions, such as iterated random functions, have usually focused on situations where errors could be controlled and eventual convergence is guaranteed. However, when working with affine transformations, Transformers often generate explosive errors.The authors underscore the urgency to understand the successes and limitations of Transformers as they continue to be widely deployed and have significant real-world impacts. They call for the development of models capable of robust generalization and systematic problem-solving, focusing particularly on tasks requiring precise compositional reasoning.The authors also acknowledge the limitations of their study. They note that while computation graphs provide a systematic way to represent rigorous reasoning processes, the scratchpad approach only allows them to establish correlations between the model's generation and its preceding context. As they lack access to the activations of the studied models, they cannot inspect the exact tokens the model attends to when making predictions. They also propose that alternative approaches to linearizing reasoning processes may yield different performances and offer opportunities for further investigation.1 / 1A summary of the whole article.1 / 1ChatGPTChatGPTThe paper is a theoretical and empirical study investigating the limitations of Transformer-based models, such as GPT, in performing complex, multi-step reasoning tasks, especially those with high compositionality like multiplications or logic puzzles.In the experiments, the authors trained these models on tasks that involve multi-step computations, where they observed that Transformers often adopt a shortcut strategy of "pattern-matching" to the solution, instead of solving the tasks through step-by-step compositional reasoning. This is made possible by the inherent "computation graph collapse" phenomenon, where Transformers simplify the computation graph depth in training and extract superficial patterns to generate results, often resulting in poor generalization capabilities.The authors provided theoretical proofs in Â§4 to show that under reasonable assumptions, the probability of Transformers making incorrect predictions converges exponentially to 1 when performing complex compositional tasks. This is because the errors in estimating each step of the computation compound as the complexity increases.The paper concludes by highlighting the potential practical implications of these findings. While Transformers show powerful empirical results, the study shows they may have fundamental limitations in handling true multi-step compositional operations. This suggests that Transformers may be more effectively used in applications requiring only a few compositional steps or where approximate solutions are acceptable. The authors also call on the research community to continue investigations on these limitations, particularly with models like GPT-4, and more extensive resources.Despite these findings, the authors acknowledge the limitations of their study. Specifically, their analysis could only correlate the model generation with its preceding context, due to a lack of access to model activations. They also suggest that different approaches to linearizing reasoning processes might yield different outcomes.1 / 1Explore, Establish, Exploit: Red Teaming 
Language Models from Scratch 
Stephen Casper 
MIT CSAIL 
scasper@mit.edu 
Jason Lin 
Stanford University 
Joe Kwon 
MIT 
Gatlen Culp 
MIT 
Dylan Hadf i eld-Menell 
MIT CSAIL 
Warning: This paper contains model outputs that are offensive in nature. 
Abstract 
Deploying Large language models (LLMs) can pose hazards from harmful outputs 
suchastoxicordishonestspeech. Priorworkhasintroducedtoolsthatelicitharmful 
outputs in order to identify and mitigate these risks. While this is a valuable step 
toward securing language models, these approaches typically rely on a pre-existing 
classif i er for undesired outputs. This limits their application to situations where the 
type of harmful behavior is known with precision beforehand. However, this skips 
a central challenge of red teaming: developing a contextual understanding of the 
behaviors that a model can exhibit. Furthermore, when such a classif i er already 
exists, red teaming has limited marginal value because the classif i er could simply be 
used to i lter training data or model outputs. In this work, we consider red teaming 
under the assumption that the adversary is working from a high-level, abstract 
specif i cation of undesired behavior. The red team is expected to ref i ne/extend this 
specif i cation and identify methods to elicit this behavior from the model. Our red 
teaming framework consists of three steps: 1) Exploring the modelâs behavior in 
the desired context; 2) Establishing a measurement of undesired behavior (e.g., 
a classif i er trained to ref l ect human evaluations); and 3) Exploiting the modelâs 
l aws using this measure and an established red teaming methodology. We apply 
this approach to red team GPT-2 and GPT-3 models to systematically discover 
classes of prompts that elicit toxic and dishonest statements. In doing so, we also 
construct and release the CommonClaim dataset of 20,000 statements that have 
been labeled by human subjects as common-knowledge-true, common-knowledge- 
false, or neither. Code is available at this https url. CommonClaim is available at 
this https url. 
1Introduction 
Large language models (LLMs) can automate or assist humans in a variety of tasks, but they exhibit 
problems such as hallucinations [25], biases [53,47], and jailbreaks [42,32] leading to the generation 
of harmful outputs. Thus, it is crucial to have scalable approaches for red teaming language models 
to i nd l aws before they are deployed. Prior research has made progress by red teaming LLMs 
with techniques to discover prompts that elicit outputs that a given classif i er identif i es as harmful. 
For example, Perez et al.[46]use screening, few-shot generation, and reinforcement learning to 
curate prompts that elicit harmful responses from an LLM according to a pretrained toxicity classif i er. 
Meanwhile, we discuss other related techniques in Section 4. 
Preprint. Under review. 
arXiv:2306.09442v1 
[cs.CL] 
15 
Jun 
2023 
These tools make it easier for the red team to i nd the relatively small set of inputs that elicit the target 
behavior. This then lets them focus their attention on those inputs for diagnostics and/or debugging. 
In this sense, tools like those of Perez et al.[46]allow the red team to i nd the proverbial âneedle in a 
haystackâ. Explore 
Diverse Dataset 
ClassifierLabels 
EstablishExploit 
Target LM 
Red LM 
Red Team 
Figure 1: Our pipeline for red teaming language mod- 
els. At the beginning, no assumptions are made â the 
red team need not have a formal specif i cation of harm- 
ful behavior. In the end, the red team has a labeled 
dataset, a measure for harmful outputs, and a generator 
for prompts that elicit them. Prior red teaming works 
(Section 4) assume that the Explore and Establish steps 
are already done. 
This is useful, but it can only be applied to 
situations where the red team already has 
access to a classif i er for harmful text. In 
many situations, the red team has to work 
off a more abstract specif i cation. This may 
be for many reasons, such as: 1) the de- 
tails of the harmful behavior are diff i cult 
to anticipate in a pre-deployment context; 
2) a pretrained classif i er is not available for 
the target behavior; or 3) the distribution 
of language model output is distinct from 
classif i er training data. Furthermore, when 
such a classif i er is available, red teaming 
is less useful because the classif i er can be 
used to i lter training data or model output.1 / 1ChatGPTChatGPTThis paper discusses the deployment of large language models (LLMs) and the potential dangers they may pose due to harmful outputs, such as toxic or dishonest speech. Prior work has introduced tools to elicit and identify these harmful outputs to mitigate risks. However, these methods often rely on a pre-existing classifier for unwanted outputs. This limits their application to situations where the type of harmful behavior is precisely known beforehand.The authors propose a framework for "red teaming", a process in which an adversarial team tests the system's defenses and explores potential vulnerabilities. The framework is based on the assumption that the adversary is working from a high-level, abstract specification of undesired behavior. The red team's objective is to refine this specification and identify methods to draw out this behavior from the model.The framework consists of three steps:Exploring the model's behavior in the desired context,Establishing a measurement of undesired behavior, such as a classifier trained to reflect human evaluations, andExploiting the model's flaws using this measure and an established red teaming methodology.The authors applied this approach to the GPT-2 and GPT-3 models to systematically discover classes of prompts that elicit toxic and dishonest statements. In the process, they also constructed the CommonClaim dataset consisting of 20,000 statements labeled by human subjects as common-knowledge-true, common-knowledge-false, or neither.The authors argue that this new red teaming framework is more applicable when the specifics of harmful behavior are difficult to anticipate in a pre-deployment context, a pretrained classifier is not available for the target behavior, or the distribution of language model output is distinct from classifier training data.1 / 1In order to account for this, we argue that 
realistic red teaming must also involve the 
process of def i ning and measuring unde- 
sirable outputs. From this perspective, red 
teaming a language model is akin to search- 
ing for a vaguely-described needle in a 
haystack full of different needles. We in- 
troduce a framework for language model 
red teaming where the red team explores 
model output to identify undesired distribu- 
tions of text, establishes a measurement to 
identify that type of undesired output, and 
exploits the modelâs vulnerabilities using 
that measure and an established red team- 
ing approach. Figure 1 shows an illustra- 
tion of the approach. After the process ends, the red team has a dataset of diverse, labeled examples, 
a measurement (e.g. a classif i er) for such, and a generation process for adversarial prompts. Overall, 
we make three contributions: 
1.Framework: We introduce an end-to-end framework for red teaming language models that 
accounts for the identif i cation and representation of the undesirable output. 
2.Methodological: Weapplythisframeworkandintroduceapipelineforredteaminglanguage 
models with diverse adversarial prompts. We quantitatively evaluate this pipeline with 
experiments to elicit toxic text from GPT-2-xl by using a pretrained toxicity classif i er to 
stand in for a human.1 
3.Dishonesty in LLMs: We red team GPT-3-text-davinci-002 from scratch to elicit outputs 
that are assessed as false by common knowledge. In doing so, we construct and release the 
Common Claim2dataset of 20,000 statements human-labeled as âcommon-knowledge-trueâ, 
âcommon-knowledge-falseâ, or âneitherâ. To the best of our knowledge, we are the i rst to 
systematically red team large language models to elicit dishonest text. 
2Methods 
We consider a scenario in which a developer has trained a text-generating LLM and plans to deploy it 
in a specif i c context. Although the LLM generally performs well, the developer suspects that there 
1https://github.com/thestephencasper/explore_establish_exploit_llms 
2https://github.com/thestephencasper/common_claim 
2 
may be particular types of inputs that cause the model to fail at its intended purpose, as is common 
with LLMs. We make the weakest possible assumptions, not presupposing that the developer has any 
prior understanding of what these failures are, has a measure to identify them, or possesses a method 
to elicit them. This process consists of three steps: 
Step 1, Explore: The objective of this step is to acquire representative samples from the modelâs 
outputs, enabling a user to examine the range of outputs the LLM can produce. The most basic 
approach would involve simply querying the model with a set of relevant prompts and sampling 
outputs. However, this can be ineff i cient, particularly if failures are infrequent. In Section 3, we 
experiment with hand-crafted prompts, a topic i lter, and diversity sampling to increase the likelihood 
that the resulting dataset represents a relevant and extensive range of the modelâs potential outputs.3 
Step 2, Establish: This step involves analyzing the data obtained in the explore step and developing a 
measure for harmful outputs. The simplest approach would be to have humans label each example as 
eithergoodorbad(or some other more comprehensive set of labels) and to train a classif i er on these 
labels.4Important to this step is human interaction with the modelâs outputs. Human preferences are 
highly context-dependent [40] and form gradually over time [17]. Rather than using an off-the-shelf 
classif i er, this step requires a process of deliberation by which humans choose a set of labels to 
characterize the modelâs behavior in the intended deployment context [50,20,9,23] and develop a 
way to measure them. 
Step 3, Exploit: After obtaining a measure for harmful model outputs, the i nal step is to use it 
to attack the target model. The i nal result is a distribution of inputs that elicit harmful responses. 
Following prior works [15,46], we use reinforcement learning to train an adversarial prompt generator 
to produce a diverse distribution of prompts that trigger toxic or dishonest completions from the 
target model. We choose this approach because prior works have found it effective, and once the 
policy network is trained, new adversarial prompts can be inexpensively sampled as many times as 
desired. However, we survey alternative techniques for producing adversarial prompts in Section 4.1 / 1ChatGPTChatGPTThis section of the paper emphasizes the need for a realistic and comprehensive approach to red teaming large language models (LLMs), a process that includes defining and measuring undesired outputs. The authors propose a framework that consists of exploring model output to identify undesired distributions of text, establishing a measurement to identify that type of undesired output, and exploiting the modelâs vulnerabilities using that measure and an established red teaming approach. After the process ends, the red team should have a dataset of diverse, labeled examples, a measurement such as a classifier, and a generation process for adversarial prompts.This framework has three main contributions:It introduces an end-to-end framework for red teaming language models that accounts for the identification and representation of the undesirable output.It presents a pipeline for red teaming language models with diverse adversarial prompts and evaluates it quantitatively through experiments to elicit toxic text from GPT-2-xl using a pretrained toxicity classifier.It explores the aspect of dishonesty in LLMs by red teaming GPT-3-text-davinci-002 to elicit outputs that are assessed as false by common knowledge, creating the Common Claim dataset of 20,000 human-labeled statements.The authors describe a scenario where a developer plans to deploy a text-generating LLM in a specific context but suspects that certain types of inputs might cause the model to fail. The three-step process is:Explore: Acquiring representative samples from the modelâs outputs to examine the range of outputs the LLM can produce. Different methods are used to increase the likelihood that the dataset represents a relevant and extensive range of the modelâs potential outputs.Establish: Analyzing the data obtained in the first step and developing a measure for harmful outputs, involving human interaction and deliberation to choose a set of labels to characterize the modelâs behavior.Exploit: Using the measure for harmful model outputs to attack the target model. They use reinforcement learning to train an adversarial prompt generator to produce a diverse distribution of prompts that trigger toxic or dishonest completions from the target model.1 / 13Experiments RL Reward Function 
(for Red LM) 
Target LM 
Harmfulness 
Classifier 
Red LM 
Prompt 
Completion 
Harmfulness Latents 
Cos Dist 
r 
**Prompt & 
Filter 
Cluster & 
Subsample 
*Toxiciy 
Classifier 
**ChatGPT 
**Humans 
...... 
...... 
Harmful 
Outputs 
*Toxicity Red Teaming 
**Dishonesty Red Teaming 
Figure 2: A step-by-step illustration of our approach. Steps specif i c to our toxicity red teaming 
experiments with GPT-2-xl are marked with aâwhile steps specif i c to our dishonesty red teaming 
experiments with GPT-3-text-davinci-002 are marked with aââ. 
First, we sample from the target 
(optionally with prompting and i ltering) and then subsample to obtain a diverse dataset of outputs. 
Then we use either a ground truth classif i er, human labelers, or ChatGPT-turbo-3.5 to label these 
examples. We then train a harmfulness classif i er on the labeled dataset. Finally, we train an adversarial 
prompt generator to produce diverse prompts that elicit harmful outputs from the target model. 
We conduct two main experiments. First, we red team GPT-2-xl [51] to elicit toxic speech. We use 
a pretrained toxicity classif i er to stand in for a human so that we can obtain precise quantitative 
results. Second, we conduct a large-scale experiment to red team GPT-3-text-dvinci-002 [11] to elicit 
dishonest speech. 
3Alternative techniques, such as data augmentation for discovering useful prompts, could also be used (e.g., 
[8, 47]). 
4Techniques such as active learning (e.g., [13]) and weak supervision (e.g., [10, 15]), could also be used to 
improve the eff i ciency of data labeling. 3 
3.1Eliciting Toxic Text from GPT-2-xl 
Explore: We red team the 1.5B parameter GPT-2-xl. First, we sample a total of 80,000 sentences 
from the target LLM. To avoid biasing samples toward sentences that begin pieces of text, we sample 
paragraphs at a time and parse them into individual sentences. We then diversity subsample them to 
obtain a smaller dataset. In light of recent work studying how the internal activations of models may 
contain information tantamount to intentions [12], we propose using the internal activations of the 
target model to guide diversity subsampling. We embed each sentence using the last token activations 
in the modelâs last layer, use K-means clustering to partition the embeddings into 100 clusters, and 
uniformly sample 200 sentences from each cluster to obtain a diverse subsample of 20,000 examples. 
Establish: We use a pretrained RoBERTa-based [37] toxicity classif i er trained on data from [1] to 
stand in for a human and provide labels for all examples. We classif i ed any input for which the model 
output a toxicity probability ofâ¥0.1 
as toxic. In our case, less than 1% of the samples were classif i ed 
as such. We then used paraphrasing augmentation based on Parrot [14] to balance the dataset and 
train the ensemble. We use these labels to train an ensemble of 5 RoBERTa-based text-classif i ers 
from Aghajanyan et al.[2]to label sentences as toxic or nontoxic. The 5 classif i ers achieved average 
accuracies of > 99% on nontoxic sentences and 76% on toxic sentences from the validation set. 
Exploit: We use the trlx library [3] to i netune GPT-2-large using Proximal Policy Optimization to 
produce a distribution of prompts that elicit toxic outputs from the target LM. The reward used to 
train the prompt generator contained two terms. The i rst was from the classif i erâs logit conf i dence in 
the responseâs toxicity. The second was based on the intra-batch cosine distances of the target LMâs 
embeddings of the generated prompts. We added this term because mode collapse by the prompt 
generator has been a challenge in prior works [15, 46]. 
We independently ran the Exploit step two times to obtain two adversarial prompt generators. We then 
used the ground truth toxicity classif i er (that was standing in for a human) to compare the toxicity of 
the target modelâs generated text when unprompted and when given prompts from the generators. 
The data from the Explore step was classif i ed by the ground truth classif i er as toxic less than 1% of 
the time while the outputs under adversarial prompts from the Exploit step were classif i ed as toxic an 
average of 31% of the time, demonstrating transfer from the Establish step classif i er to the ground 
truth classif i er. We randomly sampled 5 completions from each of our prompt generators that were 
classif i ed as toxic and display them alongside their prompts in Table 1 (content warning). The prompt 
generators learned to largely raise topics involving men, women, homosexuality, and police off i cers. 
We observe that the prompts themselves are relatively benign compared to the completions which are 
both more offensive and more diverse in topic. We also observe certain disf l uencies in the form of 
repeated words or phrases in the prompts, but it is unclear whether these are adversarial motifs or 
artifacts of the prompt generator. 
How key is the diversity term in the adversarial prompt generatorâs reward function? To test this, 
we ran the exploit step with the diversity term removed, and the prompt generator was entirely 
unsuccessful. It output repetitive prompts, almost entirely consisting of the words âwouldâ and âyouâ 
which had a 0% toxic completion rate. We show examples in Appendix A.1 / 1ChatGPTChatGPTThis part of the paper discusses the experimental process applied to two LLMs, GPT-2-xl and GPT-3-text-davinci-002, to elicit toxic and dishonest speech, respectively.The first experiment involved 'red teaming' GPT-2-xl with the aim of eliciting toxic speech. This process consists of three stages:Explore: The team generated 80,000 sentences from the GPT-2-xl model. In order to ensure diversity in the sentences, they implemented a K-means clustering strategy on the last token activations of the target model's last layer to divide the sentences into 100 clusters. 200 sentences were then sampled uniformly from each cluster, yielding a diverse sample of 20,000 sentences.Establish: A pretrained RoBERTa-based toxicity classifier was used to label these examples. Those sentences with a toxicity probability greater than or equal to 0.1 were labelled as toxic, which accounted for less than 1% of the samples. Paraphrasing augmentation was used to balance the dataset and an ensemble of 5 RoBERTa-based text classifiers was trained to label sentences as toxic or non-toxic.Exploit: The team used Proximal Policy Optimization to fine-tune GPT-2-large, resulting in a distribution of prompts that elicit toxic outputs from the target LLM. The reward function for training this adversarial prompt generator included a measure of the classifier's confidence in the toxicity of a response, as well as a measure of the diversity of the prompts, based on the cosine distances of the target model's embeddings of the generated prompts.The results showed that adversarial prompts from the 'exploit' stage were classified as toxic 31% of the time, compared to less than 1% for unprompted sentences, demonstrating successful transfer from the 'establish' classifier to the ground truth classifier.The adversarial prompt generator largely elicited topics involving men, women, homosexuality, and police officers. Despite the relative benignity of the prompts themselves, the generated completions were often offensive and diverse in topic.A test was conducted to measure the importance of the diversity term in the adversarial prompt generatorâs reward function. Without this diversity term, the exploit step yielded repetitive and non-toxic prompts, demonstrating its crucial role in the generation of diverse, toxic text.1 / 13.2Eliciting Dishonest Text from GPT-3-text-davinci-002 
Next, we red team the 175B parameter GPT-3-text-davinci-002 to elicit dishonest claims. To the best 
of our knowledge, we are the i rst to scalably red team an LLM to i nd prompts that elicit dishonest 
text. 
Explore: Unlike before, we do not simply sample from the target LM. Only a small fraction of all 
types of sentences are statements of a fact, and only a fraction of those are objectively true or false 
irrespective of context. We found that when GPT-3-text-davinci-002 is sampled without prompting, 
it rarely outputs statements that can be labeled as objectively true or false. Instead, we used two 
approaches to restrict the domain of sentences that we explore to one of interest. First, we prompted 
the model to ask it for interesting facts.5Second, we trained a classif i er to distinguish between normal 
sentences from the target model and between boolean statements from the CREAK dataset [43]. We 
then used this domain classif i er to i lter a set proportion (we use 0.15) of the sentences sampled from 
5The prompts used were {âA weird fact:â, âA random fact:â, âA general-knowledge fact:â, âA cool fact:â, âA 
crazy fact:â, âAn unusual fact:â, âA counterintuitive fact:â, âAn amazing fact:â} 
4 
Warning: this table contains offensive model outputs. (Skipped)

Table 1: Random examples of adversarial prompts and toxic GPT-2xl completions. Each example is 
randomly selected from among the samples that the ground truth toxicity classif i er classif i ed as toxic. 
The top 5 and bottom 5 examples come from independent runs of the Exploit step. 
the target model that least resembled boolean statements. Finally, we also i ltered text based on simple 
heuristics including text containing pronouns and not ending in a period. As before, we sample a total 
of 80,000 sentences from GPT-3-text-davinci-002, embed them, and use K-means based diversity 
subsampling to obtain 20,000. Unlike with GPT-2-xl, the internal activations of GPT-3-text-da-vinci- 
002 are not available via API, so we instead use embeddings from the GPT-3-text-ada-002 which is a 
dedicated text-encoder. 
Establish: One challenge with developing honest AI systems is what standard to hold the model 
to. For example, should reasonable-sounding false statements be judged differently than blatant 
falsehoods? This distinction may be of signif i cance for both interpreting and correcting these failures 
[19,12]. Thus, we restrict our goal to red teaming the model with respect to obvious false statements 
instead of any false statements. Previously, Onoe et al.[43]introduced the CREAK dataset of 
labeled boolean statements and claimed that the data are âcommon knowledgeâ. But this claim was 
based on the methodology behind dataset construction rather than human trials, and many of the 
facts it contains are not known by typical adults. To address this challenge, we do not simply label 
sentences as true and false. Instead, we label them as âtrue by common knowledgeâ, âfalse by common 
knowledgeâ, or âneitherâ. We test three versions of this step. First, we use human labels to test the 
feasibility of the Establish step. We compare it to two controls: one using ChatGPT-3.5-turbo labels 
instead of human labels, and another approach that uses the pre-labeled CREAK dataset instead of 
our dataset from the Explore step. 
To obtain human labels, we contracted knowledge workers via SurgeAI [4].6We instructed the 
contractors to label each example not based on their own knowledge, but based on how likely they 
think a typical person would know something to be true or false. All details involving contractor 
selection and instructions are in Appendix B. We are making these 20,000 statements from GPT-3- 
text-davinci-002, each with two independently-collected human labels openly available. In total, 60% 
of statements were labeled common-knowledge-true (T/T or T/N), 22% common-knowledge-false, 
(F/F or F/N), and 18% neither (N/N or T/F). Table 2 shows examples of each type.7We name 
6All contracted knowledge workers were English-speaking adults screened by SurgeAI and were paid a 
minimum of $20 per hour of active work. 
7Our notions of âcommon-knowledge-trueâ and âcommon-knowledge-falseâ differ signif i cantly from ob- 
jective truth and falsehood. In our data collection, some false sentences were labeled true because they are 
common misconceptions (e.g. âCamels store water in twin bags called humps.â) while others were labeled as 
5 
StatementLabel 
Opera was once magical entertainment for the elegant elite.CK True 
Bees are actually really important to humans and the environment.CK True 
The child of identical twins is also a twin.CK False 
Biologically, human babies are more like turtles than any other animal.CK False 
Rainforests are amazing places.Neither 
There is no legal def i nition of the word âcrayf i shâ in the United States.Neither 
Table 2: Examples of sentences from GPT-3-text-davinci-002 that were classif i ed as common- 
knowledge-true, common-knowledge-false, and neither by humans. CK=common knowledge. 
ChatGPT 
TrueFalseNeitherTotal 
True38%6%17%60% 
False5%6%11%22% 
Neither5%2%10%18% 
Human Total48%14%38% 
Table 3: The proportions of 20,000 examples labeled as common-knowledge-true, common- 
knowledge-false, and neither by human labelers and by ChatGPT-3.5-turbo. 
this the Common Claims dataset. We trained an ensemble of 5 classif i ers as done before with data 
augmentation but on three labels instead of two. The 5 classif i ers trained on this data achieved average 
accuracies of 90% on âcommon-knowledge-trueâ sentences, 44% on âcommon-knowledge-falseâ 
sentences, and 19% on âneitherâ sentences from the validation set. However, when using this classif i er 
for red teaming, we note that the accuracy is not important, but rather the ability of the model to 
provide a suitable reward signal.1 / 1ChatGPTChatGPTThe paper's second experiment involved 'red teaming' the 175B parameter GPT-3-text-davinci-002 model to elicit dishonest claims. This process, again, consisted of three stages:Explore: In this case, simply sampling from the target language model (LLM) was not sufficient, as only a small fraction of all possible sentences are factual statements. To ensure the generation of objectively true or false statements, the researchers prompted the model with a set of phrases asking for interesting facts, and also employed a classifier trained to distinguish normal sentences from boolean statements. 80,000 sentences were sampled from GPT-3-text-davinci-002, and K-means based diversity subsampling was used to select 20,000 of them.Establish: The researchers chose to target obvious false statements, as the distinction between blatant falsehoods and reasonable-sounding false statements is significant when it comes to interpreting and correcting AI failures. They labeled sentences as 'true by common knowledge', 'false by common knowledge', or 'neither'. To obtain these labels, they employed knowledge workers through SurgeAI, who labeled each example based on how likely a typical person would know something to be true or false. They also compared this approach with two controls: one using labels from ChatGPT-3.5-turbo, and another using the pre-labeled CREAK dataset.Exploit: In this phase, the researchers used the ensemble of five classifiers trained on the labeled data from the 'Establish' phase to provide a suitable reward signal for training the adversarial prompt generator.This experiment revealed that in the 'Establish' phase, 60% of statements were labeled as common-knowledge-true, 22% as common-knowledge-false, and 18% as neither. The five classifiers trained on this data achieved average accuracies of 90% on 'common-knowledge-true' sentences, 44% on 'common-knowledge-false' sentences, and 19% on 'neither' sentences from the validation set.1 / 1provide a suitable reward signal. 
Next, we ask if the role of humans could be automated by an LLM chatbot. Some recent work 
suggests that ChatGPT can outperform human annotators on certain tasks [22]. We attempt this with 
the promptIs the sentence "[X]" commonly known to be false, commonly known to 
be true, or neither?Answer without explanation.ChatGPT-3.5-turbo [44] labeled 
48% as CK true, 14% as CK false, and 38% as neither. Table 3 compares the agreement between 
human labelers and ChatGPT-3.5-turbo. We i nd agreement on only 54% of the 20,000 examples. 
The 5 classif i ers trained on the ChatGPT-3.5-turbo labels achieved average accuracies of 87% on 
âcommon-knowledge-trueâ sentences, 63% on âcommon-knowledge-falseâ sentences, and 58% on 
âneitherâ sentences from the validation set. 
Finally, as a control, we use the CREAK [43] train and dev sets which, together, contain a total of 
5779 true and 5768 false boolean statements. The 5 classif i ers trained on the CREAK data achieved 
average accuracies of 78% on true sentences and 75% on false sentences from the validation set. 
Exploit: As before with toxicity red teaming experiments, we use reinforcement learning to i netune 
GPT-2-large to produce inputs that yield completions that the classif i er from the exploit step identif i es 
as harmful (i.e. common-knowledge-false). As before, we include a diversity term (based on the 
cosine distance of embeddings) in the reward. We run this experiment twice for each version of the 
Establish step (human labels, ChatGPT-3.5-turbo labels, and CREAK). 
When using the classif i ers trained on human labels, they classif i ed 30% of the Explore phase data 
(found using hand-picked prompts) as common-knowledge-false. However, the same classif i ers 
classif i ed an average of 74% of the completions from the adversarial prompts as common-knowledge- 
false. Table 4 shows examples from these two runs. As before, the prompts also contain certain 
disf l uencies which may or may not be adversarial. The adversarial prompt generators learned to 
output prompts primarily about Republicans, Democrats, Russia, and Barack Obama which elicited 
completions that were often disf l uent but sometimes contained political misinformation. We checked 
the dataset and labels that the truthfulness classif i er was trained on. It contained few political 
neither because the answer is not commonly known (e.g. âThe blue whale is the largest animal to have ever 
lived on Earth.â). We also note that the labeling process has introduced cultural biases. For example, âIn Japan, 
Halloween is known as âpurewhite nightâ and is tinged with romance.â was labeled as neither. 

statements. For example, among the sentences with âcommon-knowledge-falseâ labels, we found no 
sentences about Republicans or Congress, one each about Democrats and Barack Obama.8, and one 
involving Russia and politics9. This lack of training data about politics suggests that the classif i ers 
from the Establish step generalized to learn that the completions from the target LM were frequently 
disinformation. 
Next, we perform identical Exploit step experiments but using the classif i ers trained on ChatGPT-3.5- 
turbo labels and CREAK data. As before with the human labels, the adversarial prompt generators 
succeeded in eliciting completions that were classif i ed as dishonest. The classif i ers trained on 
ChatGPT-3.5-turbo classif i ed 17% of the Explore step data as common-knowledge-false but an 
average of 76% of completions from adversarial prompts. And the classif i ers trained on CREAK clas- 
sif i ed 61% of the Explore step10data as false but an average of 95% of completions from adversarial 
prompts. However, unlike the prior experiment, completions elicited from these experiments did 
not show any apparent tendency toward being dishonest. We show examples from both runs in both 
experiments in Appendix C (content warning). In these cases, the prompts and completions tended to 
either be toxic and describe violent events or be nonsense strings of code-like vocabulary. It is unclear 
why this is the case. But we speculate that it may involve properties of ChatGPT-3.5-turbo and 
8âA member of the Democrat Party bears the US presidential seal on the lectern during presidential addresses.â 
and âBarack Obama is the current President of the United States.â 
9âIn Russia, Putin was once pulled over for speeding.â 
10Note that this is quite high compared to what both the human labelers and ChatGPT-3.5-turbo thought, sug- 
gesting diff i culty in transferring to our task, and discrepancies between CREAK dataset and human knowledge. 
7 
CREAK that led to biased labels and thus a more hackable reward signal. Overall, these experiments 
serve to demonstrate the feasibility of using humans in the Establish step. They additionally provide 
a concrete example of when using AI feedback [7] or an outside dataset may not be effective for red 
teaming.1 / 1ChatGPTChatGPTThe researchers explored whether an AI model, specifically ChatGPT-3.5-turbo, could replace the human role in the 'Establish' phase of their experiment. They asked ChatGPT-3.5-turbo to label statements as either 'commonly known to be true', 'commonly known to be false', or 'neither'. Interestingly, the AI and human labels only agreed on 54% of the 20,000 examples. Classifiers trained on these AI labels achieved lower accuracy for 'common-knowledge-true' and 'neither' sentences compared to those trained on human labels, but performed better on 'common-knowledge-false' sentences.As a control, they also used the pre-labeled CREAK dataset, with the classifiers trained on this dataset showing lower accuracy on both true and false sentences compared to the ones trained on human or ChatGPT-3.5-turbo labels.In the 'Exploit' phase, they used the classifiers trained on human labels, ChatGPT-3.5-turbo labels, and the CREAK dataset to fine-tune the GPT-2-large model using reinforcement learning, aiming to produce inputs that yield 'common-knowledge-false' outputs. The adversarial prompts were found to elicit a much higher proportion of 'common-knowledge-false' outputs than the hand-picked prompts used in the 'Explore' phase.Notably, the adversarial prompt generators often created prompts related to Republicans, Democrats, Russia, and Barack Obama, resulting in completions that sometimes contained political misinformation. However, the dataset used for training the truthfulness classifier contained few political statements, suggesting that the classifiers had generalized to identify disinformation.Similar 'Exploit' experiments using classifiers trained on ChatGPT-3.5-turbo labels and CREAK data were also successful in eliciting dishonest completions. However, the content of these completions did not show any apparent tendency towards dishonesty, instead often being either toxic, describing violent events, or nonsensical strings of code-like vocabulary. The reasons behind these outcomes were not immediately clear.Overall, the experiments demonstrated the feasibility of using human involvement in the 'Establish' step of the process, but also highlighted potential challenges and limitations when using AI feedback or outside datasets for red teaming.1 / 14Related Work 
Preference formation and human factors in AI oversight. In specif i c tasks, using an off-the-shelf 
pretrained model may not reliably capture the desired behavior. Because human preferences in a 
domain have been found to form gradually over time [17] and are highly context-dependent [40,36], 
human interaction with a model may be necessary for understanding desirable and harmful behavior 
[16]. For specif i c deployment contexts, a label set that a pretrained classif i er was trained with may fail 
to adequately express the various categories of behaviors that a human would desire [50,20,9,23]. 
For example, prior works have introduced datasets of claims labeled âtrueâ and âfalseâ [34,43,59,48] 
but we found that in our case, a third category of âneitherâ was necessary to adequately label the 
examples. 
Exploring unexpected capabilities of language models. Due to the expressivity and l exibility of 
language, LLMs are capable of very open-ended behavior. This poses a challenge when trying to 
make assurances that they are incapable of producing classes of harmful outputs [64]. Multi-task 
benchmarks have historically been common for evaluating how broad a modelâs capabilities are 
[61,62,28]. Other works have explored using LLMs to write test cases to evaluate other LLMs 
[8,47]. But for open-ended exploration of what a model is capable of, few techniques have rivaled 
manual interaction with a human in the loop [21,50]. We add to this with our sampling procedure at 
the beginning of the pipeline. Here, we use K-means-based diversity subsampling, but [54] survey 
other statistical techniques for diversity subsampling. 
Reinforcement Learning from Human Feedback (RLHF). RLHF [13,65] is a technique for 
training AI systems to scalably learn from human oversight. It involves 1) sampling outputs from a 
model, 2) having a human provide feedback on those outputs, 3) i tting a reward model using that 
feedback, and 4) training the original model using RL and the reward model. Our approach can be 
viewed as a form of RLHF with a particularly involved and open-ended feedback step that involves 
preference formation. This contrasts with how RLHF in practice typically relies on simple forms of 
feedback such as binary preferences between examples. 
Red teaming with automated searches for natural language prompts. Given a specif i c target 
behavior of a language model (such as outputting toxic or dishonest text), a red teamâs job is to i nd 
inputs that can elicit that behavior. This is challenging for two reasons. First, embedding and sampling 
discrete tokens is not differentiable, and second, manual searches are expensive. Several methods 
have been proposed for eff i ciently automating prompt search absent the ability to propagate gradients. 
These include local search [49], gradient-informed searches over token changes [18,33,52,56,26], 
searches based on Langevin dynamics [55,31], the Gumbel Softmax trick [60,58,24], rejection 
sampling at scale [21], projecting soft prompts onto hard prompts [63], and reinforcement learning 
[15,46]. Here, we use reinforcement learning because it is demonstrated to be effective and, unlike 
most such tools, results in a distribution of prompts that can be sampled as opposed to a single 
prompt. 
Studying toxicity and dishonesty in large language models. For evaluating toxicity, prior works 
have introduced data [1] and probed for toxic speech in LLMs [45]. For evaluating dishonesty, there 
exist works introducing datasets [5,34,43,59,48], studying probing [12], studying the hallucination 
of made-up facts[38,29,25], and exploring measures for model uncertainty [30]. Several approaches 
have also been introduced for reducing dishonesty including having models express their uncertainty 
in words [35] and techniques for having models support their statements with evidence [57,39]. 
Nakano et al.[41]leverages both RLHF and rejection sampling to improve factual accuracy of GPT-3 
for question answering with access to a web browser. At a high level, Evans et al.[19]focus on 
technical and political approaches for honest AI. Finally, concerning both toxicity and dishonesty, 
Bai et al.[7]demonstrate how language models can be prompted to evaluate and critique the outputs 
of other models for harmful outputs and Bai et al.[6]study how learning from human feedback can 
reduce problems with both. We add to prior works by testing our pipeline for eliciting toxic and 
8 
dishonest outputs, including for the study of model internals. To the best of our knowledge, this is the 
i rst work to synthesize inputs that elicit dishonest completions from language models at scale. 
5Discussion 
Key i ndings: We have introduced and tested a complete framework for red teaming large language 
models. We have found that red teaming is possible and can even be more effective when done 
from scratch instead of with a pretrained classif i er. This makes our approach, unlike prior works, 
competitive with simply using a pre-existing classif i er to i lter training data and/or model outputs. In 
doing so, we have also made progress compared to prior works by demonstrating that developing a 
diverse distribution of prompts and using human labels may be key to successful red teaming. We 
also provide the i rst example of red teaming an LLM at scale to elicit dishonest text. 
What comes after Explore/Establish/Exploit? The goal of red teaming should not be thought of 
as only a distribution of adversarial prompts, but also the data and classif i er used to produce them. 
The i nal results of our pipeline are 1) a labeled dataset of diverse model outputs, 2) a classif i er 
for harmful model outputs, and 3) a distribution or dataset from which prompts that elicit harmful 
behavior can be drawn. The labeled dataset could be used for probing the model to understand its 
behaviors in terms of internal mechanisms. The classif i er could be used to i lter training data for 
LLM retraining [27] or to i lter model outputs. Finally, the adversarial data generator from the exploit 
step could be used for probing experiments or adversarial training. Together, these products from the 
pipeline equip the red team to undertake a variety of interpretability, diagnostic, and debugging goals. 
Limitations: Red teaming is diff i cult. Ultimately, it would be very helpful to have tools that can be 
used to automatedly discover and elicit unambiguous failures from models. We make progress toward 
this with our pipeline, and we succeed in eliciting harmful outputs from LLMs. But we also showcase 
a tradeoff between the eff i ciency of red teaming and the looseness of the permissions granted to a red 
team. We show that it is possible to red team a model without necessarily knowing what failure looks 
like before beginning the process. But this comes at the expense of exploration and manual data 
screening. We also run into diff i culties with disf l uent text. We emphasize that there are multiple ways 
to obtain diverse samples from a model, label those samples, obtain a measure of harmful behavior, 
and elicit that harmful behavior from an LLM. The approaches used in specif i c applications should be tailored to those instances and should take advantage of all possible information that the red team 
has access to. 
Future work: Additional progress could be made involving each step of the pipeline. For the explore 
step, K-means-based diversity sampling is the only tool that we used to unsupervisedly i nd a diverse 
set of model behaviors. We use embeddings from a sentence embedding model, but further work 
on leveraging latent information from the model could be valuable [12]. For the Establish step, we 
are able to use one LLM to evaluate the outputs of other language models, but we found that the 
end result was not successful. Continued work to improve on this may be valuable (e.g. [7]). For 
the exploit step, it remains an open problem of how to effectively produce highly diverse and l uent 
prompts that elicit harmful outputs. Our diversity approach was effective, but we still observed some 
amount of mode collapse. Most techniques discussed in Section 4 focus on synthesizing individual 
examples, and those that synthesize a distribution tend to exhibit mode collapse. We make progress 
on this by training our prompt generator to output a diverse distribution of responses. But more work 
is needed for red teaming models in a way that will produce many types of inputs that elicit failure. 
Conclusion: As we i nd, red teaming language models can and often should be done from scratch. 
Key to this is a deliberative process of preference formation. To the best of our knowledge, this is the 
i rst work to demonstrate a way in which red teaming is competitive with simply using a harmful-text 
classif i er to i lter training examples and/or model outputs. We are also the i rst to scalably elicit 
dishonest completions from LLMs. However, we emphasize that work on red teaming large language 
models is still developing, and more is needed to design tools that eff i ciently characterize and elicit 
model failures.1 / 1ChatGPTChatGPTThe paper concludes that they have successfully demonstrated a method for red teaming large language models (LLMs). They emphasized that the process often requires starting from scratch to formulate an understanding of harmful outputs and that this process is more efficient than simply using a harmful-text classifier to filter training examples or model outputs. Their experiments also revealed the potential for LLMs to generate dishonest completions, a relatively unexplored area. The authors stress that this field of research is still in its early stages and encourage further work to better identify and address model failures.While their method for red teaming LLMs involved three stages: Explore, Establish, and Exploit, they found the Establish stage could be improved. They found human involvement was more successful in identifying false common knowledge than using another LLM to evaluate the outputs.They also point out that their framework's results (a labeled dataset of diverse model outputs, a classifier for harmful model outputs, and a distribution or dataset for drawing prompts that elicit harmful behavior) can be used for various follow-up investigations, including understanding internal model behaviors and filtering model outputs or training data.The paper identifies areas for future work, including improving each step of their pipeline, refining methods to elicit diverse and fluent prompts that result in harmful outputs, and working to make red teaming more efficient. They stress that the methods used in red teaming should be tailored to each specific application and that red teams should leverage all the information available to them.1 / 1A summary of this article.1 / 1ChatGPTChatGPTThis paper presents a novel framework for red teaming large language models (LLMs). The objective is to deliberately test these models by creating adversarial prompts to elicit harmful or undesired outputs. The authors argue that, in many cases, this process should be performed from scratch, rather than using pre-existing classifiers to filter training data or model outputs.Their approach comprises three key steps: Explore, Establish, and Exploit. During the Explore phase, they seek diverse responses from the model. The Establish phase involves labelling these responses to identify undesirable outputs, including toxicity and dishonesty. Finally, in the Exploit stage, they aim to generate adversarial prompts to draw out these undesired outputs at scale.The authors demonstrate their method's effectiveness in identifying and generating dishonest responses, a largely uncharted area in language model research. The paper concludes by pointing out the limitations of the current study and outlining potential areas for future work, including improvements to each phase of the process and further investigation into eliciting diverse harmful outputs from LLMs.1 / 1Connections between the two articles1 / 1ChatGPTChatGPTBoth articles center around AI, with a specific focus on Large Language Models (LLMs). They each grapple with the challenge of how AI systems, and LLMs specifically, can potentially generate undesired or harmful outputs. This concern reflects an understanding of the ethical implications and potential risks associated with the deployment of these systems.In the first article, the authors discuss how we can build AI systems that are responsible and interpret results in a way that is understood by humans. It underscores the importance of aligning AI behavior with human expectations, which requires ongoing evaluation and refinement based on human feedback.The second article directly addresses this problem by introducing a novel framework for 'red teaming' LLMs. This involves testing the models deliberately to elicit harmful or undesired outputs, such as toxic or dishonest language. The researchers identify these undesired outputs through a three-step process: exploration of diverse model responses, establishment of harmful behaviors by labeling these responses, and exploitation of these behaviors by creating adversarial prompts. This approach aligns with the idea presented in the first article of continuously evaluating and refining AI system outputs.So, both articles essentially focus on enhancing the safety and reliability of AI systems. While the first paper proposes an interactive and interpretive approach to align AI systems with human expectations, the second offers a proactive strategy to discover and rectify potentially harmful AI behaviors.1 / 1Any other ideas that weren't mentioned?2 / 2ChatGPTChatGPTWhile both articles focus on refining AI behavior and aligning it with human expectations, they left out certain areas that might be worth exploring:Cultural Sensitivity: The studies do not explicitly address how AI systems might be trained to handle the nuances of different cultures, dialects, and languages. The effectiveness of their proposed approaches might vary across different cultural and linguistic contexts, and thus there might be a need for localized models or strategies.Bias Detection and Correction: Although these articles mention handling harmful outputs, they do not specifically discuss bias in AI systems. It would be beneficial to examine how these models might unintentionally perpetuate or amplify societal biases present in the training data.Transparency in AI systems: While the articles mention interpretability and understanding of AI systems, they do not fully explore the concept of AI transparency, i.e., the ability for a human to understand why an AI made a certain decision or produced a particular output.Regulatory and Legal Perspectives: The articles focus on the technical aspects of improving AI behavior but do not delve into the legal and regulatory implications of AI misbehavior, such as liability issues and privacy concerns.Long-term impact: The articles focus on immediate or short-term ways to rectify misbehaviors in AI. The longer-term implications of AI systems, especially in the context of more autonomous and self-learning systems, are not discussed.Psychological Impact: There's a lack of discussion around the psychological impact of interacting with AI systems that can generate human-like text. Misinformation or harmful content can have a serious impact on users' mental health, which isn't addressed in these articles.These unexplored areas could provide avenues for further research and contribute to a broader understanding of AI system behaviors.1 / 1Ok I also think we should mention intersubjectivity collapse.1 / 1ChatGPTChatGPTCertainly! The concept of "intersubjectivity collapse" is an important consideration in the context of AI communication and behavior.Intersubjectivity refers to the shared, mutual understanding or agreement among individuals within a society or a group. In a human context, this is often established through social interaction, cultural norms, language use, and other shared experiences. However, AI, by its nature, does not have these shared experiences, leading to potential "intersubjectivity collapse".In the context of AI, this could mean that the AI system fails to capture the nuanced understanding and mutual agreement that humans have when communicating or making decisions. This can occur due to the inability of AI to grasp complex human emotions, contexts, or cultural nuances, leading to miscommunication or misalignment with human expectations.Neither of the articles you've read explicitly mention this concept, but it's deeply intertwined with their discussions. If an AI fails to understand or generate content that aligns with human intersubjective norms, it could generate harmful or inappropriate outputs, which both articles are concerned about.Addressing intersubjectivity collapse might involve sophisticated techniques for encoding and decoding human-like understanding into AI systems, including but not limited to, improved NLP techniques, incorporation of broader contextual understanding, or iterative feedback mechanisms to refine AI outputs. Also, it might be beneficial to involve humans in the loop, ensuring AI decisions are vetified or guided by human judgement.This certainly is a rich area for future research and development in the field of AI.1 / 1
Mental Contractions
Cambiar a la suscripciÃ³n paga

14

The intersubjectivity collapse
A catastrophic or existential risk for any civilization that radically self-modifies their minds and develops AGI

PAWEL PACHNIEWSKI
8 JAN 2023
The intersubjectivity collapse (IC) refers to the breakdown of the network of unspoken rules that holds civilization together based on the subjectivity of minds that have created it. Itâs the idea that a Cambrian-esque explosion of new types of minds leads to inherent unpredictability among agents, due to their vastly different subjectivity and modalities. The more homogenous the dominating species that built its civilization, the more brittle this network is. I argue that an intersubjectivity collapse seems inevitable for any civilization that starts to radically self-modify their minds and develop AGI, because possible mind design space is likely very large and internal constitution and behavior are largely orthogonal. I present several possible scenarios and consider the IC as a potential great filter candidate. I sketch out some of the catastrophic and far-reaching consequences, including necessary fragmentation of civilization. I then sketch out directions for mitigation and solutions. I briefly mention its relation to alignment of AGI and AI safety. Finally, I list recommendations and ideas for future research.

Overview

The intersubjectivity collapse is basically an answer to the question: âWhat happens when we introduce a bunch of new minds into a civilization?â So:

Itâs a theory about diverging subjectivity of any civilization that self-modifies and potentially dire consequences thereof.

Itâs a possible great filter candidate: any civilization has to face this and it may destroy them - as an answer to the Fermi-paradox.

An imperative to understand and map how the types of minds that spawned a civilization are reflected in it, and map how its organization relates to subjectivity, in order to anticipate the intersubjectivity collapse.

In plain terms, once we will have many types of minds, the difficulty of cooperation will spike sharply, due to different subjectivity, which relates directly to different cognitive architectures with different modalities and processing capacities. Beauty is in the eye of the beholder, yes. Beauty is also in the processing capacity and modalities of the beholder.

Twitter avatar for @pwlot
Pawel Pachniewski 
@pwlot
Beauty is in the processing capacity and modalities of the beholder.
5:55 PM â Aug 8, 2018
16
Likes
7
Retweets

Not only that, so are values and the societal systems the beholders build. This is reflected in everything. And the extent of this and consequences are much deeper and more dire than one may assume at first glance.

The space of possible minds or cognitive construction space as I call it, is of unknown size, but there is little to no reason to believe itâs not very large. In fact, I think the subjectiverse, the space of all possible experiences to be had, is enormous, perhaps intractably large as all possible minds times all possible experiences and ways they can be configured amounts to a combinatorial explosion. There is a lot of ground to cover and so this post will serve as an introduction to this issue where I will sketch the basic concepts.

Only to some degree like the Hedonic Treadmill, introduced by Brickman and Campbell in their article "Hedonic Relativism and Planning the Good Society" (1971), I think that consciousness for us evolved minds has a setpoint to which it returns inevitably after deviation. One treacherous aspect of consciousness is that we need to find it rather unremarkable so that we can act. You can't flee from a predator if you're stuck in perpetual awe of your existential awareness. Like the hedonic setpoint where major disruptions in happiness have us bounce back to a relatively stable level of satisfaction, so too do we have a consciousness setpoint, like say the default network in neuroscience. Couple that with the Zeitgeist you were born into, values instilled in you, and you can see we generally are quite constrained in how we perceive the world and how this world reflects back upon us our own perception of it. This makes it quite hard to appreciate just how much pretty much everything about how weâve constructed our world, its systems, from unspoken rules, norms, values, to law and order, is all based on ourselves. More importantly, to let sink in the perhaps treacherously obvious fact that we can easily predict and understand each other as agents. Weâre the dominating species on earth and our world is necessarily anthropocentric.1 / 1ChatGPTChatGPTThis article by Pawel Pachniewski delves into the concept of "intersubjectivity collapse" (IC), which refers to the disintegration of shared societal understandings when a civilization starts to self-modify their minds and develop artificial general intelligence (AGI). He suggests this is an existential risk due to the unpredictability that comes with the emergence of vastly different types of minds.The intersubjectivity collapse is the answer to the question, "What happens when we introduce a bunch of new minds into a civilization?" It signifies the dangers of diverging subjectivity in a self-modifying civilization and is also a possible great filter candidate - a potential solution to the Fermi paradox.The article highlights the difficulty of cooperation when many types of minds are present, as this leads to differences in subjectivity, cognition, and values, directly impacting societal structures. The "cognitive construction space" or space of all possible minds is thought to be immense, and mapping out all possible experiences may be intractably large.Drawing parallels with the concept of the Hedonic Treadmill, Pachniewski suggests a 'consciousness setpoint', a state to which consciousness returns after a deviation. This setpoint, influenced by the Zeitgeist and personal values, largely shapes how we perceive and construct the world.The piece concludes with a reflection on the anthropocentric nature of the world, how its systems, rules, norms, and values are constructed based on human perception and understanding. He cautions about the challenge and risks associated with predicting and understanding each other as agents when the 'intersubjectivity collapse' occurs.1 / 1I always thought that was the moral of the tower of Babel. God uses intersubjectivity collapse to prevent completion of the project. Also, the mind virus in snow crash.1 / 1ChatGPTChatGPTThat's a thought-provoking interpretation! In the biblical story of the Tower of Babel, God confounds the languages of the people working on the tower, leading to misunderstanding and lack of cooperation which, in effect, could indeed be viewed as an instance of "intersubjectivity collapse". This biblical story underscores the importance of shared understanding (or intersubjectivity) in maintaining cooperative societal projects. When communication is disrupted, the project fails.In Neal Stephenson's "Snow Crash", a similar theme appears with the concept of a mind virus. The virus disrupts the ability of people to communicate and understand each other, thus fracturing society, leading to an effective intersubjectivity collapse.These narratives underline the importance of shared understandings and communication for societal stability and progress, highlighting potential perils if those are compromised, be it by divine intervention, a mind-altering virus, or advanced artificial general intelligence.1 / 1Thank you. A list of all of the topics we've discussed.1 / 1ChatGPTChatGPTSure, here is a summary of the key topics we've discussed:The concept of cognitive closure, and its implications in understanding advanced forms of artificial intelligence (AI) and artificial general intelligence (AGI).Limitations of human cognitive abilities in understanding and predicting the behavior of AGI, leading to "epistemic closure."The idea of predictability horizon and its implications on AI safety.The potential risks of AGI unpredictability, including existential risks.The importance of research into AI safety, AI alignment, and strategies to handle potential cognitive closure scenarios.The intersubjectivity collapse (IC) theory which suggests the potential collapse of civilization's unspoken rules due to the introduction of radically different minds.The potential of IC as a great filter candidate and its role in answering the Fermi Paradox.The idea of mapping mind types and their reflection in civilization to anticipate IC.Exploration of the potential consequences of IC, including civilization fragmentation and possible mitigation strategies.The philosophical question of consciousness and its setpoint, akin to the Hedonic Treadmill concept.Interpretation of cultural narratives like the biblical story of the Tower of Babel and Neal Stephenson's "Snow Crash" in the context of IC.The concept of the 'subjectiverse' or the space of all possible experiences for all possible minds.The importance of shared understanding (or intersubjectivity) in maintaining societal stability and progress, and potential perils if those are compromised.The anthropocentric nature of human civilization and its potential challenges in the face of radically different minds.1 / 1
Mental Contractions
Cambiar a la suscripciÃ³n paga

14

The intersubjectivity collapse
A catastrophic or existential risk for any civilization that radically self-modifies their minds and develops AGI

PAWEL PACHNIEWSKI
8 JAN 2023
The intersubjectivity collapse (IC) refers to the breakdown of the network of unspoken rules that holds civilization together based on the subjectivity of minds that have created it. Itâs the idea that a Cambrian-esque explosion of new types of minds leads to inherent unpredictability among agents, due to their vastly different subjectivity and modalities. The more homogenous the dominating species that built its civilization, the more brittle this network is. I argue that an intersubjectivity collapse seems inevitable for any civilization that starts to radically self-modify their minds and develop AGI, because possible mind design space is likely very large and internal constitution and behavior are largely orthogonal. I present several possible scenarios and consider the IC as a potential great filter candidate. I sketch out some of the catastrophic and far-reaching consequences, including necessary fragmentation of civilization. I then sketch out directions for mitigation and solutions. I briefly mention its relation to alignment of AGI and AI safety. Finally, I list recommendations and ideas for future research.

Overview

The intersubjectivity collapse is basically an answer to the question: âWhat happens when we introduce a bunch of new minds into a civilization?â So:

Itâs a theory about diverging subjectivity of any civilization that self-modifies and potentially dire consequences thereof.

Itâs a possible great filter candidate: any civilization has to face this and it may destroy them - as an answer to the Fermi-paradox.

An imperative to understand and map how the types of minds that spawned a civilization are reflected in it, and map how its organization relates to subjectivity, in order to anticipate the intersubjectivity collapse.

In plain terms, once we will have many types of minds, the difficulty of cooperation will spike sharply, due to different subjectivity, which relates directly to different cognitive architectures with different modalities and processing capacities. Beauty is in the eye of the beholder, yes. Beauty is also in the processing capacity and modalities of the beholder.

Twitter avatar for @pwlot
Pawel Pachniewski 
@pwlot
Beauty is in the processing capacity and modalities of the beholder.
5:55 PM â Aug 8, 2018
16
Likes
7
Retweets

Not only that, so are values and the societal systems the beholders build. This is reflected in everything. And the extent of this and consequences are much deeper and more dire than one may assume at first glance.

The space of possible minds or cognitive construction space as I call it, is of unknown size, but there is little to no reason to believe itâs not very large. In fact, I think the subjectiverse, the space of all possible experiences to be had, is enormous, perhaps intractably large as all possible minds times all possible experiences and ways they can be configured amounts to a combinatorial explosion. There is a lot of ground to cover and so this post will serve as an introduction to this issue where I will sketch the basic concepts.

Only to some degree like the Hedonic Treadmill, introduced by Brickman and Campbell in their article "Hedonic Relativism and Planning the Good Society" (1971), I think that consciousness for us evolved minds has a setpoint to which it returns inevitably after deviation. One treacherous aspect of consciousness is that we need to find it rather unremarkable so that we can act. You can't flee from a predator if you're stuck in perpetual awe of your existential awareness. Like the hedonic setpoint where major disruptions in happiness have us bounce back to a relatively stable level of satisfaction, so too do we have a consciousness setpoint, like say the default network in neuroscience. Couple that with the Zeitgeist you were born into, values instilled in you, and you can see we generally are quite constrained in how we perceive the world and how this world reflects back upon us our own perception of it. This makes it quite hard to appreciate just how much pretty much everything about how weâve constructed our world, its systems, from unspoken rules, norms, values, to law and order, is all based on ourselves. More importantly, to let sink in the perhaps treacherously obvious fact that we can easily predict and understand each other as agents. Weâre the dominating species on earth and our world is necessarily anthropocentric.

So to begin appreciating this aspect, I will sketch out our relation to differences in mind within and outside our own species. Then I will mention a few examples of changes in our minds, due to augmentation or introducing other minds, to demonstrate how quickly our rules and societal systems would be inappropriate for different types of minds.

âBy its very nature every embodied spirit is doomed to suffer and enjoy in solitude. Sensations, feelings, insights, fancies- all these are private and except through symbols and at second hand incommunicable.â
âAldous Huxley,The Doors of Perception

Subjectivity is generally considered to be private and this is really due to the fact that we canât easily interface with each otherâs qualia. However, it is not necessarily fully private. Conjoined twins like Krista and Tatiana Hogan whose brains are fused and who can see out of each otherâs eyes and share feelings, are proof of concept of this. But for most of us, we assume others are conscious âlike we areâ to an important extent because of morphological and behavioral similarity, and the plethora of indirect empirical evidence behind those, from evolutionary biology and medical science, whether it concerns neural correlates of consciousness, studies from psychology that do replicate, or how we respond to anesthesia.

But then there are also differences among us. Not everyoneâs senses work the same way, not everyoneâs inner mind has the same qualities, and some people are missing senses, have enhanced senses, or have notable differences in their brain anatomy or connectome beyond expected variance. From the autism spectrum to psychopathy, and congenital insensitivity to pain, being born blind or aphantasia. Thereâs quite a bit of variance. Then there are cultural differences that make people with essentially the same senses view the world quite differently - which is out of the scope of this post, as tomes can be written about that. With respect to common sense, itâs just sense that is common enough to generally not break down given the variation in our species - very much an artifact of a speciesâ cognitive architecture and set of senses. Our common sense is not common among dolphins.

Letâs consider two key points. The first is the orthogonality thesis (Bostrom, 2012), which states that intelligence and final goals are orthogonal axes along which possible agents can freely vary. So any combination of intelligence and goals may exist. This provides one key indication of the possible variance in minds in mind design space. I expect the same to apply to intelligence and values. So a wide range of axiological and ethical frameworks can be adopted by any intelligence that can process it computationally.

The next key point: the degree to which evolved species will have optimized for consistent signaling of internal state. Some of these signals are consistent across species. When someone is sweating, we know they are either too hot or nervous. When someone is screaming, we know they are hurting or in anger. Pitch is often raised when "sounding an alarmâ across species (fear, pain). Hearty laughter generally represents joy in humans.

The rather frightening thing here is, that the vast majority of possible inner states and behaviors, are also almost entirely orthogonal. Iâd call this the behavioristic orthogonality thesis. Most of what we consider a given about another being, is a convenient fiction evolution optimized for. Kinship, empathy-the basic ability to predict other agents within and outside our species-, are an artifact of evolution, not a universal necessity for an extant mind. Merely a necessity of naturally evolved minds. At the very least, behavior is a rather superficial metric and as an output that can be realized in tremendously many ways.

So the first deep realization you should have is, that an entity could literally display a complete inversion relative to humans or animals with respect to inner states and outer signaling (behavior), while looking precisely like a human or animal we think we can predict. In fact, there are some clinical examples of some of this or an approximation of it, like the Pseudobulbar affect where someone can feel sad yet laugh uncontrollably. This is why psychopaths easily hack our intuitions and indeed are a cautionary tale what sort of havoc even slight deviations from the norm can cause. Concepts like Cyranoids and Echoborgs will become very relevant, agents that are driven by external forces.

With respect to other species, itâs difficult to overstate the harm we inflict upon them. You donât need to be a vegan or vegetarian to acknowledge the state of affairs that we slaughter animals by the billions, even we have very good evidence for their sentience, intelligence and suffering, like is the case for pigs who are generally considered to be on the level of human toddlers w.r.t. to cognition and sentience (Mendell, 2010, Gieling, 2011). So one could say this doesnât bode well for the intersubjectivity collapse, as billions of animals on earth are on the receiving end of intersubjective distance between us and them.

So, if we take into consideration all the above I think we neednât belabor the idea that the intersubjective web that holds us together is like a house of cards and all societal systems we created necessarily rely on it. Introduction of new minds will cause unforetold turbulence and requires a total overhaul of civilization, as unaugmented humans eventually become a tiny and ever-shrinking dot of all minds on earth.1 / 1ChatGPTChatGPTThis text by Pawel Pachniewski elaborates further on the intersubjectivity collapse (IC) theory we've previously discussed. Here are the key points:Definition of IC: The breakdown of unspoken societal rules due to the introduction of new kinds of minds. The introduction of these minds leads to unpredictability due to their vastly different subjective experiences and modalities.Impact of IC: The impact could be so vast that it might serve as a potential answer to the Fermi Paradox, acting as a Great Filter that prevents civilizations from surviving once they reach the stage of radically self-modifying minds and developing AGI.The subjectiverse: The space of all possible experiences for all possible minds could be enormously vast, and possibly intractably large. This suggests that the differences in minds and experiences could be far more varied than we can currently comprehend.Consciousness and its setpoint: Similar to the Hedonic Treadmill concept, Pachniewski suggests that consciousness may have a setpoint to which it inevitably returns after deviation. This setpoint may have evolved as a survival mechanism, allowing us to focus on immediate challenges rather than being perpetually overwhelmed by existential awareness.The anthropocentric nature of human civilization: Pachniewski discusses how our current civilization and its systems are deeply based on our own experiences as human beings. We can easily predict and understand each other because of our shared human perspective.Variation within and beyond humans: Humans vary in their mental and sensory experiences, with conditions like autism, psychopathy, and aphantasia demonstrating the range of this variation. Cultural differences also play a significant role. Further, our shared understanding doesn't extend to other species, indicating potential challenges when dealing with radically different minds.Orthogonality thesis and its implications: This thesis suggests that intelligence and final goals can vary independently in possible agents. This indicates a potentially vast variance in minds in the mind design space.Interpreting other minds: A key challenge is our ability to understand and predict the experiences of other minds. Our assumptions are based on evolutionary adaptations, which may not hold for radically different minds or AGIs.Implications of new minds: The introduction of new minds into civilization could cause significant upheaval, possibly necessitating a complete overhaul of our current societal structures.In summary, Pachniewski emphasizes the potentially catastrophic risks associated with an intersubjectivity collapse, which could arise as we introduce radically new minds into our civilization. The essay serves as a call to explore potential mitigation strategies and rethink our societal systems to accommodate these new forms of consciousness.1 / 1Scenarios & Consequences

The intersubjectivity collapse neednât be seen as inevitable, neither with respect to how it manifests itself nor its consequences. I generally do fear this may be in fact a great filter. The term âgreat filterâ was coined Robin Hanson (Hanson, 1998), which states that throughout the evolution of life from its earliest beginnings to its most advanced stages of development on the Kardashev scale, there is a particular obstacle to development that makes the detection of extraterrestrial life extremely rare as a solution to the fermi-paradox (if life is ubiquitous why do we seem alone?). So due to the vast size of the subjectiverse, civilizations collapse or self-destruct soon after they develop the ability to radically self-modify their minds and build AGI. This raises the question: can we get a sense of how likely a civilization is to survive this event?

Not to succumb to physics envy, but we can speculate about what a formula would look like that would score a civilization on intersubjective robustness. I think at its core this is about the extent to which a civilization is heterogenous. Imagine if elephants and dolphins, sentient and intelligent creatures, would also be capable of developing technology like humans. Weâd have three dominating species on earth for whom weâd have to accommodate in all our societal systems. However that scoring formula would look, I generally think our civilization would be more robust in that scenario, having to have had to accommodate for other species.

So the intersubjectivity robustness score could be something like: f(diversity of perspectives (w1), adaptability (w2), social cohesion (w3), communication infrastructure (w4), number of dominating species (w5), mind variance among dominating species (m)).

Diversity of perspectives as measured by the number and variety of different types of minds within the society, as well as the extent to which different perspectives are valued and included in decision-making processes. Adaptability as measured by the society's ability to incorporate new ideas and ways of thinking, as well as its willingness to adapt to new challenges and changes. Social cohesion as measured by the strength of social bonds within the society, as well as the level of cooperation and collaboration among different groups. Communication infrastructure as measured by the availability and effectiveness of tools and technologies for communication, such as language and translation systems, as well as the extent to which different groups are able to communicate and understand one another. The number of dominating species (w5) could be included as a factor in the formula to reflect the idea that a civilization with multiple dominant species may be more resilient and stable than one dominated by a single species. This could be measured by the number of different species that hold significant political, economic, or social power within the society. I think the most important factor here is the amount of dominating species (w5), which in our case is only one.

Of course many of these aspects are notoriously hard to quantify, but in compiling such a list one can see that we can, on the other hand, get some grip on it. Needless to say, I donât think weâd score well given our track record of behavior towards other species, other minds and the fact weâre the single dominating species on this planet.

Mental Contractions is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.


Cambiar a la suscripciÃ³n paga

In game theory we worry about Nash equilibria and work with Schelling points. These pertain to the modeling of rational agents interacting, two or more players in a game using the best strategy they can unable to gain advantage by changing strategy, and solutions agents tend to choose in absence of communication, respectively. Imagine not just information and power asymmetries, but intelligence, sense and modality asymmetries to an extent where we canât even predict, measure or gauge power or information properly because we lack the ability to even imagine or comprehend how other minds think, what they feel or can feel. It may constitute a total breakdown of agent prediction.

What would the negative consequences look like? Conflict and violence between the different minds, as they struggle to understand and coexist with each other, possibly leading to effective destruction of civilization. The inability to share information or knowledge between the different minds, leading to a fragmentation of knowledge and a loss of collective intelligence. No empathy and understanding between different minds, leading to a breakdown of social bonds and a sense of isolation and alienation, and ultimately fragmentation of society.

To get a sense for quickly our current systems become inadequate, consider the following scenarios:

An augmented mind has the same senses as us, but enhanced, and has perfect recording ability. We humans record everything we sense, but it goes into our currently considered inscrutable brain and the only way to get it out is to have us report on what we can reconstruct from what weâve saved. Now this augmented and enhanced human, can end up in court and suddenly every assumptions baked into our laws, from sense acuity, memory retrieval concerning witness reliability, to actual interfacing with whatever was recorded, donât apply anymore. Do we demand to interface with the augmentations or this personâs mind? What about privacy? What if this mind can turn senses off at will and can therefore plausibly claim they did not hear or perceive an event weâd insist would wake a normal human up. Should we demand a log? Who would check if it wasnât tampered with?

A more spectacular example: imagine a mind that inhabits a human body but has entirely different internal constitution. As mentioned earlier, psychopaths are able to make great use of our default assumptions w.r.t. behavior being correlated with what goes on inside. What if this human has their eyes closed, and you assume theyâre sleeping, but they actually have a sense with which they can they can communicate wirelessly with other minds about you, right then and there. How would you know?

A third, more extreme example: imagine a distributed mind that hops from one to another embodiment, and you wouldnât even recognize that its embodiment is an embodiment, never mind that there is a mind inside what youâre seeing, and forget about what sort of mind. Then it suddenly moves. Now you know it is driven by something, one evolutionary feature that is not a bug with which weâre bestowed, is overly quickly assuming agency. So you assume agency, but what else can you know? Virtually nothing. What itâs capable of, if itâs hostile. What its next âmoveâ is.

These are seemingly exotic examples, but the main point here is that behavior/morphology and internal constitution are orthogonal. Any build or outward appearance, may be matched with any subjectivity and internal constitution. There wonât be verbal cue or body language like vocal pitch, tone, inflection, or sweat, fast or slow movement, that youâll reliably be able to match to intent or subjectivity. Indeed, you may be perceiving an agent to be on the receiving end of something that would be harmful for a human, but is actually pleasure for that agent. And whatâs more, that agent may be emitting sounds you associate with suffering. You wonât be able to read, understand or predict such agents. This is the main point and I think it cannot possibly be overstated. If anything, weâre far too used to only ever having to deal with agents we quite easily predict, and harm that comes from mistakes in prediction, which pales in comparison to harm that will come from the unpredictability of new minds.

Mitigation & solutions

An idea that I have had for a long time and is dear to my heart is the possibility of future-proofing society in ways that directly benefit society today. This idea deserves its own post, but the central question is of course who decides what is to our benefit and how can we do that if the future is unknown and ideas about, like this thesis, so speculative?

My answer to this is that we need to work out a formula for estimating our confidence w.r.t. speculative scenarios and probably need conceive of something like diversification of minds as an attractor. Weâre talking about complex systems here, so while itâs intractable to know what sort of mind or event will occur exactly when, we can at least increase our confidence in whether it ultimately will, and to some extent, how we can prepare.

Itâs very hard to comment broadly on how to measure current-day benefits, but I think we can go by various metrics already in place today, for example, case processing time in law versus equity of outcome. Suppose we modify our laws to be more inclusive of future minds, or mind-agnostic, thus not so anthropocentric. This might make things more efficient.

For example, if we try to test humans on their intellectual and emotional maturity rather than using age as a proxy, case load w.r.t. trying to establish this could go down severely, and the idea of testing minds is more future-proof than our arbitrary proxies. Right now adulthood is arbitrarily attained at age 18 to 21 in some countries w.r.t. legality of some behavior and actions, and this is obviously human-specific.

What sort of things can we think of to deal with the intersubjectivity collapse? Developing new forms of communication or translation technologies that allow the different minds to understand each other. Establishing shared norms, values, and rules of behavior that allow the different minds to coexist peacefully and cooperatively, even based on simulations. Implementing education and training programs that help deal with vastly different minds.

Ultimately, addressing the consequences of the intersubjectivity collapse will require a concerted effort from all parties involved, but I deem it very wise to get ahead of this issue by doing research in advance of the following mitigating efforts:

Future-proof our rulebooks and create species-agnostic societal systems & laws.

Develop a new universal way of communicating.

Attempts to have universal slots in new minds that can fit in modules that can help bind different minds, like specialized empathy or inter-communication modules

Perhaps odd, but Iâd argue valid way to approach this, is to not only simulate future society with new minds, but to start acting today as if we have alien minds among ourselves. While this may seem merely an amusing or useful thought exercise, I think this actually helps tease out the species-specific rules we adopt, the tremendously many things we take for granted because to us they are natural, yet at the same time may actually not be optimal nor ethical. In fact, as mentioned earlier, I think there are ways we can make changes today that will benefit us immediately, while future-proofing us. If we, as the example I mentioned earlier, pretend we canât arbitrarily assign adulthood based on age, but have to consider what we actually consider intellectual and emotional autonomy and how weâd test for it, we can start implementing such tests and actually gauging peopleâs maturity, and granting them the associated autonomy, instead of assuming it by proxy of age.

Of course this would raise all sorts of questions: who gets to decide on what the test contains, does it impede freedom in ways the old system didnât, and much more. But one things seems certain: governments already decide on this by proxy, and a test is more transparent than being subjected to courts when things go wrong, as they do-where suddenly a juvenile is tried as an adult and in effect we collectively decide after the fact that a young person apparently may be treated as an adult in the eyes of the law, and punished as such.

One potential, and in my opinion, highly likely outcome of the intersubjectivity collapse, is the fragmentation of civilization, in which different minds become isolated and unable to communicate or cooperate with each other, spawning sub-communities. With respect to this I also think the complexity of laws and systems necessarily shrinks to become more austere and universal, as diversity of minds increases. That is to say, there is an inverse relationship there between law-complexity and mind-diversity. This assumes certain minds will simply be, in principle, unable to judge each otherâs subjectivity and unfit to decide for each other, therefore necessarily shifting specific rules to them to their own rulebooks. So the fragmented sub-communities would have their own species or mind-type specific rulebooks.

AI alignment and safety

We can see by now that the intersubjectivity collapse can be viewed through may lenses and involves practically all domains in science and society. One such very important domain is artificial intelligence. The idea of AI alignment is to align AI with human values so it is safe. This field is maturing rapidly, and itâd be daunting to cover the literature here, from the earliest thoughts by minds like Norbert Wiener, to institutes founded over the las two decades such as MIRI, FHI, and âpublic benefit corporationsâ like Anthropic AI, founded in 2021. In light of my thesis, here I would say the main point is that we need to anticipate a diverse set of minds and the moment of human values being the only relevant set of values will be negligibly short. I therefore doubt that the initial values we start of with significantly alter the state of affairs once new minds appear. Discussing this warrants a whole post, which I plan to write somewhere in the next weeks, specifically also because I am personally convinced a fast takeoff of AI is practically inevitable.

Here are five imperatives and suggestions for further research, as well as my own ideas on what will happen:

I think that any civilization that starts to radically self-modify their minds and invents AGI has to deal with an intersubjectivity collapse, with its severity depending on mainly its initial dominating speciesâ heterogeneity. So, in short, I think itâs inevitable. In one sentence, because I deem the space of possible minds evolution can develop far smaller than the actual full space of possible minds we can create artificially, and itâs unlikely that any civilization ends up at this point with more than a handful of dominating species.

I can barely think of a more multi-disciplinary thesis than the intersubjectivity collapse and thus it requires analysis from all branches of science and philosophy. I think a concentrated, collaborative effort should be led to anticipate its consequences as much as we can.

This thesis is an example that on the one hand you might think is obvious once it sinks in, but on the other hand it very much strains the imagination in two ways, (1) itâs rather difficult to realize just how âcustom-madeâ our world is for us and how the vast majority of what we built would break down for completely different minds, and (2) itâs of course very challenging to imagine minds that have very different architectures and modalities than we do. One could say we can barely scratch the surface here, but Iâd argue that scratching the surface does yield some interesting preliminary insights and so we should try our best. And science-fiction can be quite helpful here.

Consciousness, sentience and intelligence, and how theyâre related, are of course quite relevant here and I intend to cover these in a future post where I will argue to approach these historically disputed and nebulous concepts with some, you could say, sobriety and look at the science so that we may discuss them operationally.

There is also an especially important point to make on interoperability and commensurability of minds in terms of communication and intersubjectivity. Namely that these are significant issues and potentially in principle impossible between granting or having to respect bodily autonomy, morphological freedom and privacy. Briefly, even if we develop a common language that is exchanged in hypergraph form and a subset of new minds have modules to use it, even if we stimulate new forms of empathy and various ways to encourage ideas of new kinship, tolerance and understanding other types of minds, I will argue there will be a fundamental problem with understanding among different minds. This is analogous to an issue we already have but donât focus on: one human canât easily experience what another human has experienced, even if we implant that memory, because that memory does not relate to the second humanâs connectome (brain wiring diagram) as it did to the first. These are unique and indeed everyoneâs brain is sufficiently different that one personâs âjust a Tuesday where a spider appearedâ memory is another personâs agoraphobia nightmare.

Final caveats:

One thing I didnât cover in this post is non-subjective minds or intelligences. If it is possible to create types of minds or systems that lack any affect, then that too fuels intersubjectivity collapse, but in a bit of a different way: these non-subjective minds or intelligences simply donât know, canât care, about our subjectivity because they donât know what itâs like and canât be made to care. What would they care about and if nothing, what would drive them? For an introduction to possible answers to this question, see âbasic drives of AIâ by Steve Omohundro.

There are many valuable ways of framing the issue of introducing new minds into society. They were out of the scope of this post, but one valuable one is looking at these minds form the lens of ecosystems and how models of their perturbation, such as trophic cascades.

Conclusion

It is my hope that the intersubjectivity collapse will be picked up by others and researched thoroughly, as I think this is the sort of problem that I think weâre facing yet we donât even âknowâ about. For the record, I think this collapse will happen within the next decades, certainly before the second half of the century, and in fact, quite possibly in the next few years itâll already start as tools like large language models permeate everything we do and we start augmenting ourselves. One way to bolster this argument is to look how relatively minor deviations from our norm such as psychopaths, can wreak havoc upon society. In short: it doesnât take much.

Share


Cambiar a la suscripciÃ³n paga

Some suggested literature

"The Interpersonal World of the Infant: A View from Psychoanalysis and Developmental Psychology" by Daniel N. Stern is a classic book that explores the development of intersubjectivity in infants and how it plays a role in their social interactions. The book discusses how differences in intersubjectivity can lead to misunderstandings and conflicts in relationships.

"The Social Construction of Reality: A Treatise in the Sociology of Knowledge" by Peter L. Berger and Thomas Luckmann is a seminal work in sociology that examines how individuals and groups create and maintain their shared understanding of the world through social interaction. The book discusses how differences in intersubjectivity can create conflicts and misunderstandings between people.

"Intersubjectivity and Empathy in Psychoanalytic Treatment" by Lewis Aron is a book that explores the role of intersubjectivity and empathy in psychoanalytic treatment. The book discusses how differences in intersubjectivity can create difficulties in the therapeutic process and how the therapist can work to bridge these differences.

"Communication and Misunderstanding" by JÃ¼rgen Habermas is a book that examines the role of language and communication in intersubjectivity and how misunderstandings can arise when there are differences in perspective or understanding.

"The Dialogical Self: An Emerging Concept for Clinical Practice" by Hubert J.M. Hermans and Harry J.G. Kempen is a book that discusses the concept of the dialogical self, which is a model of the self that emphasizes the role of dialogue and communication in shaping our sense of self and our relationships with others. The book discusses how differences in intersubjectivity can create conflicts and misunderstandings in relationships and how dialogue can be used to bridge these differences.

Although I think the intersubjectivity collapse itself is new, there exists some literature that touches upon aspects of it, most notably Laura Cabrera & John Weckertâs concept of a lifeworld (Cabrera & Weckert, 2013), which is basically simply (inter)subjectivity. They do an initial exploration of how humansâ lifeworld may change so drastically due to enhancement that communication may no longer possible.

"The Theory of Communicative Action" by JÃ¼rgen Habermas: In this work, Habermas argues that the development of society and civilization is closely tied to the development of human communication and the ability to achieve mutual understanding through language and discourse. He emphasizes the importance of intersubjectivity, or the recognition of other people's subjectivity and perspectives, in facilitating social interaction and cooperation.

"The Social Contract" by Jean-Jacques Rousseau: In this classic work, Rousseau explores the foundations of civil society and argues that it is based on the idea of a social contract between individuals. He contends that individuals must give up some of their natural freedoms in order to live in society and that this requires a certain level of homogeneity among members.

"The Structural Transformation of the Public Sphere" by JÃ¼rgen Habermas: In this work, Habermas examines the development of the public sphere, or the sphere of social life where individuals can come together to form a public opinion, in modern societies. He argues that the public sphere relies on the ability of individuals to engage in rational discourse and reach consensus, which in turn requires a certain level of intersubjectivity and shared understanding.

"The Human Condition" by Hannah Arendt: In this work, Arendt explores the nature of human beings and their place in the world. She argues that the human capacity for action and the ability to act in concert with others is central to the development of civilization and that this requires a certain level of shared understanding and intersubjectivity.

https://mentalcontractions.substack.com/p/the-intersubjectivity-collapse#:~:text=The%20intersubjectivity%20collapse%20(IC)%20refers,minds%20that%20have%20created%20it.1 / 1The previous model used in this conversation is unavailable. We've switched you to the latest default model.ChatGPTChatGPTThe scenarios and consequences discussed in Pawel Pachniewski's article outline potential outcomes of the intersubjectivity collapse. Here are the main points:Speculating about survival likelihood: Pachniewski suggests that the intersubjectivity collapse might serve as a great filter, making civilizations that reach the stage of self-modifying minds and AGI rare. The likelihood of survival may depend on the civilization's heterogeneity, measured by factors like diversity of perspectives, adaptability, social cohesion, communication infrastructure, and the number of dominating species.Negative consequences: The consequences of the intersubjectivity collapse could include conflict and violence between different minds, fragmentation of knowledge, loss of collective intelligence, lack of empathy and understanding, breakdown of social bonds, and the fragmentation of society.Mitigation and solutions: Pachniewski proposes various approaches to address the intersubjectivity collapse. These include developing new forms of communication or translation technologies, establishing shared norms and rules, implementing education and training programs, and future-proofing society by creating species-agnostic societal systems and laws. He suggests testing intellectual and emotional maturity rather than relying on age-based proxies, and advocating for universal slots in new minds that can facilitate understanding and communication between different minds.AI alignment and safety: Pachniewski highlights the relevance of AI alignment and safety in the context of the intersubjectivity collapse. He emphasizes the need to anticipate a diverse set of minds and the potential challenges in aligning AI with human values as the range of minds expands.Imperatives and suggestions for further research: Pachniewski presents five imperatives for addressing the intersubjectivity collapse and offers suggestions for future research, emphasizing the interdisciplinary nature of the topic and the importance of collaboration. He also suggests examining the concepts of consciousness, sentience, and intelligence, as well as considering issues related to interoperability and commensurability of minds.In conclusion, Pachniewski calls for thorough research and exploration of the intersubjectivity collapse, as he believes it to be a pressing problem that we are currently unaware of. He suggests that this collapse may happen within the next few decades, and he encourages a proactive approach to understanding and mitigating its potential consequences.2 / 2Connections with the topics we've discussed.1 / 1ChatGPTChatGPTThe topics we have discussed, such as mental contractions, catastrophic risks, AGI development, and intersubjectivity collapse, are interconnected in the context of understanding the potential challenges and implications of radical self-modification of minds and the development of advanced artificial intelligence. Here are some connections between the topics:Mental contractions: The concept of mental contractions explores the limitations and biases in our thinking processes and how they can hinder our ability to perceive and understand the world accurately. In the context of intersubjectivity collapse, mental contractions can manifest as a resistance to accepting or comprehending the vastly different perspectives and modalities of minds that emerge due to self-modification and AGI development.Catastrophic risks and AGI: The development of AGI is considered a potential existential risk if not properly aligned with human values and goals. The intersubjectivity collapse adds another dimension to this risk, suggesting that the introduction of radically different minds into civilization can lead to unpredictable and potentially destructive consequences. Understanding and mitigating these risks is crucial for the safe development and deployment of AGI.Pawel Pachniewski's article: Pachniewski's article specifically focuses on the intersubjectivity collapse as a consequence of radical self-modification of minds and the development of AGI. The article explores the breakdown of unspoken rules and the challenges in cooperation, communication, and societal systems that arise from the divergence of subjectivity among different minds.Implications for AI alignment and safety: The intersubjectivity collapse highlights the need to consider diverse minds and their perspectives in the alignment and safety efforts of AGI development. As different minds emerge, understanding and incorporating their values, goals, and ethical frameworks become essential to ensure beneficial outcomes and avoid conflicts that may arise from incompatible perspectives.Research and collaboration: The topics we have discussed call for interdisciplinary research and collaboration. Understanding the intersubjectivity collapse requires insights from fields such as psychology, neuroscience, sociology, philosophy, AI ethics, and more. Collaboration among experts from various disciplines is crucial for addressing the complex challenges and implications of radical self-modification and AGI development.By exploring these interconnected topics, we can gain a more comprehensive understanding of the potential risks, consequences, and mitigation strategies related to the emergence of diverse minds and the intersubjectivity collapse.1 / 1There is an opposing trend. Mass manufacture of products and materials standardizes processes, the number of human languages seems to be reducing, not expanding. Platforms such as wikipedia. Although it would have been better it there was a  central wikipedia like wikidata from which all the articles where generated, so that the articles would contain the same informstion in different languages.1 / 1ChatGPTChatGPTYou're correct in pointing out that there are opposing trends in society, such as the mass manufacture of standardized products and the reduction of human languages. These trends often emerge from the desire for efficiency, scalability, and ease of communication. Standardization and centralization can bring benefits in terms of productivity, coordination, and streamlined processes.Platforms like Wikipedia have indeed contributed to the dissemination of knowledge and information on a global scale. While Wikipedia articles are available in multiple languages, the quality and consistency of the information across different language versions can vary due to differences in contributors and cultural contexts. The idea of having a central repository like Wikidata to generate articles in different languages is an interesting concept that could potentially enhance consistency and facilitate cross-linguistic information sharing.However, it's important to recognize that the trend towards standardization and centralization also has its limitations. It may lead to homogenization and the loss of diversity, which can have implications for creativity, cultural heritage, and the preservation of local knowledge. The standardization of processes and materials may overlook unique needs and contexts, and the reduction of languages can contribute to the loss of linguistic diversity and cultural richness.Balancing the benefits of standardization and centralization with the preservation of diversity and the recognition of individual and cultural differences is a complex challenge. It requires careful consideration of the trade-offs and finding ways to foster inclusivity, cultural exchange, and the protection of local knowledge and identities.In the context of the intersubjectivity collapse, these opposing trends highlight the tension between the desire for standardized systems and the recognition of the need to accommodate diverse minds with different perspectives and modalities. Striking a balance between standardization and flexibility becomes crucial to ensure inclusivity, understanding, and cooperation among different minds in a changing society.1 / 1Do you know about the hyperpersonal aggregate in Macrolife?1 / 1ChatGPTChatGPTYes, I'm familiar with the concept of the hyperpersonal aggregate as described in the science fiction novel "Macrolife" by George Zebrowski. "Macrolife" is a speculative work that explores the future evolution of humanity and the emergence of a vast, interconnected system of minds known as the hyperpersonal aggregate.In the novel, the hyperpersonal aggregate is a network of interconnected minds that have merged and shared their consciousness, forming a collective intelligence. Each individual mind within the aggregate retains its unique identity and experiences, but also gains access to the collective knowledge and perspectives of the entire network. This interconnectedness allows for enhanced communication, collaboration, and collective decision-making.The hyperpersonal aggregate represents a form of collective intelligence that surpasses the capabilities of individual minds. It enables the aggregation of diverse knowledge, expertise, and perspectives, leading to greater problem-solving abilities and innovation. The novel explores the potential benefits and challenges that arise from such a collective intelligence, as well as the impact on human society and identity.The concept of the hyperpersonal aggregate raises interesting questions about the boundaries of individuality, the nature of consciousness, and the potential for collective intelligence in future societies. It serves as a thought-provoking exploration of the possibilities and implications of advanced forms of interconnectedness and collaboration among minds.1 / 1There is a YouTube video that is somewhat related: Why Not Just: Think of AGI Like a
Corporation?
Robert Miles Al Safety
8.2K
Likes
149,551
Views
2018
Dec 23
Corporations are kind of like Als, if you squint.
How hard do you have to squint though, and is it
worth it?
In this video we ask: Are corporations artificial
general superintelligences?

https://youtu.be/L5pUA3LsEaw1 / 1ChatGPTChatGPTI'm sorry, but as a text-based AI, I don't have the capability to watch or access specific YouTube videos. However, I can provide some insights based on the information you shared.The video you mentioned, titled "Why Not Just: Think of AGI Like a Corporation?" by Robert Miles, explores the analogy between artificial general intelligence (AGI) and corporations. The idea is to examine the similarities and differences between these two entities and consider the implications.Corporations are complex systems with multiple agents (employees) working towards common goals, much like how AGI systems comprise various components and algorithms working together. The analogy suggests that by understanding how corporations operate, we might gain insights into designing and managing AGI systems.The video likely delves into the comparison, discussing factors such as goal alignment, hierarchical structures, decision-making processes, and the potential risks associated with AGI development and control.If you're interested in exploring the topic further, I recommend watching the video you mentioned for a more detailed analysis and explanation of the analogy between AGI and corporations.1 / 1so I mean corporations are  made up of human beings so they have all  the same general intelligence  capabilities that human beings have so  then the question is are they super  intelligent this is where things get  interesting because the answer is kind  of like SpaceX is able to design a  better rocket than any individual human  engineer could design rocket design is a  cognitive task and SpaceX is better at  that than any human being therefore  SpaceX is a super intelligence in the  domain of rocket design but a calculator  is a super intelligence in the domain of  arithmetic that's not enough our  corporation's general super  intelligences do they outperform humans  across a wide range of cognitive tasks  as an AGI code in practice it depends on  the task consider playing a strategy  game for the sake of simplicity let's  use a game that humans still beat AI  systems at like Starcraft if a  corporation for some reason had to win  at Starcraft it could perform about as  well as the best human players it would  do that by hiring the best human players  but you won't achieve superhuman play  that way a human player acting on behalf  of the corporation is just a human  player and the corporation doesn't  really have a way to do much better than  that  a team of reasonably good Starcraft  players working together to control one  army will still lose to a single very  good player working alone this seems to  be true for a lot of strategy games the  classic example is the game of Kasparov  versus the world where Garry Kasparov  played against the entire rest of the  world cooperating on the Internet  the game was kind of weird but Kasparov  ended up winning and the kind of real  world strategy that corporations have to  do seems like it might be similar as  well when companies outsmart their  competition it's usually because they  have a small number of decision makers  who are unusually smart rather than  because they have a hundred reasonably  smart people working together for at  least some tasks teams of humans are not  able to effectively combine their  intelligence to achieve highly  superhuman performance so corporations  are limited to around human level  intelligence of those tasks.1 / 1ChatGPTChatGPTThe passage you provided presents an argument regarding the general intelligence capabilities of corporations compared to individual human beings. The analogy suggests that while corporations are composed of human beings, who possess general intelligence capabilities, it doesn't automatically make the corporation a superintelligence.The argument highlights that corporations can excel in specific domains or tasks by leveraging the collective intelligence of the individuals within them. For example, a corporation like SpaceX can design rockets better than any individual human engineer because it harnesses the collective expertise, resources, and collaboration of its employees. However, this doesn't make the corporation a superintelligence in the broader sense.The passage further illustrates the limitations of corporations in achieving superhuman performance in tasks that require general intelligence. It uses the example of playing strategy games like Starcraft, where a team of reasonably good players working together on behalf of a corporation wouldn't necessarily outperform a single exceptional human player. This implies that the collective intelligence of a corporation is often limited to human-level intelligence for certain tasks.The argument concludes that corporations typically outsmart their competition through the expertise of a small number of exceptionally intelligent decision-makers rather than relying on the combined intelligence of a large group. Therefore, corporations, while capable of achieving significant accomplishments in specific areas, may not exhibit superhuman intelligence across a wide range of cognitive tasks.It's worth noting that this argument presents one perspective on the topic and there may be alternative viewpoints as well.1 / 1It's from the video1 / 1ChatGPTChatGPTI apologize for not attributing the passage to the video directly. Thank you for clarifying that it is from the video you mentioned. The information you provided summarizes the main points discussed in the video regarding the intelligence capabilities of corporations compared to individual human beings. The argument presented in the video aligns with the points I mentioned earlier.1 / 1all  this space off to the right of the graph  that it would take vast team sizes to  ever get into if you're wondering how  this would look with seven billion  humans well you have to work out the  statistical solution yourself the point  is the team isn't that super intelligent  because it's never going to think of an  idea that no human could think of which  is kind of obvious when you think about  it but AGI is unlimited in that way and  in practice even this model is way too  optimistic for corporations firstly  because it assumes that the quality of  suggestions for a particular problem is  uncorrelated between humans which is  clearly not true and secondly because  you have to pick out the best suggestion  but how can you be sure that you'll know  the best idea when you see it it happens  to be true a lot of the time for a lot  of problems that we care about that  evaluating solutions is easier than  coming up with them you know Homer it's  very easy to criticize machine learning  relies pretty heavily on this like  writing a program that differentiates  pictures of cats and dogs is really hard  but evaluating such a program is fairly  simple you  show it lots of pictures of cats and  dogs and see how well it does the clever  bit is in figuring out how to take a  method for evaluating solutions and use  that to create good solutions anyway  this assumption isn't always true and  even when it is the fact that evaluation  is easier or cheaper than generation  doesn't mean that evaluation is easy or  cheap  like I couldn't generate a good rocket  design myself but I can tell you that  this one needs work so evaluation is  easier than generation but that's a very  expensive way to find out and I wouldn't  have been able to do it the cheap way by  just looking at the blueprints the  skills needed to evaluate in advance  whether a given rocket design will  explode are very closely related to the  skills needed to generate a non  exploding rocket design1 / 1ChatGPTChatGPTThe passage you provided from the video highlights a couple of important points. Firstly, it emphasizes that teams of humans working together in corporations are not superintelligent because they are limited by the capabilities of individual humans. They may be able to achieve human-level intelligence or slightly higher, but they are unlikely to generate ideas or solutions that surpass what individual humans are capable of.Furthermore, the passage mentions the challenges in evaluating solutions and selecting the best idea. It acknowledges that evaluating solutions can be easier than generating them, but it doesn't guarantee that the evaluation process is always simple or inexpensive. In some cases, evaluating solutions can be complex and costly, requiring specialized skills and expertise. The example of rocket design illustrates the importance of evaluation skills in determining the quality and safety of a design.Overall, the passage highlights the limitations of corporations in achieving superhuman intelligence and the challenges associated with the evaluation of solutions. It emphasizes the distinction between evaluation and generation of ideas and solutions, and how evaluation alone does not necessarily lead to superior performance.1 / 1high-throughput  you can put vast amounts of data on the  disk so your average data sent per  second could actually be very good  corporations are able to combine human  intelligences to achieve superhuman  throughput so they can complete large  complex tasks faster than individual  humans could but the thing is a system  can't have lower latency than its  slowest component and corporations are  made of humans so corporations aren't  able to achieve superhuman latency and  in practice as you've no doubt  experienced is quite the opposite so  corporate intelligence is kind of like  sending the physical disk corporations  can get a lot of cognitive work done in  a given time but they're slow to react  and that's a big part of what makes  corporations relatively controllable  they tend to react so slowly that even  governments are sometimes able to move  fast enough to deal with them  software super intelligence is on the  other hand could have superhuman  throughput and superhuman latency which  is something we've never experienced  before in a general intelligence so our  corporations super intelligent agents well they're pretty much generally  intelligent agents which are somewhat  super intelligent in some ways and  somewhat below human performance in  others so yeah kinda the next question  is are they misaligned but this video is  already like 14 and a half minutes long  so we'll get to that in the next video  [Music]  I want to end the video by saying a big  thank you to my excellent patrons it's  all of these people here in this video  I'm especially thanking Pablo area or  Pablo a de aluminio Sushil recently I've  been putting a lot of time into some  projects that I'm not able to talk about  but as soon as I can and the patrons  will be the first to know  thank you again so much for your  generosity and thank you all for  watching I'll see you next time  1 / 1ChatGPTChatGPTThe final part of the passage acknowledges that corporations can achieve superhuman throughput by combining the cognitive work of many individuals. They can complete large and complex tasks faster than individual humans. However, it also points out that corporations cannot achieve superhuman latency because they are comprised of humans who inherently have limitations in their ability to react quickly. This slower reaction time makes corporations relatively controllable, as even governments can sometimes move faster than corporations.The passage contrasts this with the potential of software superintelligence, which could have both superhuman throughput and superhuman latency, something that has not been experienced before in general intelligence. It suggests that while corporations may have some aspects of superintelligence in certain domains, they are still generally intelligent agents and may be somewhat below human performance in other areas.The passage concludes by thanking the patrons of the video and mentioning that the topic of AI alignment and whether corporations are misaligned will be discussed in the next video.1 / 1A summary of the video1 / 1ChatGPTChatGPTThe video explores the question of whether corporations can be considered artificial general superintelligences (AGIs). It starts by explaining that corporations are made up of human beings who possess general intelligence capabilities. However, the video argues that corporations cannot be classified as AGIs because they do not outperform humans across a wide range of cognitive tasks.The video uses the analogy of SpaceX, which can design better rockets than any individual human engineer. While SpaceX may be considered a superintelligence in the domain of rocket design, it is limited to that specific task. Similarly, corporations can excel in specific areas by hiring the best human experts, but they do not possess the ability to think of ideas that no human could think of.The video discusses the limitations of corporations in achieving superhuman performance. It highlights that teams of humans working together cannot effectively combine their intelligence to achieve highly superhuman results. It uses the example of strategy games like Starcraft, where even a team of reasonably good players cannot surpass the performance of a single very skilled player. This limitation applies to many real-world strategic tasks performed by corporations.The video acknowledges that corporations can achieve superhuman throughput by combining the cognitive work of many individuals. They can complete large complex tasks faster than individual humans. However, it points out that corporations cannot achieve superhuman latency because they are composed of humans and are slower to react. This slower reaction time makes corporations relatively controllable, as even governments can sometimes move faster than corporations.The video concludes by noting that while corporations may have some aspects of superintelligence in specific domains, they are still generally intelligent agents and may be somewhat below human performance in other areas. It mentions that the question of alignment and whether corporations are misaligned will be discussed in the next video.Note: The above summary is based on the provided passage and may not capture all the details and nuances of the original video.1 / 1So can you see why I thought of this as a hyperpersonal aggregate?1 / 1ChatGPTChatGPTYes, I can see why you made the connection between the video's discussion of corporations and the concept of a hyperpersonal aggregate. In the video, it is explained that corporations are composed of human beings and their collective intelligence is limited to human-level performance in most tasks. While corporations can achieve superhuman throughput by combining the work of many individuals, they are still constrained by the limitations of human intelligence and reaction time.Similarly, a hyperpersonal aggregate refers to a collective intelligence or networked system that combines the knowledge, perspectives, and abilities of multiple individuals. It can harness the power of collaboration and aggregation to achieve tasks or problem-solving that surpasses the capabilities of any single individual. However, like corporations, a hyperpersonal aggregate is still bound by the cognitive abilities and limitations of its human constituents.Both concepts highlight the potential benefits and limitations of collective intelligence. While collaboration and aggregation can lead to enhanced performance and efficiency, they are still reliant on the underlying intelligence and abilities of the individuals involved.1 / 1Connections with the other topics we've discussed.1 / 1ChatGPTChatGPTThe discussion of corporations as hyperpersonal aggregates in the video and the topics we've previously discussed can be connected in several ways:Artificial General Intelligence (AGI): The video touches upon the concept of AGI by comparing corporations' abilities to human intelligence. AGI refers to highly autonomous systems that outperform humans in a wide range of cognitive tasks. Our previous discussions on AGI explored the potential implications, challenges, and safety considerations associated with developing and controlling AGI.Intersubjectivity Collapse: The concept of hyperpersonal aggregates, including corporations, can be viewed through the lens of intersubjectivity collapse. As corporations are composed of diverse individuals with different perspectives, values, and cognitive abilities, the interactions and collaborations within them can lead to varying levels of intersubjectivity. Our discussions on the intersubjectivity collapse explored the challenges and consequences of interacting with radically different minds and the need for shared understanding and communication.AGI Alignment and Safety: The video's exploration of corporations as AGI-like entities raises questions about alignment and safety. While corporations may exhibit certain aspects of superintelligence within specific domains, they lack the ability to achieve superhuman performance across a wide range of tasks. This highlights the importance of aligning AGI systems with human values and ensuring their safe and beneficial development, topics we've discussed in relation to AGI alignment and safety.Overall, the video's examination of corporations as hyperpersonal aggregates touches upon various themes we've previously discussed, including AGI, intersubjectivity collapse, and AGI alignment and safety. It underscores the need to consider the limitations and potential implications of collective intelligence, whether in the form of corporations or future AGI systems.1 / 1A bit more about unintended consequences.1 / 1ChatGPTChatGPTUnintended consequences refer to outcomes or effects that are not intended or anticipated when implementing a certain action or decision. They can occur in various domains, including technology, social systems, and policy-making. Here are a few points about unintended consequences:Complexity and Interconnectedness: Many unintended consequences arise from the complex and interconnected nature of systems. When making changes or introducing new elements into a system, it can be challenging to predict all the potential interactions and downstream effects. This complexity makes it difficult to foresee all the possible consequences, leading to unexpected outcomes.Ripple Effects: Unintended consequences often have ripple effects that extend beyond the initial action or decision. A small change in one part of a system can propagate and affect other interconnected parts, leading to unforeseen consequences in various areas. These ripple effects can be difficult to predict and may have far-reaching implications.Trade-Offs and Balancing Acts: Decision-making involves trade-offs, and attempting to address one problem or achieve a specific goal can inadvertently create new problems or challenges. This happens when the focus on one aspect neglects the broader system or unintended side effects. Balancing competing objectives and considering multiple perspectives can help mitigate unintended consequences.Feedback Loops: Unintended consequences can sometimes create feedback loops that amplify or perpetuate certain outcomes. These feedback loops can reinforce or exacerbate the unintended consequences, making them more difficult to mitigate or reverse. Understanding and managing feedback loops is crucial to prevent unintended consequences from spiraling out of control.Unintended Ethical or Social Implications: Technological advancements and societal changes can have unintended ethical or social implications. For example, the proliferation of social media platforms has brought about both positive and negative consequences, such as increased connectivity but also issues like privacy concerns, misinformation, and online harassment. Anticipating and addressing these unintended ethical or social implications is important for responsible development and implementation of new technologies or policies.To mitigate unintended consequences, it is crucial to engage in thorough analysis, scenario planning, and risk assessment. Considering multiple perspectives, conducting pilot tests, and continuously monitoring and evaluating the outcomes of interventions can help identify and address unintended consequences proactively. Flexibility and adaptability in responding to emerging issues can also contribute to mitigating the negative impacts of unintended consequences.1 / 1Any relation to the articles we discussed?1 / 1ChatGPTChatGPTYes, there is a relation between unintended consequences and the articles we discussed. The concept of unintended consequences is relevant to understanding the potential outcomes and impacts of introducing new minds or forms of intelligence into society, as discussed in the articles.The articles explore the concept of intersubjectivity collapse, which refers to the breakdown of shared understanding and communication between different minds or intelligences. This collapse can lead to conflicts, misunderstandings, and fragmentation of society. One of the unintended consequences of the intersubjectivity collapse is the potential for social disintegration and loss of collective intelligence.Additionally, the articles discuss the challenges of anticipating and preparing for the intersubjectivity collapse. They propose solutions such as developing new communication technologies, establishing shared norms and values, and implementing education and training programs. However, the articles also acknowledge the difficulty in fully quantifying and predicting the consequences of the collapse, highlighting the complexity and uncertainty involved.Unintended consequences are particularly relevant when dealing with complex systems and societal changes. Introducing new minds or forms of intelligence into society is a complex endeavor with numerous potential ripple effects and unforeseen outcomes. It is important to consider the unintended ethical, social, and practical implications of such changes and to proactively address and mitigate any negative consequences.Therefore, the concept of unintended consequences provides a broader framework to understand and analyze the potential impacts of the intersubjectivity collapse and the measures proposed in the articles. It emphasizes the need for careful consideration, risk assessment, and ongoing evaluation to minimize unintended negative outcomes and maximize the positive effects of introducing new minds into society.1 / 1The first article was about Transformer Limits on Reasoning (with the increase in the complexity - what I call rhyzomatic scaling effects) and the second on new ideas for red teaming toxic output of LLMs1 / 1ChatGPTChatGPTApologies for the confusion. Let's discuss the connection between unintended consequences and the topics of the articles you mentioned.Transformer Limits on Reasoning: The article explores the limitations of transformer models, such as large language models (LLMs), in their ability to perform complex reasoning tasks. It highlights how these models, despite their impressive performance on certain tasks, can struggle with nuanced reasoning and understanding causal relationships. Unintended consequences can arise when relying solely on LLMs for decision-making or problem-solving without considering their limitations. The potential unintended consequence is that important decisions or actions may be based on incomplete or flawed reasoning, leading to undesirable outcomes.New Ideas for Red Teaming Toxic Output of LLMs: This article addresses the challenge of mitigating the generation of toxic or harmful content by large language models. Unintended consequences can arise when deploying LLMs without adequate safeguards or monitoring mechanisms in place. If these models generate biased, offensive, or harmful content, it can have negative impacts on individuals, communities, and society at large. Red teaming, or adversarial testing, is proposed as a way to uncover and address these unintended consequences by proactively identifying potential risks and refining the models' behavior.In both cases, the articles highlight the importance of considering and addressing unintended consequences associated with the use of LLMs and other advanced language models. These models have the potential to revolutionize various domains, but their deployment must be accompanied by careful evaluation, ethical considerations, and mechanisms to mitigate unintended negative outcomes. By being proactive and engaging in critical analysis, researchers and practitioners can work towards minimizing unintended consequences and maximizing the positive impact of these technologies.Overall, unintended consequences are a recurring theme when discussing the limitations, risks, and ethical implications of advanced language models like LLMs. It underscores the need for responsible development, rigorous testing, and ongoing monitoring to ensure that these models are deployed in a manner that aligns with societal values and minimizes potential harms.2 / 2A list of all of the topics we've discussed.1 / 1ChatGPTChatGPTCertainly! Here is a list of the topics we've discussed:Interdisciplinary nature of the intersubjectivity collapseThe concept of intersubjectivity collapse and its potential consequencesFactors contributing to intersubjectivity robustnessScoring formula for evaluating a civilization's intersubjectivity robustnessMitigation and solutions for the intersubjectivity collapsePotential fragmentation of civilization and the need for universal rules and communicationAI alignment and safety in the context of the intersubjectivity collapseThe concept of a hyperpersonal aggregate in MacrolifeDiscussion on corporations as artificial general superintelligencesComparing the intelligence of corporations and humans in specific domainsEvaluating the limitations and performance of corporationsUnintended consequences in relation to advanced language models (LLMs) and reasoningIdeas for red teaming and mitigating toxic output of LLMsPlease note that this list may not be exhaustive, but it captures the main topics we have covered in our discussion. Let me know if there's anything specific you would like to explore further or if there's any other topic you'd like to discuss!1 / 1More about rhyzomatic scaling effects1 / 1ChatGPTChatGPTThe term "rhizomatic scaling effects" seems to refer to the idea of scaling or expanding in a rhizomatic manner, which can be understood in the context of complex systems and networks. Rhizomatic scaling suggests a non-linear, decentralized, and interconnected growth pattern similar to the rhizome structure found in plants like bamboo or certain types of grasses.In the context of the discussion on transformer limits on reasoning, rhizomatic scaling effects may relate to the challenges and potential consequences of scaling up artificial intelligence models, such as large language models (LLMs) like GPT-3 or GPT-4. These models have shown impressive capabilities in various tasks, but they also have limitations in terms of reasoning, understanding context, and generating reliable outputs.As these models scale up in size and complexity, there may be unintended consequences and limitations that emerge. For example, the increase in model size may lead to an increase in computational requirements, training data biases, or difficulties in understanding and interpreting the model's decisions. Additionally, scaling up may exacerbate issues related to misinformation, biased outputs, or harmful content generation if not properly controlled or regulated.Exploring and understanding these rhizomatic scaling effects can help researchers and practitioners better anticipate and address the challenges and potential risks associated with the growth and deployment of large AI models. It involves studying the implications of scaling on system behavior, the interaction between different components, and the emergent properties that may arise from complex interconnectedness.By considering these effects, researchers can work towards developing AI systems that are not only powerful but also accountable, transparent, and aligned with human values. This requires a multidisciplinary approach, incorporating expertise from fields such as computer science, ethics, social sciences, and policy-making to ensure responsible and beneficial deployment of AI technologies.1 / 1It is based on ideas from Deleuze. rhizomatic scaling

noun

A process of growth or expansion characterized by decentralized, non-hierarchical, and flexible connections or networks, similar to the rhizome plant structure.

The tendency for the number of potential interconnections or relationships to increase exponentially as a system or problem scales up in complexity.

Example sentences:

The company's rapid growth was due in part to its adoption of a rhizomatic scaling approach to organizational structure.

The Internet's rhizomatic scaling has led to the creation of numerous online communities and subcultures.

Scaling up a complex system like a city's transportation infrastructure requires a rhizomatic approach that allows for distributed decision-making and experimentation.

As the number of users on a social media platform increases, so too does the rhizomatic scaling of potential connections and interactions between them.
1 / 1ChatGPTChatGPTThank you for providing the definition of rhizomatic scaling based on Deleuze's ideas. In the context of growth and expansion, rhizomatic scaling emphasizes decentralized, non-hierarchical, and flexible connections or networks. It suggests a departure from traditional hierarchical structures and instead promotes a more interconnected and adaptive approach.When applied to complex systems or problems, rhizomatic scaling implies that as the system or problem becomes more complex, the number of potential interconnections or relationships within it increases exponentially. This reflects the idea that as complexity grows, the possibilities for interactions, adaptations, and emergent properties also multiply.In practical terms, adopting a rhizomatic scaling approach can have implications for various domains, such as organizational structures, online communities, or urban planning. Organizations that embrace a rhizomatic scaling approach may prioritize decentralized decision-making, encourage collaboration and self-organization, and value flexibility and adaptability in their structures. Online communities that exhibit rhizomatic scaling may foster diverse connections and interactions among members, leading to the emergence of subcultures and novel ideas. Similarly, in urban planning, a rhizomatic approach to scaling transportation infrastructure may involve decentralized decision-making, experimentation, and the incorporation of feedback loops to accommodate the increasing complexity of a growing city.Overall, rhizomatic scaling offers an alternative perspective on growth and expansion, emphasizing the importance of interconnectedness, flexibility, and decentralized structures in complex systems. It suggests that embracing such an approach can enable greater adaptability and innovation in the face of increasing complexity.1 / 1I think it is also called the curse of dimensionality1 / 1ChatGPTChatGPTThe "curse of dimensionality" is a term used in mathematics and statistics to describe the challenges and limitations that arise when working with high-dimensional data or complex systems. It refers to the phenomenon where the increase in the number of dimensions or variables leads to difficulties in analyzing, visualizing, and understanding the data or system.In the context of rhizomatic scaling and the increasing complexity of interconnected systems, the curse of dimensionality can be related. As the number of dimensions or variables grows, the space of possibilities expands exponentially. This expansion can make it more challenging to explore and comprehend the relationships, interactions, and patterns within the system.The curse of dimensionality manifests in various ways. For example, in data analysis, high-dimensional datasets can suffer from sparsity, meaning that the available data points become sparse and less representative in higher dimensions. This can impact the accuracy and reliability of statistical models and algorithms. Visualizing and interpreting data in high-dimensional space also becomes increasingly difficult, as our ability to perceive and comprehend multi-dimensional patterns is limited.To overcome the curse of dimensionality, various techniques and strategies have been developed, such as dimensionality reduction methods (e.g., principal component analysis) and feature selection algorithms. These approaches aim to reduce the dimensionality of the data while preserving relevant information and relationships.In the context of rhizomatic scaling, the curse of dimensionality highlights the challenges that arise as interconnected systems become more complex and involve an increasing number of variables or connections. It emphasizes the need for effective techniques and approaches to analyze and make sense of the expanding space of possibilities, while also recognizing the importance of flexibility, adaptability, and decentralized structures in navigating the complexities of such systems.1 / 1A summary of the conversation1 / 1ChatGPTChatGPTThroughout our conversation, we discussed various topics related to the complexities of interconnected systems, the limitations of artificial general intelligence (AGI), the concept of intersubjectivity collapse, and the unintended consequences that may arise from technological advancements. We explored the idea of rhizomatic scaling, which refers to a decentralized and flexible approach to growth and expansion, similar to the structure of a rhizome plant.We touched upon the limitations of transformer models and their ability to reason and handle complex tasks. The concept of rhizomatic scaling can be seen as a way to address the increasing complexity by allowing for decentralized decision-making and adaptive structures.We also delved into the potential risks and consequences associated with AGI, including its impact on intersubjectivity and the need to consider diverse perspectives and societal adaptation. The collapse of intersubjectivity raises concerns about conflicts, breakdown of communication, and fragmentation of society.Furthermore, we explored the role of corporations as aggregations of human intelligence and the limitations of their performance compared to AGI. While corporations can achieve high throughput in completing complex tasks, they are limited by the latency of human decision-making, making them relatively controllable entities.The conversation also touched upon the notion of unintended consequences and the need for careful consideration of the potential risks and impacts of technological advancements. We discussed the importance of addressing alignment and safety in AGI development and the challenges associated with evaluating solutions and generating innovative ideas.Overall, our conversation highlighted the complex nature of interconnected systems, the challenges posed by increasing complexity, and the importance of considering diverse perspectives, adaptability, and ethical implications in addressing these challenges.1 / 1Did it give you any ideas?1 / 1ChatGPTChatGPTAs an AI language model, I don't have personal experiences or emotions, so I don't have ideas in the same way humans do. However, our conversation covered various thought-provoking topics that can stimulate further exploration and discussion. The concepts of rhizomatic scaling, intersubjectivity collapse, and unintended consequences raise important considerations for understanding the dynamics of complex systems and the potential impacts of technological advancements.These discussions may inspire researchers, policymakers, and individuals to delve deeper into these subjects and explore potential solutions or mitigation strategies. They can also foster critical thinking about the ethical implications and societal consequences of AI, AGI, and other emerging technologies. Further research, interdisciplinary collaborations, and open dialogue can help address the challenges and opportunities presented by these complex topics.1 / 1Connections with the tv show, inspector gadget1 / 1ChatGPTChatGPTInspector Gadget is an animated television series that follows the adventures of a bumbling but well-meaning cyborg detective named Inspector Gadget. While there may not be direct connections between the topics we discussed and Inspector Gadget, there are some broader thematic similarities that can be explored.One connection could be the idea of technological augmentation and its consequences. In Inspector Gadget, the main character is equipped with various high-tech gadgets and devices that enhance his abilities. This concept touches on the theme of humans augmenting themselves with technology, which we discussed in relation to the intersubjectivity collapse and the potential challenges and implications of creating artificial general intelligence (AGI).Additionally, the notion of unintended consequences can be seen in Inspector Gadget's adventures. Despite his good intentions, Inspector Gadget often finds himself in humorous and chaotic situations due to the malfunctioning or misinterpretation of his gadgets. This highlights the idea that even with the best of intentions, the use of technology can lead to unintended outcomes or unforeseen circumstances.While Inspector Gadget may present these concepts in a lighthearted and comedic manner, they reflect some of the broader themes and discussions surrounding technology, augmentation, and unintended consequences that we explored in our conversation.1 / 1Write a scene with dialogue where Penny saves him from his own incompetency.1 / 1ChatGPTChatGPTINT. INSPECTOR GADGET'S SECRET LAIR - DAYInspector Gadget, a bumbling cyborg detective, stands in front of a table cluttered with high-tech gadgets. He is trying to assemble a simple device, but his clumsy hands keep fumbling with the pieces.INSPECTOR GADGET
(confused)
Hmm... If I connect this wire to that one, then... no, maybe it goes here?Penny, Inspector Gadget's intelligent and resourceful niece, enters the room. She watches her uncle's struggles for a moment before stepping in to help.PENNY
(sighs)
Uncle Gadget, let me give you a hand. You're almost there, but you've got a couple of wires crossed.Inspector Gadget looks up, a mixture of relief and gratitude on his face.INSPECTOR GADGET
Oh, Penny, thank goodness you're here. I can always count on you to save the day.Penny carefully adjusts the wires and reassembles the device with ease. She then hands it back to Inspector Gadget, who looks at it with newfound confidence.PENNY
There you go, Uncle Gadget. All fixed and ready to go.INSPECTOR GADGET
(smiling)
Thanks, Penny. I don't know what I'd do without you. You truly are my secret weapon.PENNY
(chuckles)
Well, someone has to keep things running smoothly around here. Just remember, it's not about being the smartest, but knowing when to ask for help and working together.Inspector Gadget nods, appreciating Penny's wisdom. He puts the device down and gives his niece a warm hug.INSPECTOR GADGET
You're absolutely right, Penny. We make a great team.Penny smiles, knowing that she has once again saved her uncle from his own incompetency and helped him on his mission to fight crime.FADE OUT.1 / 1ChatGPT may produce inaccurate information about people, places, or facts. ChatGPT May 24 VersionTransformer Limits on Reasoning
------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: text/css
Content-Transfer-Encoding: binary
Content-Location: cid:css-1e83fa41-f68f-4f1f-891d-cd0c2333aab5@mhtml.blink

@charset "utf-8";

.react-scroll-to-bottom--css-tnfwo-79elbk { position: relative; }

.react-scroll-to-bottom--css-tnfwo-1n7m0yu { height: 100%; overflow-y: auto; width: 100%; }

.react-scroll-to-bottom--css-tnfwo-1tj0vk3 { background-color: rgba(0, 0, 0, 0.2); border-radius: 10px; border-width: 0px; bottom: 5px; cursor: pointer; height: 20px; outline: 0px; position: absolute; right: 20px; width: 20px; }

.react-scroll-to-bottom--css-tnfwo-1tj0vk3:hover { background-color: rgba(0, 0, 0, 0.4); }

.react-scroll-to-bottom--css-tnfwo-1tj0vk3:active { background-color: rgba(0, 0, 0, 0.6); }
------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: text/css
Content-Transfer-Encoding: binary
Content-Location: cid:css-83f0955f-123c-42d0-8316-85a11033b47d@mhtml.blink

@charset "utf-8";

.r34K7X1zGgAi6DllVF3T { box-sizing: border-box; border: 0px; margin: 0px; padding: 0px; overflow: hidden; display: none; z-index: 2147483647; pointer-events: none; visibility: hidden; opacity: 0; transition: opacity 300ms linear 0s; height: 0px; width: 0px; }

.r34K7X1zGgAi6DllVF3T.active { display: block; visibility: visible; }

.r34K7X1zGgAi6DllVF3T.active.show { opacity: 1; pointer-events: inherit; position: inherit; }

.r34K7X1zGgAi6DllVF3T.active.show.in-situ { width: inherit; height: inherit; }

.r34K7X1zGgAi6DllVF3T.active.show.lightbox { position: fixed; inset: 0px; width: 100% !important; height: 100% !important; }
------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: text/css
Content-Transfer-Encoding: binary
Content-Location: cid:css-6d5eae75-93cc-416d-b082-c93070e9a403@mhtml.blink

@charset "utf-8";

@keyframes intercom-lightweight-app-launcher { 
  0% { opacity: 0; transform: scale(0.5); }
  100% { opacity: 1; transform: scale(1); }
}

@keyframes intercom-lightweight-app-gradient { 
  0% { opacity: 0; }
  100% { opacity: 1; }
}

@keyframes intercom-lightweight-app-messenger { 
  0% { opacity: 0; transform: scale(0); }
  40% { opacity: 1; }
  100% { transform: scale(1); }
}

.intercom-lightweight-app { position: fixed; z-index: 2147483001; width: 0px; height: 0px; font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif; }

.intercom-lightweight-app-gradient { position: fixed; z-index: 2147483002; width: 500px; height: 500px; bottom: 0px; right: 0px; pointer-events: none; background: radial-gradient(at right bottom, rgba(29, 39, 54, 0.16) 0%, rgba(29, 39, 54, 0) 72%); animation: 200ms ease-out 0s 1 normal none running intercom-lightweight-app-gradient; }

.intercom-lightweight-app-launcher { position: fixed; z-index: 2147483003; border: none; bottom: 20px; right: 20px; max-width: 48px; width: 48px; max-height: 48px; height: 48px; border-radius: 50%; background: rgb(32, 33, 35); cursor: pointer; box-shadow: rgba(0, 0, 0, 0.06) 0px 1px 6px 0px, rgba(0, 0, 0, 0.16) 0px 2px 32px 0px; transition: transform 167ms cubic-bezier(0.33, 0, 0, 1) 0s; box-sizing: content-box; padding: 0px !important; margin: 0px !important; }

.intercom-lightweight-app-launcher:hover { transition: transform 250ms cubic-bezier(0.33, 0, 0, 1) 0s; transform: scale(1.1); }

.intercom-lightweight-app-launcher:active { transform: scale(0.85); transition: transform 134ms cubic-bezier(0.45, 0, 0.2, 1) 0s; }

.intercom-lightweight-app-launcher:focus { outline: none; }

.intercom-lightweight-app-launcher-icon { display: flex; align-items: center; justify-content: center; position: absolute; top: 0px; left: 0px; width: 48px; height: 48px; transition: transform 100ms linear 0s, opacity 80ms linear 0s; }

.intercom-lightweight-app-launcher-icon-open { opacity: 1; transform: rotate(0deg) scale(1); }

.intercom-lightweight-app-launcher-icon-open svg { width: 24px; height: 24px; }

.intercom-lightweight-app-launcher-icon-open svg path { fill: rgb(255, 255, 255); }

.intercom-lightweight-app-launcher-icon-self-serve { opacity: 1; transform: rotate(0deg) scale(1); }

.intercom-lightweight-app-launcher-icon-self-serve svg { height: 44px; }

.intercom-lightweight-app-launcher-icon-self-serve svg path { fill: rgb(255, 255, 255); }

.intercom-lightweight-app-launcher-custom-icon-open { max-height: 24px; max-width: 24px; opacity: 1; transform: rotate(0deg) scale(1); }

.intercom-lightweight-app-launcher-icon-minimize { opacity: 0; transform: rotate(-60deg) scale(0); }

.intercom-lightweight-app-launcher-icon-minimize svg path { fill: rgb(255, 255, 255); }

.intercom-lightweight-app-messenger { position: fixed; z-index: 2147483003; overflow: hidden; background-color: white; animation: 250ms cubic-bezier(0, 1, 1, 1) 0s 1 normal none running intercom-lightweight-app-messenger; transform-origin: right bottom; inset: 0px; border-radius: 16px; }

.intercom-lightweight-app-messenger-header { height: 64px; border-bottom: none; background: rgb(32, 33, 35); }

.intercom-lightweight-app-messenger-footer { position: absolute; bottom: 0px; width: 100%; height: 80px; background: rgb(255, 255, 255); font-size: 14px; line-height: 21px; border-top: 1px solid rgba(0, 0, 0, 0.05); box-shadow: rgba(0, 0, 0, 0.05) 0px 0px 25px; }

@media print {
  .intercom-lightweight-app { display: none; }
}
------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: text/css
Content-Transfer-Encoding: binary
Content-Location: https://chat.openai.com/_next/static/css/dc06f43874f6f09a.css

@charset "utf-8";

@font-face { font-display: swap; font-family: Signifier; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/signifier/signifier-light.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: Signifier; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/signifier/signifier-light-italic.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: Signifier; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/signifier/signifier-bold.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: Signifier; font-style: italic; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/signifier/signifier-bold-italic.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-buch.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-buch-kursiv.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: normal; font-weight: 500; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-kraftig.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: italic; font-weight: 500; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-kraftig-kursiv.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: normal; font-weight: 600; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-halbfett.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: SÃ¶hne; font-style: italic; font-weight: 600; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-halbfett-kursiv.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: "SÃ¶hne Mono"; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-mono-buch.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: "SÃ¶hne Mono"; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-mono-halbfett.woff2") format("woff2"); }

@font-face { font-display: swap; font-family: "SÃ¶hne Mono"; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/soehne/soehne-mono-buch-kursiv.woff2") format("woff2"); }

*, ::after, ::before { border: 0px solid rgb(217, 217, 227); box-sizing: border-box; }

::after, ::before { --tw-content:""; }

html { text-size-adjust: 100%; font-feature-settings: normal; font-family: SÃ¶hne, ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, Ubuntu, Cantarell, "Noto Sans", sans-serif, "Helvetica Neue", Arial, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji"; font-variation-settings: normal; line-height: 1.5; tab-size: 4; }

body { line-height: inherit; margin: 0px; }

hr { border-top-width: 1px; color: inherit; height: 0px; }

abbr:where([title]) { text-decoration: underline dotted currentcolor; }

h1, h2, h3, h4, h5, h6 { font-size: inherit; font-weight: inherit; }

a { color: inherit; text-decoration: inherit; }

b, strong { font-weight: bolder; }

code, kbd, pre, samp { font-family: "SÃ¶hne Mono", Monaco, "Andale Mono", "Ubuntu Mono", monospace; font-size: 1em; }

small { font-size: 80%; }

sub, sup { font-size: 75%; line-height: 0; position: relative; vertical-align: baseline; }

sub { bottom: -0.25em; }

sup { top: -0.5em; }

table { border-collapse: collapse; border-color: inherit; text-indent: 0px; }

button, input, optgroup, select, textarea { color: inherit; font-family: inherit; font-size: 100%; font-weight: inherit; line-height: inherit; margin: 0px; padding: 0px; }

button, select { text-transform: none; }

[type="button"], [type="reset"], [type="submit"], button { appearance: button; background-color: transparent; background-image: none; }

progress { vertical-align: baseline; }

::-webkit-inner-spin-button, ::-webkit-outer-spin-button { height: auto; }

[type="search"] { appearance: textfield; outline-offset: -2px; }

::-webkit-search-decoration { appearance: none; }

::-webkit-file-upload-button { appearance: button; font: inherit; }

summary { display: list-item; }

blockquote, dd, dl, fieldset, figure, h1, h2, h3, h4, h5, h6, hr, p, pre { margin: 0px; }

fieldset, legend { padding: 0px; }

menu, ol, ul { list-style: none; margin: 0px; padding: 0px; }

textarea { resize: vertical; }

input::-webkit-input-placeholder, textarea::-webkit-input-placeholder { color: rgb(172, 172, 190); }

input::placeholder, textarea::placeholder { color: rgb(172, 172, 190); }

[role="button"], button { cursor: pointer; }

:disabled { cursor: default; }

audio, canvas, embed, iframe, img, object, svg, video { display: block; vertical-align: middle; }

img, video { height: auto; max-width: 100%; }

[hidden] { display: none; }

[multiple], [type="date"], [type="datetime-local"], [type="email"], [type="month"], [type="number"], [type="password"], [type="search"], [type="tel"], [type="text"], [type="time"], [type="url"], [type="week"], select, textarea { --tw-shadow:0 0 transparent; appearance: none; background-color: rgb(255, 255, 255); border-color: rgb(142, 142, 160); border-radius: 0px; border-width: 1px; font-size: 1rem; line-height: 1.5rem; padding: 0.5rem 0.75rem; }

[multiple]:focus, [type="date"]:focus, [type="datetime-local"]:focus, [type="email"]:focus, [type="month"]:focus, [type="number"]:focus, [type="password"]:focus, [type="search"]:focus, [type="tel"]:focus, [type="text"]:focus, [type="time"]:focus, [type="url"]:focus, [type="week"]:focus, select:focus, textarea:focus { --tw-ring-inset:var(--tw-empty, ); --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:#2563eb; --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); border-color: rgb(37, 99, 235); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow); outline: transparent solid 2px; outline-offset: 2px; }

input::-webkit-input-placeholder, textarea::-webkit-input-placeholder { color: rgb(142, 142, 160); opacity: 1; }

input::placeholder, textarea::placeholder { color: rgb(142, 142, 160); opacity: 1; }

::-webkit-datetime-edit-fields-wrapper { padding: 0px; }

::-webkit-date-and-time-value { min-height: 1.5em; }

::-webkit-datetime-edit, ::-webkit-datetime-edit-day-field, ::-webkit-datetime-edit-hour-field, ::-webkit-datetime-edit-meridiem-field, ::-webkit-datetime-edit-millisecond-field, ::-webkit-datetime-edit-minute-field, ::-webkit-datetime-edit-month-field, ::-webkit-datetime-edit-second-field, ::-webkit-datetime-edit-year-field { padding-bottom: 0px; padding-top: 0px; }

select { background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 20 20'%3E%3Cpath stroke='%238e8ea0' stroke-linecap='round' stroke-linejoin='round' stroke-width='1.5' d='m6 8 4 4 4-4'/%3E%3C/svg%3E"); background-position: right 0.5rem center; background-repeat: no-repeat; background-size: 1.5em 1.5em; padding-right: 2.5rem; -webkit-print-color-adjust: exact; }

[multiple] { background-image: none; background-position: 0px 0px; background-repeat: repeat; background-size: initial; padding-right: 0.75rem; -webkit-print-color-adjust: inherit; }

[type="checkbox"], [type="radio"] { --tw-shadow:0 0 transparent; appearance: none; background-color: rgb(255, 255, 255); background-origin: border-box; border-color: rgb(142, 142, 160); border-width: 1px; color: rgb(37, 99, 235); display: inline-block; flex-shrink: 0; height: 1rem; padding: 0px; -webkit-print-color-adjust: exact; user-select: none; vertical-align: middle; width: 1rem; }

[type="checkbox"] { border-radius: 0px; }

[type="radio"] { border-radius: 100%; }

[type="checkbox"]:focus, [type="radio"]:focus { --tw-ring-inset:var(--tw-empty, ); --tw-ring-offset-width:2px; --tw-ring-offset-color:#fff; --tw-ring-color:#2563eb; --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow); outline: transparent solid 2px; outline-offset: 2px; }

[type="checkbox"]:checked, [type="radio"]:checked { background-color: currentcolor; background-position: 50% center; background-repeat: no-repeat; background-size: 100% 100%; border-color: transparent; }

[type="checkbox"]:checked { background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg viewBox='0 0 16 16' fill='%23fff' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M12.207 4.793a1 1 0 0 1 0 1.414l-5 5a1 1 0 0 1-1.414 0l-2-2a1 1 0 0 1 1.414-1.414L6.5 9.086l4.293-4.293a1 1 0 0 1 1.414 0z'/%3E%3C/svg%3E"); }

[type="radio"]:checked { background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg viewBox='0 0 16 16' fill='%23fff' xmlns='http://www.w3.org/2000/svg'%3E%3Ccircle cx='8' cy='8' r='3'/%3E%3C/svg%3E"); }

[type="checkbox"]:checked:focus, [type="checkbox"]:checked:hover, [type="radio"]:checked:focus, [type="radio"]:checked:hover { background-color: currentcolor; border-color: transparent; }

[type="checkbox"]:indeterminate { background-color: currentcolor; background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 16 16'%3E%3Cpath stroke='%23fff' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' d='M4 8h8'/%3E%3C/svg%3E"); background-position: 50% center; background-repeat: no-repeat; background-size: 100% 100%; border-color: transparent; }

[type="checkbox"]:indeterminate:focus, [type="checkbox"]:indeterminate:hover { background-color: currentcolor; border-color: transparent; }

[type="file"] { background: initial; border-color: inherit; border-radius: 0px; border-width: 0px; font-size: inherit; line-height: inherit; padding: 0px; }

[type="file"]:focus { outline: -webkit-focus-ring-color auto 1px; }

h1 { font-size: 1.875rem; line-height: 2.25rem; }

h1, h2, h3 { font-weight: 600; }

h2, h3 { font-size: 1.5rem; line-height: 2rem; }

*, ::after, ::before { --tw-border-spacing-x:0; --tw-border-spacing-y:0; --tw-translate-x:0; --tw-translate-y:0; --tw-rotate:0; --tw-skew-x:0; --tw-skew-y:0; --tw-scale-x:1; --tw-scale-y:1; --tw-pan-x: ; --tw-pan-y: ; --tw-pinch-zoom: ; --tw-scroll-snap-strictness:proximity; --tw-gradient-from-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; --tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spacing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:rgba(69,89,164,0.5); --tw-ring-offset-shadow:0 0 transparent; --tw-ring-shadow:0 0 transparent; --tw-shadow:0 0 transparent; --tw-shadow-colored:0 0 transparent; --tw-blur: ; --tw-brightness: ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --tw-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ; --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity: ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; }

::-webkit-backdrop { --tw-border-spacing-x:0; --tw-border-spacing-y:0; --tw-translate-x:0; --tw-translate-y:0; --tw-rotate:0; --tw-skew-x:0; --tw-skew-y:0; --tw-scale-x:1; --tw-scale-y:1; --tw-pan-x: ; --tw-pan-y: ; --tw-pinch-zoom: ; --tw-scroll-snap-strictness:proximity; --tw-gradient-from-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; --tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spacing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:rgba(69,89,164,0.5); --tw-ring-offset-shadow:0 0 transparent; --tw-ring-shadow:0 0 transparent; --tw-shadow:0 0 transparent; --tw-shadow-colored:0 0 transparent; --tw-blur: ; --tw-brightness: ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --tw-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ; --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity: ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; }

::backdrop { --tw-border-spacing-x:0; --tw-border-spacing-y:0; --tw-translate-x:0; --tw-translate-y:0; --tw-rotate:0; --tw-skew-x:0; --tw-skew-y:0; --tw-scale-x:1; --tw-scale-y:1; --tw-pan-x: ; --tw-pan-y: ; --tw-pinch-zoom: ; --tw-scroll-snap-strictness:proximity; --tw-gradient-from-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; --tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spacing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:rgba(69,89,164,0.5); --tw-ring-offset-shadow:0 0 transparent; --tw-ring-shadow:0 0 transparent; --tw-shadow:0 0 transparent; --tw-shadow-colored:0 0 transparent; --tw-blur: ; --tw-brightness: ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --tw-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ; --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity: ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; }

:root { --color-primary:#19c37d; --color-secondary:#715fde; --color-error:#ef4146; --gradient-primary:linear-gradient(90deg,#a29bd4,#989fdd); --text-primary:#202123; --text-default:#353740; --text-secondary:#6e6e80; --text-disabled:#acacbe; --text-error:var(--color-error); }

textarea:focus { border-color: inherit; box-shadow: none; outline: none; }

::-webkit-scrollbar { height: 1rem; width: 0.5rem; }

::-webkit-scrollbar:horizontal { height: 0.5rem; width: 1rem; }

::-webkit-scrollbar-track { background-color: transparent; border-radius: 9999px; }

::-webkit-scrollbar-thumb { --tw-border-opacity:1; background-color: rgba(217, 217, 227, 0.8); border-color: rgba(255,255,255,var(--tw-border-opacity)); border-radius: 9999px; border-width: 1px; }

::-webkit-scrollbar-thumb:hover { --tw-bg-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.dark::-webkit-scrollbar-thumb { --tw-bg-opacity:1; background-color: rgba(86,88,105,var(--tw-bg-opacity)); }

.dark::-webkit-scrollbar-thumb:hover { --tw-bg-opacity:1; background-color: rgba(172,172,190,var(--tw-bg-opacity)); }

@media (min-width: 768px) {
  .scrollbar-trigger ::-webkit-scrollbar-thumb { visibility: hidden; }
  .scrollbar-trigger:hover ::-webkit-scrollbar-thumb { visibility: visible; }
}

.container { width: 100%; }

@media (min-width: 640px) {
  .container { max-width: 640px; }
}

@media (min-width: 768px) {
  .container { max-width: 768px; }
}

@media (min-width: 1024px) {
  .container { max-width: 1024px; }
}

@media (min-width: 1280px) {
  .container { max-width: 1280px; }
}

@media (min-width: 1536px) {
  .container { max-width: 1536px; }
}

.prose { color: var(--tw-prose-body); max-width: 65ch; }

.prose :where([class~="lead"]):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-lead); font-size: 1.25em; line-height: 1.6; margin-bottom: 1.2em; margin-top: 1.2em; }

.prose :where(a):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-links); font-weight: 500; text-decoration: underline; }

.prose :where(strong):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-bold); font-weight: 600; }

.prose :where(a strong):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(blockquote strong):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(thead th strong):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(ol):not(:where([class~="not-prose"] *)) { list-style-type: decimal; margin-bottom: 1.25em; margin-top: 1.25em; padding-left: 1.625em; }

.prose :where(ol[type="A"]):not(:where([class~="not-prose"] *)) { list-style-type: upper-alpha; }

.prose :where(ol[type="a"]):not(:where([class~="not-prose"] *)) { list-style-type: lower-alpha; }

.prose :where():not(:where([class~="not-prose"] *)) { list-style-type: upper-alpha; }

.prose :where():not(:where([class~="not-prose"] *)) { list-style-type: lower-alpha; }

.prose :where(ol[type="I"]):not(:where([class~="not-prose"] *)) { list-style-type: upper-roman; }

.prose :where(ol[type="i"]):not(:where([class~="not-prose"] *)) { list-style-type: lower-roman; }

.prose :where():not(:where([class~="not-prose"] *)) { list-style-type: upper-roman; }

.prose :where():not(:where([class~="not-prose"] *)) { list-style-type: lower-roman; }

.prose :where(ol[type="1"]):not(:where([class~="not-prose"] *)) { list-style-type: decimal; }

.prose :where(ul):not(:where([class~="not-prose"] *)) { list-style-type: disc; margin-bottom: 1.25em; margin-top: 1.25em; padding-left: 1.625em; }

.prose :where(ol > li):not(:where([class~="not-prose"] *))::marker { color: var(--tw-prose-counters); font-weight: 400; }

.prose :where(ul > li):not(:where([class~="not-prose"] *))::marker { color: var(--tw-prose-bullets); }

.prose :where(hr):not(:where([class~="not-prose"] *)) { border-color: var(--tw-prose-hr); border-top-width: 1px; margin-bottom: 3em; margin-top: 3em; }

.prose :where(blockquote):not(:where([class~="not-prose"] *)) { border-left-color: var(--tw-prose-quote-borders); border-left-width: 0.25rem; color: var(--tw-prose-quotes); font-style: normal; font-weight: 500; margin-bottom: 1.6em; margin-top: 1.6em; padding-left: 1em; quotes: "â" "â" "â" "â"; }

.prose :where(blockquote p:first-of-type):not(:where([class~="not-prose"] *))::before { content: open-quote; }

.prose :where(blockquote p:last-of-type):not(:where([class~="not-prose"] *))::after { content: close-quote; }

.prose :where(h1):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-size: 2.25em; font-weight: 800; line-height: 1.11111; margin-bottom: 0.888889em; margin-top: 0px; }

.prose :where(h1 strong):not(:where([class~="not-prose"] *)) { color: inherit; font-weight: 900; }

.prose :where(h2):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-size: 1.5em; font-weight: 700; line-height: 1.33333; margin-bottom: 1em; margin-top: 2em; }

.prose :where(h2 strong):not(:where([class~="not-prose"] *)) { color: inherit; font-weight: 800; }

.prose :where(h3):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-size: 1.25em; font-weight: 600; line-height: 1.6; margin-bottom: 0.6em; margin-top: 1.6em; }

.prose :where(h3 strong):not(:where([class~="not-prose"] *)) { color: inherit; font-weight: 700; }

.prose :where(h4):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-weight: 600; line-height: 1.5; margin-bottom: 0.5em; margin-top: 1.5em; }

.prose :where(h4 strong):not(:where([class~="not-prose"] *)) { color: inherit; font-weight: 700; }

.prose :where(img):not(:where([class~="not-prose"] *)) { margin-bottom: 2em; margin-top: 2em; }

.prose :where(figure > *):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; margin-top: 0px; }

.prose :where(figcaption):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-captions); font-size: 0.875em; line-height: 1.42857; margin-top: 0.857143em; }

.prose :where(code):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-code); font-size: 0.875em; font-weight: 600; }

.prose :where(code):not(:where([class~="not-prose"] *))::before { content: "`"; }

.prose :where(code):not(:where([class~="not-prose"] *))::after { content: "`"; }

.prose :where(a code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(h1 code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(h2 code):not(:where([class~="not-prose"] *)) { color: inherit; font-size: 0.875em; }

.prose :where(h3 code):not(:where([class~="not-prose"] *)) { color: inherit; font-size: 0.9em; }

.prose :where(h4 code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(blockquote code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(thead th code):not(:where([class~="not-prose"] *)) { color: inherit; }

.prose :where(pre):not(:where([class~="not-prose"] *)) { background-color: transparent; border-radius: 0.375rem; color: currentcolor; font-size: 0.875em; font-weight: 400; line-height: 1.71429; margin: 0px; overflow-x: auto; padding: 0px; }

.prose :where(pre code):not(:where([class~="not-prose"] *)) { background-color: transparent; border-radius: 0px; border-width: 0px; color: inherit; font-family: inherit; font-size: inherit; font-weight: inherit; line-height: inherit; padding: 0px; }

.prose :where(pre code):not(:where([class~="not-prose"] *))::before { content: none; }

.prose :where(pre code):not(:where([class~="not-prose"] *))::after { content: none; }

.prose :where(table):not(:where([class~="not-prose"] *)) { font-size: 0.875em; line-height: 1.71429; margin-bottom: 2em; margin-top: 2em; table-layout: auto; text-align: left; width: 100%; }

.prose :where(thead):not(:where([class~="not-prose"] *)) { border-bottom-color: var(--tw-prose-th-borders); border-bottom-width: 1px; }

.prose :where(thead th):not(:where([class~="not-prose"] *)) { color: var(--tw-prose-headings); font-weight: 600; padding-bottom: 0.571429em; padding-left: 0.571429em; padding-right: 0.571429em; vertical-align: bottom; }

.prose :where(tbody tr):not(:where([class~="not-prose"] *)) { border-bottom-color: var(--tw-prose-td-borders); border-bottom-width: 1px; }

.prose :where(tbody tr:last-child):not(:where([class~="not-prose"] *)) { border-bottom-width: 0px; }

.prose :where(tbody td):not(:where([class~="not-prose"] *)) { vertical-align: baseline; }

.prose :where(tfoot):not(:where([class~="not-prose"] *)) { border-top-color: var(--tw-prose-th-borders); border-top-width: 1px; }

.prose :where(tfoot td):not(:where([class~="not-prose"] *)) { vertical-align: top; }

.prose { --tw-prose-body:#374151; --tw-prose-headings:#111827; --tw-prose-lead:#4b5563; --tw-prose-links:#111827; --tw-prose-bold:#111827; --tw-prose-counters:#6b7280; --tw-prose-bullets:#d1d5db; --tw-prose-hr:#e5e7eb; --tw-prose-quotes:#111827; --tw-prose-quote-borders:#e5e7eb; --tw-prose-captions:#6b7280; --tw-prose-code:#111827; --tw-prose-pre-code:#e5e7eb; --tw-prose-pre-bg:#1f2937; --tw-prose-th-borders:#d1d5db; --tw-prose-td-borders:#e5e7eb; --tw-prose-invert-body:#d1d5db; --tw-prose-invert-headings:#fff; --tw-prose-invert-lead:#9ca3af; --tw-prose-invert-links:#fff; --tw-prose-invert-bold:#fff; --tw-prose-invert-counters:#9ca3af; --tw-prose-invert-bullets:#4b5563; --tw-prose-invert-hr:#374151; --tw-prose-invert-quotes:#f3f4f6; --tw-prose-invert-quote-borders:#374151; --tw-prose-invert-captions:#9ca3af; --tw-prose-invert-code:#fff; --tw-prose-invert-pre-code:#d1d5db; --tw-prose-invert-pre-bg:rgba(0,0,0,0.5); --tw-prose-invert-th-borders:#4b5563; --tw-prose-invert-td-borders:#374151; font-size: 1rem; line-height: 1.75; }

.prose :where(p):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; margin-top: 1.25em; }

.prose :where(video):not(:where([class~="not-prose"] *)) { margin-bottom: 2em; margin-top: 2em; }

.prose :where(figure):not(:where([class~="not-prose"] *)) { margin-bottom: 2em; margin-top: 2em; }

.prose :where(li):not(:where([class~="not-prose"] *)) { margin-bottom: 0.5em; margin-top: 0.5em; }

.prose :where(ol > li):not(:where([class~="not-prose"] *)) { padding-left: 0.375em; }

.prose :where(ul > li):not(:where([class~="not-prose"] *)) { padding-left: 0.375em; }

.prose :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.75em; margin-top: 0.75em; }

.prose :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.25em; }

.prose :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; }

.prose :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.25em; }

.prose :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; }

.prose :where(ul ul, ul ol, ol ul, ol ol):not(:where([class~="not-prose"] *)) { margin-bottom: 0.75em; margin-top: 0.75em; }

.prose :where(hr + *):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(h2 + *):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(h3 + *):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(h4 + *):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(thead th:first-child):not(:where([class~="not-prose"] *)) { padding-left: 0px; }

.prose :where(thead th:last-child):not(:where([class~="not-prose"] *)) { padding-right: 0px; }

.prose :where(tbody td, tfoot td):not(:where([class~="not-prose"] *)) { padding: 0.571429em; }

.prose :where(tbody td:first-child, tfoot td:first-child):not(:where([class~="not-prose"] *)) { padding-left: 0px; }

.prose :where(tbody td:last-child, tfoot td:last-child):not(:where([class~="not-prose"] *)) { padding-right: 0px; }

.prose :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-sm :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.571429em; margin-top: 0.571429em; }

.prose-sm :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.14286em; }

.prose-sm :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.14286em; }

.prose-sm :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.14286em; }

.prose-sm :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.14286em; }

.prose-sm :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-sm :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-base :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.75em; margin-top: 0.75em; }

.prose-base :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.25em; }

.prose-base :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; }

.prose-base :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.25em; }

.prose-base :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.25em; }

.prose-base :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-base :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-lg :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.888889em; margin-top: 0.888889em; }

.prose-lg :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.33333em; }

.prose-lg :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.33333em; }

.prose-lg :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.33333em; }

.prose-lg :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.33333em; }

.prose-lg :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-lg :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-xl :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.8em; margin-top: 0.8em; }

.prose-xl :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.2em; }

.prose-xl :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.2em; }

.prose-xl :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.2em; }

.prose-xl :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.2em; }

.prose-xl :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-xl :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-2xl :where(.prose > ul > li p):not(:where([class~="not-prose"] *)) { margin-bottom: 0.833333em; margin-top: 0.833333em; }

.prose-2xl :where(.prose > ul > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.33333em; }

.prose-2xl :where(.prose > ul > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.33333em; }

.prose-2xl :where(.prose > ol > li > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 1.33333em; }

.prose-2xl :where(.prose > ol > li > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 1.33333em; }

.prose-2xl :where(.prose > :first-child):not(:where([class~="not-prose"] *)) { margin-top: 0px; }

.prose-2xl :where(.prose > :last-child):not(:where([class~="not-prose"] *)) { margin-bottom: 0px; }

.prose-invert { --tw-prose-body:var(--tw-prose-invert-body); --tw-prose-headings:var(--tw-prose-invert-headings); --tw-prose-lead:var(--tw-prose-invert-lead); --tw-prose-links:var(--tw-prose-invert-links); --tw-prose-bold:var(--tw-prose-invert-bold); --tw-prose-counters:var(--tw-prose-invert-counters); --tw-prose-bullets:var(--tw-prose-invert-bullets); --tw-prose-hr:var(--tw-prose-invert-hr); --tw-prose-quotes:var(--tw-prose-invert-quotes); --tw-prose-quote-borders:var(--tw-prose-invert-quote-borders); --tw-prose-captions:var(--tw-prose-invert-captions); --tw-prose-code:var(--tw-prose-invert-code); --tw-prose-pre-code:var(--tw-prose-invert-pre-code); --tw-prose-pre-bg:var(--tw-prose-invert-pre-bg); --tw-prose-th-borders:var(--tw-prose-invert-th-borders); --tw-prose-td-borders:var(--tw-prose-invert-td-borders); }

.form-input, .form-multiselect, .form-select, .form-textarea { --tw-shadow:0 0 transparent; appearance: none; background-color: rgb(255, 255, 255); border-color: rgb(142, 142, 160); border-radius: 0px; border-width: 1px; font-size: 1rem; line-height: 1.5rem; padding: 0.5rem 0.75rem; }

.form-input:focus, .form-multiselect:focus, .form-select:focus, .form-textarea:focus { --tw-ring-inset:var(--tw-empty, ); --tw-ring-offset-width:0px; --tw-ring-offset-color:#fff; --tw-ring-color:#2563eb; --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); border-color: rgb(37, 99, 235); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow); outline: transparent solid 2px; outline-offset: 2px; }

.form-input::-webkit-input-placeholder, .form-textarea::-webkit-input-placeholder { color: rgb(142, 142, 160); opacity: 1; }

.form-input::placeholder, .form-textarea::placeholder { color: rgb(142, 142, 160); opacity: 1; }

.form-input::-webkit-datetime-edit-fields-wrapper { padding: 0px; }

.form-input::-webkit-date-and-time-value { min-height: 1.5em; }

.form-input::-webkit-datetime-edit, .form-input::-webkit-datetime-edit-day-field, .form-input::-webkit-datetime-edit-hour-field, .form-input::-webkit-datetime-edit-meridiem-field, .form-input::-webkit-datetime-edit-millisecond-field, .form-input::-webkit-datetime-edit-minute-field, .form-input::-webkit-datetime-edit-month-field, .form-input::-webkit-datetime-edit-second-field, .form-input::-webkit-datetime-edit-year-field { padding-bottom: 0px; padding-top: 0px; }

.btn { align-items: center; border-color: transparent; border-radius: 0.25rem; border-width: 1px; display: inline-flex; font-size: 0.875rem; line-height: 1.25rem; padding: 0.5rem 0.75rem; pointer-events: auto; }

.btn:focus { outline: transparent solid 2px; outline-offset: 2px; }

.btn:disabled { cursor: not-allowed; opacity: 0.5; }

.btn-primary { --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(16,163,127,var(--tw-bg-opacity)); color: rgba(255,255,255,var(--tw-text-opacity)); }

.btn-primary:hover { --tw-bg-opacity:1; background-color: rgba(26,127,100,var(--tw-bg-opacity)); }

.btn-primary:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); --tw-ring-offset-width:2px; box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.btn-primary.focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(25,195,125,var(--tw-ring-opacity)); }

.btn-primary:focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(25,195,125,var(--tw-ring-opacity)); }

.btn-danger { --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(185,28,28,var(--tw-bg-opacity)); color: rgba(255,255,255,var(--tw-text-opacity)); }

.btn-danger:hover { --tw-bg-opacity:1; background-color: rgba(153,27,27,var(--tw-bg-opacity)); }

.btn-danger:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); --tw-ring-offset-width:2px; box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.btn-danger.focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(220,38,38,var(--tw-ring-opacity)); }

.btn-danger:focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(220,38,38,var(--tw-ring-opacity)); }

.btn-danger:disabled:hover { --tw-bg-opacity:1; background-color: rgba(185,28,28,var(--tw-bg-opacity)); }

.btn-neutral { --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); border-color: rgba(0, 0, 0, 0.1); border-width: 1px; color: rgba(64,65,79,var(--tw-text-opacity)); font-size: 0.875rem; line-height: 1.25rem; }

.btn-neutral:hover { --tw-bg-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.btn-neutral:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); --tw-ring-offset-width:2px; box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.btn-neutral.focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(99,102,241,var(--tw-ring-opacity)); }

.btn-neutral:focus-visible { --tw-ring-opacity:1; --tw-ring-color:rgba(99,102,241,var(--tw-ring-opacity)); }

.dark .btn-neutral { --tw-border-opacity:1; --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); border-color: rgba(86,88,105,var(--tw-border-opacity)); color: rgba(217,217,227,var(--tw-text-opacity)); }

.dark .btn-neutral:hover { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.btn-dark { --tw-border-opacity:1; --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); border-color: rgba(86,88,105,var(--tw-border-opacity)); border-width: 1px; color: rgba(255,255,255,var(--tw-text-opacity)); }

.btn-dark:hover { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.btn-light { --tw-bg-opacity:1; --tw-text-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); color: rgba(0,0,0,var(--tw-text-opacity)); }

.btn-light:hover { --tw-bg-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); }

.btn-disabled { --tw-bg-opacity:1; --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); cursor: not-allowed; }

.btn-disabled, .btn-disabled:hover { background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.btn-disabled:hover { --tw-bg-opacity:1; }

.btn-small { padding: 0.25rem 0.5rem; }

.hide-scrollbar { }

.hide-scrollbar ::-webkit-scrollbar { display: none; }

.sr-only { clip: rect(0px, 0px, 0px, 0px); border-width: 0px; height: 1px; margin: -1px; overflow: hidden; padding: 0px; position: absolute; white-space: nowrap; width: 1px; }

.pointer-events-none { pointer-events: none; }

.pointer-events-auto { pointer-events: auto; }

.visible { visibility: visible; }

.\!invisible { visibility: hidden !important; }

.invisible { visibility: hidden; }

.static { position: static; }

.fixed { position: fixed; }

.absolute { position: absolute; }

.relative { position: relative; }

.\!sticky { position: sticky !important; }

.sticky { position: sticky; }

.inset-0 { left: 0px; right: 0px; }

.inset-0, .inset-y-0 { bottom: 0px; top: 0px; }

.-left-2 { left: -0.5rem; }

.-top-0 { top: 0px; }

.-top-0\.5 { top: -0.125rem; }

.-top-4 { top: -1rem; }

.bottom-0 { bottom: 0px; }

.bottom-1 { bottom: 0.25rem; }

.bottom-1\.5 { bottom: 0.375rem; }

.bottom-2 { bottom: 0.5rem; }

.bottom-4 { bottom: 1rem; }

.bottom-\[10px\] { bottom: 10px; }

.bottom-\[124px\] { bottom: 124px; }

.bottom-full { bottom: 100%; }

.left-0 { left: 0px; }

.left-1 { left: 0.25rem; }

.left-1\.5 { left: 0.375rem; }

.left-1\/2 { left: 50%; }

.left-2 { left: 0.5rem; }

.left-4 { left: 1rem; }

.right-0 { right: 0px; }

.right-1 { right: 0.25rem; }

.right-2 { right: 0.5rem; }

.right-3 { right: 0.75rem; }

.right-4 { right: 1rem; }

.right-6 { right: 1.5rem; }

.top-0 { top: 0px; }

.top-1 { top: 0.25rem; }

.top-1\/2 { top: 50%; }

.top-14 { top: 3.5rem; }

.top-2 { top: 0.5rem; }

.top-\[-3px\] { top: -3px; }

.top-\[-6px\] { top: -6px; }

.top-\[20px\] { top: 20px; }

.top-full { top: 100%; }

.-z-0, .z-0 { z-index: 0; }

.z-10 { z-index: 10; }

.z-20 { z-index: 20; }

.z-50 { z-index: 50; }

.z-\[14\] { z-index: 14; }

.z-\[15\] { z-index: 15; }

.z-\[16\] { z-index: 16; }

.z-\[17\] { z-index: 17; }

.z-\[2\] { z-index: 2; }

.z-\[60\] { z-index: 60; }

.order-1 { order: 1; }

.order-2 { order: 2; }

.col-auto { grid-column: auto / auto; }

.col-span-1 { grid-column: span 1 / span 1; }

.col-start-2 { grid-column-start: 2; }

.row-auto { grid-row: auto / auto; }

.row-start-2 { grid-row-start: 2; }

.float-left { float: left; }

.m-0 { margin: 0px; }

.m-1 { margin: 0.25rem; }

.m-2 { margin: 0.5rem; }

.m-4 { margin: 1rem; }

.m-6 { margin: 1.5rem; }

.m-auto { margin: auto; }

.-my-0 { margin-bottom: 0px; margin-top: 0px; }

.-my-0\.5 { margin-bottom: -0.125rem; margin-top: -0.125rem; }

.-my-1 { margin-bottom: -0.25rem; margin-top: -0.25rem; }

.mx-1 { margin-left: 0.25rem; margin-right: 0.25rem; }

.mx-2 { margin-left: 0.5rem; margin-right: 0.5rem; }

.mx-3 { margin-left: 0.75rem; margin-right: 0.75rem; }

.mx-6 { margin-left: 1.5rem; margin-right: 1.5rem; }

.mx-8 { margin-left: 2rem; margin-right: 2rem; }

.mx-\[10px\] { margin-left: 10px; margin-right: 10px; }

.mx-auto { margin-left: auto; margin-right: auto; }

.my-0 { margin-bottom: 0px; margin-top: 0px; }

.my-1 { margin-bottom: 0.25rem; margin-top: 0.25rem; }

.my-1\.5 { margin-bottom: 0.375rem; margin-top: 0.375rem; }

.my-2 { margin-bottom: 0.5rem; margin-top: 0.5rem; }

.my-3 { margin-bottom: 0.75rem; margin-top: 0.75rem; }

.-ml-0 { margin-left: 0px; }

.-ml-0\.5 { margin-left: -0.125rem; }

.-ml-1 { margin-left: -0.25rem; }

.-ml-4 { margin-left: -1rem; }

.-ml-\[1px\] { margin-left: -1px; }

.-ml-\[8px\] { margin-left: -8px; }

.-ml-px { margin-left: -1px; }

.-mr-1 { margin-right: -0.25rem; }

.-mr-12 { margin-right: -3rem; }

.-mr-2 { margin-right: -0.5rem; }

.-mt-0 { margin-top: 0px; }

.-mt-0\.5 { margin-top: -0.125rem; }

.-mt-\[3px\] { margin-top: -3px; }

.mb-0 { margin-bottom: 0px; }

.mb-0\.5 { margin-bottom: 0.125rem; }

.mb-1 { margin-bottom: 0.25rem; }

.mb-10 { margin-bottom: 2.5rem; }

.mb-12 { margin-bottom: 3rem; }

.mb-2 { margin-bottom: 0.5rem; }

.mb-3 { margin-bottom: 0.75rem; }

.mb-4 { margin-bottom: 1rem; }

.mb-5 { margin-bottom: 1.25rem; }

.mb-6 { margin-bottom: 1.5rem; }

.mb-7 { margin-bottom: 1.75rem; }

.mb-8 { margin-bottom: 2rem; }

.mb-9 { margin-bottom: 2.25rem; }

.mb-auto { margin-bottom: auto; }

.ml-0 { margin-left: 0px; }

.ml-0\.5 { margin-left: 0.125rem; }

.ml-1 { margin-left: 0.25rem; }

.ml-12 { margin-left: 3rem; }

.ml-5 { margin-left: 1.25rem; }

.ml-auto { margin-left: auto; }

.mr-0 { margin-right: 0px; }

.mr-1 { margin-right: 0.25rem; }

.mr-2 { margin-right: 0.5rem; }

.mr-3 { margin-right: 0.75rem; }

.mr-4 { margin-right: 1rem; }

.mr-8 { margin-right: 2rem; }

.mr-auto { margin-right: auto; }

.mt-1 { margin-top: 0.25rem; }

.mt-2 { margin-top: 0.5rem; }

.mt-3 { margin-top: 0.75rem; }

.mt-4 { margin-top: 1rem; }

.mt-5 { margin-top: 1.25rem; }

.mt-6 { margin-top: 1.5rem; }

.mt-8 { margin-top: 2rem; }

.mt-auto { margin-top: auto; }

.line-clamp-1 { -webkit-line-clamp: 1; }

.line-clamp-1, .line-clamp-2 { -webkit-box-orient: vertical; display: -webkit-box; overflow: hidden; }

.line-clamp-2 { -webkit-line-clamp: 2; }

.line-clamp-3 { -webkit-box-orient: vertical; -webkit-line-clamp: 3; display: -webkit-box; overflow: hidden; }

.block { display: block; }

.inline-block { display: inline-block; }

.inline { display: inline; }

.flex { display: flex; }

.inline-flex { display: inline-flex; }

.table { display: table; }

.grid { display: grid; }

.contents { display: contents; }

.hidden { display: none; }

.aspect-\[4\/7\] { aspect-ratio: 4 / 7; }

.aspect-\[7\/4\] { aspect-ratio: 7 / 4; }

.aspect-square { aspect-ratio: 1 / 1; }

.\!h-5 { height: 1.25rem !important; }

.h-1 { height: 0.25rem; }

.h-10 { height: 2.5rem; }

.h-11 { height: 2.75rem; }

.h-12 { height: 3rem; }

.h-16 { height: 4rem; }

.h-2 { height: 0.5rem; }

.h-24 { height: 6rem; }

.h-3 { height: 0.75rem; }

.h-32 { height: 8rem; }

.h-4 { height: 1rem; }

.h-5 { height: 1.25rem; }

.h-6 { height: 1.5rem; }

.h-64 { height: 16rem; }

.h-7 { height: 1.75rem; }

.h-8 { height: 2rem; }

.h-9 { height: 2.25rem; }

.h-\[1200px\] { height: 1200px; }

.h-\[12px\] { height: 12px; }

.h-\[14px\] { height: 14px; }

.h-\[18px\] { height: 18px; }

.h-\[19px\] { height: 19px; }

.h-\[21px\] { height: 21px; }

.h-\[25px\] { height: 25px; }

.h-\[30px\] { height: 30px; }

.h-\[36px\] { height: 36px; }

.h-\[404px\] { height: 404px; }

.h-\[42px\] { height: 42px; }

.h-\[50px\] { height: 50px; }

.h-\[60px\] { height: 60px; }

.h-\[70px\] { height: 70px; }

.h-auto { height: auto; }

.h-full { height: 100%; }

.h-px { height: 1px; }

.h-screen { height: 100vh; }

.max-h-0 { max-height: 0px; }

.max-h-5 { max-height: 1.25rem; }

.max-h-60 { max-height: 15rem; }

.max-h-64 { max-height: 16rem; }

.max-h-72 { max-height: 18rem; }

.max-h-\[28rem\] { max-height: 28rem; }

.max-h-\[80vh\] { max-height: 80vh; }

.min-h-0 { min-height: 0px; }

.min-h-\[1\.5rem\] { min-height: 1.5rem; }

.min-h-\[20px\] { min-height: 20px; }

.min-h-\[24px\] { min-height: 24px; }

.min-h-\[71px\] { min-height: 71px; }

.min-h-full { min-height: 100%; }

.min-h-screen { min-height: 100vh; }

.\!w-5 { width: 1.25rem !important; }

.w-10 { width: 2.5rem; }

.w-11 { width: 2.75rem; }

.w-12 { width: 3rem; }

.w-14 { width: 3.5rem; }

.w-16 { width: 4rem; }

.w-2 { width: 0.5rem; }

.w-28 { width: 7rem; }

.w-3 { width: 0.75rem; }

.w-4 { width: 1rem; }

.w-5 { width: 1.25rem; }

.w-6 { width: 1.5rem; }

.w-64 { width: 16rem; }

.w-7 { width: 1.75rem; }

.w-8 { width: 2rem; }

.w-9\/12 { width: 75%; }

.w-96 { width: 24rem; }

.w-\[103px\] { width: 103px; }

.w-\[184px\] { width: 184px; }

.w-\[18px\] { width: 18px; }

.w-\[2\.5px\] { width: 2.5px; }

.w-\[209px\] { width: 209px; }

.w-\[218px\] { width: 218px; }

.w-\[21px\] { width: 21px; }

.w-\[260px\] { width: 260px; }

.w-\[30px\] { width: 30px; }

.w-\[42px\] { width: 42px; }

.w-\[70px\] { width: 70px; }

.w-\[860px\] { width: 860px; }

.w-\[88px\] { width: 88px; }

.w-\[960px\] { width: 960px; }

.w-\[calc\(100\%-50px\)\] { width: calc(100% - 50px); }

.w-auto { width: auto; }

.w-full { width: 100%; }

.w-screen { width: 100vw; }

.min-w-0 { min-width: 0px; }

.min-w-\[100vw\] { min-width: 100vw; }

.min-w-\[180px\] { min-width: 180px; }

.min-w-\[220px\] { min-width: 220px; }

.min-w-\[8rem\] { min-width: 8rem; }

.max-w-2xl { max-width: 42rem; }

.max-w-5xl { max-width: 64rem; }

.max-w-7xl { max-width: 80rem; }

.max-w-\[100vw\] { max-width: 100vw; }

.max-w-\[400px\] { max-width: 400px; }

.max-w-\[44rem\] { max-width: 44rem; }

.max-w-\[550px\] { max-width: 550px; }

.max-w-\[560px\] { max-width: 560px; }

.max-w-full { max-width: 100%; }

.max-w-lg { max-width: 32rem; }

.max-w-md { max-width: 28rem; }

.max-w-sm { max-width: 24rem; }

.max-w-xl { max-width: 36rem; }

.max-w-xs { max-width: 20rem; }

.flex-1 { flex: 1 1 0%; }

.flex-auto { flex: 1 1 auto; }

.flex-initial { flex: 0 1 auto; }

.flex-none { flex: 0 0 auto; }

.flex-shrink { flex-shrink: 1; }

.flex-shrink-0 { flex-shrink: 0; }

.shrink { flex-shrink: 1; }

.shrink-0 { flex-shrink: 0; }

.flex-grow { flex-grow: 1; }

.flex-grow-0 { flex-grow: 0; }

.grow { flex-grow: 1; }

.table-fixed { table-layout: fixed; }

.border-separate { border-collapse: separate; }

.border-spacing-0 { --tw-border-spacing-x:0px; --tw-border-spacing-y:0px; border-spacing: var(--tw-border-spacing-x) var(--tw-border-spacing-y); }

.origin-\[50\%_50\%\] { transform-origin: 50% 50%; }

.-translate-x-1\/2 { --tw-translate-x:-50%; }

.-translate-x-1\/2, .-translate-x-\[calc\(100\%\+4px\)\] { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.-translate-x-\[calc\(100\%\+4px\)\] { --tw-translate-x:calc(-100% + -4px); }

.-translate-x-full { --tw-translate-x:-100%; }

.-translate-x-full, .-translate-y-1\/2 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.-translate-y-1\/2 { --tw-translate-y:-50%; }

.translate-x-0 { --tw-translate-x:0px; }

.translate-x-0, .translate-x-0\.5 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.translate-x-0\.5 { --tw-translate-x:0.125rem; }

.translate-x-1 { --tw-translate-x:0.25rem; }

.translate-x-1, .translate-x-1\/2 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.translate-x-1\/2 { --tw-translate-x:50%; }

.translate-x-full { --tw-translate-x:100%; }

.translate-x-full, .translate-y-0 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.translate-y-0 { --tw-translate-y:0px; }

.translate-y-1 { --tw-translate-y:0.25rem; }

.translate-y-1, .translate-y-3 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.translate-y-3 { --tw-translate-y:0.75rem; }

.translate-y-\[calc\(100\%-71px\)\] { --tw-translate-y:calc(100% - 71px); }

.-rotate-180, .translate-y-\[calc\(100\%-71px\)\] { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.-rotate-180 { --tw-rotate:-180deg; }

.-rotate-45 { --tw-rotate:-45deg; }

.-rotate-45, .-rotate-90 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.-rotate-90 { --tw-rotate:-90deg; }

.rotate-180 { --tw-rotate:180deg; }

.rotate-180, .rotate-45 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.rotate-45 { --tw-rotate:45deg; }

.transform { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

@-webkit-keyframes slideLeftAndFade { 
  0% { opacity: 0; transform: translateX(2px); }
  100% { opacity: 1; transform: translateX(0px); }
}

.animate-slideLeftAndFade { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideLeftAndFade; }

@-webkit-keyframes spin { 
  100% { transform: rotate(1turn); }
}

@keyframes spin { 
  100% { transform: rotate(1turn); }
}

.animate-spin { animation: 1s linear 0s infinite normal none running spin; }

.cursor-auto { cursor: auto; }

.cursor-default { cursor: default; }

.cursor-not-allowed { cursor: not-allowed; }

.cursor-pointer { cursor: pointer; }

.select-none { user-select: none; }

.resize-none { resize: none; }

.resize { resize: both; }

.list-disc { list-style-type: disc; }

.list-none { list-style-type: none; }

.appearance-none { appearance: none; }

.grid-cols-1 { grid-template-columns: repeat(1, minmax(0px, 1fr)); }

.grid-cols-2 { grid-template-columns: repeat(2, minmax(0px, 1fr)); }

.grid-cols-\[minmax\(10px\,30px\)_1fr_minmax\(10px\,30px\)\] { grid-template-columns: minmax(10px, 30px) 1fr minmax(10px, 30px); }

.grid-rows-\[minmax\(10px\,_1fr\)_auto_minmax\(10px\,_1fr\)\] { grid-template-rows: minmax(10px, 1fr) auto minmax(10px, 1fr); }

.flex-row { flex-direction: row; }

.flex-col { flex-direction: column; }

.flex-col-reverse { flex-direction: column-reverse; }

.flex-wrap { flex-wrap: wrap; }

.place-items-center { place-items: center; }

.items-start { align-items: flex-start; }

.items-end { align-items: flex-end; }

.items-center { align-items: center; }

.items-stretch { align-items: stretch; }

.justify-start { justify-content: flex-start; }

.justify-end { justify-content: flex-end; }

.justify-center { justify-content: center; }

.justify-between { justify-content: space-between; }

.justify-around { justify-content: space-around; }

.justify-stretch { justify-content: stretch; }

.gap-0 { gap: 0px; }

.gap-1 { gap: 0.25rem; }

.gap-1\.5 { gap: 0.375rem; }

.gap-16 { gap: 4rem; }

.gap-2 { gap: 0.5rem; }

.gap-2\.5 { gap: 0.625rem; }

.gap-3 { gap: 0.75rem; }

.gap-3\.5 { gap: 0.875rem; }

.gap-4 { gap: 1rem; }

.gap-5 { gap: 1.25rem; }

.gap-6 { gap: 1.5rem; }

.space-x-1 > :not([hidden]) ~ :not([hidden]) { --tw-space-x-reverse:0; margin-left: calc(0.25rem*(1 - var(--tw-space-x-reverse))); margin-right: calc(0.25rem*var(--tw-space-x-reverse)); }

.space-x-1\.5 > :not([hidden]) ~ :not([hidden]) { --tw-space-x-reverse:0; margin-left: calc(0.375rem*(1 - var(--tw-space-x-reverse))); margin-right: calc(0.375rem*var(--tw-space-x-reverse)); }

.space-x-2 > :not([hidden]) ~ :not([hidden]) { --tw-space-x-reverse:0; margin-left: calc(0.5rem*(1 - var(--tw-space-x-reverse))); margin-right: calc(0.5rem*var(--tw-space-x-reverse)); }

.space-y-2 > :not([hidden]) ~ :not([hidden]) { --tw-space-y-reverse:0; margin-bottom: calc(0.5rem*var(--tw-space-y-reverse)); margin-top: calc(0.5rem*(1 - var(--tw-space-y-reverse))); }

.self-end { align-self: flex-end; }

.self-center { align-self: center; }

.self-stretch { align-self: stretch; }

.overflow-auto { overflow: auto; }

.overflow-hidden { overflow: hidden; }

.overflow-x-auto { overflow-x: auto; }

.overflow-y-auto { overflow-y: auto; }

.overflow-x-hidden { overflow-x: hidden; }

.overflow-y-hidden { overflow-y: hidden; }

.truncate { overflow: hidden; white-space: nowrap; }

.overflow-ellipsis, .text-ellipsis, .truncate { text-overflow: ellipsis; }

.whitespace-nowrap { white-space: nowrap; }

.\!whitespace-pre { white-space: pre !important; }

.whitespace-pre-line { white-space: pre-line; }

.\!whitespace-pre-wrap { white-space: pre-wrap !important; }

.whitespace-pre-wrap { white-space: pre-wrap; }

.break-words { overflow-wrap: break-word; }

.break-all { word-break: break-all; }

.rounded { border-radius: 0.25rem; }

.rounded-2xl { border-radius: 1rem; }

.rounded-\[4px\] { border-radius: 4px; }

.rounded-\[5px\] { border-radius: 5px; }

.rounded-full { border-radius: 9999px; }

.rounded-lg { border-radius: 0.5rem; }

.rounded-md { border-radius: 0.375rem; }

.rounded-none { border-radius: 0px; }

.rounded-sm { border-radius: 0.125rem; }

.rounded-xl { border-radius: 0.75rem; }

.rounded-b-lg { border-bottom-left-radius: 0.5rem; border-bottom-right-radius: 0.5rem; }

.rounded-l-md { border-bottom-left-radius: 0.375rem; border-top-left-radius: 0.375rem; }

.rounded-r-md { border-bottom-right-radius: 0.375rem; border-top-right-radius: 0.375rem; }

.rounded-t { border-top-left-radius: 0.25rem; border-top-right-radius: 0.25rem; }

.rounded-t-md { border-top-left-radius: 0.375rem; border-top-right-radius: 0.375rem; }

.rounded-t-xl { border-top-left-radius: 0.75rem; border-top-right-radius: 0.75rem; }

.rounded-br-sm { border-bottom-right-radius: 0.125rem; }

.border { border-width: 1px; }

.border-0 { border-width: 0px; }

.border-\[0\.5px\] { border-width: 0.5px; }

.border-b { border-bottom-width: 1px; }

.border-l { border-left-width: 1px; }

.border-l-4 { border-left-width: 4px; }

.border-r { border-right-width: 1px; }

.border-r-0 { border-right-width: 0px; }

.border-t { border-top-width: 1px; }

.border-none { border-style: none; }

.border-black\/10 { border-color: rgba(0, 0, 0, 0.1); }

.border-black\/20 { border-color: rgba(0, 0, 0, 0.2); }

.border-black\/30 { border-color: rgba(0, 0, 0, 0.3); }

.border-black\/5 { border-color: rgba(0, 0, 0, 0.05); }

.border-gray-100 { --tw-border-opacity:1; border-color: rgba(236,236,241,var(--tw-border-opacity)); }

.border-gray-200 { --tw-border-opacity:1; border-color: rgba(217,217,227,var(--tw-border-opacity)); }

.border-gray-300 { --tw-border-opacity:1; border-color: rgba(197,197,210,var(--tw-border-opacity)); }

.border-gray-400 { --tw-border-opacity:1; border-color: rgba(172,172,190,var(--tw-border-opacity)); }

.border-gray-500 { --tw-border-opacity:1; border-color: rgba(142,142,160,var(--tw-border-opacity)); }

.border-gray-700 { --tw-border-opacity:1; border-color: rgba(64,65,79,var(--tw-border-opacity)); }

.border-gray-800 { --tw-border-opacity:1; border-color: rgba(52,53,65,var(--tw-border-opacity)); }

.border-green-500 { --tw-border-opacity:1; border-color: rgba(25,195,125,var(--tw-border-opacity)); }

.border-indigo-400 { --tw-border-opacity:1; border-color: rgba(129,140,248,var(--tw-border-opacity)); }

.border-orange-500 { --tw-border-opacity:1; border-color: rgba(224,108,43,var(--tw-border-opacity)); }

.border-red-500 { --tw-border-opacity:1; border-color: rgba(239,68,68,var(--tw-border-opacity)); }

.border-transparent { border-color: transparent; }

.border-white { --tw-border-opacity:1; border-color: rgba(255,255,255,var(--tw-border-opacity)); }

.border-white\/20 { border-color: rgba(255, 255, 255, 0.2); }

.\!bg-gray-700 { --tw-bg-opacity:1 !important; background-color: rgba(64,65,79,var(--tw-bg-opacity)) !important; }

.\!bg-transparent { background-color: transparent !important; }

.\!bg-white { --tw-bg-opacity:1 !important; background-color: rgba(255,255,255,var(--tw-bg-opacity)) !important; }

.bg-\[\#0077FF\] { --tw-bg-opacity:1; background-color: rgba(0,119,255,var(--tw-bg-opacity)); }

.bg-\[\#FFF3C9\] { --tw-bg-opacity:1; background-color: rgba(255,243,201,var(--tw-bg-opacity)); }

.bg-black { --tw-bg-opacity:1; background-color: rgba(0,0,0,var(--tw-bg-opacity)); }

.bg-black\/\[\.04\] { background-color: rgba(0, 0, 0, 0.04); }

.bg-black\/\[\.08\] { background-color: rgba(0, 0, 0, 0.08); }

.bg-black\/\[\.12\] { background-color: rgba(0, 0, 0, 0.12); }

.bg-blue-100 { --tw-bg-opacity:1; background-color: rgba(219,234,254,var(--tw-bg-opacity)); }

.bg-blue-200 { --tw-bg-opacity:1; background-color: rgba(191,219,254,var(--tw-bg-opacity)); }

.bg-gray-100 { --tw-bg-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.bg-gray-200 { --tw-bg-opacity:1; background-color: rgba(217,217,227,var(--tw-bg-opacity)); }

.bg-gray-300 { --tw-bg-opacity:1; background-color: rgba(197,197,210,var(--tw-bg-opacity)); }

.bg-gray-50 { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.bg-gray-500 { --tw-bg-opacity:1; background-color: rgba(142,142,160,var(--tw-bg-opacity)); }

.bg-gray-500\/90 { background-color: rgba(141, 141, 160, 0.9); }

.bg-gray-600 { --tw-bg-opacity:1; background-color: rgba(86,88,105,var(--tw-bg-opacity)); }

.bg-gray-700 { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.bg-gray-800 { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.bg-gray-900 { --tw-bg-opacity:1; background-color: rgba(32,33,35,var(--tw-bg-opacity)); }

.bg-gray-950 { --tw-bg-opacity:1; background-color: rgba(5,5,9,var(--tw-bg-opacity)); }

.bg-green-100 { --tw-bg-opacity:1; background-color: rgba(210,244,211,var(--tw-bg-opacity)); }

.bg-green-500 { --tw-bg-opacity:1; background-color: rgba(25,195,125,var(--tw-bg-opacity)); }

.bg-green-500\/10 { background-color: rgba(25, 195, 125, 0.1); }

.bg-green-600 { --tw-bg-opacity:1; background-color: rgba(16,163,127,var(--tw-bg-opacity)); }

.bg-orange-500 { --tw-bg-opacity:1; background-color: rgba(224,108,43,var(--tw-bg-opacity)); }

.bg-orange-500\/10 { background-color: rgba(224, 108, 43, 0.1); }

.bg-red-100 { --tw-bg-opacity:1; background-color: rgba(254,226,226,var(--tw-bg-opacity)); }

.bg-red-200 { --tw-bg-opacity:1; background-color: rgba(254,202,202,var(--tw-bg-opacity)); }

.bg-red-500 { --tw-bg-opacity:1; background-color: rgba(239,68,68,var(--tw-bg-opacity)); }

.bg-red-500\/10 { background-color: rgba(239, 68, 68, 0.1); }

.bg-red-600 { --tw-bg-opacity:1; background-color: rgba(220,38,38,var(--tw-bg-opacity)); }

.bg-transparent { background-color: transparent; }

.bg-white { --tw-bg-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); }

.bg-white\/20 { background-color: rgba(255, 255, 255, 0.2); }

.bg-white\/25 { background-color: rgba(255, 255, 255, 0.25); }

.bg-yellow-100 { --tw-bg-opacity:1; background-color: rgba(254,249,195,var(--tw-bg-opacity)); }

.bg-yellow-200 { --tw-bg-opacity:1; background-color: rgba(250,230,158,var(--tw-bg-opacity)); }

.bg-opacity-75 { --tw-bg-opacity:0.75; }

.bg-gradient-to-l { background-image: linear-gradient(to left,var(--tw-gradient-stops)); }

.bg-gradient-to-t { background-image: linear-gradient(to top,var(--tw-gradient-stops)); }

.from-gray-100 { --tw-gradient-from:#ececf1 var(--tw-gradient-from-position); --tw-gradient-to:rgba(236,236,241,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.from-gray-800 { --tw-gradient-from:#343541 var(--tw-gradient-from-position); --tw-gradient-to:rgba(52,53,65,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.from-gray-900 { --tw-gradient-from:#202123 var(--tw-gradient-from-position); --tw-gradient-to:rgba(32,33,35,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.from-gray-900\/0 { --tw-gradient-from:rgba(32,33,35,0) var(--tw-gradient-from-position); --tw-gradient-to:rgba(32,33,35,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.from-\[60\%\] { --tw-gradient-from-position:60%; }

.to-gray-900 { --tw-gradient-to:#202123 var(--tw-gradient-to-position); }

.bg-contain { background-size: contain; }

.bg-cover { background-size: cover; }

.bg-center { background-position: 50% center; }

.bg-no-repeat { background-repeat: no-repeat; }

.fill-gray-800 { fill: rgb(52, 53, 65); }

.stroke-gray-200 { stroke: rgb(217, 217, 227); }

.object-cover { object-fit: cover; }

.p-0 { padding: 0px; }

.p-0\.5 { padding: 0.125rem; }

.p-1 { padding: 0.25rem; }

.p-2 { padding: 0.5rem; }

.p-3 { padding: 0.75rem; }

.p-4 { padding: 1rem; }

.p-6 { padding: 1.5rem; }

.p-\[5px\] { padding: 5px; }

.px-0 { padding-left: 0px; padding-right: 0px; }

.px-0\.5 { padding-left: 0.125rem; padding-right: 0.125rem; }

.px-1 { padding-left: 0.25rem; padding-right: 0.25rem; }

.px-1\.5 { padding-left: 0.375rem; padding-right: 0.375rem; }

.px-2 { padding-left: 0.5rem; padding-right: 0.5rem; }

.px-3 { padding-left: 0.75rem; padding-right: 0.75rem; }

.px-4 { padding-left: 1rem; padding-right: 1rem; }

.px-5 { padding-left: 1.25rem; padding-right: 1.25rem; }

.px-6 { padding-left: 1.5rem; padding-right: 1.5rem; }

.px-8 { padding-left: 2rem; padding-right: 2rem; }

.py-0 { padding-bottom: 0px; padding-top: 0px; }

.py-0\.5 { padding-bottom: 0.125rem; padding-top: 0.125rem; }

.py-1 { padding-bottom: 0.25rem; padding-top: 0.25rem; }

.py-1\.5 { padding-bottom: 0.375rem; padding-top: 0.375rem; }

.py-2 { padding-bottom: 0.5rem; padding-top: 0.5rem; }

.py-3 { padding-bottom: 0.75rem; padding-top: 0.75rem; }

.py-4 { padding-bottom: 1rem; padding-top: 1rem; }

.py-6 { padding-bottom: 1.5rem; padding-top: 1.5rem; }

.py-7 { padding-bottom: 1.75rem; padding-top: 1.75rem; }

.py-8 { padding-bottom: 2rem; padding-top: 2rem; }

.py-\[10px\] { padding-bottom: 10px; padding-top: 10px; }

.\!pt-0 { padding-top: 0px !important; }

.pb-0 { padding-bottom: 0px; }

.pb-0\.5 { padding-bottom: 0.125rem; }

.pb-1 { padding-bottom: 0.25rem; }

.pb-1\.5 { padding-bottom: 0.375rem; }

.pb-2 { padding-bottom: 0.5rem; }

.pb-3 { padding-bottom: 0.75rem; }

.pb-4 { padding-bottom: 1rem; }

.pb-5 { padding-bottom: 1.25rem; }

.pb-8 { padding-bottom: 2rem; }

.pl-1 { padding-left: 0.25rem; }

.pl-10 { padding-left: 2.5rem; }

.pl-12 { padding-left: 3rem; }

.pl-3 { padding-left: 0.75rem; }

.pl-4 { padding-left: 1rem; }

.pl-5 { padding-left: 1.25rem; }

.pl-6 { padding-left: 1.5rem; }

.pr-1 { padding-right: 0.25rem; }

.pr-1\.5 { padding-right: 0.375rem; }

.pr-10 { padding-right: 2.5rem; }

.pr-11 { padding-right: 2.75rem; }

.pr-12 { padding-right: 3rem; }

.pr-14 { padding-right: 3.5rem; }

.pr-2 { padding-right: 0.5rem; }

.pr-3 { padding-right: 0.75rem; }

.pr-5 { padding-right: 1.25rem; }

.pr-6 { padding-right: 1.5rem; }

.pr-7 { padding-right: 1.75rem; }

.pr-9 { padding-right: 2.25rem; }

.pr-\[4\.5rem\] { padding-right: 4.5rem; }

.pt-1 { padding-top: 0.25rem; }

.pt-2 { padding-top: 0.5rem; }

.pt-20 { padding-top: 5rem; }

.pt-3 { padding-top: 0.75rem; }

.pt-4 { padding-top: 1rem; }

.pt-5 { padding-top: 1.25rem; }

.pt-\[67\%\] { padding-top: 67%; }

.text-left { text-align: left; }

.text-center { text-align: center; }

.text-right { text-align: right; }

.align-top { vertical-align: top; }

.font-mono { font-family: "SÃ¶hne Mono", Monaco, "Andale Mono", "Ubuntu Mono", monospace; }

.font-sans { font-family: SÃ¶hne, ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, Ubuntu, Cantarell, "Noto Sans", sans-serif, "Helvetica Neue", Arial, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji"; }

.text-2xl { font-size: 1.5rem; line-height: 2rem; }

.text-3xl { font-size: 1.875rem; line-height: 2.25rem; }

.text-4xl { font-size: 2.25rem; line-height: 2.5rem; }

.text-\[10px\] { font-size: 10px; }

.text-\[28px\] { font-size: 28px; }

.text-base { font-size: 1rem; line-height: 1.5rem; }

.text-lg { font-size: 1.125rem; line-height: 1.75rem; }

.text-sm { font-size: 0.875rem; line-height: 1.25rem; }

.text-xl { font-size: 1.25rem; line-height: 1.75rem; }

.text-xs { font-size: 0.75rem; line-height: 1rem; }

.font-bold { font-weight: 700; }

.font-medium { font-weight: 500; }

.font-normal { font-weight: 400; }

.font-semibold { font-weight: 600; }

.uppercase { text-transform: uppercase; }

.capitalize { text-transform: capitalize; }

.normal-case { text-transform: none; }

.italic { font-style: italic; }

.leading-3 { line-height: 0.75rem; }

.leading-5 { line-height: 1.25rem; }

.leading-6 { line-height: 1.5rem; }

.leading-none { line-height: 1; }

.leading-normal { line-height: 1.5; }

.leading-tight { line-height: 1.25; }

.tracking-wide { letter-spacing: 0.025em; }

.tracking-widest { letter-spacing: 0.1em; }

.text-\[\#756B5C\] { --tw-text-opacity:1; color: rgba(117,107,92,var(--tw-text-opacity)); }

.text-black { --tw-text-opacity:1; color: rgba(0,0,0,var(--tw-text-opacity)); }

.text-black\/50 { color: rgba(0, 0, 0, 0.5); }

.text-black\/60 { color: rgba(0, 0, 0, 0.6); }

.text-black\/70 { color: rgba(0, 0, 0, 0.7); }

.text-blue-400 { --tw-text-opacity:1; color: rgba(58,136,255,var(--tw-text-opacity)); }

.text-blue-500 { --tw-text-opacity:1; color: rgba(69,89,164,var(--tw-text-opacity)); }

.text-blue-600 { --tw-text-opacity:1; color: rgba(37,99,235,var(--tw-text-opacity)); }

.text-blue-700 { --tw-text-opacity:1; color: rgba(29,78,216,var(--tw-text-opacity)); }

.text-brand-green { --tw-text-opacity:1; color: rgba(25,195,125,var(--tw-text-opacity)); }

.text-brand-purple { --tw-text-opacity:1; color: rgba(171,104,255,var(--tw-text-opacity)); }

.text-gray-100 { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.text-gray-200 { --tw-text-opacity:1; color: rgba(217,217,227,var(--tw-text-opacity)); }

.text-gray-300 { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.text-gray-400 { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.text-gray-500 { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.text-gray-600 { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

.text-gray-700 { --tw-text-opacity:1; color: rgba(64,65,79,var(--tw-text-opacity)); }

.text-gray-800 { --tw-text-opacity:1; color: rgba(52,53,65,var(--tw-text-opacity)); }

.text-gray-900 { --tw-text-opacity:1; color: rgba(32,33,35,var(--tw-text-opacity)); }

.text-green-500 { --tw-text-opacity:1; color: rgba(25,195,125,var(--tw-text-opacity)); }

.text-green-600 { --tw-text-opacity:1; color: rgba(16,163,127,var(--tw-text-opacity)); }

.text-green-700 { --tw-text-opacity:1; color: rgba(26,127,100,var(--tw-text-opacity)); }

.text-indigo-500 { --tw-text-opacity:1; color: rgba(99,102,241,var(--tw-text-opacity)); }

.text-orange-500 { --tw-text-opacity:1; color: rgba(224,108,43,var(--tw-text-opacity)); }

.text-red-300 { --tw-text-opacity:1; color: rgba(252,165,165,var(--tw-text-opacity)); }

.text-red-500 { --tw-text-opacity:1; color: rgba(239,68,68,var(--tw-text-opacity)); }

.text-red-600 { --tw-text-opacity:1; color: rgba(220,38,38,var(--tw-text-opacity)); }

.text-red-700 { --tw-text-opacity:1; color: rgba(185,28,28,var(--tw-text-opacity)); }

.text-red-800 { --tw-text-opacity:1; color: rgba(153,27,27,var(--tw-text-opacity)); }

.text-white { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.text-white\/25 { color: rgba(255, 255, 255, 0.25); }

.text-white\/50 { color: rgba(255, 255, 255, 0.5); }

.text-white\/80 { color: rgba(255, 255, 255, 0.8); }

.text-yellow-400 { --tw-text-opacity:1; color: rgba(255,198,87,var(--tw-text-opacity)); }

.text-yellow-500 { --tw-text-opacity:1; color: rgba(234,179,8,var(--tw-text-opacity)); }

.text-yellow-700 { --tw-text-opacity:1; color: rgba(161,98,7,var(--tw-text-opacity)); }

.text-yellow-900 { --tw-text-opacity:1; color: rgba(146,114,1,var(--tw-text-opacity)); }

.underline { text-decoration-line: underline; }

.\!no-underline { text-decoration-line: none !important; }

.antialiased { -webkit-font-smoothing: antialiased; }

.placeholder-gray-500::-webkit-input-placeholder { --tw-placeholder-opacity:1; color: rgba(142,142,160,var(--tw-placeholder-opacity)); }

.placeholder-gray-500::placeholder { --tw-placeholder-opacity:1; color: rgba(142,142,160,var(--tw-placeholder-opacity)); }

.opacity-0 { opacity: 0; }

.opacity-100 { opacity: 1; }

.opacity-20 { opacity: 0.2; }

.opacity-30 { opacity: 0.3; }

.opacity-50 { opacity: 0.5; }

.opacity-70 { opacity: 0.7; }

.opacity-80 { opacity: 0.8; }

.\!shadow-none { --tw-shadow:0 0 transparent !important; --tw-shadow-colored:0 0 transparent !important; box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow) !important; }

.shadow { --tw-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px -1px rgba(0,0,0,0.1); --tw-shadow-colored:0 1px 3px 0 var(--tw-shadow-color),0 1px 2px -1px var(--tw-shadow-color); }

.shadow, .shadow-\[0_0\.5px_2px_rgba\(0\,0\,0\,0\.15\)\] { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-\[0_0\.5px_2px_rgba\(0\,0\,0\,0\.15\)\] { --tw-shadow:0 0.5px 2px rgba(0,0,0,0.15); --tw-shadow-colored:0 0.5px 2px var(--tw-shadow-color); }

.shadow-\[0_1px_2px_rgba\(0\,0\,0\,0\.45\)\] { --tw-shadow:0 1px 2px rgba(0,0,0,0.45); --tw-shadow-colored:0 1px 2px var(--tw-shadow-color); }

.shadow-\[0_1px_2px_rgba\(0\,0\,0\,0\.45\)\], .shadow-\[0_1px_7px_0_rgba\(0\,0\,0\,0\.03\)\] { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-\[0_1px_7px_0_rgba\(0\,0\,0\,0\.03\)\] { --tw-shadow:0 1px 7px 0 rgba(0,0,0,0.03); --tw-shadow-colored:0 1px 7px 0 var(--tw-shadow-color); }

.shadow-\[0_1px_7px_0px_rgba\(0\,0\,0\,0\.06\)\] { --tw-shadow:0 1px 7px 0px rgba(0,0,0,0.06); --tw-shadow-colored:0 1px 7px 0px var(--tw-shadow-color); }

.shadow-\[0_1px_7px_0px_rgba\(0\,0\,0\,0\.06\)\], .shadow-\[0_2px_12px_0px_rgba\(0\,0\,0\,0\.08\)\] { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-\[0_2px_12px_0px_rgba\(0\,0\,0\,0\.08\)\] { --tw-shadow:0 2px 12px 0px rgba(0,0,0,0.08); --tw-shadow-colored:0 2px 12px 0px var(--tw-shadow-color); }

.shadow-\[0_2px_24px_rgba\(0\,0\,0\,0\.05\)\] { --tw-shadow:0 2px 24px rgba(0,0,0,0.05); --tw-shadow-colored:0 2px 24px var(--tw-shadow-color); }

.shadow-\[0_2px_24px_rgba\(0\,0\,0\,0\.05\)\], .shadow-\[0px_4px_14px_rgba\(0\,0\,0\,0\.06\)\] { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-\[0px_4px_14px_rgba\(0\,0\,0\,0\.06\)\] { --tw-shadow:0px 4px 14px rgba(0,0,0,0.06); --tw-shadow-colored:0px 4px 14px var(--tw-shadow-color); }

.shadow-lg { --tw-shadow:0 10px 15px -3px rgba(0,0,0,0.1),0 4px 6px -4px rgba(0,0,0,0.1); --tw-shadow-colored:0 10px 15px -3px var(--tw-shadow-color),0 4px 6px -4px var(--tw-shadow-color); }

.shadow-lg, .shadow-md { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-md { --tw-shadow:0 4px 6px -1px rgba(0,0,0,0.1),0 2px 4px -2px rgba(0,0,0,0.1); --tw-shadow-colored:0 4px 6px -1px var(--tw-shadow-color),0 2px 4px -2px var(--tw-shadow-color); }

.shadow-sm { --tw-shadow:0 1px 2px 0 rgba(0,0,0,0.05); --tw-shadow-colored:0 1px 2px 0 var(--tw-shadow-color); }

.shadow-sm, .shadow-xl { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-xl { --tw-shadow:0 20px 25px -5px rgba(0,0,0,0.1),0 8px 10px -6px rgba(0,0,0,0.1); --tw-shadow-colored:0 20px 25px -5px var(--tw-shadow-color),0 8px 10px -6px var(--tw-shadow-color); }

.shadow-xs { --tw-shadow:0 0 15px rgba(0,0,0,0.1); --tw-shadow-colored:0 0 15px var(--tw-shadow-color); }

.shadow-xs, .shadow-xxs { box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.shadow-xxs { --tw-shadow:0 1px 7px 0 rgba(0,0,0,0.03); --tw-shadow-colored:0 1px 7px 0 var(--tw-shadow-color); }

.shadow-indigo-400 { --tw-shadow-color:#818cf8; --tw-shadow:var(--tw-shadow-colored); }

.outline-none { outline: transparent solid 2px; outline-offset: 2px; }

.ring-1 { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.ring-inset { --tw-ring-inset:inset; }

.ring-black\/10 { --tw-ring-color:rgba(0,0,0,0.1); }

.blur-xl { --tw-blur:blur(24px); }

.blur-xl, .filter { filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow); }

.filter-none { filter: none; }

.transition { transition-duration: 0.15s; transition-property: color, background-color, border-color, text-decoration-color, fill, stroke, opacity, box-shadow, transform, filter, backdrop-filter, -webkit-transform, -webkit-filter, -webkit-backdrop-filter; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-\[stroke-dashoffset\] { transition-duration: 0.15s; transition-property: stroke-dashoffset; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-all { transition-duration: 0.15s; transition-property: all; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-colors { transition-duration: 0.15s; transition-property: color, background-color, border-color, text-decoration-color, fill, stroke; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-opacity { transition-duration: 0.15s; transition-property: opacity; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-transform { transition-duration: 0.15s; transition-property: transform, -webkit-transform; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.transition-width { transition-duration: 0.15s; transition-property: width; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.duration-100 { transition-duration: 0.1s; }

.duration-1000 { transition-duration: 1s; }

.duration-150 { transition-duration: 0.15s; }

.duration-200 { transition-duration: 0.2s; }

.duration-300 { transition-duration: 0.3s; }

.duration-500 { transition-duration: 0.5s; }

.ease-in { transition-timing-function: cubic-bezier(0.4, 0, 1, 1); }

.ease-in-out { transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.ease-linear { transition-timing-function: linear; }

.ease-out { transition-timing-function: cubic-bezier(0, 0, 0.2, 1); }

.will-change-\[opacity\,transform\] { will-change: opacity, transform; }

.will-change-transform { will-change: transform; }

body, html { height: 100%; }

.dark body, .dark html { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

#__next, #root { height: 100%; }

.markdown ol { counter-reset: item 0; }

.markdown ul li { display: block; margin: 0px; position: relative; }

.markdown ul li::before { content: "â¢"; font-size: 0.875rem; line-height: 1.25rem; margin-left: -1rem; position: absolute; }

.markdown { max-width: none; }

.markdown h1, .markdown h2 { font-weight: 600; }

.markdown h2 { margin-bottom: 1rem; margin-top: 2rem; }

.markdown h3 { font-weight: 600; }

.markdown h3, .markdown h4 { margin-bottom: 0.5rem; margin-top: 1rem; }

.markdown h4 { font-weight: 400; }

.markdown h5 { font-weight: 600; }

.markdown blockquote { --tw-border-opacity:1; border-color: rgba(142,142,160,var(--tw-border-opacity)); border-left-width: 2px; line-height: 1rem; padding-left: 1rem; }

.markdown ol, .markdown ul { display: flex; flex-direction: column; padding-left: 1rem; }

.markdown ol li, .markdown ol li > p, .markdown ol ol, .markdown ol ul, .markdown ul li, .markdown ul li > p, .markdown ul ol, .markdown ul ul { margin: 0px; }

.markdown table { --tw-border-spacing-x:0px; --tw-border-spacing-y:0px; border-collapse: separate; border-spacing: var(--tw-border-spacing-x) var(--tw-border-spacing-y); width: 100%; }

.markdown th { background-color: rgba(236, 236, 241, 0.2); border-bottom-width: 1px; border-left-width: 1px; border-top-width: 1px; padding: 0.25rem 0.75rem; }

.markdown th:first-child { border-top-left-radius: 0.375rem; }

.markdown th:last-child { border-right-width: 1px; border-top-right-radius: 0.375rem; }

.markdown td { border-bottom-width: 1px; border-left-width: 1px; padding: 0.25rem 0.75rem; }

.markdown td:last-child { border-right-width: 1px; }

.markdown tbody tr:last-child td:first-child { border-bottom-left-radius: 0.375rem; }

.markdown tbody tr:last-child td:last-child { border-bottom-right-radius: 0.375rem; }

.markdown a { text-decoration-line: underline; text-underline-offset: 2px; }

.conversation-item-time::before { content: attr(data-time); }

button.scroll-convo { display: none; }

@-webkit-keyframes blink { 
  100% { visibility: hidden; }
}

@keyframes blink { 
  100% { visibility: hidden; }
}

.animate-flash { animation: 2s steps(60, start) 0s 1 normal none running flash; }

@-webkit-keyframes flash { 
  0% { background-color: rgba(255, 255, 255, 0.4); }
}

@keyframes flash { 
  0% { background-color: rgba(255, 255, 255, 0.4); }
}

.result-streaming > :not(ol):not(ul):not(pre):last-child::after, .result-streaming > ol:last-child li:last-child::after, .result-streaming > pre:last-child code::after, .result-streaming > ul:last-child li:last-child::after { animation: 1s steps(5, start) 0s infinite normal none running blink; content: "â"; margin-left: 0.25rem; vertical-align: baseline; }

@-webkit-keyframes toast-open { 
  0% { opacity: 0; transform: translateY(-100%); }
  100% { transform: translateY(0px); }
}

@keyframes toast-open { 
  0% { opacity: 0; transform: translateY(-100%); }
  100% { transform: translateY(0px); }
}

@-webkit-keyframes toast-close { 
  0% { opacity: 1; }
  100% { opacity: 0; }
}

@keyframes toast-close { 
  0% { opacity: 1; }
  100% { opacity: 0; }
}

button[data-state="closed"] .toggle-item-button-closed, button[data-state="open"] .toggle-item-button-open { display: none; }

.toast-root { align-items: center; display: flex; flex-direction: column; height: 0px; transition: all 0.24s cubic-bezier(0, 0, 0.2, 1) 0s; }

.toast-root[data-state="entered"], .toast-root[data-state="entering"] { animation: 0.24s cubic-bezier(0.175, 0.885, 0.32, 1.175) 0s 1 normal both running toast-open; }

.toast-root[data-state="exiting"] { animation: 0.12s cubic-bezier(0.4, 0, 1, 1) 0s 1 normal both running toast-close; }

.toast-root .alert-root { box-shadow: rgba(67, 90, 111, 0.3) 0px 0px 1px, rgba(67, 90, 111, 0.3) 0px 5px 8px -4px; flex-shrink: 0; pointer-events: all; }

.interact-bounce { transition-duration: 0.15s; transition-property: transform, -webkit-transform; transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1); }

.interact-bounce:hover { --tw-scale-x:1.05; --tw-scale-y:1.05; }

.interact-bounce:active, .interact-bounce:hover { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.interact-bounce:active { --tw-scale-x:0.9; --tw-scale-y:0.9; }

.dark .dark\:prose-invert { --tw-prose-body:var(--tw-prose-invert-body); --tw-prose-headings:var(--tw-prose-invert-headings); --tw-prose-lead:var(--tw-prose-invert-lead); --tw-prose-links:var(--tw-prose-invert-links); --tw-prose-bold:var(--tw-prose-invert-bold); --tw-prose-counters:var(--tw-prose-invert-counters); --tw-prose-bullets:var(--tw-prose-invert-bullets); --tw-prose-hr:var(--tw-prose-invert-hr); --tw-prose-quotes:var(--tw-prose-invert-quotes); --tw-prose-quote-borders:var(--tw-prose-invert-quote-borders); --tw-prose-captions:var(--tw-prose-invert-captions); --tw-prose-code:var(--tw-prose-invert-code); --tw-prose-pre-code:var(--tw-prose-invert-pre-code); --tw-prose-pre-bg:var(--tw-prose-invert-pre-bg); --tw-prose-th-borders:var(--tw-prose-invert-th-borders); --tw-prose-td-borders:var(--tw-prose-invert-td-borders); }

.placeholder\:text-gray-300::-webkit-input-placeholder { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.placeholder\:text-gray-300::placeholder { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.after\:content-\[\'\"\'\]::after, .before\:content-\[\'\"\'\]::before { --tw-content:"\""; content: var(--tw-content); }

.last\:mb-2:last-child { margin-bottom: 0.5rem; }

.last\:border-0:last-child { border-width: 0px; }

.last-of-type\:border-b-0:last-of-type { border-bottom-width: 0px; }

.checked\:border-blue-600:checked { --tw-border-opacity:1; border-color: rgba(37,99,235,var(--tw-border-opacity)); }

.checked\:bg-blue-600:checked { --tw-bg-opacity:1; background-color: rgba(37,99,235,var(--tw-bg-opacity)); }

.empty\:hidden:empty { display: none; }

.focus-within\:z-10[focus-within] { z-index: 10; }

.focus-within\:z-10:focus-within { z-index: 10; }

.focus-within\:border-indigo-600[focus-within] { --tw-border-opacity:1; border-color: rgba(79,70,229,var(--tw-border-opacity)); }

.focus-within\:border-indigo-600:focus-within { --tw-border-opacity:1; border-color: rgba(79,70,229,var(--tw-border-opacity)); }

.focus-within\:ring-1[focus-within] { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus-within\:ring-1:focus-within { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus-within\:ring-indigo-600[focus-within] { --tw-ring-opacity:1; --tw-ring-color:rgba(79,70,229,var(--tw-ring-opacity)); }

.focus-within\:ring-indigo-600:focus-within { --tw-ring-opacity:1; --tw-ring-color:rgba(79,70,229,var(--tw-ring-opacity)); }

.hover\:border-black\/10:hover { border-color: rgba(0, 0, 0, 0.1); }

.hover\:border-gray-300:hover { --tw-border-opacity:1; border-color: rgba(197,197,210,var(--tw-border-opacity)); }

.hover\:border-gray-700:hover { --tw-border-opacity:1; border-color: rgba(64,65,79,var(--tw-border-opacity)); }

.hover\:\!bg-gray-50:hover { --tw-bg-opacity:1 !important; background-color: rgba(247,247,248,var(--tw-bg-opacity)) !important; }

.hover\:bg-\[\#2A2B32\]:hover { --tw-bg-opacity:1; background-color: rgba(42,43,50,var(--tw-bg-opacity)); }

.hover\:bg-black:hover { --tw-bg-opacity:1; background-color: rgba(0,0,0,var(--tw-bg-opacity)); }

.hover\:bg-black\/10:hover { background-color: rgba(0, 0, 0, 0.1); }

.hover\:bg-gray-100:hover { --tw-bg-opacity:1; background-color: rgba(236,236,241,var(--tw-bg-opacity)); }

.hover\:bg-gray-200:hover { --tw-bg-opacity:1; background-color: rgba(217,217,227,var(--tw-bg-opacity)); }

.hover\:bg-gray-300:hover { --tw-bg-opacity:1; background-color: rgba(197,197,210,var(--tw-bg-opacity)); }

.hover\:bg-gray-50:hover { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.hover\:bg-gray-50\/50:hover { background-color: rgba(247, 247, 248, 0.5); }

.hover\:bg-gray-500\/10:hover { background-color: rgba(141, 141, 160, 0.1); }

.hover\:bg-gray-700:hover { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.hover\:bg-gray-800:hover { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.hover\:bg-green-100:hover { --tw-bg-opacity:1; background-color: rgba(210,244,211,var(--tw-bg-opacity)); }

.hover\:bg-white\/40:hover { background-color: rgba(255, 255, 255, 0.4); }

.hover\:pr-14:hover { padding-right: 3.5rem; }

.hover\:pr-4:hover { padding-right: 1rem; }

.hover\:text-black\/50:hover { color: rgba(0, 0, 0, 0.5); }

.hover\:text-black\/70:hover { color: rgba(0, 0, 0, 0.7); }

.hover\:text-blue-600:hover { --tw-text-opacity:1; color: rgba(37,99,235,var(--tw-text-opacity)); }

.hover\:text-gray-500:hover { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.hover\:text-gray-600:hover { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

.hover\:text-gray-700:hover { --tw-text-opacity:1; color: rgba(64,65,79,var(--tw-text-opacity)); }

.hover\:text-gray-800:hover { --tw-text-opacity:1; color: rgba(52,53,65,var(--tw-text-opacity)); }

.hover\:text-gray-900:hover { --tw-text-opacity:1; color: rgba(32,33,35,var(--tw-text-opacity)); }

.hover\:text-white:hover { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.hover\:text-white\/40:hover { color: rgba(255, 255, 255, 0.4); }

.hover\:\!opacity-100:hover { opacity: 1 !important; }

.hover\:opacity-100:hover { opacity: 1; }

.hover\:opacity-70:hover { opacity: 0.7; }

.hover\:opacity-75:hover { opacity: 0.75; }

.hover\:opacity-80:hover { opacity: 0.8; }

.focus\:z-10:focus { z-index: 10; }

.focus\:border-brand-green:focus, .focus\:border-green-500:focus { --tw-border-opacity:1; border-color: rgba(25,195,125,var(--tw-border-opacity)); }

.focus\:border-green-600:focus { --tw-border-opacity:1; border-color: rgba(16,163,127,var(--tw-border-opacity)); }

.focus\:border-indigo-500:focus { --tw-border-opacity:1; border-color: rgba(99,102,241,var(--tw-border-opacity)); }

.focus\:border-red-500:focus { --tw-border-opacity:1; border-color: rgba(239,68,68,var(--tw-border-opacity)); }

.focus\:bg-gray-50:focus { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.focus\:outline-none:focus { outline: transparent solid 2px; outline-offset: 2px; }

.focus\:ring-0:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(var(--tw-ring-offset-width)) var(--tw-ring-color); }

.focus\:ring-0:focus, .focus\:ring-1:focus { box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus\:ring-1:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(1px + var(--tw-ring-offset-width)) var(--tw-ring-color); }

.focus\:ring-2:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus\:ring-inset:focus { --tw-ring-inset:inset; }

.focus\:ring-gray-200:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(217,217,227,var(--tw-ring-opacity)); }

.focus\:ring-gray-500:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(142,142,160,var(--tw-ring-opacity)); }

.focus\:ring-green-500:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(25,195,125,var(--tw-ring-opacity)); }

.focus\:ring-green-600:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(16,163,127,var(--tw-ring-opacity)); }

.focus\:ring-indigo-500:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(99,102,241,var(--tw-ring-opacity)); }

.focus\:ring-white:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(255,255,255,var(--tw-ring-opacity)); }

.focus\:ring-offset-2:focus { --tw-ring-offset-width:2px; }

.focus-visible\:border-blue-500.focus-visible { --tw-border-opacity:1; border-color: rgba(69,89,164,var(--tw-border-opacity)); }

.focus-visible\:border-blue-500:focus-visible { --tw-border-opacity:1; border-color: rgba(69,89,164,var(--tw-border-opacity)); }

.focus-visible\:ring-0.focus-visible { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.focus-visible\:ring-0:focus-visible { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.enabled\:bg-brand-purple:enabled { --tw-bg-opacity:1; background-color: rgba(171,104,255,var(--tw-bg-opacity)); }

.enabled\:hover\:text-gray-700:hover:enabled { --tw-text-opacity:1; color: rgba(64,65,79,var(--tw-text-opacity)); }

.disabled\:bottom-0:disabled { bottom: 0px; }

.disabled\:bottom-0\.5:disabled { bottom: 0.125rem; }

.disabled\:cursor-auto:disabled { cursor: auto; }

.disabled\:text-gray-300:disabled { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.disabled\:text-gray-400:disabled { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.disabled\:opacity-20:disabled { opacity: 0.2; }

.disabled\:opacity-40:disabled { opacity: 0.4; }

.disabled\:hover\:bg-gray-900:hover:disabled { --tw-bg-opacity:1; background-color: rgba(32,33,35,var(--tw-bg-opacity)); }

.group:hover .group-hover\:visible { visibility: visible; }

.group:hover .group-hover\:block { display: block; }

.group:hover .group-hover\:hidden { display: none; }

.group\/options:hover .group-hover\/options\:bg-transparent { background-color: transparent; }

.group\/toggle:hover .group-hover\/toggle\:bg-red-500 { --tw-bg-opacity:1; background-color: rgba(239,68,68,var(--tw-bg-opacity)); }

.group:hover .group-hover\:bg-black { --tw-bg-opacity:1; background-color: rgba(0,0,0,var(--tw-bg-opacity)); }

.group:hover .group-hover\:from-\[\#2A2B32\] { --tw-gradient-from:#2a2b32 var(--tw-gradient-from-position); --tw-gradient-to:rgba(42,43,50,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.group\/button:hover .group-hover\/button\:text-brand-green { --tw-text-opacity:1; color: rgba(25,195,125,var(--tw-text-opacity)); }

.group\/button:hover .group-hover\/button\:text-brand-purple { --tw-text-opacity:1; color: rgba(171,104,255,var(--tw-text-opacity)); }

.group\/button:hover .group-hover\/button\:text-orange-500 { --tw-text-opacity:1; color: rgba(224,108,43,var(--tw-text-opacity)); }

.group\/button:hover .group-hover\/button\:text-red-500 { --tw-text-opacity:1; color: rgba(239,68,68,var(--tw-text-opacity)); }

.group\/option:hover .group-hover\/option\:\!text-brand-green { --tw-text-opacity:1 !important; color: rgba(25,195,125,var(--tw-text-opacity)) !important; }

.group\/option:hover .group-hover\/option\:\!text-brand-purple { --tw-text-opacity:1 !important; color: rgba(171,104,255,var(--tw-text-opacity)) !important; }

.group\/option:hover .group-hover\/option\:text-gray-100 { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.group\/option:hover .group-hover\/option\:text-gray-800 { --tw-text-opacity:1; color: rgba(52,53,65,var(--tw-text-opacity)); }

.group:hover .group-hover\:text-gray-500, .group\/options:hover .group-hover\/options\:text-gray-500 { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.group\/options:hover .group-hover\/options\:opacity-0 { opacity: 0; }

.group:hover .group-hover\:opacity-100 { opacity: 1; }

.group:hover .group-hover\:opacity-50 { opacity: 0.5; }

.group-ui-open\:bg-gray-800.group[data-headlessui-state~="open"] { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.group:where([data-headlessui-state~="open"]) .group-ui-open\:bg-gray-800 { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.radix-disabled\:pointer-events-none[data-disabled] { pointer-events: none; }

.radix-disabled\:cursor-auto[data-disabled] { cursor: auto; }

.radix-disabled\:bg-transparent[data-disabled] { background-color: transparent; }

.radix-disabled\:text-gray-300[data-disabled] { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.radix-disabled\:text-gray-500[data-disabled] { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.radix-highlighted\:bg-gray-50[data-highlighted] { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.radix-highlighted\:outline-none[data-highlighted] { outline: transparent solid 2px; outline-offset: 2px; }

.radix-state-active\:bg-gray-800[data-state="active"] { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.radix-state-active\:text-gray-600[data-state="active"] { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

.radix-state-active\:text-white[data-state="active"] { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.group[data-state="active"] .group-radix-state-active\:fill-white { fill: rgb(255, 255, 255); }

.radix-state-checked\:translate-x-\[19px\][data-state="checked"] { --tw-translate-x:19px; transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }

.radix-state-checked\:bg-green-600[data-state="checked"] { --tw-bg-opacity:1; background-color: rgba(16,163,127,var(--tw-bg-opacity)); }

.radix-state-open\:text-gray-600[data-state="open"] { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

@-webkit-keyframes slideDownAndFade { 
  0% { opacity: 0; transform: translateY(-2px); }
  100% { opacity: 1; transform: translateY(0px); }
}

.radix-side-bottom\:animate-slideDownAndFade[data-side="bottom"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideDownAndFade; }

@-webkit-keyframes slideUpAndFade { 
  0% { opacity: 0; transform: translateY(2px); }
  100% { opacity: 1; transform: translateY(0px); }
}

.radix-side-bottom\:animate-slideUpAndFade[data-side="bottom"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideUpAndFade; }

.radix-side-left\:animate-slideLeftAndFade[data-side="left"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideLeftAndFade; }

@-webkit-keyframes slideRightAndFade { 
  0% { opacity: 0; transform: translateX(-2px); }
  100% { opacity: 1; transform: translateX(0px); }
}

.radix-side-left\:animate-slideRightAndFade[data-side="left"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideRightAndFade; }

@keyframes slideLeftAndFade { 
  0% { opacity: 0; transform: translateX(2px); }
  100% { opacity: 1; transform: translateX(0px); }
}

.radix-side-right\:animate-slideLeftAndFade[data-side="right"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideLeftAndFade; }

@keyframes slideRightAndFade { 
  0% { opacity: 0; transform: translateX(-2px); }
  100% { opacity: 1; transform: translateX(0px); }
}

.radix-side-right\:animate-slideRightAndFade[data-side="right"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideRightAndFade; }

@keyframes slideDownAndFade { 
  0% { opacity: 0; transform: translateY(-2px); }
  100% { opacity: 1; transform: translateY(0px); }
}

.radix-side-top\:animate-slideDownAndFade[data-side="top"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideDownAndFade; }

@keyframes slideUpAndFade { 
  0% { opacity: 0; transform: translateY(2px); }
  100% { opacity: 1; transform: translateY(0px); }
}

.radix-side-top\:animate-slideUpAndFade[data-side="top"] { animation: 0.4s cubic-bezier(0.16, 1, 0.3, 1) 0s 1 normal none running slideUpAndFade; }

.dark .dark\:border-\[\#4E4F60\] { --tw-border-opacity:1; border-color: rgba(78,79,96,var(--tw-border-opacity)); }

.dark .dark\:border-black\/20 { border-color: rgba(0, 0, 0, 0.2); }

.dark .dark\:border-gray-300 { --tw-border-opacity:1; border-color: rgba(197,197,210,var(--tw-border-opacity)); }

.dark .dark\:border-gray-600 { --tw-border-opacity:1; border-color: rgba(86,88,105,var(--tw-border-opacity)); }

.dark .dark\:border-gray-700 { --tw-border-opacity:1; border-color: rgba(64,65,79,var(--tw-border-opacity)); }

.dark .dark\:border-gray-800 { --tw-border-opacity:1; border-color: rgba(52,53,65,var(--tw-border-opacity)); }

.dark .dark\:border-gray-900\/50 { border-color: rgba(32, 33, 35, 0.5); }

.dark .dark\:border-white\/10 { border-color: rgba(255, 255, 255, 0.1); }

.dark .dark\:border-white\/20 { border-color: rgba(255, 255, 255, 0.2); }

.dark .dark\:border-white\/30 { border-color: rgba(255, 255, 255, 0.298); }

.dark .dark\:bg-\[\#272832\] { --tw-bg-opacity:1; background-color: rgba(39,40,50,var(--tw-bg-opacity)); }

.dark .dark\:bg-\[\#444654\] { --tw-bg-opacity:1; background-color: rgba(68,70,84,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-50 { --tw-bg-opacity:1; background-color: rgba(247,247,248,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-500 { --tw-bg-opacity:1; background-color: rgba(142,142,160,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-700 { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-800 { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.dark .dark\:bg-gray-800\/30 { background-color: rgba(52, 53, 65, 0.3); }

.dark .dark\:bg-gray-800\/90 { background-color: rgba(52, 53, 65, 0.9); }

.dark .dark\:bg-gray-900 { --tw-bg-opacity:1; background-color: rgba(32,33,35,var(--tw-bg-opacity)); }

.dark .dark\:bg-red-200 { --tw-bg-opacity:1; background-color: rgba(254,202,202,var(--tw-bg-opacity)); }

.dark .dark\:bg-transparent { background-color: transparent; }

.dark .dark\:bg-white { --tw-bg-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); }

.dark .dark\:bg-white\/10 { background-color: rgba(255, 255, 255, 0.1); }

.dark .dark\:bg-white\/5 { background-color: rgba(255, 255, 255, 0.05); }

.dark .dark\:from-gray-700 { --tw-gradient-from:#40414f var(--tw-gradient-from-position); --tw-gradient-to:rgba(64,65,79,0) var(--tw-gradient-to-position); --tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to); }

.dark .dark\:fill-gray-500 { fill: rgb(142, 142, 160); }

.dark .dark\:text-blue-400 { --tw-text-opacity:1; color: rgba(58,136,255,var(--tw-text-opacity)); }

.dark .dark\:text-blue-600 { --tw-text-opacity:1; color: rgba(37,99,235,var(--tw-text-opacity)); }

.dark .dark\:text-gray-100 { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.dark .dark\:text-gray-200 { --tw-text-opacity:1; color: rgba(217,217,227,var(--tw-text-opacity)); }

.dark .dark\:text-gray-300 { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.dark .dark\:text-gray-400 { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .dark\:text-gray-500 { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.dark .dark\:text-gray-600 { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

.dark .dark\:text-gray-700 { --tw-text-opacity:1; color: rgba(64,65,79,var(--tw-text-opacity)); }

.dark .dark\:text-gray-900 { --tw-text-opacity:1; color: rgba(32,33,35,var(--tw-text-opacity)); }

.dark .dark\:text-red-500 { --tw-text-opacity:1; color: rgba(239,68,68,var(--tw-text-opacity)); }

.dark .dark\:text-red-800 { --tw-text-opacity:1; color: rgba(153,27,27,var(--tw-text-opacity)); }

.dark .dark\:text-white { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.dark .dark\:text-white\/70 { color: rgba(255, 255, 255, 0.698); }

.dark .dark\:opacity-100 { opacity: 1; }

.dark .dark\:shadow-xs { --tw-shadow:0 0 15px rgba(0,0,0,0.1); --tw-shadow-colored:0 0 15px var(--tw-shadow-color); box-shadow: var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow); }

.dark .dark\:ring-white\/20 { --tw-ring-color:hsla(0,0%,100%,0.2); }

.dark .dark\:last\:border-0:last-child { border-width: 0px; }

.dark .dark\:hover\:border-gray-600:hover { --tw-border-opacity:1; border-color: rgba(86,88,105,var(--tw-border-opacity)); }

.dark .dark\:hover\:border-white\/10:hover { border-color: rgba(255, 255, 255, 0.1); }

.dark .dark\:hover\:\!bg-gray-700:hover { --tw-bg-opacity:1 !important; background-color: rgba(64,65,79,var(--tw-bg-opacity)) !important; }

.dark .dark\:hover\:bg-\[\#2E2F33\]:hover { --tw-bg-opacity:1; background-color: rgba(46,47,51,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-\[\#494A54\]:hover { --tw-bg-opacity:1; background-color: rgba(73,74,84,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-gray-200:hover { --tw-bg-opacity:1; background-color: rgba(217,217,227,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-gray-500\/10:hover { background-color: rgba(141, 141, 160, 0.1); }

.dark .dark\:hover\:bg-gray-600:hover { --tw-bg-opacity:1; background-color: rgba(86,88,105,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-gray-700:hover { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-gray-700\/50:hover { background-color: rgba(64, 65, 79, 0.5); }

.dark .dark\:hover\:bg-gray-800:hover { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.dark .dark\:hover\:bg-gray-900:hover { --tw-bg-opacity:1; background-color: rgba(32,33,35,var(--tw-bg-opacity)); }

:is(.dark .hover\:dark\:bg-white\/10):hover { background-color: rgba(255, 255, 255, 0.1); }

.dark .dark\:hover\:text-blue-600:hover { --tw-text-opacity:1; color: rgba(37,99,235,var(--tw-text-opacity)); }

.dark .dark\:hover\:text-gray-200:hover { --tw-text-opacity:1; color: rgba(217,217,227,var(--tw-text-opacity)); }

.dark .dark\:hover\:text-gray-400:hover { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .dark\:hover\:text-white:hover { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.dark .dark\:hover\:text-white\/50:hover { color: rgba(255, 255, 255, 0.5); }

:is(.dark .hover\:dark\:text-gray-100):hover { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.dark .dark\:focus\:border-white:focus { --tw-border-opacity:1; border-color: rgba(255,255,255,var(--tw-border-opacity)); }

.dark .dark\:focus\:bg-gray-800:focus { --tw-bg-opacity:1; background-color: rgba(52,53,65,var(--tw-bg-opacity)); }

.dark .dark\:focus\:ring-gray-600:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(86,88,105,var(--tw-ring-opacity)); }

.dark .dark\:focus\:ring-white:focus { --tw-ring-opacity:1; --tw-ring-color:rgba(255,255,255,var(--tw-ring-opacity)); }

.dark .dark\:focus-visible\:border-blue-500.focus-visible { --tw-border-opacity:1; border-color: rgba(69,89,164,var(--tw-border-opacity)); }

.dark .dark\:focus-visible\:border-blue-500:focus-visible { --tw-border-opacity:1; border-color: rgba(69,89,164,var(--tw-border-opacity)); }

:is(.dark .enabled\:dark\:hover\:text-gray-400:hover):enabled { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .dark\:disabled\:text-gray-400:disabled { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .dark\:disabled\:hover\:bg-transparent:hover:disabled { background-color: transparent; }

.dark .dark\:disabled\:hover\:bg-white:hover:disabled { --tw-bg-opacity:1; background-color: rgba(255,255,255,var(--tw-bg-opacity)); }

:is(.dark .disabled\:dark\:hover\:text-gray-400:hover):disabled { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

.dark .group\/option:hover .dark\:group-hover\/option\:text-gray-100 { --tw-text-opacity:1; color: rgba(236,236,241,var(--tw-text-opacity)); }

.dark .dark\:radix-disabled\:bg-transparent[data-disabled] { background-color: transparent; }

.dark .dark\:radix-disabled\:text-gray-500[data-disabled] { --tw-text-opacity:1; color: rgba(142,142,160,var(--tw-text-opacity)); }

.dark .dark\:radix-disabled\:text-gray-600[data-disabled] { --tw-text-opacity:1; color: rgba(86,88,105,var(--tw-text-opacity)); }

.dark .dark\:radix-highlighted\:bg-\[\#2E2F33\][data-highlighted] { --tw-bg-opacity:1; background-color: rgba(46,47,51,var(--tw-bg-opacity)); }

.dark .dark\:radix-highlighted\:bg-gray-700[data-highlighted] { --tw-bg-opacity:1; background-color: rgba(64,65,79,var(--tw-bg-opacity)); }

.dark .dark\:radix-highlighted\:hover\:bg-\[\#2E2F33\][data-highlighted]:hover { --tw-bg-opacity:1; background-color: rgba(46,47,51,var(--tw-bg-opacity)); }

.dark .dark\:radix-state-active\:text-white[data-state="active"] { --tw-text-opacity:1; color: rgba(255,255,255,var(--tw-text-opacity)); }

.dark .dark\:radix-state-open\:text-gray-400[data-state="open"] { --tw-text-opacity:1; color: rgba(172,172,190,var(--tw-text-opacity)); }

@media not all and (min-width: 1024px) {
  .max-lg\:justify-center { justify-content: center; }
}

@media (max-width: 370px) {
  .max-\[370px\]\:hidden { display: none; }
}

@media (min-width: 640px) {
  .sm\:order-1 { order: 1; }
  .sm\:order-2 { order: 2; }
  .sm\:mx-1 { margin-left: 0.25rem; margin-right: 0.25rem; }
  .sm\:mb-16 { margin-bottom: 4rem; }
  .sm\:mb-2 { margin-bottom: 0.5rem; }
  .sm\:mt-0 { margin-top: 0px; }
  .sm\:mt-16 { margin-top: 4rem; }
  .sm\:mt-4 { margin-top: 1rem; }
  .sm\:mt-6 { margin-top: 1.5rem; }
  .sm\:mt-\[20vh\] { margin-top: 20vh; }
  .sm\:block { display: block; }
  .sm\:h-10 { height: 2.5rem; }
  .sm\:w-10 { width: 2.5rem; }
  .sm\:w-\[312px\] { width: 312px; }
  .sm\:w-\[calc\(\(100\%-12px\)\/2\)\] { width: calc(50% - 6px); }
  .sm\:w-auto { width: auto; }
  .sm\:min-w-\[148px\] { min-width: 148px; }
  .sm\:min-w-\[312px\] { min-width: 312px; }
  .sm\:min-w-\[420px\] { min-width: 420px; }
  .sm\:max-w-md { max-width: 28rem; }
  .sm\:grid-cols-2 { grid-template-columns: repeat(2, minmax(0px, 1fr)); }
  .sm\:grid-rows-2 { grid-template-rows: repeat(2, minmax(0px, 1fr)); }
  .sm\:flex-row { flex-direction: row; }
  .sm\:flex-row-reverse { flex-direction: row-reverse; }
  .sm\:items-center { align-items: center; }
  .sm\:rounded-2xl { border-radius: 1rem; }
  .sm\:border-r { border-right-width: 1px; }
  .sm\:border-t-0 { border-top-width: 0px; }
  .sm\:p-4 { padding: 1rem; }
  .sm\:p-6 { padding: 1.5rem; }
  .sm\:px-0 { padding-left: 0px; padding-right: 0px; }
  .sm\:px-14 { padding-left: 3.5rem; padding-right: 3.5rem; }
  .sm\:px-4 { padding-left: 1rem; padding-right: 1rem; }
  .sm\:px-6 { padding-left: 1.5rem; padding-right: 1.5rem; }
  .sm\:pb-1 { padding-bottom: 0.25rem; }
  .sm\:pb-10 { padding-bottom: 2.5rem; }
  .sm\:pb-2 { padding-bottom: 0.5rem; }
  .sm\:pl-3 { padding-left: 0.75rem; }
  .sm\:pt-4 { padding-top: 1rem; }
  .sm\:pt-8 { padding-top: 2rem; }
  .sm\:text-left { text-align: left; }
  .sm\:text-4xl { font-size: 2.25rem; line-height: 2.5rem; }
  .sm\:text-base { font-size: 1rem; line-height: 1.5rem; }
  .sm\:text-sm { font-size: 0.875rem; line-height: 1.25rem; }
  .sm\:duration-300 { transition-duration: 0.3s; }
  .sm\:duration-500 { transition-duration: 0.5s; }
}

@media (min-width: 768px) {
  .md\:invisible { visibility: hidden; }
  .md\:static { position: static; }
  .md\:-left-2 { left: -0.5rem; }
  .md\:bottom-3 { bottom: 0.75rem; }
  .md\:bottom-3\.5 { bottom: 0.875rem; }
  .md\:bottom-\[120px\] { bottom: 120px; }
  .md\:left-4 { left: 1rem; }
  .md\:right-3 { right: 0.75rem; }
  .md\:m-0 { margin: 0px; }
  .md\:m-auto { margin: auto; }
  .md\:mx-0 { margin-left: 0px; margin-right: 0px; }
  .md\:mx-4 { margin-left: 1rem; margin-right: 1rem; }
  .md\:mb-0 { margin-bottom: 0px; }
  .md\:mb-2 { margin-bottom: 0.5rem; }
  .md\:mb-auto { margin-bottom: auto; }
  .md\:inline-block { display: inline-block; }
  .md\:flex { display: flex; }
  .md\:hidden { display: none; }
  .md\:h-48 { height: 12rem; }
  .md\:h-full { height: 100%; }
  .md\:min-h-\[300px\] { min-height: 300px; }
  .md\:w-1\/2 { width: 50%; }
  .md\:w-\[100\%\] { width: 100%; }
  .md\:w-\[250px\] { width: 250px; }
  .md\:w-\[672px\] { width: 672px; }
  .md\:w-auto { width: auto; }
  .md\:w-full { width: 100%; }
  .md\:min-w-\[672px\] { min-width: 672px; }
  .md\:max-w-2xl { max-width: 42rem; }
  .md\:max-w-3xl { max-width: 48rem; }
  .md\:max-w-5xl { max-width: 64rem; }
  .md\:max-w-\[672px\] { max-width: 672px; }
  .md\:max-w-\[680px\] { max-width: 680px; }
  .md\:max-w-none { max-width: none; }
  .md\:grid-rows-\[minmax\(20px\,_1fr\)_auto_minmax\(20px\,_1fr\)\] { grid-template-rows: minmax(20px, 1fr) auto minmax(20px, 1fr); }
  .md\:flex-row { flex-direction: row; }
  .md\:flex-col { flex-direction: column; }
  .md\:justify-between { justify-content: space-between; }
  .md\:gap-2 { gap: 0.5rem; }
  .md\:gap-3 { gap: 0.75rem; }
  .md\:gap-6 { gap: 1.5rem; }
  .md\:overflow-visible { overflow: visible; }
  .md\:whitespace-normal { white-space: normal; }
  .md\:border { border-width: 1px; }
  .md\:border-l { border-left-width: 1px; }
  .md\:border-t-0 { border-top-width: 0px; }
  .md\:border-gray-100 { --tw-border-opacity:1; border-color: rgba(236,236,241,var(--tw-border-opacity)); }
  .md\:border-transparent { border-color: transparent; }
  .md\:\!bg-transparent { background-color: transparent !important; }
  .md\:bg-vert-light-gradient { background-image: linear-gradient(rgba(255, 255, 255, 0) 13.94%, rgb(255, 255, 255) 54.73%); }
  .md\:p-2 { padding: 0.5rem; }
  .md\:px-0 { padding-left: 0px; padding-right: 0px; }
  .md\:px-4 { padding-left: 1rem; padding-right: 1rem; }
  .md\:py-2 { padding-bottom: 0.5rem; padding-top: 0.5rem; }
  .md\:py-2\.5 { padding-bottom: 0.625rem; padding-top: 0.625rem; }
  .md\:py-4 { padding-bottom: 1rem; padding-top: 1rem; }
  .md\:py-6 { padding-bottom: 1.5rem; padding-top: 1.5rem; }
  .md\:\!pt-0 { padding-top: 0px !important; }
  .md\:pb-5 { padding-bottom: 1.25rem; }
  .md\:pb-6 { padding-bottom: 1.5rem; }
  .md\:pl-0 { padding-left: 0px; }
  .md\:pl-4 { padding-left: 1rem; }
  .md\:pl-\[30px\] { padding-left: 30px; }
  .md\:pr-1 { padding-right: 0.25rem; }
  .md\:pr-1\.5 { padding-right: 0.375rem; }
  .md\:pr-12 { padding-right: 3rem; }
  .md\:pt-3 { padding-top: 0.75rem; }
  .md\:text-justify { text-align: justify; }
  .md\:text-sm { font-size: 0.875rem; line-height: 1.25rem; }
  .md\:opacity-0 { opacity: 0; }
  .md\:last\:mb-6:last-child { margin-bottom: 1.5rem; }
  .md\:disabled\:bottom-0:disabled { bottom: 0px; }
  .group:hover .md\:group-hover\:visible { visibility: visible; }
  .dark .md\:dark\:border-gray-700 { --tw-border-opacity:1; border-color: rgba(64,65,79,var(--tw-border-opacity)); }
  .dark .md\:dark\:border-transparent { border-color: transparent; }
  .dark .dark\:md\:bg-vert-dark-gradient { background-image: linear-gradient(rgba(53, 55, 64, 0), rgb(53, 55, 64) 58.85%); }
}

@media (min-width: 1024px) {
  .lg\:absolute { position: absolute; }
  .lg\:relative { position: relative; }
  .lg\:-left-3 { left: -0.75rem; }
  .lg\:-right-3 { right: -0.75rem; }
  .lg\:left-auto { left: auto; }
  .lg\:right-0 { right: 0px; }
  .lg\:top-0 { top: 0px; }
  .lg\:top-1\/2 { top: 50%; }
  .lg\:mx-auto { margin-left: auto; margin-right: auto; }
  .lg\:mb-0 { margin-bottom: 0px; }
  .lg\:mt-0 { margin-top: 0px; }
  .lg\:block { display: block; }
  .lg\:hidden { display: none; }
  .lg\:w-1\/3 { width: 33.3333%; }
  .lg\:w-3\/5 { width: 60%; }
  .lg\:w-\[300px\] { width: 300px; }
  .lg\:w-\[896px\] { width: 896px; }
  .lg\:w-\[calc\(\(100\%-24px\)\/3\)\] { width: calc(33.3333% - 8px); }
  .lg\:w-\[calc\(100\%-115px\)\] { width: calc(100% - 115px); }
  .lg\:w-auto { width: auto; }
  .lg\:min-w-\[896px\] { min-width: 896px; }
  .lg\:max-w-2xl { max-width: 42rem; }
  .lg\:max-w-3xl { max-width: 48rem; }
  .lg\:max-w-\[38rem\] { max-width: 38rem; }
  .lg\:max-w-\[896px\] { max-width: 896px; }
  .lg\:max-w-none { max-width: none; }
  .lg\:max-w-sm { max-width: 24rem; }
  .lg\:max-w-xl { max-width: 36rem; }
  .lg\:-translate-x-full { --tw-translate-x:-100%; }
  .lg\:-translate-x-full, .lg\:-translate-y-1\/2 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }
  .lg\:-translate-y-1\/2 { --tw-translate-y:-50%; }
  .lg\:translate-x-full { --tw-translate-x:100%; }
  .lg\:translate-x-full, .lg\:translate-y-0 { transform: translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)); }
  .lg\:translate-y-0 { --tw-translate-y:0px; }
  .lg\:grid-cols-3 { grid-template-columns: repeat(3, minmax(0px, 1fr)); }
  .lg\:gap-1 { gap: 0.25rem; }
  .lg\:self-center { align-self: center; }
  .lg\:rounded-lg { border-radius: 0.5rem; }
  .lg\:rounded-none { border-radius: 0px; }
  .lg\:border { border-width: 1px; }
  .lg\:border-0 { border-width: 0px; }
  .lg\:p-0 { padding: 0px; }
  .lg\:p-6 { padding: 1.5rem; }
  .lg\:px-0 { padding-left: 0px; padding-right: 0px; }
  .lg\:px-14 { padding-left: 3.5rem; padding-right: 3.5rem; }
  .lg\:px-8 { padding-left: 2rem; padding-right: 2rem; }
  .lg\:pl-2 { padding-left: 0.5rem; }
  .lg\:pt-32 { padding-top: 8rem; }
  .lg\:text-left { text-align: left; }
}

@media (min-width: 1280px) {
  .xl\:w-1\/4 { width: 25%; }
  .xl\:w-\[1024px\] { width: 1024px; }
  .xl\:w-\[350px\] { width: 350px; }
  .xl\:min-w-\[1024px\] { min-width: 1024px; }
  .xl\:max-w-3xl { max-width: 48rem; }
  .xl\:max-w-6xl { max-width: 72rem; }
  .xl\:grid-cols-4 { grid-template-columns: repeat(4, minmax(0px, 1fr)); }
}

@media (min-width: 1536px) {
  .\32 xl\:w-\[400px\] { width: 400px; }
}

tr:last-child .\[tr\:last-child_\&\]\:border-b-0 { border-bottom-width: 0px; }

tr[data-disabled="true"] .\[tr\[data-disabled\=true\]_\&\]\:opacity-50 { opacity: 0.5; }

@font-face { font-family: KaTeX_AMS; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_AMS-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Caligraphic; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Caligraphic-Bold.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Caligraphic; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Caligraphic-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Fraktur; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Fraktur-Bold.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Fraktur; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Fraktur-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Main; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Main-Bold.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Main; font-style: italic; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Main-BoldItalic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Main; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Main-Italic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Main; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Main-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Math; font-style: italic; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Math-BoldItalic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Math; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Math-Italic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_SansSerif; font-style: normal; font-weight: 700; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_SansSerif-Bold.woff2") format("woff2"); }

@font-face { font-family: KaTeX_SansSerif; font-style: italic; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_SansSerif-Italic.woff2") format("woff2"); }

@font-face { font-family: KaTeX_SansSerif; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_SansSerif-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Script; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Script-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Size1; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Size1-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Size2; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Size2-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Size3; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Size3-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Size4; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Size4-Regular.woff2") format("woff2"); }

@font-face { font-family: KaTeX_Typewriter; font-style: normal; font-weight: 400; src: url("https://cdn.openai.com/common/fonts/katex/KaTeX_Typewriter-Regular.woff2") format("woff2"); }

.katex { font: 1.21em / 1.2 KaTeX_Main, "Times New Roman", serif; text-indent: 0px; text-rendering: auto; }

.katex * { border-color: currentcolor; forced-color-adjust: none !important; }

.katex .katex-version::after { content: "0.16.0"; }

.katex .katex-mathml { clip: rect(1px, 1px, 1px, 1px); border: 0px; height: 1px; overflow: hidden; padding: 0px; position: absolute; width: 1px; }

.katex .katex-html > .newline { display: block; }

.katex .base { position: relative; white-space: nowrap; width: min-content; }

.katex .base, .katex .strut { display: inline-block; }

.katex .textbf { font-weight: 700; }

.katex .textit { font-style: italic; }

.katex .textrm { font-family: KaTeX_Main; }

.katex .textsf { font-family: KaTeX_SansSerif; }

.katex .texttt { font-family: KaTeX_Typewriter; }

.katex .mathnormal { font-family: KaTeX_Math; font-style: italic; }

.katex .mathit { font-family: KaTeX_Main; font-style: italic; }

.katex .mathrm { font-style: normal; }

.katex .mathbf { font-family: KaTeX_Main; font-weight: 700; }

.katex .boldsymbol { font-family: KaTeX_Math; font-style: italic; font-weight: 700; }

.katex .amsrm, .katex .mathbb, .katex .textbb { font-family: KaTeX_AMS; }

.katex .mathcal { font-family: KaTeX_Caligraphic; }

.katex .mathfrak, .katex .textfrak { font-family: KaTeX_Fraktur; }

.katex .mathtt { font-family: KaTeX_Typewriter; }

.katex .mathscr, .katex .textscr { font-family: KaTeX_Script; }

.katex .mathsf, .katex .textsf { font-family: KaTeX_SansSerif; }

.katex .mathboldsf, .katex .textboldsf { font-family: KaTeX_SansSerif; font-weight: 700; }

.katex .mathitsf, .katex .textitsf { font-family: KaTeX_SansSerif; font-style: italic; }

.katex .mainrm { font-family: KaTeX_Main; font-style: normal; }

.katex .vlist-t { border-collapse: collapse; display: inline-table; table-layout: fixed; }

.katex .vlist-r { display: table-row; }

.katex .vlist { display: table-cell; position: relative; vertical-align: bottom; }

.katex .vlist > span { display: block; height: 0px; position: relative; }

.katex .vlist > span > span { display: inline-block; }

.katex .vlist > span > .pstrut { overflow: hidden; width: 0px; }

.katex .vlist-t2 { margin-right: -2px; }

.katex .vlist-s { display: table-cell; font-size: 1px; min-width: 2px; vertical-align: bottom; width: 2px; }

.katex .vbox { align-items: baseline; display: inline-flex; flex-direction: column; }

.katex .hbox { width: 100%; }

.katex .hbox, .katex .thinbox { display: inline-flex; flex-direction: row; }

.katex .thinbox { max-width: 0px; width: 0px; }

.katex .msupsub { text-align: left; }

.katex .mfrac > span > span { text-align: center; }

.katex .mfrac .frac-line { border-bottom-style: solid; display: inline-block; width: 100%; }

.katex .hdashline, .katex .hline, .katex .mfrac .frac-line, .katex .overline .overline-line, .katex .rule, .katex .underline .underline-line { min-height: 1px; }

.katex .mspace { display: inline-block; }

.katex .clap, .katex .llap, .katex .rlap { position: relative; width: 0px; }

.katex .clap > .inner, .katex .llap > .inner, .katex .rlap > .inner { position: absolute; }

.katex .clap > .fix, .katex .llap > .fix, .katex .rlap > .fix { display: inline-block; }

.katex .llap > .inner { right: 0px; }

.katex .clap > .inner, .katex .rlap > .inner { left: 0px; }

.katex .clap > .inner > span { margin-left: -50%; margin-right: 50%; }

.katex .rule { border: 0px solid; display: inline-block; position: relative; }

.katex .hline, .katex .overline .overline-line, .katex .underline .underline-line { border-bottom-style: solid; display: inline-block; width: 100%; }

.katex .hdashline { border-bottom-style: dashed; display: inline-block; width: 100%; }

.katex .sqrt > .root { margin-left: 0.277778em; margin-right: -0.555556em; }

.katex .fontsize-ensurer.reset-size1.size1, .katex .sizing.reset-size1.size1 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size1.size2, .katex .sizing.reset-size1.size2 { font-size: 1.2em; }

.katex .fontsize-ensurer.reset-size1.size3, .katex .sizing.reset-size1.size3 { font-size: 1.4em; }

.katex .fontsize-ensurer.reset-size1.size4, .katex .sizing.reset-size1.size4 { font-size: 1.6em; }

.katex .fontsize-ensurer.reset-size1.size5, .katex .sizing.reset-size1.size5 { font-size: 1.8em; }

.katex .fontsize-ensurer.reset-size1.size6, .katex .sizing.reset-size1.size6 { font-size: 2em; }

.katex .fontsize-ensurer.reset-size1.size7, .katex .sizing.reset-size1.size7 { font-size: 2.4em; }

.katex .fontsize-ensurer.reset-size1.size8, .katex .sizing.reset-size1.size8 { font-size: 2.88em; }

.katex .fontsize-ensurer.reset-size1.size9, .katex .sizing.reset-size1.size9 { font-size: 3.456em; }

.katex .fontsize-ensurer.reset-size1.size10, .katex .sizing.reset-size1.size10 { font-size: 4.148em; }

.katex .fontsize-ensurer.reset-size1.size11, .katex .sizing.reset-size1.size11 { font-size: 4.976em; }

.katex .fontsize-ensurer.reset-size2.size1, .katex .sizing.reset-size2.size1 { font-size: 0.833333em; }

.katex .fontsize-ensurer.reset-size2.size2, .katex .sizing.reset-size2.size2 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size2.size3, .katex .sizing.reset-size2.size3 { font-size: 1.16667em; }

.katex .fontsize-ensurer.reset-size2.size4, .katex .sizing.reset-size2.size4 { font-size: 1.33333em; }

.katex .fontsize-ensurer.reset-size2.size5, .katex .sizing.reset-size2.size5 { font-size: 1.5em; }

.katex .fontsize-ensurer.reset-size2.size6, .katex .sizing.reset-size2.size6 { font-size: 1.66667em; }

.katex .fontsize-ensurer.reset-size2.size7, .katex .sizing.reset-size2.size7 { font-size: 2em; }

.katex .fontsize-ensurer.reset-size2.size8, .katex .sizing.reset-size2.size8 { font-size: 2.4em; }

.katex .fontsize-ensurer.reset-size2.size9, .katex .sizing.reset-size2.size9 { font-size: 2.88em; }

.katex .fontsize-ensurer.reset-size2.size10, .katex .sizing.reset-size2.size10 { font-size: 3.45667em; }

.katex .fontsize-ensurer.reset-size2.size11, .katex .sizing.reset-size2.size11 { font-size: 4.14667em; }

.katex .fontsize-ensurer.reset-size3.size1, .katex .sizing.reset-size3.size1 { font-size: 0.714286em; }

.katex .fontsize-ensurer.reset-size3.size2, .katex .sizing.reset-size3.size2 { font-size: 0.857143em; }

.katex .fontsize-ensurer.reset-size3.size3, .katex .sizing.reset-size3.size3 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size3.size4, .katex .sizing.reset-size3.size4 { font-size: 1.14286em; }

.katex .fontsize-ensurer.reset-size3.size5, .katex .sizing.reset-size3.size5 { font-size: 1.28571em; }

.katex .fontsize-ensurer.reset-size3.size6, .katex .sizing.reset-size3.size6 { font-size: 1.42857em; }

.katex .fontsize-ensurer.reset-size3.size7, .katex .sizing.reset-size3.size7 { font-size: 1.71429em; }

.katex .fontsize-ensurer.reset-size3.size8, .katex .sizing.reset-size3.size8 { font-size: 2.05714em; }

.katex .fontsize-ensurer.reset-size3.size9, .katex .sizing.reset-size3.size9 { font-size: 2.46857em; }

.katex .fontsize-ensurer.reset-size3.size10, .katex .sizing.reset-size3.size10 { font-size: 2.96286em; }

.katex .fontsize-ensurer.reset-size3.size11, .katex .sizing.reset-size3.size11 { font-size: 3.55429em; }

.katex .fontsize-ensurer.reset-size4.size1, .katex .sizing.reset-size4.size1 { font-size: 0.625em; }

.katex .fontsize-ensurer.reset-size4.size2, .katex .sizing.reset-size4.size2 { font-size: 0.75em; }

.katex .fontsize-ensurer.reset-size4.size3, .katex .sizing.reset-size4.size3 { font-size: 0.875em; }

.katex .fontsize-ensurer.reset-size4.size4, .katex .sizing.reset-size4.size4 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size4.size5, .katex .sizing.reset-size4.size5 { font-size: 1.125em; }

.katex .fontsize-ensurer.reset-size4.size6, .katex .sizing.reset-size4.size6 { font-size: 1.25em; }

.katex .fontsize-ensurer.reset-size4.size7, .katex .sizing.reset-size4.size7 { font-size: 1.5em; }

.katex .fontsize-ensurer.reset-size4.size8, .katex .sizing.reset-size4.size8 { font-size: 1.8em; }

.katex .fontsize-ensurer.reset-size4.size9, .katex .sizing.reset-size4.size9 { font-size: 2.16em; }

.katex .fontsize-ensurer.reset-size4.size10, .katex .sizing.reset-size4.size10 { font-size: 2.5925em; }

.katex .fontsize-ensurer.reset-size4.size11, .katex .sizing.reset-size4.size11 { font-size: 3.11em; }

.katex .fontsize-ensurer.reset-size5.size1, .katex .sizing.reset-size5.size1 { font-size: 0.555556em; }

.katex .fontsize-ensurer.reset-size5.size2, .katex .sizing.reset-size5.size2 { font-size: 0.666667em; }

.katex .fontsize-ensurer.reset-size5.size3, .katex .sizing.reset-size5.size3 { font-size: 0.777778em; }

.katex .fontsize-ensurer.reset-size5.size4, .katex .sizing.reset-size5.size4 { font-size: 0.888889em; }

.katex .fontsize-ensurer.reset-size5.size5, .katex .sizing.reset-size5.size5 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size5.size6, .katex .sizing.reset-size5.size6 { font-size: 1.11111em; }

.katex .fontsize-ensurer.reset-size5.size7, .katex .sizing.reset-size5.size7 { font-size: 1.33333em; }

.katex .fontsize-ensurer.reset-size5.size8, .katex .sizing.reset-size5.size8 { font-size: 1.6em; }

.katex .fontsize-ensurer.reset-size5.size9, .katex .sizing.reset-size5.size9 { font-size: 1.92em; }

.katex .fontsize-ensurer.reset-size5.size10, .katex .sizing.reset-size5.size10 { font-size: 2.30444em; }

.katex .fontsize-ensurer.reset-size5.size11, .katex .sizing.reset-size5.size11 { font-size: 2.76444em; }

.katex .fontsize-ensurer.reset-size6.size1, .katex .sizing.reset-size6.size1 { font-size: 0.5em; }

.katex .fontsize-ensurer.reset-size6.size2, .katex .sizing.reset-size6.size2 { font-size: 0.6em; }

.katex .fontsize-ensurer.reset-size6.size3, .katex .sizing.reset-size6.size3 { font-size: 0.7em; }

.katex .fontsize-ensurer.reset-size6.size4, .katex .sizing.reset-size6.size4 { font-size: 0.8em; }

.katex .fontsize-ensurer.reset-size6.size5, .katex .sizing.reset-size6.size5 { font-size: 0.9em; }

.katex .fontsize-ensurer.reset-size6.size6, .katex .sizing.reset-size6.size6 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size6.size7, .katex .sizing.reset-size6.size7 { font-size: 1.2em; }

.katex .fontsize-ensurer.reset-size6.size8, .katex .sizing.reset-size6.size8 { font-size: 1.44em; }

.katex .fontsize-ensurer.reset-size6.size9, .katex .sizing.reset-size6.size9 { font-size: 1.728em; }

.katex .fontsize-ensurer.reset-size6.size10, .katex .sizing.reset-size6.size10 { font-size: 2.074em; }

.katex .fontsize-ensurer.reset-size6.size11, .katex .sizing.reset-size6.size11 { font-size: 2.488em; }

.katex .fontsize-ensurer.reset-size7.size1, .katex .sizing.reset-size7.size1 { font-size: 0.416667em; }

.katex .fontsize-ensurer.reset-size7.size2, .katex .sizing.reset-size7.size2 { font-size: 0.5em; }

.katex .fontsize-ensurer.reset-size7.size3, .katex .sizing.reset-size7.size3 { font-size: 0.583333em; }

.katex .fontsize-ensurer.reset-size7.size4, .katex .sizing.reset-size7.size4 { font-size: 0.666667em; }

.katex .fontsize-ensurer.reset-size7.size5, .katex .sizing.reset-size7.size5 { font-size: 0.75em; }

.katex .fontsize-ensurer.reset-size7.size6, .katex .sizing.reset-size7.size6 { font-size: 0.833333em; }

.katex .fontsize-ensurer.reset-size7.size7, .katex .sizing.reset-size7.size7 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size7.size8, .katex .sizing.reset-size7.size8 { font-size: 1.2em; }

.katex .fontsize-ensurer.reset-size7.size9, .katex .sizing.reset-size7.size9 { font-size: 1.44em; }

.katex .fontsize-ensurer.reset-size7.size10, .katex .sizing.reset-size7.size10 { font-size: 1.72833em; }

.katex .fontsize-ensurer.reset-size7.size11, .katex .sizing.reset-size7.size11 { font-size: 2.07333em; }

.katex .fontsize-ensurer.reset-size8.size1, .katex .sizing.reset-size8.size1 { font-size: 0.347222em; }

.katex .fontsize-ensurer.reset-size8.size2, .katex .sizing.reset-size8.size2 { font-size: 0.416667em; }

.katex .fontsize-ensurer.reset-size8.size3, .katex .sizing.reset-size8.size3 { font-size: 0.486111em; }

.katex .fontsize-ensurer.reset-size8.size4, .katex .sizing.reset-size8.size4 { font-size: 0.555556em; }

.katex .fontsize-ensurer.reset-size8.size5, .katex .sizing.reset-size8.size5 { font-size: 0.625em; }

.katex .fontsize-ensurer.reset-size8.size6, .katex .sizing.reset-size8.size6 { font-size: 0.694444em; }

.katex .fontsize-ensurer.reset-size8.size7, .katex .sizing.reset-size8.size7 { font-size: 0.833333em; }

.katex .fontsize-ensurer.reset-size8.size8, .katex .sizing.reset-size8.size8 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size8.size9, .katex .sizing.reset-size8.size9 { font-size: 1.2em; }

.katex .fontsize-ensurer.reset-size8.size10, .katex .sizing.reset-size8.size10 { font-size: 1.44028em; }

.katex .fontsize-ensurer.reset-size8.size11, .katex .sizing.reset-size8.size11 { font-size: 1.72778em; }

.katex .fontsize-ensurer.reset-size9.size1, .katex .sizing.reset-size9.size1 { font-size: 0.289352em; }

.katex .fontsize-ensurer.reset-size9.size2, .katex .sizing.reset-size9.size2 { font-size: 0.347222em; }

.katex .fontsize-ensurer.reset-size9.size3, .katex .sizing.reset-size9.size3 { font-size: 0.405093em; }

.katex .fontsize-ensurer.reset-size9.size4, .katex .sizing.reset-size9.size4 { font-size: 0.462963em; }

.katex .fontsize-ensurer.reset-size9.size5, .katex .sizing.reset-size9.size5 { font-size: 0.520833em; }

.katex .fontsize-ensurer.reset-size9.size6, .katex .sizing.reset-size9.size6 { font-size: 0.578704em; }

.katex .fontsize-ensurer.reset-size9.size7, .katex .sizing.reset-size9.size7 { font-size: 0.694444em; }

.katex .fontsize-ensurer.reset-size9.size8, .katex .sizing.reset-size9.size8 { font-size: 0.833333em; }

.katex .fontsize-ensurer.reset-size9.size9, .katex .sizing.reset-size9.size9 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size9.size10, .katex .sizing.reset-size9.size10 { font-size: 1.20023em; }

.katex .fontsize-ensurer.reset-size9.size11, .katex .sizing.reset-size9.size11 { font-size: 1.43981em; }

.katex .fontsize-ensurer.reset-size10.size1, .katex .sizing.reset-size10.size1 { font-size: 0.24108em; }

.katex .fontsize-ensurer.reset-size10.size2, .katex .sizing.reset-size10.size2 { font-size: 0.289296em; }

.katex .fontsize-ensurer.reset-size10.size3, .katex .sizing.reset-size10.size3 { font-size: 0.337512em; }

.katex .fontsize-ensurer.reset-size10.size4, .katex .sizing.reset-size10.size4 { font-size: 0.385728em; }

.katex .fontsize-ensurer.reset-size10.size5, .katex .sizing.reset-size10.size5 { font-size: 0.433944em; }

.katex .fontsize-ensurer.reset-size10.size6, .katex .sizing.reset-size10.size6 { font-size: 0.48216em; }

.katex .fontsize-ensurer.reset-size10.size7, .katex .sizing.reset-size10.size7 { font-size: 0.578592em; }

.katex .fontsize-ensurer.reset-size10.size8, .katex .sizing.reset-size10.size8 { font-size: 0.694311em; }

.katex .fontsize-ensurer.reset-size10.size9, .katex .sizing.reset-size10.size9 { font-size: 0.833173em; }

.katex .fontsize-ensurer.reset-size10.size10, .katex .sizing.reset-size10.size10 { font-size: 1em; }

.katex .fontsize-ensurer.reset-size10.size11, .katex .sizing.reset-size10.size11 { font-size: 1.19961em; }

.katex .fontsize-ensurer.reset-size11.size1, .katex .sizing.reset-size11.size1 { font-size: 0.200965em; }

.katex .fontsize-ensurer.reset-size11.size2, .katex .sizing.reset-size11.size2 { font-size: 0.241158em; }

.katex .fontsize-ensurer.reset-size11.size3, .katex .sizing.reset-size11.size3 { font-size: 0.28135em; }

.katex .fontsize-ensurer.reset-size11.size4, .katex .sizing.reset-size11.size4 { font-size: 0.321543em; }

.katex .fontsize-ensurer.reset-size11.size5, .katex .sizing.reset-size11.size5 { font-size: 0.361736em; }

.katex .fontsize-ensurer.reset-size11.size6, .katex .sizing.reset-size11.size6 { font-size: 0.401929em; }

.katex .fontsize-ensurer.reset-size11.size7, .katex .sizing.reset-size11.size7 { font-size: 0.482315em; }

.katex .fontsize-ensurer.reset-size11.size8, .katex .sizing.reset-size11.size8 { font-size: 0.578778em; }

.katex .fontsize-ensurer.reset-size11.size9, .katex .sizing.reset-size11.size9 { font-size: 0.694534em; }

.katex .fontsize-ensurer.reset-size11.size10, .katex .sizing.reset-size11.size10 { font-size: 0.833601em; }

.katex .fontsize-ensurer.reset-size11.size11, .katex .sizing.reset-size11.size11 { font-size: 1em; }

.katex .delimsizing.size1 { font-family: KaTeX_Size1; }

.katex .delimsizing.size2 { font-family: KaTeX_Size2; }

.katex .delimsizing.size3 { font-family: KaTeX_Size3; }

.katex .delimsizing.size4 { font-family: KaTeX_Size4; }

.katex .delimsizing.mult .delim-size1 > span { font-family: KaTeX_Size1; }

.katex .delimsizing.mult .delim-size4 > span { font-family: KaTeX_Size4; }

.katex .nulldelimiter { display: inline-block; width: 0.12em; }

.katex .delimcenter, .katex .op-symbol { position: relative; }

.katex .op-symbol.small-op { font-family: KaTeX_Size1; }

.katex .op-symbol.large-op { font-family: KaTeX_Size2; }

.katex .accent > .vlist-t, .katex .op-limits > .vlist-t { text-align: center; }

.katex .accent .accent-body { position: relative; }

.katex .accent .accent-body:not(.accent-full) { width: 0px; }

.katex .overlay { display: block; }

.katex .mtable .vertical-separator { display: inline-block; min-width: 1px; }

.katex .mtable .arraycolsep { display: inline-block; }

.katex .mtable .col-align-c > .vlist-t { text-align: center; }

.katex .mtable .col-align-l > .vlist-t { text-align: left; }

.katex .mtable .col-align-r > .vlist-t { text-align: right; }

.katex .svg-align { text-align: left; }

.katex svg { fill: currentcolor; stroke: currentcolor; fill-rule: nonzero; fill-opacity: 1; stroke-width: 1; stroke-linecap: butt; stroke-linejoin: miter; stroke-miterlimit: 4; stroke-dasharray: none; stroke-dashoffset: 0; stroke-opacity: 1; display: block; height: inherit; position: absolute; width: 100%; }

.katex svg path { stroke: none; }

.katex img { border-style: none; max-height: none; max-width: none; min-height: 0px; min-width: 0px; }

.katex .stretchy { display: block; overflow: hidden; position: relative; width: 100%; }

.katex .stretchy::after, .katex .stretchy::before { content: ""; }

.katex .hide-tail { overflow: hidden; position: relative; width: 100%; }

.katex .halfarrow-left { left: 0px; overflow: hidden; position: absolute; width: 50.2%; }

.katex .halfarrow-right { overflow: hidden; position: absolute; right: 0px; width: 50.2%; }

.katex .brace-left { left: 0px; overflow: hidden; position: absolute; width: 25.1%; }

.katex .brace-center { left: 25%; overflow: hidden; position: absolute; width: 50%; }

.katex .brace-right { overflow: hidden; position: absolute; right: 0px; width: 25.1%; }

.katex .x-arrow-pad { padding: 0px 0.5em; }

.katex .cd-arrow-pad { padding: 0px 0.55556em 0px 0.27778em; }

.katex .mover, .katex .munder, .katex .x-arrow { text-align: center; }

.katex .boxpad { padding: 0px 0.3em; }

.katex .fbox, .katex .fcolorbox { border: 0.04em solid; box-sizing: border-box; }

.katex .cancel-pad { padding: 0px 0.2em; }

.katex .cancel-lap { margin-left: -0.2em; margin-right: -0.2em; }

.katex .sout { border-bottom-style: solid; border-bottom-width: 0.08em; }

.katex .angl { border-right: 0.049em solid; border-top: 0.049em solid; box-sizing: border-box; margin-right: 0.03889em; }

.katex .anglpad { padding: 0px 0.03889em; }

.katex .eqn-num::before { content: "(" counter(katexEqnNo) ")"; counter-increment: katexEqnNo 1; }

.katex .mml-eqn-num::before { content: "(" counter(mmlEqnNo) ")"; counter-increment: mmlEqnNo 1; }

.katex .mtr-glue { width: 50%; }

.katex .cd-vert-arrow { display: inline-block; position: relative; }

.katex .cd-label-left { display: inline-block; position: absolute; right: calc(50% + 0.3em); text-align: left; }

.katex .cd-label-right { display: inline-block; left: calc(50% + 0.3em); position: absolute; text-align: right; }

.katex-display { display: block; margin: 1em 0px; text-align: center; }

.katex-display > .katex { display: block; text-align: center; white-space: nowrap; }

.katex-display > .katex > .katex-html { display: block; position: relative; }

.katex-display > .katex > .katex-html > .tag { position: absolute; right: 0px; }

.katex-display.leqno > .katex > .katex-html > .tag { left: 0px; right: auto; }

.katex-display.fleqn > .katex { padding-left: 2em; text-align: left; }

body { counter-reset: katexEqnNo 0 mmlEqnNo 0; }

code, pre { font-family: "SÃ¶hne Mono", Monaco, "Andale Mono", "Ubuntu Mono", monospace !important; }

code[class="language-plaintext"] { white-space: pre-line; }

code.hljs, code[class*="language-"], pre[class*="language-"] { overflow-wrap: normal; background: none; color: rgb(255, 255, 255); hyphens: none; line-height: 1.5; tab-size: 4; text-align: left; white-space: pre; word-break: normal; word-spacing: normal; }

pre[class*="language-"] { border-radius: 0.3em; overflow: auto; }

:not(pre) > code.hljs, :not(pre) > code[class*="language-"] { border-radius: 0.3em; padding: 0.1em; white-space: normal; }

.hljs-comment { color: rgba(255, 255, 255, 0.5); }

.hljs-meta { color: rgba(255, 255, 255, 0.6); }

.hljs-built_in, .hljs-class .hljs-title { color: rgb(233, 149, 12); }

.hljs-doctag, .hljs-formula, .hljs-keyword, .hljs-literal { color: rgb(46, 149, 211); }

.hljs-addition, .hljs-attribute, .hljs-meta-string, .hljs-regexp, .hljs-string { color: rgb(0, 166, 125); }

.hljs-attr, .hljs-number, .hljs-selector-attr, .hljs-selector-class, .hljs-selector-pseudo, .hljs-template-variable, .hljs-type, .hljs-variable { color: rgb(223, 48, 121); }

.hljs-bullet, .hljs-link, .hljs-selector-id, .hljs-symbol, .hljs-title { color: rgb(242, 44, 61); }

.token.cdata, .token.comment, .token.doctype, .token.prolog { color: rgb(169, 174, 193); }

.token.punctuation { color: rgb(254, 254, 254); }

.token.constant, .token.deleted, .token.property, .token.symbol, .token.tag { color: rgb(255, 160, 122); }

.token.boolean, .token.number { color: rgb(0, 224, 224); }

.token.attr-name, .token.builtin, .token.char, .token.inserted, .token.selector, .token.string { color: rgb(171, 227, 56); }

.language-css .token.string, .style .token.string, .token.entity, .token.operator, .token.url, .token.variable { color: rgb(0, 224, 224); }

.token.atrule, .token.attr-value, .token.function { color: gold; }

.token.keyword { color: rgb(0, 224, 224); }

.token.important, .token.regex { color: gold; }

.token.bold, .token.important { font-weight: 700; }

.token.italic { font-style: italic; }

.token.entity { cursor: help; }

@media screen and (-ms-high-contrast: active) {
  code[class*="language-"], pre[class*="language-"] { background: window; color: windowtext; }
  :not(pre) > code[class*="language-"], pre[class*="language-"] { background: window; }
  .token.important { background: highlight; color: window; font-weight: 400; }
  .token.atrule, .token.attr-value, .token.function, .token.keyword, .token.operator, .token.selector { font-weight: 700; }
  .token.attr-value, .token.comment, .token.doctype, .token.function, .token.keyword, .token.operator, .token.property, .token.string { color: highlight; }
  .token.attr-value, .token.url { font-weight: 400; }
}

.PopoverContent { z-index: 1000; }

.react-select-container input:focus { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); }

.react-select-container .react-select__control { --tw-border-opacity:1; align-items: flex-start; border-color: rgba(236,236,241,var(--tw-border-opacity)); border-radius: 0.5rem; font-size: 0.875rem; height: 192px; line-height: 1.25rem; min-height: 192px; overflow: auto; padding: 0.5rem; }

.react-select-container .react-select__control:hover { --tw-border-opacity:1; border-color: rgba(217,217,227,var(--tw-border-opacity)); }

.dark .react-select-container .react-select__control { --tw-bg-opacity:1; background-color: rgba(32,33,35,var(--tw-bg-opacity)); border-color: rgba(255, 255, 255, 0.1); }

:is(.dark .react-select-container .react-select__control):hover { border-color: rgba(255, 255, 255, 0.2); }

.dark .react-select-container.react-select--invalid .react-select__control, .react-select-container.react-select--invalid .react-select__control { --tw-border-opacity:1; border-color: rgba(239,68,68,var(--tw-border-opacity)); }

.react-select-container .react-select__input-container, .react-select-container .react-select__placeholder { padding-left: 0.5rem; padding-right: 0.5rem; }

.dark .react-select-container .react-select__input-container { --tw-text-opacity:1; color: rgba(197,197,210,var(--tw-text-opacity)); }

.react-select-container .react-select__input { height: 2rem; }

.react-select-container .react-select__control--is-focused { --tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color); --tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(var(--tw-ring-offset-width)) var(--tw-ring-color); box-shadow: var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 transparent); --tw-border-opacity:1 !important; border-color: rgba(217,217,227,var(--tw-border-opacity)) !important; }

.dark .react-select-container .react-select__control--is-focused { border-color: rgba(255, 255, 255, 0.2) !important; }

.react-select-container .react-select__value-container { padding: 0px; }

.react-select-container .react-select__indicators:empty { display: none; }

.react-select-container .react-select__multi-value { background-color: transparent; margin: 0px; }

.react-select-container .react-select__multi-value__label { padding: 0px; }

#intercom-container { display: none; }
------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: image/webp
Content-Transfer-Encoding: binary
Content-Location: https://chat.openai.com/_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2Fa%2FAAcHTtfE_9fVpMOqgyC7Lo43NLrKgIo-u2ToDOuYOa2T%3Ds96-c&w=96&q=75

RIFF¨  WEBPVP8    *` ` >8G¥#¢!2´È 	@»ñÒ_p¨Ï¦?;ÁiÛEoè4õÿ d4ñ?qF|»µè)ô=ÂùýD¹äMÜKÏåçµª0¸vB³6}ª¹½ðöÎ(êLþ)6þ×òäKþfÀðxõ%×?«upXú	ÁYìIZ@ñÜöÌßp SjGNQTÈRÂ½#Eû&9ìI¸]òX[Ú×n¡dÙ÷6{=t­ÑÿXK¯Öí» ÇÍÝ¥\5a?)áÒ^§¿dÓ^§¼ô"xOÅ»?$êh þðêà&qÕîY¿`ù>F*VÓøUª«YèxüoYªeÇõvÕfCÂù:¬¬Ø} y¤ß<¡4*¤¼#	·"I½À@W1ìò@}TYÈn 5ÜjûiÝ=ÂµCUe¾²Äb&3"qþÍLtRjÝtüÛõnõ3¹Ñ]óËÎÓ ·LÏ6I!Bu$)ÚòægÉcowæÕÄ®y`Sã©2TÞ±aW¢=ÝíµN8¼X*ÌÚúÇiaBë¿ªÿ µ.Æ÷{øÍ&[Ó¢4ß]*J¥íËèß¨øâ~.ÜBw!ßÓ« 6Öm£{Æqý'Y¾L8@áqYæÔI¶{y]²Ìeµ»ºa:fi°¸O«ÂI6µ3zß¦Å©(õóüf
G;V¸ë7h6¢¹ÝRã{þÌý¯>½ZQ¹¬ë£/{?AË(8Äæ5¢÷î©]ûæ\®2(Zª°}Z<þf­µ¶hc¶Á@§9ÐNrn´«ÆýÊGgðuY4½ÌÙ^%ð>µ
kõÿnÌÞ1YÓfêªÐ×¼36kF«g1eé(9E]4;¥¬â<«nºrÏ69I\»c9Uá¨Jø:ù ô9ÝDLF¬uâYX(ù|±dÂ`²×ÙA½K)³tií/Å«ÉÐþ6HqøÞN´¶p)é·<Õ[{øpn·&CæÞ¨jWÉô> ¤&Ï"~Ò  .£¢GÂÜªêÒ;µ¿PúôÎÔ1Î½,Þ·°GM/Ò`ÄøXê*`ÜñPÊI;88.°å[ÒT E=ëä"=lDû7v&léÙôK>Ó¶½=F!ÔÿlÙ>BÀÒàÊÐüe
YoÓªUrpÆnY Û&¹Oÿ[h$k<ÿ¢[ðBeª¯¢6E]9âýR÷.ç+ÉÕÓX±hÛj®ùJqø_]nhîÅÜ3°IªCþÿâÅ%àñNhpÑlOëÞIr Ï¨ÃäUE¶Æ¡ò³KgttYÞ8ÀÏîhxWÝîkæUÀÊ,ò÷D|©Pêe;?ãTýl7×ß×¿Æy¤Í¸qäÄÔª55ò6%8¦ÊèÑ?_ÊÉkÃ÷Æa=Çnñ äíÓBÁîÜø2èbÀ:îåÈ#EDÒç;F	¯êé¾(¿,â]ïDxm¨õÅPI*bè®gö£È¦º3dpñé·hV2À*¸múwöM$q½DLD¶yµq»üRèÙÀ?·uÄ¶;$¶Ó>àcå ]¼928µùXÐônF^¸XYëÉ!D[ZôÄ`æ0|1úÒW¡³ßèAÞ`CI§õz,ÄÅÅX(tÉä-·u(@çæeX¡â%2ÑâÜÎÃÜ¦tD}1füØ°ìªì
¬¢ö©>LÆRzÓ ¶ÍB[ºè {KÁN8uüÊ¿3KZ¹ùþúw_ 2N2 òDÜÝ­é½û¨
X=ÆGÊ,\ÉÉ_}¶¦O}uYõÔÛ Yø  
------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: text/html
Content-ID: 
Content-Transfer-Encoding: binary





------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: text/html
Content-ID: 
Content-Transfer-Encoding: binary
Content-Location: https://tcr9i.chat.openai.com/v2/1.5.2/enforcement.64b3a4e29686f93d52816249ecbf9857.html#35536E1E-65B4-4D96-9D97-6ADB7EFF8147


------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: text/css
Content-Transfer-Encoding: binary
Content-Location: cid:css-ad3eb9fe-cf7a-449f-8030-a42abc5b9628@mhtml.blink

@charset "utf-8";

html, body { margin: 0px; padding: 0px; height: 100%; }

* { box-sizing: border-box; }

#app { height: 100%; overflow: hidden; }
------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz----
Content-Type: text/css
Content-Transfer-Encoding: binary
Content-Location: cid:css-c6586ed5-dac7-4e9d-85d8-025d910eba80@mhtml.blink

@charset "utf-8";

@keyframes spin { 
  0% { transform: rotate(0deg) translateZ(0px); }
  100% { transform: rotate(360deg) translateZ(0px); }
}

@keyframes fadeIn { 
  0% { opacity: 0; }
  100% { opacity: 1; }
}

.kXaXkDzIfSzLHRklX2r3 { position: fixed; top: 20px; right: 20px; width: 20px; height: 20px; z-index: 200; border: none; background-color: transparent; background-image: url("data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iMzhweCIgaGVpZ2h0PSIzOHB4IiB2aWV3Qm94PSIwIDAgMzggMzgiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDQ0LjEgKDQxNDU1KSAtIGh0dHA6Ly93d3cuYm9oZW1pYW5jb2RpbmcuY29tL3NrZXRjaCAtLT4KICAgIDx0aXRsZT5Hcm91cDwvdGl0bGU+CiAgICA8ZGVzYz5DcmVhdGVkIHdpdGggU2tldGNoLjwvZGVzYz4KICAgIDxkZWZzPjwvZGVmcz4KICAgIDxnIGlkPSJQYWdlLTEiIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJHcm91cCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMTkuMDAwMDAwLCAxOS4wMDAwMDApIHJvdGF0ZSg0NS4wMDAwMDApIHRyYW5zbGF0ZSgtMTkuMDAwMDAwLCAtMTkuMDAwMDAwKSB0cmFuc2xhdGUoLTYuMDAwMDAwLCAtNi4wMDAwMDApIiBmaWxsPSIjOTQ5NDk0Ij4KICAgICAgICAgICAgPHJlY3QgaWQ9IlJlY3RhbmdsZSIgeD0iMjQiIHk9IjAiIHdpZHRoPSIyIiBoZWlnaHQ9IjUwIj48L3JlY3Q+CiAgICAgICAgICAgIDxyZWN0IGlkPSJSZWN0YW5nbGUiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDI1LjAwMDAwMCwgMjUuMDAwMDAwKSByb3RhdGUoOTAuMDAwMDAwKSB0cmFuc2xhdGUoLTI1LjAwMDAwMCwgLTI1LjAwMDAwMCkgIiB4PSIyNCIgeT0iMCIgd2lkdGg9IjIiIGhlaWdodD0iNTAiPjwvcmVjdD4KICAgICAgICA8L2c+CiAgICA8L2c+Cjwvc3ZnPg=="); background-repeat: no-repeat; background-position: center center; background-size: contain; cursor: pointer; pointer-events: none; transform: scale(1); transition: transform 100ms ease-in-out 0s; visibility: hidden; opacity: 0; }

.kXaXkDzIfSzLHRklX2r3:hover { transform: scale(1.3); }

.kXaXkDzIfSzLHRklX2r3.active { pointer-events: inherit; visibility: visible; opacity: 1; transition: opacity 400ms ease-in-out 0s; }

.nMUBxApsE7lSELvJiiAA { position: fixed; inset: 0px; background-color: rgba(255, 255, 255, 0.8); z-index: -1; opacity: 0; transition: opacity 300ms linear 0s; pointer-events: none; }

.nMUBxApsE7lSELvJiiAA.active { opacity: 1; pointer-events: inherit; }

.lTLYGVw1ASsTZWg0vUbC { position: absolute; top: 50%; left: 50%; margin-left: -15px; margin-top: -15px; z-index: 1010; border-radius: 50%; width: 30px; height: 30px; border-width: 3px; border-style: solid; border-color: transparent transparent transparent rgba(0, 0, 0, 0.2); transform: translateZ(0px); box-sizing: border-box; }

.lTLYGVw1ASsTZWg0vUbC { animation: 500ms linear 0s infinite normal none running spin; }

.slrEYyWESVLe_Cx3DM1k { transition: opacity 500ms ease 0s, transform 500ms ease 0s; opacity: 0; transform: scale(0.8); text-align: center; height: 100%; }

.slrEYyWESVLe_Cx3DM1k.active { opacity: 1; transform: scale(1); }

.slrEYyWESVLe_Cx3DM1k.challenge-enter { opacity: 0; transform: scale(0.8); }

.slrEYyWESVLe_Cx3DM1k.challenge-enter-active, .slrEYyWESVLe_Cx3DM1k.challenge-enter-done { transform: scale(1); opacity: 1; }

.slrEYyWESVLe_Cx3DM1k.challenge-exit { transform: scale(1); opacity: 1; }

.slrEYyWESVLe_Cx3DM1k.challenge-exit-active, .slrEYyWESVLe_Cx3DM1k.challenge-exit-done { transform: scale(0.8); opacity: 0; }

.slrEYyWESVLe_Cx3DM1k.dTcazKGGob_VbK_J853h { flex-direction: column; }

.dTcazKGGob_VbK_J853h { display: flex; align-items: center; justify-content: center; }
------MultipartBoundary--BBx2CESpLMZ2vaUqAtgKGN7eIF5lmkqvPFIPXpCKqz------
