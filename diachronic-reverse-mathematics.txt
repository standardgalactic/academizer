Diachronic Reverse 
Mathematics

The paper "A Category 
Theory Framework for 
Bayesian Learning" by 
Kotaro Kamiya and John 
Welliaveetil introduces a
categorical framework to 
formalize Bayesian 
inference and learning. 
It builds upon previous 
foundational works and 

introduces the concept 
of Bayesian inversions 
and the functor GL. The 
paper shows that 
Bayesian learning is a 
special case of a broader 
learning paradigm and 
provides categorical 
formulations for both 
batch and sequential 
Bayes updates. It also 
addresses the problem in
machine learning of 

estimating a function 
that relates two 
variables or random 
vectors. Overall, the 
paper aims to offer a 
more structured and 
formalized approach to 
Bayesian learning using 
the principles of 
category theory.

The introduction of the 
paper lays out the 
objectives and the 
approach taken to 
formalize Bayesian 
learning within a category
theory framework. It 
begins by describing a 
standard problem in 
machine learning: 
estimating a function 

f that models the 
relationship between two
random variables 

x and y. In contrast to 
traditional approaches, 
the paper suggests using 
a probabilistic model 

(  ∣  ; ) p(y∣x;θ) where  
θ is also treated as a 
random variable, and the

aim is to find a posterior 
distribution for  θ.

The authors then 
summarize previous work 
in the field that 
employed category 
theory to formalize 
learning algorithms. 
Specifically, they 
mention the foundational
work of Fong, Spivak, and
Tuyeras and another 

paper that introduces 
the notion of a Cartesian 
Reverse Differential 
category (CRDC). In this 
setting, learning 
algorithms are 
represented as 
functors.

The paper's primary goal 
is to integrate these 
approaches to create a 
category theory 

framework for Bayesian 
learning. The authors 
argue that Bayesian 
learning simplifies the 
framework in previous 
research, noting that in 
the right setup, Bayesian
inversion is a well-
defined dagger functor.

Overall, the paper aims 
to provide a theoretical 
foundation for Bayesian 

learning, drawing on the 
principles of category 
theory to create a 
structured and 
formalized framework.

The text provides a 
detailed look at the 
mathematical 
underpinnings of using 

category theory to 
formalize Bayesian 
learning. It covers 
several key points:

Markov Categories: The 
text refers to the work 
by Cho and Jacobs, and 
Fritz, introducing the 
notion of Markov 
categories as a 
foundational framework 
to discuss Bayesian 

inversion and other 
probabilistic operations. 
In particular, the paper 
uses examples of 
FinStoch and Stoch as 
guiding categories.

Bayesian Inversion: This 
is described as a morphism

† :  →  p † :Y→X derived 
using Bayes' theorem. 
However, this is not 

always unique or 
existent, so the paper 
restricts focus to 
Markov categories that 
admit Bayesian inversion.

ProbStoch(C): A symmetric
monoidal category, 
introduced by Cho and 
Jacobs, allows for dealing 
with almost sure equality
and is used to overcome 
issues with non-unique 

Bayesian inversion. It's 
denoted as   ( ) PS(C) for 
ease.

Kleisli Category and M-
actegory: The authors 
work within a suitable 
Kleisli category, assuming
that their Markov 
category 

C is an M-actegory. They 
use the Para

M construction to 
generalize previous work.

BayesLearn Functor: The
paper introduces a 
functor named 
BayesLearn that 
captures the essence of 
the Bayesian learning 
algorithm. This functor 
is inspired by work on 
gradient-based learning 

and operates between 
generalized lens 
categories.

Mapping and Induced 
Morphism: The paper 
provides the specifics of 
how BayesLearn works. 
Given a parametrized 
morphism 

→  X→Y and a state on  X, 
the functor induces 
another morphism in 

 ( ) PS(C), leading to a 
well-defined learning 
mechanism within the 
category.

Overall, the text aims to
provide a robust 
mathematical framework 
for understanding 

Bayesian learning 
through the lens of 
category theory. It builds
on existing work but also 
introduces novel 
structures and functors 
to encapsulate Bayesian 
learning methods.

In this section, the text 
provides an overview of 
Bayesian inference and 
its application to modeling
relationships between 
random variables. It uses 
a reference lecture [11]
for context. The 
approach is illustrated 
with an example where 

= (  1 , .  .  .  ,  ) x=(x 1 
,...,x n ) is a random 

vector and  y is a random 
variable related by  =  (
) +  y=f(x)+ϵ, where  ϵ
is normally distributed 
with mean 0 and variance 
2 σ 2 .

Here's a breakdown of 
the key points in this 
section:

Training Set and Bayesian
Approach: Given a training

set  = { (  1 ,  
1) , .  .  .  , (   ,  ) } 
T={(x 1  ,y 1 ),...,(x N  ,y
N )}, Bayesian inference 
is divided into two parts. 

First, treat  β (a 
parameter in the model) 
as a random variable and 
choose a prior 
distribution for it. Then,
update this distribution 
using Bayes' rule to 

obtain the posterior 
distribution after 
considering the training 
data.

Updating the Posterior 
Distribution: With an 
assumed improper prior  (
) = 1 q(β)=1, applying 
Bayes' rule results in a 
proportional relationship 
between the posterior 
distribution  (  ∣ ) 

p(β∣T) and the 
likelihood  (  ∣ ) p(T∣β) 
times the prior  ( ) q(β).

Likelihood Calculation: 
Given the nature of the 
data and independence 
assumptions, the 
likelihood  (  ∣ ) p(T∣β) 
is calculated. In the 
context of normally 
distributed data, this 
expression is derived.

Inference Approaches: 
The text outlines two 
ways to perform 
inference using the 
learned posterior 
distribution:

Maximum a Posteriori 
(MAP) Estimate: 
Calculate     = argmax   (
∣ ) β MAP  =argmax β  
p(β∣T), which 

represents the most 
likely parameter given 
the training data. Then 
use  (  ∗ ∣  ∗ ,    ) p(y ∗ 
∣x ∗ ,β MAP ).

Full Bayesian Inference:
Integrate over the 
entire posterior 
distribution  (  ∣ ) 
p(β∣T) to calculate  (  ∗
∣  ∗ , ) p(y ∗ ∣x ∗ ,T), 
which takes into account 

the uncertainty in the 
parameter estimation.

Relation to Ordinary 
Least Squares (OLS): In 
the example, the     β 
MAP  estimate coincides 
with the ordinary least 
squares (OLS) estimate.

This section lays the 
foundation for Bayesian 
inference, demonstrating

how to update prior 
beliefs about parameters
based on observed data 
and how to perform 
inference using the 
posterior distribution.

In this section, the text 
introduces the concept 
of a category named 
"Stoch" to deal with 

distributions whose 
supports might not be 
infinite. Stoch consists of
measurable spaces, 
tuples of the form (X, 
ΣX) where X is a set and 
ΣX is a well-defined σ-
algebra on X. Here's a 
breakdown of the key 
points:

Category Stoch: Stoch is 
introduced to handle 

distributions with non-
infinite supports. Objects
in Stoch are measurable 
spaces. A morphism (X, 
ΣX) → (Y, ΣY) in Stoch is a
map  :  × Σ  → [ 0 , 1 ] 
f:X×Σ Y  →[0,1] with 
specific properties. The 
category Stoch inherits a 
symmetric monoidal 
structure from 
measurable spaces.

Monoidal Structure: 
Stoch's monoidal 
structure is defined as (
, Σ ) ⊗ (  , Σ ) = (  ×  , Σ
⊗ Σ ) (X,Σ X )⊗(Y,Σ Y 
)=(X×Y,Σ X  ⊗Σ Y ), 
where Σ  ⊗ Σ  Σ X  ⊗Σ Y 
is generated by subsets 
of the form  ×  U×V,  ∈ 
Σ  U∈Σ X  ,  ∈ Σ  V∈Σ Y 
.

Copy and Delete 
Morphisms: Copy and 
delete morphisms are 
introduced, but delete 
isn't explicitly defined 
in the text. Copy 
morphism copy  copy X  is 
defined for objects (  , 
Σ ) (X,Σ X ) and maps a 
pair (  , ) (S,x) to 1 if 
(  , ) (x,x) belongs to  S, 
and 0 otherwise.

Composition of Morphisms: 
Composition of 
morphisms  : (  , Σ ) → (  ,
Σ ) f:(X,Σ X )→(Y,Σ Y ) 
and  : (  , Σ ) → (  , Σ ) g:
(Y,Σ Y )→(Z,Σ Z ) is 
defined as  ;  f;g and is 
given by (  , ) ↦ ∫   (  , )  
(   , ) (S,x)↦∫ Z  
g(S,y)f(dy,x), where  ( ) 
f(x) refers to a measure
Σ  → [ 0 , 1 ] Σ Y  →[0,1].

Disintegration and 
Jointification: The 
concept of disintegration 
is introduced, consisting 
of a channel  :  →  f:X→Y 
and a state   :  →  π X
 :I→X that satisfy certain
conditions. Jointification 
of a morphism  :  →  
f:X→Y and a state  :  →  
ψ:I→X is also introduced.

Conditional Distributions: 
The concept of a Markov 
category admitting 
conditional distributions 
is introduced, where for 
each morphism  :  →  ⊗  
s:A→X⊗Y, there exists a 
morphism  :  ⊗  →  
t:X⊗A→Y such that 
specific string diagrams 
are equal.

In summary, this section 
defines the category 
Stoch to deal with 
distributions on non-
infinite supports and 
introduces concepts like 
copy and delete 
morphisms, composition, 
disintegration, 
jointification, and 
conditional distributions. 
These concepts provide a 
mathematical foundation 

for handling probabilistic
relationships within the 
framework of category 
theory.

In this section, the text 
outlines the construction
of the "BayesLearn" 
functor and provides the
necessary preliminary 

concepts to understand 
the category structure 
within   ( ) PS(C) where  C
is a Markov category. 
Here are the main points 
of this section:

Inducing the M-actegory 
Structure: To ensure 
that the categories used 
in the ParaM construction
have the structure of 
an M-actegory, 

modifications are made to 
the category 

M. This modification is 
made to ensure well-
defined priors for 
parameter spaces. The 
text refers to a 
commutative diagram that
illustrates the 
relationship between 
certain morphisms in  M 
and  C.

Agreement between 
Categories: The text 
introduces the concept 
of "agreement" between 
categories  C and  M. 
Specifically, if 

C is a symmetric monoidal 
M-actegory and satisfies 
a certain condition with 
respect to  M, then  C is 
said to be in agreement 

with  M. This notion is 
crucial for ensuring 
compatibility between the
categories.

Utilizing PS(M): For 
capturing the concept of 
state on a parameter and
updating it through 
Bayesian inversion, the 
category   ( ) PS(M) (as 
discussed in a previous 
section) is used. This 

choice naturally aligns 
with the requirements 
of Bayesian learning.

Lemma 3.3: The main 
result of this section is 
presented as a lemma. It 
states that if (  ,  , ⋆) 
(M,J,⋆) is a causal Markov
category and (  ,  , ⊗) 
(C,I,⊗) is a Markov 
category in agreement 
with  M, then the 

category   ( ) PS(C) is a 
PS(M)-actegory. The 
construction of an 
endofunctor (  ,  ) ⊙ :   (
) →   ( ) (P,π P 
)⊙:PS(C)→PS(C) is detailed,
which plays a crucial role
in establishing this 
result.

The overall goal of this 
section is to set the 
stage for the subsequent

construction of the 
"BayesLearn" functor by
introducing necessary 
concepts and establishing 
the compatibility between
categories required for 
Bayesian learning within 
the category theory 
framework.

In this part of the text, 
it discusses how to 
perform updates in 
Bayesian learning using 
the categorical 
framework. It highlights 
sequential updates and 
batch updates, based on 
the data and parameters 
involved. Here are the 
main points:

Bayes Predictive Density:
The Bayes predictive 
density, described in 
§3.3, is given by an 
equation involving 

P, the posterior 
distribution of the 
parameter. It involves 
the composition of 
morphisms and is derived 
from the Chapman-

Kolmogorov equation in 
the Stoch category.

Bayes Updates: The goal 
is to update the prior 
distribution on the 
parameter space 

M given a training dataset
T. The approach 
presented in this section 
aims to translate this 

update into the 
categorical framework.

Sequential Updates: In 
the context of a Markov 
category 

C, the text considers a 
model  :  ⊙  →  f:M⊙X→Y, 
where  M is the 
parameter space and  f 
represents the true 
relationship between 

input  X and output  Y. 
With a prior state   :  →  
π X  :I→X and a prior on  
M,   , 0 :  →  π M,0  :J→M,
the text discusses how 
to update the posterior 
sequentially. It involves 
applying Bayesian 
inversion and obtaining a 
morphism  joint † :  →  ⊙  
f joint †  :Z→M⊙I, where 
=  ⊙  Z=X⊙Y.

Batch Updates: Instead 
of sequentially updating,
the text proposes a 
batch update approach. 
Given a training set  T 
with elements (  , ) (x,y),
it constructs morphisms 
that represent the data 
points. It then uses 
these morphisms to 
calculate a joint morphism
that factors through  = 
⊙  Z=X⊙Y.

The main focus here is on
understanding how to 
perform updates to the 
prior distribution of 
parameters in a Bayesian 
learning scenario using 
the categorical 
framework. The methods 
discussed involve 
concepts such as Bayesian
inversion, morphisms, and
the relationships 

between different 
categorical constructs.

This portion of the text 
explores batch updates 
in the context of the 
categorical framework 
for Bayesian learning. 
Here's an overview of 

the key concepts and 
ideas presented:

Batch Updates with Zn: 
The text introduces the 
idea of batch updates 
using an object   Z n  , 
which is constructed by 
taking the tensor 
product of  n copies of  ⊗
X⊗Y. This object is used 
to represent datasets of
a specified size. The 

model  f gives rise to a 
morphism   joint :  →   f n 
joint  :M→Z n  , capturing 
the relationship between
the parameter space  M 
and the dataset   Z n  .

Updating the Prior: Given
a training dataset  T, 
consisting of pairs (   ,  ) 
(x i  ,y i ), the batch 
update of the prior   , 0 
π M,0  with respect to  T

is performed by applying 
a Bayesian inversion to 
the morphism   joint f n 
joint  . This updated 
prior is denoted as   ,  π 
M,T  .

Conditions for 
Coincidence: The text 
raises the question of 
under what conditions 
the sequential Bayes 
update (discussed 

earlier) and the batch 
update coincide. The 
example provided 
(Example 4.5) 
demonstrates that in 
some cases, sequential 
and batch updates can 
yield the same result. 
The text prompts 
further exploration into
the conditions that 
establish a relationship 
between these updates 

in the broader 
categorical framework.

Overall, this section 
delves into the concepts 
of batch updates, the 
construction of objects to
represent datasets, and 
the relationship between
sequential and batch 
updates in the context 
of Bayesian learning 

within the categorical 
framework.

Certainly! Here's a list 
of the topics we've 
discussed so far:

Introduction to the 
Problem of Machine 

Learning and Additive 
Models
Formulation of the 
Framework within 
Category Theory
Bayesian Inference and 
Parametrized 
Distributions
Preliminaries about 
Markov Categories, 
Conditional Distributions, 
and Symmetric Monoidal 
Structures

Bayesian Learning 
Overview: Example of 
Relationship Between 
Random Variables
Stoch Category and 
Measurable Spaces
Bayesian Learning: 
Sequential and Batch 
Updates
Conditions for Coincidence
of Sequential and Batch 
Updates

Feel free to ask if you'd
like more information 
about any specific topic or
if you have any questions
related to these topics!

Sure! Let's break down 
the idea of fitting 
Bayesian theory into 

category theory in 
simpler terms:

Bayesian Theory: In 
Bayesian theory, we're 
interested in 
understanding the 
relationship between 
random variables. We 
often want to estimate 
the probability of one 
variable given another. 
For instance, given 

certain data, we want to 
find the likelihood of an
event happening.

Category Theory: 
Category theory is a way 
of organizing and studying
different mathematical 
structures and their 
relationships. It provides
a high-level framework 
to understand how 
different objects (like 

sets or spaces) relate to 
each other through 
morphisms (functions or 
mappings).

Fitting Bayesian Theory 
into Category Theory: 
Imagine you have a system
where you're trying to 
learn about the 
relationship between 
different variables. 
Instead of just using 

traditional probability 
calculations, you're using
the principles of 
category theory to 
organize your 
understanding.

In this approach, you use 
category theory to 
represent things like 
random variables, their 
relationships, and the 
way you update your 

understanding with new 
data. You map the 
concepts from Bayesian 
theory into the 
structures provided by 
category theory.

For example, you can 
think of the different 
types of variables as 
objects in a category, and 
the relationships 
between them as 

morphisms. The process 
of updating your beliefs 
with new data can be 
represented using 
category theory concepts.

Overall, fitting Bayesian
theory into category 
theory is about 
leveraging the 
organizational power of 
category theory to 
represent and reason 

about the probabilistic 
relationships between 
variables in a more 
structured and 
systematic way.

The dissertation titled 
"Geometric Bayes" by 
Andrew J. Holbrook, 
submitted for the 

degree of Doctor of 
Philosophy in Statistics at
the University of 
California, Irvine, 
focuses on incorporating 
geometric concepts into 
Bayesian theory. Here's 
a simplified overview of 
the main topics discussed 
in the different sections
of the dissertation:

Introduction:

Introduces the idea of 
using geometry in 
statistics.
Highlights the 
significance of Riemannian
geometry, which deals 
with smooth spaces and 
distances.
Summarizes the 
contributions and main 
areas of focus in the 
dissertation.

Bayesian Inference on 
General Riemannian 
Manifolds:

Explains the motivation 
of learning the spectral 
density matrix.
Discusses Riemannian 
manifolds and geodesics, 
which are curves that 
capture shortest paths.
Introduces Bayesian 
inference techniques 

using the geodesic 
Lagrangian Monte Carlo.
Applies these techniques
to the space of positive 
definite matrices, which 
are important in 
statistics.
Provides examples of 
prior distributions on 
covariance matrices.
Presents empirical 
validation and results of

learning the spectral 
density.
Differentiating the 
Pseudo Determinant:

Discusses the concept of 
the canonical derivative 
and how it relates to 
matrices.
Explains matrix 
differentials and their 
significance.

Demonstrates the 
application of these 
concepts in a statistical 
context.
Simplifying the Geodesic 
Monte Carlo:

Introduces the idea of 
simplifying geodesic Monte
Carlo using embedded 
manifolds.

Presents an alternative 
derivation for this 
technique.
Discusses the implications
and possible 
improvements.
Fisher Geometry and 
Bayesian Nonparametric 
Density Estimation:

Explores Fisher 
geometry, which provides 
a way to measure 

distances between 
probability distributions.
Discusses the 
nonparametric Fisher 
geometry, extending it 
beyond parametric 
models.
Introduces the chi-
square process density 
prior.
Describes the Karhunen-
Loève representation, a 

way of approximating 
random processes.
Applies this model for 
Bayesian density 
estimation.
Presents empirical 
results from simulated 
experiments and real-
world data.
Each section of the 
dissertation delves into 
different aspects of 
incorporating geometric 

ideas into Bayesian 
theory, applying these 
concepts to statistical 
problems, and providing 
empirical results to 
support the proposed 
methodologies.

Application: Bayesian 
Neural Decoding:

Introduces the 
application of geometric 
Bayesian methods in the 
field of neural decoding.
Provides the scientific 
background and 
experimental setup for 
the study.
Discusses Bayesian linear
dimensionality reduction 
techniques and their 
extensions.

Explores methods like 
exponential family PCA, 
wavelet transform, and 
supervised exponential 
PCA.
Introduces the 
supervised dual-
dimensionality reduction 
model.
Presents results 
related to prediction, 
variable selection, and 

scientific inference in 
neural decoding.
Concludes with a 
discussion on the 
outcomes of the 
application.
Future Directions: 
Bayesian Inference on 
Infinite Manifolds:

Discusses potential 
future research 
directions.

Highlights dimensionality 
reduction techniques.
Explores the idea of 
learning the quantum 
wave.
Discusses computing on 
infinite manifolds and its
implications.
Bibliography: Lists the 
references and sources 
used in the dissertation.

Appendices:

Provides additional 
details on topics related 
to prediction error 
estimation for complex 
samples.
Discusses real and 
complex matrix 
derivatives in the 
context of Bayesian 
inference on general 
Riemannian manifolds.

Presents information on 
the simplification of the 
geodesic Monte Carlo.
Explores the 
initialization of the 
Markov chain and its 
relationship to the Cox 
process in the context of
Fisher geometry and 
Bayesian nonparametric 
density estimation.
Overall, the dissertation
covers a wide range of 

topics related to applying
geometric concepts to 
Bayesian theory, 
including applications in 
statistical analysis, 
dimensionality reduction, 
and neural decoding.

This dissertation 
explores the fascinating 

connections between 
differential geometry 
and Bayesian analysis. 
Differential geometry 
provides insights into the
spatial structure of the 
universe, while Bayesian
analysis is a powerful 
framework for 
statistical inference 
using probability and 
Bayes' theorem. The aim 
here is to combine these 

disciplines to enable 
practical applications of 
Bayesian inference in 
real-world science, with 
a specific focus on 
dynamic and high-
dimensional neural data.

A significant part of this 
work involves developing 
and applying probabilistic 
models defined over 
smooth manifolds. These 

models capture 
dependencies in time 
series using the manifold
of Hermitian positive 
definite matrices, 
represent probability 
density functions using 
the infinite sphere, and 
handle high-dimensional 
data using the Stiefel 
manifold of orthonormal 
matrices. While 
formulating manifold-

based models is 
conceptually feasible, 
the complex geometry 
poses computational 
challenges for model-
based inference.

To address these 
challenges, this thesis 
introduces two new 
algorithms for Bayesian 
inference on Riemannian 
manifolds. The first 

algorithm is designed for 
inference on general 
Riemannian manifolds, 
particularly applied to 
Hermitian positive 
definite matrices. The 
second algorithm focuses 
on inference over 
manifolds embedded in 
Euclidean space and is 
used for inference on 
the sphere and Stiefel 
manifolds.

The structure of the 
dissertation is as 
follows:

Chapter 1 introduces the 
general context and 
fundamental concepts of 
Riemannian geometry.
Chapter 2 presents the 
geodesic Lagrangian Monte
Carlo algorithm and 
applies it to Bayesian 

inference on the space 
of Hermitian positive 
definite matrices. This 
application involves 
learning spectral 
densities of time series 
data from rodent brain 
local field potentials.
Chapter 4 introduces an 
alternative version of 
the geodesic Monte Carlo 
algorithm that is 
conceptually simpler but 

requires differentiation 
of the pseudo 
determinant. The 
derivative of the pseudo
determinant is derived in
Chapter 3.
Chapter 5 leverages the 
geometry of the 
infinite-dimensional 
sphere for Bayesian 
nonparametric density 
estimation.

Chapter 6 uses high-
dimensional spike trains 
and local field potentials
from rodent brains to 
predict environmental 
stimuli. This Bayesian 
"neural decoding" 
involves both geometric 
and non-geometric 
models.
Chapter 7 looks ahead to 
the potential frontiers 

of Bayesian inference on
infinite manifolds.
The dissertation 
ultimately strives to 
merge differential 
geometry and Bayesian 
analysis to create 
powerful tools for 
analyzing complex data 
sets, especially in the 
realm of neural decoding
and high-dimensional data
analysis.

Introduction:
1.1 Geometry in Statistics

Human beings possess a 
natural ability for 
spatial reasoning, 
allowing us to navigate 
and comprehend our 
surroundings. This innate

skill assists us in 
organizing and 
understanding the world,
enabling us to deduce 
intricate relationships 
among objects. This 
capacity for spatial 
reasoning plays a pivotal 
role in induction, 
empowering us to exert 
control over nature and 
our environment. Given 
its primal significance, 

it's unsurprising that 
geometry, which 
formalizes our spatial 
intuition mathematically, 
has found a significant 
place in statistics—a 
mathematical discipline 
concerned with 
inference.

In statistical analysis, 
researchers often 
assume that the data 

they observe resides 
within a specific space. A 
classic instance is the 
utilization of Euclidean 
geometry in linear 
regression. This involves 
modeling the relationship
between an outcome 
variable and explanatory 
variables as a line of 
best fit. Minimizing the 
squared error between 
observed outcomes and 

the fitted values is 
equivalent to projecting 
the outcome vector onto 
the linear subspace 
spanned by the covariate 
vectors.

While data may often be 
complex and high-
dimensional, it's 
reasonable to assume 
that data points tend to 
concentrate within a 

lower-dimensional space. 
This assumption 
underpins linear 
dimensionality reduction 
methods like factor 
analysis, principal 
component analysis, and 
canonical correlation 
analysis. These 
techniques project the 
observed high-
dimensional data onto a 
lower-dimensional space 

using linear 
transformations. More on
this topic, along with its 
Bayesian interpretations,
is explored in Chapter 6.

However, there's no 
inherent reason to 
assume a priori that data 
belongs exclusively to a 
linear subspace of the 
observed support. This 
insight has led to 

