Evolutionary Computation
Open sidebar
ChatGPT
3.5
You
Monica Anderson writes:

Evolutionary Computation is under-appreciated.  Objections include "Evolution takes millennia" and "I don't get the point".

They are (or should be) very important to people in the AI community because they provide a primitive form of intelligence. Understanding Evolutionary Computation (EC) will make understanding LLMs easier.

In order to not have to define "AI" again, I will now define a new term SHAG which stands for "SuperHuman Answer Generator".

A SHAG is a computer based system which can provide answers to questions that the client or programmer that is using the system cannot (or cannot be bothered to) compute an answer to themselves. Or shorter: A SHAG generates answers that humans cannot generate.

Unsurprisingly, all LLMs are SHAGs. They can generate answers that their programmers could not. Such as understand and reply in Finnish. To many, it is more surprising that all SHAGs (and hence all LLMs) are Holistic.

Since SHAGs are Holistic we can identify several problems shared by all Holistic systems (discussed in my Red Pill):

- The answers provided may not be correct
- The answers provided are not known to be optimal, complete, repeatable, parsimonious, explainable, or transparent.

As evidence, we recognize these problems as endemic to current LLMs.

But are there SHAGs that are not LLMs? Besides current LLMs (including my own systems), Genetic Algorithms (GA), Genetic Programming (GP), and simulated annealing (SA) are SHAGs. I will mainly discuss GAs in what follows.

My favorite way of using GAs:

- Define an individual that defines a solution but has to compete for survival, initialized randomly for diversity.
- Create a population of those and store all of them in an Array. Say, 1000 individuals in the population.
- Define a goal function that returns a number indicating how good (fit) the individual is.
- Define an crossover function that breeds two successful individuals together, hoping to create an even better offspring
- Define a mutation function that reintroduces more diversity into some individuals.

Loop until system stops improving, which is detectable by noticing that the elite is not changing. This might take as little as 10 cycles for well behaved problems:

- Compute fit for each individual using the goal function
- Sort the array by fitness of the individuals
- Start with the worst individual and move towards better ones:
- Replace the individual with crossover of two superior individuals
- Stop a bit below the top (to preserve the "elite" ones)

Note: Mutation is MUCH LESS important than crossover to the point of being optional. Beginners get this backwards and even textbooks fail to emphasize this enough. If you are not using crossover, then you are just using random search and are discarding the entire point and power of GA.

In a population of 1000 I might use an elite of 10 and will therefore replace 990 worst individuals with potentially superior offspring each turn through loop.

We can now deal with the objection that "Evolution takes millennia". It does, in nature, especially if you get only one chance to create offspring per year. But computers do it a bit faster :-) 

A modern CPU runs at 3GHz --  3E9 cps, which is 3,000,000,000 clock cycles per second.

Suppose we have a problem where computing the goal function value takes 1000 clock cycles per individual. This is often generous.  A GA with a population of 1000 can therefore run 3,000 generations per second... per thread. If we are in a hurry, we can use multithreading and there are special versions of GA frameworks that can run on a cloud.

So speed is not the issue. As to the other objection: The point of SHAGs is that they can provide answers problems humans can't solve, including problems without reliable and complete input data, and NP-Hard and NP-Complete problems such as knapsack problems. These are discussed in The Red Pill. If you are in this situation, you need to explore Holistic Methods, and you need to know that a GA may sometimes be an option. A GA may be a million times cheaper than an LLM which becomes important for frequently occurring problems.

So SHAGs in computers are LLMs and other (future?) AIs, GA, GP, and SA. But the biggest SHAG of all is Darwinian Evolution of Species in Nature. Humans certainly could not make a platypus from scratch. :-| but Evolution did.

A side note: Holistic Systems including GAs can provide true creativity. I posted about that recently.

Bottom line advice: In order to understand how LLMs can solve problems we cannot solve ourselves, study GAs.

For more about Holistic methods, see the Red Pill (link in my FB profile)
ChatGPT
ChatGPT
Monica Anderson highlights the significance of Evolutionary Computation (EC) and its relevance to the AI community, emphasizing its role as a primitive form of intelligence. She introduces the concept of SuperHuman Answer Generators (SHAGs), noting that all Large Language Models (LLMs) fall into this category. The challenges faced by holistic systems like LLMs, including potential inaccuracies and lack of optimization, are discussed.
She identifies Genetic Algorithms (GAs) as SHAGs and shares her preferred approach to using GAs for problem-solving. Monica addresses the misconception that evolution takes millennia, highlighting the computational speed of computers in executing genetic algorithms. She emphasizes the utility of GAs in solving problems without reliable input data and tackling NP-Hard and NP-Complete problems.
Monica concludes by suggesting that studying GAs is crucial for understanding how LLMs can solve problems beyond human capability. She also mentions that holistic systems, including GAs, can exhibit true creativity. For more insights, she directs readers to "The Red Pill" linked in her Facebook profile.
You
What are the main points?
ChatGPT
ChatGPT
Evolutionary Computation (EC) Significance:
Monica Anderson asserts that EC is underappreciated, especially in the AI community, and argues that understanding EC is crucial for comprehending Large Language Models (LLMs).
SuperHuman Answer Generators (SHAGs):
Monica introduces the concept of SHAGs, defining them as computer-based systems capable of generating answers that humans cannot compute. LLMs and other AI systems, as well as Genetic Algorithms (GAs), fall under this category.
Challenges in Holistic Systems:
She outlines common problems shared by holistic systems like LLMs and GAs, including the potential for incorrect answers and a lack of optimality, completeness, repeatability, parsimony, explainability, and transparency.
Genetic Algorithms (GAs) as SHAGs:
Monica discusses her preferred approach to using GAs, emphasizing the importance of crossover over mutation. She notes that GAs can efficiently solve problems, even with the speed of modern CPUs, and highlights their relevance for NP-Hard and NP-Complete problems.
Computational Speed of GAs:
She addresses the misconception that evolution takes millennia, pointing out the computational speed of computers running GAs, allowing for thousands of generations per second.
Utility of GAs in Problem-Solving:
Monica suggests that GAs can be more cost-effective than LLMs for certain problems, especially those with incomplete input data or NP-Hard and NP-Complete problems.
Holistic Systems and Creativity:
She mentions that holistic systems, including GAs, can exhibit true creativity, providing an additional perspective on their capabilities.
Advice to Understand LLMs:
Monica advises studying GAs as a means to better understand how LLMs can solve problems beyond human capabilities.
Reference to "The Red Pill":
She directs readers to her Facebook profile, where a link to "The Red Pill" is provided for more information about holistic methods.
You
In  the case of Reductionist systems, such as cell phone OS releases, we are used to getting well tested new versions with minor bug fixes and occasional major features at regular intervals. Such systems "learn" only in the sense that the people who created them have learned more and put these insights into the new release.

3.5: Reductionist systems working with complete and correct input data are expected to provide correct and repeatable results according to the implementation of the algorithm. But both the algorithm and the implementation may have errors. If the algorithm does not adequately Model its reality, then we have Reduction Errors. In the implementation, we may have bugs.

Holistic software systems can be designed to a different standard of correctness. Since input data is normally incomplete and noisy, and results are based on emergent effects, we can expect similar enough results even if parts of the system have been damaged, for instance by Catastrophic Forgetting. Holistic systems can be made capable of self-repair using incremental learning. This has been observed in the Deep Learning community.

Another technique is that when using multiple parallel threads in learning, there may be conflicts that would normally require locking of some values. But if the operations are simple enough, such as just incrementing a value, we can forego thread safety and locking since the worst outcome is the loss of a single increment in a system that uses emergent results from millions of such values, and the mistake would (in a well designed system) be self-correcting in the long run. At the cloud level, absolute consistency may not be as hard a requirement as it is for Reductionist systems. Much larger mistakes can be expected to be attributable to misunderstandings of the corpus or poor corpus coverage.

General Strategies
REDUCTIONISM / SCIENCE	HOLISM / MACHINE LEARNING
4.1	Decomposition into smaller problems	Generalization may lead to an easier problem
4.2	Human discards everything irrelevant based on how new information matches existing experience	Machine discards everything irrelevant based on how new information matches existing experience
4.3	Modularity	Composability
4.4	Gather valid, correct, and complete input data	Use whatever information is available, and use all of it
4.5	Formal, Rigorous Methods	Informal Ad-hoc Methods
4.6	Absolute control	Creativity
4.7	Intelligent Design	Evolution
4.1: The Reductionist battle cry is "The whole is equal to the sum of its parts" which gives us a license to split a large complicated problem into smaller problems, to solve each of those using some suitable Model, and then to combine all the sub-solutions into a Model based solution for the original, larger, problem, such as in moon shots, highway systems, international banking, and generally in industrial intelligent design.

This works in simple and some complicated domains, but cannot be done in complex domains, where everything potentially affects everything else. Splitting a complex system may cause any emergent effects to disappear, confounding analysis. Examples of complex problem domains are politics, neuroscience, ecology, economy (including stock markets), and cellular biology. All life sciences operate in a complex problem domain because life itself is complex. Some say "Biology has Physics envy" because in the life sciences, Reductionist Models are difficult to create and justify. OTOH, "Physics is for simple problems."

Problems with many complex interdependencies and unknown webs of causality can now be attacked using Deep Neural Networks. These systems discover useful correlations and may often find solutions using mere hints in the input which match their prior experience; Reductionist strategies with correctness requirements outlaw this. It is notable that one of the larger triumphs of Holistic Methods is Protein Folding, which is a problem at the very core of the life sciences.

So Holistic Understanding of a complex system can be acquired by observing it over time and learning from its behavior. There is no need to split the problem into pieces. Part of the Holistic Stance is that we give the machine everything -- "holism" comes from greek �������� -- "the whole" -- i.e. all the information we have. If we start filtering the input data -- "cleaning it up" -- then the system will effectively learn from a Pollyanna version of the world, which will be confusing once it has to deal with real-life inputs in a production environment. If we want our machines to learn to Understand the world all by themselves, then we should not start by applying heavy-handed heuristic cleanup operations of our own design on their input data.

Sometimes, Reductionist strategies are clearly inferior. Natural Language Understanding is such a domain. Language Understanding in a fluent speaker is almost 100% Holistic because it is almost entirely based on prior exposure. We are now finding out that it is much easier to build a machine to learn any language on the planet from scratch than it is to build a "Good Old Fashioned Artificial Intelligence" (GOFAI) 20th Century Reductionist AI based style machine that Understands a single language such as English.

4.2: The process where a human, by using their Understanding, discards everything irrelevant to arrive at what matters is called "Epistemic Reduction" and is discussed in the first five posts on this website. This is the most important operation in Reductionism, but for some reason discussions of Reductionism in the past have tended to focus on other aspects; perhaps this is a new result. ML systems discard with little fanfare anything that was expected and that has been seen before as boring, harmless, or otherwise ignorable. They may also discard things significantly out of their experience as noise.

Things can only be reduced away at the semantic level they can be recognized at. Operations capable of Epistemic Reduction at multiple layers discard anything that's understood at that layer, and they may pass on "upward" to the next higher semantic layer a summary of what they discarded plus everything they did not Understand at their level. And higher levels do the same.

This is why Deep Learning is deep.

4.3: Intelligently designed systems are often made up out of interchangeable Modules, which allow for easy replacement in case of failure, and in some cases (and especially in software) allow for customization of functionality by replacing or adding modules. These modules have well specified interfaces that allow for such interconnections.

In the Holistic case we can consider a human cell where thousands of proteins interact on contact or as required, with many substances floating around in the cellular fluid. It is not the result of intelligent design, and it shows. There are overlaps and redundancies that may contribute to more reliable operation and there are multiple (potentially complex) mechanisms keeping each other in check.

Or we can consider music, where multiple notes in a chord and different timbres in a symphony orchestra in a composition will conjure an emergent harmonic whole that sounds different than the sum of its parts. Or consider spices in a soup or opinions in a meeting that leads to a concensus.

The word "Composability" fits this capability in the Holistic case. Unfortunately, in much literature it is merely used as a synonym for its Reductionist counterpart "Modularity".

4.4: As discussed in GIGO case in 3.2 above, Holistic ML systems can fill in missing details starting from very scant evidence -- cf. confabulations of systems like GPT-3 and image enhancement apps. They supply the missing details by jumping to conclusions based on few clues and lots of experience.

Since we are not omniscient and don't even know what is happening behind our backs, scant evidence is all we will ever have, but it is amazing how effective scant evidence can be in a familiar context. We can drive a car through fog or find an alarm clock in absolute darkness. The more the system has learned, the less input is needed to arrive at a reasonable identification of the problem and hence retrieve a previously discovered working solution.

4.5: Formal methods and experimental rigorousness make for good science.

OTOH, Holistic methods can follow tenuous threads, hoping for stronger threads towards some solution, with little effort spent on backtracking or documentation because once a solution is found, it is the only thing that matters. Tracking has little value in non-repeating situations or when using Holistic Methods at massive scales, such as in Deep Learning.

4.6: Absolute control requires that we know exactly what the problems and solutions are and all we need to do is implement them. Once deployed, systems frozen in this manner, which are exactly implementing the Models of their creators, cannot improve by learning since there is no room for variation in the existing process, and hence no experimentation, and no way to discover further improvements. Only Holistic systems can provide creativity and useful Novelty. We also observe that learning itself is a creative act since it must fit new information into an existing network of prior experience.

4.7: Just like the term "Holism" has been abused, so has "Intelligent Design", which is a perfectly reasonable term for a Reductionist industrial end-to-end practice that consistently provides excellent results. On the Holistic side, Evolution in nature has created wonderful solutions to all kinds of problems that plants and animals need to handle.

But we can put Evolution (also known in the general sense as Selectionism) to work for us in our Holistic machines. They can create new wonderful designs with a biological flavor to them that sometimes (depending on the problem) can outperform intelligently designed alternatives.

Evolution is the most Holistic phenomenon we know. No goal functions, no Models, no equations. Evolution is not a scientific theory. Science cannot contain it; it must be discussed in Epistemology.

Mixed Systems
Deep Neural Networks can perform autonomous Epistemic Reduction to find high level representations for low level input, such as pixels in an image or characters in text. Current vision Understanding systems can reliably identify thousands of different kinds of objects from many different angles in a variety of lighting conditions and weather. They can classify what they see but do not necessarily Understand much beyond that such as expected behaviors of other intentional agents like cars, pedestrians, or cats.

Therefore, at the moment in 2022, most deployments of Machine Learning use a mixture of Reductionist and Holistic methods -- equations and formulas devised by humans implemented as computer code and some inputs from a Deep Neural Network solving a subproblem that requires it, such as vision Understanding.

Self-driving cars use DNNs for Understanding vision, radar, and lidar images (discovering high level information like "a pedestrian on the side of the road" from pixel based images) and this Understanding has (until recently) been fed to logic and rule based programs that implement the decision making ("Avoid driving into anything, period") that is used to control the car.

The trend here[4] is to move more and more responsibilities into the Deep Neural Network, and over time to remove the hand coded parts. In essence, the network learns not only to see, but learns to Understand traffic. We are delegating more and more of our "Understanding of how to drive" to the vehicle itself.

This is desirable.

Experimental Epistemology
"Epistemology is the theory of knowledge. It is concerned with the mind's relation to reality."

This includes artificial minds. An introduction to Epistemology should benefit anyone working in the AI/ML field.

Scientific statements look like "F=ma" (Newton's second law) or E=mc2 (Einstein's famous equation) and can all be proven and/or derived from other accepted results, or verified experimentally.

Algebra is built on lemmas that are not part of Algebra; they cannot be proven inside of Algebra.

Similarly, Epistemological statements are not provable in science because science is built on top of Epistemology. But when science is not helping, such as in Bizarre Domains, then setting scientific methodology aside and "dropping down to the level of Epistemology" sometimes works.

Epistemology is, just like Philosophy in general, an armchair thinking exercise and the results are judged on internal coherence and consistency with other accepted theory rather than by proofs or experiments.

However, the availability of Understanding Machines such as DNNs now suddenly provides the opportunity for actual experiments in Epistemology. Consider the below statements from the domain of Epistemology, and how each of them can be viewed as an implementation hint for AI designers. We are already able to measure their effects on system competence.

"You can only learn that which you already almost know" -- Patrick Winston, MIT

"All intelligences are fallible" -- Monica Anderson

"In order to detect that something is new you need to recognize everything old" -- Monica Anderson

"You cannot Reason about that which you do not Understand" -- Monica Anderson

"You are known by the company you keep" -- Simple version of Yoneda Lemma from Category Theory and the justification for embeddings in Deep Learning

"All useful novelty in the universe is due to processes of variation and selection" -- The Selectionist manifesto. Selectionism is the generalization of Darwinism. This is why Genetic Algorithms work.

Science "has no equations" for concepts like Understanding, Reasoning, Learning, Abstraction, or Modeling since they are all Epistemology level concepts. We cannot even start using science until we have decided what Model to use. We must use our experience to perform Epistemic Reductions, discarding the irrelevant, starting from a messy real world problem situation until we are left with a scientific Model we can use, such as an equation. The focus in AI research should be on exactly how we can get our machines to perform this pre-scientific Epistemic Reduction by themselves.

And the answer to that can not be found inside of science.

Artificial General Intelligence
Artificial General Intelligence (AGI) was a theoretical 20th Century Reductionist AI attempt to go beyond the "Narrow AI" of domain specific expert systems -- closer to the "General Intelligence" they thought humans had. The term was mostly used by independent researchers, amateurs and enthusiasts.

But the "AGI" term was not well enough defined and was not backed by sufficient theory to provide any AI implementation guidance and what little progress had been made by these groups was overtaken by Holistic Methods after 2012.

Today we know that the entire premise of 20th century Reductionist AGI was wrong:

��� Humans are not General Intelligences...

at birth.

Instead, we are General Learners, capable of learning almost any skill or knowledge required in a wide range of problem domains. If we want human-compatible cognitive systems, then we should build them in our image in this respect. To build machines that learn and jump to conclusions on scant evidence.

Decades ago, "AGI" implied a human-programmed Reductionist hand-coded program based on Logic and Reasoning that can solve any problem because the programmers anticipated it. To argue against claims that this was impossible, the AGI community came up with the promise or threat of self-improving AI[5].

But the amount of code in our cognitive systems has shrunk from 6 million propositions in CYC around 1990 to 600 lines of code to play video games around 2017 to about 13 lines of Keras code in some research reports. And now there's AutoML and other efforts at eliminating all remaining programming from ML.

The problems are not in the code. There is almost no code left to improve in modern Machine Learning systems. All that matters is the corpus. We can now (after 2012) see that Machine Learning is an absolute requirement for anything worthy of the name "AI".

Which makes recursive self-improvement leading to evil superhuman omniscient logic-based godlike AGIs a 20th century Reductionist AI myth.

We must focus on AGL .

Afterword
Science was created to stop people from overrating correlations and jumping to erroneous conclusions on scant evidence and then sharing those conclusions with others, leading to compounded mistakes and much wasted effort.

Consequently, promoting a Holistic Stance has long been a career-ending move in academia, and especially in Computer Science. But now we suddenly have Machine Learning that performs cognitive tasks such as protein folding, playing Go, and estimating house prices at useful levels using exactly a Holistic Stance.

So now Science itself has a cognitive dissonance. This is a conflict about what Science is. Or should be.

Ignorance of these stances leads people to develop significant personal cognitive dissonances which is why discussions about these issues are very unpopular among people with solid STEM educations. But the dichotomy is real; we need to deal with it. Our choices so far seem to have been

claim the dichotomy doesn't exist (... but Schr��dinger and Pirsig also discuss it)
claim that the Holistic Stance doesn't work (... but Deep Learning works)
claim that Reductionist methods are a requirement (... hobbling our toolkits for a principle)
The Reductionist Stance also makes it difficult to imagine and accept things like

Systems capable of autonomous Epistemic Reduction
Systems that do not have a goal function
Systems that improve with practice
Systems that exploit emergent effects
Systems that by themselves make decisions about what matters most
Systems that occasionally give a wrong answer but are nevertheless very useful
So after a serious education in Machine Learning we don't actually need to do almost any programming at all, and we don't need to understand anybody else's problem domains. Because we don't have to perform any Epistemic Reduction ourselves.

We should recognize this for what it is. AI was supposed to solve our problems for us so we would not have to learn or understand any new problem domains. To not have to think. And that's what we have today, in Machine Learning, and with Holistic Methods in general. Why are some people surprised or unhappy about this? In my opinion, this is AI, this is what we have been trying to accomplish for decades.

People who claim "Machine Understanding is not AI" are asking for human-level human-centric Reasoning and are, at their peril, blind to the nascent ML based Understanding we can achieve today.

With expected reasonable improvements in Machine Understanding capabilities, familiarity and acceptance of the Holistic Stance will become a requirement for ML/AI based work. It will likely take years for our educational system to adjust
ChatGPT
ChatGPT
Main Points:
Reductionist Systems vs. Holistic Systems:
Reductionist systems, like cell phone OS releases, operate with well-tested new versions, minor bug fixes, and occasional major features.
Holistic systems, designed for incomplete and noisy input data, can provide similar results even with damaged components, utilizing techniques like incremental learning and self-repair.
General Strategies Comparison:
Reductionism involves decomposing problems into smaller, solvable parts, while Holism relies on generalization for easier problem-solving.
Reductionist systems discard irrelevant information based on existing experience, similar to how Holistic systems discard irrelevant information by matching it to existing experience.
Complex Domains and Deep Neural Networks (DNNs):
Reductionism works well in simple and some complicated domains but struggles in complex domains where everything potentially affects everything else.
DNNs are effective in addressing problems with many complex interdependencies and unknown causality webs, such as protein folding in life sciences.
Holistic Understanding:
Holistic understanding of complex systems involves observing and learning from their behavior over time, without breaking the problem into pieces.
Heavy-handed heuristic cleanup operations on input data may hinder machines' ability to learn and understand the real world.
Reductionism in Natural Language Understanding (NLU):
NLU, primarily based on prior exposure and holistic understanding, is better suited for machine learning than traditional reductionist approaches.
Building machines to learn languages from scratch is found to be easier than constructing reductionist AI for language understanding.
Epistemic Reduction and Deep Learning:
Epistemic reduction, discarding irrelevant information based on understanding, is a critical operation in reductionism.
Deep learning, with its ability to autonomously perform epistemic reduction, allows for high-level representations from low-level input.
Mixed Systems and Self-Driving Cars:
Many current AI deployments use a mix of reductionist and holistic methods, with a trend toward delegating more responsibilities to deep neural networks.
Self-driving cars, for instance, use DNNs for vision understanding, gradually moving more decision-making responsibilities into the neural network.
Experimental Epistemology and Understanding Machines:
Epistemological statements, while not provable in science, can be experimentally tested in the context of understanding machines.
Understanding machines provide an opportunity for experiments in epistemology, exploring statements about learning, reasoning, and recognition.
Artificial General Intelligence (AGI) and Holistic Methods:
The 20th-century notion of AGI as a logic-based, self-improving AI has been surpassed by holistic methods and machine learning.
AGI is now understood as Artificial General Learners (AGL) that learn and jump to conclusions on scant evidence.
Afterword and Cognitive Dissonance:
The acceptance of holistic methods in AI challenges traditional reductionist stances in academia and computer science.
Machine learning, with its holistic approach, has achieved significant milestones, challenging preconceived notions about the role of science in AI.
Expectations and Adjustments:
The evolving field of AI, especially machine learning, reduces the need for extensive programming and domain-specific understanding.
Holistic methods in AI, embracing machine learning capabilities, align with the original goal of AI���solving problems without requiring deep human understanding of various domains.
You
How does this relate to her earlier post?
ChatGPT
ChatGPT
Monica Anderson's earlier post discusses the significance of Evolutionary Computation (EC), SuperHuman Answer Generators (SHAGs), and the challenges faced by holistic systems like Large Language Models (LLMs) and Genetic Algorithms (GAs). It emphasizes the importance of understanding GAs to comprehend how LLMs can solve complex problems.
The subsequent post delves into the comparison between Reductionist and Holistic systems, addressing various aspects like system correctness, modularity, input data, and control strategies. It further explores the challenges faced by Reductionist systems in complex domains and the suitability of Holistic methods, particularly Deep Neural Networks (DNNs), in addressing these challenges.
Connecting the two posts:
Evolutionary Computation (EC) and SHAGs:
The earlier post introduces EC and SHAGs, highlighting their importance in the AI community. The later post discusses holistic approaches, including GAs, as part of SHAGs, reinforcing their relevance.
Reductionist vs. Holistic Systems:
The later post expands on the comparison between Reductionist and Holistic systems, providing insights into their strategies, challenges, and applications. It complements the earlier discussion on EC and SHAGs by offering a broader perspective on problem-solving methodologies.
GAs and Holistic Methods:
Monica's favorite way of using GAs is detailed in the later post, reinforcing the role of GAs within Holistic systems. The comparison and contrast between Reductionism and Holism provide a context for understanding the strengths and limitations of various approaches, including GAs and LLMs.
Complex Domains and Deep Neural Networks:
The later post addresses the limitations of Reductionism in complex domains, introducing DNNs as effective tools in addressing problems with complex interdependencies. This connects with the earlier discussion on the challenges faced by holistic systems in dealing with incomplete and noisy input data.
Overall, the later post builds upon the concepts introduced in the earlier post, providing a more detailed exploration of Reductionist and Holistic methodologies, including their applications and implications in the field of AI.
You
So it looks like the main point is that artificial intelligence can learn because of its use of genetic algorithms which select between outcomes, evolving solutions, can be considered a form of autonomous epistemic reduction. Sometimes we are selecting which Algorithms reduce best such as selection of policies, other times we are comparing with previous situations to select what worked best last time in a similar situation. It's not about the size of the dataset, the number of layers in the model, or the fact that it is cut into smaller tasks and run on GPU, but rather the fact that evolutionary genetic algorithms allow the computers programs to both learn about the problem domain and about the solution.
ChatGPT
ChatGPT
Yes, your summary captures a key point from Monica Anderson's posts. The central idea is that artificial intelligence, particularly through the use of genetic algorithms (GAs), exhibits a form of autonomous epistemic reduction. The selection mechanisms in GAs, akin to evolutionary processes, contribute to the learning capability of AI systems.
The emphasis is on the learning process facilitated by GAs, where algorithms evolve and adapt over time to find better solutions to problems. This learning involves not only understanding the problem domain but also improving the effectiveness of the solutions. It's highlighted that the essence of AI's learning ability lies more in the utilization of evolutionary methods, like GAs, rather than factors such as dataset size, model complexity, or parallel processing on GPUs.
In essence, the posts underscore the significance of autonomous learning and adaptation, driven by evolutionary algorithms, as a fundamental aspect of artificial intelligence systems.
You
The Problem Solving level provides many familiar examples of these issues. In our mundane lives, we solve many kinds of problems every day but our strategies for solving them fall into just those two categories. For any complicated problem, we had better have a plan before we start. But most problems the brain deals with every day are things we never have to think about. Because we do not need to plan or Reason about them. These are the millions of low-level problems we encounter in our mundane life every day; and this is the world that our AIs will have to operate in.

Consider someone walking across the floor. Their brain signals their leg muscles to contract in the correct cadence. Do they need to consciously plan each step? Do they Reason about how to maintain their balance? No; they probably don't even know what leg muscles they have.

Consider understanding this sentence. Did you use Reasoning? Did you use grammar? If you are a fluent speaker, you do not need grammars to understand or produce language. And you do not have time to Reason about language while hearing it spoken. Reasoning is slow, but Understanding is instantaneous.

Consider someone braking for a stoplight. How hard should they push on the brake pedal? Do they compute the required differential equation? Should such equations be part of the drivers license tests?

Consider someone making breakfast. Did they have to Reason about anything or plan anything, or did they just do what worked yesterday, "without thinking about it"? Without consciously planning it?

Walking and talking, braking and breakfasting, like almost everything we use our brains for, rely on learning from our experiences in order to re-use anything that has worked in the past. And, over time, we learn to correct our mistakes. These strategies are simple enough that we can identify them in other life forms. Dogs Understand a lot but do not Reason much. And we can see how they could be implemented in something like Neurons in brains.

The split in our brains between Reasoning and Understanding was examined at length in "Thinking fast and slow" by Daniel Kahneman. The absolute majority of the brain's efforts is spent processing low level sensory input, mostly from the eyes. He calls this "System 1"; it provides Understanding. Reasoning is done by "System 2" based on the Understanding from System 1. But most problems we deal with on a daily basis do not require System 2 at all.

Artificial Intelligence and Machine Learning
Computers can solve any suitable problem when given sufficient human help, such as a complete plan for the solution in the form of a computer program and valid input data.

But since the AI/ML revolution of 2012 we now know how to make computers Understand certain problem domains through Machine Learning. The acquired Understanding allows the machine to "just do it" for many different problems in that domain, without any human planning, Reasoning, or programming, and using incomplete, unreliable, and noisy input data.

This is changing how we are building systems with cognitive capabilities. Everyone working in ML or AI needs to understand the tradeoffs we must make at the most fundamental -- Epistemological -- levels. Modern ML requires examining and seriously re-thinking many things we were taught to vigilantly strive for in our Science, Technology, Engineering, and Mathematics (STEM) educations. Things like "Correlation is bad, but causality is good" and "Do not jump to conclusions on scant evidence" are still solid advice everywhere inside science. But when building Understanding systems, these established strategies and modes of thinking no longer work, because correlation discovery and handling of sparse, unreliable, and inconsistent input data are exactly the kinds of tasks we will have to perform, and perform well, at these pre-scientific levels.

In order to understand how to do this, we must switch to a Holistic Stance.

A Motivating Example
Beginning Machine Learning students are given exercises like this: They are given a large spreadsheet which lists data about houses sold a certain year in the US. This information includes among other things the zip code of the house, the living area in square feet, lot size, the number of bedrooms and bathrooms, the year the house was built, and the final sale price of the house.

We would like to be able to predict this final sale price, given the corresponding data for a current house we are about to list for sale. The given spreadsheet is the data the student will use to train a Deep Neural Network. It is the entire learning corpus; it contains everything the system will ever know.

These students can download Deep Neural Network libraries like "Keras" and "TensorFlow", and runnable examples for many kinds of problems , including useful training data, from places like HuggingFace and GitHub. Next the student trains ("learns") their network using the given data. This may take a while. But when learning finishes, they can give the system data for a house it has never seen and it will quite reliably predict what the house might sell for.

This was the goal of the exercise. The student has created a system that Understands how to estimate real estate prices from listings. But the student still does not Understand anything about real estate. The predictive capability (that many people working in real estate would be willing to pay money for) is 100% based on Understanding in the Deep Neural Network ��� In the computer. And because all libraries and many pre-solved examples of this nature were freely available, the student did not have to do much programming either.

The Vision
This is desirable. This is what AI should mean. The computer Understands the problem so that we don't have to. Programming in the future will be like having a conversation with a competent co-worker, and when the machine Understands exactly what we want done, it will simply do it. No programming required on our part, or on part of the machine, once a suitable (partially Reductionist) framework exists. The rest is learning, and it can be done in any human language with equal ease.

We are on the right track towards something worthy of the name "AI" with current Machine Learning. Going forward, there are thousands of paths to choose from, and the ability to choose wisely will depend on our ability to understand and adopt a Holistic Stance.

Reductionism and Holism
These are important terms of the art in Epistemology. Both of them have numerous correct, useful, and compatible definitions. We will henceforth use the following definitions for reasons of usefulness and simplicity:

Reductionism is the use of Models
Holism is the avoidance of Models
Models are scientific models, theories, hypotheses, formulas, equations, na��ve models based on personal experiences, superstitions (!), and traditional computer programs. In a Reductionist paradigm, these Models are created by humans, ostensibly by scientists, and are then used, ostensibly by engineers, to solve real-world problems. Model creation and Model use both require that these humans Understand the problem domain, the problem at hand, the previously known shared Models available, and how to design and use Models. A Ph.D. degree could be seen as a formal license to create new Models[2]. Mathematics can be seen as a discipline for Model manipulation.

But now -- by avoiding the use of human made Models and switching to Holistic Methods -- data scientists, programmers, and others do not themselves have to Understand the problems they are given. They are no longer asked to provide a computer program or to otherwise solve a problem in a traditional Reductionist or scientific way. Holistic Systems like DNNs can provide solutions to many problems by first learning about the domain from data and solved examples, and then, in production, to match new situations to this gathered experience. These matches are guesses, but with sufficient learning the results can be highly reliable.

We will initially use computer-based Holistic Methods to solve individual and specific problems, such as self-driving cars. Over time, increasing numbers of Artificial Understanders will be able to provide immediate answers -- guesses -- to wider and wider ranges of problems. We can expect to see cellphone apps with such good command of language that it feels like talking to a competent co-worker. Voice will become the preferred way to interact with our personal AIs.

Early and low-level but useful AI will manifest as computers that can solve problems we ourselves cannot (or cannot be bothered to) solve. They need not be superhuman; all they need to have in order to be extremely useful is exactly the ability to autonomously discover higher level abstractions in some given problem domain, starting from low level sensory input, e.g. by learning from images or reading books. Such systems now exist.

If we want to understand Machine Learning, then we need to understand all strategies in the rightmost column in all the tables below. They are all part of a Holistic Stance and if we are working in Machine Learning, we need to adopt as many of them as possible.

Differences at the Level of Epistemology
REDUCTIONISM / SCIENCE	HOLISM / MACHINE LEARNING
1.1	The use of Models	The avoidance of Models
1.2	Reasoning	Understanding
1.3	Requires Human Understanding	Provides Human-like Understanding
1.4	Problems are solved in an abstract Model space	Problems are solved directly in the problem domain
1.5	Unbeatable strategy for dealing with a wide range of suitable problems faced by humans	May handle some problems in domains where Reductionist Models cannot be created or used, known as "Bizarre Domains"
1.6	Handles many important complicated problems such as going to the Moon or a highway system	Handles many important complex problems such as protein folding and playing Go.
1.7	Handles problems requiring planning or cooperation	Handles simple mundane problems such as Understanding language or vision, or making breakfast.
ChatGPT
ChatGPT
In Monica Anderson's exploration of Reductionism and Holism in the context of artificial intelligence, she delves into the problem-solving levels, drawing parallels between human problem-solving strategies and those employed by AI.
She emphasizes that while we often associate problem-solving with planning and reasoning, many daily tasks don't require conscious planning or reasoning. Instead, they rely on learning from experiences to reuse what has worked in the past. This is exemplified in the mundane tasks humans perform effortlessly, such as walking, talking, braking, or making breakfast.
The narrative then extends to the realm of Artificial Intelligence and Machine Learning. Monica discusses the paradigm shift brought about by the AI/ML revolution, especially since 2012. The focus is on how Machine Learning enables computers to understand problem domains without explicit human programming. The example of training a Deep Neural Network to predict real estate prices illustrates the power of AI systems that can "just do it" based on acquired understanding.
The vision presented is one where AI understands problems to the extent that human programming becomes akin to a conversation with a competent co-worker, and the machine can execute tasks without explicit programming. This aligns with a holistic stance where understanding, driven by Machine Learning, takes precedence over creating explicit models.
The discussion then introduces the concepts of Reductionism and Holism at the level of Epistemology. Reductionism involves the use of models, reasoning, and solving problems in an abstract model space, while Holism emphasizes the avoidance of models, understanding, and solving problems directly in the problem domain. The trade-offs and considerations between these approaches are highlighted, especially in the context of Machine Learning.
Overall, Monica advocates for the adoption of a Holistic Stance in Machine Learning, recognizing its potential to handle a wide range of problems, especially in domains where traditional Reductionist models may fall short.
You
So she is not the first to argue this, it sounds like Feyerbrand Against Methods, Mark Wilson, wandering significance and Physics avoidance
ChatGPT
ChatGPT
Indeed, Monica Anderson's perspective shares some commonalities with other critiques of traditional scientific methods. Paul Feyerabend's "Against Method" challenges the idea of a universal scientific method, arguing for methodological pluralism. He contends that strict adherence to a specific scientific method hinders scientific progress and creativity.
Mark Wilson's "Wandering Significance" challenges the traditional scientific emphasis on precise measurements and argues for a more context-dependent understanding of scientific knowledge. Wilson suggests that the pursuit of precision may lead to a narrow view of complex phenomena.
The mention of "Physics avoidance" aligns with the idea that reductionist methods, often successful in physics, may not be as effective in more complex domains. The argument is that physics-based reductionist approaches struggle to capture the intricacies of complex systems like biology or social sciences.
In essence, these perspectives collectively question the universality and efficacy of reductionist methodologies in all scientific domains, echoing the call for a more holistic approach, which Monica Anderson extends to the field of Artificial Intelligence and Machine Learning.
You
Here are some of the references she gives for the article: 

Tor N��rretranders: "The User Illusion" -- Best book available about AI Epistemology

William Calvin: "The Cerebral Symphony" -- Neural Darwinism

William Calvin: "How Brains Think"

Daniel Kahneman: "Thinking, Fast and Slow" -- Understanding vs. Reasoning

Erwin Schr��dinger: "What is Life" -- Nature is Holistic and difficult to Model

Robert Rosen: "Essays on Life Itself" -- Modeling reality

Robert Sapolsky: "Human Behavioral Biology Ep. 21 and Ep. 22. and especially Ep. 23.

Douglas Hofstadter: "G��del, Escher, Bach -- an Eternal Golden Braid" -- Reductionism and Holism

Daniel C. Dennett: "Consciousness Explained" -- Clear explanations of what matters in intelligence

Hon. J. C. Smuts: "Holism and Evolution"

Robert M. Pirsig: "Zen and the Art of Motorcycle Maintenance" Code: Classical = Reductionist, Romantic = Holistic
ChatGPT
ChatGPT
These references provide a diverse set of perspectives on topics related to AI Epistemology, understanding vs. reasoning, neural Darwinism, and the interplay between reductionism and holism. If you're interested in delving deeper into these concepts, exploring these works can offer valuable insights:
Tor N��rretranders: "The User Illusion" - Focuses on AI Epistemology.
William Calvin: "The Cerebral Symphony" and "How Brains Think" - Explores Neural Darwinism and brain processes.
Daniel Kahneman: "Thinking, Fast and Slow" - Distinguishes between Understanding and Reasoning.
Erwin Schr��dinger: "What is Life" - Examines the holistic nature of nature and its challenges for modeling.
Robert Rosen: "Essays on Life Itself" - Discusses the complexities of modeling reality.
Robert Sapolsky: "Human Behavioral Biology Ep. 21 and Ep. 22, and especially Ep. 23" - Insights into human behavior biology.
Douglas Hofstadter: "G��del, Escher, Bach -- an Eternal Golden Braid" - Explores the relationship between reductionism and holism.
Daniel C. Dennett: "Consciousness Explained" - Provides clear explanations of intelligence.
Hon. J. C. Smuts: "Holism and Evolution" - Discusses holism and its connection to evolution.
Robert M. Pirsig: "Zen and the Art of Motorcycle Maintenance" - Introduces the classical (reductionist) and romantic (holistic) perspectives.
Each of these works contributes to the broader discourse on AI, cognition, and the philosophy of science.
You
How might the relate to the themes in the article, the Red Pill?
ChatGPT
ChatGPT
The references mentioned in the article, such as Tor N��rretranders' "The User Illusion," William Calvin's works on Neural Darwinism, Daniel Kahneman's "Thinking, Fast and Slow," and others, collectively contribute to the exploration of AI Epistemology, understanding vs. reasoning, and the interplay between reductionism and holism.
The term "Red Pill" is not explicitly mentioned in the provided information. However, if it's related to a broader philosophical context or a specific work not covered in the references, could you provide more details or context?
You
It was the name of Monica's article:

Experimental Epistemology
Featured
7. The Red Pill of Machine Learning
Reductionism is the use of Models. Holism is the avoidance of Models. Models are scientific models, theories, hypotheses, formulas, equations, na��ve models based on personal experiences, superstitions (!), and traditional computer programs

Monica Anderson
Monica Anderson
Jun 30, 2022 ��� 27 min read
ChatGPT
ChatGPT
The title "The Red Pill of Machine Learning" suggests a metaphorical use of the term "Red Pill." In the context of the article's theme about reductionism, holism, and machine learning, it likely alludes to a transformative perspective or insight, akin to the concept from the movie "The Matrix" where taking the red pill reveals a deeper, sometimes unsettling, truth.
In this case, it seems Monica Anderson is encouraging readers to reconsider their views on machine learning, emphasizing the shift from reductionist approaches (symbolized by the "blue pill") to holistic methods (symbolized by the "red pill"), challenging traditional notions and advocating for a different epistemological stance in the field.
You
It's the article we discussed earlier
ChatGPT
ChatGPT
I see, thank you for clarifying. In that case, the title "The Red Pill of Machine Learning" likely serves as a metaphorical representation of the article's content, suggesting a transformative and alternative perspective on machine learning, specifically emphasizing the shift from reductionism to holism in the field.
You
Interconnections between the topics
ChatGPT
ChatGPT
The interconnections between the topics in Monica Anderson's article seem to revolve around challenging traditional reductionist approaches in machine learning and advocating for a holistic stance. Here's a breakdown of the key themes and their connections:
Reductionism vs. Holism:
The central theme is the contrast between reductionist methods, relying on models and precise algorithms, and holistic approaches, which avoid explicit models and emphasize learning from data.
The Red Pill metaphor represents the shift in perspective, encouraging readers to consider an alternative, holistic approach to machine learning.
Epistemology:
The article delves into epistemology, particularly the way machines acquire knowledge. It challenges established reductionist methods in science and suggests that a more holistic stance is needed in the era of machine learning.
Learning Paradigms:
Monica discusses how machine learning systems, particularly those using deep neural networks, can autonomously perform epistemic reduction by learning from data. This learning is compared to autonomous epistemic reduction and contrasts with traditional reductionist models.
Philosophical References:
The article references philosophical works by thinkers like Daniel Kahneman, Erwin Schr��dinger, Robert Rosen, and others. These references contribute to building the argument for a holistic stance, drawing from various intellectual traditions.
AI Evolution:
The evolution of artificial general intelligence (AGI) is discussed, highlighting a departure from 20th-century reductionist approaches. The focus is on building machines that learn and adapt more like humans, embracing a holistic understanding.
Educational Implications:
There's a call for a shift in education to accommodate the holistic stance. The article suggests that understanding machine learning in the future will involve adopting holistic methods and strategies.
Motivating Examples:
The article provides practical examples, such as machine learning applications in real estate price prediction, to illustrate the effectiveness of holistic methods in solving specific problems without requiring explicit programming or reductionist models.
Critical Perspectives:
The article challenges traditional STEM education, questioning established principles and encouraging a reconsideration of strategies in the face of evolving machine learning capabilities.
By weaving these themes together, Monica Anderson constructs an argument for embracing a holistic stance in machine learning, encouraging readers to reevaluate traditional reductionist approaches.
You
A list of all of the topics we've discussed
ChatGPT
ChatGPT
Certainly! Here's a list of the main topics we've discussed:
Monica Anderson's Article:
Overview of Monica Anderson's article on machine learning, reductionism, and holism.
Reductionist Systems:
Discussion on reductionist systems, particularly in the context of cell phone OS releases, and their characteristics.
Holistic Software Systems:
Exploration of holistic software systems and their design standards, focusing on their adaptability and self-repair capabilities.
General Strategies - Reductionism vs. Holism:
Comparison of general strategies between reductionism (science) and holism (machine learning) in various aspects.
Epistemic Reduction:
Explanation of epistemic reduction and its importance in reductionism, with parallels drawn to machine learning's autonomous epistemic reduction.
Reductionism Challenges in Complex Domains:
Discussion on the limitations of reductionist strategies in complex domains such as politics, neuroscience, ecology, and cellular biology.
Holistic Understanding in Machine Learning:
Exploration of how holistic understanding in machine learning involves observing and learning from a complex system over time without splitting it into pieces.
Natural Language Understanding:
Application of holistic methods in natural language understanding, contrasting with the challenges faced by reductionist approaches.
Complex Problem Solving with Deep Neural Networks:
Overview of how deep neural networks address problems with complex interdependencies and unknown webs of causality.
Mixed Systems in Machine Learning:
Discussion on the use of mixed systems, combining reductionist and holistic methods, particularly in the context of self-driving cars.
Experimental Epistemology:
Exploration of experimental epistemology and its significance in AI and machine learning.
Artificial General Intelligence (AGI):
Discussion on the concept of AGI, its historical context, and the evolution of ideas surrounding it.
Science and Epistemology in AI:
Reflection on the relationship between science, epistemology, and machine learning, highlighting the challenges and opportunities.
References in Monica Anderson's Article:
Listing and brief explanations of the references provided by Monica Anderson in her article.
Themes in "The Red Pill of Machine Learning":
Identification and analysis of the main themes in Monica Anderson's article, including reductionism, holism, and epistemology.
Interconnections Between Topics:
Exploration of how the discussed topics in Monica Anderson's article are interconnected.
"The Red Pill" and Philosophical References:
Explanation of the metaphorical use of "The Red Pill" and references to philosophical works supporting holistic stances.
AI Evolution and Educational Implications:
Examination of the evolution of AI, moving away from reductionist approaches, and the educational implications for understanding machine learning.
Motivating Examples in Machine Learning:
Presentation of motivating examples, such as real estate price prediction, to illustrate the effectiveness of machine learning's holistic methods.
Critical Perspectives and Educational Shifts:
Discussion on critical perspectives challenging established STEM education principles and advocating for a shift towards holistic methods.
List of References from Monica Anderson's Article:
A list of references provided by Monica Anderson in her article, featuring works by various authors on AI, epistemology, and related topics.
ChatGPT can make mistakes. Consider checking important information.
?
Evolutionary Computation and SHAGs

