And without further ado, I'm Scott Alexander of Astral Codex 10.
This is a man who needs no introduction, Nate Silver.
We are extremely grateful to have him here today.
My plan is I'm going to ask him a couple of questions.
Then I will open up the floor to any of you
who want to ask questions.
Do we have an audience, Mike?
Great.
Then let's go.
So, Nate, there are about 200 people here today.
It's our most crowded session.
None of these people care about either of us at all.
None of our triumphs, none of our setbacks.
They all want to know who is going to win the election.
I think we're past the point now where you can honestly
call it a toss up.
I think if you had a free wager to place
on any of the many prediction market sites,
and I think you'd probably at 50-50 won a bit, Trump.
Maybe not much more than 50-50.
But so it's a classic case of having a prior versus posterior,
the prior being that usually incumbent,
selected incumbents win re-election.
The economy is good, depending on how you measure it.
Not good without some speed bumps.
I mean, obviously, prices are a big concern for voters.
But if you knew nothing else, if there had been no polls,
your prior would be that Biden would win at 70% likelihood.
We are into June now.
Trump has had a very consistent lead in polls and swing
states of two or three points.
I think we're at the point where the balance tips
a little bit toward that polling data point.
Probably when we have the 538 model, the Silver Bulletin
model launching in a few weeks, I haven't run the numbers yet.
My hunch is that it will say 55% or 60% Trump
or something like that.
Now, I've been wrong before about what my model says.
We have a complex version of an economic calculation.
I don't know what that will say either.
And there's been some movement in the polls toward Biden
since Trump's conviction.
But I think it's a little bit dishonest to just say,
it's a way to cover your ass and not, you know,
you guys understand 55% doesn't mean 99%.
The rest of the world might not.
This might get aggregated and thrown on Twitter.
But that's my honest assessment is like,
I think at this point, Trump is a very slight favorite.
Thank you.
Now that we've gotten that out of the way, I wanted to ask you.
I think one of the grievances of this community
is that the media is not made of forecasters.
The media is made of idiots who don't
deserve to have opinions expressing those opinions
anyway.
And then you have all of these super forecasters
and prediction markets and so on
that aren't being taken seriously.
You are the one exception to this.
You are a great forecaster who has managed to become
kind of worldwide known as a great forecaster
and have people consult you on their opinions.
So my question is, let's say there
is a almost Nate Silver quality forecaster in the audience
wondering how to become Nate Silver levels of famous.
What's that pathway?
What's your origin story for how you succeeded
where nobody else has done this?
I mean, my origin story involved kind of being
in the right place at the right time.
But it was also very circuitous, where
I took a consulting job out of college.
I was a transfer pricing consultant for KPMG,
which is just as exciting as it sounds.
In 2004, I discovered the then nascent world of online poker.
This is in the middle of what's now known as the poker boom,
where poker was on ESPN a lot, an amateur accountant named
Chris Moneymaker, great poker name,
won the World Series Poker Main Event,
and touched off really, really juicy soft poker games
that I kind of played after coming home from work,
and then going to the bar, and then coming home at 10
at night, and the games are so juicy
that I could still make a lot of money anyway
for a couple of years.
So quit my consulting job to play poker
and work on baseball forecasting for the group baseball
Respectus, which is still around, unfortunately.
And then in 2006, Congress passed a law that basically
banned internet poker, technically not, but de facto.
That got me more interested in politics.
I wanted to see the assholes who put me out of my livelihood
vote out of office, which a lot of them were actually.
And that kind of, with more time on my hands,
I was frustrated with political coverage
and kind of tried to apply the way we used analytics
and baseball toward politics was the rough idea
and founded 538.
And then 538 was the beginning of an inflection point
in much more interested in politics with Barack Obama.
And then you had Donald Trump come along eight years later.
But it's been an interesting time.
But look, I think people kind of wanted a real life sequel
to Moneyball or something.
And so you kind of fit this cultural need
and then become kind of popular for the wrong reasons,
I think, in some ways.
That's kind of like, I'm not sure I would necessarily advise.
I mean, it's good in some ways.
It's led to financial well-being and recognition
and things like that.
But I think I still am kind of fighting in some ways,
like being well-known for the wrong reasons.
Because people think I'm some magic oracle and not someone
who is more about uncertainty.
I think people thought I was some type of partisan Democrat
because in 2008 and 2012, we had Obama with more chance
of winning the consensus.
So it's been a, look, I wouldn't trade it.
I wouldn't not have taken that path.
But it was A, kind of random, and B, maybe not
very generalizable.
OK.
OK.
So what I would say is, look, differentiate yourself,
especially kind of in an AI-driven world
where we can talk about this more.
Kind of the average or baseline is more likely to rise.
Like, don't be afraid.
I mean, this is the one conference
that might be dangerous to say.
Like, oh, just be yourself.
That might usually it's good advice for people,
maybe not in this conference.
But don't be afraid to differentiate.
Don't be afraid to be a little bit polarizing,
to add something kind of unique to the world.
Don't be afraid to specialize too much.
Those are things that I don't worry too much about the haters.
I mean, those are things that I think
are relatively robust pieces of advice.
OK.
I'm bored of the human interest questions.
I want to ask you your probabilities of various things.
Oh, shit.
OK.
OK, let's start.
And feel free to pass or give explanations.
Probability that Democrats keep the Senate next election.
25%?
OK.
Probability that AI destroys the world before 2100.
So in the book, there's actually a range.
Like, a lot of people I duck this question by giving a range,
in part because I think there are very different definitions
of what PDOOM means from, like, the Eliezer,
like literally every human cat and mouse is eradicated
from the earth to, like, that we kind of lose agency.
That's kind of the maybe more loose definition.
The range given in the book is kind of punting on being pinned
down.
It's 2% to 20%, which I see as reflecting the consensus.
I mean, the expert surveys tend to be in the range of 5% to 10%.
So I just kind of take that and expand the range outward
further.
Despite spending a ton of time talking to dozens of people
in the expert community for the book,
I couldn't quite converge on an opinion.
It's a little bit weird.
I guess I find kind of compelling cases,
both in the doomer and anti-doomer cases.
I will say that when I was going from the first draft
of the book to the second draft, I
pared down the top end of that range.
It was originally 2% to 25%, and now it's
2% to 20%, which is still a ridiculously large range.
I do think it's somewhat material that GPT-4 came out,
I guess, March 2023.
I think there's been, maybe in the wrong room to say this,
I think there's been a little bit of a plateau.
I think if you had asked people in March 2023,
what would you expect to have seen in LLMs by June 2024,
I think we'd actually be a little bit under what
we've seen in that development.
And I think we're kind of at an inflection point
where that might be material.
But look, in any other room, I'd be saying, yes,
you have to take this risk seriously, even
for the lower end.
The expected value loss could be very high.
Also, the upside could be very high and the fact
that transformers have done miraculous things
that were far beyond people's expectations.
We have this kind of machine that is almost human-like
and it's ability to do verbal reasoning.
I mean, that's a very impressive development,
but maybe it's an unsatisfactory answer,
but that's kind of the short-ish version.
No, it's a good answer.
I'm just trying to figure out whether I
should take the geometric mean of that range
or the arithmetic mean.
Probability that in 15 years, the United States
is significantly more authoritarian.
I know significantly as a weasel word answer,
however you prefer.
20%?
I mean, look, are we talking about a kind of tail risk
from Trump being elected or some other Trump-like figure?
I mean, that's one way it could happen.
I'm kind of asking for your overall probability.
25% maybe?
Yeah, maybe kind of 10% from some Trump-adjacent scenario
and 10% from some AI-adjacent scenario.
Well, how recently are we talking about?
Or how far in the future?
I said 15 years.
Yeah, and then maybe 5% from left-wing authority,
something like that.
25% seems not crazy.
OK.
You've written a little bit about this.
Do you have any other opinions on how we could prevent it
or what we should be doing?
I mean, look, I am a big believer in liberal values,
liberal as opposed to left, necessarily.
I think kind of continuing to kind of preach
the gospel of free speech and well-regulated,
but free-ish markets, I think.
I think all that stuff is still pretty important.
I don't know, although I've become less confident, right?
I mean, I'm still someone who kind of rings the bell for,
hey, if you have better information out there
and people are kind of rational in the long run,
maybe that's how I'm going to take a little bit harder
to make, I suppose.
But no, look, if I had some genius solution,
like how do we kind of prevent authoritarianism,
then believe me, I'd be writing about it.
And I'm not sure that I do, and maybe I'm just
being stubborn by kind of like doubling down
on my political priors and saying, yes, just kind
of classical liberalism mixed with a generous welfare state
is, I mean, that's a kind of classic center-left liberal
positions.
And maybe those aren't working.
I don't know, right?
And maybe I haven't thought enough about this.
Probability that in 15 years, it's a cliche
that minorities obviously vote Republican.
I mean, look, the Black vote is still
going to likely be 82 or 85 or 87% Democratic.
I mean, the Hispanic vote might be more 50-50.
I mean, I think the Asian-American vote might be 70-30.
You're going to get definitions of what counts as a minority
group and not, and that gets complicated.
I think you see some reversion to the mean
where Democrats are becoming the party of the college-educated
class.
And there are racial differences in kind of who
has college degrees.
It's a lot of white people.
It's a lot of Asian people.
It's fewer Black and Hispanics, although Hispanic college
attendance rates are increasing quite a bit.
But if you have some big regression analysis,
then race still plays a fairly major role, I think.
I do think the Republican Party lacks visionary leaders,
I suppose I'd say.
I mean, maybe Trump has a certain type of political talent.
But Trump is not very popular.
I think the reason he's winning is
because Biden probably shouldn't be running again
at 81 years old, and inflation has caused a lot of problems
for incumbents all around the world,
including in France and the UK, which
are going to have elections next month.
Even India, which did not have much inflation.
Modi way underperformed what Poles said,
although it didn't get re-elected.
So yeah, if you kind of were able to get rid
of the Trumpian element of the GOP,
and then they could probably make a pretty good argument,
but they still are going to nominate a lot of bad candidates.
There is still, obviously, I think,
a fair degree of racism in the United States,
I think, that's still more concentrated in the GOP.
So I think those are some barriers on their upside.
Probability that the Democrats win the presidency
this election conditional on Biden dropping
dead tomorrow of natural causes.
Well, I'm trying to figure out how to nominate Harris
or have an open process.
I don't want to get aggregated in too many headlines.
Look, I think 50-50.
And given that it was below 50 before, then I don't know.
I mean, yeah.
I mean, if, look, probability, if Joe Biden had retired
a year ago, or not retired, but said,
I'm not going to run for a second term,
and we're going to have an open contest where
you have the optionality of seeing how people perform,
then I think Democrats would be favored, right?
But no matter what they do now, it's pretty suboptimal.
And by the way, if you had a more popular vice president,
I think Biden might not have run for a second term.
That's not based on any inside info.
The White House probably hates my guts at this point.
But I think that's a big problem here,
too, which is that the kind of natural succession that he kind
of made a lot of pretty implicit, almost
virtually unexplicit promises in 2020
that, like, I'm running as a bridge
to the next generation of Democrats, right?
So it's not just that, like, he's old.
It's also the rationale for his campaign in 2020.
It's an emergency situation.
Trump is screwing up on COVID and other things.
We need an elder statesman to come and write the ship
to get it back to port.
And now we're at port, and we're kind of in a peacetime
situation, and he's still running again.
I mean, I think that's if he doesn't beat Trump,
it's going to come down as one of the biggest mistakes
in American political history, right?
Probability that in 15 years, prediction markets
will be as familiar a feature of the media landscape
as polls or infographics or any of the other familiar features.
20%?
Really, tell me more.
And I should disclose here.
I am going to begin a kind of advisory role
to prediction markets company soon.
We're not ready to announce that quite yet,
but that's full disclosure, right?
Because I think it's a, well, I don't know.
I mean, the obvious analogy in some ways
is to sports betting, which has gotten very ubiquitous.
I'm not sure that the kind of average kind of consumer
of political news as opposed to other categories,
including sports for that matter,
is necessarily all that quantitatively minded.
I think they mostly want to be reaffirmed in their beliefs.
I know it's kind of a cliche, but I
think it's a true cliche for the most part.
You know, I think there's in some ways more,
I mean, it's probably the last panel if you saw it.
It's kind of like, I think in some ways,
the rationales are more interesting than the number.
I don't look.
I think prediction markets are an extremely, extremely
valuable and important product.
I think they have a particular constituency
that is maybe not as broad as people think.
By the way, I think there also might be a backlash to sports
betting too, a little bit, where people
think that having the minus 400 on every screen and things
like that has gone a little bit too far.
But I'd say 80% that they're more widespread
by a substantial amount, but only 20%
that they've kind of overtaken the polls
and more traditional horse race coverage.
All right, thank you.
I am done torturing Nate.
I'm happy to get questions from the audience.
These don't have to be in the form of probabilities.
They can be anything you want.
Why don't you decide who gets the microphone?
I'll give them a check.
Yeah.
So why weren't your online polls or your online models
during your peak election coverage from, say, 2016-2020?
Why weren't they Marangales?
You'll nail the tailing criticism.
So what do you mean?
Like, I'm pretty sure you never really
disagreed with Taylor's specific claim
that if you were to bet money on your predictions
on any given day, someone could arbitrage
against those online models.
Is that true?
Yeah, so I mean, the question is like,
so why weren't they reflected in prediction market odds
or whatever?
Why didn't you correct for the fact
that you could bet against your future self
under these models?
Oh, no, I just think that's just wrong.
I mean, I think that's OK.
Yeah, I disagree with Taylor.
I mean, Talib, actually, he used a version of the forecast
called the nowcast, which is what you would predict today.
He didn't actually understand what the forecast was saying.
He's a brilliant guy in some ways,
but he's a fucking idiot in other ways,
and he didn't bother to check his work.
Hey, so what's your probability that the US survives
the war with China if we have Trump seeing us through it?
I'll use my get a jail-free card on that one.
I'm not a foreign policy expert.
Hi, so if I remember when you were at the New York Times,
there was an issue that you couldn't bet
or it couldn't advertise betting,
you couldn't have any relationship to it.
And I think you've been beholden to large media corporations
for a while.
Now you're free.
Are you doing lots of betting now?
I am not betting on politics, but I
am doing some consulting for a financial company that's
election-related.
So between that and having a subscriber newsletter,
where we will eventually sell the model there
beginning in a few weeks, I already
feel like I have a lot more skin in the game
to use Tell-Eb's phrase, which is good, by the way.
It was very weird, as somebody who believes in incentives,
just have spent 10 years working for one of the world's
largest media corporations with no incentive-based
compensation whatsoever.
And for the first eight and a half of those years,
I worked really fucking hard despite that.
And then last year and a half, I kind of de facto
quiet quit to write the book.
But don't tell anyone that, fortunately,
in public or anything like that.
But yeah, no.
So I feel like my incentives are aligned,
but I'm not at this point making bets in the markets.
And I would probably think that me going in betting on Poly
Market or something or Calci on the election,
I mean, that would feel a little bit weird, I think still,
since we could have market-moving influence.
But yeah.
Hey, Nate, I am curious how you think about risk.
You've obviously just written a book about risk,
and all these different areas, whether it's gambling or hedge
fund traders or AI.
But there's a kind of risk that is more personal and harder
to quantify, for instance, the risk of leaving a corporate job
and starting a sub-stack, the risk of moving to a new country,
moving to a new city.
All of these are risks.
And in your personal life, do you
operate where you actually try to take major decisions
like that, build a model around it,
actually put some kind of numbers?
Or do you operate more on feel when
it comes to those kind of things?
Because that's a form of risk as well.
Look, I think in general, most people
are probably too risk averse when it
comes to that type of decision.
Annie Duke, another former poker player,
wrote a book called Quit that covers
some of the evidence on this where in general,
people seem to be happier when they make a career change,
make a lifestyle change, make a change of location
in terms of where they're living,
and their relationships and things like that.
People are probably too risk averse from years
of evolutionary training of being in this kind of subsistence
era where if you screw up, you might die.
We have much more robustness and resilience now.
I'm not someone who's usually using a spreadsheet
to make personal decisions, but I do take my time with it.
I mean, I've settled on a combination of things now,
including the book and the newsletter and consulting
instead of jumping at the first opportunities I might have had.
And it took a while.
I mean, it took a while for me to kind of figure out
what I thought the right opportunities were,
and I'm pretty deliberate about the big decisions.
I think sometimes people can think to death
about some minor decision like, where
are they going to go to dinner, right?
And then big things like, should I quit my job?
Or what should I do with my life?
They're kind of intuitive.
And there's a role for intuition,
but hopefully it's providing some approximation
of a good answer.
In a Twitter thread a couple months ago,
you said that you'll be talking about the effect of altruism
community in your book, and that you
offer a substantial amount of critique of the community.
And I'm curious if you could preview that a little bit.
Sure.
I think there are a couple of.
So some of my beef, I would say, is probably
with certain kinds of utilitarianism.
So in the middle of this kind of book about gambling and risk,
there's like a 3,500 page critique of kind of Peter
Singer, basically, I think.
Such part of it.
Part of critique, too, is that the book
deals with people who are very analytical.
It's kind of the books really about people
who are at the cross of being very analytical
and very competitive, which describes poker players.
It describes venture capitalists in Silicon Valley.
It describes sports better.
It describes a lot of the world.
Whereas EAs are very analytical, but not very competitive,
at least in a monetary sense, which in some sense
seems really good.
But in some sense, I think, so one critique actually I have
is that I think EA can be a little bit too trusting
at times, that there is too much trust for people
to be acting in good faith.
I mean, I also talked a lot to SBF for the book.
And maybe it's an inconveniently timed for EA,
but I think that's a non-trivial critique.
Look, I think EA sounds a little bit like what Tyler Cowan said.
I think EA attracts an extremely high ratio of very smart
and intelligent people, and that means a lot.
I think people's hearts really are in the right place
for the most part, and that means a lot.
I think EAs do a lot of kind of thankless work
of being willing to be weird and say things that
are not mainstream, and I think that is extremely
worthy and valuable.
I probably err on the side of being warmer
toward rationalism more broadly than kind of the EA brand
more specifically.
The book's pretty sympathetic to rationalism, to prediction
markets, for example.
It's trying to give a pretty honest and detailed history
of all the figures in EA slash rationalism and that distinction,
including Scott and things like that.
So I hope the book will be scriptulously fair, right?
And I would say, too, the fact that kind of SBF
is a big part of this world, and he's in the middle of it,
I mean, I tried not to overweight that too much,
but that's a factor, too, in how the book
will end up getting written.
Your views on prediction markets seem to have changed a bit
over time, where you've always had a baseline respect for them,
but then in 2020, you were kind of very dismissive
about the predicted traders, and then that's gone back now.
And for what it's worth in 2020, their briar score
was relatively good on the state things,
and in 2022, you really beat them.
What are your thoughts on that journey?
I mean, for one thing, I think politics
is somewhat unique in that.
So if you look at sports betting,
it kind of forms a U-shaped curve in terms
of how beatable are the markets, right?
If you're an expert on Mongolian table tennis,
you can definitely beat the betting markets
for Mongolian table tennis.
The problem is they'll cut you off from betting more
than $5 a match the minute they realize that you're any good,
right?
On the other end of the tail of the U, as I call it,
it's something like the Super Bowl,
where there is so much public money,
that there's not actually enough sharp money to absorb it all.
So the Super Bowl, you can have plus-CV bets
by kind of fading the public sometimes, right?
Figure out what average Joe is doing, but the opposite side,
you might actually have after the House rake,
you might actually have a slightly plus-CV bet.
Presidential elections have historically
been on the extreme end of that U,
where lots of people have opinions about the election.
There has not been a large class of professional forecasters
of elections.
I think that is changing to some degree.
I mean, now that I was a free agent,
I was able to talk to different financial concerns
and hedge funds and things like that.
And clearly, without disclosing names,
clearly there are multiple firms that are now
like taking election forecasting very seriously.
But I think kind of in the circa 2016-2020 world,
then you had a lot of dumb money in those markets
in ways that make prediction markets maybe or make politics
like not the best example for prediction markets, right?
Because they're so public, and because there's
not this kind of group of experts that specialize in it
very much, apart from like a handful of people,
then it's more the exception than the rule, I think.
But I think it's going to probably
change at least based on the conversations I've
had with much more investment in as kind of everything
gets swallowed by politics.
I mean, I think financial firms feel like we
have to forecast politics well to forecast financial markets
well.
So I think that's in the process of evolving.
You've obviously done a lot on forecasting,
but you've also done a lot on explaining forecasting
to very wide audiences.
And I'm curious what you've learned
about that over the last 10 years
and how kind of optimistic or pessimistic you are about that
at this point.
Mm-hmm.
I mean, in some sense, kind of my more recent moves
reflect a certain sort of pessimism, I guess,
where it's like I want to try to talk to a narrower audience
that understands it more, maybe is
willing to pay for things that are behind a paywall,
for parts of the analysis, and things like that,
as opposed to trying to talk to a really wide audience.
You know, look, I think it's something of a misnomer
that, oh, people just don't understand probability.
It's a thing when people go to their doctor
and their doctor says there's a 30% chance of a cancer
reoccurrence if you do this.
But 20% if you change your lifestyle on these ways,
I think people have a pretty good intuitive grasp
of what that means, right?
If you say there's a 20% chance of rain,
they may or may not carry an umbrella,
but they kind of understand what that means.
I think it's more that kind of people's brains
are kind of quote unquote poisoned
by political partisanship.
And that affects it more than the numbers.
But yeah, I mean, the typical audience for politics
coverage is quite partisan.
And that's not the audience I want.
And so, and so, and I'm not sure to the earlier point
about kind of just as I don't know
that presidential elections are the best way to teach people
about prediction markets.
I'm not sure they're the best example for forecasting either.
I think people tend to see elections
as like their own special unique snowflakes
and not drawn from some larger probability
distribution of outcomes.
So sports is probably much better by comparison.
I think sports fans intuit there's
some degree of randomness in the outcome.
Whereas with politics, I'm kind of,
I'm not waving the white flag, but I'm trying to be more
selective in how I engage and trying to very deliberately
kind of steer away from being like the election forecast guy.
How many more questions do you have in you?
Yeah, Scott, this is fucking Scott Alexander.
He needs some questions too, people.
I'm happy to answer questions.
OK, not at all for Scott, sorry.
There's tens of dollars of fake money
writing on this question.
So have you made a manifold account?
Have you placed a bet?
And have you created a market?
No.
Sure, I mean, I love manifold.
Yeah.
OK.
I remember thinking that you were the only sane public figure
in the world when Johnson and Johnson paused its vaccine
on account of one death in 7 million cases.
Yeah.
I'm wondering if you intend to write more
about public health and the FDA specifically
and any ideas that we might have to stop it
from being so terrible.
Probably.
I kind of wonder if I had had my substack
during kind of the peak of the pandemic,
I wonder how audience captured it
would have gotten by COVID stuff.
No, look, I mean, COVID is one of those topics
on which I think I'm actually, in public health,
I'm kind of like punting on until the election's
over a little bit.
Even the very kind of long, like, root claim stuff,
I've kind of only browsed through even though it's a debate
I'm very, very interested in.
But yeah, I might get back to it at some point,
but I have to triage some stuff.
And when you're kind of on the newsletter
you learn a lot of tricks for like,
what can I actually write a good post in three hours?
What's going to kind of creep into like three days?
And so, and the public health stuff,
I think you want to get all the details right.
And so that's probably more of a post-November project.
In election modeling, what have you found
is the best way to deal with circular covariates,
like the polls affect the fundraising
and the fundraising affects the polls reciprocally?
So with the presidential model,
the presidential model is actually very simple, right?
It's just the polls and an economic index.
I guess in principle it could be some feedback
in the stock market because the stock market
can reflect election expectations.
It's one of the variables in the six variable economic index.
If you saw the previous panel with David Shore
and Kate Holland political forecasting,
this is more of an issue when it comes to
the congressional model where traditionally
the 538 model used expert ratings
from groups like the Cook Political Report.
But the expert raters actually look at
like what the 538 model says,
so it becomes very circular very quickly.
We probably will not have a congressional model
at Silver Bolton in 2024, but for 2026,
hopefully they'll be restored.
I'll probably just remove that component, right?
It was a little bit of a cheat anyway, I think.
I'd rather have a model that is purely
quote unquote quantitative and objective
and then you make your kind of subjective corrections
after that than this kind of mushy middle
uncanny valley in between, if that makes sense, right?
And I think kind of incorporating the expert ratings
apart from this pergurgitation problem
suffer from that kind of uncanny valley effect
a little bit too, where it was like kind of
subjective in a way that got a little bit weird.
The second question from now,
we will take for Scott Alexander.
That's the first question.
Oh, okay, hi.
Yeah, feel free to not answer this if you don't want to,
but in your personal investments, are you long AI?
Me? This was for an eighth.
I have a fair amount of Nvidia, so I guess yes.
Okay, so my question is for actually both of you.
So Scott Alexander, one of the questions you asked, Nate,
is about the conditional probabilities.
So regarding conditional markets,
if you could magically wave your hand
and create one conditional market that is very liquid
and gives a lot of information
on what conditional market would you like to see
in the world that doesn't exist today?
Tough question.
So I think I would really like to know more
about AI strategy, and the market about AI strategy
that comes to mind first is something like,
suppose everybody who was interested in AI risk
completely abandoned working with any companies whatsoever
said that AI companies were the devil,
treated them the same way
that global warming activists treat fossil fuel companies,
what would AI risk be then compared to
if those same AI activists did some kind of middle way policy
where they continue to cooperate with those companies?
There's a question that I'm thinking about a lot.
Would I necessarily trust prediction markets
to have a good opinion on that?
I guess it depends what we mean by very liquid.
I'd like to see some markets,
so maybe there are,
maybe haven't spent enough time looking around,
but more markets on kind of what the risks
of a Trump presidency are.
You'll hear Democrats say things like,
if Trump gets elected,
this is the last election we'll ever have, right?
Which I think is a low tail risk probability.
At the same time, January 6th was a very serious event
that in some ways suffers from the problem of like,
it was ultimately a near miss,
and people probably don't learn enough from near misses.
But I'd like the kind of people who use that rhetoric
to quantify it, both as kind of like a challenge to like,
okay, do you really mean that?
Are you kind of using rhetoric to try to rile people up?
But also to say like,
what scenario should people be relatively more
or less concerned about, right?
In 2020, a lot of the concern was,
oh, the courts, the courts will step in
and stop the vote count, right?
Which is not what they did.
The courts didn't really play ball at all
with Geo-Petian and against.
However, you had Trump kind of launch a physical
insurrection against the Capitol,
and that wasn't on people's bingo card.
But like, I think for like threat modeling,
and I think that would be valuable for a variety of reasons.
This question is for Nate over here.
How do you feel like your work has changed
the political economy of DC specifically?
Or yeah, I feel like, you know,
you arrived on the scene and made a lot of waves,
and there's a lot of money in politics.
And so how do you feel like your work has altered
that world and helped shape it?
I mean, I really don't know that world that well, right?
Like, I don't have a lot of friends in like politics.
You know, I like people in this community,
I like people in poker a whole lot,
and sports and things like that.
I've always been like a little bit of a square peg
in politics, and I live in New York and not DC.
I mean, in the kind of narrow market
for like election forecasting,
I think it's been filled in somewhat cynical ways, right?
There's kind of always gonna be like a market
for like the guy who always has good news for Democrats,
right?
Like that's a role that's filled,
and then like, you know, you keep doubling down every time
until Democrats have had election,
then you get your head chopped off,
some other guy pops up to replace you,
that kind of thing.
Look, I mean, certainly I think like the news media
has gotten more sophisticated with election coverage.
People have lots of complaints about the New York Times
and the Boston Post and things like that.
But if you go and like read like Times political coverage
from like the 1980s, it's like fairy tales, right?
They just make shit up.
They just make up narratives, whole cloth,
based on the prerogative of the author.
And now there are, I think, a lot more grounded
in reality and that's improved.
But you know, I wouldn't say there's not enough polling
being cited, right?
I'm not kind of one of those scolding people who's like,
oh, there's too much horseback coverage,
but like there's probably enough.
I mean, this year we've had the general election matchup
locked in for a long time and you've had like
page A1 polling stories, like a year in advanced election,
like that's probably overcorrecting a bit, I'd say.
But still, I think news coverage has been net-improved
and I don't know about like how campaigns are run.
I think the Biden campaign seems to be in a little bit
of denial about the polling, but for news coverage
it's improved for sure.
Yeah, my question is mostly for Scott,
but I appreciate your technique as well.
And it relates to the previous panel discussion, basically.
My version of what has been discussed partly at least there
is something like, well, we have been focusing a lot
on probabilistic answers to measure forecasting outputs
and maybe if we now focus more on the rationale
or the reasoning behind this, it might help to,
so forecasting more, the prediction markets
can take over the world finally.
So yeah, I was curious, Scott, what do you think about this?
If that's something that you think would really help
or you also see as a missing piece
or if you think it's a major contribution
to why prediction markets haven't taken over the world?
I think it depends on the application.
I think if we're talking about, let's say,
me writing a blog post, for example,
I recently wrote a blog post on,
I'm going to forget the exact number,
but California bill on regulating AI.
And it seemed like an obvious thing you would want
in that blog post is, is this bill actually going to pass?
And this was something that I didn't know.
Probably there are some lobbyists in Sacramento
who have a pretty good idea, but they're not telling.
And so I went to the manifold prediction market
and it had that.
I don't think having rationale would have helped at all
for that, like we know the reasons the bill might pass,
we know the reasons the bill might not pass
and it's kind of just a question of which side
is more powerful, what do people think?
And I think there are thousands of questions like that,
where you use the prediction market kind of as a way
to get acquainted with a subject
where otherwise you would just have no idea
about something very important.
I think what, I didn't get most of the last panel,
but I think what many of them were saying
is that if you're trying to convince a decision maker,
like a CEO, to use a prediction market in their planning,
then they want to know why it says what it says.
And I think that's extremely reasonable
and I think it's great that people,
that both people and AIs are working on that problem.
Hi, here.
This is a politics question, but definitely for both of you.
If you look at the like poly market or manifold graph
of Trump winning the primary over the last year or so,
it basically looks like a straight lineup
from like initially contested with the Santas
to like he was going to win,
which is not impossible,
but it's sort of a weird thing for a probability graph
to look like.
It's tricky with benefit of hindsight,
but do you think this was a fair estimate
at all times of the probability
or was the market sort of too slow
to realize that Trump was going to win?
I had bet money on Trump in like 2021 or something.
So I think it was too slow.
I think it's often reasonable to have a straight line graph
let's say Donald Trump just often does insane things.
And I think maybe in 2021,
what you were thinking was something like,
well, Trump seems beloved by the Republicans.
He's the natural choice,
but he's always doing these insane things
and getting convicted of crimes.
As time goes on,
maybe one of them will finally alienate people.
And it seems like instead with every passing month,
we've learned that no,
Trump's various insane crimes have not passed
whatever hypothetical bar we thought might have existed,
where that will kind of knock him down,
leave a place for DeSantis or someone to come through.
So I think people were generally like a fixed 10%
or something too low,
but I also think that the general shape of the graph
isn't that unreasonable.
I'd like to hear Nate on this also.
No, look, if you had a marker on one of the odds
that Nate gets hit by a bus
by August 10th, 2024 or something,
that would be more or less a straight line chart, right?
In an NBA game, when an NBA team is favored
and they just kind of maintain their favorite,
then they go from 80% favorite to 100% favorite.
I do think like Scott said,
I thought the market was low on Trump in general,
especially from late spring onward
when kind of the DeSantis campaign
began to clearly fail.
I mean, at some point,
it was actually pretty close in the polls
and then DeSantis wasn't a product that was selling
and that became self-evident pretty quickly.
And at that point, I think Trump should have been
much a much heavier favorite than he was.
Hey, I have a question just for Scott.
It's a two-part question.
Part one, I think the fire is out, so I feel robbed.
Part two.
We are both spatially and temporally
by the side of the fire.
All right, all right.
Part two, you've written a lot about predictive processing
as a way of understanding the human brain,
minimizing predictive error.
That's sort of like manifold, right?
Anyway, I'm interested in like
whether AI is gonna kill everyone.
And recently, some people have like started thinking,
hey, can we just think of minimizing predictive error
as the source of agency?
Can we use that frame to think about AI?
So I wanna check that it's like actually real,
that that's like actually what's happening with humans.
What are like the open frontiers and just figuring out
is this actually what's happening in the human brain?
That is a great question where I don't think
I have enough of a neuroscience background to understand.
I don't think we know at the level of population.
Like we have things like the nucleus accumbens.
We're able to see that the reward signal
pretty closely tracks something
that could be predictive error.
I think we know less about how cognitive schemas are formed.
We know less about kind of how you go from predictive error
in dealing with cats to a strong model of cats.
And I don't think you have the same kind of like clear
this neuron's signal as monitoring the prediction error
and something that we have for reward signal.
So I cannot really tell you a great answer to that.
And I would recommend just kind of reading
Friston and neuroscience papers
and seeing if they know anything about that.
What topic would each of you like to have the other
think really hard about and write a thoughtful post on?
I mean, I'll kind of repeat the same thing.
I would love Scott to weigh in
on the Trump threat to democracy stuff.
As someone who I think would come at it
from kind of a fresh perspective
and someone who is not particularly partisan
or maybe great tribe partisan or whatever.
I would love to see that post.
I am very happy with Nate's most recent book.
I am at the risk.
I enjoy seeing him think about AI
and I also think that him thinking about AI
lends it a lot of credibility
that will make it get taken more seriously
in the halls of power.
So I'm delighted to see him working on that.
Hey, right over here.
This question is for Nate.
There's actually two parts.
One is after a brief plateau,
polling response rates are dropping again
basically to an all-time low.
What are your thoughts on that?
How are you gonna basically deal with that?
The other question is,
is the narrative that young people
are basically turning against Biden over Palestine?
Do you see any evidence for that actually being true?
Yeah, so on the first question,
I mean, look, this is one of many reasons
why I'm explicitly transitioning out of politics, right?
I mean, the book is not all about politics
and it's kind of, well, it is about politics.
Everything's about politics,
but it's not about elections per se.
Look, in the long run,
if you're getting fewer and fewer people
respond to your polls
and the sample is less than that's represented,
that kind of has to be a problem.
I think pollsters figured out maybe before 2022,
which is a pretty good year for polling
that they have to like,
like polls now are basically more like models
than like poll with poll-favored inputs
than like pure public opinion surveys any longer.
But yeah, it's a problem which had like,
very wrong polling in India,
although India, the polling has always been very wrong,
so it was nothing new, for example.
But yeah, I mean, to have a continued secular decline
in the actual polling seems like a fairly good prior to me.
As far as Israel-Palestine,
I mean, I think it is an issue where Biden is hurt
no matter what he says or does a little bit.
It's also made with the issue that most over-indexes
for concern among kind of college-educated elites,
quote-unquote, as compared to regular voters, right?
If you'd like kind of like, have Gallup say,
what's the most important problem
facing the electorate today than like,
then 1% of people might mention Israel-Palestine, Gaza,
whereas the New York Times would occupy, you know,
20% of headline space and things like that.
You know, it causes problems for Biden in Michigan,
for example, which has a substantial Arab-American,
Palestinian-American population.
Michigan's usually a little bit bluer
than Pennsylvania and Wisconsin,
but like even a one or two-point swing,
it's like 2% of the population could be material there,
potentially.
But, you know, on my list of concerns for Biden,
it would be like, not higher than like fifth or sixth
after age and higher prices and maybe, you know,
frankly, general backlash to left where it shifts
in cultural areas and things like that
and immigration's a problem for Biden
and then maybe fifth and like, but you know,
it's not helpful to him, but yeah.
It's time for three more questions.
This question is for Scott.
You have written a lot about problems in academia
and you read a lot of papers.
What are your heuristics for separating good science
from bad science when you're like reading through papers
and trying to get to like ground truths?
Yeah, so it's very hard.
There are approximately two sources of information.
One is, do you actually understand the paper
and what it's talking about?
The other is the buzz around the paper,
the credentials of the author, all of this indirect data
that we try not to use because it's contaminated,
but sometimes you have to use.
I think partly you use the buzz
to determine how closely to read the paper.
Nobody can read every paper closely,
but you wanna see which ones are controversial
or which ones seem like the kind of thing
that might be biased and then you maybe just try to rely
on your knowledge of statistics or talk to someone else.
I have found that it is very useful
to talk to people in a field,
not just because they have the actual knowledge,
but because there are whole fields
where people be like, oh yeah, that's by Smith and Jones.
Everyone knows that all of their papers are wrong.
Like, nobody told the rest of us.
They said, yeah, well, interfield politics,
it's complicated.
Or they'll be like, yeah, everybody knows
that they had to publish that one paper
because their department needed to do something
to cooperate with that journal editor,
but they don't really take it seriously and nobody cares.
So it's very useful to be able to get
that kind of academic inside view.
And otherwise, it's just kind of a question
of how much do you know
and how closely are you gonna read the paper?
And also just checking a lot of different sources.
There are many papers that are great on their own.
And then if you look on Google Scholar,
even just in the work cited by this paper,
work cited in this paper,
you find 20 other papers, 10 of them agree with it,
10 of them disagree with it.
And then you're like,
I'm not gonna solve this personally right now.
Or you're gonna look at all 10 papers
and see what they find differently.
So I think it's very important
to never trust a single paper.
And once you read the whole structure
of people citing other people and so on,
you kind of get a 80-20 of being in the field
and knowing who's doing what and why.
Scott, this is a question for you.
So private equity is really excited
to replace doctors with anything faster and cheaper.
And insurance companies really love algorithmic medicine
in terms of reimbursements.
And I'm wondering, given that,
what you think the role AI will play
in real-time clinical decision-making,
maybe over the next 10 years or so?
Yeah, so you may know more about this than I do.
My perspective is,
AIs now are often quite good at certain kinds of medicine.
Even like an off-the-shelf LLM,
you can give it a medical case.
And often, I mean, it may not give you
the exact right diagnosis,
but if you ask for five diagnoses,
it may give you some that you didn't consider before.
Or if you ask it for five different courses of action,
you may realize, oh yeah, I hadn't thought about that.
So it's pretty good.
I'm sure that if somebody were working on a medical AI
with the same level of dedication
that, let's say, perplexity is working on a search AI
or future search is working on a forecasting AI,
they could make that even better.
You're not gonna replace doctors
for purely regulatory reasons.
Nobody is going to trust their care to an AI.
No medical regulator is going to let them do that.
And no pharmacy is going to accept prescriptions
written by an AI.
So one possibility is that you get a doctor
who's using an EMR that's plugged into an AI
and just as EMRs now pop up a thousand useless pop-up
saying like, hey, I see this as an old person.
Have you asked them about falls or something like that?
Instead of just reading their age off of the age box,
it will be like, hey, I see that the whole clinical picture
of this case suggests that there's somebody
who's vulnerable to this thing.
And do you want to consider that?
In theory, you could have that streamlined doctors
and let one doctor see more patients.
In practice, they've already streamlined doctors
to the point where they spend five minutes per patient
and I don't know how you would streamline it any further.
So I think the future is probably AI enabled EMRs.
I don't think it has any real effect on the world
in terms of fewer doctors or faster care.
And there may be people here who know much more
about this than I do.
This next one is our final question,
but our speakers can opt into holding office hours
to your right at the pagoda.
That's a question for both of you.
What do you think the probability of a war over AI supremacy
occurs either if Biden is elected or Trump is elected?
Is that, what's the probability in each circumstance?
I mean, I'm not sure that AI thought that much
about whether I think Biden or Trump is better for AI
or B, I've kind of thought about this enough
to put a probability on it.
I do think in general that if you think that AI
is gonna be extremely disruptive,
then wars or substantial reshaping
in the political environment is possible if not likely, right?
So in the book, I kind of like,
I don't wanna put a number, but not zero, like not tiny, right?
I mean, you know, in the book, I think we should kind of,
I think my thing is, I think we should think about like
how seismic or disruptive we expect AI to be first
and then kind of maybe flow
into like a PDOOM probability from there, right?
Like if you think AI is the most important
technological invention since the dawn of humankind, right?
Then that's gonna disrupt everything, obviously, right?
Maybe war is just one of many concerns that we have.
If you think it's just kind of like,
oh, it's like kind of like the automobile or something,
probably you wouldn't go to war over the Model T
or something, so that's how I kind of vaguely think about it.
Well, this is a really complex question.
So you gotta sort it out into,
we are in the middle of an intelligence explosion,
a singularity versus everything else.
I don't wanna predict what happens during a singularity.
I do think wars are generally unlikely,
a war between two great powers
which has a big chance of turning nuclear,
it has a big chance of just devastating everybody.
So my impression is that usually
when large wars happen nowadays
with the exception of maybe Ukraine,
it's often everybody was trying to do brinksmanship
and made a mistake.
I can imagine that happening with Taiwan especially
if people care a lot about Taiwan's microchips.
But in general, I don't think that AI
necessarily changes things that much.
Either people are not far ahead in AI,
in which case they just wanna compete normally
rather than have a war,
or somebody is ahead, far ahead in AI
and it seems important in which case they will win the war
and the other person won't want to start it.
So I think you need like a pretty complicated,
like very small middle ground between those places
before you get a war.
And my impression is that great powers
have been pretty good at avoiding war
since World War II.
I know that Taleb says this is kind of over updating
on a small amount of data and I respect that.
But I would just not,
I would not expect that Xi Jinping wakes up one morning
and thinks let's have a war about AI.
I think that's not really how great powers work these days.
Well, okay, so that's the other half of your question.
And I actually don't know how to calculate that.
I've heard people say that because Trump
is such a weird guy,
you can't do brinksmanship with him.
So you mostly just back down.
This seems to be kind of how he did okay versus Iran.
So I don't think of him as the kind of person
who would start a war for no reason.
I think he would do kind of stupid brinksmanship
for stuff for no reason,
but given the fact that he's such a bad guy
to do brinksmanship stuff against,
I don't know if that would go better or worse
than if Biden does it.
So I have no strong opinion there.
No, a book comes out on the edge.
The art of risking everything comes out August 13th
at your favorite retailer.
I will be reviewing Nate Silver's book
sometime after August 13th.
Thank you very much for coming
and thank you for your excellent questions.
Thank you so much everybody.
