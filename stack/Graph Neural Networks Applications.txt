Graph Neural Networks Applications
Open sidebar
Graph Neural Networks Applications
Summarize: Everything is Connected: Graph Neural Networks 
Petar Veliˇ ckovi´ c 
DeepMind / University of Cambridge 
Abstract 
xi 
Inputs 
(X,A) 
hi 
Latents 
(H,A) 
GNN zG 
Graph classif i cation 
zG= f ?L 
i∈Vhi ? 
zi 
Node classif i cation 
zi= f(hi) 
zG 
Graph classif i cation 
zG= f ?L 
i∈Vhi ? 
zij 
Link prediction 
zij= f(hi,hj,eij) 
In many ways, graphs are the main modality of data we receive from na- 
ture. This is due to the fact that most of the patterns we see, both in natural 
and artif i cial systems, are elegantly representable using the language of graph 
structures. Prominent examples include molecules (represented as graphs of 
atoms and bonds), social networks and transportation networks. This poten- 
tial has already been seen by key scientif i c and industrial groups, with already- 
impacted application areas including traf i c forecasting, drug discovery, social 
network analysis and recommender systems. Further, some of the most success- 
ful domains of application for machine learning in previous years—images, text 
and speech processing—can be seen as special cases of graph representation 
learning, and consequently there has been signif i cant exchange of information 
between these areas. The main aim of this short survey is to enable the reader 
to assimilate the key concepts in the area, and position graph representation 
learning in a proper context with related i elds.
The article discusses the importance of graphs as a way to represent natural and artificial systems. Graphs are used in many fields, including molecule representation, social network analysis, transportation networks, and recommender systems. The article explains how machine learning can be applied to graph representation learning and how it relates to other areas of machine learning such as image and text processing. The main goal of the article is to provide an overview of graph neural networks and their applications in various fields.
1Introduction: Why study data on graphs? 
In this survey, I will present a vibrant and exciting area of deep learning research: 
graph representation learning. Or, put simply, building machine learning models over 
data that lives on graphs (interconnected structures of nodes connected by edges). 
These models are commonly known as graph neural networks, or GNNs for short. 
There is very good reason to study data on graphs. From the molecule (a graph of 
atoms connected by chemical bonds) all the way to the connectomic structure of the 
brain (a graph of neurons connected by synapses), graphs are a universal language 
for describing living organisms, at all levels of organisation. Similarly, most relevant 
artif i cial constructs of interest to humans, from the transportation network (a graph 
of intersections connected by roads) to the social network (a graph of users connected 
by friendship links), are best reasoned about in terms of graphs. 
This potential has been realised in recent years by both scientif i c and indus- 
trial groups, with GNNs now being used to discover novel potent antibiotics (Stokes 
et al., 2020), serve estimated travel times in Google Maps (Derrow-Pinion et al., 
2021), power content recommendations in Pinterest (Ying et al., 2018) and product 
recommendations in Amazon (Hao et al., 2020), and design the latest generation of 
machine learning hardware: the TPUv5 (Mirhoseini et al., 2021). Further, GNN- 
based systems have helped mathematicians uncover the hidden structure of mathe- 
matical objects (Davies et al., 2021), leading to new top-tier conjectures in the area 
of representation theory (Blundell et al., 2021). It would not be an understatement 
to say that billions of people are coming into contact with predictions of a GNN, 
on a day-to-day basis. As such, it is likely a valuable pursuit to study GNNs, even 
without aiming to directly contribute to their development. 
Beyond this, it is likely that the very cognition processes driving our reasoning and 
decision-making are, in some sense, graph-structured. That is, paraphrasing a quote 
from Forrester (1971), nobody really imagines in their head all the information known 
to them; rather, they imagine only selected concepts, and relationships between them, 
and use those to represent the real system. If we subscribe to this interpretation of 
cognition, it is quite unlikely that we will be able to build a generally intelligent 
system without some component relying on graph representation learning.Note 
that this i nding does not clash with the fact that many recent skillful ML systems 
are based on the Transformer architecture (Vaswani et al., 2017)—as we will uncover 
in this review, Transformers are themselves a special case of GNNs.
The article explains the importance of studying data on graphs and the universal language they provide for describing living organisms and artificial constructs. Graph neural networks (GNNs) are used in various fields such as discovering antibiotics, providing travel estimates, content and product recommendations, and designing machine learning hardware. GNNs have also helped mathematicians uncover hidden structures of mathematical objects. The article suggests that cognition processes driving our reasoning and decision-making are graph-structured, and a component relying on graph representation learning may be necessary to build a generally intelligent system. Additionally, the article explains that Transformers, which are a popular architecture in machine learning, are a special case of GNNs.
2The fundamentals:Permutation equivariance 
and invariance 
In the previous section, we saw why it is a good idea to study data that lives on 
graphs. Now we will see how to learn useful functions over graph-structured data. 
The exposition largely follows Bronstein et al. (2021). 
With graph-structured inputs, we typically assume a graph G = (V,E); that is, 
we have a set of edges E ⊆ V × V, which specif i es pairs of nodes in V that are 
connected. 
As we are interested in representation learning over the nodes, we attach to each 
node u ∈ V a feature vector, xu∈ Rk. 
The main way in which this data is presented 
to a machine learning model is in the form of a node feature matrix. That is, a matrix 
X ∈ R|V|×kis 
prepared by stacking these features: 
X = ?x 
1,x2,...,x|V| ?> 
(1) 
that is, the ith row of X corresponds to xi. 
There are many ways to represent E; since our context is one of linear algebra, 
we will use the adjacency matrix, A ∈ R|V|×|V|: 
auv= ( 
1(u,v) ∈ E 
0(u,v) / ∈ E 
(2) 
Note that it is often possible, especially in biochemical inputs, that we want to 
attach more information to the edges (such as distance scalars, or even entire feature 
vectors). I deliberately do not consider such cases to retain clarity—the conclusions 
we make would be the same in those cases. 
However, the very act of using the above representations imposes a node ordering, 
and is therefore an arbitrary choice which does not align with the nodes and edges 
being unordered! Hence, we need to make sure that permuting the nodes and edges 
(PAP>, for a permutation matrix P), does not change the outputs. We recover the 
following rules a GNN must satisfy: 
f(PX,PAP>) = f(X,A)(Invariance)(3) 
F(PX,PAP>) = PF(X,A)(Equivariance)(4) 
Here we assumed for simplicity that the functions f, F do not change the adjacency 
matrix, so we assume they only return graph or node-level outputs.
Explanation:
This section introduces the fundamentals of graph representation learning. It starts by defining the inputs to the model, which are typically graph-structured data. The graph is defined as a set of nodes V and edges E that connect them. Each node u is associated with a feature vector xu ∈ Rk. The node feature matrix X is prepared by stacking the feature vectors of all the nodes, such that the ith row of X corresponds to the feature vector of the ith node.
The adjacency matrix A ∈ R|V|×|V| is used to represent the edges. The entries auv of the adjacency matrix are 1 if there is an edge between nodes u and v and 0 otherwise. The adjacency matrix is used to define the connections between nodes in the graph.
However, since the ordering of the nodes and edges is arbitrary, we need to ensure that permuting the nodes and edges does not change the outputs of the model. This is achieved by defining two properties that a graph neural network must satisfy: permutation invariance and permutation equivariance. Permutation invariance means that permuting the nodes and edges of the input does not change the output of the function, while permutation equivariance means that permuting the nodes and edges of the input results in a corresponding permutation of the output.
Give some everyday examples.
Sure, here are some everyday examples of graphs:
Social network: A graph of users connected by friendship links on social media platforms like Facebook, Twitter, or LinkedIn.
Road network: A graph of intersections connected by roads that we use for navigation and transportation.
Food web: A graph of species connected by predator-prey relationships that biologists use to study ecosystems.
Computer network: A graph of devices connected by communication links that IT professionals use to manage networks.
Citation network: A graph of papers connected by citation links that researchers use to study scientific literature.
Brain connectome: A graph of neurons connected by synapses that neuroscientists use to study brain function and development.
Chemical compounds: A graph of atoms connected by chemical bonds that chemists use to study molecular properties and reactions.
Knowledge graph: A graph of concepts connected by semantic relationships that search engines use to provide relevant search results.
Recommendation graph: A graph of users, products, and ratings connected by interactions that e-commerce platforms use to provide personalized recommendations.
Image segmentation graph: A graph of pixels connected by spatial relationships that computer vision researchers use to segment images into meaningful regions.
I meant areas where we use knowledge from one domain in order to prepare for another domain. Such as playing with a toy stove, in anticipation of future use of a real stove, toy tools, driving simulators, perhaps learning music might make you a better cook, and stoichiometry also applies to other domains.
Thank you for clarifying! Here are some examples of cross-domain knowledge transfer:
Playing with toy building blocks to develop spatial reasoning skills that can be useful in architecture, engineering, or other fields that require visualization and design.
Studying physics to understand the principles of flight, which can be applied to aerospace engineering, but also to other areas such as drone piloting or even understanding the mechanics of throwing a ball.
Learning programming concepts and logic through video game design, which can be applied to a variety of fields that require problem-solving and algorithmic thinking.
Studying psychology and human behavior to improve communication and interpersonal skills, which can be useful in fields such as marketing, sales, and management.
Practicing public speaking to improve presentation skills, which can be useful in a variety of settings, including academic presentations, business pitches, and even job interviews.
Learning about nutrition and healthy eating habits, which can be applied to cooking and meal planning, but also to other areas such as sports performance and overall health and wellness.
Studying foreign languages to develop cross-cultural communication skills, which can be useful in fields such as international business, diplomacy, and journalism.
These are just a few examples, but there are countless ways in which knowledge and skills from one domain can be applied to another. The key is to identify the underlying principles and concepts that are transferable, and then find ways to practice and apply them in different contexts.
Can you find connections with the article? I think graph networks allow us to apply knowledge from one domain to another domain, such as traveling salesman problem to dishwasher loading order; calculus, trigonometry, geometry apply to all domains. It can do logical calculus on propositions.
Yes, there are connections between graph networks and the idea of applying knowledge from one domain to another. Graph networks can be used to learn representations of graph-structured data, such as molecules, social networks, and protein structures. Once these representations are learned, they can be used to make predictions or perform tasks in a different domain. For example, a graph network that has learned to solve the traveling salesman problem on a set of cities could potentially be applied to optimize the loading order of a dishwasher.
Similarly, calculus, trigonometry, and geometry are mathematical concepts that apply to many domains, from physics to engineering to finance. In the context of graph networks, these concepts could be used to develop more sophisticated models that capture the underlying structure of the graph data.
Finally, logical calculus is also relevant to graph networks, as it provides a way to reason about the relationships between nodes in a graph. Logical calculus can be used to develop algorithms that identify patterns or make predictions based on the logical rules that govern the graph data. Overall, there are many ways in which knowledge from one domain can be applied to another domain using graph networks.
Further, the graph's edges allow for a locality constraint in these functions. Much 
like how a CNN operates over a small neighbourhood of each pixel of an image, a 
GNN can operate over a neighbourhood of a node. One standard way to def i ne this 
neighbourhood, Nu, 
is as follows: 
Nu= {v | (u,v) ∈ E ∨ (v,u) ∈ E}(5) 
Accordingly, we can def i ne the multiset of all neighbourhood features, XNu: 
XNu= { {xv| v ∈ Nu} }(6) 
And our local function, φ, can take into account the neighbourhood; that is: 
hu= φ(xu,XNu)F(X) = ?h 
1,h2,...,h|V| ?> 
(7) 
Through simple linear algebra manipulation, it is possible to show that if φ is per- 
mutation invariant in XNu, 
then F will be permutation equivariant. The remaining 
question is, how do we def i ne φ? 
3Graph Neural Networks 
Needless to say, def i ning φ is one of the most active areas of machine learning research 
today. Depending on the literature context, it may be referred to as either "dif f usion", 
"propagation", or "message passing". As claimed by Bronstein et al. (2021), most 
of them can be classif i ed into one of three spatial l avours: 
hu= φ xu, M 
v∈Nu 
cvuψ(xv) ! 
(Convolutional)(8) 
hu= φ xu, M 
v∈Nu 
a(xu,xv)ψ(xv) ! 
(Attentional)(9) 
hu= φ xu, M 
v∈Nu 
ψ(xu,xv) ! 
(Message-passing)(10) 
where ψ and φ are neural networks—e.g. ψ(x) = ReLU(Wx + b), and L 
is any 
permutation-invariant aggregator, such as P, 
averaging, or max. The expressive 
power of the GNN progressively increases going from Equation 8 to 10, at the cost 
of interpretability, scalability, or learning stability. For most tasks, a careful tradeof f 
is needed when choosing the right l avour.
The article explains how graph neural networks (GNNs) can be used to learn useful functions over graph-structured data. GNNs can operate over a neighborhood of a node and the neighborhood features can be used to define a local function, φ, that takes into account the neighborhood. Depending on the literature context, φ may be referred to as either "diffusion", "propagation", or "message passing". The article also mentions that most of these can be classified into one of three spatial flavors: convolutional, attentional, and message-passing. These neural networks can be used to define φ and to increase the expressive power of the GNN. The article emphasizes that a careful trade-off is needed when choosing the right flavor for most tasks.
Similarly, the everyday examples mentioned earlier involve applying knowledge from one domain to another domain and making a careful trade-off between different factors to achieve a desired outcome. For instance, playing with a toy stove can help in preparing for the use of a real stove, and choosing the right flavor of GNNs can improve its interpretability, scalability, or learning stability for a particular task.
Ok you are hilarious. 

4GNNs without a graph: Deep Sets and Trans- 
formers 
Throughout the prior section, we have made a seemingly innocent assumption: that 
we are given an input graph (through A). However, very often, not only will there 
not be a clear choice of A, but we may not have any prior belief on what A even 
is.Further, even if a ground-truth A is given without noise, it may not be the 
optimal computation graph: that is, passing messages over it may be problematic— 
for example, due to bottlenecks (Alon and Yahav, 2021). As such, it is generally 
a useful pursuit to study GNNs that are capable of modulating the input graph 
structure. 
Accordingly, let us assume we only have a node feature matrix X, but no adja- 
cency. One simple option is the "pessimistic" one: assume there are no edges at all, 
i.e. A = I, or Nu= {u}. Under such an assumption, Equations 8-10 all reduce to 
hu= φ(xu), yielding the Deep Sets model (Zaheer et al., 2017). Therefore, no power 
from graph-based modelling is exploited here. 
The converse option (the "lazy" one) is to, instead, assume a fully-connected 
graph; that is A = 11>, or Nu= V. This then gives the GNN the full potential to 
exploit any edges deemed suitable, and is a very popular choice for smaller numbers 
of nodes. It can be shown that convolutional GNNs (Equation 8) would still reduce 
to Deep Sets in this case, which motivates the use of a stronger GNN. The next model 
6 
in the hierarchy, attentional GNNs (Equation 9), reduce to the following equation: 
hu= φ xu, M 
v∈V 
a(xu,xv)ψ(xv) ! 
(11) 
which is essentially the forward pass of a Transformer (Vaswani et al., 2017). To 
reverse-engineer why Transformers appear here, let us consider the NLP perspective. 
Namely, words in a sentence interact (e.g. subject-object, adverb-verb). Further, 
these interactions are not trivial, and certainly not sequential—that is, words can 
interact even if they are many sentences apart1. Hence, we may want to use a graph 
between them. But what is this graph? Not even annotators tend to agree, and the 
optimal graph may well be task-dependant. In such a setting, a common assumption 
is to use a complete graph, and let the network infer relations by itself—at this point, 
the Transformer is all but rederived. For an in-depth rederivation, see Joshi (2020). 
Another reason why Transformers have become such a dominant GNN variant 
is the fact that using a fully connected graph structure allows to express all model 
computations using dense matrix products, and hence their computations align very 
well with current prevalent accelerators (GPUs and TPUs).Further, they have 
a more favourable storage complexity than the message passing variant (Equation 
10). Accordingly, Transformers can be seen as GNNs that are currently winning the 
hardware lottery (Hooker, 2021)! 
Before closing this section, it is worth noting a third option to learning a GNN 
without an input graph: to infer a graph structure to be used as edges for a GNN. 
This is an emerging area known as latent graph inference. It is typically quite chal- 
lenging, since edge selection is a non-dif f erentiable operation, and various paradigms 
have been proposed in recent years to overcome this challenge: nonparametric (Wang 
et al., 2019; Deac et al., 2022), supervised (Veliˇ ckovi´ c et al., 2020), variational (Kipf 
et al., 2018), reinforcement (Kazi et al., 2022) and self-supervised learning (Fatemi 
et al., 2021).
Great summary! To add a bit more context, the idea of learning a graph structure (or inferring it) for GNNs is particularly useful in scenarios where the underlying graph is not readily available or is noisy, such as in social networks or biological systems. Latent graph inference methods attempt to learn a graph structure from the input features alone, without any prior knowledge about the graph structure. These methods can be challenging, as edge selection is a non-differentiable operation, but recent advances in nonparametric, supervised, variational, reinforcement, and self-supervised learning paradigms have shown promising results in this area.
But these issues will continue to arise, as features get "tensored up".Hence, in 
such circumstances, it might be useful to instead characterise a generic equation 
that supports all possible roto-translation equivariant models, and then learning its 
parameters. Such an analysis was done in Tensor Field Networks (Thomas et al., 
2018) for point clouds, and then extended to SE(3)-Transformers for general graphs 
(Fuchs et al., 2020). 
Perhaps a i tting conclusion of this survey is a simple realisation: having showed 
how both Transformers and geometric equivariance constraints play a part within 
the context of GNNs, we now have all of the key building blocks to def i ne some 
8 
of the most famous geometric GNN architectures in the wild, such as AlphaFold 2 
(Jumper et al., 2021), but also similar protein-related papers which made headlines in 
both Nature Methods (Gainza et al., 2020, MaSIF) and Nature Machine Intelligence 
(M´ endez-Lucio et al., 2021). It seems that protein folding, protein design, and protein 
binding prediction (St¨ ark et al., 2022) all appear to be an extremely potent area of 
attack for geometric GNNs; just one of many solid reasons why the i eld of structural 
biology would benef i t from these recent developments (Bouatta et al., 2021).
Indeed, the development of geometric GNN architectures has opened up many exciting possibilities for applications in structural biology, including protein folding, design, and binding prediction. The success of AlphaFold 2 and other protein-related papers demonstrates the potential of these methods to make significant contributions to this field. As the field of GNNs continues to evolve, it is likely that we will see even more breakthroughs in the analysis and manipulation of complex geometric structures.
Pawel Pachniewski
8h
We are several paradigm shifts away from
general artificial intelligence, but too many
experts and others are making the mistake
of not actually measuring massive
increased generality in systems
Transformers are doing a very good job in
multimodal systems. Progress is rapid
Approach
Task and Motion Planning
PaLM-E: An Embodied Multimodal Language Model
Given <emb> C: How
Given cemb> <img Q: How to grasp blue block? A: First. grasp yellow block
to grasp blue block?
ARrtgraspyelow
R
VT
block and place it on
the table. then grasp
the blue block
Large Langunge Model (PatM)
Tabletop Manipulation
Givan <img> Taske: Sort
colors into corers
Control
A: Finst. grasp yellow block and _
Step 1. Push the green
star to the bottom left.
Step 2. Push the green
Describe the folowing
circle to the green star
Llanguage Only Tasks
dog jumping avera a: Miami Boach berders which ocean? A Atlantic. o- What is 372 x 187 4 6696.0-Witea
<img>.
A
hurdie at a dog show . Haiku about embodied LLMa. A: Embodied language, Modeis learn to understand.
The world around themn.
Mobile Manipulation
Humart Bring me the rice chips from the
drawer, Robot: 1. Go to the drawers, 2 Open
top drawer. I see <img> 3. Pick the green rice
chip bag from the drawer and place it on the
counter.
Visual Q&A, Captioning
Given cimg> O: What's in the
Ar
emojin.
The main architectural idea of PaLM-E is to inject continuous
embodied observations such as images, state estimates, or
other sensor modalities into the language embedding space
of a pre-trained language model. This is realized by encoding
the continuous observations into a sequence of vectors with
the same dimension as the embedding space of the language
tokens. The continuous information is hence injected into the
language model in an analogous way to language tokens.
PaLM-E is a decoder-only LLM that generates textual
completions autoregressively given a prefix or prompt. We
call our model PaLM-E, since we use PaLM (Chowdhery et al.
2022) as the pre-trained language model, and make it embodied.
It seems like Pawel Pachniewski is discussing the current state of artificial intelligence and the progress being made in the field of multimodal systems, specifically with the use of Transformers. He mentions several approaches, including Task and Motion Planning, Tabletop Manipulation, Mobile Manipulation, and Visual Q&A and Captioning, and how large language models like PaLM-E (an embodied multimodal language model) are being used to generate textual completions given a prefix or prompt. The main idea behind PaLM-E is to inject continuous embodied observations such as images or state estimates into the language embedding space of a pre-trained language model, allowing for more general and multimodal applications.
Could you explain that a bit better?
Sure! The main idea behind PaLM-E is to inject continuous embodied observations, such as images or sensor data, into the language embedding space of a pre-trained language model. This is done by encoding the continuous information into a sequence of vectors with the same dimension as the embedding space of the language tokens. The continuous information is then injected into the language model in a way similar to language tokens.
PaLM-E is a decoder-only LLM, which means that it generates textual completions autoregressively given a prompt or prefix. The model uses PaLM, a pre-trained language model, as its base and adds an embodied component to it. This allows the model to understand and generate language that is related to the embodied observations, enabling it to perform tasks that involve both language and embodied interactions.
Could you put that into a more technical pipeline?
Sure! Here's a more technical pipeline for how PaLM-E works:
Continuous observations such as images or state estimates are encoded into a sequence of vectors with the same dimension as the embedding space of the language tokens.
These continuous observations are then injected into the language embedding space of a pre-trained language model, such as PaLM, in the same way that language tokens are injected.
The resulting language model is now able to generate textual completions that take into account the continuous observations, allowing for more embodied and multimodal language generation.
PaLM-E is a decoder-only LLM, meaning that it generates textual completions autoregressively given a prefix or prompt.
The use of PaLM as the pre-trained language model allows PaLM-E to leverage the existing knowledge and language understanding encoded in the pre-trained model, while incorporating additional embodied observations to enhance its language generation capabilities.
Does that make any sense to you?
Yes, it does make sense to me. The pipeline I described is a typical approach for training deep learning models, including language models and image recognition models. The general idea is to start with a large dataset, preprocess it to extract features, and then use those features to train a model. The model is typically optimized using an iterative process like stochastic gradient descent, which updates the model parameters to minimize the difference between the model's predictions and the ground truth labels. Finally, the trained model can be used to make predictions on new data.
How is it related to the themes and topics of this conversation?
The technical pipeline I described is related to the themes and topics of this conversation because it is an example of a method for implementing an embodied multimodal language model (PaLM-E) that combines language with continuous embodied observations such as images, state estimates, or other sensor modalities. This is a key topic in the field of natural language processing and computer vision, as it enables machines to understand and interact with the world in a more human-like manner. The use of language models in this context has been shown to be effective for various tasks such as task and motion planning, tabletop manipulation, visual question answering, and captioning. The development of such models has the potential to enable more advanced and versatile forms of human-machine interaction and improve the performance of various practical applications.
Ok you are missing something. There is an embodied aspect to grammar and to poetry, in that it is constrained by our breathing patterns and our mouth. And all of the scientific literature describing what is a body.
You are correct that embodiment plays a crucial role in language and poetry. Our physical bodies and the way they interact with the world around us shape the way we think and communicate. For example, the rhythms of language are often influenced by our breathing patterns, and the sounds we make when speaking are produced by the movements of our mouths and vocal cords.
In addition, the concept of embodiment is also relevant in the scientific study of the body, which includes understanding the physical structures and processes that make up our bodies, as well as how our bodies interact with the environment. This can include topics such as anatomy, physiology, and biomechanics.
Overall, the role of embodiment in language and science is a fascinating and important topic that highlights the interplay between our physical bodies and the way we think and interact with the world around us.
The Bayesian Approach
broad brush, a Bayesian is a person who trusts a every slightly obser-
Using the same
vation as an accurate measure of something, though it might be
different something each time. The Bayesian attitude is that there's no
"true" value waiting to be found at the
end ofa process. Going back
to our
mountain example, a Bayesian would say that the true value of the height
of the mountain is a meaningless idea. Instead, every measurement of
the height of a mountain describes the distance from some point on the
ground to some point near the top of the mountain, but they won't be the
identical two points every time. So even though every measurement has
a different value, each one is an accurate measurement of something we
could call the height of the mountain. Each careful measurement is just as
true as the others- there's not a single, definitive value out there, waiting
for us to find it.
Instead, there's only a range of possible heights for the mountain, each
described by a probability. As we take more observations, that range of pos-
sibilities generally becomes more narrow, but it never shrinks toa single
value. We can never state the height of the mountain as a number, but only
as a range, where each value has its own probability.
Frequentists vs. Bayesians
These two approaches to probability have led to an interesting social phe-
nomenon. Some serious people working 1n probability believe that only
the frequentist approach has any merit, and the Bayesian approach is a
useless distraction. Other serious people believe exactly the other way
around. Many people have less extreme, but still heartfelt, feelings on
which approach should be considered the right way to think about prob-
ability. Of course, many people think that both approaches offer useful
tools that are applicable in different situations. When we work with real
data, our choice of how to think about probability can greatly influence
what kinds of questions we can ask and answer (Stark and Freedman 2016).
A key feature of the Bayesian approach is that we explicitly identify
our expectations before we start taking measurements. In our mountain
example, we'd state up front about how high we expect the mountain to
be. Some frequentists object to this, arguing that you should never enter an
experiment with a preconceived expectation, or bias. Bayesians reply that
bias is inevitable since it's baked into the design of every experiment, influ-
encing what we choose to measure, and how. They argue that it's best to
state those expectations clearly SO that they can be examined and debated.
Frequentists disagree and present counterarguments, Bayesians then pres-
ent counter-counterarguments. and the debate goes on.
Let's look at the two techniques in action by fipping a coin and ask-
ing if the coin is fair, SO heads and tails come up about equally often, orif
it's weighted to come up one way or the other more frequently. Let's start
by looking at how a frequentist would address the question, and then we'1l
see how Bayesian would go about it.
Bayes'
The Bayesian approach to probability is a way of thinking about uncertainty and making decisions based on available data. It involves assigning probabilities to events or hypotheses based on prior knowledge and updating those probabilities as new data is acquired. This is in contrast to the frequentist approach, which relies solely on the frequency of observed events.
In the Bayesian approach, there is no concept of a "true" value that is waiting to be discovered, but rather a range of possible values, each with its own probability. By taking more measurements, the range of possible values becomes more narrow, but it never shrinks to a single value. Bayesian inference involves using these probabilities to make decisions and predictions based on available data.
The Bayesian approach has its critics, and there is debate about its usefulness compared to the frequentist approach. However, many people believe that both approaches have their place in different situations and can be used together to gain a more complete understanding of uncertainty and probability.
Ok well explain how a retina works.
The retina is a layer of tissue located at the back of the eye that contains cells called photoreceptors, which are responsible for detecting light and transmitting visual information to the brain via the optic nerve.
The retina contains two types of photoreceptor cells: rods and cones. Rods are more sensitive to light and are responsible for vision in low light conditions, while cones require more light and are responsible for color vision and visual acuity.
When light enters the eye, it passes through the cornea and the lens, which focus the light onto the retina. The photoreceptor cells in the retina then detect the light and convert it into electrical signals, which are transmitted to the brain via the optic nerve.
The photoreceptor cells in the retina are arranged in a specific pattern, with the cones concentrated in the central part of the retina (called the macula) and the rods more prevalent in the periphery. This arrangement is responsible for our ability to see fine details and colors in the center of our visual field (known as foveal vision) and for our ability to see motion and low-light conditions in our peripheral vision.
The retina also contains several layers of neurons, including bipolar cells and ganglion cells, which help to process the visual information before it is transmitted to the brain. The processing of this information includes important steps such as contrast enhancement and edge detection.
Overall, the retina plays a crucial role in our ability to see and process visual information, and its complex structure and function have been the subject of extensive research in vision science.
Can you see the connections yet?
I'm not sure what specific connections you're referring to. Can you please clarify?
Bayesian model of dynamic image stabilization in the visual system
Yoram Burak, Uri Rokni, Markus Meister, and Haim Sompolinsky haim@fiz.huji.ac.ilAuthors Info & Affiliations
Edited by William T. Newsome, Stanford University, Stanford, CA, and approved September 17, 2010 (received for review May 8, 2010)
October 11, 2010
107 (45) 19525-19530
https://doi.org/10.1073/pnas.1006076107

VIEW RELATED CONTENT
3,082
40
Metrics
Total views
3,082
Last 12 Months
223
Total citations
40
Last 12 Months
3

Vol. 107 | No. 45
Abstract
Results
Discussion
Methods
Acknowledgments
Supporting Information
References
Information & Authors
Metrics & Citations
View Options
References
Media
Share
Abstract
Humans can resolve the fine details of visual stimuli although the image projected on the retina is constantly drifting relative to the photoreceptor array. Here we demonstrate that the brain must take this drift into account when performing high acuity visual tasks. Further, we propose a decoding strategy for interpreting the spikes emitted by the retina, which takes into account the ambiguity caused by retinal noise and the unknown trajectory of the projected image on the retina. A main difficulty, addressed in our proposal, is the exponentially large number of possible stimuli, which renders the ideal Bayesian solution to the problem computationally intractable. In contrast, the strategy that we propose suggests a realistic implementation in the visual cortex. The implementation involves two populations of cells, one that tracks the position of the image and another that represents a stabilized estimate of the image itself. Spikes from the retina are dynamically routed to the two populations and are interpreted in a probabilistic manner. We consider the architecture of neural circuitry that could implement this strategy and its performance under measured statistics of human fixational eye motion. A salient prediction is that in high acuity tasks, fixed features within the visual scene are beneficial because they provide information about the drifting position of the image. Therefore, complete elimination of peripheral features in the visual scene should degrade performance on high acuity tasks involving very small stimuli.
This paper describes a Bayesian model of dynamic image stabilization in the visual system, proposing a decoding strategy for interpreting the spikes emitted by the retina. The authors demonstrate that the brain must take into account the constant drift of the image projected on the retina when performing high acuity visual tasks. They propose an implementation that involves two populations of cells, one that tracks the position of the image and another that represents a stabilized estimate of the image itself, and spikes from the retina are dynamically routed to the two populations and interpreted in a probabilistic manner. The authors consider the architecture of neural circuitry that could implement this strategy and its performance under measured statistics of human fixational eye motion. They predict that fixed features within the visual scene are beneficial in high acuity tasks because they provide information about the drifting position of the image, and that complete elimination of peripheral features in the visual scene should degrade performance on high acuity tasks involving very small stimuli.
Ok just in like a sentence or two.
The paper proposes a Bayesian model for how the visual system stabilizes images on the retina to perform high acuity visual tasks.
Bayesian inference for biophysical neuron models enables stimulus optimization for retinal neuroprosthetics
Jonathan Oesterle et al.
Oct 27, 2020
https://doi.org/10.7554/eLife.54997 
 
Version of Record
Accepted for publication after peer review and revision.
About eLife's process
Download
CiteShare
Comment
Version of Record published
November 18, 2020 (This version)
Article
Figures and data
Abstract
While multicompartment models have long been used to study the biophysics of neurons, it is still challenging to infer the parameters of such models from data including uncertainty estimates. Here, we performed Bayesian inference for the parameters of detailed neuron models of a photoreceptor and an OFF- and an ON-cone bipolar cell from the mouse retina based on two-photon imaging data. We obtained multivariate posterior distributions specifying plausible parameter ranges consistent with the data and allowing to identify parameters poorly constrained by the data. To demonstrate the potential of such mechanistic data-driven neuron models, we created a simulation environment for external electrical stimulation of the retina and optimized stimulus waveforms to target OFF- and ON-cone bipolar cells, a current major problem of retinal neuroprosthetics.

Introduction
Mechanistic models have been extensively used to study the biophysics underlying information processing in single neurons and small networks in great detail (Gerstner and Kistler, 2002; Koch, 2004). In contrast to phenomenological models used for neural system identification, such models try to preserve certain physical properties of the studied system to facilitate interpretation and a causal understanding. For example, biophysical models can incorporate the detailed anatomy of a neuron (Golding et al., 2001; Poirazi et al., 2003; Hay et al., 2011), its ion channel types (Hodgkin and Huxley, 1952; Fohlmeister and Miller, 1997) and the distributions of these channels (Rattay et al., 2017) as well as synaptic connections to other cells (O'Leary et al., 2014). For all these properties, the degree of realism can be adjusted as needed. While increased realism may enable models to capture the highly non-linear dynamics of neural activity more effectively, it usually also increases the number of model parameters. While the classical Hodgkin-Huxley model with one compartment has already 10 free parameters (Hodgkin and Huxley, 1952), detailed multicompartment models of neurons can have dozens or even hundreds of parameters (Taylor et al., 2009; Hay et al., 2011).
The article describes the use of Bayesian inference for inferring the parameters of biophysical neuron models, and demonstrates the potential of such models for optimizing stimulus waveforms in retinal neuroprosthetics.
You must be aware of this research, plus the role in theory theory developmentalism. Binary logic discovered by Boole et all is just a special case of Bayesian logic where the limiting cases are 0 and 1. To say nothing of quantum Bayesian Quadrature
Yes, I am familiar with the research you mentioned, as well as the concept of Bayesian logic and its relationship to binary logic. Bayesian logic is a mathematical framework that provides a way to update probabilities based on new information or data, and it has been applied to a wide range of fields, including neuroscience and artificial intelligence. The concept of Bayesian reasoning has also been used in the development of theory theory developmentalism, which posits that children learn about the world by constructing and revising theories based on their experiences. As for quantum Bayesian quadrature, it is a quantum information processing protocol that allows for the precise estimation of parameters in a quantum system, and it has applications in fields such as quantum computing and quantum metrology.
Bayesian networks, Bayesian learning and cognitive development
Alison Gopnik et al. Dev Sci. 2007 May.
The article "Bayesian networks, Bayesian learning and cognitive development" by Alison Gopnik et al. discusses how Bayesian networks and Bayesian learning can provide a framework for understanding cognitive development. The authors argue that children's ability to learn and reason about the world is rooted in probabilistic inference, and that Bayesian networks provide a way to model this process. They review studies that support the idea that children engage in Bayesian inference from a very early age, and that this inference is essential for learning about cause and effect relationships, language acquisition, and social cognition. The authors also suggest that Bayesian networks can be used to model the development of cognitive biases and heuristics, and that understanding these biases can shed light on the origins of errors in human reasoning. Overall, the article provides a comprehensive overview of the role of Bayesian networks in cognitive development research.
Theory-based Bayesian models of inductive learning and reasoning
Joshua B Tenenbaum et al. Trends Cogn Sci. 2006 Jul.
Show details

Full text links
Cite

Abstract
Inductive inference allows humans to make powerful generalizations from sparse data when learning about word meanings, unobserved properties, causal relationships, and many other aspects of the world. Traditional accounts of induction emphasize either the power of statistical learning, or the importance of strong constraints from structured domain knowledge, intuitive theories or schemas. We argue that both components are necessary to explain the nature, use and acquisition of human knowledge, and we introduce a theory-based Bayesian framework for modeling inductive learning and reasoning as statistical inferences over structured knowledge representations.
This article discusses the importance of both statistical learning and structured domain knowledge, intuitive theories, or schemas in explaining human knowledge acquisition through inductive inference. The authors introduce a theory-based Bayesian framework that combines both components for modeling inductive learning and reasoning as statistical inferences over structured knowledge representations.
Reconstructing Constructivism: Causal Models, Bayesian Learning
Mechanisms, and the Theory Theory
Alison Gopnik
University of California at Berkeley
Henry M. Wellman
University of Michigan at Ann Arbor
We propose a new version of the "theory theory" grounded in the computational framework of
probabilistic causal models and Bayesian learning. Probabilistic models allow a constructivist but
rigorous and detailed approach to cognitive development. They also explain the learning of both more
specific causal hypotheses and more abstract framework theories. We outline the new theoretical ideas,
explain the computational framework in an intuitive and nontechnical way, and review an extensive but
relatively recent body of empirical results that supports these ideas. These include new studies of the
mechanisms of learning. Children infer causal structure from statistical information, through their own
actions on the world and through observations of the actions of others. Studies demonstrate these learning
mechanisms in children from 16 months to 4 years old and include research on causal statistical learning,
informal experimentation through play, and imitation and informal pedagogy. They also include studies
of the variability and progressive character of intuitive theory change, particularly theory of mind. These
studies investigate both the physical and the psychological and social domains. We conclude with
suggestions for further collaborative projects between developmental and computational cognitive
scientists.
Keywords: cognitive development, Bayesian inference, theory of mind, causal knowledge, intuitive
theories
The study of cognitive development suffers from a deep theo-
retical tension—one with ancient philosophical roots. As adults,
we seem to have coherent, abstract, and highly structured repre-
sentations of the world around us. These representations allow us
to make predictions about the world and to design effective plans
to change it. We also seem to learn those representations from the
fragmented, concrete, and particular evidence of our senses. De-
velopmental psychologists actually witness this learning unfold
over time. Children develop a succession of different, increasingly
accurate conceptions of the world, and it at least appears that they
do this as a result of their experience. But how can the concrete
particulars of experience become the abstract structures of knowl-
edge?
In the past, there have been no satisfying theoretical accounts of
how this kind of learning might take place. Instead, traditional
empiricist accounts, most recently in the form of connectionist and
dynamic systems theories (Elman et al., 1996; Thelen & Smith
1994), denied that there actually was the kind of abstract, coherent
structure we seem to see in adult representations. They saw instead
a distributed collection of specific associations between particular
inputs or a context-dependent assemblage of various functions.
Traditional nativist accounts, most recently in the form of modu-
larity and core knowledge theories (Pinker, 1997; Spelke, Brein-
linger, Macomber, & Jacobson, 1992; Spelke & Kinzler, 2007),
pointed to the structure, coherence, and abstractness of our repre-
sentations but denied that they could be learned.
Piaget (1926) famously tried to resolve this tension by calling
for a "constructivist" theory. But aside from the phrase itself, there
was little detail about how constructivist learning processes might
work. Piaget also made empirical claims; he described develop-
mental evidence that appeared to support constructivism. But in
the past 30 years, many of those empirical claims have been
overturned. The combination of theoretical vagueness and empir-
ical inadequacy doomed the Piagetian account.
Recently, however, a new set of computational ideas promises
to reconstruct constructivism. This new rational constructivism
(Xu, Dewar, & Perfors, 2009) uses the theoretical framework of
probabilistic models and Bayesian learning. In tandem, new em-
pirical studies, studies of the mechanisms of learning and studies
of the progressive character of development, provide support for
these theoretical ideas and suggest new areas of theoretical inves-
tigation. In this article, we weave together this new theoretical and
empirical work. The basic computational ideas and experimental
techniques we will discuss have been applied to many types of
This article was published Online First May 14, 2012.
Alison Gopnik, Department of Psychology, University of California at
Berkeley; Henry M. Wellman, Department of Psychology, University of
Michigan at Ann Arbor.
We are grateful to Noah Goodman and Laura Schulz for very helpful
comments and to Sheba Shakir and Sophie Bridges for assistance. The
article was supported by National Institute of Child Health and Human
Development Grant HD022149 to Henry M. Wellman and National Sci-
ence Foundation Grant BCS-1023875 to Alison Gopnik. Most signifi-
cantly, we acknowledge and deeply thank the members of the McDonnell
Causal Learning Collaborative and the James S. McDonnell Foundation
itself. The ideas and research reported here are a direct consequence of the
vision of both our colleagues in the collaborative and the foundation that
supported them.
Correspondence concerning this article should be addressed to Alison
Gopnik, Department of Psychology, University of California at Berkeley,
Berkeley, CA 94704. E-mail: Gopnik@berkeley.edu
Psychological Bulletin © 2012 American Psychological Association
2012, Vol. 138, No. 6, 1085-1108 0033-2909/12/$12.00 DOI: 10.1037/a0028044
This article proposes a new version of the "theory theory" in cognitive development that is grounded in the computational framework of probabilistic causal models and Bayesian learning. The authors argue that probabilistic models allow for a constructivist but rigorous and detailed approach to cognitive development, explaining the learning of both more specific causal hypotheses and more abstract framework theories.
The article reviews recent empirical studies that support these ideas, including studies of the mechanisms of learning in children from 16 months to 4 years old, such as causal statistical learning, informal experimentation through play, and imitation and informal pedagogy. These studies investigate both the physical and psychological/social domains and demonstrate the variability and progressive character of intuitive theory change, particularly theory of mind.
The authors conclude by suggesting further collaborative projects between developmental and computational cognitive scientists. The new rational constructivism proposed in this article offers a promising direction for reconciling the theoretical tension in cognitive development between the concrete particulars of experience and the abstract structures of knowledge.
Explain these, as they relate:

 Banburismus, a cryptanalytic process
Bayesian approaches to brain function
Bayesian inference in marketing
Bayesian inference in motor learning
Bayesian inference using Gibbs sampling (BUGS)
Bayesian interpretation of kernel regularization
Bayesian tool for methylation analysis (BATMAN)
Conditional Probability
Credibility theory
Evidence under Bayes' theorem
Dempster-Shafer theory, a generalization of Bayes' theorem.
History of Bayesian statistics
Inverse probability
Inverse resolution
Nested sampling algorithm
Polytree
Signaling game
Banburismus is a cryptanalytic process that was used by British codebreakers during World War II to decipher German messages. The process involved using statistical methods to analyze the patterns in encrypted messages and to infer the most likely plaintext message.
Bayesian approaches to brain function is a field of neuroscience that uses Bayesian inference to model the brain's information processing. It posits that the brain's neural activity is consistent with Bayesian statistical principles, and that the brain uses probabilistic models to make decisions and learn from experience.
Bayesian inference in marketing is the application of Bayesian statistical methods to marketing research. It involves using prior knowledge, expert opinion, and data to infer the probability of certain outcomes or events related to marketing campaigns, product launches, and customer behavior.
Bayesian inference in motor learning is the application of Bayesian statistical methods to the study of motor learning. It involves modeling the process of learning a motor skill as a probabilistic inference problem, and using prior knowledge and feedback to update the learner's beliefs about the task.
Bayesian inference using Gibbs sampling (BUGS) is a computational method for performing Bayesian inference on complex models. It involves simulating the joint probability distribution of the model parameters using a Markov chain Monte Carlo (MCMC) algorithm.
Bayesian interpretation of kernel regularization is a technique used in machine learning that involves using Bayesian inference to regularize the parameters of a model. It involves placing a prior distribution on the parameters, which allows for regularization and uncertainty quantification.
Bayesian tool for methylation analysis (BATMAN) is a software package used for the analysis of DNA methylation data. It uses a Bayesian statistical framework to model the methylation patterns in genomic data and to infer the most likely methylation state at each genomic location.
Conditional probability is the probability of an event occurring given that another event has occurred. It is calculated by dividing the joint probability of both events by the probability of the event that has already occurred.
Credibility theory is a field of actuarial science that involves the analysis of insurance risk. It uses Bayesian statistical methods to estimate the probability of an insurance claim occurring based on historical data and other relevant factors.
Evidence under Bayes' theorem refers to the probability of a hypothesis given the available data. Bayes' theorem allows for the updating of prior beliefs based on new evidence, and provides a way to quantify the strength of evidence in favor of a particular hypothesis.
Dempster-Shafer theory is a generalization of Bayes' theorem that allows for reasoning with uncertain or incomplete information. It involves assigning belief functions to sets of hypotheses, and combining these belief functions to obtain a measure of the degree of belief in a particular hypothesis.
The history of Bayesian statistics traces the development of Bayesian inference from its origins in the work of Thomas Bayes and Pierre-Simon Laplace to its modern applications in fields such as machine learning, finance, and medicine.
Inverse probability is a statistical concept that involves reversing the direction of probability statements. Instead of calculating the probability of an event given certain conditions, inverse probability involves calculating the probability of certain conditions given that an event has occurred.
Inverse resolution is a problem-solving technique used in artificial intelligence and logic programming. It involves starting with a desired conclusion and working backwards to determine the necessary conditions for that conclusion to be true.
Nested sampling algorithm is a computational method used to estimate the marginal likelihood of a statistical model. It involves iteratively sampling from a sequence of nested probability distributions, and using the samples to estimate the likelihood.
Polytree is a type of graphical model used in probabilistic inference. It consists of a directed acyclic graph in which nodes represent random variables and edges represent probabilistic dependencies between them.
Signaling game is a type of game theory model that involves two players communicating with each other to achieve a certain outcome. It is often
Approximate Bayesian computation
Bayesian average
Bayesian Analysis (journal)
Bayesian approaches to brain function
Bayesian bootstrap
Bayesian control rule
Bayesian cognitive science
Bayesian econometrics
Bayesian efficiency
Bayesian epistemology
Approximate Bayesian computation: A computational technique for approximate inference in Bayesian statistics when the likelihood function is intractable or unknown, but it is possible to simulate data from the model.
Bayesian average: A type of weighted average that incorporates prior information or beliefs about the distribution of the data into the calculation of the mean.
Bayesian Analysis (journal): A peer-reviewed academic journal that publishes research articles and reviews on all aspects of Bayesian analysis and its applications.
Bayesian approaches to brain function: A framework for understanding how the brain processes information and makes decisions by using probabilistic models and Bayesian inference.
Bayesian bootstrap: A method for generating posterior distributions in Bayesian inference by simulating data from the prior and resampling from the posterior using a weighted bootstrap scheme.
Bayesian control rule: A decision-making rule that incorporates Bayesian inference to optimize the control of a system over time.
Bayesian cognitive science: An interdisciplinary field that uses Bayesian models and Bayesian inference to study cognitive processes and behavior.
Bayesian econometrics: A branch of econometrics that uses Bayesian inference to estimate economic models and make predictions.
Bayesian efficiency: A measure of the efficiency of statistical inference methods in terms of their ability to make use of available information and minimize errors.
Bayesian epistemology: A philosophical approach to knowledge and belief that uses Bayesian inference to formalize and evaluate theories of knowledge and justification.
Bayesian expected loss
Bayesian experimental design
Bayesian game
Bayesian hierarchical modeling
Bayesian History Matching
Bayesian inference
Bayesian inference in phylogeny
Bayesian information criterion (BIC) and
Widely applicable Bayesian information criterion (WBIC)
Bayesian expected loss: A decision-making framework that uses Bayesian inference to estimate the expected loss associated with different decisions. This involves modeling the uncertainty in the decision-making process and incorporating prior knowledge to make better decisions.
Bayesian experimental design: A statistical approach to optimize the design of experiments by using Bayesian inference to select the most informative data points. This involves selecting experimental conditions that will provide the most information about the parameters of interest.
Bayesian game: A game-theoretic framework that uses Bayesian inference to model players' beliefs about the other players' strategies and payoffs. This allows for a more realistic and flexible modeling of strategic interactions in complex environments.
Bayesian hierarchical modeling: A statistical modeling approach that involves modeling multiple levels of variability using Bayesian inference. This allows for more complex and flexible modeling of relationships between variables.
Bayesian History Matching: A statistical method for calibrating and validating complex computer models by comparing the model output to observed data. This involves using Bayesian inference to estimate the uncertainty in the model parameters and selecting the parameter values that provide the best match to the observed data.
Bayesian inference: A statistical approach to update beliefs and make predictions based on observed data and prior knowledge. It involves using Bayes' theorem to calculate the posterior probability distribution of the parameters of interest, given the observed data and the prior distribution.
Bayesian inference in phylogeny: A statistical approach to reconstructing evolutionary relationships between species using Bayesian inference. This involves modeling the evolution of DNA sequences and using Bayesian inference to estimate the most likely phylogenetic tree.
Bayesian information criterion (BIC) and Widely applicable Bayesian information criterion (WBIC): Model selection criteria that use Bayesian inference to compare different statistical models based on their goodness of fit and complexity. BIC is a widely used criterion that penalizes models for complexity, while WBIC is a more flexible criterion that can be applied to a wider range of models.
Bayesian Kepler periodogram
Bayesian Knowledge Tracing
Bayesian learning mechanisms
Bayesian linear regression
Bayesian model of computational anatomy
Bayesian model averaging (BMA)
Bayesian model combination (BMC)
Bayesian Kepler periodogram: A method to search for exoplanets using Bayesian inference to fit a model to time series of stellar brightness data. The method was developed based on the classical Kepler periodogram, but with additional Bayesian statistical tools to improve the robustness and reliability of the analysis.
Bayesian Knowledge Tracing: A machine learning algorithm used in educational technology that models the probability of a student mastering a particular skill or concept over time, based on their performance on a series of assessments. The algorithm uses Bayesian inference to update its estimates of the student's knowledge state with each new piece of data.
Bayesian learning mechanisms: A general term for any learning algorithm or system that incorporates Bayesian inference. These mechanisms use prior knowledge and probabilities to update beliefs about new data and generate predictions or decisions based on those beliefs.
Bayesian linear regression: A statistical method for modeling the relationship between a dependent variable and one or more independent variables, using Bayesian inference to estimate the model parameters and uncertainty.
Bayesian model of computational anatomy: A mathematical model that combines Bayesian inference with computational anatomy to analyze and understand brain structure and function.
Bayesian model averaging (BMA): A statistical technique that uses Bayesian inference to combine multiple models into a single, more accurate model. BMA assigns weights to each model based on its likelihood of producing the observed data, and then combines the models by taking a weighted average of their predictions.
Bayesian model combination (BMC): A similar approach to BMA, but instead of averaging the models, it selects the best model from the set of candidate models based on their posterior probabilities.
Just give the commonalities: Bayesian model reduction
Bayesian model selection
Bayesian multivariate linear regression
Bayesian Nash equilibrium
Bayesian network
Bayesian neural network
Bayesian operational modal analysis (BAYOMA)
Bayesian-optimal mechanism
Bayesian-optimal pricing
Bayesian optimization
Bayesian poisoning
Bayesian probability
Bayesian procedures
Bayesian programming
Bayesian program synthesis
Bayesian quadrature
Bayesian regret
Bayesian search theory
Bayesian spam filtering
Bayesian statistics
Bayesian structural time series
Bayesian support-vector machine
Bayesian survival analysis
Bayesian template estimation
Bayesian tool for methylation analysis
Bayesian vector autoregression
Dynamic Bayesian network
International Society for Bayesian Analysis
Perfect Bayesian equilibrium (PBE)
Quantum Bayesianism
Recursive Bayesian estimation
Robust Bayesian analysis
Variable-order Bayesian network
Variational Bayesian methods
The commonality among these terms is that they are all related to Bayesian statistics or Bayesian methods, which involve using probability theory and Bayes' theorem to update beliefs or knowledge about a particular hypothesis or model based on new data or evidence. These methods are widely used in various fields such as statistics, machine learning, data analysis, econometrics, marketing, and many others. They all involve some form of probabilistic inference and can provide a flexible and powerful framework for modeling complex systems and making predictions or decisions under uncertainty.
Give a detailed account of the interconnections, particularly as it relates to our discussion earlier:

Bayes action
Bayes Business School
Bayes classifier
Bayes discriminability index
Bayes error rate
Bayes estimator
Bayes factor
Bayes Impact
Bayes linear statistics
Bayes prior
Bayes' theorem / Bayes-Price theorem -- sometimes called Bayes' rule or Bayesian updating.
The interconnections between the terms are rooted in the concept of Bayesian inference, which is a statistical method used for updating beliefs or probabilities based on new data. Bayes' theorem or Bayes-Price theorem is the foundation of Bayesian inference, and it states that the probability of a hypothesis or event given some data is proportional to the prior probability of the hypothesis multiplied by the likelihood of the data given the hypothesis. Bayes theorem is sometimes called Bayes' rule or Bayesian updating.
Bayesian updating is used in a wide range of applications, including Bayes action, which is a decision-making process that uses Bayesian inference to determine the best course of action given the available data. Bayes estimator is a method for finding the best estimate of an unknown parameter based on a set of observations, using Bayes' theorem. Bayes prior is the prior probability distribution used in Bayesian inference.
Bayes classifier is a statistical classification algorithm that uses Bayes' theorem to classify data into categories based on observed features. Bayes discriminability index measures the ability of a classifier to distinguish between two classes of data. Bayes error rate is the probability of misclassification when using a Bayes classifier.
Bayes factor is a statistical measure used in Bayesian model selection to compare the fit of two or more models to the observed data. Bayes linear statistics is a framework for Bayesian inference that uses linear models to represent the relationship between variables.
Bayes Impact is a nonprofit organization that applies Bayesian reasoning and probabilistic modeling to social impact problems. It was founded in 2013 by Dustin Tran and Adam Elmachtoub, who were graduate students at Columbia University at the time.
Overall, the interconnections between these terms all relate to the concept of Bayesian inference and the use of Bayes' theorem or Bayesian updating to make decisions, estimate parameters, classify data, select models, and solve various other problems in a probabilistic framework.
And to the history of science?

Empirical Bayes method
Evidence under Bayes theorem
Hierarchical Bayes model
Laplace-Bayes estimator
Naive Bayes classifier
Random naive Bayes
The development of Bayesian statistics has a rich history in the field of science. One of the earliest proponents of Bayesian thinking was Reverend Thomas Bayes in the 18th century, who developed what is now known as Bayes' theorem. However, Bayesian statistics did not gain significant traction until the 20th century, when advances in computing made it possible to perform complex Bayesian analyses.
In the mid-20th century, the Empirical Bayes method was developed, which allowed for the estimation of parameters in complex statistical models. This method was used in a variety of fields, including astronomy and genetics.
The concept of evidence under Bayes' theorem was developed in the late 20th century, which allowed for the integration of prior beliefs with new evidence in a rational and quantitative manner.
The hierarchical Bayes model, also known as the multilevel model, was developed in the 1970s and 1980s. This model allows for the estimation of parameters at multiple levels of a data set, such as individuals nested within groups.
The Laplace-Bayes estimator, also known as the Bayesian estimator, was developed in the early 19th century by Pierre-Simon Laplace. This estimator is used to estimate the parameters of a probability distribution using Bayesian methods.
The Naive Bayes classifier was developed in the 1960s and 1970s, and is used in machine learning and natural language processing to classify text data based on their features.
The random naive Bayes method is a variant of the Naive Bayes classifier that takes into account the uncertainty in the classification process. This method is useful in situations where the data are highly variable or noisy.
Overall, Bayesian statistics has a long and storied history in science, and has been used in a variety of fields to analyze complex data sets and make predictions about the future.
Ok we are going to say that is the historical chronology of the idea of the discovery of the idea and its population, meanwhile, there has been a kind of logic being played out on network of collectively autocatalytic sets, in the clay mineral world before the invention of fatty lipid cell walls, for billion years a logic worked on it, the constraints of the environment, to say nothing of the development of perceptual sensation in plants and animals.
I see. It's interesting to think about the role of network dynamics and autocatalytic sets in the evolution of life on Earth. The concept of autocatalytic sets was first proposed by Stuart Kauffman in the 1980s, but it has roots in the work of Ilya Prigogine and others on self-organizing systems and the emergence of order from chaos.
Autocatalytic sets are networks of chemical reactions in which the products of one reaction serve as the catalysts for other reactions in the set. These networks can exhibit emergent properties such as self-organization and adaptation, and they may have played a role in the origin of life on Earth.
The evolution of life on Earth has also been shaped by the constraints of the environment, including factors such as temperature, pH, and the availability of nutrients. Organisms that are better adapted to their environment are more likely to survive and reproduce, passing on their traits to future generations. This process of natural selection has been a driving force in the evolution of life on Earth.
Perceptual sensation in plants and animals has also played a role in the evolution of life. Sensory systems allow organisms to detect and respond to their environment, enabling them to find food, avoid predators, and navigate their surroundings. The development of complex nervous systems has allowed some organisms to learn and adapt to changing environments over time.
ChatGPT Mar 14 Version
. Free Research Preview. Our goal is to make AI systems more natural and safe to interact with. Your feedback will help us improve.
New chat