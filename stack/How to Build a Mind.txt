How to Build a Mind
Open sidebar
How to Build a Mind
Summarize: 
MIND & BRAIN
The Video Game Engine in Your Head
Scientists use video games to explain how the brain interprets the world around us. 

By Joshua Hartshorne on April 1, 2014
For years now, physicists and engineers have been building computer simulations of physics in order to understand the behavior of objects in the world. Want to see if a bridge would be stable during an earthquake? Enter it into the simulation, apply earthquake dynamics, and see what happens.

Recently, the prestigious Proceedings of the National Academy of Sciences published work by MIT psychologists (and my labmates) Peter Battaglia, Jessica Hamrick, and Joshua Tenenbaum, arguing that all humans do roughly the same thing when trying to understand or make predictions about the physical world. The primary difference is that we run our simulations in our brains rather than in digital computers, but the basic algorithms are roughly equivalent. The analogy runs deep: To model human reasoning about the physical world, the researchers actually used an open-source computer game physics engine ��� the software that applies the laws of physics to objects in video games in order to make them interact realistically (think Angry Birds). 

Battaglia and colleagues found that their video game-based computer model matches human physical reasoning far better than any previous theory. The authors asked people to make a number of predictions about the physical world: will tower of blocks stand or fall over, what direction would it fall over, and where would the block that landed the farthest away land; which object would most likely fall off of a table if the table was bumped; and so on. In each case, human judgments closely matched the prediction of the computer simulation ... but not necessarily the actual world, which is where it gets interesting.

Whether or not a tower of blocks (or a bridge, etc.) will fall over depends on its exact dimensions and the exact position of each block, potentially down to the millimeter. But a human can't tell the dimensions and position of every block down to the millimeter just by looking. That is why we invented rulers. Instead, we know approximately how big each block is and where it is. If the simulation was given the exact coordinates of the blocks, it predicted human judgments reasonably well but far from perfectly. If the simulation was given approximate coordinates, taking into account human uncertainty, it matched the actual world less well but human judgments very well.

In retrospect, it may seem intuitive that when we made predictions about the physical world ��� what will happen to towers during earthquakes or books on shelves ��� we query an internal, virtual simulation of the real world, but it represents a sharp departure from previous scientific thinking. Many scientists thought that we use rules-of-thumb to predict the world around us.
 
As a theory, the rules-of-thumb account seems to be a failure: Battaglia and colleagues tested a number of plausible rules-of-thumb. For instance, maybe we base our guesses as to whether a block tower will fall based on the tower���s height or center of mass. None of the rules-of-thumb fared as well as the simulation account. Even worse, rules-of-thumb have to be tailored to the question: The heuristics for the tower of blocks scenario are useless for the table-bump scenario. In contrast, simulations are one-size-fits-all.

But that leaves the question of whether the simulation account is plausible. After all, if we already have a physics simulator in our heads, why did scientists have to discover the laws of physics, and why do we have to learn physics in school (or not at all)? Part of the answer may lie in the distinction between implicit and explicit knowledge. A bird doesn't have to be able to teach a university course on aerodynamics in order to fly, and we don't have to understand biophysics in order to walk or neuroscience in order to think.
1 / 1
ChatGPT
ChatGPT
In a study published in the Proceedings of the National Academy of Sciences, MIT psychologists explored how humans understand and predict the physical world. They found that humans employ a simulation process in their brains similar to video game physics engines. By using an open-source computer game physics engine, the researchers demonstrated that their video game-based computer model closely matched human physical reasoning. However, it was noted that human judgments were not always aligned with the actual world, highlighting the role of human uncertainty and approximation in decision-making. This approach challenges the notion that humans rely on rules-of-thumb to predict the world around them. While the simulation account offers a plausible explanation, it also raises questions about the need for discovering scientific laws and studying physics, suggesting a distinction between implicit and explicit knowledge in human cognition.
1 / 1
Summarize: How to Grow a Mind: Statistics,
Structure, and Abstraction
Joshua B. Tenenbaum,1
* Charles Kemp,2 Thomas L. Griffiths,3 Noah D. Goodman4
In coming to understand the world���in learning concepts, acquiring language, and grasping
causal relations���our minds make inferences that appear to go far beyond the data available.
How do we do it? This review describes recent approaches to reverse-engineering human learning
and cognitive development and, in parallel, engineering more humanlike machine learning
systems. Computational models that perform probabilistic inference over hierarchies of flexibly
structured representations can address some of the deepest questions about the nature and origins
of human thought: How does abstract knowledge guide learning and reasoning from sparse
data? What forms does our knowledge take, across different domains and tasks? And how is that
abstract knowledge itself acquired?
The Challenge: How Does the Mind Get
So Much from So Little?
For scientists studying how humans come
to understand their world, the central challenge is this: How do our minds get so
much from so little? We build rich causal models,
make strong generalizations, and construct powerful abstractions, whereas the input data are
sparse, noisy, and ambiguous���in every way far
too limited. A massive mismatch looms between
the information coming in through our senses
and the ouputs of cognition.
Consider the situation of a child learning the
meanings of words. Any parent knows, and scientists have confirmed (1, 2), that typical 2-yearolds can learn how to use a new word such as
���horse��� or ���hairbrush��� from seeing just a few
examples. We know they grasp the meaning, not
just the sound, because they generalize: They
use the word appropriately (if not always perfectly) in new situations. Viewed as a computation on sensory input data, this is a remarkable
feat. Within the infinite landscape of all possible
objects, there is an infinite but still highly constrained subset that can be called ���horses��� and
another for ���hairbrushes.��� How does a child grasp
the boundaries of these subsets from seeing just
one or a few examples of each? Adults face the
challenge of learning entirely novel object concepts
less often, but they can be just as good at it (Fig. 1).
Generalization from sparse data is central in
learning many aspects of language, such as syntactic constructions or morphological rules (3).
It presents most starkly in causal learning: Every
statistics class teaches that correlation does
not imply causation, yet children routinely infer causal links from just a handful of events (4),
far too small a sample to compute even a reliable correlation! Perhaps the deepest accomplishment of cognitive development is the construction
of larger-scale systems of knowledge: intuitive
theories of physics, psychology, or biology or rule
systems for social structure or moral judgment.
Building these systems takes years, much longer
than learning a single new word or concept, but
on this scale too the final product of learning far
outstrips the data observed (5���7).
Philosophers have inquired into these puzzles for over two thousand years, most famously
as ���the problem of induction,��� from Plato and
Aristotle through Hume, Whewell, and Mill to
Carnap, Quine, Goodman, and others in the 20th
century (8). Only recently have these questions
become accessible to science and engineering by
viewing inductive learning as a species of computational problems and the human mind as a natural computer evolved for solving them.
The proposed solutions are, in broad strokes,
just what philosophers since Plato have suggested. If the mind goes beyond the data given,
another source of information must make up
the difference. Some more abstract background
knowledge must generate and delimit the hypotheses learners consider, or meaningful generalization would be impossible (9, 10). Psychologists
and linguists speak of ���constraints;��� machine learning and artificial intelligence researchers, ���inductive bias;��� statisticians, ���priors.���
This article reviews recent models of human
learning and cognitive development arising at
the intersection of these fields. What has come
to be known as the ���Bayesian��� or ���probabilistic���
approach to reverse-engineering the mind has been
heavily influenced by the engineering successes of
Bayesian artificial intelligence and machine
learning over the past two decades (9, 11) and,
in return, has begun to inspire more powerful and
more humanlike approaches to machine learning.
As with ���connectionist��� or ���neural network���
models of cognition (12) in the 1980s (the last
moment when all these fields converged on a
common paradigm for understanding the mind),
the labels ���Bayesian��� or ���probabilistic��� are merely placeholders for a set of interrelated principles
and theoretical claims. The key ideas can be
thought of as proposals for how to answer three
central questions:
1) How does abstract knowledge guide learning and inference from sparse data?
2) What forms does abstract knowledge take,
across different domains and tasks?
3) How is abstract knowledge itself acquired?
We will illustrate the approach with a focus
on two archetypal inductive problems: learning
concepts and learning causal relations. We then
briefly discuss open challenges for a theory of human cognitive development and conclude with a
summary of the approach���s contributions.
We will also draw contrasts with two earlier
approaches to the origins of knowledge: nativism
and associationism (or connectionism. These approaches differ in whether they propose stronger
or weaker capacities as the basis for answering
the questions above. Bayesian models typically
combine richly structured, expressive knowledge
representations (question 2) with powerful statistical inference engines (questions 1 and 3), arguing
that only a synthesis of sophisticated approaches
to both knowledge representation and inductive
inference can account for human intelligence. Until
recently it was not understood how this fusion
could work computationally. Cognitive modelers
were forced to choose between two alternatives
(13): powerful statistical learning operating over
the simplest, unstructured forms of knowledge,
such as matrices of associative weights in connectionist accounts of semantic cognition (12, 14),
or richly structured symbolic knowledge equipped
with only the simplest, nonstatistical forms of
learning, checks for logical inconsistency between
hypotheses and observed data, as in nativist accounts of language acquisition (15). It appeared
necessary to accept either that people���s abstract
knowledge is not learned or induced in a nontrivial
sense from experience (hence essentially innate)
or that human knowledge is not nearly as abstract or structured (as ���knowledge-like���) as it
seems (hence simply associations). Many developmental researchers rejected this choice altogether and pursued less formal approaches to
describing the growing minds of children, under
the headings of ���constructivism��� or the ���theory
theory��� (5). The potential to explain how people can genuinely learn with abstract structured
knowledge may be the most distinctive feature
of Bayesian models: the biggest reason for their
recent popularity (16) and the biggest target of
skepticism from their critics (
1 / 1
ChatGPT
ChatGPT
This article discusses the challenge of understanding how the human mind is able to make inferences that go beyond the available data in various cognitive tasks. It explores the reverse-engineering of human learning and cognitive development and the development of more humanlike machine learning systems. The article focuses on computational models that perform probabilistic inference over hierarchies of structured representations. It addresses questions about how abstract knowledge guides learning from sparse data, the forms that abstract knowledge takes across different domains, and how abstract knowledge is acquired. The article highlights the mismatch between the limited input data from our senses and the rich cognitive outputs we produce. It discusses examples such as learning word meanings and generalizing from sparse data in language and causal learning. The article presents the Bayesian or probabilistic approach to understanding the mind, influenced by Bayesian artificial intelligence and machine learning. It emphasizes the role of abstract background knowledge, constraints, and priors in enabling meaningful generalization and addresses the challenges of learning concepts and causal relations. The article contrasts this approach with nativism and associationism and highlights the potential of Bayesian models to explain how people learn with abstract structured knowledge.
1 / 1
Connections between the topics.
1 / 1
ChatGPT
ChatGPT
Both articles explore the nature of human cognition and the challenges it poses in understanding and learning from limited data. While the first article focuses on the use of video game physics engines as a model for human reasoning about the physical world, the second article delves into the reverse-engineering of human learning and cognitive development through probabilistic inference over structured representations.
The first article highlights how humans run internal simulations, similar to video game physics engines, to make predictions about the physical world. It emphasizes the role of approximation and human uncertainty in decision-making and challenges the notion that humans rely solely on rules-of-thumb. The second article addresses the broader issue of how the human mind extracts meaningful knowledge from sparse, noisy, and ambiguous data across various cognitive tasks.
Both articles emphasize the importance of abstract knowledge in guiding human cognition. The second article specifically focuses on how abstract knowledge plays a crucial role in learning concepts, generalizing from limited data, and constructing larger-scale systems of knowledge. It argues that a synthesis of sophisticated approaches to knowledge representation and statistical inference, as seen in Bayesian models, is necessary to account for human intelligence.
Furthermore, both articles discuss the limitations of traditional approaches in explaining human cognition. The first article critiques the rules-of-thumb account for physical reasoning, while the second article contrasts Bayesian models with nativism and associationism, highlighting the unique ability of Bayesian models to explain how people can learn with abstract structured knowledge.
Overall, these articles provide insights into the underlying mechanisms of human cognition, the challenges involved in learning and reasoning from limited data, and the potential of computational models to unravel the nature and origins of human thought.
1 / 1
Explain how to build a brain by simulating a mind using perceptual control theory.
1 / 1
ChatGPT
ChatGPT
Building a brain by simulating a mind using perceptual control theory involves understanding the principles and concepts of perceptual control theory (PCT) and applying them in the development of a simulated cognitive system. Here's a general overview of the steps involved:
Understand Perceptual Control Theory (PCT): Perceptual control theory is a psychological framework that explains how organisms regulate their behavior to maintain desired goals or outcomes. It posits that individuals continually compare their current perception of the world with their desired perception and take actions to minimize any discrepancies between the two. Familiarize yourself with the key principles and concepts of PCT, including reference signals, control systems, and negative feedback loops.
Define the goals and behaviors of the simulated mind: Determine the specific goals or outcomes that the simulated mind should achieve and the corresponding behaviors it should exhibit. This could include tasks like problem-solving, decision-making, learning, or perception. Clearly defining the objectives will guide the development of the simulated cognitive system.
Design a control system: Based on the goals and behaviors identified in step 2, develop a control system that emulates the functioning of the human brain. The control system should consist of sensory inputs, reference signals representing desired perceptions or states, and an action system that adjusts behavior to minimize the discrepancies between the perceived and desired states.
Implement the control system in a simulated environment: Create a simulated environment that allows the control system to interact with and perceive its surroundings. This could be a virtual environment or a computer-based simulation. The simulated mind should receive sensory inputs from the environment and use the control system to regulate its behavior in response to the perceived information.
Test and refine the simulation: Run experiments and simulations to test the performance of the simulated mind. Evaluate how well it achieves the desired goals and behaviors. Identify any areas of improvement or inconsistencies and make necessary adjustments to the control system or simulated environment.
Iterate and optimize: Refine and iterate the simulation based on the feedback and results obtained from testing. Continue to modify the control system, adjust parameters, and enhance the simulated environment to improve the overall performance and realism of the simulated mind.
Validate against empirical data: Compare the behavior and performance of the simulated mind against empirical data or observations of human cognition. Validate the simulation by ensuring that it aligns with known cognitive processes and behaviors.
It's important to note that building a complete and fully functional brain using simulation is an extremely complex task that goes beyond the scope of current capabilities. However, simulating aspects of the mind using PCT can provide valuable insights into cognitive processes and contribute to the development of more sophisticated artificial intelligence systems.
1 / 1
Abstract:
Autonomous systems can be found in areas such as automotives, robotics, avionics, industry automation, and many more. Such systems become increasingly ���intelligent��� with the rise of machine learning techniques. Designing such systems has, therefore, become even more complex since new parameters significantly increase the design space and capabilities of such systems. An overview of this complex design process that also includes test, verification, and so on is brought to us by the guest editors of this special issue, Selma Saidi, Dirk Ziegenbein, Jyotirmoy V. Deshmukh, and Rolf Ernst. The guest editors have selected four articles for this special issue. They also introduce the readers to this field in their overview article titled ���Autonomous Systems Design: Charting a New Discipline,��� which lays the foundation for understanding and awareness of the complexity when designing and testing autonomous systems. Thanks to the guest editors for this special issue that covers the IEEE Design&Test topical area ���systems of systems.���
1 / 1
ChatGPT
ChatGPT
The abstract discusses the increasing complexity of designing autonomous systems, particularly in areas like automotives, robotics, avionics, and industry automation, due to the integration of machine learning techniques. The design process of these systems, including testing and verification, is explored in a special issue introduced by guest editors Selma Saidi, Dirk Ziegenbein, Jyotirmoy V. Deshmukh, and Rolf Ernst. The special issue provides an overview of the design challenges and complexities in autonomous systems and includes four articles that delve into various aspects of this field. The guest editors' overview article, titled "Autonomous Systems Design: Charting a New Discipline," serves as a foundation for understanding and addressing the intricacies involved in designing and testing autonomous systems. The special issue focuses on the "systems of systems" aspect within the IEEE Design&Test topical area.
1 / 1
How to build a brain.
1 / 1
ChatGPT
ChatGPT
Building a brain is an incredibly complex task, and our current understanding of the brain is still limited. However, I can provide a general overview of some key aspects involved in building a brain-like system.
Study the Brain: Start by studying the structure, function, and processes of the human brain. This includes exploring neuroanatomy, neurophysiology, and cognitive neuroscience to understand how the brain processes information, learns, and performs various tasks.
Simulate Neural Networks: Neural networks are the fundamental building blocks of the brain. Develop computational models and simulations that mimic the behavior of neural networks. Artificial Neural Networks (ANNs), such as deep learning models, can be used to simulate the information processing and learning capabilities of the brain.
Emulate Neuronal Connectivity: The brain consists of billions of interconnected neurons. Develop models and algorithms that replicate the connectivity patterns found in the brain. This involves understanding how neurons communicate through synapses and developing techniques to simulate these interactions.
Implement Learning Mechanisms: The brain is a highly adaptive system that can learn from experience. Integrate learning mechanisms into the brain model, such as reinforcement learning, unsupervised learning, and supervised learning, to enable the system to acquire knowledge and improve performance over time.
Incorporate Sensory Input: The brain processes information from various sensory modalities. Include sensory input interfaces in your brain-like system to receive and process data from the environment. This could involve integrating technologies like computer vision, speech recognition, or tactile sensors.
Develop Cognitive Abilities: The brain exhibits a wide range of cognitive abilities, including perception, attention, memory, reasoning, and decision-making. Design algorithms and mechanisms that enable your brain-like system to perform these cognitive functions effectively.
Test and Validate: Continuously test and validate your brain-like system against real-world scenarios and benchmarks. Compare its performance to human capabilities and evaluate its ability to adapt, learn, and solve complex problems.
It's important to note that building a complete functioning human brain is currently beyond our technological capabilities. However, researchers and engineers are making significant progress in developing brain-inspired systems and artificial intelligence that draw inspiration from the brain's principles.
1 / 1
Specifically with the topics and themes discussed earlier.
1 / 1
ChatGPT
ChatGPT
Certainly! Based on the topics and themes discussed earlier, here's a more specific approach to building a brain-like system using perceptual control theory:
Understand Perceptual Control Theory (PCT): Familiarize yourself with Perceptual Control Theory, which posits that the brain operates by continuously comparing perceptions with reference values and adjusting actions to maintain control over desired variables. Study how PCT explains the brain's ability to regulate behavior and achieve goals.
Model Control Systems: Develop computational models inspired by PCT to simulate control systems within the brain. These models should include feedback loops that compare sensory perceptions with desired reference values and generate actions to achieve control. Consider incorporating concepts like feedback control, error signals, and reference signals into your model.
Emulate Neural Networks: Simulate the neural networks involved in perceptual control using artificial neural networks (ANNs). ANNs can mimic the behavior of neurons and their interconnections. Design and train ANNs that can process sensory inputs, generate appropriate control signals, and adjust actions to maintain desired reference values.
Incorporate Learning Mechanisms: Integrate learning mechanisms into your brain model to replicate the brain's ability to adapt and improve over time. This could involve incorporating reinforcement learning algorithms that allow the system to learn from rewards or punishments, adjust control parameters, and optimize its performance.
Implement Sensorimotor Integration: Incorporate sensory inputs into your brain-like system. Develop interfaces that allow the system to receive and process sensory information from the environment, such as visual, auditory, or tactile inputs. These inputs should be integrated into the control system to enable perception-action coupling.
Develop Cognitive Abilities: Extend your brain-like system to encompass various cognitive abilities. Design algorithms and mechanisms that enable the system to perform higher-level cognitive functions, such as attention, memory, decision-making, and problem-solving. Consider how these cognitive processes interact with the perceptual control system.
Validate and Refine: Test and validate your brain-like system by comparing its behavior to real-world scenarios and human performance. Evaluate its ability to regulate perceptions, achieve control over variables, and exhibit adaptive behavior. Refine and adjust your model based on experimental results and insights from cognitive neuroscience research.
It's important to note that building a fully functional brain is an ongoing challenge, and current models are still simplified representations. However, by following these steps and incorporating the principles of PCT, you can develop a brain-like system that captures some aspects of how the brain perceives, controls, and learns in order to achieve desired goals.
1 / 1
How to build a mind
1 / 1
ChatGPT
ChatGPT
Building a mind is a complex task, but here are some general steps to consider when approaching the development of a mind-like system:
Define the Purpose and Scope: Determine the purpose and goals of the mind you want to build. Consider the specific cognitive abilities and functionalities you want the mind to possess, such as perception, reasoning, learning, memory, and decision-making. Define the scope of the mind by specifying the tasks or domains it will operate in.
Study Cognitive Science and Neuroscience: Gain a solid understanding of cognitive science and neuroscience to inform your approach. Familiarize yourself with theories and models of the mind, such as computational cognitive models and neural networks, to gain insights into how the brain processes information and performs cognitive tasks.
Choose an Architectural Framework: Select an architectural framework that provides a structure for building the mind. Examples include symbolic architectures (e.g., rule-based systems), connectionist architectures (e.g., artificial neural networks), or hybrid architectures that combine multiple approaches. Consider the strengths and limitations of each framework in relation to your mind's goals.
Implement Perception and Sensing: Develop mechanisms for perceiving and sensing the environment. Determine how the mind will receive and interpret sensory inputs, such as visual, auditory, or tactile information. Implement algorithms or models that allow the mind to process and make sense of these sensory inputs.
Design Cognitive Processes: Define the cognitive processes required for your mind. This may involve creating algorithms or models for tasks like pattern recognition, language processing, problem-solving, decision-making, and learning. Consider how these processes interact and integrate with each other to support higher-level cognitive functions.
Incorporate Learning and Adaptation: Enable the mind to learn and adapt based on experience. Implement learning algorithms, such as reinforcement learning, supervised learning, or unsupervised learning, to allow the mind to acquire new knowledge, refine its cognitive processes, and improve its performance over time.
Test and Evaluate: Evaluate the performance and behavior of your mind-like system. Test it against relevant tasks or scenarios to assess its effectiveness, accuracy, and efficiency. Use benchmarks or human performance as references for comparison. Iterate and refine your design based on the evaluation results.
Continuously Improve and Refine: Building a mind is an iterative process. Continuously update and refine your mind-like system based on new research findings, user feedback, and insights from cognitive science and neuroscience. Aim to enhance its capabilities, optimize its performance, and align it more closely with human-like cognition.
Remember that building a complete and fully functional mind is a challenging task, and current models are still far from replicating the complexities of human cognition. However, by following these steps and leveraging knowledge from cognitive science and neuroscience, you can develop a mind-like system that exhibits some cognitive abilities and approaches human-like performance in specific domains.
1 / 1
Free Research Preview. ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT May 24 Version
ChatGPT

