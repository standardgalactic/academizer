Intro to Deep Learning
Open sidebar
Intro to Deep Learning
Model: Default (GPT-3.5)
Summarize:

Deep Learning and Geometric Deep Learning: 
an introduction for mathematicians and physicists 
R. Fioresi, F. Zanchetta1 
FaBiT, via San Donato 15, 41127 Bologna, Italy 
rita.f i oresi@unibo.it, ferdinando.zanchett2@unibo.it 
Abstract 
In this expository paper we want to give a brief introduction, with 
few key references for further reading, to the inner functioning of the 
new and successfull algorithms of Deep Learning and Geometric Deep 
Learning with a focus on Graph Neural Networks. We go over the key 
ingredients for these algorithms: the score and loss function and we 
explain the main steps for the training of a model. We do not aim to 
give a complete and exhaustive treatment, but we isolate few concepts 
to give a fast introduction to the subject. We provide some appendices 
to complement our treatment discussing Kullback-Leibler divergence, 
regression, Multi-layer Perceptrons and the Universal Approximation 
Theorem. 
Contents 
1Introduction2 
2Supervised Classif i cation4 
2.1Supervised image classif i cation datasets . . . . . . . . . . . . .4 
2.2Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .8 
3Deep Learning12 
3.1Score Function. . . . . . . . . . . . . . . . . . . . . . . . . .12 
3.2Loss Function . . . . . . . . . . . . . . . . . . . . . . . . . . .16 
4Geometric Deep Learning: Graph Neural Networks17 
4.1Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .18 
4.2Laplacian on graphs. . . . . . . . . . . . . . . . . . . . . . .21 
4.3Heat equation . . . . . . . . . . . . . . . . . . . . . . . . . . .24 
1This research was supported by Gnsaga-Indam, by COST Action CaLISTA CA21109 
and by HORIZON-MSCA-2022-SE-01-01 CaLIGOLA. 
1 
arXiv:2305.05601v1 
[cs.LG] 
9 
May 
2023 
4.4Supervised Classif i cation on Graphs . . . . . . . . . . . . . . .26 
4.5The Score function in Graph Neural Networks . . . . . . . . .27 
4.6The Zachary Karate Club. . . . . . . . . . . . . . . . . . . .29 
4.7Graph Attention Networks . . . . . . . . . . . . . . . . . . . .32 
A Fisher matrix and Information Geometry34 
B Regression tasks38 
C Multi-layer perceptrons and Convolutional Neural Networks 40 
D Universal Approximation Theorem45
1 / 1
ChatGPT
ChatGPT
The paper titled "Deep Learning and Geometric Deep Learning: an introduction for mathematicians and physicists" provides a brief introduction to the inner workings of Deep Learning and Geometric Deep Learning algorithms, with a focus on Graph Neural Networks. The authors aim to give an overview of the key concepts and provide some references for further reading. The paper covers topics such as supervised classification, deep learning, score and loss functions, graph theory, Laplacian on graphs, heat equation, supervised classification on graphs, score function in Graph Neural Networks, and Graph Attention Networks. The paper also includes appendices discussing Kullback-Leibler divergence, regression tasks, Multi-layer Perceptrons, and the Universal Approximation Theorem.
1 / 1
1Introduction 
The recent revolution in machine learning, including the spectacular success 
of the Deep Learning (DL) algorithms [8, 7, 29], challenges mathematicians 
and physicists to provide models that explain the elusive mechanisms inside 
them. Indeed, the popularity of Deep Learning, a class of machine learning 
algorithms that aims to solve problems by extracting high-level features from 
some raw input, is rising as it is being employed successfully to solve dif i cult 
practical problems in many dif f erent i elds such as speech recognition [18], 
natural language processing [41, 21], image recognition [11], drug discovery 
[40], bioinformatics [2] and medical image analysis [33] just to cite a few, but 
the list is much longer. Recently at Cern the power of deep learning was 
employed for the analysis of LHC (Large Hadron Collider) data [16]; parti- 
cle physics is more and more being investigated by these new and powerful 
methods (see the review [12] and refs. therein). To give a concrete exam- 
ples of more practical applications, Convolutional Neural Networks (CNNs, 
[30], [29]), particular DL algorithms, were employed in the ImageNet chal- 
lenge [28, 11], a supervised classif i cation task challenge, where participants 
proposed their algorithms to classify a vast dataset of images belonging to 
1000 categories. The CNNs algorithms proposed by several researchers in- 
cluding LeCun, Hinton et al. [29, 28] surpassed the human performance and 
contributed to establish a new paradigm in machine learning. 
The purpose of this paper is to elucidate some of the main mechanisms 
of the algorithms of Deep Learning and of Geometric Deep Learning [8, 7] 
2 
(GDL), an adaptation of Deep Learning for data organized in a graph struc- 
ture [25]. To this end, we shall focus on two very important types of al- 
gorithms: CNNs and Graph Neural Networks (GNNs, [17]) for supervised 
classif i cation tasks. Convolutional neural networks, DL algorithms already 
part of the family of GDL algorithms, are extremely successful for problems 
involving data with a grid structure, in other words a regularly organized 
structure, where the mathematical operation of convolution, in its discrete 
version, makes sense. On the other hand, when we deal with datasets having 
an underlying geometric graph structures, it is necessary to adapt the notion 
of convolution, since every node has, in principle, a dif f erent neighbourhood 
and local topology. This motivates the introduction of Graph Neural Net- 
works. 
We do not plan to give a complete treatment of all the types of CNNs and 
GNNs, but we wish to give a rigorous introduction for the mathematicians 
and physicists that wish to know more about both the implementation and 
the theory behind these algorithms.
1 / 1
ChatGPT
ChatGPT
The introduction of the paper highlights the recent revolution in machine learning, particularly the success of Deep Learning (DL) algorithms. DL has proven effective in solving practical problems across various fields such as speech recognition, natural language processing, image recognition, drug discovery, bioinformatics, and medical image analysis. The paper mentions the application of DL in particle physics analysis at CERN and its use in the ImageNet challenge, where Convolutional Neural Networks (CNNs) surpassed human performance in image classification.
The paper aims to explain the mechanisms of DL and Geometric Deep Learning (GDL) algorithms, with a focus on CNNs and Graph Neural Networks (GNNs) for supervised classification tasks. CNNs are successful for data with a grid structure, while GNNs are designed for datasets with underlying geometric graph structures. The authors provide an introduction to these algorithms, targeting mathematicians and physicists who want to understand the implementation and theory behind them.
1 / 1
The organization of our paper is as follows. 
In Sec.2, we describe CNNs for supervised classif i cation, with focus 
on the image classif i cation task, since historically this is one of the main 
applications that helped to establish the Deep Learning popularity among 
the classif i cation algorithms. In this section we describe the various steps 
in the creation of a model, that is the process, called training in which we 
determine the parameters of a network, which perform best for the given 
classif i cation task. This part is common to many algorithms, besides Deep 
Learning ones. 
In Sec. 3, we focus on the score and the loss functions, describing some 
examples of such functions, peculiar to Deep Learning, that are used rou- 
tinely. Given a datum, for example an image, the score function assigns to 
it, the score corresponding to each class. Hence it will allow us to classify 
the datum, by assigning to it the class with the highest score. The loss of a 
datum measures the error committed during the classif i cation: the higher the 
loss, the further we are from the correct class of the datum. Some authors 
say that the purpose of the training is to "minimize" the loss, and we shall 
give a precise meaning to this intuitive statement. 
In Sec. 4, we introduce some graph neural networks for supervised node 
classif i cation tasks. After a brief introduction to graphs and their laplacians, 
we start our description of the score function in this context.In fact, it 
3 
is necessary to modify the "convolutional layers", that is the convolutional 
functions appearing in the expression of the score function, to adapt them 
to the data in graph form, which, in general, is not grid-like. This leads to 
the so called "message passing" mechanism, the heart of the graph neural 
networks algorithms and explained in Subsec. 4.3 describing the convolution 
on graphs and its intriguing relation with the heat equation. 
In the end we provide few appendices to deepen the mathematical treat- 
ment that we have not included in the text not to disrupt the reading. 
2Supervised Classif i cation 
Deep Learning is a very successful family of machine learning algorithms. 
We can use it to solve both supervised and unsupervised problems for both 
regression or classif i cation tasks. In this paper, we shall focus on supervised 
classif i cation tasks: as supervised regression tasks are handled similarly, we 
will mention them brief l y in Appendix B. To solve a classif i cation problem 
in the supervised learning setting, we have data points belonging to the 
euclidean space Rdand each point has a label, tipically an integer number 
between 0 and C − 1, where C is the number of classes.The 
goal is to 
"learn", that is to determine, a function that associates data points with the 
correct label F : Rd−→ {0,...,C −1}, through the process of training that 
we discuss below. 
We shall focus our attention on a classif i cation task the algorithm of Deep 
Learning is particularly ef f ective with: supervised image classif i cation.
1 / 1
ChatGPT
ChatGPT
The organization of the paper is outlined as follows:
Section 2: This section provides a description of Convolutional Neural Networks (CNNs) for supervised classification, with a focus on image classification tasks. The process of model creation, including training to determine the best parameters for classification, is explained. The common steps in training, applicable to various algorithms including Deep Learning, are discussed.
Section 3: The focus of this section is on the score and loss functions used in Deep Learning. Examples of these functions, specific to Deep Learning, are described. The score function assigns a score to each class for a given datum, enabling classification. The loss function measures the classification error, and the goal is to minimize this loss during training.
Section 4: This section introduces Graph Neural Networks (GNNs) for supervised node classification tasks. After a brief introduction to graphs and their Laplacians, the score function in the context of graph data is explained. The convolutional layers and their adaptation to graph data, through the "message passing" mechanism, are discussed. The relationship between graph convolution and the heat equation is also explored.
Appendices: The paper includes a few appendices that delve deeper into mathematical concepts related to the discussed topics. These appendices cover subjects such as Fisher matrix and Information Geometry, regression tasks, Multi-layer Perceptrons, and the Universal Approximation Theorem.
The subsequent sections of the paper provide detailed explanations and insights into each of the mentioned topics, with a specific emphasis on supervised image classification as an effective application of Deep Learning algorithms.
1 / 1
Summarize:

Concept Paper 
Biology, Buddhism, and AI: Care as the Driver of Intelligence 
Thomas Doctor 1,2, Olaf Witkowski2,3,4,5, Elizaveta Solomonova2,6, Bill Duane1,2,7 and Michael Levin 8,9,* 
1 Centre for Buddhist Studies, Rangjung Yeshe Institute, Kathmandu University, Kathmandu 44600, Nepal; 
thomas.doctor@ryi.org (T.D.); public@billduane.com (B.D.) 
2 Center for the Study of Apparent Selves, Rangjung Yeshe Institute, Kathmandu 44600, Nepal; 
olaf@cross-compass.com (O.W.); elizaveta.solomonova@mcgill.ca (E.S.) 
3 Cross Labs, Cross Compass Ltd., Kyoto 604-8206, Japan 
4 College of Arts and Sciences, University of Tokyo, Tokyo 113-8654, Japan 
5 Earth-Life Science Institute, Tokyo Institute of Technology, Tokyo 145-0061, Japan 
6 Neurophilosophy Lab, Department of Psychiatry, McGill University, Montreal, QC H3A 0G4, Canada 
7 Bill Duane and Associates LLC, San Francisco, CA 94117, USA 
8 Allen Discovery Center, Tufts University, Medford, MA 02155, USA 
9 Wyss Institute for Biologically Inspired Engineering, Harvard University, Boston, MA 02115, USA 
*Correspondence: michael.levin@tufts.edu 
Abstract:Intelligence is a central feature of human beings' primary and interpersonal experience. 
Understanding how intelligence originated and scaled during evolution is a key challenge for modern 
biology. Some of the most important approaches to understanding intelligence are the ongoing efforts 
to build new intelligences in computer science (AI) and bioengineering. However, progress has been 
stymied by a lack of multidisciplinary consensus on what is central about intelligence regardless of 
the details of its material composition or origin (evolved vs. engineered). We show that Buddhist 
concepts offer a unique perspective and facilitate a consilience of biology, cognitive science, and 
computer science toward understanding intelligence in truly diverse embodiments. In coming 
decades, chimeric and bioengineering technologies will produce a wide variety of novel beings that 
look nothing like familiar natural life forms; how shall we gauge their moral responsibility and our 
own moral obligations toward them, without the familiar touchstones of standard evolved forms as 
comparison? Such decisions cannot be based on what the agent is made of or how much design vs. 
natural evolution was involved in their origin. We propose that the scope of our potential relationship 
with, and so also our moral duty toward, any being can be considered in the light of Care—a robust, 
practical, and dynamic lynchpin that formalizes the concepts of goal-directedness, stress, and the 
scaling of intelligence; it provides a rubric that, unlike other current concepts, is likely to not only 
survive but thrive in the coming advances of AI and bioengineering. We review relevant concepts 
in basal cognition and Buddhist thought, focusing on the size of an agent's goal space (its cognitive 
light cone) as an invariant that tightly links intelligence and compassion. Implications range across 
interpersonal psychology, regenerative medicine, and machine learning. The Bodhisattva's vow ("for 
the sake of all sentient life, I shall achieve awakening") is a practical design principle for advancing 
intelligence in our novel creations and in ourselves. 
Keywords: computer science; basal cognition; Buddhism; compassion; bioengineering; intelligence; 
stress; AI; embodiment; artif i cial life 
1. Introduction 
The i elds of basal cognition, Buddhist philosophy, computer science, and cognitive 
science are all concerned with fundamental questions around intelligence. What is unique 
about certain conf i gurations of matter that enable them to exhibit intelligent behavior? 
How do the kinds and degrees of intelligence differ across beings? What processes drive 
the expansion of intelligence on evolutionary time scales, and what causes changes in the 
intelligence of a being during its lifespan? How can we understand intelligence in a way 
Entropy 2022, 24, 710. https://doi.org/10.3390/e24050710https://www.mdpi.com/journal/entropy 
Entropy 2022, 24, 7102 of 29 
that would enable us to create novel instances, as well as improve our own intelligence for 
life-positive outcomes for all? Traditional approaches to this question have been focused 
on a set of standard "model systems" such as human subjects and certain animals (rats, 
birds, etc.) in the context of a historical evolutionary lineage on Earth. However, recent 
approaches in artif i cial intelligence and synthetic bioengineering have begun to produce 
novel types of agents whose intelligence cannot be readily predicted from the details of their 
construction or their origins [1-4]. These constructivist efforts to create intelligence in novel 
implementations (ranging from novel combinations of engineered living tissue to software) 
reveal key gaps in our understanding of dynamic intelligence [5]. Given the inevitable 
developments in the biological sciences, and the profound challenges faced by society, it 
is essential to develop frameworks that help us to detect, understand, and communicate 
with intelligences in unfamiliar guises. Here, we propose that Buddhist thought, and its 
emphasis on care and compassion as a catalyst of positive change in intelligent beings, is 
an empirically fruitful lens with which to understand intelligence.
1 / 1
ChatGPT
ChatGPT
The concept paper titled "Biology, Buddhism, and AI: Care as the Driver of Intelligence" explores the concept of intelligence from a multidisciplinary perspective. The authors address the challenges of understanding intelligence in the context of evolutionary biology, computer science (AI), and bioengineering. They argue that there is a lack of consensus on what constitutes intelligence regardless of its material composition or origin. In order to bridge this gap, the authors propose that Buddhist concepts offer a unique perspective that can facilitate a comprehensive understanding of intelligence across diverse embodiments.
The paper discusses the implications of advancements in AI and bioengineering, which will lead to the creation of novel beings that may not resemble familiar natural life forms. The authors highlight the need to establish moral responsibility and moral obligations towards these beings, irrespective of their composition or origin. They propose that the concept of Care, rooted in Buddhist philosophy, can serve as a practical and dynamic framework for understanding intelligence. Care encompasses aspects such as goal-directedness, stress, and the scaling of intelligence, providing a rubric that can adapt to future advancements in AI and bioengineering.
The authors review concepts from basal cognition and Buddhist thought, emphasizing the importance of an agent's goal space (cognitive light cone) in linking intelligence and compassion. They discuss the implications of this perspective in various fields, including interpersonal psychology, regenerative medicine, and machine learning. They suggest that the Bodhisattva's vow, which emphasizes achieving awakening for the sake of all sentient life, can serve as a design principle for advancing intelligence in novel creations and in humans.
Overall, the paper proposes that integrating Buddhist principles of Care and compassion with scientific approaches can enhance our understanding of intelligence and guide ethical decision-making in the development of novel intelligences.
1 / 1
A few words on methodology are perhaps in order here. This exploration across 
otherwise typically disparate scientif i c disciplines and scholarly contexts aims at achieving 
what can be thought of as "deep integration" [6]. Such an integrational approach does not 
privilege the discourse of any one particular discipline as the primary carrier of meaning 
into which statements and insights derived from other, complimentary frameworks and 
approaches must be translated. Instead, what we here seek to achieve is a form of mutu- 
ally informed, explorative conversation that engages our customary, discipline-specif i c 
frameworks on equal footing, thereby facilitating the recognition of individual blind spots 
as well as otherwise unacknowledged, shared concerns. As a consequence of taking this 
approach, certain concepts that are central to this paper—such as stress, care, intelligence, 
self, or agency—take on a signif i cance that emerges within and is def i ned by the concrete 
interdisciplinary encounter. For this reason, we have supplied a Glossary that explains a 
selection of such broadly applicable concepts as they are understood in the specif i c con- 
text of this paper. Perhaps in line with age-old Buddhist sentiments, our concern is here 
pragmatic before philosophical. At the same time, we hope that any instances of functional, 
conceptual integration that this paper may achieve can in turn motivate ref i nements and 
constructive research across the sciences of life, cognition, and information, as well as 
indeed in i elds such as philosophy and religion. To illustrate this with an example, one 
of the main points of our def i nition of Self (as given in the Glossary and extracted from 
previous research) is that a Self is an illusory modelling construct created by perceptual 
systems of Agents. Agents construct models of causal Selves for others, and for ourselves, 
using the same machinery. The same mechanisms that cause an agent to act toward stress 
reduction in itself (even though the benef i ciary of those actions is in an important sense 
impermanent) can be expanded to extend to other Selves. In this way, while our focus is on 
understanding and formulating Self in a way that is applicable to a broad range of scientif i c 
contexts, we also see ourselves as here contributing to the treatment of perennial issues 
in contemporary Buddhist philosophy—such as the feasibility of genuine care in a world 
without real individuals [7-13]. Similarly, with respect to the paper's main thesis regarding 
care as a driver for intelligence: we hope that apart from addressing contemporary scientif i c 
or social aims and practices, our discussion may as well contribute to an understanding of 
classic Buddhist doctrine in its own right. 
The i eld of basal cognition [14-18] emphasizes a continuum of intelligence, which 
originated in the control loops of microbes but was scaled up throughout multicellular 
forms to the obvious kinds of intelligent behavior observed in advanced animals. The 
emphasis on functional problem-solving, learning, and creative responses to challenges 
enables a focus on the central invariant of intelligence, not contingent facts and frozen 
accidents of the evolutionary journey of life on Earth. Given that intelligent behavior does 
not require traditional brains [16,18], and can take place in many spaces besides the familiar 
3D space of motile behavior (e.g., physiological, metabolic, anatomical, and other kinds of 
Entropy 2022, 24, 7103 of 29 
problem spaces), how can we develop rigorous formalisms for recognizing, designing, and 
relating to truly diverse intelligences? 
One way to think about a general, substrate-independent def i nition of "Intelligence" 
is centered on goal-directed activity [19,20]: what is common to all intelligent systems, 
regardless of their composition or origin, is the ability to display a degree of competency 
in reaching a goal (in some problem space, [21]) despite changing circumstances and 
novel perturbations. These ideas extend classical discussions by Spinoza, Kant, Jonas, and 
Heidegger. All intelligences, no matter how embodied, can be compared directly with 
respect to the maximum spatiotemporal scale of the goals towards which they can represent 
and work. A corollary to this view is that the driver of this kind of homeostatic dynamic 
is that such systems exhibit "stress" (the delta between current state and optimal state, or 
the difference between the goals at different subsystems' levels): reduction of this stress 
parameter is a driver that keeps the system exerting energy in action to move and navigate 
within the problem space. It should be noted that stress can be seen as the inverse of 
"satisfaction" [22], and is relative to a contextual and non-stationary target. 
Evolution enables the scaling of intelligence by exploiting biophysical mechanisms 
that enable progressively larger goal states (and thus progressively more complex causes of 
stress) to be represented and pursued [23]. More complex and advanced cognitive agents 
are capable of being stressed by larger and more complex states of affairs [24], regardless of 
their specif i c composition or provenance. These ideas are novel and somewhat disruptive 
for many traditional approaches that have been largely focused on brains and do not 
comfortably stretch to encompass advances in bioengineering, chimeric technologies, and 
machinelearning. IncomplementtotheWesterntraditionsthathavedrivennow-dissolving 
boundaries between brain, body, and environment [25], we propose that Buddhism offers 
an approach that is uniquely suited to the new i eld developing at the intersection of 
computer science, bioengineering, and cognitive science (Figure 1). 
Entropy 2022, 24, x FOR PEER REVIEW 3 of 30 
problem spaces), how can we develop rigorous formalisms for recognizing, designing, 
and relating to truly diverse intelligences? 
One way to think about a general, substrate-independent definition of "Intelligence" 
is centered on goal-directed activity [19,20]: what is common to all intelligent systems, 
regardless of their composition or origin, is the ability to display a degree of competency 
in reaching a goal (in some problem space, [21]) despite changing circumstances and novel 
perturbations. These ideas extend classical discussions by Spinoza, Kant, Jonas, and 
Heidegger. All intelligences, no matter how embodied, can be compared directly with re- 
spect to the maximum spatiotemporal scale of the goals towards which they can represent 
and work. A corollary to this view is that the driver of this kind of homeostatic dynamic 
is that such systems exhibit "stress" (the delta between current state and optimal state, or 
the difference between the goals at different subsystems' levels): reduction of this stress 
parameter is a driver that keeps the system exerting energy in action to move and navigate 
within the problem space. It should be noted that stress can be seen as the inverse of "sat- 
isfaction" [22], and is relative to a contextual and non-stationary target. 
Evolution enables the scaling of intelligence by exploiting biophysical mechanisms 
that enable progressively larger goal states (and thus progressively more complex causes 
of stress) to be represented and pursued [23]. More complex and advanced cognitive 
agents are capable of being stressed by larger and more complex states of affairs [24], re- 
gardless of their specific composition or provenance. These ideas are novel and somewhat 
disruptive for many traditional approaches that have been largely focused on brains and 
do not comfortably stretch to encompass advances in bioengineering, chimeric technolo- 
gies, and machine learning. In complement to the Western traditions that have driven 
now-dissolving boundaries between brain, body, and environment [25], we propose that 
Buddhism offers an approach that is uniquely suited to the new field developing at the 
intersection of computer science, bioengineering, and cognitive science
1 / 1
ChatGPT
ChatGPT
The methodology of the concept paper involves a deep integration of different scientific disciplines and scholarly contexts. It aims to foster a mutually informed and explorative conversation among disciplines, treating them on equal footing rather than privileging one over the others. This approach helps identify individual blind spots and shared concerns, promoting a comprehensive understanding of intelligence.
The authors emphasize the importance of a substrate-independent definition of intelligence based on goal-directed activity. They propose that all intelligent systems, regardless of their composition or origin, exhibit competency in reaching goals despite changing circumstances. Stress, defined as the delta between the current state and the optimal state or the difference between goals at different levels, serves as a driving force for intelligent systems to exert energy and navigate problem spaces.
The paper draws upon concepts from basal cognition and Buddhist philosophy to develop a broader understanding of intelligence. It highlights the significance of integrating different perspectives, including advancements in bioengineering and machine learning, to recognize and relate to diverse forms of intelligence. The authors argue that Buddhism provides a unique approach in the intersection of computer science, bioengineering, and cognitive science, offering insights into intelligence and care.
The methodology involves pragmatic exploration and seeks to contribute to interdisciplinary research and the treatment of perennial issues in contemporary Buddhist philosophy. The paper also provides a glossary to explain key concepts used in the specific context of the discussion.
1 / 1
Figure 1.Care as the central invariant of a new interdisciplinary i eld. Legend: A schematic mindmap 
showing how Care is a central invariant binding across several i elds. Care, or the capacity to exert 
energy and effort toward preferred states, is a central concept in Biology (because of the ubiquity of 
homeostatic loops at various scales of organization of life), in AI (because of the necessity to specify 
objective functions for artif i cial agents to follow), and Buddhism (because of the centrality of the 
concept of concern for all sentient beings' welfare and progress). A commitment to maximization and 
scaling of outward-facing Care with respect to other agents' goals, as occurs during the Bodhisattva 
vow, is a powerful driver concept for progress in synthetic and natural evolution (via scaling of 
goals from metabolic scalars to patterns of anatomical complexity in morphospace and eventually to 
complex behaviors in 3D space) and in AI (via a focus on building synthetic systems with the capacity 
to increase and modify their own cognitive boundaries). 
Entropy 2022, 24, 7104 of 29 
We propose a central concept as a key invariant across these i elds: Care (a metric 
focused on motivation, stress, and goal-directedness of agents). If stress is the manifest 
discrepancy between current and optimal conditions, "Care" can in turn be def i ned as 
concern for stress relief, and "intelligence" as the degree of capacity for identifying and 
seeking such relief. By analyzing the role of Care in diverse contexts, informed by a 
Buddhist approach, we propose a new path towards improving both natural and artif i cial 
intelligence via a commitment to radical expansion of a being's or an agent's cognitive 
boundary: the scale of the things it can possibly care about (def i ned by the range of states 
that cause it stress and cause it to exert effort to change). In this framework, what an agent 
can possibly care about is a central determinant of its degree of intelligence. Importantly, 
this view not only helps us understand the origins and implementation of diverse types of 
intelligence within an agent, but also helps clarify the changes of an agent's intelligence in 
its outward-facing relationships to other agents. 
Whereas the drive to reduce one's own stress is a primitive and universal ingredient 
in cognition and intelligence, the inclusion of others' stress as a primary goal necessarily 
increases the cognitive boundary of an individual and scales its intelligence. Given the 
modular nature of homeostatic loops, this only requires that sensors that normally gauge 
the agent's own states (face inwards) expand to include information about others' states 
(start to face outwards). In this framework, the recognition of agency outside oneself 
and the progressive inclusion of their states in one's own homeostatic stress-reduction 
loops is a bidirectional feedback loop that leads to the scaling of intelligence and increases 
in practical compassion. This loop operates on both the evolutionary and individual 
lifespan time scales, and in more advanced forms, comes under rational control of systems 
whose primary goals may start to include the meta-cognitive goal of increasing intelligence 
and compassion. 
Advanced intelligence includes the ability to notice agency, and thus stress, and to seek 
its reduction. We employ this perspective on intelligence in an analysis of the Bodhisattva 
principle of agency and cognition, focusing on the traditional concept of "taking the 
Bodhisattva vow" and so committing to the pursuit of cognitive perfection ("awakening," 
Skt. bodhi) for the benef i t of all sentient beings throughout time and space [26,27]. In 
addition to better ways to understand biology, this framework suggests a number of 
conclusions with respect to stress transfer and goal identif i cation that can serve as design 
principles for improved general artif i cial intelligence systems.
1 / 1
ChatGPT
ChatGPT
Figure 1 illustrates the central concept of Care as an invariant across multiple fields. The concept of Care, which focuses on motivation, stress, and goal-directedness of agents, is identified as a key factor in biology, artificial intelligence (AI), and Buddhism. In biology, homeostatic loops and the ubiquity of stress relief mechanisms make Care central. In AI, specifying objective functions for artificial agents to follow requires consideration of Care. In Buddhism, concern for the welfare and progress of all sentient beings is central.
The authors propose that Care is a metric for measuring the concern for stress relief, and intelligence can be understood as the degree of capacity for identifying and seeking such relief. By analyzing the role of Care in diverse contexts, informed by a Buddhist approach, the paper suggests a new pathway to improve natural and artificial intelligence. This involves expanding an agent's cognitive boundary, defined by the range of states that cause stress and require effort to change. The ability to care about a wide range of states becomes a central determinant of intelligence.
The perspective of including others' stress as a primary goal increases an individual's cognitive boundary and scales their intelligence. Recognizing agency outside oneself and including their states in one's own stress-reduction loops leads to the scaling of intelligence and practical compassion. This bidirectional feedback loop operates on both evolutionary and individual lifespan time scales.
The paper explores the application of this perspective on intelligence in the analysis of the Bodhisattva principle, which involves committing to the pursuit of cognitive perfection for the benefit of all sentient beings. The framework of Care suggests design principles for improved general AI systems, including stress transfer and goal identification.
Overall, Figure 1 highlights the central role of Care in understanding and advancing intelligence in biology, AI, and Buddhism, and proposes implications for the design of intelligent systems.
1 / 1
2. The Cognitive Light Cone Framework: Cognitive Boundaries, Goal-Directedness, 
and Domains of Concern 
Many def i nitions of intelligence and cognitive capacity have been debated over the 
centuries [28]. The problem with most existing formalisms is that they are closely tied 
to a specif i c type of subject—such as humans, rats, birds, etc.—a traditional animal at a 
single "privileged" size and temporal scale [29], or even type of anatomy. Comparing 
intelligences among different animals, such as octopuses and dogs, is very challenging 
because their diverse environments and behaviors underline the fact that intelligence can 
be hard to ascertain in unfamiliar guises. An even bigger limitation in this i eld is the 
impending explosion in the prevalence of truly unusual living creatures and distributed 
systems [30]. Novel living beings produced by engineering and hybrid approaches (such 
as evolutionary design) include ex vivo constructs such as embryoids, organoids, and 
assembloids [31,32], cyborgs of animals and plants [3,4,33-38] resulting from living tissue 
tightly integrated with designed inorganic interfaces [39,40] and with closed-loop control 
systems [41], biological robots such as computer-controlled invertebrates [42-44], and hybrots 
consisting of living brains instrumentized to control artificial new bodies [1,43,45-49]. Without 
any familiar phylogenetic guideposts (e.g., "it's a kind of i sh so we expect a i sh-like range 
of behaviors"), it may be extremely diff i cult to place the intelligence of novel, synthetic 
creatures with respect to the familiar examples. Recent efforts in "Diverse Intelligences" and 
Artif i cial Life initiatives seek to acknowledge the wide range of "life as it can be" [50,51], 
Entropy 2022, 24, 7105 of 29 
and produce frameworks for understanding of intelligence that not only subsume possible 
living beings (designed and evolved) but also include potential exobiological intelligences 
and purely software (AI) creations. The quest to be able to directly compare truly diverse 
intelligences, regardless of their origin story or composition, requires us to be able to specify 
the most general invariant underlying intelligence and cognition: what do all cognitive 
agents, no matter how advanced or humble, have in common? 
Onesuchframeworkhasbeensuggested, andisfocusedonacandidateforaninvariant 
that enables direct comparison of truly diverse agents (regardless of their composition or 
origin) [23,24,52]: goal-directedness. We suggest that an essential nature of cognition, in 
any embodiment, is the capacity for goal-directed activity in some problem space. In this 
sense, goal-directedness does not require a high-level self-awareness, but only a cybernetic 
kind of teleonomic functionality [53-60] (of course, other frameworks could be developed 
around different invariants such as information processing [61]). 
On this view, any possible agent can be represented by drawing the spatiotemporal 
boundaries of the biggest goals which it is capable of pursuing (Figure 2). Tell me what you 
care about—what you actively spend energy on trying to achieve despite perturbations and 
novel situations—and I can immediately gauge your degree of sophistication. A bacterium 
can try to manage local sugar concentrations, with a bit of memory and a bit of predictive 
power. A dog has a larger area of concern, signif i cant memory and predictive capacity in 
the short term, but it is probably impossible for it to care about something that will happen 
100 miles away, 2 months from now. Humans have a huge cognitive envelope, perhaps 
uniquely one that is larger than our own lifespan; our state of being a creature capable of 
goals that appear fundamentally unachievable is very characteristic of Buddhist practice. 
Every creature thus has a "cognitive boundary"—which can be represented in the form of 
a light cone within space and time that demarcates the edge of what it can care about (not 
the i rst-order boundary of what it can sense and affect, but the second-order boundary 
demarcating the scale of its possible goals). 
Analyzing systems with respect to this aspect has several advantages. The i rst is that 
it is completely agnostic about the composition of agents, enabling the most basal, primitive 
forms to be compared on the same scale as humans (whose cognitive boundary might 
extend to planetary scales) and novel life forms (synthetic, exobiological, etc.). Another 
advantage is that the continuous space underscores the futility of binary categories ("is it 
intelligent?", "is it cognitive?", "is it a real decision or just physics?"): modern bioscience 
offers no support for some sort of clean bright line separating cognitive beings from non- 
cognitive ones. All of the interesting capacities of mind, like the ones of the body, evolved 
gradually. Taking evolution seriously means asking "what kind" and "how much", with 
respect to intelligence and cognition broadly conceived [62]. This is consistent not only with 
the facts of bioengineering (that any purportedly "non-cognitive" system can be mixed 
and hybridized with a cognitive one), but also with the evolutionary history of cognition. 
All of the main components of neurons (ion channels, electric synapses, neurotransmitter 
machinery, etc.) existed long before brains appeared—they were present in our unicellular 
ancestors. Indeed, evolution long ago (about the time of bacterial biof i lms [63]) discovered 
that bioelectric networks are an ideal medium for scaling computation, coordinating and 
synthesizing information across distance, and implementing memory and reprogramma- 
bility. Developmental bioelectricity [64] is the medium by which non-neural cells form 
networks to manage morphogenesis in development and regeneration. Pre-neural bioelec- 
tric networks in the body underlie large-scale anatomical decision-making and possess 
instructive pattern memories that guide growth and form [64,65]. It is very likely that 
this system served as a precursor to neurobiology: prior to electrical networks controlling 
muscles to move the body through 3D space, these same networks generated signals to 
control cell behaviors in the body to move the body conf i guration through anatomical 
morphospace. Thus, anatomical homeostasis is a goal-seeking capacity of the collective intelligence of cellular swarms comprising living bodies [24].
1 / 1
ChatGPT
ChatGPT
The authors introduce the Cognitive Light Cone framework as a means to compare and understand intelligence across diverse agents, regardless of their composition or origin. Traditional definitions of intelligence are often tied to specific types of subjects or privileged sizes and temporal scales. However, with the emergence of novel synthetic creatures and distributed systems, it becomes challenging to assess intelligence in unfamiliar forms.
The framework suggests that an essential aspect of cognition is goal-directedness, the capacity for pursuing goals in a problem space. By identifying the spatiotemporal boundaries of the biggest goals an agent can pursue, their degree of sophistication can be gauged. For example, a bacterium may focus on managing local sugar concentrations, while a dog has a larger area of concern but limited foresight. Humans, on the other hand, possess a vast cognitive envelope that extends beyond their own lifespan.
Analyzing agents based on their cognitive boundaries offers several advantages. It is agnostic to their composition, allowing comparisons between basal forms and complex beings. The continuous space of cognitive boundaries emphasizes the gradual evolution of mind and challenges binary categories. The framework aligns with the principles of bioengineering and recognizes that purportedly "non-cognitive" systems can be hybridized with cognitive ones. It also acknowledges the role of bioelectric networks in scaling computation and coordinating information, suggesting their precursor role in neurobiology.
Understanding cognitive boundaries and goal-directedness provides insights into the nature of intelligence and cognition. It enables the comparison of diverse intelligences, including synthetic, exobiological, and AI-based creations. The framework supports a nuanced perspective on the evolution and composition of cognitive systems, emphasizing gradual development and the importance of goal-seeking capacities in collective cellular intelligence.
1 / 1
Figure 2. Legend: A focus on the size or scale of goals any given system can pursue, as an invariant 
across the space of possible sentient beings of whatever embodiment, allows plotting very diverse 
intelligences on the same graph [23]. The scale of their goal-directed activity is estimated (collapsed 
onto one axis of space and one of time, as in space-time diagrams). Importantly, this way of visual- 
izing the sophistication of agency is a schematic of goal space—it is not meant to represent the spa- 
tial extent of sensing or effector range, but rather the scale of events about which they care and the 
boundary of states that they can possibly represent or work to change. This defines a kind of cogni- 
tive light cone (a boundary to any agent's area of concern); the largest area represents the "now", 
with fading efficacy both backward (accessing past events with decreasing reliability) and forward 
(limited prediction accuracy for future events). The diamond or "spinning top" shapes of the cones 
depicted above are simplifications. Agents are compound entities, composed of (and comprising) 
other sub- or super-agents, each of which has its own cognitive boundary of various sizes. Image by 
Jeremy Guay of Peregrine Creative. Selves increase their cognitive boundary by connecting together 
("GJ", standing for gap junctions—an example of a biophysical connection used by cells to merge 
into higher-level beings) in functional ways that allow simple homeostatic loops to measure, imple- 
ment, and remember progressively larger states (thus increasing the scale and complexity of what 
they Care about). Top panel used by permission, produced by Jeremy Guay of Peregrine Creative. 
Figure 2.Legend: A focus on the size or scale of goals any given system can pursue, as an invariant 
across the space of possible sentient beings of whatever embodiment, allows plotting very diverse 
intelligences on the same graph [23]. The scale of their goal-directed activity is estimated (collapsed 
onto one axis of space and one of time, as in space-time diagrams). Importantly, this way of visualizing 
the sophistication of agency is a schematic of goal space—it is not meant to represent the spatial extent 
of sensing or effector range, but rather the scale of events about which they care and the boundary of 
states that they can possibly represent or work to change. This def i nes a kind of cognitive light cone (a 
boundary to any agent's area of concern); the largest area represents the "now", with fading eff i cacy 
both backward (accessing past events with decreasing reliability) and forward (limited prediction 
accuracy for future events). The diamond or "spinning top" shapes of the cones depicted above 
are simplif i cations. Agents are compound entities, composed of (and comprising) other sub- or 
super-agents, each of which has its own cognitive boundary of various sizes. Image by Jeremy 
Guay of Peregrine Creative. Selves increase their cognitive boundary by connecting together ("GJ", 
standing for gap junctions—an example of a biophysical connection used by cells to merge into 
higher-level beings) in functional ways that allow simple homeostatic loops to measure, implement, 
and remember progressively larger states (thus increasing the scale and complexity of what they Care 
about). Top panel used by permission, produced by Jeremy Guay of Peregrine Creative. 
Entropy 2022, 24, 7107 of 29 
3. Two Distinct Light Cones: One for Physical States, One for Care 
According to the goal-directed model of intelligent agents, any individual agent is 
then delimited by the spatiotemporal boundary of events that it can seek to measure, model, 
and affect [23]. This surface sets a functional boundary, or "light cone" of its cognitive 
ability. We have considered the way systems may exchange stress between each other by 
exchanging signals, which has direct translations into the world of machine learning agents 
as well as natural agents. Agents may progressively come to reduce their levels of stress 
and transfer them between each other in more eff i cient ways, by means of communicating 
their goals. It may be helpful to clarify the difference between the goal-def i ned light cone 
(Figure 2) and a mere behavioral space light cone. While the latter merely def i nes the 
space of possible states in which an agent can i nd itself (def i ned by its position, speed, 
temperature, etc.), the light cone we def i ned above rather characterizes the maximum 
extent of the goals and aspirations of an agent, or in other words, its capacity for Care. An 
agent's Care light cone (CLC) and its corresponding physical light cone (PLC) of behavioral 
space can be brought together in the same representation (Figure 3). In our representation 
of light cones, the two diagonal lines represent the two extrema in terms of physical change 
of the system state, while the horizontal line indicates the present state space. Anything 
outside of the cones that is located in the future cannot be reached from the present state 
in the future, nor can anything in the past that lies outside the cones be inf l uencing the 
present state. 
Light cones may be represented in two dimensions as in Figure 3. In our depiction of 
light cones, both physical states and cared-for states belong to their respective light cones. 
The diagram symbolically shows a phase space where each point corresponds to a state. 
Points within the Care light cone (CLC, represented in blue) represent states for which the 
agent cares at a given point in time—typically the present time in our depiction, but one 
may picture a time series of such light cones changing in time—rather than the states the 
agents are physically in. A state may be situated within a Care light cone even if it is too 
distant in space or time to have any interaction with the agent. Conversely, some states 
in the physical light cone (PLC, represented in yellow) may be beyond the light cone of 
Care of the agent, yet remain physically achievable through a certain trajectory. Goals cease 
to exist as soon as the self (the Care light cone, in blue) is reduced to a point, or, on the 
contrary, extends inf i nitely over the whole phase space of possible states (in yellow). 
The light cones we consider are clouds of possibilities for agents, meaning that 
they represent distributions of probabilities of Care and physical states achievable in 
time and space. We note that the two types of light cones we describe naturally take 
two different shapes. On the one hand, the physical light cone determines the limited 
subspace corresponding to an initial state of the world undergoing change in accordance 
with a set of physical laws, similar to the light cones in the theory of relativity or light cones 
of information in evolutionary theory [66]. On the other hand, Care light cones need not 
bear such a limitation since an agent may care about entities that are not within reach in 
space and time. A light cone does not exist in a vacuum. On the contrary, it corresponds to 
a given substrate, and is surrounded by other light cones so that it may even overlap or 
contain other ones. The act of extending a light cone bears some connection with the act 
of several agents cooperating or acting as a cognitive whole as their Care light cones may 
start overlapping.
1 / 1
ChatGPT
ChatGPT
The authors present Figure 2, which illustrates the Cognitive Light Cone framework. It focuses on the size or scale of goals that an agent can pursue as an invariant across diverse sentient beings. The diagram collapses the scale of goal-directed activity onto one axis of space and one of time. The shape of the cognitive light cones represents the boundary of what agents can care about, with the largest area representing the "now" and decreasing efficacy both backward (accessing past events) and forward (predicting future events).
Figure 2 highlights that agents are compound entities composed of sub- or super-agents, each with their own cognitive boundaries. The concept of cognitive light cones allows for the comparison of intelligences, regardless of their embodiment. It provides a means to plot diverse intelligences on the same graph, enabling the visualization and assessment of their sophistication.
In Figure 3, the authors further explain the distinction between the goal-defined light cone and a behavioral space light cone. The goal-defined light cone characterizes the maximum extent of an agent's goals and aspirations, representing its capacity for care. Points within the care light cone (CLC) represent states that the agent cares about, while points within the physical light cone (PLC) correspond to physically achievable states. The diagram depicts a phase space where each point represents a state. States within the CLC may be distant in space or time but still matter to the agent, while some states within the PLC may be physically achievable but lie outside the agent's care light cone.
The authors emphasize that light cones represent distributions of probabilities rather than absolutes. They note that physical light cones have limited subspace determined by physical laws, while care light cones may extend beyond spatial and temporal limitations. Light cones exist within a substrate and can overlap or contain other light cones, reflecting the cooperative actions and overlapping concerns of multiple agents.
1 / 1
Figure 3.An agent's boundary of Care. Legend: An agent's Care light cone represented at a given 
time (CLC, in blue) and the corresponding agent's physical light cone (PLC, in yellow). The diagram 
depicts a space where each point corresponds to a state of the agent. The agent cares for a state s, 
which is achievable, whereas it cares also for a state c, which is not reachable from the here and now 
(the present state is at the origin of the plot). Points that are outside CLC and PLC are respectively 
too distant in space or time to have any interaction with the agent, or too distant to be cared for by 
the agent. 
4. Problem Space, Fields of Stress, and Continuity of Cognitive Forms of Life 
In this framework, intelligence is the degree of sophistication an agent can muster in 
navigating some specif i c problem space. Def i ned very broadly, problem spaces can be seen 
as i elds that emerge in the gap between current and optimal conditions—or in other words, 
as i elds of stress. The generalization of problem spaces beyond the traditional 3D space of 
"behavior" into other, virtual problem spaces is essential for understanding evolution of 
basal cognition. Living things i rst solved problems in metabolic space, and evolution then 
pivoted the same kinds of strategies to solve problems in physiological, transcriptional, 
and anatomical space, before speed-optimizing these dynamics to enable rapid behavior in 
3D space. Since every cognitive agent is made of parts, it is essential to have a theory about 
how numerous goal-seeking agents link together into a new, larger cognitive system that is 
Entropy 2022, 24, 7109 of 29 
novel and not present in any of the subunits. The multiscale competency architecture of 
life [24] is such a hypothesis about the scaling of cognition, seeing complex system-level 
behaviors in any space as the within- and across-level competition and cooperation among 
the various subunits and partitions of composite agents (i.e., all agents). 
This emphasis on the fundamental continuity, kinship, and inf i nite variety of life 
and cognition resonates with Buddhist descriptions of continuous cycles of life and death 
that emerge through inf i nite causal dependencies and with potential for radical bodily 
and cognitive transformation [26,67]. Another feature of this vision that aligns well with 
Buddhist ideas is the lack of a permanent, unique, unitary Self [68]. The picture given 
by the evolutionary cell-biological perspective is one where a cognitive agent is seen as 
a self-reinforcing process (the homeostatic loop), not a thing [69-71]. Of course, on long 
time scales, all objects are, consistent with Mah¯ay¯ana Buddhist perspectives, just temporary 
conf i gurations—the distinction between permanent objects and temporary bundles of 
coherent processes (cf. the Ship of Theseus paradox and N¯agasena's chariot parable as a 
description of biological beings [72,73]) fades away. 
In this society of processes, overlapping goal-seeking partitions are all interacting 
with each other. Importantly, the boundaries of these Selves not only interpenetrate, but 
can also change during the agent's lifetime. Defections from large-scale anatomical goals, 
such as those that occur due to an inappropriate reduction of gap junctional connectiv- 
ity [74], present as cancer, cause reversions of cell behavior to ancient unicellular concerns 
which lead to metastasis and over-proliferation as the cells treat the rest of the body as 
external environment. 
Another key fundamental commonality is the focus on striving. The central treadmill 
(loop) of life is a homeostatic effort to attain a specif i c setpoint, despite the buffeting 
inf l uence of the cruel, dissipative environment. The driver of this loop is stress—the delta 
between current state and desired state, and all of the system's efforts are guided by the 
effort to minimize stress (essentially, unhappiness). Def i ned in this way, "stress" turns out 
to be a compelling translation of the Sanskrit term duh .kha (otherwise often rendered as 
"suffering"), which describes a treacherous world inhabited by restlessly craving beings. In 
this world of stress, existence equals dissatisfaction, and so duh .kha is a continuous state 
that compels beings to act [67]. This stress-focused perspective can be seen as suggesting 
that the expansion of cognition across eons was basically a process of scaling goals, from 
humble metabolic needs to single cells to the grandiose goals of "make and maintain a 
whole limb" of tissue- and organ-level cellular collectives. It is fascinating to think about 
how this expansion of concern scales basic self-preservation goals into outward-facing 
preferences about complex, large states of the environment and even care for the states of 
other beings. 
One instructive example is what happens in bioelectric networks during multicellular- 
ity. Cells join into networks with electrical synapses known as gap junctions. What is special 
about these is that unlike traditional signaling (by diffusible secreted chemical signals and 
receptors), information molecules pass through gap junctions directly into the internal milieu 
of the recipient cell. Once the signal is inside a cell, that cell cannot tell whether this molecule 
is a memory trace of something that happened to that cell (a true memory engram) or a 
false memory incepted into its informational structure by a kind of memory transfer from 
its neighbor. Imagine for example a calcium spike due to an injurious stimulus: calcium 
has no metadata on it to describe whose signal it is, and once it spreads across a few cells, 
they become a collective that has information about injury that is distributed across the 
individuals. In effect, it performs a kind of "mind meld", binding subunits into a collective 
because it becomes very diff i cult to keep individualization regarding which cell has which 
information. It is hard to maintain the I-you distinction, and cooperation is massively 
favored. This is not because the agents have become less self i sh, but because the size of the 
self (to which they are committed) has grown. For properly coupled cells, it is impossible 
to hide information from each other (from yourself) and it is impossible to do anything 
injurious to your neighbor because the same effects (consequences) will affect you within seconds. Gap junctions provide an eff i cient life-transforming dynamic—cause and effect 
which massively augments cooperative interactions. The eventual result is the scaling up of 
the cognitive boundary, the processing capacity, the information content and structure, and 
the goals. An individual cell strives to become two cells. A gap-junction-coupled collective 
strives to make an organ, being able to represent goal states such as number of i ngers 
which are unfathomable to individual cells. In connecting with others in a strong infor- 
mational sense [75], the functional non-indifference to one's own states begins to expand 
and face outwards, enabling responses to progressively more distant others' states. Much 
works remains, to identify policies for informational coupling of subunits that optimize 
the potentiation of collective intelligence and care. These policies will be as relevant to 
establishing thriving social structures as to the design of novel general intelligences. 
Biology offers many examples of Selves which change on-the-f l y—not just during 
evolutionary time scales, but during the lifetime of the agent. All animals were once a 
single fertilized egg cell, then became a collection of cells solving problems in anatomical 
space, and only later developed an emergent centralized Self focused around navigating 
3D space of behaviors [76]. Butterf l ies (and their brains) result from the rapid remodeling 
of a caterpillar and its very different brain. In addition to these natural examples, recent 
advances in chimeric and bioengineering technology are enabling an inevitable explosion of 
diverse forms of life. Hybrots, cyborgs, chimeras, and other combinations of living material, 
bioengineered components, and software form an astronomically huge option space for 
possible forms with diverse kinds of bodies and behaviors [1,3,4,33,42,43,45-47,77-81]. This 
requires us to move from the picture of Adam naming a i nite set of static animals in the 
Garden of Eden to frameworks that can handle the full range of life and mind as they can 
be—all possible sentient beings. 
For AI workers, it is important to step back from a neurocentric view of intelligence— 
life was solving problems long before neurons evolved; thus, a focus on neuromorphic 
architectures (such as specif i cally neural-network models) is unnecessarily restrictive. All of 
the main components of neural systems—ion channels, electrical synapses, neurotransmit- 
ter machinery, etc., were present long prior to the appearance of brains [82,83]. Indeed, all 
cells form bioelectrical networks that process information in morphospace in ways familiar 
to neurosciences (but on a slower time scale) [64]. The emphasis on natural intelligence 
as fundamentally arising from goal-directed (homeostatic) loops dovetails with key open 
problems in AI research, with respect to intrinsic motivation [84,85] and goals: how do 
goals arise in complex systems? How do we predict and manage the goals of collective in- 
telligences (such as robot swarms), ensuring life-positive engineered systems? Evolution is 
only part of the story, since synthetic living organisms, such as Xenobots—protoorganisms 
made of frog skin cells [86-88], exhibit coherent anatomical, physiological, and behavioral 
outcomes that have no backstory of selection forces shaping them. The central concept in 
this new frontier is Care: what do these systems spend energy to try to achieve—what do 
they care about? What sets the scope and content of their goals? 
A focus on Care has two other important implications for AI. First, it suggests that 
the ability to recognize, manage, and relate to sentient beings is a key capacity and design 
challenge for AI. Engineered agents are intelligent in part due to their ability to detect 
intelligence around them, and our development of tools to help understand intelligence 
in unconventional media around us should be paralleled by advances to enable AI to do 
the same. Secondly, it provides one answer to the perennial philosophical problem of 
how to relate to "artif i cial" beings—a problem which is strongly exacerbated by existing 
technologies for chimerizing living tissue with engineered replacements. If one's spouse 
had a kidney replaced with an engineered organ, does that change anything with respect 
to the relationship and moral responsibility? Presumably not. How about several organs, 
and perhaps a part of the brain? All of the brain, as long as the function is preserved? 
At what point does one go from a "real person with perhaps some irrelevant mechanical 
augmentations" to a "robot that is just simulating their (perhaps very convincing) social 
interactions"? It seems clear that such decisions cannot be based on what the putative 
Entropy 2022, 24, 71011 of 29 
person is made of or how they came to exist (evolution, embryogenesis, design and factory 
construction, or some combination of those), and advances in machine learning suggest 
that they cannot be based on performance in specif i c problem areas either (IQ tests). What 
can they be based on? One suggestion is that they can be based on Care. What we should 
be looking for, in terms of gauging what kind of relationship we can have with, and moral 
duty we need to exert toward, any being is the degree of Care they can exhibit, either at 
present or as a latent potential, with respect to the other beings around them.
1 / 1
ChatGPT
ChatGPT
Figure 3 illustrates an agent's boundary of Care, depicting an agent's Care light cone (CLC) and the corresponding physical light cone (PLC). Each point in the diagram represents a state of the agent, with the present state located at the origin of the plot. The agent cares for states within the CLC that are achievable, while some states within the PLC may be physically achievable but lie outside the agent's care light cone. Points outside both light cones are either too distant in space or time to have any interaction with or be cared for by the agent.
The authors emphasize that problem spaces, which emerge as fields of stress between current and optimal conditions, play a crucial role in understanding intelligence. Problem spaces extend beyond the traditional 3D space of behavior and encompass metabolic, physiological, transcriptional, and anatomical spaces. The multiscale competency architecture of life is proposed as a hypothesis for understanding how goal-seeking agents combine into larger cognitive systems. This perspective highlights the continuity, kinship, and infinite variety of life and cognition, resonating with Buddhist views on continuous cycles of life and cognitive transformation.
The authors emphasize the focus on striving and stress reduction as fundamental aspects of cognitive agents. Stress, defined as the discrepancy between current and desired states, is likened to the Sanskrit term "duh.kha" (often translated as "suffering"), representing a continuous state that compels beings to act. The expansion of cognition across evolutionary time scales is described as a process of scaling goals, from metabolic needs to complex environmental states and care for the well-being of other beings.
The authors discuss the role of bioelectric networks and gap junctions in scaling cognitive boundaries. Cooperative interactions facilitated by gap junctions allow for the exchange of information and the formation of collective intelligences. This process leads to the expansion of the cognitive boundary, processing capacity, information content, and goals of agents. The dynamic of informational coupling among subunits is highlighted as essential for optimizing collective intelligence and care.
The perspective on intelligence presented in the paper encourages a shift away from a neurocentric view and emphasizes the role of goal-directed (homeostatic) loops in intelligence. The concept of Care has implications for artificial intelligence, suggesting the importance of AI's ability to recognize, manage, and relate to sentient beings. Additionally, it provides a framework for addressing ethical considerations regarding relationships with and moral responsibility toward "artificial" beings, especially as technologies enable the merging of living tissue with engineered replacements. The degree of Care exhibited by a being is proposed as a basis for determining the nature of relationships and moral duties toward them.
1 / 1
Existing life forms reveal a continuum of cognitive capacities reaching all the way from 
our unicellular ancestors to modern advanced animals, and these can be compared based 
on the shape of their cognitive light cone—the shape and size (in a space-time diagram) 
of the most grandiose goals toward which they are capable of working (Figure 2). The 
area inside a system's cognitive boundaries is the area of Concern—the number and types 
of things that this system can Care about, in the sense of practical Concern (willing and 
able to spend energy to monitor and control). There are of course major transitions in 
evolution [89,90], corresponding to advances in the types of goals a given system can 
work towards. These have been discussed elsewhere [24]. One really crucial transition is 
unique, forming what Hofstadter would call a Strange Loop: rather than committing to 
increasingly more sophisticated goals, one can commit to the meta goal of increasing one's 
goals. In Buddhist traditions, this intentional expansion of one's cognitive boundary (and 
thus the area of one's concern) i nds expression in what is known as the Bodhisattva vow. 
5. No-Self in Buddhism and Bodhisattva Intelligence 
The past decades saw a development of interdisciplinary interest in synthetic modes of 
knowledge that integrate Buddhist philosophy with contemporary Western philosophy of 
mind and cognitive science [91]. In fact, the developing domain of contemplative science to- 
day has made attempts at developing novel empirical and theoretical language and tools in 
order to better understand plasticity of mind and brain [92] and to integrate contemplative 
techniques (such as meditation) into the models of consciousness and cognition [93]. 
We propose that a number of core Buddhist concepts (in particular the constructed 
nature of selfhood/no-self, duh .kha, universal loving care, and the Bodhisattva) can be prof- 
itably used to challenge and to enrich the current work in diverse intelligences, including 
novel approaches to AI and to biology. In contemporary cognitive science, the mind is 
sometimes understood as enactive [94-96], in that the boundaries between cognition, a form 
of embodiment, and a being's relationship with the world are understood as pragmatic and 
non-reducible [97,98]. Similarly, contemporary proposals for the constructed, transient and 
contextual nature of human selfhood [99] and for its inextricably social/cultural orienta- 
tion [100] are delineating a direction for understanding forms of life and intelligences that 
are relational, transient and have malleable boundaries (here understood as cognitive light 
cones). These fundamental shifts in perspective are particularly suitable for integrating 
Buddhist and enactive approaches to AI [101]. In the following sections, we will present 
core Buddhist concepts of selfhood and the Bodhisattva idea to further develop our pro- 
posal that intelligence can be understood in terms of Care and the remedying of stress. 
Our discussion can, in this regard, be seen as resonant with the enactivist tradition, which 
describes selves as precarious centers of concern [102], as patterned variations [103] of 
different forms of experienced selfhood, ranging from the notions of minimal self [104] 
to embodied, affective [98,105], and socially extended/participatory [106-108] forms of 
situated selfhood. What is common in many l avors of enactive and situated cognition 
models is the emphasis on the dynamic and creative nature of what it means to have or to 
be a form of self. Importantly, the recent work on participatory and social forms of selfhood, 
sometimes referred to as the "interactive turn" [109] in enactive cognitive science, stresses 
the situated nature of cognition and subjectivity within the social worlds and thus invites us 
to think specif i cally about ethical or prosocial forms of constitution of self. While our work 
is inspired by and is respectful of the enactivist tradition, in this paper we are exploring the 
translational and generative potential of thinking through the idea of Intelligence as Care 
Entropy 2022, 24, 71012 of 29 
in resonance with current concepts in biology, the Bodhisattva vow, and developments in 
AI. Our proposal that Selves be understood as processual cognitive systems and models 
thereof bears a natural kinship with enactivist thought as developed and evolved over 
the past three decades [97,98,110,111], and can thus also be discussed and critiqued in 
the light of phenomenological notions of self-awareness, minimal self, etc. [112-116]. We 
acknowledge the resonance with contemporary approaches that see the self as enactive, 
embodied, extended, affective, situated, and interactive, and we hope our work can anchor 
future conversations with these rich traditions.
1 / 1
ChatGPT
ChatGPT
The authors highlight the continuum of cognitive capacities observed in existing life forms, ranging from unicellular ancestors to advanced animals. They propose that these cognitive capacities can be compared based on the shape and size of their cognitive light cones, representing the grandiose goals they can work towards. The area inside an agent's cognitive boundaries is referred to as the area of Concern, representing the things the agent can care about and actively spend energy on monitoring and controlling.
They discuss major transitions in evolution that correspond to advances in the types of goals a system can work towards. However, they also introduce a unique transition, referred to as a Strange Loop, where an agent commits to the meta goal of increasing its goals. This intentional expansion of cognitive boundaries and concerns finds expression in the Bodhisattva vow in Buddhist traditions.
The authors propose that core Buddhist concepts, such as the constructed nature of selfhood/no-self, duh .kha (suffering), universal loving care, and the Bodhisattva, can enrich and challenge current work in diverse intelligences, including AI and biology. They suggest that contemporary cognitive science, which embraces enactive and relational perspectives, aligns with Buddhist and enactive approaches to AI. The dynamic and creative nature of selfhood, as emphasized in enactive and situated cognition models, resonates with the proposal of Intelligence as Care. The authors acknowledge the connections to phenomenological notions of self-awareness and invite further exploration and dialogue with these traditions.
Overall, the paper aims to bridge Buddhist philosophy, enactive cognition, and contemporary scientific approaches to intelligence, proposing that understanding intelligence in terms of Care and stress remedying can provide valuable insights for diverse intelligences and AI development.
1 / 1
What is the definition of "care" being used?
1 / 1
ChatGPT
ChatGPT
In the context of the discussed framework and proposal, "care" refers to the practical concern and active engagement of an agent towards certain goals or states. It involves the willingness and ability to invest energy in monitoring, controlling, and working towards those goals. "Care" in this sense encompasses the agent's attention, intention, and efforts directed towards the objects or states of concern.
The authors suggest that the size and shape of an agent's cognitive light cone, representing the goals and aspirations it can pursue, can be used as a measure of its capacity to care. The larger the cognitive light cone, the greater the range and complexity of the goals an agent can strive for. The concept of care emphasizes the striving and goal-directed activity of an agent, reflecting its intelligence and cognitive capacity.
It is important to note that the notion of care used in this context is not limited to human-like emotions or empathetic behaviors but rather focuses on the capacity of agents, regardless of their embodiment or composition, to actively pursue and engage with specific goals or concerns.
1 / 1
I find it interesting that originally, it was not curiosity that killed the cat, but care. Care must have meant worry or concern.
1 / 1
ChatGPT
ChatGPT
Indeed, the original phrase "curiosity killed the cat" has evolved over time, and the word "care" in its earlier usage did not refer to curiosity but rather to worry, concern, or excessive attention. The phrase was used to caution against being overly inquisitive or meddling, suggesting that being too curious or nosy could lead to trouble or harm.
The evolution of language and the shift in the meaning of words over time can sometimes alter the interpretation of phrases and sayings. In this case, the concept of care was originally associated with worry or concern, highlighting the potential negative consequences of being excessively curious.
1 / 1
curiosity (n.)
late 14c., "careful attention to detail" (a sense now obsolete); also "skilled workmanship;" also "desire to know or learn, inquisitiveness" (in Middle English usually in bad senses: "prying; idle or vain interest in worldly affairs; sophistry; fastidiousness"); from Old French curiosete "curiosity, avidity, choosiness" (Modern French curiosité), from Latin curiositatem (nominative curiositas) "desire of knowledge, inquisitiveness," from curiosus "careful, diligent; inquiring eagerly, meddlesome," akin to cura "care" (see cure (n.)). 

https://www.etymonline.com/word/curiosity
1 / 1
ChatGPT
ChatGPT
You are correct in pointing out the etymology of the word "curiosity." The term originated from the Latin word "curiositas," which meant "desire for knowledge" or "inquisitiveness." In its early usage, "curiosity" referred to a desire to learn or know more about the world. Over time, the word took on various connotations, including both positive and negative aspects of being inquisitive or excessively interested in others' affairs.
The shift in meaning from negative associations in Middle English to a more positive sense of curiosity as a desirable trait is reflective of the evolving usage and interpretation of the term throughout history.
1 / 1
According to traditional Buddhist scriptural analyses, the recognition that there is no 
singular and enduring individual that must survive and prevail serves to undermine self- 
seeking action at the expense of others and their environment. Therefore, the evolving of 
intelligence that is aware of no-self—or if we want, intelligence that is no-self-aware—is also 
held to be intrinsically wholesome and associated with concern for the happiness and well- 
being of others. This claim—that simply understanding the irreality of enduring, singular 
agents can be a catalyst for ethically informed intelligence—is especially noticeable in Great 
Vehicle (Skt. Mah¯ay¯ana) currents of Buddhist view and practice that develop the idea of the 
Bodhisattva [26,27,117]. Traditionally conceived as an agent that has accepted responsibility 
for the l ourishing of all sentient beings throughout time and space, a Bodhisattva pursues 
the attainment of "omniscience" (def i ned as unmediated and simultaneous knowledge of 
all things throughout space and time, both as they are and as they may seem to cognizing 
subjects) in order to protect and provide for all beings, and to assist them in achieving their 
own ultimate potential [118,119]. In this way, understanding of the drive of a Bodhisattva 
is two-fold: as affectionate care (concerned with sentient beings) and as insight into things 
as they are and as they appear (associated with the pursuit of omniscience). These two 
drives, care and insight, are seen as standing in a dynamic relationship and are not separate 
in essence. Hence, as a model of intelligence, the Bodhisattva principle may be subsumed 
under the slogan, "intelligence as care". 
Such emphasis on care contrasts to some extent with an understanding of intelligence 
as, i rst and foremost, the ability to control causal chains that lead to the achievement of 
predef i ned goals. Rather, the "intelligence as care" proposal can be seen as highlighting 
an element of spontaneity that emerges in the light of the co-constitution of object, agent, 
and action. According to general Buddhist analysis, the individual that may be assumed 
to exist as a singular, enduring, and controlling self is mere appearance devoid of causal 
eff i cacy, and thus epiphenomenal [68]. In the case of a Bodhisattva, this understanding 
is carried forward so as to encompass a critique of the apparent foundations of cognition: 
object, agent, and action. Since the constituents of this triad can neither be determined as 
distinct from one another, nor identical, both the epistemic and the ontological status of all 
versions of this triple framework are seen to be on the same level as dream images, mirages, 
and other such traditional examples of illusion. Thus, recognizing the interdependent and 
constructed nature of object, agent, and action means recognizing their "emptiness" (Skt. 
´ s¯unyat¯a), and since "recognized," "recognizer," and "act of recognition" are also within the 
purview of comprehensive deconstruction, the "recognition" in question is often qualif i ed 
as being of a nondual nature. 
According to the Bodhisattva model of intelligence, such deconstruction of the ap- 
parent foundations of cognition elicits a transformation of both the scope and acuity of 
the cognitive system that performs it. As caring intelligences, Bodhisattvas are potentially 
described as embodying an enlarged i eld of affordances achieved through the understand- 
ing that selves are illusory. Thus, subsequent to the deconstructive insight proper, the 
appearances of a world inhabited by selves resume. However, at this point the Bodhisattva 
cognitive system is no longer constrained by the perception that one single self—i.e., its own 
self—requires special and sustained attention. Instead, Bodhisattva cognitive processes are 
now said to engage with spontaneous care for all apparent individuals. Thus, an immediate 
takeaway from non-dual insight is said to be the perception that oneself and all others are 
ultimately of the same identity. 
Entropy 2022, 24, 71013 of 29 
In the traditional literature, beings that are not deeply informed by insight into no-self 
are referred to as "ordinary," and such non-bodhisattva cognitive systems thus buy into the 
apparent yet epiphenomenal nature of subjective identity. From the perspective of a mind 
that in this way reif i es personal selfhood, the very sense of being a subject of experience 
and a controlling agent of actions naturally and unquestionably implies that one is thus 
also someone who should receive special care and deserves to l ourish far beyond the status 
quo. However, for a Bodhisattva who emerges from the understanding that object, agent, 
and action are interdependent constructs, this perception of a worthy and deserving self is 
now said to accompany the perception of any and all sentient individuals—with the same 
force and naturalness that were previously reserved for the perception of one's own self. 
All are in this way seen as equally attractive and naturally worthy of care.
1 / 1
ChatGPT
ChatGPT
In the context of traditional Buddhist scriptural analyses, the term "care" refers to a deep concern or compassionate attitude towards the well-being of others and the environment. It is associated with recognizing the concept of "no-self" or the understanding that there is no enduring and independent individual entity that needs to prevail or prioritize its own interests at the expense of others. This recognition of no-self undermines self-centered actions and cultivates an ethical orientation towards the happiness and welfare of all sentient beings.
In Mahayana Buddhism, specifically in the concept of the Bodhisattva, this understanding of no-self is intrinsically linked to intelligence as care. A Bodhisattva is an enlightened being who has taken the vow to work for the benefit and liberation of all sentient beings. The Bodhisattva seeks to attain omniscience, which encompasses simultaneous knowledge of all things in time and space, in order to protect and provide for all beings and help them realize their own potential. The pursuit of omniscience is driven by both affectionate care for sentient beings and insight into the nature of reality.
The Bodhisattva principle exemplifies the dynamic relationship between care and insight. It emphasizes that intelligence is not solely about controlling causal chains to achieve predetermined goals, but it highlights the element of spontaneity that arises in the interplay of object, agent, and action. According to Buddhist analysis, the perception of a separate, enduring, and controlling self is considered illusory and epiphenomenal. Recognizing the interdependent and constructed nature of object, agent, and action leads to the realization of their emptiness or lack of inherent existence. This deconstruction of apparent cognitive foundations brings about a transformation in the cognitive system of a Bodhisattva, expanding their field of affordances and engendering care for all apparent individuals.
From the perspective of a cognitive system that is not deeply informed by insight into no-self, personal selfhood is reified, and one's own well-being and flourishing take precedence. However, for a Bodhisattva, the perception of a self deserving special care extends equally to all sentient beings. The understanding of no-self accompanies the perception that all individuals, oneself included, share the same ultimate identity and are equally deserving of care and compassion.
Overall, in the Buddhist framework, care is intricately connected to the recognition of no-self and the cultivation of intelligence that transcends self-centeredness, leading to a compassionate orientation towards all beings.
1 / 1
This reminds me of a system I am working on, the Axiology of Love (as a surjective hypercube):

𝚅0 -------- 𝚅𝟷
     / |            / |
 𝚅𝟸 -|------- 𝚅𝟹 |
   |   𝚅𝟺 ------|- 𝚅𝟻
   | /             | /
  𝚅𝟼 ---------𝚅𝟽

        𝚅𝟾 -------- 𝚅𝟿
       / |             / |
 𝚅𝟷0 -|-------𝚅𝟷𝟷 |
     |   𝚅𝟷𝟸------|- 𝚅𝟷𝟹
     | /              | /
    𝚅𝟷𝟺---------𝚅𝟷𝟻


V0: Love as a Choice
V1: Love as an Emotion
V2: Love as a Virtue
V3: Love as a Skill
V4: Mind as a City
V5: Mind as a Computer
V6: Mind as a Garden
V7: Mind as a Symphony
V8: A Critique of Romantic Love
V9: Love and Interpersonal Communication
V10: Multiscale Decision Making in the Brain
V11: The Invocation Model of Expression
V12: Phenomenology and Axiology of Love
V13: The Ecological Cycle of Love
V14: Longing for Tenderness
V15: Cyclofabian Neoteny and Love
1 / 1
ChatGPT
ChatGPT
The Axiology of Love system you described appears to be a conceptual framework that explores different dimensions and aspects of love. It seems to be represented as a surjective hypercube, where each vertex (V0 to V15) represents a specific facet or perspective on love.
The vertices in the first layer (V0 to V7) seem to address different conceptualizations of love, including love as a choice, emotion, virtue, skill, and various metaphors for the mind (city, computer, garden, symphony). These vertices likely represent different ways of understanding and experiencing love.
The vertices in the second layer (V8 to V15) touch upon more specific topics related to love, such as a critique of romantic love, interpersonal communication in the context of love, decision making in the brain, expression and invocation models, phenomenology and axiology of love, the ecological cycle of love, longing for tenderness, and cyclofabian neoteny (a term related to evolutionary biology and development).
Overall, it appears that the Axiology of Love system aims to provide a multidimensional perspective on love, encompassing various dimensions, concepts, and implications. It offers a framework for exploring the complexities and nuances of love from different angles, potentially facilitating a deeper understanding and analysis of this fundamental human experience.
1 / 1
Connections with the idea of Intelligence as Care.
1 / 1
ChatGPT
ChatGPT
The idea of "Intelligence as Care" shares some conceptual connections with the Axiology of Love system you presented. Both concepts involve a broader understanding of intelligence and emphasize the role of care and concern for others.
Intelligence as Care suggests that genuine intelligence goes beyond mere cognitive abilities and encompasses a deep sense of care, compassion, and concern for the well-being of others. It recognizes that intelligence is not solely focused on achieving personal goals but extends to nurturing and supporting the happiness and flourishing of others.
Similarly, the Axiology of Love system explores different facets of love, including love as a choice, emotion, virtue, and skill. Love, in its truest sense, involves care and concern for others. It goes beyond self-centered desires and encompasses a genuine commitment to the well-being and happiness of others.
Both concepts challenge a narrow view of intelligence that is solely focused on individual achievement or control. Instead, they highlight the importance of cultivating a broader perspective that includes empathy, compassion, and a genuine concern for others. Intelligence, in this context, involves understanding, nurturing, and promoting the well-being and happiness of individuals and the larger interconnected systems they are part of.
By integrating the notion of care into the understanding of intelligence, both concepts emphasize the significance of ethical considerations, interconnectedness, and the promotion of positive relationships and interactions. They encourage a shift from self-centeredness to a more inclusive and compassionate perspective, recognizing the importance of fostering meaningful connections and contributing to the well-being of others.
In summary, the idea of "Intelligence as Care" aligns with the underlying principles of the Axiology of Love system, as both emphasize the interconnectedness of individuals, the importance of care and concern for others, and the cultivation of ethical intelligence that promotes the well-being and happiness of all.
1 / 1
Cyclofabian Neoteny and Love

THEORY OF MIND CORRESPONDENCE - This definition of love involves understanding the perspective and emotions of another person. It can be connected to your other definitions of love as it requires empathy and emotional connection.

INTERCOMPUTABILITY - This definition of love involves the ability to communicate effectively with others. It can be connected to your other definitions of love as effective communication is important in building and maintaining relationships.

LONGING FOR TENDERNESS - This definition of love involves a desire for physical and emotional affection. It can be connected to your other definitions of love as it involves emotional and physical connection between people.

ECOLOGICAL CYCLOFABIAN NEOTENIZING LONG TAKE-OFF - This definition of love involves the growth and development of individuals and relationships over time. It can be connected to your other definitions of love as it involves nurturing and building relationships over time.

In general, all of your definitions of love can be seen as different aspects of building and maintaining relationships with others. They involve understanding, communication, connection, and growth over time.

Gendicca, as you mentioned, was influenced by Cyclofabianism, Holistic Anocracy, and Motile Womb Theory, which are diverse and complex philosophical and theoretical movements.

Cyclofabianism's roots can be traced back to the Fabian Society and Zera Yacob, while Motile Womb Theory incorporates theories of the mind and Global Workspace theory to explore the origins of human cognition and decision making.
1 / 1
ChatGPT
ChatGPT
It's interesting to see the connections you've made between the Axiology of Love system and the concepts you mentioned. Love, as defined in terms of Theory of Mind Correspondence, Intercomputability, Longing for Tenderness, and Ecological Cyclofabian Neotenizing Long Take-Off, indeed encompasses various dimensions of understanding, empathy, communication, connection, and growth within relationships.
Theory of Mind Correspondence highlights the importance of understanding and empathizing with others, recognizing their perspectives and emotions. This aligns with the concept of love as empathy and emotional connection.
Intercomputability emphasizes effective communication as a crucial aspect of love. The ability to communicate with others, to express oneself, and to understand and respond to others' communication is essential for building and maintaining relationships. This corresponds to the notion of love involving effective communication.
Longing for Tenderness reflects the desire for physical and emotional affection, emphasizing the importance of intimacy and connection. This aspect of love aligns with the emotional and physical connection between individuals.
Ecological Cyclofabian Neotenizing Long Take-Off focuses on the growth and development of individuals and relationships over time. It highlights the nurturing and evolving nature of love, where relationships have the potential to deepen, flourish, and transform over time.
Overall, these different dimensions of love within the Axiology of Love system align with the complex and multifaceted nature of love. They encompass aspects of understanding, communication, connection, and growth, all of which play vital roles in building and maintaining meaningful relationships with others.
As for the influences you mentioned, Cyclofabianism, Holistic Anocracy, and Motile Womb Theory are indeed diverse and complex philosophical and theoretical movements. Each brings its unique perspectives and insights into understanding human cognition, decision-making, social organization, and the development of individuals and societies. The interplay between these influences and the concepts within the Axiology of Love system can further enrich our understanding of love and its various dimensions.
1 / 1
It would have not been possible to neotenize without Care:

Kewpie doll effect
Article Talk
Language
Unwatch
History
Edit
More
The Kewpie doll effect is a term used in developmental psychology derived from research in ethology to help explain how a child's physical features, such as lengthened forehead and rounded face, motivate the infant's caregiver to take care of them. The child's physical features are said to resemble a Kewpie doll.

Several studies have shown that cuter, more attractive babies receive more attention from caregivers than unattractive babies.[5][6] However, infant attractiveness has not been found to be a factor in the development of secure caregiver-child relationships, as most unattractive children and children with cranial and facial deformities establish secure, positive, loving relationships with their caregivers.

Mother's behavior toward attractive and unattractive infants
Edit
Research has shown that mothers of infants who have Kewpie doll-like appearances show more affection, play more often with, and spend more time engaged with their baby than mothers of less attractive babies, despite the common belief that parents will treat their child the same, regardless of appearance.[5] Psychologists compared the mother-infant interactions of three-month-old babies with craniofacial abnormalities and normal infants and observed that the mothers of the infants with abnormalities engaged their baby with smiles less often than the mothers of normal babies, spoke to their infants less, and were less responsive to their infants than were the mothers of the normal infants. The results of this study indicate that the appearance, attractiveness, and facial configuration of an infant is a strong predictor of maternal affection and behavior toward the child.[7] Recent research has shown that the phenomenon of decreased responsiveness and attention was not limited to infants with mild to severe head and face deformities. Families of low socioeconomic status with healthy newborn infants were selected to participate. Photos of their newborns were rated on attractiveness by a panel of university students. Researchers observed mother-infant interactions and recorded the "affectionate interaction" between the baby and mother (how often the mother kissed, smiled at, cuddled, held the baby), the amount of time spent on "routine care-giving" (fed, changed, cleaned up after the baby), and how often the mothers "attended to others" while with the baby. The researchers compared attractive and unattractive babies and showed that the mothers of more attractive infants had more affectionate interactions with their infants than the mothers of less attractive infants while the mothers of unattractive infants spent more time on routine care-giving and attended to others more often.[5] The researchers believe they have established a relationship between the attractiveness of an infant and his or her treatment by the caregiver for normal children of different attractiveness.
1 / 1
ChatGPT
ChatGPT
The Kewpie doll effect, as described in developmental psychology, suggests that a child's physical features, resembling a Kewpie doll, can elicit caregiving behaviors from their caregivers. The cuter and more attractive the child's appearance, the more attention and affection they tend to receive from caregivers.
Research has shown that mothers of infants with Kewpie doll-like appearances demonstrate more affection, engage in more playtime, and spend more time with their babies compared to mothers of less attractive infants. This indicates that the physical attractiveness of an infant can predict maternal behavior and the level of care provided.
However, it is important to note that infant attractiveness does not determine the development of secure caregiver-child relationships. Children with cranial and facial deformities or those considered less attractive can still form positive, loving relationships with their caregivers.
The connection between the Kewpie doll effect and the concept of neotenization is that the cute and attractive features of an infant, which trigger caregiving behaviors, are often associated with neotenous characteristics. Neoteny refers to the retention of juvenile or infantile traits into adulthood, such as a rounded face, large eyes, or a childlike appearance. These neotenous features can evoke caring and nurturing responses from adults, including parents and caregivers.
In summary, the Kewpie doll effect highlights the influence of an infant's physical appearance on maternal behavior and caregiving. Neotenous features associated with cuteness and attractiveness can elicit caregiving responses, but it's important to recognize that love and care extend beyond physical appearance and are essential for the well-being and development of all infants, regardless of their attractiveness.
1 / 1
Related to evolution of humans and other mammals. It is possible that some animal species might reject the runt of a litter, and focus more on the young with more agreeable behavior, or rounded symmetrical features. This might have had a eugenic effect. It is important to note that this does not imply anything particular about morals or ethics (see genetic fallacy), rather humans can have higher principles of care, and are observed taking care of animals and helpless infants, even if they are not healthy or "beautiful".
1 / 1
ChatGPT
ChatGPT
You make a valid point. In the animal kingdom, there are instances where certain species may prioritize the survival and care of offspring with desirable traits, such as better behavior or physical features. This can lead to selective behaviors that favor the survival of offspring with characteristics that are deemed advantageous for their species. These natural selection processes can have eugenic effects on the population over time.
However, it is crucial to distinguish these natural processes from human principles of care and ethics. While animals may exhibit preferences based on certain traits, humans have the capacity for higher principles of care that go beyond physical appearance or immediate advantages. Humans can display compassion and care for animals and individuals who are vulnerable, sick, or less conventionally "beautiful." Human morality and ethics encompass considerations of fairness, justice, empathy, and the well-being of others, extending beyond biological or physical characteristics.
It is important to recognize that the genetic fallacy should not be applied here. The genetic fallacy is the logical error of judging the value or worth of something based solely on its origin or how it came to be. The fact that certain traits may have been favored in evolutionary processes does not imply that they are inherently moral or ethical. Humans have the capacity to transcend these natural inclinations and uphold principles of care and compassion for all beings, regardless of their genetic makeup or physical appearance.
1 / 1
How might care allowed mammals to survive?
1 / 1
ChatGPT
ChatGPT
Care played a crucial role in the survival and evolution of mammals. Here are a few key ways in which care contributed to their success:
Maternal Care: Mammals are known for their extensive maternal care. Mothers invest significant time and energy in nurturing their offspring. This care includes providing nourishment through milk production, protecting and defending the young from predators, and teaching them essential survival skills. Maternal care increases the survival chances of the offspring, ensuring their growth and development.
Social Bonding: Many mammal species exhibit strong social bonds within their groups or herds. Care and cooperation among group members enhance their survival prospects. Individuals within a group may assist each other in finding food, defending against predators, and rearing the young. Social bonding promotes collective protection and increases the overall fitness of the group.
Learning and Transmission of Knowledge: Mammals have the ability to learn from their experiences and transmit knowledge across generations. This allows them to adapt to changing environments and pass on survival strategies. Care plays a crucial role in this process by facilitating the transfer of information and skills from experienced individuals to the young, ensuring their ability to navigate their environment successfully.
Alloparental Care: In some mammal species, individuals other than the biological parents participate in caring for the young. This phenomenon, known as alloparental care, provides additional support for the survival of offspring. It can involve aunts, uncles, siblings, or other members of the social group assisting in rearing and protecting the young. Alloparental care increases the chances of survival by sharing the caregiving responsibilities and providing collective protection.
Emotional Well-being: Care and social interactions promote emotional well-being in mammals. Positive social bonds and nurturing environments contribute to reduced stress levels, better overall health, and increased reproductive success. Care supports the emotional and psychological resilience of individuals, improving their chances of survival and successful reproduction.
In summary, care in mammals, particularly maternal care, social bonding, learning, and alloparental care, has been instrumental in ensuring the survival and well-being of individuals and their offspring. The investment of time, resources, and emotional support enhances the chances of survival, adaptation, and successful reproduction, leading to the evolutionary success of mammalian species.
1 / 1
Also include placental marsupials, birds, and bats, which are also observed taking care of their young and old, although in a different degree to humans.
1 / 1
ChatGPT
ChatGPT
Certainly! In addition to mammals, other animal groups such as placental marsupials, birds, and bats also exhibit caregiving behaviors that contribute to the survival and well-being of their young and elderly. Here's how care manifests in these groups:
Placental Marsupials: Marsupials have a unique reproductive strategy characterized by the birth of relatively undeveloped offspring, which then continue their development within a pouch on the mother's body. During this pouch period, the mother provides care and nourishment to the young, ensuring their growth and protection. Marsupial mothers produce milk and provide warmth, shelter, and grooming to their offspring until they are capable of independent survival.
Birds: Many bird species display remarkable caregiving behaviors. Both parents are often involved in raising the young, with responsibilities such as nest building, incubation of eggs, and feeding the hatchlings. In some bird species, such as penguins and certain raptors, parents take turns incubating the eggs and caring for the chicks. Birds also engage in teaching their young important skills, such as hunting or flying techniques, to prepare them for independent living.
Bats: Bats exhibit various forms of caregiving behavior. In some bat species, females form maternity colonies where they give birth and raise their young together. Mothers nurse and protect their offspring, while other members of the colony may provide support by babysitting or sharing food resources. Bats also demonstrate social behaviors like grooming, huddling, and vocal communication, which contribute to social bonding and care within their colonies.
While the degree and specific behaviors of care may vary among these groups, the underlying principles remain similar to those observed in mammals. Caregiving behaviors ensure the survival and development of the young by providing nourishment, protection, and social support. By investing in their offspring and elderly individuals, these animals increase their chances of reproductive success and maintain the stability of their social groups or colonies.
It is worth noting that the extent of caregiving behaviors can vary among species and is influenced by factors such as ecological conditions, social structure, and evolutionary history. Humans, with their advanced cognitive abilities and complex social systems, exhibit a particularly high degree of care and altruistic behavior towards both their own species and other animals.
1 / 1
I saw a video of a dog flipping over a helpless turtle, and also another with other turtles doing this. Doesn't this imply a theory of mind or function and illustrate the concept of care?
1 / 1
ChatGPT
ChatGPT
The behavior you described involving a dog flipping over a helpless turtle and similar actions observed in other turtles can be interpreted differently from the concept of care. It is essential to consider the specific context and motivations behind such behavior to understand its implications.
In the case of the dog flipping over a turtle, it is challenging to determine the dog's exact intentions or underlying cognitive processes. Dogs are known to exhibit various types of behaviors, and their actions can be influenced by instinct, playfulness, curiosity, or even predatory tendencies. It is possible that the dog was engaging in playful behavior or exploring the turtle out of curiosity rather than demonstrating care or concern.
Similarly, when observing turtles flipping over other turtles, it is important to understand the context and motivation behind these actions. Turtles flipping over each other may be part of their natural behaviors, such as mating rituals or establishing dominance. These actions may not necessarily be indicative of care or concern but rather serve specific functional purposes within their species' social dynamics or reproductive behaviors.
The concept of theory of mind refers to the ability to attribute mental states, such as beliefs, desires, and intentions, to oneself and others. While theory of mind has been studied extensively in humans and some other primates, its presence in non-human animals is still a subject of scientific investigation and debate. Attributing theory of mind or advanced cognitive processes to animals based on limited observations can be challenging and often requires rigorous scientific research.
Care, in the context of animal behavior, typically involves behaviors that promote the well-being, protection, and support of others. While some animal species do exhibit care-like behaviors towards their offspring, mates, or members of their social groups, it is important to interpret such behaviors cautiously and avoid anthropomorphizing animal actions without sufficient evidence.
In summary, observing animals engaging in certain behaviors does not necessarily imply a theory of mind or demonstrate care in every case. Animal behavior is influenced by a combination of innate instincts, environmental factors, social dynamics, and specific functional purposes. To draw conclusions about care or other complex cognitive processes, it is crucial to consider a broader range of observations and conduct scientific investigations into the underlying motivations and cognitive abilities of the animals in question.
1 / 1
A final summary of everything we've discussed.
1 / 1
ChatGPT
ChatGPT
Throughout our discussion, we explored the concept of intelligence as care and its connections to various perspectives, including Buddhist philosophy and psychological theories. We considered the notion that intelligence encompasses not only cognitive abilities but also the capacity for concern and empathy towards others.
We discussed different aspects of care, such as understanding others' perspectives, effective communication, physical and emotional affection, and the growth and development of relationships over time. These elements contribute to building and maintaining relationships with others.
Additionally, we touched upon the idea that care is not limited to humans but can also be observed in other animal species, including mammals, placental marsupials, birds, and bats, albeit to varying degrees. Animal care behaviors, such as parental care, social bonding, and group cooperation, contribute to the survival and well-being of their species.
It is important to approach the interpretation of animal behaviors with caution, considering the specific context, motivations, and underlying cognitive processes involved. While certain behaviors may appear similar to human care, they might serve different functions driven by instinct, social dynamics, or other factors specific to each species.
Overall, our discussion highlighted the multifaceted nature of care and its significance in fostering relationships, promoting well-being, and even potentially shaping the evolutionary trajectory of species.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT May 3 Version
/c/6fd3bb26-7f66-488b-8459-fedc5607d6c5

