Linking Neuro-Symbolic Approaches
Open sidebar
Linking Neuro-Symbolic Approaches
I cant get this reference to link correct: ==Types of approaches==

Approaches for integration are varied. [[Henry Kautz]]'s taxonomy of neuro-symbolic architectures{{sfn|Sarker|Zhou|2021}}, along with some examples, follows:
* '''Symbolic Neural symbolic'''—is the current approach of many neural models in natural language processing, where words or subword tokens are both the ultimate input and output of large language models. Examples include [[BERT (language model)|BERT]], RoBERTa, and [[GPT-3]]. 
* '''Symbolic[Neural]'''—is exemplified by [[AlphaGo]], where symbolic techniques are used to call neural techniques. In this case, the symbolic approach is [[Monte Carlo tree search]] and the neural techniques learn how to evaluate game positions.
* '''Neural|Symbolic'''—uses a neural architecture to interpret perceptual data as symbols and relationships that are reasoned about symbolically. The Neural-Concept Learner{{sfn|Mao|Gan|Kohli|Tenenbaum|2019}} is an example.
* '''Neural: Symbolic → Neural'''—relies on symbolic reasoning to generate or label training data that is subsequently learned by a deep learning model, e.g., to train a neural model for symbolic computation by using a [[Macsyma]]-like symbolic mathematics system to create or label examples.
* '''Neural_{Symbolic}'''—uses a neural net that is generated from symbolic rules. An example is the Neural Theorem Prover,<ref>{{Cite conference| publisher = Association for Computational Linguistics| doi = 10.18653/v1/W16-1309| pages = 45-50| last1 = Rocktäschel| first1 = Tim| last2 = Riedel| first2 = Sebastian| title = Learning Knowledge Base Inference with Neural Theorem Provers| book-title = Proceedings of the 5th Workshop on Automated Knowledge Base Construction| location = San Diego, CA| access-date = 2022-08-06| date = 2016| url = https://aclanthology.org/W16-1309}}</ref> which constructs a neural network from an [[And-or tree|AND-OR]] proof tree generated from knowledge base rules and terms. Logic Tensor Networks<ref>{{cite arXiv | eprint = 1606.04422| last1 = Serafini| first1 = Luciano| last2 = Garcez| first2 = Artur d'Avila| title = Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge | date = 2016 | class = cs.AI}}</ref> also fall into this category.
* '''Neural[Symbolic]'''—allows a neural model to directly call a symbolic reasoning engine, e.g., to perform an action or evaluate a state. An example would be [[ChatGPT]] using a plugin to query [[Wolfram Alpha]].
These categories are not exhaustive, for example, as they do not consider multi-agent systems. In 2005, Bader and Hitzler presented a more fine-grained categorization that considered, e.g., whether the use of symbols included logic or not and if it did, whether the logic was propositional or first-order logic.{{sfn|Bader|Hitzler|2005}} The 2005 categorization and Kautz's taxonomy above are compared and contrasted in a 2021 article.<ref>{{cite journal| last1 = Sarker| first1 = Md Kamruzzaman| last2 = Zhou| first2 = Lu| last3 = Eberhart| first3 = Aaron|last4 = Hitzler| first4 = Pascal|title = Neuro-symbolic artificial intelligence: Current trends | journal = AI Communications | volume = 34 | issue = 3 | pages = 197-209 |date = 2021| doi = 10.3233/AIC-210084| s2cid = 239199144|url = https://ip.ios.semcs.net/articles/ai-communications/aic210084}}</ref> Recently, [[Sepp Hochreiter]] argued that [[Graph neural network|Graph Neural Networks]] "...are the predominant models of neural-symbolic computing<ref>L.C. Lamb, A.S. d'Avila Garcez, M.Gori, M.O.R. Prates, P.H.C. Avelar, [[Moshe Vardi|M.Y. Vardi]] (2020). "Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective'''."''' CoRR abs/2003.00330 (2020)</ref>" since "[t]hey describe the properties of molecules, simulate social networks, or predict future states in physical and engineering applications with particle-particle interactions."<sup>[https://dl.acm.org/doi/pdf/10.1145/3512715]</sup>
1 / 1
ChatGPT
ChatGPT
To create a correct reference link for the mentioned source, you can use the following format:
[[Author(s)]]'s taxonomy of neuro-symbolic architectures{{sfn|Reference Author(s)|Year}}
Applying this format to the provided information, the correct reference link would be:
[[Henry Kautz]]'s taxonomy of neuro-symbolic architectures{{sfn|Sarker|Zhou|2021}}
Please note that the reference tags (
{{sfn|Reference Author(s)|Year}}
) should be replaced with the actual reference information, including the authors and the publication year.
1 / 1
It's supposed to link to <ref>{{cite journal| last1 = Sarker| first1 = Md Kamruzzaman| last2 = Zhou| first2 >>>> do i have to add a ref name tag?
1 / 1
ChatGPT
ChatGPT
I apologize for the confusion. If you want to create a reference link using the
<ref>
tag, you would need to add a unique reference name tag to the citation. Here's an example of how you can modify the reference to include a reference name:
sql
Copy code
<
ref
name
=
"SarkerZhou2021"
>
{{cite journal
|
last1
=
Sarker
|
first1
=
Md Kamruzzaman
|
last2
=
Zhou
|
first2
=
Lu
|
last3
=
Eberhart
|
first3
=
Aaron
|
last4
=
Hitzler
|
first4
=
Pascal
|
title
=
Neuro
-
symbolic artificial intelligence:
Current
trends
|
journal
=
AI Communications
|
volume
=
34
|
issue
=
3
|
pages
=
197
-
209
|
date
=
2021
|
doi
=
10.3233
/
AIC
-210084
|
s2cid
=
239199144
|
url
=
https:
/
/
ip.ios.semcs.net
/
articles
/
ai
-
communications
/
aic210084}}
<
/
ref
>
Then, when you want to refer to this specific reference, you can use
<ref name="SarkerZhou2021"/>
in the text.
Please note that you should choose a meaningful and unique name for the reference tag, such as "SarkerZhou2021" in the example above.
1 / 1
A list of topics discussed.
1 / 1
ChatGPT
ChatGPT
In the provided text, the following topics are discussed:
Types of approaches for integration
Henry Kautz's taxonomy of neuro-symbolic architectures
Symbolic Neural symbolic approach in natural language processing
Symbolic[Neural] approach exemplified by AlphaGo
Neural|Symbolic approach using a neural architecture to interpret perceptual data
Neural: Symbolic → Neural approach relying on symbolic reasoning to generate or label training data
Neural_{Symbolic} approach using a neural net generated from symbolic rules
Neural[Symbolic] approach allowing a neural model to directly call a symbolic reasoning engine
Comparison of the 2005 categorization and Kautz's taxonomy
Graph Neural Networks as predominant models of neural-symbolic computing
Applications of Graph Neural Networks in describing properties of molecules, simulating social networks, and predicting future states in physical and engineering applications
These topics cover a range of approaches and concepts related to neuro-symbolic architectures and their applications.
1 / 1
Free Research Preview. ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT May 24 Version
ChatGPT

