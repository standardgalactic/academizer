This is about model and induced, which is a term which is derived from the way people talk in the AI world.
And I'm using it because I just published a book about AI. I'm not an expert on AI, but my co-author is very much an expert on AI.
And the book is about limits to AI. So AI will never take over the world.
AI can't even help you make a simple bank transaction when you call your bank.
And that's after 50 years of attempts to create chatbots which will behave like human beings.
So AI, we both think AI is a fantastic phenomenon which will get better and better, which will help us more and more as time goes by.
But it will always be along very narrow channels. There won't be general AI which would come close even to the intelligence of a rabbit.
Because organisms have a kind of general intelligence which is impossible according to the arguments of our book, which are all valid.
And some of which are quite technical mathematical arguments. It's impossible for machines.
Machines are Turing machines, which means that they are constrained by the requirements of Turing computability, which are very strict requirements.
All right. Now, just one simple example to introduce the idea of a model induced escape.
So spam filters are created by the inputs of users of email services, for instance Gmail.
We train a neural network by classifying an email as spam by pressing the spam button.
And that creates training data which creates a piece of AI which is able to filter out spam in the future because we've trained the machine to recognize what spam is like.
So the machine requires our ability to recognize spam and we transfer this ability to the machine.
And you can do that. The spam filters work. But only for a while.
Because the authors of spam are evil and they are always looking for ways of writing new kinds of spam which will cheat the spam filters.
And so the success of a spam filter will teach the authors of spam that they need to find new ways of writing spam and thereby bring about the failure of the spam filter.
And that is model induced escape. The very success of the spam filter creates its own failure.
And the same applies if you have an AI algorithm which will make you rich on the stock market.
As soon as you start transacting on the stock market, market participants will see what you're doing.
They will change their behavior and then you will lose all your money.
And that too is a case where success of an algorithm brings about its own failure. That's model induced escape.
Now people think that they can solve the problem of traffic jams.
And this is they have a model of how to solve the problem of traffic jams.
And so the way they do it is they throttle speeds on major roads so that everybody falls within a certain threshold of speed.
And thereby because they're controlling this threshold, they can avoid traffic jams.
The problem is that there are human beings who are driving cars who don't like to have their speed throttled.
They want to drive quickly and so they move to narrow roads and they create traffic jams on the narrow roads.
And so again we have model induced escape.
And this seems to be a general phenomenon that government planning quite generally leads to phenomena
like because there are human beings involved and you can't get rid of the human beings.
I don't know if you've heard about this. It's a planned ideal city to be built in Saudi Arabia in the desert.
And it will be a city which is called the line or edge city.
It's a two dimensional city. It doesn't have any real width.
It's very, very strange. 170 kilometre long line city.
And it looks a bit like this. So they live inside the edge.
They even play where they communicate with each other across bridge.
It's absolutely weird, but they've already spent billions of dollars on planning it.
They have a football field inside the city like that.
You can't do much in the desert anyway. You have to somehow close off the desert.
The problem is if you do it on a line, it will take huge queues to get to the town hall.
If the town hall were in the middle of a circular city, each person could reach it in a reasonable time.
But if a city is aligned 170 kilometres long, you're never going to be able to get to the front of the queue.
So I don't believe that smart cities which are all over the world now beginning to receive huge amounts of investment
are necessarily going to lead to smart cities. So the number one smart city for 2022 is Shanghai.
But Shanghai in 2022 was suffering huge problems because of lockdown.
It wasn't smart at all.
Now, as we've seen, there's no such thing as spam or rather there's no such thing that you can say this is spam
because what is spam at any given time changes depending upon the skills of spam authors
and the abilities of email users to recognise spam.
There are just different ways to pollute your inbox at different time.
So there are some people who think there's no such thing as knowledge that knowledge itself
forecloses on the success of knowledge and thereby brings about its own failure.
So Fire Arbent, who is evil actually, I can talk for a long time about that,
claims that knowledge is not a series of self consistent theories that converges towards an ideal view.
It is not a gradual approach to the truth.
It is rather a bit like spam or COVID or it's an ever increasing ocean of mutually incompatible alternatives.
That's what he says. I think that's true about certain things, but it's not true of physics.
It's not true of mathematics, which was where Fire Arbent actually addressed most of his comments.
It's not true about mathematics. It's not true about engineering.
Engineering can go wrong, but that's not because of engineers.
All right, but most of all, I think Fire Arbent might very well be right about philosophy.
So this is a typical phenomenon in today's philosophy.
So today's philosophy is becoming more and more scholastic.
There are very few good ideas.
There are just many, many comments on comments, on comments, on somebody else's idea,
usually the idea of somebody who is dead.
So somebody writes a paper which announces the correct interpretation of Heidegger's interpretation of a certain fragment by Heraclitus.
And I'm going to insert a joke here because I can't resist it.
So somebody once asked, why did all the ancient philosophers write fragments?
And the answer is the same reason that all the Greek architects built ruins.
All right, back to philosophy.
So Janusz publishes his correct interpretation.
Other people write articles critiquing Janusz's interpretation.
Somebody else finds errors in Ferenc's interpretation of Janusz's interpretation.
There are different ways in which Janusz's interpretation can itself be interpreted.
And all of these are then surveyed in a 100 page long encyclopedia article.
So we now have encyclopedia articles on quite narrow topics in philosophy, which are 100 pages long.
And this mechanism can only get worse.
So I foresee that in a few years there will be 1000 page long articles in encyclopedias.
This is not an approximation to knowledge.
It's some kind of spread of a strange weed.
All right, this brings us to Neary.
Not that Neary is a spread of a strange weed.
Although I think he made a mistake by not having any slides in his talk.
And maybe he's not listening anymore, but never mind.
All right, so in 1982 he wrote a paper on a conservative thread in Wittgenstein's life.
And in Wittgenstein's writings indeed.
And this was a shock.
Many people in philosophy ignored it.
They had a different view of Wittgenstein, either an idealistic view of Wittgenstein,
according to which he was above politics or a socialist or a lefty or a non-conservative view.
And so slowly papers were written defending these non-conservative views
and critiquing Neary's view.
And in this way Neary's view rather fell into the background.
So the very successive Neary's view brought about the critiques which then led to the failure of Neary's view.
And this is another example I think of model induced escape.
Now this applies not just to views about Wittgenstein's politics.
It applies to all views about Wittgenstein and all views about Heidegger and all views about Kant.
They are all bringing about model induced escape in the very discipline of philosophy.
All right, so I'll talk a little bit.
I won't talk about images. I'll just point to the death of images.
So there is now a thing called outpainting, which is done by computers.
So you start with this and then you create this.
You can guess where that came from, but now there are hundreds of these.
And now I'll finish with self-driving cars, which is one of the topics of our book.
So we don't think that self-driving cars will be a success.
I attended a meeting on self-driving cars 15 years ago in which everybody assumed that we would have them in five years.
And we don't have them yet. Whatever Elon Musk might tell you.
So self-driving cars work very well in simple controlled environments such as Disneyland.
They don't yet work in complex, uncontrolled environments.
You can get them to work in rather simple, suburban, quiet, daylight environments
or in through ways where there isn't very much traffic.
But in most uncontrolled traffic environments, they don't work.
And that's because machines can't cope in uncontrolled environments.
Now, the first reason it has nothing to do with model induced escape.
It has to do with untamed nature. So there are always things which can happen.
Avalanches, big cracks in the road, things which the car software was never trained for.
But there are ways in which we have here model induced escape.
So some people like to travel quickly, but the self-driving car will never travel quickly.
And so people will hack the software so that their car can go more quickly.
And there are Luddites who don't believe that we should have self-driving cars
because they like the old days, which I do too, actually.
And so they vandalize self-driving cars by hacking the central software or by some other means.
And these vandals become heroes, and we're seeing this happen at the moment.
Because they realize that the success of self-driving cars can only be brought about
by removing human drivers completely and having all cars be self-driving cars,
which many people would not like.
And so in this way, the very success of self-driving cars will be a threat,
and that will bring about the failure of the self-driving car vision.
And that's the end.
