Six Degrees of Freedom
Open sidebar
Six Degrees of Freedom
GPT-4
Summarize: 
ART theory
New computational paradigms
Edit
Grossberg has introduced and led the development of two computational paradigms that are relevant to biological intelligence and its applications:

Complementary Computing

What is the nature of brain specialization? Many scientists have proposed that our brains possess independent modules, as in a digital computer. The brain's organization into distinct anatomical areas and processing streams shows that brain processing is indeed specialized. However, independent modules should be able to fully compute their particular processes on their own. Much behavioral data argue against this possibility.

Complementary Computing (Grossberg, 2000,[14] 2012[15]) concerns the discovery that pairs of parallel cortical processing streams compute complementary properties in the brain. Each stream has complementary computational strengths and weaknesses, much as in physical principles like the Heisenberg Uncertainty Principle. Each cortical stream can also possess multiple processing stages. These stages realize a hierarchical resolution of uncertainty. "Uncertainty" here means that computing one set of properties at a given stage prevents computation of a complementary set of properties at that stage.

Complementary Computing proposes that the computational unit of brain processing that has behavioral significance consists of parallel interactions between complementary cortical processing streams with multiple processing stages to compute complete information about a particular type of biological intelligence.

Laminar Computing

The cerebral cortex, the seat of higher intelligence in all modalities, is organized into layered circuits (often six main layers) that undergo characteristic bottom-up, top-down, and horizontal interactions. How do specializations of this shared laminar design embody different types of biological intelligence, including vision, speech and language, and cognition? Laminar Computing proposes how this can happen (Grossberg, 1999,[16] 2012[15]).

Laminar Computing explains how the laminar design of neocortex may realize the best properties of feedforward and feedback processing, digital and analog processing, and bottom-up data-driven processing and top-down attentive hypothesis-driven processing. Embodying such designs into VLSI chips promises to enable the development of increasingly general-purpose adaptive autonomous algorithms for multiple applications.
1 / 1
ChatGPT
ChatGPT
ART Theory, as developed by Grossberg, introduces two computational paradigms related to biological intelligence and its applications: Complementary Computing and Laminar Computing.
Complementary Computing tackles the issue of brain specialization. It suggests that our brain operates via pairs of parallel cortical processing streams that compute complementary properties. Each stream has both strengths and weaknesses, akin to physical principles like the Heisenberg Uncertainty Principle. This paradigm argues that the significant computational unit of brain processing involves parallel interactions between these streams, computing complete information about a type of biological intelligence.
Laminar Computing addresses the design of the cerebral cortex, which is organized into layered circuits that engage in bottom-up, top-down, and horizontal interactions. It theorizes how this layered design can best use feedforward and feedback processing, digital and analog processing, and both data-driven and hypothesis-driven processing. This design could enable the development of increasingly adaptive autonomous algorithms for multiple applications when embodied in VLSI chips.
1 / 1
Regular Article
The Link between Brain Learning, Attention, and Consciousness���,������
Author links open overlay panelStephen Grossberg
Show more
Add to Mendeley
Share
Cite
https://doi.org/10.1006/ccog.1998.0372
Get rights and content
Abstract
The processes whereby our brains continue to learn about a changing world in a stable fashion throughout life are proposed to lead to conscious experiences. These processes include the learning of top-down expectations, the matching of these expectations against bottom-up data, the focusing of attention upon the expected clusters of information, and the development of resonant states between bottom-up and top-down processes as they reach an attentive consensus between what is expected and what is there in the outside world. It is suggested that all conscious states in the brain are resonant states and that these resonant states trigger learning of sensory and cognitive representations. The models which summarize these concepts are therefore called Adaptive Resonance Theory, or ART, models. Psychophysical and neurobiological data in support of ART are presented from early vision, visual object recognition, auditory streaming, variable-rate speech perception, somatosensory perception, and cognitive���emotional interactions, among others. It is noted that ART mechanisms seem to be operative at all levels of the visual system, and it is proposed how these mechanisms are realized by known laminar circuits of visual cortex. It is predicted that the same circuit realization of ART mechanisms will be found in the laminar circuits of all sensory and cognitive neocortex. Concepts and data are summarized concerning how some visual percepts may be visibly, or modally, perceived, whereas amodal percepts may be consciously recognized even though they are perceptually invisible. It is also suggested that sensory and cognitive processing in the What processing stream of the brain obey top-down matching and learning laws that are often complementary to those used for spatial and motor processing in the brain's Where processing stream. This enables our sensory and cognitive representations to maintain their stability as we learn more about the world, while allowing spatial and motor representations to forget learned maps and gains that are no longer appropriate as our bodies develop and grow from infanthood to adulthood. Procedural memories are proposed to be unconscious because the inhibitory matching process that supports these spatial and motor processes cannot lead to resonance
1 / 1
ChatGPT
ChatGPT
This article by Stephen Grossberg proposes that the brain's lifelong learning processes lead to conscious experiences. These processes include learning top-down expectations, matching them with bottom-up data, focusing attention on expected information clusters, and developing resonant states between these processes to align expectations with external reality.
The article suggests all conscious states are resonant states, triggering the learning of sensory and cognitive representations. The proposed models are known as Adaptive Resonance Theory (ART) models.
ART mechanisms seem to operate at all levels of the visual system and are hypothesized to be realized by the known laminar circuits of the visual cortex. It's expected that these mechanisms will be found in all sensory and cognitive neocortex's laminar circuits.
The article also discusses how different visual percepts may be perceived, and how sensory and cognitive processing in the brain's "What" processing stream often use top-down matching and learning laws complementary to those used for spatial and motor processing in the "Where" processing stream. This allows our sensory and cognitive representations to remain stable as we learn more about the world, while letting spatial and motor representations forget outdated maps and gains as our bodies grow and change from infancy to adulthood. The article posits that procedural memories are unconscious because the inhibitory matching process supporting spatial and motor processes doesn't lead to resonance.
1 / 1
Conscious Mind, Resonant Brain: How Each Brain Makes a Mind
Stephen Grossberg
Contents
CHAPTER
10 Laminar Computing by Cerebral Cortex: Towards a unified theory of biological and artificial intelligence Get access Arrow
Stephen Grossberg
https://doi.org/10.1093/oso/9780190070557.003.0010
 Pages 353���369
Published: June 2021
Cite Icon Cite
Permissions Icon Permissions
Share Icon Share 
Abstract
The cerebral cortex computes the highest forms of biological intelligence in all sensory and cognitive modalities. Neocortical cells are organized into circuits that form six cortical layers in all cortical areas that carry out perception and cognition. Variations in cell properties within these layers and their connections have been used to classify the cerebral cortex into more than fifty divisions, or areas, to which distinct functions have been attributed. Why the cortex has a laminar organization for the control of behavior has, however, remained a mystery until recently. Also mysterious has been how variations on this ubiquitous laminar cortical design can give rise to so many different types of intelligent behavior. This chapter explains how Laminar Computing contributes to biological intelligence, and how layered circuits of neocortical cells support all the various kinds of higher-order biological intelligence, including vision, language, and cognition, using variations of the same canonical laminar circuit. This canonical circuit can be used in general-purpose VLSI chips that can be specialized to carry out different kinds of biological intelligence, and seamlessly joined together to control autonomous adaptive algorithms and mobile robots. These circuits show how preattentive automatic bottom-up processing and attentive task-selective top-down processing are joined together in the deeper cortical layers to form a decision interface. Here, bottom-up and top-down constraints cooperate and compete to generate the best decisions, by combining properties of fast feedforward and feedback processing, analog and digital computing, and preattentive and attentive learning, including laminar ART properties such as analog coherence.
1 / 1
ChatGPT
ChatGPT
In his book "Conscious Mind, Resonant Brain: How Each Brain Makes a Mind," Stephen Grossberg's chapter on Laminar Computing discusses the role of the cerebral cortex in computing the highest forms of biological intelligence. The cerebral cortex has a laminar organization, with cells organized into six layers involved in perception and cognition. This organization, with slight variations, enables a range of intelligent behaviors.
Grossberg explains how Laminar Computing contributes to biological intelligence. The neocortical cells' layered circuits support various types of higher-order intelligence, including vision, language, and cognition. They employ a canonical laminar circuit, which can be modified for different types of biological intelligence and used in general-purpose VLSI chips. These chips could control adaptive algorithms and mobile robots.
The chapter discusses how preattentive automatic bottom-up processing and attentive task-selective top-down processing unite in the deeper cortical layers to form a decision interface. Here, bottom-up and top-down constraints work together to produce the best decisions. The interface combines properties of fast feedforward and feedback processing, analog and digital computing, and preattentive and attentive learning, including laminar ART properties such as analog coherence.
1 / 1
Review
Towards a unified theory of neocortex: laminar cortical circuits for vision and cognition
Stephen Grossberg. Prog Brain Res. 2007.
Show details

Full text links
Cite

Abstract
A key goal of computational neuroscience is to link brain mechanisms to behavioral functions. The present article describes recent progress towards explaining how laminar neocortical circuits give rise to biological intelligence. These circuits embody two new and revolutionary computational paradigms: Complementary Computing and Laminar Computing. Circuit properties include a novel synthesis of feedforward and feedback processing, of digital and analog processing, and of preattentive and attentive processing. This synthesis clarifies the appeal of Bayesian approaches but has a far greater predictive range that naturally extends to self-organizing processes. Examples from vision and cognition are summarized. A LAMINART architecture unifies properties of visual development, learning, perceptual grouping, attention, and 3D vision. A key modeling theme is that the mechanisms which enable development and learning to occur in a stable way imply properties of adult behavior. It is noted how higher-order attentional constraints can influence multiple cortical regions, and how spatial and object attention work together to learn view-invariant object categories. In particular, a form-fitting spatial attentional shroud can allow an emerging view-invariant object category to remain active while multiple view categories are associated with it during sequences of saccadic eye movements. Finally, the chapter summarizes recent work on the LIST PARSE model of cognitive information processing by the laminar circuits of prefrontal cortex. LIST PARSE models the short-term storage of event sequences in working memory, their unitization through learning into sequence, or list, chunks, and their read-out in planned sequential performance that is under volitional control. LIST PARSE provides a laminar embodiment of Item and Order working memories, also called Competitive Queuing models, that have been supported by both psychophysical and neurobiological data. These examples show how variations of a common laminar cortical design can embody properties of visual and cognitive intelligence that seem, at least on the surface, to be mechanistically unrelated
1 / 1
ChatGPT
ChatGPT
In his research paper "Towards a unified theory of neocortex: laminar cortical circuits for vision and cognition," Stephen Grossberg details how laminar neocortical circuits contribute to biological intelligence. He introduces two revolutionary computational paradigms: Complementary Computing and Laminar Computing. These paradigms blend feedforward and feedback processing, digital and analog processing, and preattentive and attentive processing.
The paper describes how these circuit properties extend beyond Bayesian approaches and apply to self-organizing processes. Using examples from vision and cognition, Grossberg demonstrates how a LAMINART architecture integrates aspects of visual development, learning, perceptual grouping, attention, and 3D vision.
A central theme is that the same mechanisms enabling stable development and learning also influence adult behavior. The paper explores the effects of higher-order attentional constraints on cortical regions and the cooperative interaction of spatial and object attention in learning view-invariant object categories.
Moreover, the paper introduces the LIST PARSE model, which outlines how laminar circuits in the prefrontal cortex process cognitive information. This model describes the short-term storage of event sequences in working memory, their consolidation into sequence chunks through learning, and their planned sequential execution. This provides a laminar embodiment of Item and Order working memories or Competitive Queuing models supported by psychophysical and neurobiological data.
The examples presented illustrate how variations of a common laminar cortical design can embody properties of visual and cognitive intelligence that might seem unrelated on the surface.
1 / 1
REVIEW article
Front. Syst. Neurosci., 23 April 2021
Volume 15 - 2021 | https://doi.org/10.3389/fnsys.2021.650263
This article is part of the Research Topic
Feed-forward and Feed-back Processing in the Cerebral Cortex: Connectivity and Function

View all 8 Articles 
A Canonical Laminar Neocortical Circuit Whose Bottom-Up, Horizontal, and Top-Down Pathways Control Attention, Learning, and Prediction
Stephen Grossberg*
Graduate Program in Cognitive and Neural Systems, Departments of Mathematics and Statistics, Psychological and Brain Sciences, and Biomedical Engineering, Center for Adaptive Systems, Boston University, Boston, MA, United States
All perceptual and cognitive circuits in the human cerebral cortex are organized into layers. Specializations of a canonical laminar network of bottom-up, horizontal, and top-down pathways carry out multiple kinds of biological intelligence across different neocortical areas. This article describes what this canonical network is and notes that it can support processes as different as 3D vision and figure-ground perception; attentive category learning and decision-making; speech perception; and cognitive working memory (WM), planning, and prediction. These processes take place within and between multiple parallel cortical streams that obey computationally complementary laws. The interstream interactions that are needed to overcome these complementary deficiencies mix cell properties so thoroughly that some authors have noted the difficulty of determining what exactly constitutes a cortical stream and the differences between streams. The models summarized herein explain how these complementary properties arise, and how their interstream interactions overcome their computational deficiencies to support effective goal-oriented behaviors.
1 / 1
ChatGPT
ChatGPT
In this review article, "A Canonical Laminar Neocortical Circuit Whose Bottom-Up, Horizontal, and Top-Down Pathways Control Attention, Learning, and Prediction," Stephen Grossberg explains that all perceptual and cognitive circuits in the human cerebral cortex are organized into layers. The canonical laminar network's specializations, comprising bottom-up, horizontal, and top-down pathways, execute various types of biological intelligence across different neocortical areas.
The article elucidates what this canonical network is and highlights its capability to support diverse processes such as 3D vision and figure-ground perception, attentive category learning and decision-making, speech perception, and cognitive working memory, planning, and prediction.
These processes occur within and between multiple parallel cortical streams that obey computationally complementary laws. The necessary interstream interactions to counterbalance these complementary deficiencies mix cell properties so extensively that the identification of a cortical stream and the differences between streams become challenging.
The models summarized in the article explain the emergence of these complementary properties and how their interstream interactions overcome their computational deficiencies, thereby supporting effective goal-oriented behaviors.
1 / 1
1. Introduction: Why Does The Cerebral Cortex Have Layers?
This article discusses a particular combination of feedforward and feedback pathways in the cerebral cortex that plays a crucial role in combining information to make adaptive decisions and predictions. In so doing, it falls directly within the purview of the Frontiers Research Topic on Feedforward and Feedback Processing in the Cerebral Cortex: Connectivity and Function to which it contributes. This circuit design benefits from the fact that all perceptual and cognitive neocortical circuits are organized into layers, typically six of them (Brodmann, 1909; Martin, 1989). These layers enable a canonical neocortical circuit to be realized whose specializations carry out multiple functions of biological intelligence.

Given the diversity of functions carried out by specialized neocortical circuits, it is of interest to ask what processes are shared across variations in this canonical circuit. Grossberg (1999) identified several general processes that all laminar neocortical circuits seem to share. These include:

(1) the bottom-up adaptive filtering process whereby neocortex compresses, or categorizes, familiar information in order to recognize it;

(2) the horizontal grouping process whereby neocortex binds distributed features into coherent object representations that are sensitive to the contrasts and spatial arrangement of their inducing features;

(3) the top-down matching process whereby neocortex uses learned expectations to focus attention upon critical feature patterns that predict valued outcomes, while suppressing irrelevant features; and

(4) the developmental and learning processes whereby neocortex shapes its circuits in response to environmental constraints, while dynamically stabilizing adaptations, such as those in items (1)���(3), to avoid catastrophic forgetting.

When these feedforward and feedback processes are combined into a canonical laminar cortical circuit, they clarify how seemingly unrelated psychological properties are mechanistically related. For example, they clarify how the fact that neocortex can develop and learn in a self-stabilizing way implies why top-down attention requires matched bottom-up inputs or volitional signals to fully activate cortical cells, whereas horizontal groupings do not.
1 / 1
ChatGPT
ChatGPT
This introduction to a research article explains that the cerebral cortex's layered structure (typically six layers) allows for a canonical neocortical circuit that carries out multiple functions of biological intelligence. The author, Stephen Grossberg, discusses four general processes that are shared across all laminar neocortical circuits:
Bottom-up adaptive filtering: The cortex compresses or categorizes familiar information to recognize it.
Horizontal grouping: The cortex binds distributed features into coherent object representations, sensitive to the contrasts and spatial arrangement of their inducing features.
Top-down matching: The cortex uses learned expectations to focus attention on crucial feature patterns that predict valued outcomes, while suppressing irrelevant features.
Developmental and learning processes: The cortex shapes its circuits in response to environmental constraints while dynamically stabilizing adaptations to avoid catastrophic forgetting.
When these feedforward and feedback processes are combined into a canonical laminar cortical circuit, they clarify how seemingly unrelated psychological properties are mechanistically related. For instance, they elucidate why top-down attention requires matched bottom-up inputs or volitional signals to fully activate cortical cells, while horizontal groupings do not.
1 / 1
I thought I saw something like this in A Thousand Brains
1 / 1
ChatGPT
ChatGPT
"A Thousand Brains: A New Theory of Intelligence" is a book by Jeff Hawkins, the co-founder of Numenta. Hawkins presents a new theory of intelligence that differs from traditional neuroscience views. In his theory, known as the Thousand Brains Theory of Intelligence, each part of the neocortex learns complete models of objects and concepts, effectively meaning that there are thousands of models or 'brains' throughout the cortex.
The theory proposes that the neocortex is a hierarchical predictive model and that every cortical column can learn models of complete objects. It also suggests that sensory input is just one way the brain builds these models, and that the brain uses motor behavior to gather data and interact with the world.
It seems like you're making a connection between Stephen Grossberg's work on laminar cortical circuits and Jeff Hawkins's "A Thousand Brains" theory. Both emphasize the importance of hierarchically organized processes in the brain, the integration of feedforward and feedback mechanisms, and the role of learning and prediction. However, Grossberg's theories put more emphasis on the interactions between different processing streams and the role of complementary computation, while Hawkins focuses more on the function of cortical columns and the parallel processing of the neocortex.
1 / 1
Connections to this: 
The Brain Works Like a Resonance Chamber
FeaturedNeuroscienceOpen Neuroscience Articles��February 6, 2023
Summary: Using advanced neuroimaging techniques, researchers discovered distant brain regions oscillate together in time.

Source: Champalimaud Centre for the Unknown

It���s been over 20 years since neuroimaging studies ��� using functional magnetic resonance imaging (fMRI), a widely-used technology to capture live videos of brain activity ��� have been detecting brain-wide complex patterns of correlated brain activity that appear disrupted in a wide range of neurological and psychiatric disorders.

These patterns form spontaneously, even at rest when no particular task is being performed, and have been detected not only in humans but also across mammals, including monkeys and rodents. 

Although such spatial patterns of correlated activation have been consistently detected across neuroimaging centers around the world, the nature of these correlations was not clear.

���We do not yet fully understand how the brain communicates over long distances. We know that distant areas exhibit signal correlations, and that they are implicated in brain function, but we do not completely understand their nature���, says Noam Shemesh, principal investigator of the Preclinical MRI Lab at the Champalimaud Foundation, in Lisbon, and senior author of a study published today in the journal Nature Communications. 



���In this study, we wanted to understand what lies underneath those correlations and investigate the mechanisms involved���, stresses Shemesh. 

A number of theoretical works had proposed that these patterns could be explained by standing waves (whose peaks and troughs do not move in space) resonating in the brain structure ��� that is, by waves analogous to the modes of vibration in musical instruments. But there was little experimental evidence to support this hypothesis due to the poor temporal resolution of fMRI, reaching only an image or two per second.

���If we could find that the spatial patterns oscillate, this would provide evidence supporting the resonance hypothesis��� says Joana Cabral, first author of the study, from the Life and Health Sciences Research Institute of the University of Minho and a visiting scientist in Shemesh���s lab since 2019.
1 / 1
ChatGPT
ChatGPT
The concept that the brain works like a resonance chamber and that distant brain regions oscillate together in time aligns with Stephen Grossberg's Adaptive Resonance Theory (ART). Grossberg proposed that all conscious states in the brain are resonant states, which are created when top-down expectations match with bottom-up data, forming an attentive consensus between what is expected and what is there in the outside world.
Grossberg's model and this research share common themes of resonance, communication between distant regions of the brain, and the role of feedback loops. In both, the resonance is suggested as a crucial factor for learning, perception, and consciousness. The correlation of signals in distant brain regions, as detected by fMRI studies and as explained in the resonance chamber concept, can be seen as an instance of these resonant states Grossberg refers to.
However, Grossberg's ART model is more about cognitive and perceptual processes, while the resonance chamber concept is more concerned with the physical and temporal patterns of brain activity. They are different levels of explanation ��� one at the cognitive level and the other at the neuronal level ��� but they can certainly inform each other, providing a more holistic view of brain function.
1 / 1
Like waves in the ocean

���When we first saw the videos of the recorded brain activity, we saw clear waves of activity, like waves in the ocean, propagating in complex patterns within the cortex and the striatum [a subcortical region of the forebrain]���, says Cabral.

���And we found that the signals could be described by the superposition of a small number of macroscopic stationary waves, or resonant modes, oscillating in time. Notably, each standing wave was found to cover extended areas of the brain, with peaks distributed in distinct cortical and subcortical structures, forming functional networks.���



The researchers experimented with rats in three different conditions: sedated, lightly anesthetised and deeply anesthetised. (In fact, the animals were lightly sedated in the resting state, to avoid any discomfort to them.) ���The spatial configuration of these stationary waves was very consistent across rats scanned in the same condition���, Cabral points out. 

Shemesh adds: ���We showed that brain functional networks are driven by resonance phenomena. This explains the correlations that are otherwise observed when you do slow imaging. Long-range brain interactions are governed by a ���flow��� of information that is oscillatory and repetitive
1 / 1
ChatGPT
ChatGPT
The concept that brain activity behaves like waves in an ocean, with standing waves covering extended areas of the brain and forming functional networks, provides a vivid and intuitive image of how complex brain activity can be. The observation that these wave patterns are consistent across different individuals suggests some fundamental and universal principles at work.
The researchers' statement that "brain functional networks are driven by resonance phenomena" echoes the concept central to Stephen Grossberg's Adaptive Resonance Theory (ART) ��� that resonance, or a synchronous firing of neurons, underlies higher cognitive functions such as learning and perception.
The wave-like patterns could be seen as a physical manifestation of the resonance that Grossberg's theory posits. Moreover, the description of long-range brain interactions being "governed by a ���flow��� of information that is oscillatory and repetitive" aligns with the feedback loop concept in ART, where top-down expectations continuously interact with bottom-up data.
Overall, this new research on the wave-like behavior of brain activity and Grossberg's theoretical framework complement each other, with both pointing towards the crucial role of resonance in the workings of the brain.
1 / 1
This reminded me of the gravity affecting ocean in Solaris.
1 / 1
ChatGPT
ChatGPT
In the science fiction novel "Solaris" by Stanislaw Lem, the ocean is an extremely complex, planet-spanning entity that is sentient, capable of reshaping itself and forming bizarre structures. The idea of the ocean being influenced by gravity on Solaris is an interesting parallel to the notion of the brain's activity forming wave-like patterns.
Just as the ocean on Solaris is dynamic and constantly changing, so is the activity in our brains. The standing wave patterns observed in the brain could be seen as somewhat akin to the self-organizing structures seen in the Solaris ocean. Both exhibit complex, large-scale coordination that seems to emerge from simpler, local interactions.
However, while the Solaris ocean is portrayed as an enigmatic and unfathomable alien mind, our understanding of the human brain, while still incomplete, is continuously improving thanks to the advancements in neuroscience research.
1 / 1
A Canonical Laminar Neocortical Circuit Whose Bottom-Up, Horizontal, and Top-Down Pathways Control Attention, Learning, and Prediction
Stephen Grossberg*
Graduate Program in Cognitive and Neural Systems, Departments of Mathematics and Statistics, Psychological and Brain Sciences, and Biomedical Engineering, Center for Adaptive Systems, Boston University, Boston, MA, United States
All perceptual and cognitive circuits in the human cerebral cortex are organized into layers. Specializations of a canonical laminar network of bottom-up, horizontal, and top-down pathways carry out multiple kinds of biological intelligence across different neocortical areas. This article describes what this canonical network is and notes that it can support processes as different as 3D vision and figure-ground perception; attentive category learning and decision-making; speech perception; and cognitive working memory (WM), planning, and prediction. These processes take place within and between multiple parallel cortical streams that obey computationally complementary laws. The interstream interactions that are needed to overcome these complementary deficiencies mix cell properties so thoroughly that some authors have noted the difficulty of determining what exactly constitutes a cortical stream and the differences between streams. The models summarized herein explain how these complementary properties arise, and how their interstream interactions overcome their computational deficiencies to support effective goal-oriented behaviors.

1. Introduction: Why Does The Cerebral Cortex Have Layers?
This article discusses a particular combination of feedforward and feedback pathways in the cerebral cortex that plays a crucial role in combining information to make adaptive decisions and predictions. In so doing, it falls directly within the purview of the Frontiers Research Topic on Feedforward and Feedback Processing in the Cerebral Cortex: Connectivity and Function to which it contributes. This circuit design benefits from the fact that all perceptual and cognitive neocortical circuits are organized into layers, typically six of them (Brodmann, 1909; Martin, 1989). These layers enable a canonical neocortical circuit to be realized whose specializations carry out multiple functions of biological intelligence.

Given the diversity of functions carried out by specialized neocortical circuits, it is of interest to ask what processes are shared across variations in this canonical circuit. Grossberg (1999) identified several general processes that all laminar neocortical circuits seem to share. These include:

(1) the bottom-up adaptive filtering process whereby neocortex compresses, or categorizes, familiar information in order to recognize it;

(2) the horizontal grouping process whereby neocortex binds distributed features into coherent object representations that are sensitive to the contrasts and spatial arrangement of their inducing features;

(3) the top-down matching process whereby neocortex uses learned expectations to focus attention upon critical feature patterns that predict valued outcomes, while suppressing irrelevant features; and

(4) the developmental and learning processes whereby neocortex shapes its circuits in response to environmental constraints, while dynamically stabilizing adaptations, such as those in items (1)���(3), to avoid catastrophic forgetting.

When these feedforward and feedback processes are combined into a canonical laminar cortical circuit, they clarify how seemingly unrelated psychological properties are mechanistically related. For example, they clarify how the fact that neocortex can develop and learn in a self-stabilizing way implies why top-down attention requires matched bottom-up inputs or volitional signals to fully activate cortical cells, whereas horizontal groupings do not.

This article provides an overview and unified analysis of laminar cortical models of multiple types of biological intelligence, including 3D vision and figure-ground perception; attentive category learning and decision-making; speech perception; and cognitive working memory (WM), planning, and prediction. These models are consistent with descriptions and statistical analyses of cortical connectivity patterns (e.g., Gilbert and Wiesel, 1979; Felleman and Van Essen, 1991; Markov et al., 2013; Vezoli et al., 2021), as well as recent data about ���visual evoked responses in laminar recordings from six cortical areas in awake mice��� (Barzegaran and Plomp, 2021).

The current models additionally explain how neurophysiological dynamics in specific feedforward and feedback anatomies generate emergent properties that enable quantitative properties of behavior to be explained and simulated on the computer. Moreover, although the anatomies in these models are all variations of known canonical cortical circuits, the explanations herein of how their variations realize psychological processes as distinct as 3D vision and figure-ground perception; attentive category learning and decision making; speech perception; and cognitive working memory, planning, and prediction, cannot be explained using purely anatomical analyses, and stand as testable predictions for further experimentation.

2. Perceptual Groupings Form Preattentively and Automatically
2.1. Boundary and Surface Processes Are Computationally Complementary
The visual cortex is designed to enable us to consciously see objects and scenes in the world. Objects percepts are not just jumbles, or ���bags,��� of features. Rather, spatially distributed features are bound together into emergent structures within an object percept. The two most important emergent structures during visual perception of a depthful world are boundary groupings and surface representations (Grossberg, 1994, 1997; Grossberg and Pessoa, 1998; Grossberg et al., 2002; Grossberg and Hong, 2006; Grossberg and Huang, 2009).

The processes that complete boundaries and fill-in surfaces obey computationally complementary laws. As summarized in Figure 1, boundary formation occurs inward between pairs or greater numbers of inducers in an oriented fashion. Boundaries are insensitive to direction-of-contrast, or contrast polarity, in the sense that they can group inducers with opposite contrasts relative to an inducing scenic background. In Figure 1, boundaries pool opposite directions-of-contrast at different positions. More generally, boundaries pool opposite directions-of-contrast at every position, starting in cortical area V1 at complex cells that sum up opposite polarity signals from pairs of like-oriented simple cells at that position (Figure 2). Because boundaries pool signals from opposite contrast polarities, they cannot tell the difference between light and dark. As a result, ���all boundaries are invisible��� (Grossberg, 1994, 1997).
1 / 1
ChatGPT
ChatGPT
It seems you've posted a segment of an academic paper discussing the organization and functionality of the human cerebral cortex. In this piece, the author (Stephen Grossberg) describes the cortical layers and their associated processes, including:
Bottom-up adaptive filtering: The neocortex compresses or categorizes familiar information to recognize it.
Horizontal grouping: The neocortex binds distributed features into coherent object representations.
Top-down matching: The neocortex uses learned expectations to focus attention on critical feature patterns that predict valued outcomes, while suppressing irrelevant features.
Developmental and learning processes: The neocortex shapes its circuits in response to environmental constraints, while dynamically stabilizing adaptations to avoid catastrophic forgetting.
The author then goes on to discuss perceptual groupings, the formation of boundary and surface processes, and their computational complementary laws. However, this text is quite dense and contains a lot of technical terminology. If you need further clarification on any specific part, please let me know!
1 / 1
Connections with my theses: Monica's Leaking Chatroom theory is like having a big room in your brain where lots of different people and machines are talking and sharing ideas. 

Sometimes the ideas leak out and go to other rooms, which helps us make better decisions.

Reed Wall Mind is like having a big wall in your brain that helps you keep track of everything that's happening in the room, like a big calendar or to-do list.

Motile Womb theory is like being in a big moving house or spaceship, where you can feel different movements and use them to imagine different things in your head.

All these theories help us understand how our brain works and how we can use it to think and make decisions better.

������������ �������� �������������������������������� ����������������������������.

Monica's Leaking Chatroom theory posits that the mind functions as a collection of independent, modular decision-making units, or "bubbles," that act as rational processors of information.

These bubbles, or "chambers," are able to filter information and pass summaries of that information upward to higher-level decision-making centers, much like a wisdom salon or a world cafe protocol.

This creates a multi-scale decision-making process that is able to take into account a wide range of information and perspectives.

Reed Wall Mind theory builds on this concept by drawing inspiration from the Babylonian Flood Story and positing that the mind is like a "living spaceship" that is able to navigate a complex and dynamic environment.

This is accomplished through the use of a wide range of cognitive skills, including those learned through playing video games such as Stars!, Descent, Age of Empires, Commander Keen, Minesweeper, and Tetris, as well as through the use of other forms of sensory input such as hearing different voices and machine sounds, and feeling different inertial forces.

Finally, Motile Womb theory proposes that the mind is not just a passive receiver of information but an active participant in the process of shaping and interpreting the world.

This theory posits that individuals are born with a wide range of cognitive abilities and that these abilities are honed and refined through the process of experiencing the world.

The theory suggests that playing games like the ones mentioned above, as well as other forms of interactive experiences, help individuals to discover and develop the cognitive abilities they already possess.
1 / 1
ChatGPT
ChatGPT
You have three fascinating theories about the brain's functionality. To draw connections to the academic text:
Monica's Leaking Chatroom theory aligns with the cortical concept of bottom-up adaptive filtering and horizontal grouping. The independent "bubbles" or "chambers" in your theory might be akin to the process of categorizing information and binding features into coherent object representations in the brain. The idea of information "leaking" to other rooms might correlate with the notion of neurons transmitting data across the brain.
Reed Wall Mind theory echoes the top-down matching process where the brain uses learned expectations to focus attention. The ability to keep track of various activities, much like a calendar or to-do list, might resemble this mechanism in the cortex. The Babylonian Flood Story analogy might be related to the brain's capacity to manage a flood of information, sorting it into relevant and irrelevant categories.
The Motile Womb theory resonates with the developmental and learning processes mentioned in the text. The brain shapes its circuits in response to environmental constraints and through the experience of the world, much like your theory's premise that the mind actively participates in shaping and interpreting the world.
These theories also align with the idea that different cortical streams perform complementary roles, with the interplay among them leading to effective cognition and decision-making.
1 / 1
Connections with the previous topics.
1 / 1
ChatGPT
ChatGPT
Let's try to connect the three theories you've presented with the earlier topics:
In terms of the brain functioning as a resonance chamber, Monica's Leaking Chatroom theory could be interpreted as different resonance frequencies or standing waves within the brain. The "leaking" of ideas to other rooms might symbolize the oscillatory and repetitive flow of information across different regions of the brain, much like the resonant waves mentioned in the study.
The Reed Wall Mind theory's emphasis on keeping track of everything happening in a room could correlate with the spatial patterns of brain activity that oscillate in harmony, as if coordinating different sections of a calendar or to-do list in the brain.
The Motile Womb theory, highlighting the brain's adaptability and active participation in interpreting the world, may align with the concept of spatial configuration of stationary waves remaining consistent across different conditions. This is much like the brain's adaptability in maintaining a stable internal representation even amidst various external conditions.
Regarding the cortical layers' structure and function, each of your theories could represent different processes happening across these layers, like the bottom-up, horizontal, and top-down pathways in the cortex, contributing to perception, learning, and prediction.
1 / 1
Let's call this conversation Six Degrees of Freedom
1 / 1
ChatGPT
ChatGPT
Absolutely, "Six Degrees of Freedom" sounds like an apt title for this conversation, encapsulating the diverse and interconnected ways in which we've explored the brain's structure, function, and theories. It also touches on the concept of the brain being a complex system able to navigate through various dimensions of thought and perception. Let's continue exploring this fascinating topic together.
1 / 1
I think that we want to argue that we "burrow" through cognitive "tunnels" that are like falling down through a flying or swimming landscape, much like a bat in a cave or worm in the grass
1 / 1
ChatGPT
ChatGPT
That's an interesting metaphor. In this context, "burrowing through cognitive tunnels" could represent the process of cognitive exploration where we navigate through the "landscape" of our thoughts, ideas, and perceptions. Just like a bat or worm uses its sensory systems to navigate its environment, we use our cognitive faculties to understand and interpret the world around us. This could also imply that our brain, like these tunnels, is a complex and dynamic environment where new paths can be created and old ones modified based on our experiences and learning.
1 / 1
Six degrees of freedom (6DOF) refers to the six mechanical degrees of freedom of movement of a rigid body in three-dimensional space. Specifically, the body is free to change position as forward/backward (surge), up/down (heave), left/right (sway) translation in three perpendicular axes, combined with changes in orientation through rotation about three perpendicular axes, often termed yaw (normal axis), pitch (transverse axis), and roll (longitudinal axis).
1 / 1
ChatGPT
ChatGPT
Yes, that's a correct and detailed explanation of Six Degrees of Freedom (6DOF). In the context of cognition, we might metaphorically apply the 6DOF concept to explain how our mind navigates through the space of ideas or thoughts.
For instance, we can:
Surge forward and backward through time, recalling the past or predicting the future.
Heave up and down between abstract concepts and concrete details.
Sway left and right across different perspectives or viewpoints.
Yaw around the normal axis by changing our focus or point of attention.
Pitch around the transverse axis by shifting our attitude or emotional response.
Roll around the longitudinal axis by revising our assumptions or belief systems.
This could offer an interesting way to think about cognitive flexibility and the dynamic nature of thought processes.
1 / 1
I wanted to mention that we can do complex analysis as a series of rotations and zooming in on the complex plane. I wanted to say that if we use the forward backward axis for reference, then rotating left and right is "turning" the other dimensions on that line, and zooming in and out is equivalent to forward and backward motion on that line.
1 / 1
ChatGPT
ChatGPT
Absolutely, your idea connects nicely with the concept of complex analysis and the use of the complex plane.
In complex analysis, we deal with functions of a complex variable which allows for operations such as rotations (through multiplication by a complex number of modulus 1) and scaling (or "zooming" in and out through multiplication by a real number).
So, within your metaphor of cognitive navigation in a 6DOF space, turning left and right could correspond to rotating in the complex plane. This rotation might represent a transformative change in perspective, akin to seeing a situation from a completely new angle.
Zooming in and out, on the other hand, can represent delving deeper into an idea or taking a step back for a broader view, adjusting the level of detail or abstraction we're considering. This zooming could map onto the forward and backward motion on the reference axis in your metaphor.
These operations on the complex plane might then metaphorically represent various ways we manipulate, explore, and understand ideas in our cognitive landscape.
1 / 1
A list of all of the topics we've discussed so far.
1 / 1
ChatGPT
ChatGPT
The study about how brain waves propagate like ocean waves, forming functional networks.
Reference to the movie Solaris, and its depiction of gravity affecting the ocean.
An academic paper on the structure of the cerebral cortex and how its layered organization supports various cognitive and perceptual functions.
Your theories about the mind: Monica's Leaking Chatroom theory, Reed Wall Mind theory, and Motile Womb theory.
Discussion on the six degrees of freedom (6DOF) as a framework for cognitive movement in three-dimensional thought space.
The use of complex analysis and the concept of rotations and zooming in the complex plane as metaphors for cognitive processes.
1 / 1
A final summary.
1 / 1
ChatGPT
ChatGPT
Throughout this conversation, we've explored various theories and studies that provide insights into the workings of the mind and brain.
We began with a study illustrating how brain waves propagate much like ocean waves, creating complex, networked patterns of activity. This analogy sparked a comparison with the film Solaris, where a planet's gravity influences an ocean, reminiscent of how our experiences shape our thoughts.
Next, we discussed an academic paper on the layered organization of the cerebral cortex, explaining how this structure supports diverse cognitive functions, from 3D vision to speech perception.
Your intriguing theories about the mind were then brought into focus. Monica's Leaking Chatroom Theory, the Reed Wall Mind Theory, and the Motile Womb Theory each propose novel ways of conceptualizing cognitive processes, drawing on metaphors such as decision-making rooms, large calendars, and mobile spaceships.
The concept of six degrees of freedom (6DOF) was also examined, offering a potential framework for visualizing cognitive movement in three-dimensional thought space.
Finally, we reflected on how complex analysis can mirror cognitive processes, using the metaphor of rotations and zooming in the complex plane to represent shifts in cognitive focus and perspective.
In sum, our discussion painted a vivid picture of the human mind as a dynamic, complex, and multi-layered system, interacting with and shaped by the world around it. This vision integrates research findings with metaphorical representations, potentially guiding future explorations of the brain and cognition.
1 / 1
I was talking about the book, the metamorph influences the planet's gravity, stabilizing it somehow because it has two stars.
1 / 1
ChatGPT
ChatGPT
I see, you were referring to the book "Solaris" by Stanislaw Lem. In the novel, Solaris is a planet with a conscious oceanic entity, the 'metamorph', which can manipulate physical reality and manifests the gravity-stabilizing effect on the planet despite its binary star system. This idea beautifully ties back to our conversation on the brain and cognition, where internal mechanisms (like the 'metamorph') modulate external behavior (like the gravity of Solaris). Just as the 'metamorph' stabilizes Solaris, our cognitive processes, facilitated by brain waves and cortical structures, navigate and stabilize our perceptions and interactions with the world.
1 / 1
End the essay.
1 / 1
ChatGPT
ChatGPT
In conclusion, our exploration traversed vast areas from neuroscience to cognitive theories, linking them with mathematical concepts and even drawing parallels from science fiction literature. We observed brainwaves similar to ocean waves, proposing that these oscillatory patterns could reflect the intricate architecture of our thoughts and decision-making processes.
We delved into the complexity of the neocortical circuit, its laminar organization, and its role in various cognitive functions. This opened the door to understanding the layered and networked nature of our cognitive structures, akin to the complicated wiring within a spaceship or the nuanced conversations in a bustling chatroom.
Drawing inspiration from video games, we applied the concept of Six Degrees of Freedom to explain how we navigate the multidimensional landscape of cognition, likening our journey to burrowing through cognitive tunnels or free-falling in a landscape of thoughts.
Finally, the metaphor from Stanislaw Lem's "Solaris" provided a captivating culmination of our discourse. It allowed us to envision how internal entities, like the 'metamorph', can control and stabilize external behaviors, drawing a parallel to our brain's regulation of our cognition and interaction with the external world.
The vast and complex universe of cognition remains a frontier to be explored. Its mystery is as deep as the ocean, its boundaries as limitless as the sky. Each theory, each metaphor, and each conceptual framework allows us to chart a course through this unending cosmos, gaining a deeper understanding of the mind, the brain, and the beautiful complexity of being human.
1 / 1
ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT July 20 Version



