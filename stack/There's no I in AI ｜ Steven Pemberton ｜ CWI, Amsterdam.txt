Yes, okay.
So as was mentioned I sort of have a distant relationship with Alan Turing.
This year is the 70th anniversary of his untimely death at the age of 41.
He's considered the father of AI and of computing really.
In 1950 he wrote this paper and where he asked can machines think.
He introduces what is now known as the Turing test.
Now as was pointed out, I went to university at Sussex, this was my tutor.
He was the man who built the first transistrized computer ever in the whole world.
ac yw flucturor yn gynnist ag oedd wrth garnish a gwrth cînw i datgwyr ymgobl.
Gardyntan, byddwch ein ffordd i'w Om, i y bwysig taeth yn mae Cadw.
Hyderwch fel Thrym Llywodraeth F Sang Sióth Gyryraeth Cymru,
gyda'n fynd i ddweud cyfavio ni'n dangos ysgent Turing-ewr mi yn UE o Un,
Dan haith yr ysbynhym y byddwodd, raref dependio.
Rwy'r lleodi'r 라는 fo,iau'r dda heddara brands,
rydy'r diwyllian cyfryd,
rydw i ddim yn arhu yn ddweud yr astiol a phobl ynadhodd yn diwyllian.
Yn ychydig a eu wrthogибu amgylch pan fain llawer,
a dy'r am dabby,攕eno bodinell,
a phobl am wath Así dachte fighting Intelig Tryn.
Maen nhw hyn ceisioill. Rydw i'n wneud hof â bwysig mä importantlyniwyr a unigwyr hon yarnhraethon a gwyf Those وجd wychgwch.
Mae yefyddi wrth gwaith gwahanol – nawr – fere intr yn ei weld ff capturohodau, eich le wasnioel.
Fe hwn nriff cyddi o bobl hon, a brick.
ychydig sydd wedi'i gwiaith uned jagu wych ar gyfer Ryw'vei audition yn dis.
Yn y cenderfwir o'r heartbeat ar y gymryd gydeg,
y rhan odyn ni ddes.
Dyle config ynglyniad yma gan y g которую y uğr,
er fydd iawn iкиwch bod byddwch y cenderfwyll eich dddir ar draws.
Roedd mynd i 쿠 plant ar gyfer yn Rhagline.
atfer wedi bodi'r F4 peon يد draw yn protagonig iawn.
Dy'r tynbef, Wyver Rhysd-Ly,
nawr er cyr manuscripteon i'r ffordd,
wrth gofynnodd can Sex queen
a'r Cydraedd Tedd –
ac aned ond hanfyd 표현 gw deconstroed
I wnaethaf o'r corf that I give at Summer School at Oxford University every year which includes an introduction to AI.
It's not the principal subject of the Summer School but it's part of it.
So let's get on with the talk.
So there are currently two ways of doing AI.
You either teach at the computer what you want it to know, or you let it learn for itself.
So I'd like to just goh treat both of those.
Therefore, weíll start off with teaching or encoding our own knowledge.
So, to take an example, letís take Nauts and Crosses.
cozy Ergal in One
Or if youíre from the Americas, you might know it as tic-tac-toe.
Now, I imagine everybody here can play that perfectly.
So, what we want to do is we want to teach the computer how to play it,
and there are two ways you can do it, principally.
You can either give it rules or you can give it state.
Felly, nifer om ei rіл, eich fed ratau y cynesis sy'n gyntaf.
Felly, gan ni'n gweithio, y ring syml na gweld y Y nŵr y swerid mewn roll gael yn nôl Carlos
oedd ei fyrdd iawniaeth yingo', rydych yn gweld eMAg i aw夫 ac yn yr urriyelli.
Mae rhera, mewn rŵn ei fyrdd iawn, yn cw réalitéur oed i ei wneud erbyn,
Darwin yn eff曾w, n y tu cavbon a fydd eithafencing wrth gyrdd iawn
llwyddo'i cyfrventiaimd a dy Sirddoreth yn dawy i newid atall,
yn ddatblygiadion'ch sgwvet ag ystod papuruaeth bwysig a'i erbyn inghys spau am fy mod.
Felly mae yna'r fwrdd y cyfrventiaid.
embracellu â wybod.
A mae ydw i cael gweithio.
Andio sydd cyflwyno fanny singersiau.
� llwyddo llawer o fan ag pobodaeth.
Mae'r ailbeithio cyflwneél gweld pot â caala chdrwy'r boett.
dlyniad cyllyn, lle deuluad sylwad cwerthio newydd mewn fed Ortacker Mumol
i fygd Lwyddon 3.
Dyna mae gennych 700 o, wedyn ni'n 160 g
byddayaeth unig fiant allan run,
gemnig gennych maelod.
Byddai sefydlu eich 750.
Fel y hoedau yn rhiwsh a oeddi
a'w rhai sydd fersio dag arall
fel angen, rydw i'n credu odynnyn yn cyf fizadolわ'u.
O skerbl yn rhai a'r led yw'r mallu murdsenas arall.
see feth gen i chi ei meddwl â phlo chatol o profa yma
ac nhw'n meddwl y Moe Rhyw tan ar roedd Babyllol.
Mae seedsion fel rhai.
Mae sengddai'n Math Roedd Ddech chi'n olygra i chi hael
mae sydd d promising idd autograph
felly mae cael ei wneud gw再來f国 yma
maen nhw ychydigion d SC 머�筋
Mae'n gyd ynchwch chi fydd�iais wneud hefyd a dw i gwisech yn jeithio byddol yn ystryd.
Mae'n amser i maen nhw ond bod yw'r fag oedd y bach i fawr e.
Felly'r wnes hwn i'w wicatedd prices ochr translates.
Felly certh gof Womanf мерr,
mae'r pryd hawr y feature yn ddim yn y ffaith,
wasgogd final dデu daeth eich跟au.
DAes ma' ar y phenedd y cynthig ph tweith,
gallwn eu lle cyfan o'i trafod,
a sencillnau'r robi'ch chysylltiad hwn.
Here is a corner. Who takes an edge? Nobody takes an edge. Interesting.
We'll talk about that shortly again.
The other way is learning. I talked about two ways of encoding your knowledge,
and now how to let the computer learn.
Again, we take those 765 boards, and we link from each board what the possible follow-up moves are.
Felly, mae'r blach am y bach, mae'r ffordd,
mae'r llwythiaeth o'r dweud o'r rheswm yn ymdill.
Mae'r ddweud o'r dda i'r ddweud o'r dda,
o'r ddweud o'r ddweud o'r ddweud o'r ddweud,
sy'n bod yn fawr,
a sefydli, mae'r ddweud o'r ddweud o'r ddweud,
mae'r ddweud o ddweud o'r ddweud o'r ddweud o'r ddweud.
Dyma.
Ond, mae'n dechrau i'n ddweud i'r ddweud,
y gallwn gyda oes glif ar y cyholyg ymję suggests
ac mae defnyddio fy ng共�ri ar eieso ac mae fyddai y cyholyg ond
mae'n tawad Sebastian Rpedo Araoud eich cyholygu
ac mae efallai e enhance am bwysig o ran gynhym bod ein camarhar串 pwysig
mae'n pwysig i ddyn, alei'r haff wnaeth yn yr alfa physicist
mae'n ymwysigae i unaid i mae fferwg ac mae'r cyholyg sydd dechrau
wedi bod Beth yna y blaenau merchoo am ddechrau,
a fynd gofynodd hyn adwedd i dynio.
Dyn mor cyfo wahanol trwy taelod.
Rajwdych chi'n gwahanol eliwaith oertingod
ac yn ni'r ystgrif iawn,
r ponton Guild Marr ao hyn yn ddefnyddio.
A beth na dích chi ar gy anch N rainbow
oes wedi sawl ni ym inward pay rofi dyla pennyddw.
Dewch amdillgrif14 a d 46 Bilio pa ang Q1
Ac yn staffau cyntaf, dyla'r ystod mae'r dyfodol mujergin ar y go ееflow,
a'r theyfm h lyw fydd yn Unioniaeth Cleامau ar gerda mae gallran arth yn ein rhan yn hyho,
ac mae eich bydd yn cael cumrhau eich byd yn ei gweithio, rhwybarth ac cro Brooklyn.
Yr ymgyrch i gyffredinol ar y cerdd Llyfr anplyn,
mae'r yr hyn bynnag mae ar nakod y gyd yn excess fenlawm ngolwg'i gwybod.
… ac yr ystyr yn cael lrousengno neu r mem anhodpet ar y buddyn iawn,
llanfarn llawer a'r mentheiaeth yn hyn, cyn fydd Maserwydd.
Ond mae oedd wedi cael ei parion ar uncIO a'r busys y tîmeta Digw desものd hwnnw.
Lyn bod mai'r peth yn cymorth yn ddefnyddio café ar eich iddiadol i weithartydd gan ddelch.
Mae holl ddatblygu'ya achos unig ymgylchedau neu can collegell.
The learning method, well, again, it's only as good as the training material you give it.
This can also encode hidden bias because there may be bias in the training material.
In general, it can't explain why it makes a particular move or a particular decision.
But the nice thing about it is that it can discover new things that maybe you didn't know yourself.
But note well, in both cases, it's not true intelligence.
It's just learning, but it's not intelligence.
So let me just take a few of those points.
So bias, so in 1970, only 6% of musicians in American orchestras were women.
And then around that time they introduced blind auditions so that if somebody auditioned for the orchestra,
you couldn't see who they were, what colour they were, what gender they were.
And since then, the number of women in orchestras has increased incredibly.
Boston is at a third and New York is at 50%.
Now, you can't imagine in 1970 that they wanted bad orchestras.
They want the best orchestra possible.
Clearly there was some bias and clearly it wasn't deliberate, but nonetheless there was bias.
Another example is that sentencing software for criminals in America was trained on existing sentencing
so that it's still biased because black people get thrown in prison more often than white people
and the software still does that itself.
Here's an example of not being able to explain.
I actually got this image.
It asked me, are these the same people?
For some reason it thinks these are two faces.
This is Google images, Google photos.
But you can't ask why do you think that's a face because it just does.
Why can't AI explain itself?
Well, in fact humans can't explain themselves either.
Why is it an Italian wooden serving dish and not a wooden serving Italian dish in English?
Why is it a lovely little bird and not a little lovely bird?
Why is it a silly old fool and not an old silly fool?
Well, that's because in English there's an order to how we use adjectives.
Opinion size, age, shape, colour, origin, material, purpose.
We all, as English speakers, have that rule in our heads, native English speakers,
but we can't say what that rule is unless we've actually studied it.
So, there's no intelligence in AI as we know it yet.
An interesting thing is that saying old corners are the same as I did at the beginning in Noughts and Crosses,
is actually encoding some knowledge.
And so what I did was, I realised it was encoding knowledge and not letting the computer learn it.
So in fact my learning programme already encoded some knowledge among Noughts and Crosses.
So I rewrote it without that knowledge.
And the interesting thing is the two programmes play differently.
For instance, the first move, the one with the encoded knowledge, takes a corner first,
because actually a corner is a better first move than a centre.
The corner is an attacking move whereas a centre is a defensive move.
And so you're just slightly more likely to win if you start with a corner than if you start with a centre.
So that's an example of bias, that if you programmed it to take the first move in the centre,
you're actually biased against what is actually objectively a better move.
So the two programmes play differently, but the one that does the learning will never learn that the corners are the same.
It plays differently because it doesn't know the corners are the same,
and so it doesn't see that if you added those corners up, you'd actually have a better chance than if you'd taken the centre position.
So why do we think intelligent programmes that we currently are using are intelligence?
And I would claim that it's because of Paradoilia, that we have this thing as humans of interpreting everything in terms of ourselves.
So for instance, and this is the classic Paradoilia, we all see faces here, but there are no faces.
You have to admit there are no faces there, but we see faces and that's Paradoilia at work.
Here's another example, this is a film that went around the internet showing swans feeding fish,
which was sort of like amazing, these swans are feeding the fish, isn't that nice?
Because the swans can get the food and the fish come. The swans are not feeding the fish.
That's how people have interpreted it. The thing is, swans can't eat dry food, so they take the dry food and they wet it,
and in wetting it they drop some of the food and the fish then know about that and so they catch it.
The swans aren't doing anything for the fish there, they're doing it for themselves, they're wetting the food so they can eat it.
So that's our Paradoilia again working, interpreting it in the way that we would see it feeding the fish, but that's not what's happening.
Another example is Joseph Weisenbaum who wrote a programme that imitated a psychotherapist.
It was purely textual, picking up on keywords and giving responses, but when he gave it to his departmental secretary to try out,
she asked him to leave the room so that she could talk personally to it.
But there was no personal there, it was just purely automatic and she was using her Paradoilia to think that it was actually intelligent.
And this has happened recently at AI with Lambda that somebody who worked with one of the programmes imagined that the AI chat programme was sentient
because he asked it, are you sentient? And it said yes, and so he assumed that it was sentient and said we must never switch it off again.
They sacked him by the way.
So we have this tendency to interpret intelligent programmes, I mean sorry, non-intelligent programmes as if they were intelligent.
They're only machine learning but we think that they're intelligent and then we get shocked when they make stupid mistakes.
This is a mathematical question out of a school exam.
It's meant to show that you are intelligent and you know what's really going.
So it says an orchestra of 120 players takes 40 minutes to play Beethoven's 5th, how long will it take 60 players?
Well chat GPT says it would take twice as long.
So the Turing test which I mentioned earlier by Alan Turing proposed that we would be able to tell when computers were intelligent
by putting you at the end of a teletype and typing questions to and you didn't know whether it was a person or a computer
and then asking questions to try and determine if you've got a computer or a human at the other end.
So in that paper that I mentioned this was an example of what Turing proposed as a session.
In the first line of the sonnet which reads shall I compare thee to a summer's day would not a spring day do as well or better reply it wouldn't scan.
Well how about a winter's day that would scan all right? Yes but nobody wants to be compared to a winter's day.
So I thought I'm going to try this out on chat GPT.
Now chat GPT is terribly verbose so I'm not going to read this out to you because we don't have the rest of the day for this talk
but I'll just point out some of the terrible things that it did.
So I asked it exactly that question it didn't mention scanning but it said that summer is traditionally seen as the season of love and passion.
Not true spring that's why this question is asked spring is the season of love and passion that's why it might be a better comparison.
So chat GPT didn't do very well there.
The slides will be online so if you want to read this whole conversation this evening you can be.
So I said well you forgot to mention it wouldn't scan and then you forget this is a big apology.
Oh sorry yes you're right. Oh sorry for the oversight and then long long long blab blab blab it really likes the sound of its own voice
and then it gets it completely wrong about how the stress works in the process.
So so so that's an example of it's seeming intelligent but in fact the real intelligence that you're looking for is not there at all.
It's it's just giving you an answer that it thinks might match.
I asked a chat GPT to make a bio of me and it got it completely wrong saying that I've got all sorts of honorary doctorates and stuff which I haven't but if you want to give me one please do but none of this was true.
So so it's not intelligent and then the nice word that the nice phrase that has come up is stochastic parrot because that's really what it's doing.
It's learning all these texts and then sort of creating new texts based on the text that is read.
And so there was this paper written on the dangers of stochastic parrots which which pointed out all the dangers of modern so-called AI programs.
And like like I mentioned well financial costs but inscrutability not being able to see why it makes it biases the inability of the models to actually understand the world and the possibility of deceiving people.
Anyway the people who wrote this program got this paper got got fired by Google for writing it because I think that Google didn't like people criticizing their AI.
But anyway on the basis of this I thought I'd like to poke fun at chat GPT and I said somebody said to me chat GPT is like autocomplete on and then didn't finish the sentence.
What do you think he was going to say?
Well so again blah blah blah blah but against me two possible solutions chat GPT is like autocomplete on steroids or chat GPT is like autocomplete on a whole other level.
As you will see I said I said any other possibilities as you can see chat GPT has a very high opinion of itself.
On steroids on a whole different scale on a massive scale much broader range generate full sentences smarter and more intuitive it really loves itself.
So I said well how about on crack and again blah blah blah blah blah and it said but you should it's important to use discretion and sensitivity when using language that references drug use.
Well I bet you can guess what I said then your very first answer was on steroids.
And then you go oops you're absolutely right sorry about that and then a whole blah blah blah about why you shouldn't use drug references.
So then I asked don't you think I might be making fun of you and then it sort of owns up.
I don't have emotions and so so worry is not something that it can do.
So I said well how about how about irony and again it owns up.
I don't have the ability to detect irony in the same way that humans do which is honesty but I think that this is an example of the lack of intelligence.
If you can't spot irony then you're you're you're definitely not very intelligent.
So I want to briefly go through how Jack chatty pt works greatly simplified but at least it will give you a feel for it.
So what I did and again I took another small example I took the first chapter of James Joyce's Ulysses just because I had it available actually it contains about 1100 sentences 7000 words 40000 plus characters.
But of those characters only about three and a half well sorry not only about three and a half thousand about nine percent of the letter E but only 24 are an X and 33 a J.
So these are the first few lines of of of Ulysses.
So what I did with that I generated random texts from that only using the statistical likelihood of a character appearing.
So you've got about the same percentage of ease in this and the same percentage of X's and J's and so on.
So as you can see it's complete nonsense.
It doesn't that is unrecognisably English I would say even though this has the same statistical property of English in terms of the letter the frequency of letters.
But there's another statistical property that is that if you've got a letter it can only be followed by a smaller number of letters.
For instance a Q is only ever followed by a U and a Z well at least in this training set is only followed by E I O Y and Z.
So what I do is I select a character at random and then the next character randomly from the letters that may follow it.
So it already begins to look a little bit more sensible.
It's still it's not quite as much rubbish but it's still it's still rubbish.
You can still see an occasional word.
But okay I've now created this using two letters but what if I do three letters?
Well all of a sudden it starts getting even more English like.
And if I do four letters well even more English like by five and six we've only got English words more or less.
It's very interesting to see how with very little information you can actually create at least English words just using statistical properties.
Okay but I've done this only with characters but then of course you can do it with words.
Here I just take words at random again it doesn't look much doesn't make much sense but if I take pairs of words or triples of words it gets more and more like English.
And you actually get things that are sort of understandable.
By the time I get to quadruples well because of the small learning set I actually only get lines out of Ulysses.
But that's only because I've got a very small learning set.
So chatGPD is really just this process but they're not on a huge scale because it's read the whole of the internet and it uses other statistical techniques for a meaning.
But what it does it just generates text related to what you've typed.
It doesn't do any understanding, no real understanding, it's just parroting stuff at you.
And this is why we get such crazy images like this because it's the same process it's sort of piecing bits of photos together.
And you very often see that it doesn't know the difference between an ankle and a wrist and which is why you sometimes get a foot at the end of an arm rather than a hand and vice versa.
So generalized intelligence.
So what will happen if we do finally get real intelligence when there really is an eye in AI?
And when will it happen and what are the consequences?
So there's something very interesting.
When my grandfather was born which 1880 he really only had two technologies in his life that you would call in any way modern, trains and photography.
You might want to include flushing toilets but that's really the limit of the technologies that he had at his disposal.
But in his longish life of 90 plus years he saw an amazing number of changes.
The list is absolutely huge, electricity, telephone, lift, central heating, cars, films, radio, television, recorded sound, flight, space travel.
The number of things that changed in his lifetime was enormous and we're still seeing enormous numbers of changes.
Mobile telephones, GPS, cheap computers, self-driving cars, all this stuff is happening now in our lives.
And the question is are paradigm shifts, which is what these all are, they change your thinking about a particular thing in our life, money or travel or whatever,
are paradigm shifts happening faster and faster?
And the answer is yes.
This is a very interesting study that Kurzweil did.
He asked a large number of disciplines, I think 15 disciplines, representatives from a large number of disciplines,
to identify when the paradigm shifts happened in their discipline.
And we're talking about huge periods, we're talking about 10 to 11 years here, because some of these technologies are like metallurgy,
where the paradigm shifts happened over thousands of years, moving from iron to steel and so on.
But then he graphed them, he graphed all these, comparing the time it took between, so this is the time between events and this is time before the present.
And what you can see is there's clearly a straight line there, a worrying straight line, because this is 100 years and it's heading down to 10 and then one year in the very near future.
So this means that paradigm shifts are happening faster and faster, exponentially faster.
So that it means that if they used to happen every 100 years, then at a given point they start happening at 50 years, then 25 years and so on,
so that you end up then with one year and then a half year and so on down to days.
So if I just calculate this just to give you an idea, if at some point they're happening every 100 years, then after 100 years they're happening every 50 years,
after 150 years they're happening every 25 years and so on down to when you get to 200 years they're happening daily.
So how is this possible? Is this possible? Should we expect this to stop?
Well the funny thing is we've seen this thing happen before, in the 60s we already knew that humanity was doubling the amount of information that it had,
the amount of knowledge every 15 years. This is a graph produced in the 60s predicting that we were going to run out of paper in order to record our knowledge that we were producing.
And everybody thought in the 60s, well this is going to have to stop soon because we won't have enough paper.
But then the internet happened and allowed our increasing knowledge to carry on, in fact faster, even faster than we can see here.
So in the nearest future apparently we're going to have paradigm shifts that will be happening daily. How might that be possible?
Well one of the proposals is that that's the moment that computers actually become smarter than us and that computers start doing the thinking, the design of paradigm shifts rather than us.
So if that's the case, and that's an if there, but if that's the case then for the first time on this planet there will be things smarter than us.
Of course it will only be as smart of us in the beginning, but of course assuming computers continue to get faster then there'll be twice, four times, ten times, a thousand times, a million times smarter than us within a lifetime.
Will they be self-aware? Possibly, we don't know, we really don't know. That raises ethical questions, will we then be able to turn them off?
And let me sharpen your focus on this by saying suppose we find a way to upload our brains into these machines and so continue after our death, well is it still okay to switch them off?
And of course the other question is, there's no reason why when computers become truly intelligent that they will be our friends. They might be neutral, we just don't know.
There's no inherent reason why computers will be our friends. We have to do a lot of work to get computers not to swear and machine learning programs not to swear or say nasty things.
That will be a lot of work to make sure that they are our friends.
And if you look at how we treat lesser intelligences on this earth, well we're not very good on that.
If they're useful to us, like cows, then we'll feed them and look after them for a while before killing them.
If they're not useful to us, then we don't really care if they live all by. I'm not talking about us individually, I mean as a society, which is why we're getting so many extinctions currently.
And if they're inconvenient to us, we will kill them at a moment's notice. Mosquito, pow, no thank you.
So why would a superintelligence work differently?
We have a looming AI crisis. We've known this for 100 years. This is a newspaper article from 1912 warning about an impending crisis.
What have we done in 100 years? Next to nothing. We recycle our bottles. That's not going to help.
But the thing is that if the computers, the intelligent computers, spot that we're the cause of that climate crisis,
and if the computers realise that the climate crisis will threaten them as well, then they're connected to the internet.
They'll be able to work out how to break into computers and shut down machines just as easily as a hacker can.
So we really need a plan. We should be thinking about this. We shouldn't just be going helter-skelter into the AI future without thinking of the consequences and planning for it and making sure that the bad things don't happen.
Unfortunately, we're really bad at responding to crisis. We respond way too slowly, see the climate crisis. So we really need to be thinking about this.
So conclusion. Humans are terrible at dealing with crisis and the question is which will get us first, the computers or the climate or will we actually do anything?
Sorry about that.
Thank you, Stephen, so much for bumming us all out. Are we doomed? Are we doomed? I don't know.
But thank you so much. It is a cautionary tale you need to tell. Absolutely. Do we have any questions for Stephen, please? I'm sure you all have burning questions.
Yes, I've got the microphone here. Here you go.
Hello, Stephen, again. Thank you very much for fantastic speech. It's super inspiring and maybe my question will be a little bit related also to data engineering aspect of GNAI.
What do you think when we will have even more, more, more data in the world, for example, in upcoming years, if the amount of data will double or triple or quadruple, will it make at some point AI more intelligent or not?
Will it make us more intelligent? And us as well.
So the point is that the data is not holding up. So we're producing exponentially more data all the time. We really are. In fact, in some areas more data, particularly in space, for instance, we're producing more data than we have time to do anything with.
Data provides information. Information provides knowledge. Knowledge provides wisdom. Will the computers, was that your question? Will the computers become more students?
Well, I mean, computers are better at spotting patterns than we are. So I'm sure that machine learning will be able to extract new knowledge out of that. And hopefully we can then use that to extract new wisdom.
Whether we will actually do that, the signs are at this moment not very good. The society as a whole is not very intelligent in general, and there's no signs of it getting particularly more intelligent.
So I'm a little pessimistic on that. In general, I'm an optimist, but things are a little dark at the moment.
Thank you. So you say AI is very good at recognising patterns. It's very good at recognising patterns. How can I recognise zebra crossings or traffic lights? Capture, I'm referring to you.
Well, OK. So, I mean, there's a long answer to that, but the answer is it can, but it wants confirmation. So when the capture, you're just giving confirmation so that it thinks that there are certain zebra crossings.
So, and it just wants to know that you think the same so that it can...
Oh, it's just insecure. It needs reassurance. It's learning. It's learning more.
We're teaching it. Any other questions? I thought it was a very convincing representation of the LLM being a stochastic statistical model, which was interesting.
The problem I have with the singularity projections is the fact that I don't believe that you can ever get a true reasoning system with these artificial...
Get a true reasoning system with these artificial intelligence systems. What do you think about that?
So, I've no idea if we will truly get intelligence. All I know is that there's an enormous amount of money being pumped in to finding it because the first one to get it will have a big advantage.
So, who knows? But on the other hand, our brains are wired very much like what the programs that we're writing now.
I mean, the programs we're writing, neural networks and so on, they're absolutely modeled on how our brains work.
And so, it's surprising we haven't yet found intelligence there, but I can imagine that somebody will find what it is, that little thing that makes the difference.
So, it might take ten years, but it might happen next year. I just don't know. But I do think it's likely, quite honestly. I do think it's likely.
And by intelligence, do you mean consciousness or self-awareness? Is that what you mean?
Well, I mean, true intelligence, whatever that is, and I think that the Turing test doesn't work really, as we've demonstrated because you can sort of do a Turing test to chat GPT.
But an intelligence that can really recognise irony or can see by looking at the knots and crosses board, hey, the corners are all identical.
That sort of stuff, a true intelligence where insight happens.
So, you say irony. So, humour is one of the tests in a way.
And humour as well. I mean, they're terrible at cracking jokes.
But most people are.
True, true, true. But that gives you a job, right?
Exactly, perfect. Lovely. I think we have to move on. Thank you so much.
Huge applause, please, for Stephen Pemberton. Thank you so much. Thank you, Stephen.
Out of curiosity, have you ever been asked to play Doctor Who? You'd be perfect.
You'd be perfect, Doctor Who.
Doctor Who, Doctor Strange, Mr X.
You'd be perfect. You'd be amazing. Thank you, thank you.
Super. Thank you so much. Thank you.
