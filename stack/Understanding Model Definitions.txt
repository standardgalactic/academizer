Understanding Model Definitions
Open sidebar
Understanding Model Definitions
Summarize: Term	Proposed Definition 1	Proposed Definition 2	Correct Examples	Incorrect Examples	Connections
Accuracy	Broad sense: how "close to the mark" an Estimator is. 	Narrow sense: the expected or realized extent of Surprise on an estimation, usually about Sense State reflecting theRecognition density 	A lower-resolution camera or fMRI has lower Accuracy and thus lesser capacity to map fine scale features of stimuli. 	The true distribution was 10 +/- 1 and the person guessed 10 +/- 5, thus they had higher Accuracy. I was sure the green car was really blue; this inaccuracy was caused by the dim light. 	Accuracy is the inverse of Uncertainty 
Ambiguity	Broad sense: Extent to which stimuli have multiple plausible interpretations, requiring priors &/or Action for disambiguation	Narrow sense: Specific model parameter used to model Uncertainty, usually about sensory Perception . 	The noisy readings from the thermometer resulted in high Ambiguity given the Sensory input to the Agent .	I am curious about what is inside the box, there is Ambiguity about what it might be. 	Uncertainty on Hidden State givenSensory input 
Bayesian Inference	As opposed to frequentist analysis, Bayesian Inference uses a specified Prior or Empirical prior to Update the distributional Posterior 		Many of the key ideas of Bayesian Inference existed before Rev. Bayes, and in some cases reflect recent contributions from computational research.	The frequentist t-test is a classical example of Bayesian Inference .	As a matter of determining the ratio of populations to sample, the following is instructive > https://aeon.co/videos/what-is-it-to-be-bayesian-the-pretty-simple-math-modelling-behind-a-big-data-buzzword
Belief	Broad sense: Felt sense by an Agent of something being true, or confidence it is the case.	Narrow sense: the State of a Random variable in a Bayesian Inference scheme.	The Prior or Empirical prior in Bayesian Inference can be a Belief on Hidden State .	A Belief in Bayesian Inference requires Subjective feeling states or conscious awareness. 	A Belief is the most likely Hypothesis that provides an Explanation for the cause of Sense State, where a cause here is a Hidden State of the Generative Process.
Belief updating	Belief updating is changes in a Bayesian Inference Belief through time. 		The incoming Sensory Data resulted in Belief updating  	I promise that if you vote for me, even if I change my mind due to new Information  coming in, I will never undergo Belief updating — so you know exactly what you get with me! 	In belief updating the Prior is altered to reflect incoporation of new Evidence presented to the model from the Generative Process.
Complexity	The extent to which an Agent must revise a Belief to explain incoming Sensory observations.  	The Kullback-Leibler Divergence between the Prior and Posterior which is used in Bayesian model selection to find the simplest (least complex) model and avoid overfitting on the noise inherent in Sensory observations.	Model Complexity can refer to the number of predictor or independent variables or features that a model needs to take into account in order to make accurate prediction.	Complexity is the opposite of concavity.	
Data	Data are a set of values of qualitative or quantitative variables about one or more Agent  or object .		These three readings from the thermometer constitute Data!	An anecdote is not a piece of Data.	Evidence is Data that is evaluated by Agent in the context of their Generative Model 
Expectation	Within a Bayesian Inference framework, Expectation is an Estimator about future timesteps 		At timestep 1, the Agent made a prediction about Expected Free Energy through time, this was an Expectation about the future. 	Although the scientist made a Prediction about the future using a Model , it was not an Expectation since they were not waiting for it to be realized.  	Anticipation, Prediction, Prediction error .
Inference	Process of reaching a (local or global) conclusion within a Model, for example with Bayesian Inference.	The process of using a Sensory observation (observed variable, data) along with a known set of parameters to determine the state of an unknown, Latent cause (unobserved variable).	The researcher made Model of Active Vision where the Agent was doing Inference on Action (Action Planning , Action Prediction ) as well as Perception (perceptual inference ). 	The ball rolled downhill using Inference on Policy selection, sometimes veering more to the left and other times more to the right.  	Action (more generally) and  perceptual inference and Bayesian Inference (more specifically).  
Information	Measured in bits, the reduction of Uncertainty on a Belief distribution of some type. Usually Syntactic (Shannon) but also can be Semantic (e.g. Bayesian ). 		There is more maximum Information in 1 terabyte than in 1 gigabyte. 	I listened to that podcast and the file checksum was OK but the Information was modified relative to the reference version. 	
Learning	Broad sense: Process of an Agent engaged in Updates to Cognition (and possibly) Behavior.	Narrow sense: Process of Bayesian Inference where Generative Model parameters undergo   Belief updating 	The software agent engaged in Belief updating on internal parameters, this is technically Learning . 	Every day we change, but from a Bayesian Inference perspective it is only Learning if the Belief updating is adaptive. 	Learning model parameters is called parameter estimation and is obtained by using Sensory observations and previously inferred Hidden State. In Bayesian Inference parameters are treated as Random variables. 
Outcome	If we consider the environment as a Generative Process that can be sampled when in a particular state, the statistical result (Data, Sensory observation) of the sampling is known as the outcome.	The Data produced by sampling a Generative Process (a joint distribution on states and outcomes).	The Generative Process produces outcomes when we sample from it.	I was worried about the Outcome of my decision.	Generative modelling involves using outcomes to approximate a statistical model of the Generative Process.
1 / 1
ChatGPT
ChatGPT
Accuracy: Broadly, accuracy refers to how close an estimator is to the true value or target. In a narrower sense, accuracy is the extent of surprise or error in an estimation, often related to the recognition of sensory input. For example, a lower-resolution camera or fMRI has lower accuracy and cannot capture fine-scale features of stimuli effectively. Correct examples include a person guessing a value close to the true distribution (10 +/- 1) with a small range (10 +/- 5), indicating higher accuracy. Incorrect examples include perceiving a green car as blue due to poor lighting, leading to inaccuracy. Accuracy is inversely related to uncertainty.
Ambiguity: Broadly, ambiguity refers to the extent to which stimuli can have multiple plausible interpretations, requiring prior knowledge or actions for disambiguation. In a narrower sense, ambiguity is a specific model parameter used to represent uncertainty, particularly in sensory perception. For instance, noisy readings from a thermometer result in high ambiguity given the sensory input to the agent. Another example is the curiosity about the contents of a box, where there is ambiguity about what it might contain. Ambiguity is related to uncertainty regarding hidden states given sensory input.
Bayesian Inference: Bayesian inference is an approach that uses specified priors or empirical priors to update the distributional posterior, as opposed to frequentist analysis. The key ideas of Bayesian inference existed before Rev. Bayes, and computational research has contributed to its development. An example of Bayesian inference is the frequentist t-test. The provided link gives an instructional example of determining the ratio of populations to sample, showcasing Bayesian inference.
Belief: Broadly, belief refers to the subjective sense of an agent that something is true or the confidence in its validity. In a narrower sense, belief represents the state of a random variable in a Bayesian inference scheme. In Bayesian inference, the prior or empirical prior can be a belief about hidden states. Belief in Bayesian inference requires subjective feeling states or conscious awareness. Belief serves as the most likely hypothesis that provides an explanation for the cause of sensory states, where the cause is a hidden state of the generative process.
Belief updating: Belief updating refers to changes in a Bayesian inference belief over time. It occurs when new sensory data or evidence is incorporated into the model, altering the prior. For example, incoming sensory data can lead to belief updating. However, a promise to never undergo belief updating, even with new information, suggests a lack of flexibility in adjusting beliefs. Belief updating involves altering the prior based on new evidence from the generative process.
Complexity: Complexity refers to the extent to which an agent needs to revise its belief to explain incoming sensory observations. In Bayesian model selection, complexity can be measured using the Kullback-Leibler Divergence between the prior and posterior distributions. It is used to find the simplest (least complex) model to avoid overfitting on the noise present in sensory observations. Model complexity can also refer to the number of predictor variables or features required for accurate predictions. Complexity is considered the opposite of concavity.
Data: Data refers to a collection of values of qualitative or quantitative variables related to one or more agents or objects. For example, three readings from a thermometer constitute data. An anecdote, on the other hand, does not qualify as data. Evidence is data that is evaluated by an agent in the context of their generative model.
Expectation: Within a Bayesian inference framework, expectation refers to an estimator about future timesteps. It represents the prediction or anticipation of future outcomes based on a model. However, it is distinct from a mere prediction since expectation implies waiting for the prediction to be realized. Expectation is related to anticipation, prediction, and prediction error.
Inference: Inference is the process of reaching a conclusion, either local or global, within a model. In Bayesian inference, it involves using sensory observations and known parameters to determine the state of unknown latent causes. For example, an agent may engage in inference on action planning, action prediction, as well as perceptual inference in a model of active vision. Inference can also apply to policy selection, as observed when a ball rolls downhill, veering left or right based on inferred policy. Inference is related to action and perceptual inference, as well as Bayesian inference.
Information: Information, measured in bits, refers to the reduction of uncertainty in a belief distribution. It can be syntactic (Shannon information theory) or semantic (Bayesian information theory). For example, 1 terabyte contains more maximum information than 1 gigabyte. Information can be modified relative to a reference version, even if the file checksum remains intact.
Learning: Broadly, learning refers to the process of an agent updating its cognition and possibly behavior. In a narrower sense, learning occurs through Bayesian inference when the parameters of a generative model undergo belief updating. For instance, a software agent engaging in belief updating on internal parameters represents learning. However, from a Bayesian inference perspective, learning is only adaptive if the belief updating is adaptive. Learning model parameters is also known as parameter estimation and involves using sensory observations and previously inferred hidden states. In Bayesian inference, parameters are treated as random variables.
Outcome: If the environment is considered a generative process that can be sampled in different states, the statistical result of sampling (data, sensory observation) is known as the outcome. It represents the data produced by sampling from a generative process. For example, one can be concerned about the outcome of a decision. Generative modeling involves using outcomes to approximate a statistical model of the generative process.
1 / 1
Summarize:

Posterior	The Update to the Prior after Observation has occurred 	In Bayes' theorem, the Posterior is equal to the product of the Likelihood and Prior divided by the model evidence.	The Posterior distribution reflects our degrees of Belief about Latent causes after we see Sensory Data. 	The Posterior distribution can always be trivially obtained by solving Bayes' theorem.	Solving an Inverse problem to go from Outcomes given a State determining a State given an Outcome. In representation learning the Posterior is called the Recognition Model since it "recognizes" the Latent cause that underlie the generation of the Sensory outcomes.  
Prediction	An Estimator about a State in a Model at a future time.   	The process of using a learned Generative Model to forecast what value a future Hidden State will be.	After successfully Learning the structure of the Generative Process  the Agent can make a Prediction about the future state of this Generative Process and the associated Sensory Data it will generate.	A magic 8-ball can make a Prediction that will reliably be true.	The top-down priors aim at Prediction the incoming Sensory Data based on what the Agent has learned about the environment. An incorrect Prediction results in a Prediction error which the Agent attempts to minimize in the long run in the process of Prediction error minimization.
Prior	The initial or preceding state of a Belief in Bayesian Inference, before Sensory Data (Observation or Evidence ) occurs. 		Active Vision uses Prior on Sensory input .	We arrested someone with no Priors.	In the Active Inference (Continuous state space formulation), the Prior is represented by a Stochastic State space equation which represents the Agent's belief about how the Hidden State in the environment change over time.
State	is the statistical, computational, or mathematical value for a parameter within the State space of a Model . 		Blanket State is a type of State that partition Internal State from External State 	California is the State with the best honey on the West Coast. 	111. Situation, Condition, State (from here)

The words, situation and condition, imply, something accidental, and transitory; with this difference, that situation, respects outward circumstances; condition, those, within the matter referred to; whereas, that of state,implies, something, more habitual, and lasting.

We, generally, use the word, situation, as relative, to affairs, rank or fortune; condition, with respect, to the nature, quality or property of a thing; and that, of state, applying it to health, or, our well or ill-being.

We say, our situation is bad; when we are surrounded with difficulties: that a building is in bad condition; when out of repair; and, that some persons enjoy but an indifferent state of health.

An ill-state of health, added to a bad situation of affairs, is a condition, into which, every man must, naturally, dread the falling.

Such is the condition, and vicissitude of human life, that, the most prudent men, have, often, found themselves in perplex|ing situations; and from a state of happiness, have, as it were, through the perverseness of fortune, fallen into one most wretched and deplorable.
State space	Set of variables/parameters that describe a System .	A state space is the set of all possible configurations of a system	The State space of a Generative Model can be a Continuous state space or Discrete state space . 	In politics, the State space  refers to the total area governed by a particular state.	
Stationarity	Of a Random variable , that it is described by parameters that are drawn from a  Gaussian distribution and unchanging over the time horizon of analysis. 		A common assumption of many time series algorithms is that the data exhibits Stationarity.	I am exhibiting Stationarity when I stop walking.	A common assumption in many time series techniques is that the data are at Stationarity .

A stationary process has the property that the mean, variance and autocorrelation structure do not change over time. Stationarity can be defined in precise mathematical terms, but for our purpose we mean a flat looking series, without trend, constant variance over time, a constant autocorrelation structure over time and no periodic fluctuations (seasonality).

For practical purposes, stationarity can usually be determined from a run sequence plot.

https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc442.htm
Surprise	In Bayesian Inference, Surprise is the negative log evidence, directly corresponding to the inverse of probability (high probability, low surprisal; low probability, high surprisal). The proxy that bounds surprisal is the difference between Prior and Posterior Distribution — how "surprising" Sensory Data are to the Generative Model of the Agent.	Surprise (also known as Surprisal or self-Information), is a quantity that, according to the Free Energy Principle, must be minimized in order for an Agent to survive; Variational Free Energy provides an upper bound on Surprisal and is minimized instead of minimizing Surprisal directly.	Surprisal cannot be minimized directly because it is involves calculating the Evidence term in Bayes' Rule which generally involves an intractable integral over all possible states an organism can be in.	When they walk into the room, yell "Surprise"! 	An organism that minimizes Surprisal can maintain Non-Equilibrium Steady State and will consistently revisit an Attracting set of states. Minimizing Surprisal is equivalent to maximizing model evidence.
2 / 2
ChatGPT
ChatGPT
Summary:
Posterior: The updated belief distribution after incorporating sensory data in Bayesian inference. It reflects the agent's belief about latent causes after observing sensory data.
Prediction: Estimating the future state of a model based on a learned generative model. It involves using prior knowledge to forecast the value of a hidden state in the future.
Prior: The initial belief distribution in Bayesian inference before observing sensory data. It represents the agent's initial state of knowledge or assumptions.
State: A parameter or value within the state space of a model. It can refer to the condition, situation, or health of an entity.
State space: The set of all possible configurations or values that describe a system or model.
Stationarity: The property of a random variable or time series where its parameters, such as mean, variance, and autocorrelation structure, remain constant over time.
Surprise: In Bayesian inference, it is the measure of the unexpectedness of sensory data to the agent's generative model. It can also be referred to as surprisal or self-information. Minimizing surprise is essential for an agent to survive and maintain a non-equilibrium steady state.
Note: The additional information about "situation," "condition," and "state" provides general definitions and distinctions between these terms in different contexts. The content under "surprise" discusses its relation to the Free Energy Principle and the concept of minimizing surprisal.
1 / 1
Summarize: Temporal Depth	The length of a time window or horizon considered (longer time → deeper / more Temporal Depth ) 		In deep temporal models, Temporal Depth or occurs because of the number of Counterfactual possibilities one must account for increases as more future states are modeled (see: https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00579/full)	The longer the queue, the greater the Temporal Depth.	From Breaking down unitization: Is the whole greater than the sum of its parts?  "Depth" as a measured difference applied to change (time passing) as Memory and Cognition . "Graf and Schacter (1989) first described unitization as the process whereby multiple, separate, items become represented as a single unit, either through perceiving or conceiving of a structure (e.g., semantic meaning) that would connect the disparate units."  Which leaves us with at least two ways of "structuring" time units (episodes and cycles (diachronic)).
Uncertainty	In Bayesian Inference , a measure of the Expectation of Surprise (Entropy) of a Random variable (associated with its variance or inverse Precision )	Random fluctuations around the true value of a quantity we are trying to measure that are a result of uncontrolled variables in the environment or measurement apparatus.	A measure of unpredictability or expected Surprise (cf, Entropy ). The Uncertainty  about a Random variable  is often quantified with its Variance  (inverse Precision ).	I felt a lot of Uncertainty after that job interview.	From Basics of Estimating Measurement Uncertainty https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2556585/There is a table of terminology of the science of measurement (metrology) that includes common metrological terms and their definitions, all of which recognize that making measurement comparisons leads to some degree of measurement uncertainty. 
Action	Broad sense: The dynamics, mechanisms, and measurements of Behavior 	Narrow sense: The sequence of Active States  enacted by an Agent  via Policy selection from Affordance 	Ants are continually involved in Action in real life (Realism) and/or in a Model (Instrumentalism) 	I love this band's first song, can't wait till the Action really begins! 	Action of the Agent is selected by Action Planning . As the consequences of Action are not fully known, the Expected Free Energy  is calculated over Affordance and used for Variational Free Energy Action and Planning as Divergence Minimization 
Action Planning	The selection of an Affordance based upon Inference of Expected Free Energy 		The robot assessed its current and target location, then engaged in Action Planning to decide under time pressure how to navigate.	The Agent used Action Planning algorithms for Variational Free Energy Inference  on Sensory input 	Action Planning draws from set of Affordances and uses Expected Free Energy Inference, also known as Action Prediction .
Agency	The ability of an Agent to engage in Action in their Niche and enact Goal-driven selection or Policy selection  based upon Preference 		An Agent uses their Agency to sculpt their environment which makes it more predictable thereby minimizing the agent'sVariational Free Energy and maintaining its Markov Blanket in the face of random fluctuations.	I got a new picture taken at the passport Agency.	Agent has Agency
Behavior	The sequence of Action that an Agent is observed to enact.		I expect you to be on your best Behavior!

The Active Inference Agent uses its selected Policy to take Action that we call its Behavior.	The Behavior of this hammer is being determined entirely by my Internal States without being intermediated by Blanket States. 	
Policy	Sequence of Actions, reflected by series of Active States as implemented in Policy selection which is Action Prediction or Action and Planning as Divergence Minimization 		The sequence of Actions that an Agent plans to take is a Policy. 	What insurance Policy do you recommend for my house?	Policy selection in Active Inference is about Prediction error minimization or minimization of Expected Free Energy 
Policy selection	The process of an Agent engaging in Action Planning from set of Affordance, in Active Inference based upon minimization of Expected Free Energy 		When the Agent decided to go one way instead of the other, it was due to an internal process of Policy selection, specifically Action and Planning as Divergence Minimization. 	We went shopping for insurance and the package was already determined for me, this is a case of Stochastic Policy selection.	Similar to Decision-making 
Preference	parameter in Bayesian Inference Markov Decision Process that ranks or scores the extent to how an Agent values Sensory input .  		The Generative Model of the bacteria underwent parameter fitting (Belief updating / Learning ) on Action , guided by a Preference for medium but not high/low sugar concentration. 	All Action results in Agents that realize their Preference in terms of Sensory outcome . 	In the Discrete state space formulation of Active Inference, the Preferences or habits of an Agent can be encapsulated in a Prior Preference Distribution, a target distribution of States the agent wishes to end up due to its phenotype and other habits it has picked up throughout its existence.
Active Inference	Active Inference is a Process Theory related to Free Energy Principle .		It is fun and rewarding to learn and apply Active Inference as a framework for Perception, Cognition , and Action — it is a Process Theory compatible with the Free Energy Principle.	Active Inference is a style of reinforcement learning Artificial intelligence that uses frequentist statistics only. 	The conclusion of Active Inference is a Hypothesis (conjecture) about the feasibility of adopting certain Policy (strategy profiles) that the Agent makes a Generative Model with Temporal Depth.
Epistemic value	is the value of Information gain or Expectation of reduction in Uncertainty about a State  with respect to a Policy, used in Policy selection 		When the environment contains Uncertainty I would like to undertake the action of Foraging for the sake of it to see if I can gather more relevant Observations to explain what is going on around me. Such relevant Observations have Epistemic value for me as an Agent. 	In the case of temperature homeostasis, taking Actions that move the body temperature in an adaptive direction are of purely Epistemic value.	It is variously known as Bayesian surprise, epistemic affordance, the value of information, intrinsic motivation and so on.
Expected Free Energy	Measure for performing Inference on Action over a given time horizon (Policy selection , Action and Planning as Divergence Minimization ). 	The two components of Expected Free Energy are the imperative to  satisfy Preferences, and the penalty for failing to minimize Expectation  of Surprisal.	The deep affective Inference Agent used Expected Free Energy calculation as a basis of Policy selection .	The amount of calories that the Living system has at Non-Equilibrium Steady State is the Expected Free Energy . 	Expected Free Energy can be seen as.... 
Free Energy	Free Energy is an Information Theoretic quantity that constitutes an upper bound on Surprisal . 	Free Energy can refer to various or multiple sub-types of Free Energy: 

* Variational Free Energy 
* Expected Free Energy 
* Free Energy of the Expected Future 
* Helmholtz Free Energy 
* ....	Free Energy can refer to various different formulations and decompositions, that share some important key features.	You can get the electricity for no cost at all, it is Free Energy.	
Free Energy Principle	A generalization of Predictive Coding (PC) according to which organisms minimize an upper bound on the Entropy of Sensory input  (or sensory signals) (the Free Energy). Under specific assumptions, Free Energy translates toPrediction error . 	A set of statistical principles that describe how Agents can maintain their self-organization  in the face of random fluctuations from the environment.	As a principle, the Free Energy Principle cannot be falsified. 	There is not enough empirical evidence to support the Free Energy Principle.	An Agent that is consistent with the Free Energy Principle will be able to minimize Variational Free Energy by taking Actions or using Perception in a way that maximizes the Evidence for its Generative Model of the environment. 

The Free Energy Principle is a more general statement about specific kinds of self-organization in random Non-linear dynamical systems assuming that these systems have certain properties like Ergodicity (weakly mixing) and a Markov Blanket. According to the Free Energy Principle, systems that minimize Variational Free Energy will maintain their low (thermodynamic) Entropy structure through Autopoiesis in the face of random fluctuations in the environment. To do so, they must take Actions that maintain the integrity of their Markov Blanket and develop a Generative Model that can successfully predict future states of the environment based on the Sensory Data they receive through the Markov Blanket.
1 / 1
ChatGPT
ChatGPT
Temporal Depth refers to the length of a time window or horizon considered, with longer time periods indicating deeper Temporal Depth. In deep temporal models, Temporal Depth increases as more future states are modeled, leading to an increase in the number of counterfactual possibilities. Uncertainty is a measure of the expectation of surprise or unpredictability, often quantified using variance. Action refers to the dynamics and mechanisms of behavior, while Action Planning is the selection of an action based on the inference of expected free energy. Agency is the ability of an agent to engage in goal-driven action, and Behavior refers to the sequence of actions enacted by an agent. Policy is a sequence of actions selected through policy selection, and Preference ranks the value an agent places on sensory input. Active Inference is a process theory related to the Free Energy Principle, and Epistemic Value refers to the value of information gain or reduction in uncertainty. Expected Free Energy is a measure used for inference on action, and Free Energy is an information theoretic quantity that bounds surprisal. The Free Energy Principle is a set of statistical principles describing self-organization in the face of random fluctuations.
1 / 1
Summarize: Generalized Free Energy	Past Variational Free Energy plus future Expected Free Energy (each totaled over Policy).		Parr and Friston 2019 wrote "Crucially, this means the Generalized Free Energy  reduces to the Variational Free Energy  for outcomes that had been observed in the past.....Outcomes in the Generalized Free Energy formulation are represented explicitly as Beliefs. This means that the Prior over Sensory outcome is incorporated explicitly in the generative model."	The speaker was talking about Variational Free Energy on Generalized coordinates in a very broad and vague fashion, this is identical to Generalized Free Energy.	
Pragmatic Value	Pragmatic Value  is the benefit to an organism of a given Policy  or Action , measured in terms of probability of a Policy  leading to Expectation of Random variable values that are aligned with the Preference of the Agent 	Pragmatic value describes the extent to which a given action is aligned with rewarding preferences over sensory outcomes.	The Agent had Preferences for there to be more beans in the jar, so adding more beans was of Pragmatic Value for them. 	If a Policy reduces the divergence between your Preferences and Observations, it is defined as having negative Pragmatic Value. 	
Variational Free Energy	Measure that performs e.g. Inference on Sensory Data given a Generative Model , F. The two sources that composeVariational Free Energy  are Model overfitting and Model accuracy		Variational Free Energy is a tractable way to compute an upper bound on Surprisal of a Generative Model given Data.	Our electric bill fluctuates so much each month though on average it is zero; this is known as Variational Free Energy.	
Active States	In the Friston Blanket formalism, the Blanket State are the Sense State (incoming Sensory input) and Active States (outgoing influence of Policy selection )		The Active States of the computer program are the statistical outputs that it presents, while the Sensory input Sense State are the incoming statistical dependencies. 	Canada and Kenya have many people involved in dance, really you could say these two are Active States 	Active States and Sense State make Blanket State, which partition Internal State and External State in the Markov Blanket partitioning formalism. 
Blanket State	Set of states in the Markov Blanket Partition that make Internal State and External State have Conditional Probability that are independent. 		I don't care whether it is an Action or Sense State, as long as it is a Blanket State!	My child created a fortress from the bedding; it belongs to the Blanket State 	
External State	States with Conditional density independent from Internal State, conditioned on Blanket State. 		In my Generative Model of temperature, the true temperature in the room is being modeled as an External State (Hidden State), so we will never know it. 	That country is outside of our borders, it is an External State. 	
Friston Blanket	Markov Blanket with partitioned Active States and Sense State . 		A Friston Blanket is a type of Markov Blanket where Sense States are associated with incoming Sensory Data and Action states are associated with outgoing Behavior of the Agent.	Karl walked into the room and cast a chilly Friston Blanket over the audience.  	
Internal State	States with Conditional density independent from External State , conditioned on Blanket State. 		When the Generative Process describes a forest outside, and the Blanket States describe the bark of the tree, the Internal States describe the core of the tree.	The State space of the internet is equivalent to the total number of computers connected to it at any given time. 	
Markov Blanket	Markov Partitioning Model of System, reflecting Agent as delineated from the Niche via an Interface. The Markov Blanket Blanket State reflect the State(s) upon which Internal State and External State are conditionally independent. 		Markov Blankets are features of Maps (e.g. Bayesian Graphical Models), not of Territories (e.g. ant colonies or brains). 	In textile industry, a Markov Blanket is a blanket made using a specific knitting technique."	
Markov Decision Process	Bayesian Inference Model where Agent Generative Model  can implement Policy selection on Affordances reflected by Active States, while other features of the Generative Process are outside the Control (states) of the Agent .  		Whether it is fully observable or not, one common type of model used in control theory is a Markov Decision Process 	We will let Captain Markov make the call here, since it is a Markov Decision Process 	Is Markov Blanket one way, and thus the Friston Blanket has x2 @markovboundaries linked to the decision making process. The probability and Preference Information Geometry  between the x2 markov boundaries at each nested levels being updated gives the @temporality at the heart of @activeinference
Sense State	In the Friston Blanket formalism, the Blanket State are the Sense State (incoming Sensory input) and Active States (outgoing influence of Policy selection )		In this model, the Observations coming in from the thermometers are considered as Sense States. 	Most models don't show it, but actually all Active Inference Generative Models include a "sixth Sense State". 	
Affordance	Options or capacities for Action by an Agent (sometimes called "Affordance 3.0") 	From Ecological Psychology, the Perception of a possibility for Action (sometimes called "Affordance 2.0").  	"In this T-maze model, there are 3 Affordance for movement at the junction (Left, Right, Down)." 	"He didn't have the Affordance to do that, but he did it anyway". 	
Agent	 Entity as modeled by Active Inference , with Internal State separated from External State by Blanket State 		"The ant nestmate is the Agent in the Active InferAnts model" 	"Calcium carbonate is the anti-caking Agent in this cookie"	Agent has Agency
Cognition	An Agent modifying the weights of its Internal State for the purpose of Action Planning and/or Belief updating . (This is a @realistCounterpart of Goal-driven selection .) 		BacillisAxelis345 engaged in Cognition to decide whether to eat or to escape.	Because the Agent is exhibiting intelligent Behavior, this means 	
Ensemble	Group of more than one Agent.		The ant colony from a Behavioral, orCollective behavior perspective, is an Ensemble of nestmates. 	After the band played their final song, the crowd called out "Ensemble!", prompting them to play another song.	Can have Group Renormalization Theory aspect or Stigmergy or Swarm
1 / 1
ChatGPT
ChatGPT
The summary of the provided text is as follows:
Temporal Depth refers to the length of a time window or horizon considered in deep temporal models.
Uncertainty is the measure of unpredictability or expected surprise associated with a random variable.
Action is the dynamics, mechanisms, and measurements of behavior, involving active states enacted by an agent through policy selection.
Action planning is the process of an agent selecting an affordance based on inference of expected free energy.
Agency refers to the ability of an agent to engage in action and enact goal-driven selection based on preference.
Behavior is the sequence of actions that an agent enacts.
Policy is a sequence of actions reflected by a series of active states and implemented in policy selection.
Policy selection is the process of an agent engaging in action planning based on the minimization of expected free energy.
Preference is a parameter that ranks or scores the extent to which an agent values sensory input.
Active inference is a process theory related to the free energy principle that involves perception, cognition, and action.
Epistemic value refers to the value of information gain or reduction in uncertainty about a state with respect to a policy.
Expected free energy is a measure used for inference on action over a given time horizon.
Free energy is an information theoretic quantity that constitutes an upper bound on surprisal.
The free energy principle is a generalization of predictive coding that organisms minimize the entropy of sensory input.
Generalized free energy is the combination of past variational free energy and future expected free energy.
Pragmatic value is the benefit to an organism of a given policy or action measured in terms of alignment with preferences.
Variational free energy is a measure that computes an upper bound on surprisal of a generative model given data.
Active states are the outgoing influence of policy selection in the Friston Blanket formalism.
Blanket state is a set of states that make internal and external states conditionally independent.
External state is a state with conditional density independent from the internal state, conditioned on the blanket state.
Friston Blanket is a Markov blanket with partitioned active states and sense state.
Internal state is a state with conditional density independent from the external state, conditioned on the blanket state.
Markov blanket is a model of a system that reflects an agent delineated from the niche via an interface.
Markov decision process is a Bayesian inference model where the agent's generative model can implement policy selection.
Sense state is the incoming sensory input in the Friston Blanket formalism.
Affordance refers to options or capacities for action by an agent.
An agent is an entity modeled by active inference with an internal state separated from the external state by a blanket state.
Cognition refers to an agent modifying the weights of its internal state for action planning and belief updating.
Ensemble is a group of more than one agent.
1 / 1
Summarize: Generative Model	A formalism that describes the mapping between Hidden State, and Expectations of Action Prediction , Sensory outcome . 	Recognition Model Update Internal State parameter  that correspond to External State  (including Hidden State causes of environment  states), Blanket State , and Internal State  (meta-modeling). In contrast, Generative Model  take those same Internal State  parameter  Estimator  and emit expected or plausible observations.	Partially Observed Markov Decision Processes are commonly used for computational modeling of Generative Models.  	The subject of the photography session made art as well, they are a Generative Model — but if they wouldn't have made the art, they would have only been a Model, not a Generative Model . 	
Generative Process	Underlying @dynamical process in the Niche giving rise to Agent Observation and @agent Action Prediction  	Enactive ecological process using morphological computing processes where the Niche Regime of Attention @morphogenesis and generative model interact to create an embodied learning dyanamic.	The Generative Process generates Sensory Data.	The Agent  uses its Generative Process to determine future Hidden State of the environment.	The Generative Process exists in certain States that are Hidden State from the perspective of the Agent. When in a state, from the statistical perspective, it can generate a Sensory outcome which is sensed by the Agent. The agent will use this Sensory Data to form a Generative Model which may or may not match the true Generative Process but will nonetheless allow it to predict future outcomes drawn from the Generative Process if it has a good Generative Model.
Niche	Ecology System constituting the Generative Process (as Partitioned from the Agent who instantiates a Generative Model ). 		Every ant lives in their ecological Niche.	That band's kind of music honestly is just too Niche for me. 	
Non-Equilibrium Steady State	Technically, a Non-Equilibrium Steady State requires a solution to the Fokker Planck equation (i.e., density dynamics). A nonequilibrium steady-state solution entails solenoidal (i.e., conservative or divergence free) dynamics that break detailed balance (and underwrite stochastic chaos ). In other words, The dynamics of systems at Non-Equilibrium Steady State  are not time reversible (unlike equilibrium steady states, in which the flow is entirely dissipative).	Generally, a Non-Equilibrium Steady State refers to a System with dynamics that are unchanging, or at Stationarity in some State. 	Blood sugar levels are dynamic and fluctuating, however they revisit characteristic states repeatedly, this can be described by a Non-Equilibrium Steady State.	The ball just lay still on the floor, we can describe this as exhibiting a Non-Equilibrium Steady State .	Similar to Stationarity 
Particle	An Agent consisting of Blanket State and Internal State , partitioned off from Niche .		Internal State and Blanket States together constitute the Particle. 	The house was made of Particle board. 	
Recognition Model	Recognition Model is the kind of Model that affords Variational Inference, which lets us calculate or approximate a probability distribution. Recognition Model is a synonym for Variational Model.	In Dayan and Abbot (2001), the probability of a Hidden State (causes) given Sensory Data (effects) under some parameter. 	After constructing a Generative Model, an Agent can invert this model to obtain the Recognition Model which allows for the prediction of the Hidden State (causes) that generated some new Sensory Data.	That billboard has a picture of one of the most Recognition Model in the world. 	
Representation	A structural correspondence between some Random variable  inside a System and some Random variable  outside the System  (isomorphism being the strongest kind of correspondence), such that the Systemengages in Inference carried out by the System maintains the correspondence		The sterotypical neural pattern induced by a Stimulus is considered a Representation, at least by those who subscribe to Representationalism. 	No Taxation without Representation!	
Attention	Broad sense: Generative Model that is aware of some Stimulus, reflected by its Salience 	Narrow sense: Attention modulates the  the confidence on the Precision of Sense State, reflecting Sensory input 	The Model instantly updated to the new Sensory Data because it was paying maximal Attention to the Stimulus.	The words were impactful even though the child was not paying Attention at all. 	Attention is structured in complex sociocultural Systems to realize a Regime of Attention 
Evidence	Data as recognized and interpreted by Generative Model of Agent 		Every photon is like a piece of Evidence on the retina. 	Just because you have litigated the case with Data doesn't mean that you provided any Evidence 	
Observation	The Belief updating of an Internal State registered by a Sensory input, given the weighting assigned to that class of input in comparison with weighting of the competing Priors. (This is a narrow sense of "observation," where the Agent is "looking for this kind of input." This sense excludes situations where (a) an incoming stimulus with these attributes has already been explained-away or pre-discounted, or (b) the prior is so strongly weighted as to exclude updating in response to any inputs (other than, perhaps, "catastrophic" ones, as may occur in e.g. fainting, hysterical blindness).)	Any Sensory input, either discrete-valued or continuous-valued. (This is a broad sense.)	One Observation can make all the difference. 	Observations are not required in order to do empirical parametrization of a statistical model. 	
Perception	Posterior State Inference after each new Observation.		Visual Perception gives us many demonstrations of the characteristics of our Generative Model — for example saccades, the blind spot, and blink supression.	Active Inference models Action and Perception as literally the same thing for each Agent. 	
Salience	The extent to which a Cue commands the Attention of an Agent given their Regime of Attention 		Salience is related to how relevant a given Stimulus appears to be. 	I can smell dinner cooking, and already my mouth is Salience.	Related to Attention, for example of Affordance 
Hierarchical Model	A hierarchy of Estimators, which operate at different spatiotemporal timescales (so they track features at different scales); all carrying out Predictive Processing 		A Nested Model is a Hierarchical Model, for example the Hierarchically Mechanistic Mind.	The Hierarchical Model stated that water boils at a higher temperature at higher altitudes.	
Living system	Agent engaged in Autopoiesis 		A body is a Living system.	A Living system  is a mathematical model used to predict weather patterns.	
Multi-scale system	Realism framing of Hierarchical Model 		The Generative Model of counties within states within countries, was a Multi-scale system 	In culinary arts, a Multi-scale system is a method for measuring ingredients in both metric and imperial units.	
System	Set of relations described by State space of a Model . 	Differentiable and Integratable in terms of Variables and functions.	George Mobus argues that Systems have some fundamental properties such as structure and function.  	A System is the scientific term for a large group of wolves.
1 / 1
ChatGPT
ChatGPT
The text contains explanations and definitions related to various concepts in the field of generative modeling and active inference. Here's a summary of each concept:
Generative Model: It describes the mapping between hidden states and the expected outcomes of actions and sensory inputs.
Generative Process: It refers to the underlying dynamics in the environment that generate agent observations and predictions.
Niche: It represents the ecological system in which the generative process operates, distinct from the agent that constructs a generative model.
Non-Equilibrium Steady State: It refers to a system with unchanging dynamics or stationarity that is not time reversible.
Particle: It represents an agent consisting of internal and blanket states, separated from the niche.
Recognition Model: It is a type of model that allows for the prediction of hidden states based on sensory data, derived from the generative model.
Representation: It refers to a structural correspondence between variables inside and outside a system, facilitating inference.
Attention: In a broad sense, it indicates a generative model's awareness of a stimulus. In a narrow sense, it modulates the confidence of sensory input precision.
Evidence: It represents data recognized and interpreted by the generative model as evidence.
Observation: It is the belief updating of an internal state based on sensory input, influenced by the weighting of competing priors.
Perception: It involves posterior state inference based on new observations.
Salience: It indicates the extent to which a cue commands an agent's attention based on their attentional regime.
Hierarchical Model: It consists of estimators operating at different spatiotemporal scales, tracking features at different levels.
Living System: It refers to an agent engaged in autopoiesis, sustaining its own existence.
Multi-scale System: It is a hierarchical model with multiple scales or levels.
System: It represents a set of relations described by the state space of a model, characterized by variables and functions.
1 / 1
Summarize each term and explain: Abstract Accuracy					
Abstract Action					
Abstract action prediction					
Abstract Bayesian Inference					
Abstract epistemic value					
Abstract External State					
Abstract Generative Model					
Abstract Hidden State					
Abstract Internal State					
Abstract Sensory State					
Abstract System					
abstractCounterpart	(abstractCounterpart ?AB ?PHYS) relates a Physical entity to an Abstract one which is an idealized model in some dimension of the Physical entity. 	Example: an Abstract GraphNode could be stated to be the counterpart of an actual Computer in a ComputerNetwork.			
Action and Planning as Divergence Minimization					
Action at a distance					
Action Integral					
Active Blockference					
Active learning					
active processes					
active processes					
Active Vision	refers to the process of visual perceptions, in terms of oculomotor Sensorimotor Behavior and Cognitive System Generative Model 	refers to regime of visual perceptions through dynamical perturbations of light over the retina. As if feeling the textured light reflected off the niche surfaces	Active Vision 		Epistemic value -driven Learning or Foraging  
affect					
Agency based model					
Agency free model					
Algorithm					
Alignment					
analogy					
Analytical Philosophy					
anticipation					
Appraisal theories of emotion					
Artificial					
Attenuation of response					
Attracting set					
Augmented reality					
Autopoiesis	Phenomena of a System that recapitulates the material and informational causes of its own composition/existence. 		In the right niche, cells can be considered to exhibit Autopoiesis at the System level.	The pile of sand quickly dissipated in the wind, however I still think it is my favorite example of long-range Autopoiesis . 	
Bayes-optimal control					
Bayesian					
Bayesian belief updating					
Bayesian Brain					
Bayesian mechanics					
Bayesian Model Selection					
Bayesian surprise					
Bethe approximation					
Blanket index					
Bottom-up attentional control					
categorical					
category					
Category Theory					
changing mind (cognition)					
changing the mind					
changing the world					
changing world (action)					
chaos					
Circular causality					
Co-category					
Coarse graining					
Cognitive Science					
Cognitive System					
Cognitivism					
colimit					
Collective behavior					
Conceptual metaphor					
Conditional density					
Conditional Probability					
Confidence					
Congruence					
Connectionism					
constraint					
Continental Philosophy					
Continuous state space					
Control (states)					
Control theory					
Counterfactual					
Cybernetics					
Decision-making	Within Active Inference , this is the same as Policy selection 				
Deflationary					
Density					
Deontic Action					
DeSci					
Development					
Discrete state space					
Dissipation					
Distribution					
divergence					
Domain					
Domain-generality					
Domain-specificity					
Dynamic Causal Modelling					
Dynamic expectation maximization					
Dynamicism					
EcoEvoDevo	Ecology, Evolution, Development				
Ecology					
Effective					
Effectivity					
effectivity					
Embedded Embodied Encultured Enactive Inference					
Embodied Belief					
Embodied Cybernetic Complexity					
Emotion					
Empirical prior					
Enactivism					
Entropy					
Epistemic foraging					
Ergodicity					
Estimator					
Event-related potential					
Evolution					
Expectation maximization					
Expected Utility Theory					
Experience of body ownership					
Explaining Away					
Explanation					
Extended Cognition					
Exteroception					
Factor graph					
Falsification					
Far-from-equilibrium					
Filter					
fitness					
flow					
Fokker-Planck Equation					
Foraging 					
Forney					
frequentist					
Friction					
Friston's Law					
functional magnetic resonance imaging (FMRi)					
Functor					
Gauge theory					
Gaussian distribution					
Generalized coordinates					
Generalized Synchrony					
Generative density					
Generative modelling					
Gestalt					
Goal-driven selection					
Gradient Descent					
Graphical					
Group Renormalization Theory					
Guidance signal					
Habit learning/formation					
Hamilton's Principle of Least Action					
Helmholtz Decomposition					
Helmholtz Free Energy					
Helmholtz machine					
Hermeneutics					
Hierarchically Mechanistic Mind
1 / 1
ChatGPT
ChatGPT
Here's a summary of each term and an explanation:
Abstract Accuracy: Refers to the accuracy or precision of an idealized model or concept.
Abstract Action: Represents a general or high-level action that is not tied to specific physical movements.
Abstract Action Prediction: Making predictions about high-level actions or outcomes based on abstract representations or models.
Abstract Bayesian Inference: Bayesian inference performed using abstract or idealized models.
Abstract Epistemic Value: Refers to the value or importance of knowledge or information within an abstract or conceptual framework.
Abstract External State: An abstract representation of the external state of a system, often used in generative models.
Abstract Generative Model: An idealized or conceptual model that describes the mapping between hidden states and sensory outcomes.
Abstract Hidden State: An abstract representation of the hidden state variables within a generative model.
Abstract Internal State: An abstract representation of the internal state variables within a generative model.
Abstract Sensory State: An abstract representation of the sensory state variables within a generative model.
Abstract System: A conceptual representation of a system or model, often used to understand its properties or behavior.
Abstract Counterpart: Relates a physical entity to its corresponding abstract or idealized model in some dimension or aspect.
Action and Planning as Divergence Minimization: The idea that action and planning involve minimizing the divergence between desired or expected states and actual states.
Action at a Distance: The ability of an agent or system to exert influence or take action without direct physical contact.
Action Integral: A mathematical concept that represents the accumulated effect of an action over time.
Active Blockference: Refers to active inference in the context of processing and integrating block-based information.
Active Learning: Refers to the process of actively acquiring new knowledge or information through exploration or interaction.
Active Processes: Processes that involve active engagement or intervention by an agent or system.
Active Vision: Refers to visual perception processes that involve active exploration and manipulation of the environment.
Affect: Refers to subjective feelings, emotions, or moods.
Agency-based Model: A model or framework that incorporates the concept of agency or intentional action.
Agency-Free Model: A model or framework that does not incorporate the concept of agency or intentional action.
Algorithm: A step-by-step procedure or set of rules for solving a specific problem or performing a specific task.
Alignment: Refers to the process of bringing different components or elements into agreement or harmony.
Analogy: A comparison between two things or concepts based on their similarities in certain aspects.
Analytical Philosophy: A philosophical approach that emphasizes the analysis of concepts, language, and logical reasoning.
Anticipation: The act of predicting or expecting future events or outcomes.
Appraisal Theories of Emotion: Theories that propose emotions are influenced by evaluations or appraisals of situations or events.
Artificial: Pertaining to something that is human-made or constructed, as opposed to occurring naturally.
Attenuation of Response: The reduction or weakening of a response or reaction to a stimulus.
Attracting Set: In dynamical systems, a set of states towards which the system tends to converge or be attracted.
Augmented Reality: A technology that overlays virtual information or objects onto the real-world environment.
Autopoiesis: Refers to the phenomenon of a system maintaining and reproducing itself through self-organization and self-production of its components.
Bayes-Optimal Control: Control strategies or policies that are optimized based on Bayesian principles or probabilities.
Bayesian: Relating to or based on Bayesian probability theory, which involves updating beliefs or probabilities based on new evidence.
Bayesian Belief Updating: The process of revising or updating beliefs or probabilities based on new information using Bayesian inference.
Bayesian Brain: A theoretical framework suggesting that the brain operates based on Bayesian inference and probabilistic computations.
Bayesian Mechanics: An approach to physics that combines Bayesian inference with classical mechanics.
Bayesian Model Selection: The process of selecting the most appropriate model from a set of candidate models based on Bayesian inference.
Bayesian Surprise: A measure of the discrepancy between expected and actual outcomes, often used in Bayesian inference.
Bethe Approximation: A method for approximating probabilities and beliefs in graphical models or networks.
Blanket Index: An index or representation of the set of variables that are causally influenced by a particular variable in a graphical model.
Bottom-Up Attentional Control: The process of attentional selection that is driven by sensory input or stimuli from the external environment.
Categorical: Relating to or characterized by categories or distinct classes.
Category: A class or grouping of objects, events, or concepts based on shared characteristics or features.
Category Theory: A branch of mathematics that studies the general properties of categories and their relationships.
Changing Mind (Cognition): Refers to the process or act of changing one's cognitive processes, thoughts, or mental states.
Changing the Mind: The act of influencing or altering someone's thoughts, beliefs, or attitudes.
Changing the World: The act of making a difference or causing an impact on the external environment or society.
Changing World (Action): The process or act of taking action to effect change or modify the external world.
Chaos: A state of complex and unpredictable behavior that arises from deterministic nonlinear systems.
Circular Causality: A type of causality where cause and effect are interdependent and form a circular relationship.
Co-Category: A category that is defined in relation to another category or set of categories.
Coarse Graining: The process of reducing the level of detail or granularity in a system or model.
Cognitive Science: The interdisciplinary study of cognition, including processes such as perception, attention, memory, and problem-solving.
Cognitive System: Refers to the system or framework responsible for cognitive processes and functions, including perception, learning, and decision-making.
Cognitivism: A psychological theory or approach that emphasizes the study of mental processes, such as thinking, memory, and problem-solving.
Colimit: A concept in category theory that represents the limit or union of a collection of objects and morphisms.
Collective Behavior: Refers to the behavior of a group of individuals or entities acting in a coordinated or collective manner.
Conceptual Metaphor: A metaphorical understanding or representation of one concept or domain in terms of another concept or domain.
Conditional Density: The probability density function of a random variable given certain conditions or constraints.
Conditional Probability: The probability of an event or outcome given certain conditions or prior information.
Confidence: Refers to the degree of certainty or belief in the correctness or accuracy of a statement, decision, or belief.
Congruence: The state of agreement, harmony, or consistency between different elements or components.
Connectionism: A theoretical framework that views cognitive processes as emergent properties of interconnected neural networks.
Constraint: A limitation, restriction, or condition that must be satisfied or considered in a system or problem.
Continental Philosophy: A philosophical tradition that originated in continental Europe and emphasizes broader existential, social, and cultural issues.
Continuous State Space: A state space in which the possible states are represented by continuous variables.
Control (States): Refers to the ability to influence or regulate the states or variables of a system or process.
Control Theory: A mathematical framework for analyzing and designing systems that can be controlled or regulated.
Counterfactual: Referring to a hypothetical or alternative situation or event that is contrary to what actually happened.
Cybernetics: The interdisciplinary study of control and communication in systems, especially in complex systems and machines.
Decision-Making: The process of selecting or choosing a course of action or making a judgment or decision.
Deflationary: Referring to a viewpoint or theory that reduces or deflates the significance or meaning of a concept or statement.
Density: In probability theory, the density function represents the distribution of a random variable or the probability per unit of its value.
Deontic Action: An action or behavior that is morally or ethically prescribed or prohibited.
DeSci: Abbreviation for "Decision Science," which refers to the interdisciplinary field of study that combines psychology, economics, and other social sciences to understand and improve decision-making.
Development: The process of growth, maturation, or change in an organism, system, or concept over time.
Discrete State Space: A state space in which the possible states are represented by discrete or distinct values.
Dissipation: The process of losing energy or decreasing in magnitude or intensity over time.
Distribution: A mathematical function or representation that describes the probabilities or likelihoods of different outcomes or events.
Divergence: A measure of the difference or separation between two probability distributions or vectors.
Domain: Refers to a specific field, area, or subject of study or application.
Domain-Generality: The property or characteristic of a cognitive process or mechanism that operates across different domains or tasks.
Domain-Specificity: The property or characteristic of a cognitive process or mechanism that is specific to a particular domain or task.
Dynamic Causal Modelling: A statistical framework for analyzing the causal interactions between different brain regions or neural systems based on neuroimaging data.
Dynamic Expectation Maximization: An iterative optimization algorithm used to estimate parameters of a probabilistic model from incomplete or noisy data.
Dynamicism: A theoretical perspective that emphasizes the dynamic and interactive nature of cognition and behavior.
EcoEvoDevo: An abbreviation for "Ecology, Evolution, Development," referring to the integration of these three disciplines to understand biological phenomena.
Ecology: The study of the relationships between organisms and their environment, including the interactions between living organisms and their ecosystems.
Effective: Producing the intended or desired outcome or effect.
Effectivity: The degree or extent to which something is effective in achieving its purpose or goal.
Effectivity: The degree or extent to which something is effective in achieving its purpose or goal.
Embedded Embodied Encultured Enactive Inference: A framework that emphasizes the interplay between embodiment, culture, and active inference in shaping cognition.
Embodied Belief: The integration of beliefs or knowledge with the embodied experiences, actions, and perceptions of an individual.
Embodied Cybernetic Complexity: The complexity that arises from the interaction between embodied agents or systems and their environment.
Emotion: A complex psychological and physiological state characterized by subjective feelings, physiological changes, and behavioral responses.
Empirical Prior: A prior distribution or belief that is based on observed or empirical data.
Enactivism: A philosophical and cognitive science framework that emphasizes the role of embodied action and interaction in cognition and perception.
Entropy: A measure of the amount of uncertainty or randomness in a system or probability distribution.
Epistemic Foraging: The process of actively seeking and acquiring information or knowledge to reduce uncertainty or improve beliefs.
Ergodicity: A property of a system in which its statistical properties remain constant over time, allowing inferences based on a single trajectory.
Estimator: A statistical method or algorithm used to estimate unknown parameters or quantities from data.
Event-Related Potential: Electrophysiological brain responses that are time-locked to specific sensory, cognitive, or motor events.
Evolution: The process of change in living organisms over successive generations, driven by genetic variation, natural selection, and adaptation.
Expectation Maximization: An iterative algorithm used to estimate parameters of probabilistic models when there are missing or incomplete data.
Expected Utility Theory: A theory in decision theory and economics that models decision-making under uncertainty based on expected utility or value.
Experience of Body Ownership: The subjective sense or feeling of ownership and identification with one's own body.
Explaining Away: A phenomenon in which the evidence or observations that support one hypothesis diminish or explain away the support for another hypothesis.
Explanation: The process of providing reasons, justifications, or causal accounts for a phenomenon, event, or observation.
Extended Cognition: The idea that cognition is not confined to the brain but extends into the environment or external tools and artifacts.
Exteroception: Sensory perception or awareness of the external environment through the senses.
Factor Graph: A graphical model representation that depicts the factorization of a joint probability distribution into factors.
Falsification: The process of proving a hypothesis or theory false by providing evidence or observations that contradict it.
Far-From-Equilibrium: Referring to a system that is not in a state of thermodynamic equilibrium and is characterized by energy flow or dissipation.
Filter: A mechanism or process that selectively allows certain information, signals, or elements to pass through while blocking or attenuating others.
Fitness: In evolutionary biology, a measure of an organism's reproductive success or ability to survive and reproduce in a given environment.
Flow: A state of optimal engagement, concentration, and enjoyment experienced during a task or activity.
Fokker-Planck Equation: A partial differential equation used to describe the time evolution of probability distributions in stochastic processes.
Foraging: The search, acquisition, and collection of resources or information in an environment to meet specific needs or goals.
Forney: Refers to the work of Robert Forney, an information theorist known for his contributions to coding theory and graphical models.
Frequentist: Relating to the frequentist interpretation of probability, which focuses on the long-run frequency or proportion of events.
Friction: The resistance encountered when two objects move or slide against each other, resulting in the conversion of kinetic energy into heat.
Friston's Law: Refers to the principles and theories proposed by Karl Friston, a neuroscientist known for his work on active inference and predictive coding.
Functional Magnetic Resonance Imaging (fMRI): A neuroimaging technique that measures brain activity by detecting changes in blood oxygenation.
Functor: A mathematical concept that maps objects and morphisms from one category to another, preserving the structure and relationships.
Gauge Theory: A type of mathematical framework used in physics to describe fundamental forces and particle interactions.
Gaussian Distribution: A probability distribution that is symmetric and bell-shaped, characterized by its mean and variance.
Generalized Coordinates: In mechanics, a set of independent variables used to describe the configuration or state of a physical system.
Generalized Synchrony: A state in which different components or systems exhibit synchronized behavior but with variable phase relationships.
Generative Density: The probability distribution that represents the generative process or model of observed data.
Generative Modeling: The process of creating or learning a probabilistic model that generates or produces data similar to a given dataset.
Gestalt: A psychological concept that emphasizes the perception of wholes or organized structures rather than individual parts.
Goal-Driven Selection: The process of selectively attending to stimuli or information based on the relevance to a specific goal or task.
Gradient Descent: An optimization algorithm that iteratively adjusts the parameters of a model or function in the direction of steepest descent.
Graphical: Relating to or represented by graphs or graphical models, which use nodes and edges to depict relationships between variables.
Group Renormalization Theory: A theoretical framework in physics that describes the behavior of systems or phenomena at different scales.
Guidance Signal: A signal or cue that provides guidance or direction for an action or behavior.
Habit Learning/Formation: The process of acquiring or forming habits through repeated actions or experiences.
Hamilton's Principle of Least Action: A principle in physics stating that the path or trajectory of a system is determined by minimizing its action.
Helmholtz Decomposition: A mathematical technique that decomposes a vector field into its irrotational and solenoidal components.
Helmholtz Free Energy: A quantity in thermodynamics that combines the internal energy and the entropy of a system.
Helmholtz Machine: A type of generative model that combines a recognition model and a generative model to learn and represent data.
Hermeneutics: The theory and methodology of interpretation, especially in understanding texts, language, and cultural phenomena.
Hierarchically Mechanistic Mind: Referring to a conceptualization of the mind as a hierarchical system of mechanisms or processes that interact and influence each other.
1 / 1
High road	One of two roads (arguments) that lead to the Free Energy Principle as a possible conclusion which starts with philosophical questions about what properties a thing must have to "exist" (i.e. it must be measurable) and then uses principles of Autopoiesis and non-equilibrium Thermodynamic systems from a statistical perspective to show what kinds of systems could continue to maintain themselves over time (see Friston 2019: Beyond the Desert Landscape and the other road, the Low road ).

"The high road stands in for a top-down approach that starts by asking fundamental questions about the necessary properties things must possess if they exist. Using mathematical (variational) principles, once can then show that existence is an embodied exchange of a creatures with its environment - that necessarily entails predictive processing as one aspect of self-evidencing mechanics."		The High road to the Free Energy Principle starts by talking about random Non-linear dynamical systems in general without a specific focus on biological organisms with brains.	You take the High road and I'll take the low road.	The High road connects a number of different fields together, drawing from concepts of Autopoiesis and self-organization within random Non-linear dynamical systems who are proposed to be in Non-Equilibrium Steady State with respect to the environment. Under certain Ergodicity assumptions about such systems it is possible to show how the Free Energy Principle arises.
Homeostasis					
Homeostatic system					
Hyperprior					
Hypothesis					
Inflationary					
Information bottleneck					
Instrumentalism					
intelligence					
Interface					
Interoception					
Interoceptive sensitivity					
Interpretation					
Inverse problem					
Kullback-Leibler Divergence					
Lagrangian					
Latent cause					
Lateral geniculate nucleus					
Least action					
Lens					
Likelihood					
link					
Low road 	One of two roads (arguments) that lead to the Free Energy Principle as a possible conclusion which starts with fundamental questions from neuroscience and psychology about the nature of perception in biological organisms within a changing environment (see Friston 2019: Beyond the Desert Landscape and the other road, the High road ).

"The low road is to pursue the agenda established by Kant and Helmholtz to generalize - in a bottom up way - the capacity for inference and prediction to see how far it takes us in understand embodied exchange with the environment."		The Low road  to the Free Energy Principle starts by looking at how biological organisms perceive their environment and take actions within it to develop a notion about how they can successfully predict the next state they will be in (Perception as Hypothesis testing). 	Be careful, the Low road  can be dangerous.	
Marginal approximation					
Markovian Monism	 Markovian Monism 				
Marr's Levels of Description					
matching					
Material science					
maximum caliber					
Mean					
Mean field approximation
1 / 1
ChatGPT
ChatGPT
High Road: One of the two roads or arguments that lead to the Free Energy Principle. It takes a top-down approach by asking fundamental questions about the necessary properties of things that exist and uses mathematical principles to show that existence involves predictive processing and embodied exchange with the environment.
Homeostasis: The tendency of a system to maintain internal stability and balance through self-regulatory mechanisms.
Homeostatic System: A system that maintains homeostasis by regulating its internal variables or states to keep them within a certain range.
Hyperprior: In the context of the Free Energy Principle, a higher-level prior belief or distribution that shapes the lower-level priors or beliefs.
Hypothesis: A proposed explanation or conjecture based on limited evidence or reasoning, subject to testing and verification.
Inflationary: Relating to inflation, which refers to a rapid and sustained increase in the general price level of goods and services in an economy.
Information Bottleneck: A concept from information theory that refers to finding a compressed representation of input data while retaining relevant information.
Instrumentalism: A philosophical position that emphasizes the practical usefulness or utility of theories or concepts rather than their truth or correspondence to reality.
Intelligence: The ability to acquire, understand, apply knowledge, and adapt to new situations effectively.
Interface: The boundary or point of interaction between two systems, allowing communication or exchange of information.
Interoception: The sense or perception of internal bodily sensations and processes, such as heartbeat, breathing, and hunger.
Interoceptive Sensitivity: The degree or accuracy with which an individual perceives and attends to their internal bodily sensations.
Interpretation: The act of assigning meaning, significance, or understanding to something, such as a text, event, or experience.
Inverse Problem: A problem in which the desired outcome or solution is known, but the process or inputs that produced it are unknown.
Kullback-Leibler Divergence: A measure of the difference or divergence between two probability distributions.
Lagrangian: In physics, a function that describes the dynamics of a system and is used to derive equations of motion.
Latent Cause: A hidden or unobserved factor or variable that influences or generates observed effects or outcomes.
Lateral Geniculate Nucleus: A relay center in the thalamus of the brain that receives and processes visual information from the retina.
Least Action: Refers to Hamilton's Principle of Least Action, which states that the path followed by a system between two points minimizes the action.
Lens: An optical device that refracts light to converge or diverge it, commonly used in vision correction or imaging systems.
Likelihood: In statistics, the probability of observing a given set of data or evidence under a specific hypothesis or model.
Link: A connection or relationship between two or more entities or concepts.
Low Road: One of the two roads or arguments that lead to the Free Energy Principle. It takes a bottom-up approach by examining the nature of perception in biological organisms and their ability to predict and interact with the environment.
Marginal Approximation: An approximation or estimation of a probability distribution by considering only a subset of variables or dimensions.
Markovian Monism: A concept or perspective that combines the ideas of Markov processes and monism, which posits a fundamental unity or oneness of reality.
Marr's Levels of Description: A framework proposed by David Marr that describes three levels of analysis in understanding information processing systems: computational, algorithmic, and implementational.
Matching: The process of aligning or finding correspondence between different entities or patterns.
Material Science: A field of science that studies the properties, behavior, and applications of materials, including their structure and composition.
Maximum Caliber: A principle or approach in statistical physics that seeks to find the most likely probability distribution consistent with given constraints or constraints that maximize entropy.
Mean: In statistics, the arithmetic average of a set of values, calculated by summing the values and dividing by the number of values.
Mean Field Approximation: A technique in statistical physics that simplifies the description of a complex system by assuming that each component interacts with an average or mean effect from the rest of the system.
1 / 1
Memory					
Message Passing					
Mismatch negativity					
Mode					
Model					
Model accuracy					
model evidence					
Model Inversion	Model Inversion 				
Monad					
morphism					
Morphogenesis					
Multisensory integration					
Natural					
Nested					
Network					
Neuronal Ensemble					
Niche construction					
Noisy signal					
Non-linear dynamical systems					
normative					
Optimal control					
overfitting					
Partially Observed Markov Decision Process					
Partition					
path					
Path integral					
Path of Least Action					
phenotype					
Policy posterior					
Policy prior					
population					
Precariousness					
Precision					
Prediction error					
Prediction error minimization					
Predictive Coding					
predictive machine					
Predictive Processing					
Principle	Principle 				
Probability distribution					
Proprioception					
Quantum					
Quantum mechanics					
Quantum-like					
Qubit					
Random variable					
Realism	Realism 				
Receptive field					
Recognition density					
Renormalization					
Representationalism					
Reservoir Computing					
Reward					
Risk 	Risk  				
Sample space					
Selection bias					
Selection history					
Self-organization 					
Selfhood					
Semi-Markovian					
Sense of agency					
Sensorimotor					
Sensory attenuation					
Sensory Data					
Sensory input					
Sensory observation					
Sensory outcome					
Sensory State					
Sensory states					
Sentience	being ''responsive to sensory impressions'' through adaptive internal processes				
Shared Generative Model 					
Signal					
Simulation					
solenoidal					
Sophisticated Inference					
spike-timing dependent plasticity					
Statistical manifold					
Statistical Parametric Mapping
1 / 1
ChatGPT
ChatGPT
Memory: The ability to retain and recall information or experiences over time.
Message Passing: The process of communication or information exchange between different components or entities within a system.
Mismatch Negativity: A neurophysiological response in the brain that occurs when an expected stimulus is different or deviates from the predicted pattern.
Mode: The most frequently occurring value or category in a dataset or probability distribution.
Model: A representation or description of a system, process, or phenomenon used to understand, predict, or simulate its behavior.
Model Accuracy: The degree to which a model's predictions or outputs match the true or observed values in a given dataset or scenario.
Model Evidence: The amount of support or information provided by data in favor of a particular model or hypothesis.
Model Inversion: The process of inverting or reversing a model to infer the inputs or causes that could produce a given output or observation.
Monad: In category theory, a mathematical structure representing a type of computation or transformation.
Morphism: In category theory, a structure-preserving map or transformation between two mathematical objects.
Morphogenesis: The process of biological development or growth, particularly the formation of complex structures and patterns.
Multisensory Integration: The integration and combination of information from multiple sensory modalities (e.g., vision, hearing, touch) to form a unified percept or understanding.
Natural: Relating to or characteristic of nature, occurring in the absence of human intervention or artificial influence.
Nested: A structure or system that is embedded or contained within another structure or system.
Network: A system or collection of interconnected elements or nodes that exchange information or interact with each other.
Neuronal Ensemble: A group or population of neurons that work together to perform a specific function or computation.
Niche Construction: The process by which organisms actively modify their environment to create a niche or favorable conditions for their own survival and reproduction.
Noisy Signal: A signal or data that is corrupted or affected by random or unwanted variations or disturbances.
Non-linear Dynamical Systems: Dynamical systems that exhibit non-linear relationships or behaviors, often characterized by sensitivity to initial conditions and the emergence of complex patterns.
Normative: Relating to norms or standards, representing how things should be or what is considered typical or desirable.
Optimal Control: The problem of finding the control inputs or actions that optimize a certain objective or performance measure in a dynamic system.
Overfitting: A phenomenon in machine learning where a model becomes too specific or closely fits the training data, resulting in poor generalization to new, unseen data.
Partially Observed Markov Decision Process: A mathematical framework used to model decision-making problems where the system dynamics are influenced by both random processes and partial observations of the system state.
Partition: The division or separation of a whole into distinct parts or subsets.
Path: A trajectory or sequence of states or events that describes the evolution or progression of a system.
Path Integral: A mathematical tool used in quantum mechanics and statistical physics to compute the probability of different paths or trajectories of a system.
Path of Least Action: In physics, the path followed by a system between two points that minimizes the action or overall energy.
Phenotype: The observable traits, characteristics, or properties of an organism, resulting from the interaction between its genes and the environment.
Policy Posterior: In decision-making or reinforcement learning, the updated probability distribution over possible actions based on new observations or information.
Policy Prior: The initial or prior belief or distribution over possible actions in decision-making or reinforcement learning.
Population: A group or collection of individuals or entities that share common characteristics or are subject to study or analysis.
Precariousness: The state or condition of being uncertain, unstable, or vulnerable to change or failure.
Precision: In statistics, a measure of the degree of exactness or refinement in a measurement or estimate.
Prediction Error: The discrepancy or difference between the predicted or expected outcome and the actual observed outcome.
Prediction Error Minimization: The process of reducing or minimizing the discrepancy between predicted and observed outcomes in order to improve the accuracy or performance of a model or system.
Predictive Coding: A computational framework or theory of brain functioning that suggests the brain generates predictions about sensory input and updates these predictions based on prediction errors.
Predictive Machine: A machine or system that uses predictive modeling or algorithms to make predictions or forecasts about future events or states.
Predictive Processing: A theoretical framework in cognitive science and neuroscience that proposes the brain operates by continuously generating and updating predictions about sensory input.
Principle: A fundamental truth, law, or rule that guides or governs a system, process, or behavior.
Probability Distribution: A mathematical function that describes the likelihood of different outcomes or events occurring.
Proprioception: The sense or perception of the position, movement, and orientation of one's own body and body parts.
Quantum: Relating to quantum mechanics, a branch of physics that describes the behavior of matter and energy at the smallest scales.
Quantum Mechanics: The theory of physics that describes the behavior and interactions of particles at the quantum or subatomic level.
Quantum-like: Referring to phenomena or models that exhibit properties resembling those of quantum mechanics, even in non-quantum systems.
Qubit: A unit of information in quantum computing, analogous to a classical bit but representing a quantum state that can exist in superposition or entanglement.
Random Variable: A variable whose value is subject to randomness or uncertainty, often used to represent the outcomes of probabilistic events or processes.
Realism: A philosophical position or perspective that asserts the existence of an objective reality independent of human perception or interpretation.
Receptive Field: In neuroscience, the specific region of sensory space or the sensory organ that influences the activity of a particular neuron.
Recognition Density: The density or concentration of neural activity or responses associated with the recognition or perception of specific stimuli or patterns.
Renormalization: A technique in physics and mathematics used to analyze or describe systems at different scales by integrating or combining information from smaller scales into larger scales.
Representationalism: The philosophical view that mental states or perceptions are representations of external objects or states of affairs.
Reservoir Computing: A computational paradigm or approach that uses fixed, randomly connected networks (reservoirs) to perform tasks such as signal processing or prediction.
Reward: A positive or negative reinforcement signal or feedback used in reinforcement learning or decision-making to guide behavior or optimize performance.
Risk: The probability or likelihood of experiencing harm, loss, or negative consequences in relation to a particular event or action.
Sample Space: The set of all possible outcomes or events in a statistical or probabilistic experiment.
Selection Bias: A bias or distortion introduced in a study or analysis when certain individuals or cases are systematically more likely to be included or excluded.
Selection History: The past sequence of events or actions that have influenced the current state or characteristics of a system or population.
Self-organization: The process by which order, patterns, or structures spontaneously emerge in a system without external direction or control.
Selfhood: The state or quality of having a sense of individuality, self-awareness, or self-identity.
Semi-Markovian: Referring to a stochastic process or model in which the time spent in each state can be variable and dependent on the previous state.
Sense of Agency: The subjective feeling or experience of being in control of one's own actions and the consequences they produce.
Sensorimotor: Relating to the integration of sensory input and motor output, particularly in the context of perception and action.
Sensory Attenuation: The reduction or suppression of sensory perception or responsiveness to self-generated or predictable stimuli.
Sensory Data: Information or input acquired through sensory organs or systems, such as vision, hearing, touch, etc.
Sensory Input: The information or stimuli received by sensory organs or systems from the external environment or the body itself.
Sensory Observation: The process of perceiving, detecting, or registering sensory stimuli or events through the senses.
Sensory Outcome: The result or consequence of sensory processing or perception, often leading to motor actions or further cognitive processing.
Sensory State: The specific configuration or pattern of sensory inputs or signals at a given moment or time point.
Sensory States: The various possible configurations or patterns of sensory inputs or signals that a system or organism can experience or perceive.
Sentience: The capacity or quality of being responsive to sensory impressions and exhibiting adaptive internal processes.
Shared Generative Model: In machine learning or Bayesian inference, a model that is used by multiple agents or entities to generate or predict data.
Signal: A measurable or detectable event, pattern, or stimulus that carries information or conveys a message.
Simulation: The imitation or representation of the behavior or characteristics of a system or process through the use of a computer program or model.
Solenoidal: Referring to a vector field that has zero divergence, meaning the field's flux is conserved within a closed surface.
Sophisticated Inference: Complex or advanced reasoning or inference processes that involve the integration of multiple sources of information or knowledge.
Spike-Timing Dependent Plasticity: A type of synaptic plasticity in neural networks where the strength of the connection between neurons is modified based on the precise timing of their spikes or action potentials.
Statistical Manifold: In differential geometry and statistics, a mathematical space that represents the set of probability distributions or models associated with a given dataset or parameter space.
Statistical Parametric Mapping: A technique used in neuroscience and image analysis to analyze brain images or other spatial data by comparing them to a statistical model or reference.
These definitions should provide you with a good understanding of the terms you requested. Let me know if you have any more questions!
1 / 1
Stigmergy					
Stochastic					
Subjective feeling states					
sufficient statistic					
Surprisal					
Swarm					
Symbol					
Synergetics					
T-Maze					
Teams					
Theory					
Thermodynamic system					
Thermostatistics					
Thing					
Thinking Through Other Minds					
time					
Top-down attentional control					
tracking					
Umwelt					
Unidirectionality					
Update					
Variance					
Variational message passing					
Variational Niche Construction					
Variational principle					
Von Economo neurons 					
Weak mixing					
Working memory					
World States					
					
Cue	a Stimulus , event,  object , or Guidance signal  that serves to guide Behavior , such as a retrieval cue, or that acts as a @Signal to the presentation of another stimulus, event, or object, such as an unconditioned stimulus or reinforcement. (dictionary.apa.org)				Approach to discussing Symbol in the Niche and social Culture patterns. 
Information Geometry	A Statistical manifold  each of whose points corresponds to a Probability distribution (e.g. the expectation and variance of a normal density).				
Action Prediction	Inference on current and future Expectation  of Action		The Generative Model over the next few timesteps with respect to Active States , is the Action Prediction .	The Agent inferred what Affordances it had, this process is known as Action Planning or Action Prediction .	Action Prediction is an enabling factor for Action Planning  and Policy selection 
Process Theory	A hypothesis or Model proposal for how a Principle is realized (e.g. the Free Energy Principle)	A Model of the dynamics of a Thing, one that describes the process of development and change. 	Friston in 2018 wrote "The distinction is between a State [theory] and Process Theory ; i.e., the difference between a normative principle that things may or may not conform to, and a Process Theory  or hypothesis about how that principle is realized"		
Variational	Biologically: Said of the behavior of a Neuronal Ensemble that minimizes the error of quantities selected by that ensemble, by implementing an algorithm that approximates calculus of variations.	Mathematically: Using calculus of variationsto find functions that optimize the values of quantities that depend on those functions.			
Hidden State	Unobserved variable in Bayesian Inference , can reflect a Latent cause . 				
Culture	Culture is the Niche for social Agent, that structures their Regime of Attention 				
Narrative	Information used by Agent in context of entity- and event-oriented Cognition, specifically Hierarchical Model (Hierarchically Mechanistic Mind ).    			I wrote a Narrative about my time in graduate school.	
Novelty 	The Internal State assumed by an Agent's epistemic Affordance, when unable to immediately (e.g. locally) resolve Uncertainty about the contingencies — i.e. the opportunity to resolve Uncertainty about 'what would happen if I did that?' (The Precision of this assumed Internal State has a distinctive, e.g. multimodal, distribution, i.e. exhibits Ambiguity .)			Candy and ice cream are kinds of Novelty  foods. 	
Regime of Attention	feedback mechanisms among practices in a Culture of scaffolding individuals' Attention, that guide Agents' style of Attention; act as determined by bodily, language, and contextual Cues in a given community; and are encoded in higher levels of the cortical hierarchy.
1 / 1
ChatGPT
ChatGPT
Stigmergy: A mechanism of indirect coordination or communication among individuals in a decentralized system, where the individuals modify their environment in response to cues left by others.
Stochastic: Pertaining to or characterized by randomness or probability, often used to describe processes or events that involve uncertainty.
Subjective Feeling States: The internal, subjective experiences or states of an individual, such as emotions, moods, or sensations.
Sufficient Statistic: In statistics, a function or summary of a dataset that contains all the relevant information about a parameter of interest, such as a mean or variance.
Surprisal: A measure of the unexpectedness or information content of an event or message, often quantified using concepts from information theory.
Swarm: A collective of individuals or agents that interact locally and exhibit coordinated behavior or emergent properties, often inspired by the behavior of social insects like ants or bees.
Symbol: A representation or sign that stands for or represents something else, often used in the context of language or communication.
Synergetics: The study of cooperative or collective behavior in complex systems, focusing on the emergence of order and patterns from the interactions of individual components.
T-Maze: A simple experimental setup or apparatus in neuroscience and psychology consisting of a T-shaped maze used to study animal behavior and decision-making.
Teams: Groups of individuals working together toward a common goal or objective, often characterized by cooperation, collaboration, and division of labor.
Theory: A systematic and coherent set of principles, concepts, or explanations that explain or predict a phenomenon or a set of phenomena.
Thermodynamic System: A physical system that is the subject of study in the field of thermodynamics, which deals with the relationships between heat, work, energy, and temperature.
Thermostatistics: The branch of physics that deals with the statistical mechanics and thermodynamics of systems composed of a large number of particles.
Thing: A general term referring to an object, entity, or concept that can be perceived, observed, or discussed.
Thinking Through Other Minds: The process of attempting to understand or empathize with the thoughts, perspectives, and experiences of other individuals.
Time: The dimension or concept that represents the sequence of events, the duration of processes, or the progression of phenomena.
Top-Down Attentional Control: The process by which attention is directed or guided by higher-level cognitive processes, expectations, or goals.
Tracking: The act or process of following, monitoring, or tracing the movements, changes, or characteristics of a target or object of interest.
Umwelt: A concept from ethology and biology that refers to the subjective or perceptual world experienced by an organism, shaped by its sensory abilities and ecological niche.
Unidirectionality: The characteristic or property of being unidirectional, meaning that a process or relationship occurs or operates in one direction or has a one-way causal influence.
Update: The act or process of revising, modifying, or incorporating new information or data into a model, system, or belief.
Variance: In statistics, a measure of the dispersion or variability of a dataset or distribution, often calculated as the average of the squared deviations from the mean.
Variational Message Passing: A computational method or algorithm used to approximate probabilistic inference in graphical models by iteratively passing messages between nodes.
Variational Niche Construction: The process by which organisms modify or shape their environment through their activities and behaviors, creating a niche that influences their own future development or evolution.
Variational Principle: In physics and mathematics, a principle that states that the behavior or properties of a system can be determined by finding the extremum (minimum or maximum) of a particular mathematical expression or functional.
Von Economo Neurons: Specialized neurons found in specific regions of the brain, such as the anterior cingulate cortex and frontoinsular cortex, believed to be involved in social cognition and higher-order processing.
Weak Mixing: In mathematics and dynamical systems theory, a property of a system or transformation that ensures a sufficient level of randomness or unpredictability in the mixing of different states or trajectories.
Working Memory: The cognitive system or mental workspace that temporarily holds and manipulates information in an active state for use in ongoing tasks or processing.
World States: The possible or actual configurations, conditions, or arrangements of the world or a system at a particular point or period in time.
Cue: A stimulus, event, object, or guidance signal that serves to guide behavior or provide information, such as a retrieval cue or a signal for the presentation of another stimulus.
Information Geometry: The study of geometric structures and properties associated with statistical manifolds, where each point represents a probability distribution.
Action Prediction: The process of inferring or predicting the current and future expectations of action, often based on the active states and generative models of an agent.
Process Theory: A hypothesis or model proposal that explains how a principle or phenomenon is realized through dynamic processes and mechanisms.
Hidden State: An unobserved variable in Bayesian inference that may reflect a latent cause or factor influencing observed data or outcomes.
Culture: The shared beliefs, values, customs, practices, and behaviors that characterize a particular group, community, or society.
Narrative: Information used by an agent in the context of entity- and event-oriented cognition, often structured in the form of hierarchical models or narratives.
Novelty: The internal state assumed by an agent's epistemic affordance when facing uncertainty or encountering unfamiliar or unexpected situations.
Regime of Attention: The feedback mechanisms and cultural practices that shape and guide an individual's style of attention, influenced by bodily, linguistic, and contextual cues within a specific community.
I hope these definitions help clarify the terms you mentioned. Let me know if there's anything else I can assist you with!
1 / 1
active					
area					
backbone					
brain					
causality					
classical physics					
computer					
concentration					
concept					
condition					
consensus					
conversation					
current					
default-mode					
dynamics					
ecosystem					
ego					
energy					
environment					
error					
feedback					
field					
framework					
free	For no cost.	Able to be liberated. 			
genetic					
hierarchical					
idea					
increase					
influence					
interpretation					
inverse					
language					
Logic					
machine					
matrix					
neuronal					
object					
objective					
observer					
Ontology-to-Model Link					
opportunity					
parameter					
part					
perceptual inference					
perspective					
phase					
physics					
play					
probability					
Probably Approximately Correct					
problem					
propositional					
Propositional attitude					
Psychological attitude					
purpose					
question					
random					
recognition					
relative entropy	Synonym for Kullback-Leibler Divergence 	relative entropy 			
represents 	SUMO relation (represents ?THING ?ENTITY) means that ?THING in some way indicates, expresses, connotes, pictures, describes, etc. ?ENTITY. The Predicates containsInformation and realization are subrelations of represents.				
resource					
role					
science					
selection					
self-organization					
situation					
social					
states					
Stimulus					
technology					
trajectory					
transition					
tree					
understanding					
witness
1 / 1
ChatGPT
ChatGPT
Active: Engaged in action, movement, or participation.
Area: A distinct or defined space or region within a larger context or physical layout.
Backbone: The central or fundamental support or structure of a system or organization.
Brain: The complex organ in the head of vertebrates that serves as the center of the nervous system, responsible for cognition, perception, consciousness, and control of bodily functions.
Causality: The relationship between cause and effect, where one event or factor brings about, determines, or influences another.
Classical Physics: The branch of physics that deals with the laws and principles governing macroscopic objects and systems, prior to the development of quantum mechanics and relativity.
Computer: An electronic device capable of storing, processing, and retrieving data or information through programmable instructions.
Concentration: The focused attention or mental effort directed toward a particular task, object, or subject.
Concept: An abstract or general idea that represents a category, class, or understanding of something.
Condition: The state or circumstances in which something exists or occurs, often influencing its behavior, functioning, or outcome.
Consensus: General agreement or harmony among a group of individuals or parties regarding a particular matter or decision.
Conversation: An exchange of ideas, thoughts, or information through verbal or written communication between two or more people.
Current: The flow of electric charge or the movement of fluid, such as air or water, in a particular direction.
Default-Mode: A term commonly used in neuroscience to describe a network of brain regions that are active during rest or when not engaged in specific tasks.
Dynamics: The study of forces, motions, and patterns of change in systems over time.
Ecosystem: A community of living organisms (plants, animals, microorganisms) and their physical environment, interacting as a complex and interconnected system.
Ego: The individual's sense of self or personal identity, often associated with self-awareness, self-esteem, and self-concept.
Energy: The capacity or ability to do work, transform or transfer heat, or produce an effect.
Environment: The surroundings, conditions, or external factors that influence and interact with an organism, system, or process.
Error: A mistake, deviation, or discrepancy between an expected or desired outcome and the actual result or observation.
Feedback: Information or signals that are returned to a system or process, often used to regulate or modify its behavior or output.
Field: A region or space in which a physical quantity or phenomenon is present or operates, such as an electromagnetic field or a gravitational field.
Framework: A structure or conceptual framework that provides support, organization, or guidance for understanding, analyzing, or solving a problem or issue.
Free: Without cost or payment. Also, the ability to act or make choices without being constrained or restricted.
Genetic: Pertaining to genes, inheritance, or the study of heredity and variation in living organisms.
Hierarchical: Arranged in a hierarchical or graded structure, where different levels or ranks have varying degrees of importance, authority, or control.
Idea: A thought, concept, or mental representation of something that can be formed in the mind.
Increase: To become larger, greater, or more numerous in quantity, size, intensity, or degree.
Influence: The power, effect, or impact that one thing or person has on another, often shaping or modifying their behavior, opinions, or decisions.
Interpretation: The act or process of explaining, understanding, or assigning meaning to something, often based on personal understanding or perspective.
Inverse: The opposite or reverse of a particular relationship, operation, or condition.
Language: A system of communication consisting of sounds, words, or symbols used by humans to express thoughts, ideas, and emotions.
Logic: The study or system of valid reasoning, rationality, or principles governing correct inference and argumentation.
Machine: A mechanical or electronic device designed to perform specific tasks, functions, or processes.
Matrix: A rectangular arrangement or grid of elements, often used to represent data, information, or relationships.
Neuronal: Relating to or involving neurons, the basic units of the nervous system responsible for transmitting and processing information.
Object: A physical entity or thing that can be observed, perceived, or manipulated.
Objective: Based on facts, evidence, or external reality, independent of personal opinions, biases, or interpretations.
Observer: A person or entity that perceives, watches, or takes note of events, objects, or phenomena.
Ontology-to-Model Link: A connection or mapping between the philosophical study of existence and reality (ontology) and the representation or abstraction of that knowledge in a model.
Opportunity: A favorable or advantageous circumstance, occasion, or chance for action or achievement.
Parameter: A measurable or variable factor that defines or characterizes a system, process, or phenomenon.
Part: A component or constituent element of a larger whole or system.
Perceptual Inference: The process by which the brain and mind make inferences or judgments about the environment based on sensory information and prior knowledge.
Perspective: A particular point of view, standpoint, or interpretation shaped by one's experiences, beliefs, or understanding.
Phase: A distinct stage, period, or state of a process, system, or phenomenon.
Physics: The branch of science that deals with the fundamental principles, properties, and behavior of matter, energy, and the interactions between them.
Play: Engaging in activities for enjoyment, amusement, or recreation, often involving imagination, creativity, and participation.
Probability: The likelihood or chance of a specific event or outcome occurring, often expressed as a number between 0 and 1.
Probably Approximately Correct: A concept in machine learning and computational learning theory, where an algorithm or model aims to provide an approximation of correct answers or predictions with a high probability.
Problem: A matter or situation that requires resolution, analysis, or solution.
Propositional: Relating to propositions or statements that express facts, assertions, or logical relationships between concepts or variables.
Propositional Attitude: A mental state or disposition toward a proposition, such as belief, doubt, or disbelief.
Psychological Attitude: An individual's mental state, disposition, or inclination that influences their thoughts, emotions, and behavior.
Purpose: The reason, intention, or objective behind an action, goal, or existence.
Question: An inquiry, request for information, or challenge posed to seek clarification, knowledge, or understanding.
Random: Without a pattern, predictable order, or specific cause, occurring by chance or probability.
Recognition: The act or process of identifying, remembering, or acknowledging someone or something based on prior knowledge or familiarity.
Relative Entropy: Synonymous with Kullback-Leibler Divergence, a mathematical measure of the difference between two probability distributions.
Represents: In the context of SUMO (Suggested Upper Merged Ontology), a relation indicating that one thing in some way indicates, expresses, connotes, or describes another entity.
Resource: A source, supply, or reserve of something that can be utilized, allocated, or consumed to achieve a particular purpose.
Role: A socially or functionally defined position or function that an individual or entity assumes within a system, organization, or society.
Science: The systematic study of the natural and physical world through observation, experimentation, and the formulation of testable explanations or theories.
Selection: The act or process of choosing, picking, or making a decision among options or alternatives based on certain criteria or preferences.
Self-Organization: The spontaneous emergence of order, structure, or patterns in a system without external influence or control, often driven by internal interactions or dynamics.
Situation: The particular set of circumstances, conditions, or factors surrounding a person, event, or system at a given moment.
Social: Pertaining to human society, relationships, interactions, or behaviors within a community or group.
States: Conditions or modes in which something exists, operates, or can be described.
Stimulus: A specific event, signal, or input that elicits or triggers a response or reaction in an organism or system.
Technology: The application of scientific knowledge, tools, and techniques to practical purposes, often involving the development or utilization of machinery, equipment, or devices.
Trajectory: The path or course followed by an object, system, or process through space or time.
Transition: The process or period of change, transformation, or movement from one state, condition, or form to another.
Tree: A woody perennial plant with a long trunk, branches, and leaves, typically living for many years and often reaching a considerable height.
Understanding: The ability to comprehend, interpret, or grasp the meaning, significance, or nature of something based on knowledge, experience, or insight.
Witness: A person who observes, sees, or has direct knowledge of an event, incident, or situation, often providing testimony or evidence based on their perception or experience.
1 / 1
Put these in the proper format with  word: definition

Temporal Depth refers to the length of a time window or horizon considered in deep temporal models.
Uncertainty is the measure of unpredictability or expected surprise associated with a random variable.
Action is the dynamics, mechanisms, and measurements of behavior, involving active states enacted by an agent through policy selection.
Action planning is the process of an agent selecting an affordance based on inference of expected free energy.
Agency refers to the ability of an agent to engage in action and enact goal-driven selection based on preference.
Behavior is the sequence of actions that an agent enacts.
Policy is a sequence of actions reflected by a series of active states and implemented in policy selection.
Policy selection is the process of an agent engaging in action planning based on the minimization of expected free energy.
Preference is a parameter that ranks or scores the extent to which an agent values sensory input.
Active inference is a process theory related to the free energy principle that involves perception, cognition, and action.
Epistemic value refers to the value of information gain or reduction in uncertainty about a state with respect to a policy.
Expected free energy is a measure used for inference on action over a given time horizon.
Free energy is an information theoretic quantity that constitutes an upper bound on surprisal.
The free energy principle is a generalization of predictive coding that organisms minimize the entropy of sensory input.
Generalized free energy is the combination of past variational free energy and future expected free energy.
Pragmatic value is the benefit to an organism of a given policy or action measured in terms of alignment with preferences.
Variational free energy is a measure that computes an upper bound on surprisal of a generative model given data.
Active states are the outgoing influence of policy selection in the Friston Blanket formalism.
Blanket state is a set of states that make internal and external states conditionally independent.
External state is a state with conditional density independent from the internal state, conditioned on the blanket state.
Friston Blanket is a Markov blanket with partitioned active states and sense state.
Internal state is a state with conditional density independent from the external state, conditioned on the blanket state.
Markov blanket is a model of a system that reflects an agent delineated from the niche via an interface.
Markov decision process is a Bayesian inference model where the agent's generative model can implement policy selection.
Sense state is the incoming sensory input in the Friston Blanket formalism.
Affordance refers to options or capacities for action by an agent.
An agent is an entity modeled by active inference with an internal state separated from the external state by a blanket state.
Cognition refers to an agent modifying the weights of its internal state for action planning and belief updating.
Ensemble is a group of more than one agent.
1 / 1
ChatGPT
ChatGPT
Temporal Depth: The length of a time window or horizon considered in deep temporal models.
Uncertainty: The measure of unpredictability or expected surprise associated with a random variable.
Action: The dynamics, mechanisms, and measurements of behavior, involving active states enacted by an agent through policy selection.
Action planning: The process of an agent selecting an affordance based on inference of expected free energy.
Agency: The ability of an agent to engage in action and enact goal-driven selection based on preference.
Behavior: The sequence of actions that an agent enacts.
Policy: A sequence of actions reflected by a series of active states and implemented in policy selection.
Policy selection: The process of an agent engaging in action planning based on the minimization of expected free energy.
Preference: A parameter that ranks or scores the extent to which an agent values sensory input.
Active inference: A process theory related to the free energy principle that involves perception, cognition, and action.
Epistemic value: The value of information gain or reduction in uncertainty about a state with respect to a policy.
Expected free energy: A measure used for inference on action over a given time horizon.
Free energy: An information theoretic quantity that constitutes an upper bound on surprisal.
Free energy principle: A generalization of predictive coding that organisms minimize the entropy of sensory input.
Generalized free energy: The combination of past variational free energy and future expected free energy.
Pragmatic value: The benefit to an organism of a given policy or action measured in terms of alignment with preferences.
Variational free energy: A measure that computes an upper bound on surprisal of a generative model given data.
Active states: The outgoing influence of policy selection in the Friston Blanket formalism.
Blanket state: A set of states that make internal and external states conditionally independent.
External state: A state with conditional density independent from the internal state, conditioned on the blanket state.
Friston Blanket: A Markov blanket with partitioned active states and sense state.
Internal state: A state with conditional density independent from the external state, conditioned on the blanket state.
Markov blanket: A model of a system that reflects an agent delineated from the niche via an interface.
Markov decision process: A Bayesian inference model where the agent's generative model can implement policy selection.
Sense state: The incoming sensory input in the Friston Blanket formalism.
Affordance: Options or capacities for action by an agent.
Agent: An entity modeled by active inference with an internal state separated from the external state by a blanket state.
Cognition: An agent modifying the weights of its internal state for action planning and belief updating.
Ensemble: A group of more than one agent.
1 / 1
I think tree is supposed to be in the context of active inference.
1 / 1
ChatGPT
ChatGPT
I apologize for the oversight. Here's the revised entry:
Tree: In the context of active inference, a tree refers to a hierarchical structure that represents the generative model of an agent's environment. It captures the causal dependencies between variables and their conditional relationships, allowing for efficient inference and prediction. The tree structure helps organize and represent the complexity of the agent's world, enabling effective decision-making and action planning.
1 / 1
a definition without using the word "tree"
1 / 1
ChatGPT
ChatGPT
Hierarchical Structure: In the context of active inference, a hierarchical structure refers to an organizational framework that captures the nested relationships and dependencies between variables in an agent's generative model. It represents the hierarchical nature of the agent's environment, where higher-level variables are influenced by lower-level variables. This structure allows for efficient information processing, inference, and decision-making, as it enables the agent to reason and make predictions at different levels of abstraction.
1 / 1
No I mean define tree, but without using it in the definition
1 / 1
ChatGPT
ChatGPT
Branching Structure: In graph theory and computer science, a tree refers to a type of branching structure composed of interconnected nodes or vertices. It exhibits a hierarchical organization without cycles or loops, where each node has a unique parent node except for the root node. The nodes in a tree are connected by edges, representing the relationships or dependencies between them. Trees are often used as data structures for organizing and representing hierarchical relationships, such as in hierarchical clustering algorithms or decision trees used in machine learning.
1 / 1
Definition of tree, but don't use that word in the definition
1 / 1
ChatGPT
ChatGPT
Branching Structure: A tree is a type of graph where each element is connected to other elements in a way that forms a hierarchical network without cycles. It consists of interconnected nodes that exhibit a parent-child relationship, with each node having only one parent except for the root node. The nodes are linked by edges, representing the connections or dependencies between them. Trees are commonly used in various fields to represent hierarchical relationships, such as in data structures, decision-making processes, and evolutionary classifications.
1 / 1
Tree:  A type of graph where each element is connected to other elements in a way that forms a hierarchical network without cycles. It consists of interconnected nodes that exhibit a parent-child relationship, with each node having only one parent except for the root node.
1 / 1
ChatGPT
ChatGPT
I apologize for the repetition in my previous response. Here's an alternative definition:
Hierarchical Graph: A tree is a structure composed of interconnected nodes that establish a hierarchical relationship. Each node, except for the root node, has a single parent and can have multiple children. The connections between nodes, known as edges, signify the hierarchical dependencies and form a network that does not contain any cycles. Trees are widely used in various domains to represent and organize hierarchical information, such as file systems, organizational structures, and family trees.
1 / 1
Names for the ten levels in a course on active inference and predictive processing
1 / 1
ChatGPT
ChatGPT
Here are ten possible names for levels in a course on active inference and predictive processing:
Introduction to Active Inference
Fundamentals of Predictive Processing
Bayesian Inference and Probabilistic Models
Perception and Sensory Processing
Action Planning and Motor Control
Hierarchical Models and Generative Models
Variational Inference and Free Energy Minimization
Neural Mechanisms of Active Inference
Applications of Active Inference in Cognitive Science
Advanced Topics in Active Inference and Predictive Processing
Please note that these names are suggestions and can be tailored or modified based on the specific content and structure of the course.
1 / 1
Not quite, just like a one or two word title, like Neophyte, Expert, Zen Master and so on
1 / 1
ChatGPT
ChatGPT
Apologies for the misunderstanding. Here are ten one or two-word titles for levels in a course on active inference and predictive processing:
Novice
Apprentice
Practitioner
Journeyman
Explorer
Analyst
Specialist
Expert
Master
Guru
1 / 1
A few more definitions from the beginning that were not properly formatted.
1 / 1
ChatGPT
ChatGPT
Certainly! Here are the additional definitions with proper formatting:
Temporal Depth: The length of a time window or horizon considered in deep temporal models.
Uncertainty: The measure of unpredictability or expected surprise associated with a random variable.
Action: The dynamics, mechanisms, and measurements of behavior, involving active states enacted by an agent through policy selection.
Action planning: The process of an agent selecting an affordance based on inference of expected free energy.
Agency: The ability of an agent to engage in action and enact goal-driven selection based on preference.
Behavior: The sequence of actions that an agent enacts.
Policy: A sequence of actions reflected by a series of active states and implemented in policy selection.
Policy selection: The process of an agent engaging in action planning based on the minimization of expected free energy.
Preference: A parameter that ranks or scores the extent to which an agent values sensory input.
Active inference: A process theory related to the free energy principle that involves perception, cognition, and action.
Please let me know if there are any more definitions you would like to have formatted.
1 / 1
Free Research Preview. ChatGPT may produce inaccurate information about people, places, or facts.
ChatGPT May 24 Version
ChatGPT

