Composite Bayesian Optimization 
in function spaces using NEON—
Neural Epistemic Operator 
Networks
Leonardo Ferreira Guilhoto1 & Paris Perdikaris2
Operator learning is a rising field of scientific computing where inputs or outputs of a machine learning 
model are functions defined in infinite-dimensional spaces. In this paper, we introduce Neon (Neural 
Epistemic Operator Networks), an architecture for generating predictions with uncertainty using a 
single operator network backbone, which presents orders of magnitude less trainable parameters than 
deep ensembles of comparable performance. We showcase the utility of this method for sequential 
decision-making by examining the problem of composite Bayesian Optimization (BO), where we aim 
to optimize a function f = g ◦h, where h : X →C(Y , Rds) is an unknown map which outputs 
elements of a function space, and g : C(Y , Rds) →R is a known and cheap-to-compute functional. 
By comparing our approach to other state-of-the-art methods on toy and real world scenarios, we 
demonstrate that Neon achieves state-of-the-art performance while requiring orders of magnitude less 
trainable parameters.
Keywords  Deep learning, Autonomous experimentation, Uncertainty quantification
High-dimensional problems are prominent across all corners of scientific and industrial applications. Within 
this realm, optimizing black-box functions and operators can be computationally expensive and require large 
amounts of hard-to-obtain data for training surrogate models. Uncertainty quantification becomes a key element 
in this setting, as the ability to identify for what inputs a surrogate model is most uncertain offers a guiding 
principle for new data acquisition. However, existing methods for surrogate modeling with built-in uncertainty 
quantification, such as Gaussian Processes (GPs)1, have demonstrated difficulty in modeling problems in high 
dimensions. While other methods such as Bayesian neural networks2 (BNNs) and deep ensembles3 are able to 
mitigate this issue, their large computational cost can still be prohibitive for some applications. This problem 
becomes more prominent in Operator Learning, where either inputs or outputs of a model are functions residing 
in infinite-dimensional function spaces. The field of Operator Learning has had many advances in recent years4–9, 
with applications across many domains in the natural sciences and engineering, but so far its integration with 
uncertainty quantification is limited10,11.
In addition to safety-critical problems using deep learning such as ones in medicine12,13 and autonomous 
driving14, the generation of uncertainty measures can also be important for decision making when collecting 
new data in the physical sciences. Total uncertainty is often decomposed into two distinct parts: epistemic and 
aleatoric uncertainty. While epistemic uncertainty relates to ambiguity in a model due to lack of sufficient data or 
undersampling in certain regions of the domain, aleatoric uncertainty relates to ambiguity in the data itself due to 
noise. In particular, when sequentially collecting new data, being able to quantify uncertainty and to decompose 
it into aleatoric and epistemic components can be of great importance15–17. Bayesian Optimization18,19 (BO), 
also known as Black-Box Optimization (BBO), for example, iteratively collects new points of a hard-to-compute 
black-box function in order to maximize/minimize its value. The black-box nature of BO creates the need for 
accurate quantification of uncertainty in order to balance out exploration and exploitation of the design space.
A recent paradigm for studying uncertainty-producing models in deep learning is the framework of 
Epistemic Neural Networks (ENNs)17. The ENN family encompasses virtually any model which has built-in 
properties to estimate epistemic uncertainty, such BNNs2, deep ensembles3 and MCMC dropout20. In order 
to model a function f : X →Y , an ENN takes as input a feature vector x ∈X and an epistemic index 
1Graduate Group on Applied Mathematics & Computational Science, University of Pennsylvania, Philadelphia, PA, 
USA. 2Mechanical Engineering & Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA. email: 
guilhoto@sas.upenn.edu
OPEN
Scientific Reports |        (2024) 14:29199 
1
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports
z ∈Z , which is sampled at random from a distribution PZ independently of the input x. An ENN with 
parameters θ then outputs prediction fθ(x, z) ∈Y . Since the variable z has no connection to the data, it 
can be varied in order to produce an ensemble of predictions f(x, z1), . . . , f(x, zn) for the same input x, 
where z1, . . . , zn
iid
∼PZ. This allows us to analyze statistics of these predictions in order to quantify epistemic 
uncertainty. For example, the standard deviation of predictions for the same input x and different epistemic 
indexes z1, . . . , zn can be used as a measure of the uncertainty.
In the light of these advances, we propose integrating the ENN framework to operator learning problems in 
order to understand epistemic uncertainty in this setting. In addition, we also combine the EpiNet architecture17 
with deep operator network models4,21 to implement Neon, a computationally cheap alternative to deep 
ensembles of operator networks, which is currently the state-of-the-art approach to uncertainty quantification in 
operator learning. Not only does this approach generally require significantly less trainable parameters than deep 
ensembles, it can be implemented as an augmentation to any pre-trained model at a very cheap computational 
cost, leading to flexibility for many problems that require large neural operator models to get accurate results.
In the light of these challenges, the contributions of this paper are as follows:
•	 We propose Neon (Neural Epistemic Operator Networks), a method for quantifying epistemic uncertainty 
in operator learning. This framework can easily be implemented on pre-trained models and enables the 
quantification of epistemic uncertainty using a single model, removing the need to train large ensembles.
•	 We study different choices of acquisition functions for composite BO using the Epistemic Neural Network 
(ENN) framework. We additionally propose the Leaky Expected Improvement (L-EI) acquisition function, 
a variant of Expected Improvement (EI) that allows for easier optimization while retaining similar local ex­
trema.
•	 By examining established benchmarks and comparing the performance of Neon against the best results avail­
able in the literature22,23, we demonstrate Neon achieves state-of-the-art performance for high-dimensional 
composite BO while at times consisting of 1–2 orders of magnitude less training parameters compared to 
Deep Ensembles.
Background
Operator learning
Operator learning4–6,24 is a field of scientific machine learning that aims to learn maps between functional 
spaces using labeled data. Formally, we let C(X , Rd) denote the set of continuous functions from X  to Rd and, 
following the notation of21, if X  and Y  are compact spaces, du, ds ∈N and G : C(X , Rdu) →C(Y , Rds) 
is an operator between function spaces, the goal of operator learning is to learn the behaviour of G  from 
observations {(ui, si)}N
i=1 where ui ∈C(X , Rdu) and si = G (ui) ∈C(Y , Rds). This is done by fitting a 
model Fθ with trainable parameters θ ∈Θ ⊆Rdθ minimizing the empirical risk
	
L (θ) = 1
N
N
∑
i=1
||Fθ(ui) −si||2
L2 = 1
N
N
∑
i=1
||Fθ(ui) −G (ui)||2
L2.
(1)
It is also common to fit the model minimizing the relative empirical risk9,25,
Fig. 1.  Flow chart illustrating the Bayesian Optimization paradigm.
 
Scientific Reports |        (2024) 14:29199 
2
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
	
Lrelative(θ) = 1
N
N
∑
i=1
||Fθ(ui) −si||2
L2
||si||2
L2
= 1
N
N
∑
i=1
||Fθ(ui) −G (ui)||2
L2
||G (ui)||2
L2
,
(2)
which is the approach we take in the experiments carried out in this paper.
In many cases (including the ones considered in our experiments), the input to the operator G  can also be a 
finite-dimensional vector u ∈X ⊆Rdu instead of a proper function. Using the operator learning framework 
in this scenario, however, can still be advantageous, as existing architectures such as the DeepONet4,24, LOCA7, 
MIONet26 and more, allow for efficient evaluation of the output function s = G (u) ∈C(Y , Rds) at any desired 
query point y ∈Y  instead of being restricted to a fixed grid.
Composite Bayesian optimization
Bayesian optimization (BO) consists of maximizing a black-box function f : X →R where we do not have 
access to the gradients of f, but only evaluations f(x1), . . . f(xn) ∈R at a given set of points x1, . . . , xn ∈X. 
The goal of BO is then to determine arg maxx∈Xf(x) by iteratively evaluating f at new points with the fewest 
possible calls to the function f. In order to determine what points to evaluate f at next, we first fit a surrogate model 
to the data {(xi, f(xi))}N
i=1 which gives us a probability measure P over the possible functions ˆf : X →R that 
agree with the observations {(xi, f(xi))}N
i=1. Using this probability measure, we then define an acquisition 
function α : X →R and set xN+1 = arg maxx∈Xα(x). Intuitively, one can think of α as a function that 
quantifies the utility of evaluating f at a given point. There are many possible choices for acquisition functions 
in BO, which have different approaches to balancing out exploitation (evaluating f at points we believe f is high) 
and exploration (evaluating f at points where there is little information available). Some of these acquisition 
functions are discussed later in this manuscript.
Although vanilla BO already presents its fair share of challenges and open problems, in this paper we 
consider Composite Bayesian Optimization22,23,27,28, where the function f : X →R we wish to optimize 
is the composition f = g ◦h of two functions h : X →Y  and g : Y →R. In this setting, it is also assumed 
that h is a hard-to-compute black-box function, while g is a known map which can be computed exactly 
and cheaply. This setting is common in engineering applications, where h may represent a complex physical 
process which is hard to evaluate (such as the solution of a PDE, or the evolution of a complicated dynamical 
system), and g is a simple function (such as a directly computable property of a dynamical system like the final 
position of a trajectory). Composite BO is of particular importance to problems in the field of optimal control, 
and recent research has shown that this approach outperforms vanilla BO22,23,27, as in the latter approach only 
the direct function f is taken into account (ignoring known information about composite structure of f and 
the known map g).
In this paper, we consider composite BO cases where X ⊆Rdu is a finite-dimensional space and 
Y = C(Y , Rds) is a space of continuous functions. That is, h : X →C(Y , Rds) is a complex function for 
which obtaining data is expensive and g : C(Y , Rds) →R is a known and cheap-to-compute functional. As 
an example, consider the problem of optimizing the coverage area and interference of the service provided by 
a set of cell towers29. In this case, u ∈R30 encodes possible configurations of antenna transmission powers 
Fig. 2.  Example of the compositional structure of the Cell Towers problem, considered in our experiments 
section. The input u ∈X = R30 encodes transmission parameters of 15 cell towers, which are used to 
produce the maps h(u) ∈Y  seen above, where signal intensity and interference are plotted, respectively. This 
information is then used to compute a scalar f(u) = g(h(u)) ∈R which evaluates the quality of cellular 
service in the region. By using the gray-box nature of operator composite BO, we take advantage of the known 
compositional structure of f = g ◦h, and only need to model the behaviour of h.
 
Scientific Reports |        (2024) 14:29199 
3
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
and down-tilt angles of 15 different cell towers, while h(u) ∈C(R2, R2) is the function that outputs the 
signal power and interference strength, respectively, at any desired location in R2. An example plot for signal 
strength and interference intensity is shown in Fig. 2. Finally, f(u) = g(h(u)) ∈R uses this map to compute 
a scalar that evaluates the quality of coverage and extent of interference between towers. In this scenario, 
predicting the map h(u) of signal strength/interference is a challenging problem involving complex physics, 
while computing g given this map is a simple and computationally cheap task. For problems like this, it is 
possible to use operator learning to infer the map h from data and use composite BO to determine the best 
configuration u for antenna powers and down-tilt angles. We explore this particular problem, among others, 
in our experiments section.
The choice of using vanilla or composite BO is problem dependent and entails different trade-offs. If no 
compositional structure is known, and f is completely black-box, vanilla BO is the only possible approach. 
However, when information about the structure of f allows for the formulation f = g ◦h in the manner 
prescribed by the composite BO framework, studies show that the composite BO formulation achieves better 
results and faster convergence27,30.
Epistemic neural networks as a flexible framework for uncertainty-aware models
The Epistemic Neural Networks (ENNs)17 framework is a flexible formal setup that describes many existing 
methods of uncertainty estimation such as Bayesian Neural Networks (BNNs)2, dropout20 and Deep Ensembles3. 
An ENN with parameters θ ∈Θ ⊆Rdθ takes as input a feature vector x ∈Rdx along with a random index 
z ∈Rdz and outputs a prediction fθ(x, z). Under this framework, the random index z is sampled from 
probability distribution PZ independently from x and therefore has no connection to the data and can be varied 
in order to obtain different predictions.
For example, a deep ensemble with n networks falls into the ENN umbrella in the following manner. The 
random index z can take values in the discrete set {1, 2, . . . , n}, indicating which network we use to carry out 
the prediction. In this way, varying z gives us variety of predictions which allow us to estimate uncertainty by 
checking how much they agree or disagree with each other. If enough data is available and the model is well 
trained, we expect the predictions to not depend strongly on z, meaning that there is little disagreement between 
different networks. On the other hand, if our predictions vary a lot depending on z, this indicates that there is 
large model (also called epistemic) uncertainty. Another example of this are Bayesian neural networks (BNNs), 
where the weights of the network are sampled according to a re-parametrization trick using z, which in this case 
takes on continuous values. In17, the authors prove that BNNs are a special case of the ENN framework.
Under this framework, we can use the same feature x and vary z in order to estimate the epistemic uncertainty 
of our model, which is crucial in the context of Bayesian Optimization.
EpiNets
The paper17 also introduces EpiNets, which implements an ENN in a simple and computationally cheap manner 
as
	
fθ(x, z)
  
ENN
= µζ(x)
  
base net
+ ση (sg[ϕζ(x)], z)



EpiNet
.

(3)
Here, ζ is the parameters of the base network (which does not take z into account), η denotes the parameters 
of the EpiNet, θ = (ζ, η) is the overall set of trainable parameters, sg is a stop gradient operation that blocks 
gradient back-propagation from the EpiNet to the base network, and ϕζ is a function that extracts useful features 
from the base network, such as the last layer of activations concatenated with the original input.
The EpiNet itself is composed of two parts, a learnable component σL
η , and a prior component σP  which is 
initialized randomly and is not optimized,
	
ση (˜x, z)
  
EpiNet
= σL
η (˜x, z)
  
learnable
+ ασP (˜x, z)



prior
,
(4)
Paradigm
Maps
Known closed form
Unknown—must be modeled
Vanilla BO
X
f
−−−→R
N/A
f
Composite BO
X
h
−−−→Y
g
−−−→R
g
h
Operator Composite BO
X
h
−−−→C(Y , Rds)
g
−−−→R
g
h
Table 1.  Representation of the different BO paradigms, showing the relationship between the input space X of 
f : X →R and potentially known structures about f.  For non-operator composite BO, the intermediate space 
Y ⊆RdY  is taken to be a subset of RdY  for some dY ∈N, while in operator composite BO the intermediate 
space Y ⊆C(Y , Rds) is taken to be a space of continuous functions from Y  to Rds.
 
Scientific Reports |        (2024) 14:29199 
4
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
where α is a hyperparameter called the scale of the prior. Feeding the random index z along with the features 
ensures that z does in fact play a role in predictions, as the learnable component of the EpiNet has to learn to 
counteract the effect of the untrained prior component as opposed to making only trivial zero predictions during 
training.
EpiNets readily enable the quantification of epistemic uncertainty for any given neural network architecture, 
including any pre-trained models that can be treated as a black-box. Even for large base models with tens of 
millions of parameters, augmentation by a small EpiNet has been demonstrated to yield good uncertainty 
estimates at little extra computational cost17. This poses a significant advantage over deep ensembles, for 
example, where several models need to be trained. In addition, the EpiNet can be trained in conjunction to 
the base network, or at a later stage, after the base network has been trained and its parameters fixed. This 
yields further flexibility, as an EpiNet can be used to augment any pre-trained base network, even if it does not 
originally fit into the ENN umbrella.
Epistemic operator networks as surrogate models
Given an unknown function h : X →C(Y , Rds), we assume an epistemic model, which, given inputs u, y, z 
and parameters θ, computes predictions ˆhθ(u, y, z) ≈h(u)(y) ∈Rds, where u ∈X ⊆Rdu is a feature vector, 
y ∈Y  is a query point and z ∈Z  is a random epistemic index with probability distribution PZ over the 
space Z . Given u and y, the predictive distribution for the unknown quantity h(u)(y) is equal to that of the 
transformed random variable ˆhθ(u, y, Z) where Z ∼PZ. That is, draws from the predictive distribution of h(u)
(y) can be obtained by first sampling Z ∼PZ and then computing the forward pass ˆhθ(u, y, Z).
Alternatively, if the output of ˆhθ(u, y, z) is a probability distribution itself (in cases such as ones using 
Negative Log-Likelihood (NLL) loss), instead of a single point in Rds we model our predictive distribution for 
h(u)(y) ∈Rds as a mixture of the output of the model over different values of z
	
pθ(h(u)(y)|u, y) =
∫
p(h(u)(y)|u, y, z)PZ(z)dz =
∫
ˆhθ(u, y, z)PZ(z)dz = Ez
[ˆhθ(u, y, z)]
.
(5)
This implies our predictive distribution over the objective function f = g ◦h is
	
pθ(f(u)|u) =
∫
p(f(u)|u, z)PZ(z)dz =
∫
g(ˆhθ(u, ·, z))PZ(z)dz = Ez
[
g (ˆhθ(u, ·, z))]
.
(6)
Although we do not take this approach in the experiments considered in this paper, training a model in this 
manner further allows for disentangling aleatoric and epistemic uncertainty and is the potential subject of future 
research.
BO acquisition functions under the ENN framework
In this section we use the language of Epistemic Neural Networks (ENNs) to examine some possible choices 
for the acquisition function α used in BO. As previously described, BO aims to optimize a black-box function 
f : X →R. Given a trained epistemic model Gθ : X × Z →R, different choices of acquisition function 
α : X →R can be made. In the case of Operator Composite BO, we have that Gθ(u, z) = g (ˆhθ(u, ·, z))
, 
where g : C(Y , Rds) →R is a known and cheap-to-evaluate functional and ˆhθ : X × Y × Z →Rds is a 
neural epistemic operator network trained on the available data.
Popular choices in the literature are Expected Improvement (EI), Probability of Improvement (PI) and Lower 
Confidence Bound (LCB), also called Upper Confidence Bound (UCB) in the case of function minimization 
instead of maximization. Some of these common choices are summarized in Table 2. It should be noted that the 
definition of these functions is the same in both vanilla and composite BO.
An important property of all the acquisition functions considered in this paper and detailed in Table 2 is 
that they are expectations over the epistemic index z and can therefore be written as α(u) = Ez∼PZ[α′(u, z)], 
where α′ : X × Z →R. Therefore, we can approximate their value via Monte Carlo by averaging the quantity 
of interest over different epistemic indices z1, . . . , zk sampled in an i.i.d. manner from Pz. This is important, 
Acquisition function α
Hyperparameters
ENN formulation
Expected Improvement (EI)
None
Ez∼PZ [ReLU (Gθ(x, z) −y∗)]
Leaky Expected Improvement (L-EI)
δ ∈R>0
Ez∼PZ [LeakyReLUδ (Gθ(x, z) −y∗)]
Lower Confidence Bound (LCB)
β ∈R>0
Ez∼PZ [Gθ(x, z)] + β√
V arz∼PZ [Gθ(x, z)]
Table 2.  Some possible choices of acquisition functions for Bayesian Optimization.  In the case of of 
EI and L-EI, y∗=
max
i=1,...,N f(ui) is the best objective value found so far. In the case of LCB, β > 0 is a 
hyperparameter that controls the exploration/exploitation trade-off.
 
Scientific Reports |        (2024) 14:29199 
5
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
as the predictive distribution generated by Gθ is often intractable or non-analytical. Using a Monte Carlo 
approximation, we can obtain α(u) ≈1
k
∑k
i=1 α′(u, zi).
The EI acquisition function focuses on improvement over the best value acquired so far. That is, if 
{(ui, f(ui))}N
i=1 is the data collected so far and we set y∗:=
max
i=1,...,N f(ui), then EI is defined in terms of our 
belief of surpassing this value. As the name suggests, we compute the expected improvement from collecting this 
new point αEI(u) = E[max{0, f(u) −y∗}] = Ez∼PZ[max{0, Gθ(u, z) −y∗}], where this is determined by 
the surrogate model Gθ.
The LCB acquisition function differs from EI by having a hyperparameter β > 0 which explicitly 
controls the exploration/exploitation trade-off. The LCB acquisition function is composed of two terms: 
µ(u) = Eu∼PZ[Gθ(u, z)], which represents the expected value of f(u) according to our surrogate model, 
and σ(u) =
√
V arz∼PZ[Gθ(u, z)], which represents the epistemic uncertainty of the prediction. It is also 
common to instead set σ(u) = Eu∼PZ [|Gθ(u, z) −µ(u)|]. By combining these two terms under a scaling 
controlled by β, we obtain αLCB(u) := µ(u) + βσ(u), where a higher choice of β leads to prioritizing 
regions of space where our predictions are most uncertain, and lower choices of β lead to ignoring uncertainty 
and focusing on regions that have the highest mean prediction. The value of β may be fixed for the entire 
BO process, or dependent on the iteration number t. In particular, scaling βt ∝log(t2) leads to provable 
guarantees for the regret in the GP bandit setting31.
Optimization of acquisition functions
In order to carry out BO, it is necessary to compute unew := arg maxu∈Xα(u) at each iteration, which entails 
solving an optimization problem. As described in the previous section, values of α(u) are determined in a 
Monte Carlo fashion as
	
α(u) = Ez∼PZ[α′(u, z)] ≈1
k
k
∑
i=1
α′(u, zi),
zi
iid
∼PZ.
(7)
Since all models and acquisition functions considered in this paper are almost-everywhere differentiable 
as a function of u ∈X, we optimize α using the SciPy32 implementation of the constrained Limited 
memory BFGS (L-BFGS) algorithm33. We carry out this process nreset times using different initial points 
u1
0, . . . , unreset
0
 to obtain converged solutions u1
ﬁnal, . . . , unreset
ﬁnal  and set the new point to be collected as 
unew = arg maxi=1,...,nresetα(ui
ﬁnal). Due to the highly non-convex nature of the problems considered in 
this paper, nreset is an important hyperparameter to consider, and we’ve found that setting nreset = 500 yields 
good results in practice. It should also be noted that each optimization ui
0 →ui
ﬁnal can be done independently, 
so the process of obtaining all the xi
ﬁnal is easily parallelised. The computational time for each function for 
each of the experiments considered are reported in the supplementary material.
Parallel acquisition
The acquisition functions described in Table 2 assume that q = 1 new points are acquired at each iteration of BO. 
Extensions of these methods such as q-EI34 and more35,36 propose to determine arg maxx1,...,xq∈Xqαq(x1, . . . , xq) 
where at each step q ≥1 different inputs are acquired simultaneously. These multi-acquisition functions are also 
compatible with the Neon framework and an experiment in this setting is briefly explored in the appendix.
Methods
Neon—an architecture for epistemic operator learning
A key disadvantage of using Deep Ensembles to quantify epistemic uncertainty in neural networks is the 
necessity to train several models at once, which can be too computationally expensive. To this end, we introduce 
Neon (Neural Epistemic Operator Network), which is a combination of the operator learning framework4,5,21 
with the EpiNet17 architecture. More specifically, it is a version of the EpiNet architecture described in section 
“EpiNets” where the base network is an operator learning model. The two main advantages of Neon over Deep 
Ensembles are the fact that (a) Neon requires training only a single model to carry out epistemic UQ; and (b) 
any pre-trained operator network can be seamlessly be converted into a Neon architecture by introducing a 
small epinet, which can be cheaply trained while freezing the parameters of the base network.
The operator learning architectures used as base networks in this paper follow a encoder/decoder structure, 
where the encoder eξe : Rdu →Rdβ with parameters ξe takes in as input u ∈Rdu and outputs a latent variable 
β = eξe(u) ∈Rdβ, and the decoder dξd : Rdβ × Y →Rds with parameters ξd takes as input β and a query 
point y ∈Y  and outputs the prediction dξd(β, y) ∈Rds. Thus, the base network µξ makes predictions of 
the form µξ(u, y) = dξd(β, y) = dξd(eξe(u), y), where ξ = (ξe, ξd) are the trainable parameters. In the 
experiments considered in this paper, the encoder is a Multi-Layer Perceptron (MLP), while the decoder 
is either another MLP taking as input a concatenation of β and a Fourier-Feature37 encoding of y, or a Split 
Decoder, which is an architecture inspired by38 and further described below. Despite these specific choices, 
Neon can use any other choice of architecture for the backbone of the encoder or decoder.
As for the architectures of the EpiNets, we use MLPs, which take as input ˜x = sg[ϕξ(u, y)] and z, where sg is 
the stop gradient operation, which stops backpropagation from the EpiNet to the base network during training. In 
the architectures implemented in this paper, we take ϕξ(u, y) to be the concatenation ϕξ(u, y) = (β, µlast, y), 
where β = eξe(u) is the output of the encoder, µlast = µlast
ξ
(u, y) is the last layer activations of the decoder, 
Scientific Reports |        (2024) 14:29199 
6
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
and y ∈Y  is the query point. Both the trainable and prior EpiNet networks then take as input the pair (˜x, z). 
This choice is similar to the original formulation of EpiNets in17.
A diagram illustrating this choice of architecture can be seen in Fig. 3, and details about hyperparameters 
used for each experiment can be seen in the appendix.
Decoder architectures
The basic formulation of Neon entails base networks that follows an encoder/decoder structure 
µξ(u, y) = dξd(β, y) = dξd(eξe(u), y), where ξ = (ξe, ξd) are the trainable parameters of the encoder and 
decoder, respectively. Although Neon allows for many different choices of architecture for the encoder and 
decoder, in the experiments carried out in this paper encoders are always MLPs, while decoders are either 
Concat Decoders or Split Decoders, which are described in this section and illustrated in Fig. 4. Other reasonable 
choices would be convolutional network or a Fourier Neural Operator (FNO)5 for the encoder, and attention-
based decoders7,38.
The simpler among the two decoders we used, Concat Decoder is defined by the concatenation of the latent 
representation β ∈Rdβ of the input function u with a Fourier feature encoding of the query point y ∈Y . 
Although this architecture yields good results on simpler tasks, it may under-perform in cases where a larger 
latent dimension dβ is needed38. This would be the case when the target output function concentrate on a high-
dimensional nonlinear manifold21.
The Split Decoder approach, inspired by38, instead splits β into smaller components β = (β1, β2, . . . , βN) 
where βi ∈Rdβ/N. These βi are then used to modulate the features of each hidden layer in the decoder. This 
approach helped the authors better fit the data by having the hyperparameter dβ be larger than it otherwise 
Fig. 4.  Diagrams representing the two decoders used in the experiments considered in this paper. On the 
left, the Concat Decoder concatenates β and y, feeding this larger vector into an MLP. On the right, the Split 
Decoder breaks β into smaller components β1, . . . , βN which are progressively concatenated and fed into 
intermediate layers of an MLP.
 
Fig. 3.  Diagrams for the architectures used in this paper. The Neon architecture (top) combines the 
deterministic output of the base network with the stochastic output of the small EpiNet in order to produce 
predictions fθ(u, y, z). The base network (bottom left) uses an encoder/decoder structure, with the 
encoder being dependent only on u, while the decoder receives as input the latent representation β(u) and 
a Fourier feature encoding of the query point y. Finally, the EpiNet (bottom right) receives as input features 
˜x = sg[ϕξ(u, y)] from the base network along with a random epistemic index z ∼PZ. Here, sg denotes the 
“stop gradient” operation. The EpiNet is composed of a learnable component σL
η  that changes through training, 
and a prior network σP  that is not affected by the data.
 
Scientific Reports |        (2024) 14:29199 
7
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
would be able to. This larger value of dβ allowed the encoder to preserve more information about the input 
function u and create a richer latent representation.
Leaky expected improvement
The Expected Improvement acquisition function αEI(u) = Ez∼PZ[max{0, Gθ(u, z) −y∗}] can be 
equivalently expressed as αEI(u) = Ez∼PZ[ReLU(Gθ(u, z) −y∗)], where ReLU(x) := max{0, x} is the 
Rectified Linear Unit function. The ReLU function became a popular activation function in deep learning 
partially because it helps mitigate the vanishing gradients39 problem, where the derivative of a neural network 
is 0 in large regions of the input space. Although ReLU aleviates this problem when compared to sigmoid 
activations, it remains prominent across many areas of machine learning where the ReLU function is used, and 
is also related to the dying ReLU problem. In the case of the EI acquisition, vanishing gradients and outputs can 
become problematic when carrying out optimization with algorithms that use information about derivatives of 
a function. This challenge in optimizing EI has been analyzed in detail in40. In particular, we have found that 
this issue completely prevented any meaningful optimization of the EI acquisition function in our experiments 
via the LBFGS optimizer. In light of this fact, this paper also introduces the Leaky Expected Improvement 
(L-EI) acquisition function, where ReLU is substituted by LeakyReLU41 in the formulation of α. This greatly 
facilitates the process of determining unew = arg maxu∈XαL-EI(u), while maintaining similar global optima 
as αEI. Following the notation from section “BO acquisition functions under the ENN framework”, we define 
αL-EI(u) = E[α′
L-EI(u, z)] where
	
α′
L-EI(u, z) = LeakyReLU(Gθ(u, z) −y∗) =
{ Gθ(u, z) −y∗
if Gθ(u, z) −y∗≥0
0.01(Gθ(u, z) −y∗)
if Gθ(u, z) −y∗< 0 
(8)
Since the number 0.01 in the formulation of α′
L-EI is arbitrary, this can be generalized to
	
α′δ
L-EI(u, z) = LeakyReLUδ(Gθ(u, z) −y∗) =
{ Gθ(u, z) −y∗
if Gθ(u, z) −y∗≥0
δ(Gθ(u, z) −y∗)
if Gθ(u, z) −y∗< 0 
(9)
where we substitute 0.01 with an arbitrary δ > 0. In cases where the subscript δ is omitted, we assume the 
default choice of δ = 0.01. This generalization allows us to adjust the negative slope of this acquisition function 
and make it closer to the original formulation of expected improvement, if desired. We prove in the appendix 
the following short theorem, which states that for any given bounded function f we can make Leaky Expected 
Improvement as close to EI as desired, no matter the choice of surrogate model Gθ : X × Z →R.
Theorem 1  Let ϵ > 0 and f : X →R be a bounded function. Then there exists a choice of δ > 0 such that for 
any surrogate model Gθ we have that |α′δ
L-EI(x, z) −α′
EI(x, z)| < ϵ. This implies that |αδ
L-EI(x) −αEI(x)| < ϵ.
To the best of the authors’ knowledge, this Leaky Expected Improvement (L-EI) acquisition function has not 
been presented before, but is similar in flavor to the techniques presented in40, where other alternatives to the EI 
acquisition are proposed.
Results
In this section we employ our method on standard synthetic benchmarks from the composite BO literature. By 
augmenting a deterministic operator network with a small EpiNet, thus creating Neon, we observe considerably 
less data and model-size requirements in order to obtain good performance. Across all experiments we observe 
comparable or better performance to state-of-the-art approaches, while using orders of magnitude less trainable 
parameters than deep ensembles. A comparison on the total number of trainable parameters between Neon and 
Deep Ensembles can be seen in Table 3. Since GPs are non-parametric models, we do not include it in the table, 
although this method was also considered as a baseline in all experiments.
In what follows, we wish to optimize a function f : X →R with compositional structure f = g ◦h 
where X ⊆Rdu is a finite dimensional space, h : X →C(Y , Rds) is an unknown map from X to a space 
of continuous functions, and g : C(Y , Rds) →R is a known and cheap-to-evaluate functional. In practice, 
we must evaluate the function h(u) on several points y1, . . . , ym ∈Y  in order to compute f(u) = g(h(u)). 
Although Neon’s super resolution capabilities as an operator network allow for the evaluation of h(u) on any 
arbitrary point y ∈Y , we limit ourselves to a fixed grid in order to be compatible with the existing literature22,23 
and provide a fair comparison. We then wish to optimize f(u) := g(h(u)) using the procedure described in the 
“Methods” section.
We display partial results in Figs. 5 and 6, comparing the best methods for Neon, RPN DeepONet ensemble22 
and GP23 approaches, and further comparisons can be found in the supplementary material.
Model\Problem
Pollutants
PDE Brusselator
Optical Interferometer
Cell towers
Neon
27,746
38,820
195,728
93,096
RPN DeepONet Ensamble22
1,123,072
1,131,264
45,152
N/A
Table 3.  Number of trainable parameters for models used in this paper and in22.
 
Scientific Reports |        (2024) 14:29199 
8
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
Environment model function
This example consists of modeling a chemical spill in a long and narrow river, and is a common synthetic 
benchmark in the Bayesian optimization literature22,27. Given the concentration of a chemical along the river at 
different points in time and space, the objective of this problem is to determine the original conditions of the spills: 
total mass, time, position and diffusion rate. For this problem, du = 4 with X =⊂Rdu and h : X →C(Y , R), 
with h(u) being evaluated on a 3x4 grid on the domain Y = [0, 2.5] × [15, 60] ⊂R2. Further details about the 
underlying process can be found in the appendix as well as in27,42.
Brusselator PDE
This problem attempts to determine the optimal diffusion and reaction rate parameters to stabilize a 
chemical dynamical system. This dynamical system can be modeled according to a PDE described in the 
py-pde43 
documentation 
​h​t​t​p​s​:​/​/​p​y​-​p​d​e​.​r​e​a​d​t​h​e​d​o​c​s​.​i​o​​/​e​n​/​l​a​t​e​s​t​/​e​x​a​m​p​l​e​s​_​g​a​l​l​e​r​y​/​p​d​e​_​b​r​u​s​s​e​l​a​t​o​r​_​e​x​p​
r​e​s​s​i​o​n​.​h​t​m​l​​. The goal is then to minimize the the weighted variance of of the solution of this PDE, which 
can be thought of as finding a stable configuration of the chemical reaction. For this problem, du = 4 with 
X = [0.1, 5]2 × [0.01, 5]2 ⊂Rdu and h : X →C(Y , R2), with h(u) being evaluated on a 64x64 grid on the 
domain Y = [0, 1]2 ⊂R2. Ground truth solutions are obtained via the py-pde43 package.
Fig. 6.  Experimental results for the Optical Interferometer (left) and Cell Towers (right) problems. For the 
interferometer case, we plot the acquisition function that resulted in the lowest final mean objective across 5 
different seeds for Neon, RPN22 and GP23 approaches. For the cell towers case, we plot comparisons between 
the L-EI acquisition function and LCB using β = 0.1. Remaining comparisons across different methods can be 
seen in the appendix. Our approach performs significantly better on the optical interferometer problem, and 
indicate good behaviour on the cell towers problem. Following22, the uncertainty bands indicate 20% of the 
standard deviation band.
 
Fig. 5.  Experimental results for the Environment Model (left) and Brusselator PDE (right) problems. In both 
cases we plot the acquisition function that resulted in the lowest final mean objective across 10 different seeds 
for Neon, RPN Ensemble22 and GP23 approaches. Remaining comparisons across different methods can be 
seen in the appendix. As can be seen, our approach performs significantly better on the environmental model 
problem, and comparably well on the Brusselator PDE. Following22, the uncertainty bands indicate 20% of the 
standard deviation band.
 
Scientific Reports |        (2024) 14:29199 
9
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
Optical interferometer
This problem consist of aligning a Mach-Zehnder interferometer by determining the positional parameters of 
two mirrors in order to minimize optical interference and thus increase visibility, which is measured as defined 
in44. For this problem, du = 4 with X = [−1, 1]4 ⊂Rdu and h : X →C(Y , R16), with h(u) being evaluated 
on a 64x64 grid on the domain Y = [0, 1]2 ⊂R2. Ground truth solutions are obtained using the code from44, 
available at https:​//gith​ub.​com/dmitrySor​okin/interferobo​tProject.
Cell towers
This problem consists of optimizing parameters of 15 different cell service towers in order to maximize coverage 
area and minimize signal interference between towers. Each tower has a downtilt angle parameter lying in 
(0, 10), as well as a power level parameter lying in (30, 50), meaning that the input dimension of this problem is 
du = 30, with inputs u ∈(0, 10)15 × (30, 50)15. The function h : X →C(R2, R2) then uses these parameters 
to compute the map of coverage and interference strengths, respectively. An example of such maps can be seen 
in Figure 2. We compute the ground truth values of h(u) using the code presented in29 and available at ​h​t​t​p​s​:​
/​/​g​i​t​h​u​b​.​c​o​m​/​R​y​a​n​d​r​y​1​s​t​/​C​C​O​-​i​n​-​O​R​A​N​​, which creates results in a 241 × 241 grid, then downsampling to 
50 × 50, as done in23. We then use the objective function g : C(R2, R2) →R presented in23 to obtain the final 
score f(u) = g(h(u)) ∈R for a given set of parameters u.
Discussion
In this paper we propose a unified framework for understanding uncertainty in operator learning and high-
dimensional regression, based on the general language of Epistemic Neural Networks (ENNs). We combine ideas 
from ENNs and operator learning to create Neon, a general framework for epistemic uncertainty quantification 
in neural operators using a single backbone architecture, as opposed to an ensemble as is done in3,22. Neon works 
by augmenting any operator network with an EpiNet, a small neural network as described in17, which allows for 
easy and inexpensive quantification of epistemic uncertainty.
By carrying out numerical experiments on four different benchmarks for operator composite BO, we 
demonstrate Neon achieves similar or better performance to state-of-the-art methods while often using orders 
of magnitude less training parameters than deep ensembles, as can be seen in Table 3.
In the more complex case of the Optical Interferometer, an ensemble of small networks is generally unable to 
capture the complex nature of the map h. As such, we use a single larger network augmented by a small EpiNet 
(195,728 trainable parameters in total) instead of an ensemble of small networks as was done in22. This led to the 
biggest improvement in performance between the two methods among the cases considered. The implementation 
of Neon allows for the added power of a larger network while still capturing epistemic uncertainty, whereas an 
ensemble of equally powerful networks would present a much higher computational cost.
Future research could explore better architectures for EpiNets in high-dimensional uncertainty quantification 
or new applications, such as active learning for operator networks. Integrating EpiNets with popular architectures 
like transformers and U-Nets remains a promising and unexplored area as well.
Data availibility
The data and code used in this paper is available upon request to the authors and will be available on the Predic­
tive Intelligence Lab GitHub at a later time: https://github.com/PredictiveIntelligenceLab/.
Received: 8 April 2024; Accepted: 11 November 2024
References
	 1.	 Rasmussen, C. E. & Williams, C. K. I. Gaussian Processes for Machine Learning.  Adaptive Computation and Machine Learning (MIT 
Press, 2006).
	 2.	 Goan, E. & Fookes, C. Bayesian neural networks: An introduction and survey. In Case Studies in Applied Bayesian Data Science 
45–87 (Springer International Publishing, 2020). https://doi.org/10.1007/978-3-030-42553-1_3.
	 3.	 Lakshminarayanan, B., Pritzel, A. & Blundell, C. Simple and scalable predictive uncertainty estimation using deep ensembles. 
https://doi.org/10.48550/ARXIV.1612.01474 (2016).
	 4.	 Lu, L., Jin, P., Pang, G., Zhang, Z. & Karniadakis, G. E. Learning nonlinear operators via DeepONet based on the universal 
approximation theorem of operators. Nat. Mach. Intell. 3, 218–229. https://doi.org/10.1038/s42256-021-00302-5 (2021).
	 5.	 Li, Z. et al. Fourier neural operator for parametric partial differential equations (2021). arXiv:2010.08895.
	 6.	 Kovachki, N. et al. Neural operator: Learning maps between function spaces with applications to pdes. J. Mach. Learn. Res. 24, 
1–97 (2023).
	 7.	 Kissas, G. et al. Learning operators with coupled attention. J. Mach. Learn. Res. 23, 9636–9698 (2022).
	 8.	 Wang, S., Wang, H. & Perdikaris, P. Learning the solution operator of parametric partial differential equations with physics-
informed deeponets. Sci. Adv. 7, eabi8605 (2021).
	 9.	 Wang, S., Wang, H. & Perdikaris, P. Improved architectures and training algorithms for deep operator networks. J. Sci. Comput. 92, 
35 (2022).
	10.	 Yang, Y., Kissas, G. & Perdikaris, P. Scalable uncertainty quantification for deep operator networks using randomized priors. 
Comput. Methods Appl. Mech. Eng. 399, 115399 (2022).
	11.	 Psaros, A. F., Meng, X., Zou, Z., Guo, L. & Karniadakis, G. E. Uncertainty quantification in scientific machine learning: Methods, 
metrics, and comparisons. J. Comput. Phys. 477, 111902 (2023).
	12.	 Filos, A. et al. A systematic comparison of bayesian deep learning robustness in diabetic retinopathy tasks (2019). arXiv:1912.10481.
	13.	 Esteva, A. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118. ​h​t​t​p​s​:​/​/​d​o​i​.​o​r​g​/​
1​0​.​1​0​3​8​/​n​a​t​u​r​e​2​1​0​5​6​​ (2017).
	14.	 Huang, Y. & Chen, Y. Autonomous driving with deep learning: A survey of state-of-art technologies (2020). arXiv:2006.06091.
	15.	 Houlsby, N., Huszár, F., Ghahramani, Z. & Lengyel, M. Bayesian active learning for classification and preference learning, ​h​t​t​p​s​:​/​/​
d​o​i​.​o​r​g​/​1​0​.​4​8​5​5​0​/​A​R​X​I​V​.​1​1​1​2​.​5​7​4​5​​ (2011).
Scientific Reports |        (2024) 14:29199 
10
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
	16.	 Kirsch, A., van Amersfoort, J. & Gal, Y. Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning. ​h​t​t​p​s​:​
/​/​d​o​i​.​o​r​g​/​1​0​.​4​8​5​5​0​/​A​R​X​I​V​.​1​9​0​6​.​0​8​1​5​8​​ (2019).
	17.	 Osband, I. et al. Epistemic neural networks. CoRR. arXiv:2107.08924 (2021).
	18.	 Wang, X., Jin, Y., Schmitt, S. & Olhofer, M. Recent advances in bayesian optimization. arXiv:2206.03301 (2022).
	19.	 Balandat, M. et al. Botorch: Programmable bayesian optimization in pytorch. CoRR. arXiv:1910.06403 (2019).
	20.	 Gal, Y. & Ghahramani, Z. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. arXiv:1506.02142 
(2016).
	21.	 Seidman, J. H., Kissas, G., Perdikaris, P. & Pappas, G. J. Nomad: Nonlinear manifold decoders for operator learning. arXiv:2206.03551 
(2022).
	22.	 Bhouri, M. A., Joly, M., Yu, R., Sarkar, S. & Perdikaris, P. Scalable bayesian optimization with randomized prior networks. Comput. 
Methods Appl. Mech. Eng. 417, 116428. https://doi.org/10.1016/j.cma.2023.116428 (2023).
	23.	 Maddox, W. J., Balandat, M., Wilson, A. G. & Bakshy, E. Bayesian optimization with high-dimensional outputs. Adv. Neural. Inf. 
Process. Syst. 34, 19274–19287 (2021).
	24.	 Chen, T. & Chen, H. Universal approximation to nonlinear operators by neural networks with arbitrary activation functions and 
its application to dynamical systems. IEEE Trans. Neural Netw. 6, 911–917. https://doi.org/10.1109/72.392253 (1995).
	25.	 Di Leoni, P. C., Lu, L., Meneveau, C., Karniadakis, G. E. & Zaki, T. A. Neural operator prediction of linear instability waves in high-
speed boundary layers. J. Comput. Phys. 474, 111793 (2023).
	26.	 Jin, P., Meng, S. & Lu, L. Mionet: Learning multiple-input operators via tensor product. arXiv:2202.06137 (2022).
	27.	 Astudillo, R. & Frazier, P. I. Bayesian optimization of composite functions. arXiv:1906.01537 (2019).
	28.	 Maus, N., Lin, Z. J., Balandat, M. & Bakshy, E. Joint composite latent space bayesian optimization. arXiv preprint. arXiv:2311.02213 
(2023).
	29.	 Dreifuerst, R. M. et al. Optimizing coverage and capacity in cellular networks using machine learning. In ICASSP 2021-2021 IEEE 
International Conference on Acoustics, Speech and Signal Processing (ICASSP) 8138–8142 (IEEE, 2021).
	30.	 Kim, S. et al. Deep learning for bayesian optimization of scientific problems with high-dimensional structure. Trans. Mach. Learn. 
Res. 2022, 859 (2022).
	31.	 Srinivas, N., Krause, A., Kakade, S. M. & Seeger, M. W. Gaussian process bandits without regret: An experimental design approach. 
CoRR. arXiv:0912.3995 (2009).
	32.	 Virtanen, P. et al. SciPy 1.0: fundamental algorithms for scientific computing in python. Nat. Methods 17, 261–272. ​h​t​t​p​s​:​/​/​d​o​i​.​o​r​g​
/​1​0​.​1​0​3​8​/​s​4​1​5​9​2​-​0​1​9​-​0​6​8​6​-​2​​ (2020).
	33.	 Liu, D. C. & Nocedal, J. On the limited memory bfgs method for large scale optimization. Math. Program. 45, 503–528 (1989).
	34.	 Ginsbourger, D., Le Riche, R. & Carraro, L. Kriging is well-suited to parallelize optimization. In Computational Intelligence in 
Expensive Optimization Problems 131–162 (Springer, 2010).
	35.	 Daulton, S., Balandat, M. & Bakshy, E. Differentiable expected hypervolume improvement for parallel multi-objective bayesian 
optimization. Adv. Neural. Inf. Process. Syst. 33, 9851–9864 (2020).
	36.	 Wang, J., Clark, S.  C., Liu, E. & Frazier, P.  I. Parallel bayesian global optimization of expensive functions. arXiv preprint. 
arXiv:1602.05149 (2016).
	37.	 Tancik, M. et al. Fourier features let networks learn high frequency functions in low dimensional domains. NeurIPS (2020).
	38.	 Rebain, D. et al. Attention beats concatenation for conditioning neural fields. arXiv:2209.10684 (2022).
	39.	 Pascanu, R., Mikolov, T. & Bengio, Y. Understanding the exploding gradient problem. CoRR. arXiv:1211.5063(2012) (2012).
	40.	 Ament, S., Daulton, S., Eriksson, D., Balandat, M. & Bakshy, E. Unexpected improvements to expected improvement for bayesian 
optimization. Adv. Neural Inf. Process. Syst. 36, 56 (2024).
	41.	 Maas, A. L., Hannun, A. Y., Ng, A. Y. et al. Rectifier nonlinearities improve neural network acoustic models. In Proc. icml, vol. 30-1 
3 (Atlanta, 2013).
	42.	 Bliznyuk, N. et al. Bayesian calibration and uncertainty analysis for computationally expensive models using optimization and 
radial basis function approximation. J. Comput. Graph. Stat. 17, 270–294 (2008).
	43.	 Zwicker, D. py-pde: A python package for solving partial differential equations. J. Open Source Softw. 5, 2158. ​h​t​t​p​s​:​/​/​d​o​i​.​o​r​g​/​1​0​.​2​
1​1​0​5​/​j​o​s​s​.​0​2​1​5​8​​ (2020).
	44.	 Sorokin, D., Ulanov, A., Sazhina, E. & Lvovsky, A. Interferobot: aligning an optical interferometer by a reinforcement learning 
agent. arXiv:2006.02252 (2021).
	45.	 Bradbury, J. et al. JAX: composable transformations of Python+NumPy programs (2018).
	46.	 Heek, J. et al. Flax: A neural network library and ecosystem for JAX (2023).
	47.	 Hunter, J. D. Matplotlib: A 2d graphics environment. Comput. Sci. Eng. 9, 90–95. https://doi.org/10.1109/MCSE.2007.55 (2007).
	48.	 Harris, C. R. et al. Array programming with NumPy. Nature 585, 357–362. https://doi.org/10.1038/s41586-020-2649-2 (2020).
Acknowledgements
We would like to acknowledge support from the US Department of Energy under the Advanced Scientific Com­
puting Research program (grant DE-SC0024563), the US National Science Foundation (NSF) Soft AE Research 
Traineeship (NRT) Program (NSF grant 2152205) and the Samsung GRO Fellowship program. We also thank 
Shyam Sankaran for helpful feedback when reviewing the manuscript and the developers of software that ena­
bled this research, including JAX45, Flax46 Matplotlib47 and NumPy48.
Author contributions
L.F.G. and P.P. conceived the methodology. L.F.G. conducted the experiments and analysed the results. P.P. pro­
vided funding and supervised this study. All authors reviewed the manuscript.
Competing interests
To the best of the author’s knowledge, they have no competing interests related to this research.
Additional information
Supplementary Information The online version contains supplementary material available at ​h​t​t​p​s​:​/​/​d​o​i​.​o​r​g​/​1​
0​.​1​0​3​8​/​s​4​1​5​9​8​-​0​2​4​-​7​9​6​2​1​-​7​​.​
Correspondence and requests for materials should be addressed to L.F.G.
Reprints and permissions information is available at www.nature.com/reprints.
Publisher’s note  Springer Nature remains neutral with regard to jurisdictional claims in published maps and 
institutional affiliations.
Scientific Reports |        (2024) 14:29199 
11
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
Open Access   This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 
4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in 
any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide 
a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have 
permission under this licence to share adapted material derived from this article or parts of it. The images or 
other third party material in this article are included in the article’s Creative Commons licence, unless indicated 
otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence 
and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to 
obtain permission directly from the copyright holder. To view a copy of this licence, visit ​h​t​t​p​:​/​/​c​r​e​a​t​i​v​e​c​o​m​m​o​
n​s​.​o​r​g​/​l​i​c​e​n​s​e​s​/​b​y​-​n​c​-​n​d​/​4​.​0​/​​.​
© The Author(s) 2024 
Scientific Reports |        (2024) 14:29199 
12
| https://doi.org/10.1038/s41598-024-79621-7
www.nature.com/scientificreports/
